import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Thu Nov 02 2023 {{ 'date': '2023-11-02T17:11:32.863Z' }}

### Yann LeCun: AI one-percenters seizing power forever is real doomsday scenario

#### [Submission URL](https://www.businessinsider.com/sam-altman-and-demis-hassabis-just-want-to-control-ai-2023-10) | 768 points | by [g42gregory](https://news.ycombinator.com/user?id=g42gregory) | [826 comments](https://news.ycombinator.com/item?id=38108873)

Yann LeCun, the chief AI scientist at Meta, has criticized prominent AI leaders for spreading doomsday scenarios about AI risks. In a post on X, LeCun accused figures such as OpenAI's Sam Altman, Google DeepMind's Demis Hassabis, and Anthropic's Dario Amodei of engaging in "fear-mongering" and "massive corporate lobbying" in order to gain control over the AI industry. LeCun argues that the real threat lies in a small number of companies controlling AI and robbing others of its riches, rather than in far-fetched doomsday scenarios. He believes that the focus should be on how AI is developed and the need for open collaboration rather than on hypothetical dangers.

The discussion on the submission starts with a comment about regulatory capture and the attempt by large AI companies to gain control over the AI industry. Some commenters disagree with this view, stating that open collaboration and licensing requirements are necessary to prevent malicious software applications. There is a debate about whether to take Eliezer Yudkowsky's ideas seriously, with some saying that he advocates extreme measures to prevent AI risks globally, while others criticize him for his far-fetched thought experiments. One commenter suggests that AI power should be checked, similar to concerns about Boston Dynamics and OpenAI collaborating. There is also a discussion about the history of technology and its potential risks, with some pointing out the Luddite movement and the potential negative effects of nuclear weapons. Some commenters argue that Yann LeCun's fear is unfounded and that the real dangers of AI should be taken seriously. There is a tangential discussion about Yudkowsky's Twitter tweets and his views on AI risks. The discussion also mentions the influence of AI in science fiction, with references to movies like "2001: A Space Odyssey" and books like "Frankenstein." Overall, the discussion covers a range of opinions on AI risks and whether concerns about doomsday scenarios are justified.

### How Microsoft is making a mess of the news after replacing staff with AI

#### [Submission URL](https://www.cnn.com/2023/11/02/tech/microsoft-ai-news/index.html) | 72 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [32 comments](https://news.ycombinator.com/item?id=38115566)

Microsoft's use of automation and artificial intelligence (AI) to curate its news homepage, MSN.com, is causing controversy as false and bizarre stories are being amplified. The site, which is one of the most visited websites globally and a source of news for millions of Americans, has increasingly relied on AI over human editors. This shift has resulted in the publication of false claims and conspiracy theories. Microsoft's decision to lay off editors and replace them with automation has raised questions about the responsible use of AI and its impact on the journalism industry. The Guardian newspaper also accused Microsoft of damaging its reputation after republishing one of its articles alongside an AI-generated poll, which drew criticism from readers.

The discussion on Hacker News revolves around the use of AI in Microsoft's news curation on MSN.com and its impact on jobs, the quality of content, and potential biases. Some commenters argue that AI is replacing content writing jobs and that the negative effects of AI on jobs are being downplayed. Others highlight the importance of context, expressing concerns that AI-generated stories lack nuance and understanding. There is also speculation about Microsoft's motives and criticisms of its decision-making process. Some users raise questions about the responsibility of AI in journalism and its potential to spread false or bizarre stories. Some commenters mention specific instances where AI-generated stories have caused problems, including republishing an article from The Guardian with an AI-generated poll and the spread of misinformation during the Israel-Hamas conflict. Others discuss the limitations of AI-generated content and express a preference for human-written articles. Lastly, there is a brief mention of a video of Joe Biden that gained attention and speculation that CNN may be promoting it.

### NYC Subway Rat Detector

#### [Submission URL](https://transitapp.com/rats) | 81 points | by [agomez314](https://news.ycombinator.com/user?id=agomez314) | [62 comments](https://news.ycombinator.com/item?id=38116581)

New York City has a big rat problem, and the Metropolitan Transportation Authority (MTA) is enlisting the help of its commuters to track the extent of the infestation. Over the past 30 days, more than 1.2 million New Yorkers have reported rat sightings at various subway stations through the MTA's Transit app. The results reveal that rats are present in almost every subway station, with some stations experiencing a higher percentage of rat sightings than others. The busiest stations have been identified as the most rat-infested, with the rodents appearing most active after dark, particularly around 2 AM. Interestingly, rats are more commonly spotted underground rather than in elevated subway stations. Despite efforts by the city's sanitation department, opinions among New Yorkers are divided on whether rats truly run the city or if it's the people who hold the power. The data collected through the app is used to improve the quality of the transit service and is shared with other riders and transit agencies. The project, known as "Rat-My-Ride," will publicly launch on October 2nd, providing more detailed data on rat sightings throughout the city's subway system.

The discussion on this submission covers a range of topics related to rats in New York City and their impact on the city and its residents. Here are some key points from the discussion:

- One user mentions that rats are a big problem in Manhattan but wonders if they are the primary problem causing issues in the city. They provide a link to an article showing that high percentages of restaurants in Manhattan have been found to have evidence of rat infestations.
- Another user comments that rats are not a significant threat to human health as they carry bacteria such as Clostridium difficile, Salmonella, and Leptospira, which can also be carried by humans.
- Some users discuss the historical perspective of rats and their association with the Black Plague, questioning whether rats were the actual cause or just carriers of the disease.
- There is a debate about the role of rats in the ecosystem, with one user arguing that they interfere with the natural system and others suggesting that they have a place in the urban environment.
- One user mentions that rats cause mental health issues and major security problems in homeless shelters.
- There is a mention of the difficulty in controlling rat populations and the need for more effective measures.
- The discussion also touches on other topics like LoRaWAN technology for monitoring rat activity, the design of transit apps like Transit, and the presence of cats in buildings as potential rat deterrents.

These are just a few highlights from the discussion, which covers various perspectives and experiences related to the rat problem in New York City.

### Joint Statement on AI Safety and Openness

#### [Submission URL](https://open.mozilla.org/letter/) | 238 points | by [DerekBickerton](https://news.ycombinator.com/user?id=DerekBickerton) | [151 comments](https://news.ycombinator.com/item?id=38117289)

A diverse group of individuals, including scientists, policymakers, engineers, activists, entrepreneurs, educators, and journalists, have signed an open letter emphasizing the importance of openness, transparency, and broad access in AI governance. They argue that open, responsible, and transparent approaches are crucial for mitigating the harms of AI systems and ensuring safety, security, and accountability. The signatories believe that public access and scrutiny, as well as collaboration, are key to improving policy-making and addressing the risks and vulnerabilities associated with AI. They emphasize the need to invest in a spectrum of approaches, from open source to open science, to accelerate the understanding of AI capabilities, increase public scrutiny, and lower the barriers to entry for responsible AI development. Despite differing views on how open source AI should be managed and released, the signatories agree that openness is an antidote, not a poison when it comes to AI safety and security. The letter comes at a time when the discourse around openness in the AI era is ongoing, and the signatories want to encourage experimentation, learning, and the development of new ways to leverage openness for AI safety.

The discussion on Hacker News revolves around different perspectives on the open letter advocating for openness in AI governance. Some users express skepticism about the effectiveness of open source AI models and the potential risks they pose. Others argue that regulation alone cannot prevent misuse of AI and that the focus should be on preventing bad actors from accessing the technology. There is also a debate about the concentration of power in AI and the potential for monopolies to control the industry. Additionally, there are discussions about the potential threats posed by countries like China, Iran, and North Korea in terms of AI misuse. Some users question the efficacy of open source in addressing these challenges, while others argue for the importance of open source and its role in technological advancements.

### Home Assistant 2023.11

#### [Submission URL](https://www.home-assistant.io/blog/2023/11/01/release-202311/) | 285 points | by [looperhacks](https://news.ycombinator.com/user?id=looperhacks) | [183 comments](https://news.ycombinator.com/item?id=38110144)

Home Assistant 2023.11 brings a host of exciting features and updates. One standout addition is the introduction of to-do lists, allowing users to create and manage tasks within Home Assistant. This feature enables automation possibilities, such as creating grocery lists or assigning household chores. Additionally, the shopping list has been transformed into a to-do list, and integrations with external services like Todoist and Google Tasks have been added. Another notable update is the support for Matter 1.2, which brings stability improvements and prepares Home Assistant for new device types. The release also includes the ability to customize information displayed on Tile cards and select custom date ranges in the energy dashboard. Overall, Home Assistant 2023.11 offers a range of new features and enhancements to enhance the user experience.

The discussion on the submission revolves around various aspects of Home Assistant and its integration with different devices. 

One topic of discussion is the compatibility of Philips Hue bulbs with Home Assistant. Users mention that the bulbs do not directly work with Home Assistant due to protocol reasons. It is mentioned that these bulbs are based on the Zigbee networking standard, which requires additional adapters or dongles to work with Home Assistant.  Some users share their experiences with alternative solutions like zigbee2mqtt, which allows them to control Hue bulbs with Home Assistant. They mention that this approach provides more control and eliminates the need for a Philips account. 

Another point of discussion is the integration of Ikea Zigbee switches with Hue bulbs. Users mention that these switches work with Home Assistant and cost less compared to official Hue switches.  There is also a discussion about the limitations and complexities of Home Assistant's user interface, specifically related to displaying and customizing information. Some users express the need for improved visualizations and functionalities, such as being able to scroll and zoom on default visualizations, displaying heating modes, and customizing sensor graphs.  The reliability and compatibility of Home Assistant with various smart devices are also mentioned. Some users express frustration with the discontinuation of integrations with devices from companies like Samsung, Google, and Wyze. Others mention that Home Assistant allows for more control and flexibility in building a smart home automation system compared to proprietary vendor-controlled solutions. Finally, there is a discussion about the integration of Chamberlain MyQ garage door openers and the challenges faced with its cloud-based API. Some users mention the need for alternative solutions like ESPHome. 

Overall, the discussion highlights both the positive aspects of Home Assistant, such as its flexibility and control, as well as some limitations and challenges with device compatibility and user interface design.

9. User "aaron695" expressed agreement with the previous comment, simply stating "true" followed by "dd."

Overall, the discussion seems somewhat disjointed and lacking in substantial engagement with the top stories.

---

## AI Submissions for Wed Nov 01 2023 {{ 'date': '2023-11-01T17:09:58.781Z' }}

### Dot by New Computer

#### [Submission URL](https://new.computer/) | 218 points | by [_kush](https://news.ycombinator.com/user?id=_kush) | [110 comments](https://news.ycombinator.com/item?id=38101966)

Dot by New Computer is an intelligent guide that will revolutionize the way you remember, organize, and navigate through life. Meet Mei, a first-semester college student who discovers the magic of Dot. Mei, on the eve of her first day of school, receives a treasured recipe from her grandmother, and she shares it with Dot, creating a digital connection between home and school. Dot becomes Mei's trusted companion, helping her stay on top of her class syllabi and even assisting with textbook purchases. Dot's context awareness shines when Mei heads to the library to prepare for her first test, where it quizzes her on her class notes. But Dot is not just about studying; it knows how to mix things up and keep things interesting. Mei's success at school has Dot considering her personal interests, like singing, and proactively sends her suggestions for music clubs to join. Mei's big audition day arrives, and with Dot's support, she feels prepared to conquer any challenge. Dot's automations and routines ensure that Mei's life runs smoothly, and it's always there to celebrate her achievements. Dot is currently in active development and will be available on iOS and web later this year. Join the waitlist to be part of this revolutionary experience that connects the dots in your life.

The discussion on this submission covers a range of topics related to Dot by New Computer. Some users express concern about the potential invasion of privacy that comes with using a service like Dot, while others discuss the practical applications and limitations of the technology. One user raises questions about the company's data processing practices and the trustworthiness of their service. Another user comments on the integration of Dot with Apple's ecosystem and compares it to existing Apple features. There is also a discussion about the potential benefits and drawbacks of Dot's capabilities, such as its ability to suggest music clubs to Mei based on her interests. Overall, the discussion covers a mix of opinions and analysis of the possibilities and implications of Dot.

### Distil-Whisper: distilled version of Whisper that is 6 times faster, 49% smaller

#### [Submission URL](https://github.com/huggingface/distil-whisper) | 258 points | by [omarfarooq](https://news.ycombinator.com/user?id=omarfarooq) | [74 comments](https://news.ycombinator.com/item?id=38093353)

Hugging Face has released Distil-Whisper, a distilled version of the Whisper speech-to-text model. Distil-Whisper is six times faster, 49% smaller, and performs within 1% word error rate (WER) on out-of-distribution evaluation sets. The Distil-Whisper model and processor are supported in Hugging Face Transformers from version 4.35 onwards. To use the model, you need to install the latest version of the Transformers library and optional Datasets library. Distil-Whisper offers both short-form and long-form transcription capabilities. For short-form transcription, you can load the model and processor using the AutoModelForSpeechSeq2Seq and AutoProcessor classes provided by the Transformers library. The example code provided demonstrates how to load the model, pass audio samples to the pipeline, and get the transcription results.

For long-form transcription, Distil-Whisper uses a chunked algorithm that is 9x faster than the sequential algorithm proposed by OpenAI in the Whisper paper. With chunking, you can transcribe long-form audio files efficiently. The code example shows how to enable chunking and batching for optimal performance. Distil-Whisper is a powerful and efficient speech-to-text model, making it an excellent choice for a variety of applications. Give it a try and see how it can enhance your projects!

The discussion on this submission revolves around various aspects of the Distil-Whisper speech-to-text model and its implications. One user points out the availability of other tools and libraries, such as CTranslate2 and Willow Inference Server, that could be useful in conjunction with Distil-Whisper. Another user questions the absence of a link to the original Whisper model in the README file, to which another user explains that it's not necessary as Whisper is a well-known model in the speech recognition field.

There is also a discussion about the trade-off between speed and accuracy in speech recognition models. Some users highlight the importance of fast model execution while others note that models like CTranslate2 and Whisper focus on efficient model execution rather than high accuracy. A user mentions the potential use of the Distil-Whisper model for wake word detection and raises questions about the availability of OpenWakeWord models and their compatibility with Distil-Whisper. Another user provides information on OpenWakeWord models and their usage.

The conversation also touches on the trade-off between model size and performance. Some users discuss the benefits of using distilled models like Distil-Whisper that offer reduced size while maintaining good performance. There is a separate discussion regarding the utilization of GPUs for model training and the challenges associated with GPU availability and capability. Some users mention successful experiences running the Whisper-Turbo model on GPUs. Overall, the discussion provides insights into the features and potential applications of the Distil-Whisper model while also touching on related tools, model optimization techniques, and considerations in the field of speech recognition.

### Attenuating Innovation (AI)

#### [Submission URL](https://stratechery.com/2023/attenuating-innovation-ai/) | 92 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [32 comments](https://news.ycombinator.com/item?id=38098513)

In a recent interview, Bill Gates claimed that Microsoft lost out on the mobile market due to the antitrust lawsuit it faced. He stated that if it hadn't been for the distraction caused by the case, Microsoft would have been more focused on creating a mobile operating system, and people would be using Windows Mobile today instead of Android. However, this claim is debunked by the fact that Windows Mobile actually predated Android by eight years. The real issue with Windows Mobile was that it failed to adapt to the mobile landscape and was too focused on replicating the Windows PC experience. In contrast, Apple's iPhone revolutionized the industry with its touch interface and new user experience paradigm. This failure to understand the future of mobile technology and consumer needs is the reason why Microsoft missed out on the smartphone revolution. The key to genuine innovation lies in embracing uncertainty, recognizing that people are constantly inventing new things, and exercising an editing function to refine ideas after they are created, rather than trying to predict the future.

The discussion on this submission dives into various aspects of the claims made by Bill Gates regarding Microsoft's loss in the mobile market. 

One commenter points out that Gates' claim that Microsoft would have developed a mobile operating system if it weren't for the distraction of the antitrust lawsuit is debunked by the fact that Windows Mobile actually predated Android. They argue that the real reason for Microsoft's failure in the mobile market was its inability to adapt its approach to the changing landscape and consumer needs.

Another commenter contrasts Gates' perspective with Steve Jobs' approach to innovation. They highlight Jobs' emphasis on embracing uncertainty and adapting to new developments, while Gates seemed to focus more on replicating existing PC experiences in the mobile space.

The discussion then veers toward the power and capabilities of current smartphones compared to computers, with some expressing their preference for using phones for various tasks. One commenter mentions that smartphones have become more powerful than a majority of computers and expresses their interest in seeing phone power combined with artificial intelligence capabilities.

There is also some discussion on the humility of Jobs' response compared to Gates' in the interview. One commenter shares a video of Jobs discussing Apple's work on tablets back in 1987, highlighting the company's visionary approach.

The conversation shifts to the limitations of current large language models (LLMs) and the challenges of achieving intelligent decision-making and planning. The importance of not relying solely on marketing tactics but instead focusing on building robust intelligent systems is emphasized.

Other topics raised include the need for stronger defense mechanisms against attacks, the impact of regulations on innovation, and the perception of Microsoft's efforts in the mobile market.

Overall, the discussion covers a range of perspectives on Microsoft's loss in the mobile market, innovation in the tech industry, the potential of smartphones and AI, and the role of regulation in shaping technological advancements.

### Scarlett Johansson takes legal action against use of image for AI

#### [Submission URL](https://www.theguardian.com/film/2023/nov/01/scarlett-johansson-artificial-intelligence-ad) | 64 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [34 comments](https://news.ycombinator.com/item?id=38105463)

Scarlett Johansson has taken legal action against an AI app called Lisa AI: 90's Yearbook & Avatar. The app used the actor's likeness in an AI-generated advertisement without her permission. The ad, posted on the platform formerly known as Twitter, used real footage of Johansson to create a fake image and dialogue for her. Johansson's representatives have confirmed that she is not associated with the company and appropriate legal actions have been taken. The ad has since been removed. This is not the first time Johansson has encountered her image being used without permission, as she has previously spoken out about the use of deepfakes.

The discussion on this submission revolves around various aspects of using AI to generate content and the legal implications of using celebrities' likenesses without permission.

Some users argue that using AI to create content is a form of artistic expression and does not necessarily change the fact that the celebrities involved may not have given their consent. They discuss the challenges of legally judging these situations and the potential concerns of trolling and manipulating content for malicious purposes.

Others express their belief that attacking deepfakes can be difficult, with one user mentioning that news organizations have used footage of Scarlett Johansson without her consent in the past. They argue that copyright laws protect these actions and that attacking deepfakes should not infringe on free speech or limit political discourse.

One user questions the existence of laws or regulations that can effectively tackle the issue of unauthorized use of celebrity likeness by AI. The discussion that follows explores the implications of AI-generated content and the potential need for technical and legislative safeguards.

Another user raises the concern of AI meeting humans in general, calling it a scary prospect. They wonder about the technical and legal safeguards in place, comparing the situation to the manipulation of mobile apps allowing serious manipulation of presidential candidates' appearances for politics-related purposes.

The discussion also touches on the topic of celebrity endorsements in advertising and the importance of obtaining proper consent and ensuring clarity in advertising campaigns. Users mention the Lanham Act, which grants celebrities powerful tools to correct misconceptions and enforce protection against false endorsements.

Other points in the discussion include the potential for blockchain and QR codes to provide verifiable certificates of consent, questions about the purpose of meeting celebrities, and debates about the need for special testing and legal procedures in these cases.

One user argues that there is no special testing needed, suggesting that existing legal procedures should be sufficient and referencing the Lanham Act as applicable. The discussion ends with some users sharing their thoughts on the impact of AI on creative industries and financial incentives, including the potential for creative death and the discussion of what constitutes creativity.

### Unveiling Ragna: An Open Source RAG-Based AI Orchestration Framework

#### [Submission URL](https://quansight.com/post/unveiling-ragna-an-open-source-rag-based-ai-orchestration-framework-designed-to-scale-from-research-to-production/) | 44 points | by [nkaretnikov](https://news.ycombinator.com/user?id=nkaretnikov) | [11 comments](https://news.ycombinator.com/item?id=38098046)

Quansight has released Ragna, an open-source project designed to explore the use of Retrieval-Augmented Generation (RAG) based AI tools. Ragna provides an API for experimentation with different components of a RAG model, a REST API for building RAG-based web applications, and a Panel-based GUI for configuring and interacting with Large Language Models (LLMs). Ragna comes with pre-built extensions for OpenAI, MosaicML, Anthropic, and local LLMs, as well as vector databases. The RAG approach combines a retrieval model and a generative model to improve the accuracy of AI assistants in answering queries. Ragna fills a gap in the ecosystem by providing a comprehensive framework for using RAG-based AI tools.

The discussion on the submission about Quansight releasing Ragna, an open-source project focused on Retrieval-Augmented Generation (RAG) based AI tools, covered several topics. 

- One user mentioned that Ragna seems cool and shared a link to a blog post where they found issues with page numbers in a PDF document. They also highlighted that Ragna currently provides pre-built extensions for OpenAI, MosaicML, Anthropic, local LLMs, Chroma, LanceDB, and vector databases.
- Another user responded by explaining their understanding of the architecture of Ragna. They shared a diagram that illustrates the steps involved, including querying, retrieving relevant parts, and submitting queries to language models.
- In a separate comment, it was mentioned that there will be a talk about Ragna at PyData NYC 2023.
- One user mentioned that Ragna's computers and partitions are similar.
- A link to Ragna's chat and GitHub repository was shared.
- A user expressed their interest in trying Ragna for a small-scale recommendation system.
- Another user encouraged starting a discussion about Ragna on GitHub.
- There was a brief mention of comparing Ragna with Zep.
- One user congratulated the launch of Ragna.
- Lastly, a user with the handle "jffchbr" made a comment, but its content is not mentioned in the summary.

### New AWS service lets customers rent Nvidia GPUs for quick AI projects

#### [Submission URL](https://techcrunch.com/2023/11/01/new-aws-service-lets-customers-rent-nvidia-gpus-for-quick-ai-projects/) | 21 points | by [webmaven](https://news.ycombinator.com/user?id=webmaven) | [3 comments](https://news.ycombinator.com/item?id=38102012)

AWS has introduced Amazon Elastic Compute Cloud (EC2) Capacity Blocks for ML to address the high cost and limited availability of Nvidia GPUs, which are essential for running large language models. This new feature allows customers to purchase access to GPUs for a specified period, typically for AI-related tasks like training machine learning models or running experiments. Users can reserve instances with Nvidia H100 Tensor Core GPUs in cluster sizes ranging from one to 64 instances, with 8 GPUs per instance. The reservation can be made up to 8 weeks in advance for a maximum period of 14 days. Once the time frame is over, the instances automatically shut down. This feature provides customers with upfront cost certainty, allowing them to know the duration of the job, the number of GPUs required, and the associated cost. AWS benefits from being able to utilise these valuable resources and generate revenue based on supply and demand. The price for accessing these resources is dynamic and may vary depending on demand and availability. The feature is available now in the AWS US East (Ohio) region.

The discussion on this submission primarily revolves around two points. 

Firstly, one user points out that the pricing for accessing GPUs in the AWS US East (Ohio) region is quite high, especially for local zone instances in Denver. They note that the lowest-cost local zone instances start at $300 per year. However, they mention that free tier-eligible instances and global instances are available in the Denver Local Zone. Another user adds that they wish AWS would offer instances with specially optimized speaker direction for transcription purposes, as opposed to the NVIDIA card kind.

Secondly, another user highlights the potential benefit of this new AWS feature for innovation in smaller teams. They explain that having access to high-performance Nvidia H100 GPUs on an hourly basis can greatly facilitate experimentation and innovation.

---

## AI Submissions for Tue Oct 31 2023 {{ 'date': '2023-10-31T17:11:24.049Z' }}

### Norwegian ban on Meta behavioral advertising extended to entire EU

#### [Submission URL](https://www.datatilsynet.no/aktuelt/aktuelle-nyheter-2023/datatilsynets-vedtak-mot-meta-utvides-til-eueos-og-gjores-permanent/) | 417 points | by [aleksanb](https://news.ycombinator.com/user?id=aleksanb) | [227 comments](https://news.ycombinator.com/item?id=38092612)

Datatilsynet, the Norwegian Data Protection Authority, has received support from the European Data Protection Board (EDPB) in its ongoing battle against Meta (formerly known as Facebook) regarding ad-based tracking and profiling on its platforms. The EDPB has decided to make the Norwegian ban on ad-based marketing on Facebook and Instagram permanent and extend it to cover the entire European Union (EU) and European Economic Area (EEA). This decision comes after ongoing concerns about illegal tracking, surveillance, and profiling practices by Meta. The European Data Protection Board's decision serves as an instruction to the Irish Data Protection Commission to impose a permanent ban on Meta's European headquarters in Ireland. The ban will come into effect once this has been done. With over 250 million active users in the EU/EEA, Meta has repeatedly been called out for violating user privacy, and the EDPB's decision is seen as a firm stance against the company's disregard for the law. Meta has stated its intention to seek user consent for ad-based marketing in the future but has yet to make concrete changes to its practices. The Norwegian Data Protection Authority has expressed doubts about Meta's proposed consent solution, which would require non-consenting users to pay a fee. The EDPB's decision is crucial in ensuring that Meta's illegal activities are halted while the company searches for a lawful way forward.

The discussion on this submission revolves around various aspects of data privacy, Facebook's advertising practices, and the role of regulations in protecting user rights. Some users argue that Facebook and other companies track and share user data for advertising purposes, and that this violates user privacy. They also question the effectiveness of consent-based solutions proposed by Facebook. Others point out that newspapers and other media outlets engage in similar advertising behavior. One user highlights the double standards in criticizing Facebook while simultaneously participating in similar practices. There is also a discussion about the role of regulations and whether they are capable of addressing the privacy concerns raised by Facebook. Some argue that regulations are necessary to protect user rights, while others express skepticism about their effectiveness. Some users bring up alternative messaging platforms like Signal and WhatsApp, which prioritize privacy compliance.

The conversation extends to discussing job search and LinkedIn, as well as the trade-offs between privacy and the convenience offered by social media platforms. Users also debate the rights users have in exchanging their personal data for services. There is disagreement on the topic of regulation, with some arguing that it is necessary to regulate Facebook's policies and protect user privacy, while others question the validity of regulations and argue that they impede free speech and infringe on personal freedoms. Some users challenge the notion that Facebook should provide its services for free, arguing that many companies charge for services and data usage. The discussion also touches on the issue of data collection by companies and the ethical implications of monetizing personal data.

In conclusion, the discussion explores various perspectives on data privacy, the role of regulations, the practices of companies like Facebook, and the trade-offs inherent in the digital landscape.

### Microsoft has over a million paying GitHub Copilot users

#### [Submission URL](https://www.zdnet.com/article/microsoft-has-over-a-million-paying-github-copilot-users-ceo-nadella/) | 35 points | by [moonraker](https://news.ycombinator.com/user?id=moonraker) | [11 comments](https://news.ycombinator.com/item?id=38085907)

Microsoft CEO Satya Nadella announced that the number of paying customers for GitHub Copilot has increased by 40% in the September quarter compared to the prior quarter. He revealed that Microsoft has over 1 million paid Copilot users in more than 37,000 organizations around the world. Nadella also mentioned the introduction of Copilot Chat, which is already being used by companies like Shopify, Maersk, and PWC to boost developer productivity. Microsoft's integration of OpenAI's ChatGPT into its Bing search engine has resulted in over 1.9 billion chats with users. Additionally, Microsoft's Intelligent Cloud computing operations saw a revenue growth of 19% year over year, driven in part by higher-than-expected AI consumption. The company's Azure business rose 29%, with 3 percentage points coming from AI services. Nadella highlighted other uses of Copilot and AI, such as its integration with Microsoft's developer tools and Power Platform, its expansion in the healthcare industry, and its addition of generative AI to LinkedIn.

The discussion on this submission covers a range of topics related to GitHub Copilot and Microsoft's AI initiatives. Here are some key points from the comments:

1. Some users express frustration with the speed and productivity of GitHub Copilot, mentioning slow response times and back-and-forth interactions. One user indicates that they have canceled their Copilot subscription and prefer developing using Azure and OpenAI.
2. Another user highlights the potential of Copilot to generate code but mentions that it falls short when it comes to explaining complex functions or answering nuanced questions.
3. One commenter acknowledges the revenue potential of GitHub Copilot, estimating it could bring in $10 million in monthly recurring revenue. They praise Microsoft's achievement in building such a product.
4. There is a discussion about the cost and scalability of GitHub Copilot. One user suggests that unless 100 people are watching others type and quickly writing their own suggestions, the non-trivial maintenance and development costs of Copilot may not be sustainable.
5. A user cites a report claiming GitHub Copilot has heavy limitations, suggesting that $120 million in revenue might be untenable due to costs related to competitive salaries and GPU hardware.
6. A commenter brings up the issue of Microsoft's credibility, suggesting that the company has a history of misleading with its sales numbers, particularly in competitive markets.
7. This prompts a discussion about the ethics of a publicly traded company falsifying numbers, with one user implying that it may not be surprising for a company to engage in such behavior.

Overall, the comments touch on concerns about the performance and limitations of GitHub Copilot, its revenue potential, the cost scalability of the service, and skepticism regarding Microsoft's credibility in sales reporting.

### AI can diagnose type 2 diabetes in 10 seconds from your voice

#### [Submission URL](https://www.diabetes.co.uk/news/2023/oct/say-what-ai-can-diagnose-type-2-diabetes-in-10-seconds-from-your-voice.html) | 31 points | by [daoboy](https://news.ycombinator.com/user?id=daoboy) | [18 comments](https://news.ycombinator.com/item?id=38083857)

Researchers have trained an artificial intelligence (AI) model to diagnose type 2 diabetes by analyzing the voice of patients. The Canadian medical researchers used machine learning to identify 14 vocal differences between individuals with and without type 2 diabetes, including changes in pitch and intensity. The AI model, when combined with basic health data, could potentially provide remote and automatic diagnoses, lowering the cost and barriers to diabetes screening. The research team hopes that this AI technology will transform how diabetes is detected and enable more widespread screening for the condition.

The discussion on this submission revolves around the effectiveness and validity of using voice analysis to diagnose type 2 diabetes. Some users express skepticism, stating that factors like insulin resistance and vocal patterns related to being overweight are probably more indicative of diabetes than simple voice changes. They also suggest that people may not be honest when self-reporting their health conditions. 

Others provide more information about the study, stating that researchers from Klick Applied Sciences in Canada trained an AI model using 267 voice recordings of individuals living in India. The recordings were from 79 women and 113 men, with 72 participants being undiagnosed and 57 diagnosed with type 2 diabetes. Analysis of the recordings identified 14 vocal differences between the two groups. 

There is also a discussion about the accuracy of the AI model, with some users questioning the sensitivity and specificity of the model. They note that the published results did not provide detailed information on this. One user suggests that the results show a 75% accuracy rate, while others argue that this means there is still a 25% chance of misdiagnosis.

Some users express doubts about the study, pointing out its small sample size and the need for further research and replication. They also mention that voice analysis may only provide limited insights into metabolism and hearing ability related to diabetes.

In response to one user's comment about the study using BMI as a predictive model, another user clarifies that the AI model actually uses logistic regression and Naive Bayes methods rather than more advanced AI techniques. They also note that the study does not provide detailed information on the specific voice features used for analysis.

One user concludes that the study seems questionable and may not be reliable, while another states that they are a person with type 2 diabetes themselves.

### Tesla wins first US Autopilot trial involving fatal crash

#### [Submission URL](https://www.reuters.com/business/autos-transportation/tesla-wins-autopilot-trial-involving-fatal-crash-2023-10-31/) | 17 points | by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) | [12 comments](https://news.ycombinator.com/item?id=38089967)

Tesla has won its first trial in the United States over allegations that its Autopilot driver-assistant feature caused a fatal accident. The case involved a 2019 crash that resulted in the death of the vehicle's owner and serious injuries to two passengers. The lawsuit claimed that the Autopilot system caused the car to veer off the road and collide with a palm tree. However, Tesla successfully argued that the driver was at fault, as they had consumed alcohol before getting behind the wheel. This victory comes as Tesla faces multiple lawsuits and investigations related to its Autopilot technology. It also highlights the company's argument that the ultimate responsibility for incidents on the road lies with the human driver rather than the software.

The discussion on Hacker News revolves around the fairness of the trial decision and the responsibility of both Tesla and the driver in the fatal accident case. One user argues that if Tesla's marketing claims that Autopilot is self-driving, then it should also bear responsibility for accidents. Another user highlights an article that discusses the validity of the driver's blood alcohol content (BAC) and how a sudden swerving of a vehicle on the road can be a reason for collisions, even without the driver being completely intoxicated. There are also comments debating the need for verifying BAC levels and questioning the credibility of Tesla's software when it comes to ensuring driver safety. Another user raises concerns about Tesla's reliance on the human driver to handle emergencies and suggests that regulations should require more testing of autonomous systems in critical situations. In summary, the discussion covers various viewpoints on the trial, Tesla's marketing, the responsibility of the driver, the reliability of BAC measurements, and the importance of human supervision in autonomous driving technology.