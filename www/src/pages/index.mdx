import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Tue Dec 19 2023 {{ 'date': '2023-12-19T17:09:45.282Z' }}

### Borges and AI

#### [Submission URL](https://arxiv.org/abs/2310.01425) | 34 points | by [alexmolas](https://news.ycombinator.com/user?id=alexmolas) | [15 comments](https://news.ycombinator.com/item?id=38693120)

The paper titled "Borges and AI" by Léon Bottou and Bernhard Schölkopf explores the connection between large language models (LLMs) and artificial intelligence (AI) through the imagery of Jorge Luis Borges, a famous 20th-century writer known for his works in magical realism and postmodern literature. The authors argue that understanding LLMs and AI through the lens of Borges' literary concepts can provide a new perspective on the relationship between language modeling and artificial intelligence. This paper challenges the common science fiction-based imagery surrounding AI and dives into a more nuanced understanding of the phenomenon at hand.

The discussion around the submission "Borges and AI" on Hacker News covers a range of perspectives and interpretations of the paper. Some users comment on Borges as their favorite writer and the influence of his works on the article. Others provide links to collections of Borges' short stories and essays for further reading.

One user points out the difficulty of finding meaningful information in large language models (LLMs) due to their tendency to generate nonsensical outputs. They mention the challenge of lacking a created index to easily find relevant information. Another user argues that the definition of artificial intelligence (AI) is often misunderstood, and suggests that it is not necessarily based on the concept of a killer machine like Terminator or HAL. They mention their own experience working on AI since 1998, focusing on planning and non-player characters in video games. There is also discussion around the paper's use of Borges and its connection to LLMs. Some suggest that the metaphor of Borges' Library of Babel, which contains incomprehensible texts produced by humans, is not applicable to LLMs. They argue that LLMs struggle to handle new tasks and cannot perform the type of reasoning humans can.

One user sees a flaw in the approach of the paper, claiming that it lacks clear conclusions and only offers insights without developing a theory. The discussion then delves into a debate about the capabilities of LLMs and how they can aid in understanding models and fine-tuning. There is a mention of Funes, a character from Borges' works with exceptional memory, and a user expresses confusion about attributing consciousness to LLMs, considering it a terrible idea.

Overall, the discussion explores different perspectives on the connection between Borges' literature and AI, as well as the capabilities and limitations of LLMs.

### TuneNN: A transformer-based network model for pitch detection

#### [Submission URL](https://github.com/TuneNN/TuneNN) | 107 points | by [CMLab](https://news.ycombinator.com/user?id=CMLab) | [38 comments](https://news.ycombinator.com/item?id=38694719)

TuneNN is a transformer-based network model for pitch detection in musical instruments. The model aims to capture the timbre of musical notes by considering various factors like harmonic relationships, harmonic strengths and weaknesses, instrument resonant peaks, and structural resonant peaks over time. It utilizes web audio and tensorflow.js for an online experience. The model employs different types of spectra, such as the STFT spectrum, Bark spectrum, and Cepstrum, to extract relevant features. These features are then processed using a sliding adjacent windows approach with a transformer-based network model. TuneNN supports tuning for 12+ instrument types. You can find more information and try it out at aifasttune.com.

The discussion on the submission "TuneNN: A Transformer-Based Network Model for Pitch Detection in Musical Instruments" on Hacker News covered various aspects of pitch detection and related topics. Here are some key points from the discussion:

- One commenter highlighted the complexity of pitch detection, stating that it is not solved by using Fast Fourier Transform (FFT) alone. They mentioned that determining the fundamental frequency is a challenging task and that simple physical measurements may not be sufficient for accurate pitch detection.
- Another user shared a link to an article discussing missing fundamentals and how they can affect perceived pitch. They explained how different tones and musical instruments can produce different harmonics and harmonic frequencies, which can impact the perception of pitch.
- A user mentioned the CREPE model and its high latency in instrument pitch recognition. They also shared a link to the TuneNN model's website and expressed interest in trying it out.
- One commenter provided a summary of the TuneNN model, mentioning its use of transformer-based network modeling to capture the timbre of musical notes and support tuning for over 12 instrument types.
- The license of TuneNN was a topic of discussion, with one user asking about the license and another sharing a link to the PESTO model, which learns pitch prediction with a self-supervised objective.
- The cost of tuning apps and their comparison with traditional methods was debated. Some users mentioned that software-based tuning techniques can be cost-effective, while others argued that professional tuning can involve additional nuances and complexities.
- A user shared their interest in implementing the Nebula1 algorithm for pitch detection and another user mentioned the McLeod Pitch Method as their favorite pitch detection method.
- The topic of licensing and open-source implementations came up, with one user discussing issues related to licensing the YIN and PYIN implementations of pitch detection algorithms.
- The effectiveness of the TuneNN model compared to traditional digital signal algorithms was discussed, with one user noting its significantly higher accuracy and robustness.
- The relevance of pitch detection to specific sounds, such as smoke alarms or 3D printer collisions, was discussed briefly.
- A user faced an error related to microphone permission while running the TuneNN website and mentioned their system configuration involving Ubuntu, KDE, and Firefox.

Overall, the discussion covered various perspectives on pitch detection, licensing, open-source implementations, and the effectiveness of the TuneNN model compared to traditional algorithms.

### A Mathematical Perspective on Transformers

#### [Submission URL](https://arxiv.org/abs/2312.10794) | 72 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [6 comments](https://news.ycombinator.com/item?id=38699331)

The paper "A mathematical perspective on Transformers" by Borjan Geshkovski and his colleagues explores the inner workings of Transformers, which are a fundamental component of large language models. The authors develop a mathematical framework for analyzing Transformers as interacting particle systems, revealing the emergence of clusters over time. This study offers new perspectives for mathematicians and computer scientists alike. The paper delves into subjects such as Machine Learning, Analysis of PDEs, and Dynamical Systems. Overall, this research contributes to a deeper understanding of Transformers and their applications.

In the comments on Hacker News, there is a mix of reactions to the submission about the paper on the mathematical perspective on Transformers. Some users express interest in the abstract and look forward to reading the research. One user mentions that they are interested in understanding the extraction skills of large language models and identifying relevant topology. There is one comment expressing disappointment because they were expecting designs of robots or something similar. Another user suggests that the study could also be approached from a statistical physics perspective.

### VideoPoet A large language model for zero-shot video generation

#### [Submission URL](https://sites.research.google/videopoet/) | 119 points | by [fchyan](https://news.ycombinator.com/user?id=fchyan) | [39 comments](https://news.ycombinator.com/item?id=38702141)

VideoPoet is a powerful language model that can generate high-quality videos based on text prompts. It can produce a wide range of visually stunning scenes, such as a dog listening to music, a robot cat eating spaghetti, and a golden retriever wearing VR goggles in Paris. VideoPoet can also generate audio to match a given video without any text guidance. This model is capable of multitasking on various video-centric inputs and outputs, including text-to-video, image-to-video, stylization, and outpainting tasks. It can create videos in square or portrait orientation, and even generate long videos by predicting one-second video clips repeatedly. Get ready to be amazed by the creative possibilities of VideoPoet!

The discussion about the VideoPoet submission on Hacker News covers various aspects of the model and its applications. Some users highlight the impressive results achieved by VideoPoet, noting that it can generate high-quality videos based on word prompts. They mention examples such as an 8K HD prompt engine and creative outputs like a dog listening to music or a robot cat eating spaghetti. Others point out the technical aspects of the model, discussing the underlying technologies used, such as VQGAN+CLIP Stable Diffusion. They also mention the potential dangers of relying on AI-generated content and its impact on human employment. There is a discussion about the commercialization of AI products and the role of companies like RunwayML and Google in bringing AI technology to the market. Some users express skepticism or disappointment with Google's promotion and suggest that the claims made by the company might be exaggerated. There are also references to other AI models and their capabilities, such as image-to-video generation and the potential impact on artistic professions. The potential of VideoPoet for personal entertainment, including TikTok short video storytelling, is also discussed.

Overall, the discussion covers topics like the technical aspects of VideoPoet, the commercialization of AI, AI-generated content's impact on employment, and the entertainment value of AI models like VideoPoet.

### The Illustrated GPT-2: Visualizing Transformer Language Models (2019)

#### [Submission URL](https://jalammar.github.io/illustrated-gpt2/) | 209 points | by [epberry](https://news.ycombinator.com/user?id=epberry) | [5 comments](https://news.ycombinator.com/item?id=38691583)

The Illustrated GPT-2 is an in-depth exploration of the architecture and inner workings of the OpenAI GPT-2 language model. The GPT-2 is a transformer-based model trained on a massive dataset to generate coherent and passionate essays. This post dives into the self-attention layer of the GPT-2 and explains how it enables the model to produce such impressive results. The author also explains the evolution of transformer blocks and discusses applications of transformer models beyond language modeling, such as machine translation, summarization, transfer learning, and music generation. If you're fascinated by the capabilities of machine learning models like GPT-2, this post is a must-read.

The discussion includes a few different comments. 

- "xnsh" shares several resources related to the topic, including links to the Illustrated Transformer, Beyond Illustrated Transformer, and LLM Visualization.
- "tlsnb" provides an excellent explanation of the self-attention mechanism and recommends exploring tensor network-like diagrams and examples. 
- "3abiton" mentions that recent posts on the topic have gained traction and discusses the changes from GPT2 to GPT4.
- "kridsdale1" adds to the discussion by mentioning the significant changes in the GPT3 architecture, including the use of mixture of experts models and the increase in dimensionality of embedding vectors.
- "Der_Einzige" compliments the author, Jay Alammar.

Overall, the comments provide additional resources, explanations, and insights related to the architecture and capabilities of language models like GPT-2.

### UK plan to digitise wills and destroy paper originals "insane" say experts

#### [Submission URL](https://www.theguardian.com/society/2023/dec/18/ministry-of-justice-plan-to-destroy-historical-wills-is-insane-say-experts) | 159 points | by [ilamont](https://news.ycombinator.com/user?id=ilamont) | [205 comments](https://news.ycombinator.com/item?id=38699007)

The UK Ministry of Justice is facing criticism for its proposal to destroy millions of historical wills in order to save on storage costs. The plan involves digitising and then discarding around 100 million paper originals of wills dating back over 150 years, with the aim of saving £4.5 million ($5.9 million) annually. Historians and archivists have called the proposal "insane" and "sheer vandalism," expressing concern that important historical records could be lost. While the government plans to keep the originals of wills belonging to famous individuals, such as Charles Darwin and Princess Diana, others may be destroyed after 25 years. Critics argue that the physicality of the original documents is important to understanding the context and significance of the wills.

The discussion around the submission on Hacker News focused on several different aspects of the UK Ministry of Justice's proposal to destroy historical wills. Here are some key points:

- Some users questioned the necessity and wisdom of destroying the original paper wills, arguing that they hold historical and cultural significance that cannot be replicated by digital copies. They expressed concern about the loss of physical artifacts and the potential for digital data loss or cyber attacks.
- Others pointed out that digitizing the wills could make them more accessible and facilitate easier search and retrieval. They also mentioned the possibility of implementing measures to ensure the integrity and authenticity of the digital copies.
- The discussion touched on the importance of physical documents in historical and legal contexts, as well as the challenges and risks associated with long-term preservation of digital records. Some users highlighted the importance of redundancy and the need for multiple copies of records.
- There was also mention of the cost-saving aspect of the proposal, with some arguing that digital storage could be a more cost-effective solution in the long run compared to maintaining physical records.
- Users debated the potential risks of relying solely on digital records, including data loss or corruption, the need for technological infrastructure to support long-term preservation, and the issue of changing file formats and technology.
- Lastly, there were discussions about the role of government in managing and preserving archives, with users expressing different opinions about the government's responsibility and the potential impact of cost-saving measures on historical records.

Overall, the discussion on Hacker News reflected a range of perspectives on the proposal to destroy historical wills in favor of digitization. Some users emphasized the importance of physical artifacts and the potential risks of relying solely on digital records, while others highlighted the benefits of digitization for accessibility and cost-saving.

### Andrew Ng: 'Do we think the world is better off with more or less intelligence?'

#### [Submission URL](https://www.ft.com/content/2dc07f9e-d2a9-4d98-b746-b051f9352be3) | 17 points | by [mgreg](https://news.ycombinator.com/user?id=mgreg) | [7 comments](https://news.ycombinator.com/item?id=38702791)

Andrew Ng, a computer scientist known for his work in artificial intelligence (AI), argues that fears of AI leading to doomsday scenarios are overhyped. Ng, who has been involved in groundbreaking AI research projects, believes that regulators who buy into the alarmist narrative around AI will only benefit vested interests. He advocates for open-source AI development and criticizes government efforts to overly regulate the technology. Ng also demonstrates the capabilities of open-source AI models on his laptop, running inference without the need to send data to the cloud. While he acknowledges the limitations of these smaller models, he sees their potential for simple tasks like brainstorming and basic information retrieval.

The discussion on this submission involves several commenters sharing their thoughts on the topic. 
One commenter, xchp, criticizes the article for oversimplifying the complexity of the issues surrounding AI by presenting a simplistic narrative that ignores essential details and nuances.
Another commenter, artninja1988, responds to xchp's comment with confusion, as they only read the headline of the article and did not fully understand the discussion.
There is a mention of an interview with Andrew Ng, the subject of the submission, by patrickhogan1.
Another commenter, jbrkr, expresses their view that the intelligence in the world is not concentrated but distributed, and that concentrating intelligence in one place can be detrimental. They further mention that distributed individual and regional governance can be harmful to society.
In response to jbrkr's comment, ntnllrvd argues that humans benefit from intelligence that is more broadly distributed, which helps in mitigating existential threats. However, they also note that the extent to which non-human intelligence in the world can be considered intelligence is questionable and subject to change.

Overall, the discussion touches on the complexity of AI and its potential impact, with varying opinions on the concentration of intelligence, the benefits of distributed intelligence, and the nature of non-human intelligence.

### Turquoise taillights tell you this Mercedes is driving autonomously

#### [Submission URL](https://arstechnica.com/cars/2023/12/turquoise-taillights-tell-you-this-mercedes-is-driving-autonomously/) | 28 points | by [addaon](https://news.ycombinator.com/user?id=addaon) | [15 comments](https://news.ycombinator.com/item?id=38698854)

Mercedes-Benz has received approvals from authorities in California and Nevada to test out a new car-to-human communication feature. The automaker will use turquoise-colored marker lights to indicate when its partially automated driver assistance feature, Drive Pilot, is operating. Drive Pilot is a Level 3 system, allowing the driver to take their hands and eyes off the road at speeds of up to 40 mph. This approval makes Drive Pilot the first Level 3 system to gain regulatory approval for deployment. The marker lights, chosen for their differentiation from other colored lights on the road, are intended to signal to other road users that the vehicle is operating autonomously.

The discussion on Hacker News about Mercedes-Benz's car-to-human communication feature involves various topics and perspectives. 
One user points out that international standards usually use a different color to signify autonomous control in self-driving cars. They mention that in Japan, green lights are slightly blue, as the Japanese language evolved differently when it comes to traffic lights. Another user adds that this can cause confusion for people who are colorblind.
There are discussions about the usefulness of the turquoise marker lights in indicating the vehicle's intentions to other road users. One user thinks that it can be helpful, but there might be challenges in understanding the level 3 autonomous driving terminology and differences between car manufacturers. Another user suggests using fluorescent square lights to signal different ADAS activities, referring to the iconic lighting in the movie Close Encounters of the Third Kind.
Some users discuss colorblindness and its implications for traffic lights. One user explains that for a colorblind person, a green traffic light might appear gray. Another user mentions that traffic lights have specific designs to help identify them, and that colorblindness can make it harder to distinguish colors while driving or walking.
There is a discussion about the location and design of lights on vehicles to help with identification. One user shares a gradient of different types of colorblindness, while another user suggests using the location rotation to help with identification.
One user raises concerns about driving behind a car that is operating autonomously, suggesting that it may be difficult to respond to sudden changes in lane position. Another user suggests that the behavior of autonomous vehicles in passing can vary and may pose risks, such as aggressive passing or unpredictable lane changes.

Overall, the discussion covers topics such as the use of colors to signify autonomous control, the challenges for colorblind individuals, and safety concerns regarding the behavior of autonomous vehicles on the road.

### An In-depth Look at Gemini's Language Abilities

#### [Submission URL](https://arxiv.org/abs/2312.11444) | 118 points | by [tbruckner](https://news.ycombinator.com/user?id=tbruckner) | [68 comments](https://news.ycombinator.com/item?id=38695583)

A recent paper titled "An In-depth Look at Gemini's Language Abilities" explores the language abilities of Google Gemini models, comparing them to the OpenAI GPT series. The authors provide a third-party, objective comparison with reproducible code and transparent results, evaluating the models across 10 datasets that test various language abilities such as reasoning, question answering, math problem solving, translation, code generation, and instruction following. The analysis shows that Gemini Pro performs slightly inferior to GPT 3.5 Turbo in terms of accuracy across all benchmarked tasks. The paper also discusses reasons for this under-performance, including difficulties with mathematical reasoning, sensitivity to multiple-choice answer ordering, and content filtering. However, areas where Gemini demonstrates high performance include generating non-English languages and handling longer and more complex reasoning chains. The paper provides code and data for reproducibility.

The discussion on Hacker News revolves around the recent paper on Gemini's language abilities and includes various perspectives on the topic. 
One user points out the inaccuracy of the Chatbot Arena Leaderboard in predicting model performance compared to human judgment and suggests using 5 years of performance work and competency SAT scores as a better evaluation metric. Another user provides a link to a paper arguing that GPT-4 matches controlled crowd-sourced human preferences at an 80% agreement level, making it a scalable and explainable approximation of human preferences. 
There is a discussion about the inclusion of other interesting models, such as the Phi-2 model and Solar-107B, in the leaderboard. Another user mentions the significance of performance differences between models and the capabilities demonstrated in benchmark domains. A user raises the issue of non-blind voting results and the lack of identification of the winning model in conversations. 
There are discussions regarding the filtering of votes and the quality improvement of voting results based on filtering conversation length and consistency. Some users express confusion about the inclusion of avatars instead of humans in the evaluation process. 
The size and performance of Mixtral, a model missing from the paper, are discussed, with users pointing out its rank on the Chatbot Arena Leaderboard. The accuracy of OpenAI's leaderboard and the need for non-blinded voting results are debated. 
There is a discussion on the difference between Gemini Ultra and Mixtral, and a user comments on the withdrawal of an arXiv article due to inappropriate sourcing, mentioning the confusion caused by the article's claims. The GPU compute time and effectiveness in discarding company results are also mentioned. 

The origins of MistralAI and the involvement of individuals from Deepmind and Google Brain in its development are discussed.

---

## AI Submissions for Mon Dec 18 2023 {{ 'date': '2023-12-18T17:09:50.734Z' }}

### LLMLingua: Compressing Prompts for Faster Inferencing

#### [Submission URL](https://github.com/microsoft/LLMLingua) | 136 points | by [TarqDirtyToMe](https://news.ycombinator.com/user?id=TarqDirtyToMe) | [38 comments](https://news.ycombinator.com/item?id=38689653)

Microsoft has developed a new tool called LLMLingua that compresses prompts for accelerated inference of large language models (LLMs). By eliminating unimportant tokens in the prompt, LLMLingua achieves up to 20x compression with minimal performance loss. This tool addresses the limitations of LLMs, such as prompt length limits and high pricing, by providing a simple and efficient method for compression. In addition, Microsoft has also introduced LongLLMLingua, which enhances LLMs' ability to perceive key information in long-context scenarios using prompt compression. This method not only improves performance but also saves cost, with potential savings of up to $28.5 per 1,000 samples. LLMLingua and LongLLMLingua offer practical solutions for users of LLMs, enabling longer contexts and more efficient processing.

The discussion around the submission revolves around various aspects of LLMLingua and its implications. Some users find the compression algorithm used in LLMLingua interesting and effective in reducing prompt sizes while maintaining semantic meaning. However, others point out potential limitations and risks such as subjective assessment of performance and concerns related to censorship. There is a discussion about the benefits and drawbacks of prompt compression, with users expressing different views. Some highlight the importance of understanding contextual information and the potential harm of using compressed prompts. Others argue that it is necessary to optimize models for efficiency and cost-effectiveness. The conversation expands to cover topics such as model expansion, text generation, compression in intelligence, common standards in context, and training LLMs. Some users wonder about the reverse application of large language models for compressing sentences. Others discuss the potential benefits of humans learning to read compressed language. There is also a brief discussion about the use of shorthand and the benefits of humans learning to compress language. In addition, users discuss the challenges and potential improvements in working with LLMLingua, as well as the importance of context in efficient model tokenization.

Finally, there are flagged comments regarding the context of distributional alignment and the need for understanding and respectful communication.

### Show HN: Microagents: Agents capable of self-editing their prompts / Python code

#### [Submission URL](https://github.com/aymenfurter/microagents) | 214 points | by [gourmetcode](https://news.ycombinator.com/user?id=gourmetcode) | [75 comments](https://news.ycombinator.com/item?id=38679453)

A GitHub repository called "microagents" has caught the attention of the Hacker News community. The repository contains a project that explores the concept of self-evolving agents capable of generating and improving themselves. These agents can automatically generate Python code prompts tailored to provide answers to user queries.
The process starts with a user query, which activates a basic "bootstrap" agent. The bootstrap agent plans and delegates tasks to specialized agents capable of running Python code for broader functions. An Agent Manager oversees these agents, selecting or creating them based on vector similarity. The agents have evolving system prompts that improve through learning.
The repository showcases two synthesized agent prompts: "CalculateAddition Agent" and "GetPopulationOfCountry Agent." The CalculateAddition Agent is an arithmetic solver that can calculate the sum of two numbers. The GetPopulationOfCountry Agent is a data extractor that retrieves the population of a given country using a provided Python code snippet.
The project faces certain challenges and potential improvements. Path optimization is needed to effectively discard non-functional agents. Performance and parallelization could be enhanced by implementing parallel processing for prompt evolutions. A refined strategy for prompt evolution, which quantifies the success ratio, would improve the system. Integrating persistent agent prompts with vector databases and sharing successful agents across runtime environments can improve efficiency. Implementing a hierarchical agent structure for managing requests could also lead to major improvements.
The project, written in Python, has garnered 365 stars and 7 forks on GitHub. It has sparked interest in the Hacker News community, with users discussing the potential applications and limitations of self-evolving agents.

The discussion on Hacker News revolves around the concept of self-evolving agents and their potential applications and limitations. Here are the main points raised:

- Some users discuss the similarity between the "Microagents" project and the movie Memento, where Leonard struggles to recall events due to a condition that causes him to lose his memories. They suggest that the prompt evolution in Microagents is similar to Leonard's experience of relying on prompts to recall information.
- Others point out that self-evolving agents can be useful but also present challenges, including the need for path optimization to discard non-functional agents and the potential for performance and parallelization enhancements.
- Users discuss the possibility of using a hierarchical agent structure for managing requests and the potential benefits of integrating persistent agent prompts with vector databases and sharing successful agents across runtime environments.
- There is interest in connecting or creating domain-specific languages (DSLs) inspired by Microagents and exploring its potential applications for Forth and Prolog.
- Some users mention related projects, such as OpenAI's prompt engine using Memento as a metaphor and the Soldier of the Mist project on Wikipedia.
- Others discuss the trade-offs and challenges of using multiple prompts for different tasks and the importance of context and history in generating effective responses.
- The performance and limitations of Microagents are discussed, including issues with generating correct responses and the potential limitations of passing messages and using machine learning models in the system.
- Some users describe their own experiments with similar projects, including a JavaScript-based Paint AI program and the challenges and feedback they encountered.
- There is appreciation for the implementation of prompt management in Microagents and its ability to generate prompts based on results.
- The discussion also touches on the broader topics of function systems, safety considerations, and the potential of genetic algorithms and thermodynamics as analogies for self-improving systems.
- Some users recommend reading materials on safety and optimality, and a few users engage in a debate about the limitations of language models and the possibilities for technological transformation.

Overall, the discussion showcases both enthusiasm for the possibilities of self-evolving agents and thoughtful consideration of the challenges and potential limitations of the approach.

### Wasm3 entering a minimal maintenance phase

#### [Submission URL](https://github.com/wasm3/wasm3) | 522 points | by [padolsey](https://news.ycombinator.com/user?id=padolsey) | [137 comments](https://news.ycombinator.com/item?id=38681672)

Wasm3 is a powerful and efficient WebAssembly interpreter that offers a universal runtime for running WASM code. It is built with speed and versatility in mind, passing the WebAssembly spec testsuite and running many WASI apps. The project provides a small getting started guide to help developers install and use Wasm3. It can be used as a library for various programming languages, including Python3, Rust, C/C++, GoLang, Zig, Perl, and more. Wasm3 also runs on a wide range of architectures and platforms, such as x86, ARM, RISC-V, Linux, Windows, iOS, Android, and even in browsers using WebAssembly itself.

While some might question why use a "slow interpreter" instead of a "fast JIT" for running WebAssembly, Wasm3 highlights the advantages of the interpreter approach. These include improved runtime executable size, reduced memory usage, and lower startup latency. Additionally, the interpreter approach offers better portability, security, and ease of integration into existing projects. Wasm3's main motivation is to provide a lightweight and reliable engine for running WebAssembly on embedded devices. While it started as a research project, Wasm3 has practical use cases in edge computing, scripting, plugin systems, IoT rule execution, smart contracts, and more. The project is actively maintained, although the developer has recently faced personal challenges due to the destruction of their home. They assure the community that they are committed to keeping the project alive and will actively review and merge incoming Pull Requests. If you're interested in exploring the capabilities of WebAssembly and need a fast and universal runtime, Wasm3 is a solid choice. You can find demos, installation instructions, troubleshooting tips, and more on the project's GitHub repository.

The discussion surrounding the submission revolves around various topics, including personal challenges faced by the developer, the performance of Wasm3 compared to native interpreters, and a heated debate about the political situation in Ukraine and Russia. Some commenters express their concern and offer support to the developer who has faced personal challenges due to the destruction of their home. The developer assures the community that they remain committed to maintaining the project and reviewing incoming pull requests. There is a debate about the performance of Wasm3 as an interpreter compared to native interpreters. Some users argue that Wasm3's performance is slower than native interpreters, while others agree with the developer's emphasis on the advantages of the interpreter approach, such as improved runtime executable size and lower startup latency. The discussion then takes a political turn, with commenters discussing the conflict between Ukraine and Russia. Some users raise concerns about the involvement of foreign countries and the spread of misinformation, while others share their personal experiences and views on the matter. The debate includes discussions about forced conscription, nationalism, and the interpretation of historical events. In response to some comments linking Azov, a Ukrainian nationalist group, to neo-Nazism, other users refute these claims and argue that Russia is the one supporting neo-Nazi ideologies. There is a back-and-forth about the involvement of fascist ideologies in the conflict and the credibility of certain sources of information.

Overall, the discussion involves a mix of technical discussions about the project itself and the broader political context in which it exists.

### Tofu-maker Yamami sees shares surge after automating ancient craft

#### [Submission URL](https://www.japantimes.co.jp/business/2023/12/18/companies/japan-tofu-maker-share-up/) | 55 points | by [mikhael](https://news.ycombinator.com/user?id=mikhael) | [13 comments](https://news.ycombinator.com/item?id=38687443)

Tofu-maker Yamami is experiencing a surge in shares after successfully automating its ancient craft. While many tofu producers in Japan are struggling to stay afloat, Yamami is forecasting record profits thanks to its mass production capabilities. The company's newest factory, located at the foot of Mount Fuji, can churn out 15,000 units of tofu per hour, surpassing its competitors. Yamami attributes its success to the ability to access pristine groundwater with a stable temperature, which is essential for tofu production. In contrast to its domestic rivals, Yamami's shares have skyrocketed by 138% this year, outperforming both Japanese packaged-food peers and the broader market indexes.

The discussion on this submission covers a few different topics. One user, KolmogorovComp, shares a link to a YouTube video discussing the use of plastic containers in tofu production. Another user, thunderbird120, comments on the grammar and pronunciation in the video, noting that it is written by non-native speakers but can still be understood. Terr_ replies to thunderbird120, saying that they are trying to improve their English script and that small changes can make a big difference. dtgrscm agrees, noting that they can tell when something is written wrong, even if they can't always explain what is wrong with it. In response to a comment by Terr_, klpt provides examples of incorrect grammar and suggests the use of spelling checkers to avoid such errors. Terr_ mentions that sometimes there are misspellings and typos that are not caught by spell checkers. rcrdbt adds a comment, stating that tofu has been produced for thousands of years and is both healthy and tasty.

Overall, the discussion touches on grammar, pronunciation, plastic container usage in tofu production, and the longevity and quality of tofu as a food product.

### Autonomous subs use AI to wayfind without GPS

#### [Submission URL](https://spectrum.ieee.org/reinforcement-learning-autonomous-submarines) | 49 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [44 comments](https://news.ycombinator.com/item?id=38678657)

Researchers at Flinders University in Australia have been testing deep reinforcement learning systems for autonomous underwater vehicles (UUVs) that can navigate without the use of GPS. UUVs face challenges in communication and navigation control due to the distorting effect of water. Since GPS signals cannot penetrate underwater and underwater cameras suffer from low visibility, researchers have turned to machine learning techniques to help UUVs navigate more accurately. The researchers used deep reinforcement learning to train the UUVs to navigate in difficult conditions and compensate for interference from ocean currents. The goal is to eventually use these autonomous subs to perform tasks such as scrubbing bio organisms off ship hulls to reduce the introduction of invasive species and lower shipping costs.

The discussion on this submission covers various topics related to underwater navigation and artificial intelligence (AI). Some commenters discuss the technical aspects of using AI for underwater navigation, such as the challenges of underwater communication and the potential for AI to replace traditional navigation methods. There is also a mention of the use of AI in nuclear submarines and the limitations of GPS-based navigation. Other discussions revolve around the use of AI in general, with comments about its marketability and its potential to replace expensive hardware. Some commenters also discuss the use of inertial navigation and the need for additional sensors in underwater vehicles. The discussion also touches on related topics such as underwater acoustic communication and the importance of accurate navigation for submarines.

---

## AI Submissions for Sun Dec 17 2023 {{ 'date': '2023-12-17T17:10:18.549Z' }}

### BrainGPT turns thoughts into text

#### [Submission URL](https://www.iflscience.com/new-mind-reading-braingpt-turns-thoughts-into-text-on-screen-72054) | 328 points | by [11thEarlOfMar](https://news.ycombinator.com/user?id=11thEarlOfMar) | [183 comments](https://news.ycombinator.com/item?id=38673854)

Researchers at the University of Technology Sydney have developed a breakthrough mind-reading technology that can transform thoughts into words on a screen. The technology, called BrainGPT, uses electroencephalogram (EEG) signals recorded from a cap worn by users to decode their brain activity and convert it into language. Unlike previous methods that require brain implants or access to an MRI machine, BrainGPT only requires the use of an EEG cap, making it more practical and convenient. The technology has shown promising results in trials, with an accuracy score of about 0.4 according to the BLEU algorithm. This innovation could have significant implications for neuroscience and AI.

The discussion around the submission revolves around several points. One comment points out that previous research in brain-computer interfaces (BCIs) focused on helping paralyzed individuals communicate, but EEG signals are not strong enough to support fast communication speeds. Another comment mentions Neuralink, Elon Musk's project, and questions if the article's findings are similar to other BCI research. There is also discussion about the signal-to-noise ratio of EEG and the challenges it presents. Another commenter brings up a recent development in communication using brain signals and mentions that it has shown promising results. Some commenters question the validity and replicability of the technology mentioned in the article, while others discuss the limitations and potential applications of BCIs. Some comments also mention previous advancements in voice-to-text systems and compare them to the potential of this mind-reading technology. The discussion touches on topics such as the use of AI to filter unwanted thoughts, the challenges of handling electrical noise in mobile devices, and the interplay between signal processing and brain waves. There is some skepticism about the claims made in the article and the credibility of the sources used. The conversation also branches out into discussions about brain scanning devices, the potential implications for privacy and surveillance, and the use of technology for tracking thoughts or detecting criminal activity.

### Intel proposes XeGPU dialect for LLVM MLIR

#### [Submission URL](https://discourse.llvm.org/t/rfc-add-xegpu-dialect-for-intel-gpus/75723) | 82 points | by [artagnon](https://news.ycombinator.com/user?id=artagnon) | [12 comments](https://news.ycombinator.com/item?id=38675503)

Intel has proposed the addition of a new XeGPU dialect to MLIR (Multi-Level Intermediate Representation), aiming to support high-performance GEMM (General Matrix Multiply) code generation on Intel GPUs. The XeGPU dialect provides an abstraction that closely models Xe instructions and introduces XeGPU operations for cases where a special Xe instruction cannot be expressed by LLVM/SPIR-V dialect. This new dialect complements existing MLIR dialects like Arith, Math, Vector, and Memref, allowing for a smooth integration of XeGPU-based MLIR GEMM implementation with other operations. The proposal includes an example code snippet showcasing the usage of the XeGPU dialect. Intel has already implemented XeGPU in its Extension to MLIR repository and has also developed a high-performance XeGPU-based GEMM implementation, which demonstrated close-to-peak performance on Intel Max series.

The discussion on this submission includes various comments from different users. Some users express confusion regarding the technical details, such as the strange characters used in the proposed MLIR dialect and its connection to GitHub. Others discuss the potential implications of the XeGPU dialect and how it models Xe instructions. There is also a comment asking for an explanation of the work done by engineers on system programming from a higher-level perspective. Some users discuss the generalizability of compiler infrastructure and the importance of hardware-software compatibility. One user shares a link to the proposal for the XeGPU dialect, while another user asks for a correction to an incorrect topic. Additionally, there is a discussion about a common middle layer for accelerators, and users make comparisons between AMD, Nvidia, and Intel.

### WyGPT: Minimal mature GPT model in C++

#### [Submission URL](https://github.com/wangyi-fudan/wyGPT) | 62 points | by [wangyi_fudan](https://news.ycombinator.com/user?id=wangyi_fudan) | [15 comments](https://news.ycombinator.com/item?id=38670358)

Introducing wyGPT, Wang Yi's GPT (Generative Pre-trained Transformer) solution! This project represents Wang Yi's 2.5 years of hard work and optimization to create a mature and highly optimized GPT model that works exceptionally well on a single GPU. The usage is straightforward: just execute the command `make` to train on a `text_file.txt`, and then you can use the GPU or CPU to generate text based on a given prompt. 
Wang Yi has also shared a working version of the model trained on PubMed and Chinese datasets, along with the respective download links. For finetuning purposes, there is an option to iterate the model over 12 hours using the `./train` command. 
The sample text provided demonstrates the analysis of EGFR gene mutation status in NSCLC patients, highlighting the impact of the EGFR mutation on prognosis and the potential for targeted treatment. The findings suggest that EGFR gene mutations should be considered as an independent risk factor in the management of advanced NSCLC. 
Overall, wyGPT offers a powerful GPT solution that has been meticulously developed and optimized by Wang Yi.

The discussion starts with a comment from user "bt1a" who finds the text in the submission cryptic and random. Another user "nmthkd" expresses surprise at the "ccrt cmmnt." User "ie21" jokingly suggests throwing a party. User "dh" adds a playful comment saying it's a "sexy part" and mentions Neanderthals. User "LoganDark" mentions that they have been reading code for 25 years and it seems to be working properly.
User "lxs" finds the project interesting but criticizes the source code as being "gross" and not properly formatted. They suggest that compilers don't care about these things. "hllplnts" agrees, saying the code release is crass and doesn't provide much information.
User "kgst" discusses the hashing algorithm used in the project and asks what information is missing from the project's description. "hskln" comments on their efforts to find a small GPU-friendly model and mentions their ongoing training.
The conversation continues with "ttrvrs" commenting on the self-contradictory naming convention used in the code. User "shvrdnn" mentions that they love mini databases but find the formatting in this case to be uncommon. "acheong08" finds the code wizardry confusing with convoluted JavaScript. "tt567x" adds a comment as well.

### Augmenting long-term memory (2018)

#### [Submission URL](https://augmentingcognition.com/ltm.html) | 73 points | by [MovingTheLimit](https://news.ycombinator.com/user?id=MovingTheLimit) | [25 comments](https://news.ycombinator.com/item?id=38669928)

Michael Nielsen, a researcher at Y Combinator, delves into the concept of augmenting long-term memory in his essay. He begins by recounting the story of Solomon Shereshevsky, a man with an exceptional memory who could recall lengthy strings of words and numbers with ease. Nielsen explores the idea of utilizing computers as tools to enhance our memory, referencing historical proposals like Vannevar Bush's memex and Tim Berners-Lee's conception of the World Wide Web. He then delves into his personal experience with a memory system called Anki, discussing its potential for remembering a wide range of information, including research papers and books. Nielsen also emphasizes the importance of memory in problem-solving and creativity, arguing against the view that rote memory is inferior. He concludes by stating that the essay serves as a guide for developing virtuoso skills with personal memory systems.

The discussion on this submission revolves around the effectiveness and usefulness of memory systems like Anki, as well as the broader concept of augmenting long-term memory. Some users express their positive experiences with Anki and highlight its benefits in helping them remember and retain information. Others discuss the differences between Anki and SuperMemo, another memory system, and share their preferences and experiences with both. The discussion also touches on the importance of structuring and processing information for effective learning, as well as the potential of using Anki for various subjects and problem-solving. Some users mention their own projects or tools inspired by Anki, such as Reasonote and table2anki. Overall, the discussion showcases the diverse perspectives and experiences related to memory systems and their impact on learning and knowledge retention.

### AI is owned by Big Tech

#### [Submission URL](https://www.technologyreview.com/2023/12/05/1084393/make-no-mistake-ai-is-owned-by-big-tech/) | 21 points | by [srbhr](https://news.ycombinator.com/user?id=srbhr) | [5 comments](https://news.ycombinator.com/item?id=38672156)

The AI industry, particularly in generative AI, is heavily dependent on Big Tech companies like Microsoft, Amazon, and Google. Startups and research labs rely on these tech giants for computing infrastructure and market reach. Many startups even license and rebrand AI models created by these companies. This concentration of power and reliance on a few corporate actors raises concerns about democracy, culture, and security. The recent OpenAI board breakdown, where Microsoft exerted its dominance, highlights the control that Big Tech has over AI development. OpenAI made a deal to exclusively license its GPT-4 system to Microsoft in exchange for access to their computing infrastructure. This leaves few alternatives for companies wishing to build their own AI models. Regulatory challenges and concentrated chipmaking markets further limit options. While open-source AI offers some benefits, it alone cannot escape the industry concentration caused by Big Tech. Without intervention, the AI market will continue to reward these companies and deepen the divide between them and the public.

The discussion on this submission is relatively brief. Here are the main points made by the commenters:

1. One commenter suggests that the development and use of AI are heavily biased towards big tech companies, and that this concentration of power is problematic.
2. Another commenter argues that the high cost of AI technologies limits access to a select few, thus creating a disparity of opportunities.
3. Efforts to decentralize AI development and make it more accessible are mentioned, with one person recommending using crowd-sourced datasets.
4. The idea of using social media platforms as an alternative to centralized AI is briefly mentioned.
5. Finally, one comment simply says "sht," indicating dissatisfaction with the submission or the discussion.

Overall, there isn't a robust or in-depth conversation happening in this particular thread.

### First autonomous, AI-powered restaurant

#### [Submission URL](https://abc7.com/ai-restaurant-pasadena-robots/14190130/) | 11 points | by [lxm](https://news.ycombinator.com/user?id=lxm) | [10 comments](https://news.ycombinator.com/item?id=38669314)

In a landmark development for the fast food industry, a Pasadena-based company called Miso Robotics has unveiled what it claims to be the world's first fully autonomous, AI-powered restaurant. Located in Pasadena's Old Town, the CaliExpress restaurant features robots that handle the cooking process, including burger making and French fry preparation. The business utilizes artificial intelligence to ensure smooth operations. Despite the robotic automation, human employees will still be present to pack the food and provide a friendly face for customers. This innovative venture represents years of research, development, and investment in a family of companies dedicated to revolutionizing the restaurant industry. The aim is to create a restaurant experience that combines the efficiency of automation with the convenience and personal touch of human interaction.

The discussion on this submission revolves around the cost and feasibility of implementing robotic systems in restaurants. Some commenters point out that the cost of the robots, such as the $4,000 Flippy robot, along with the additional components, can add up to around $20,000. Others compare this cost to the monthly wage of a minimum-wage human employee. There is also discussion about the potential benefits of automation, with one commenter mentioning that robots can perform tasks simultaneously and may be more cost-effective in the long term. However, another commenter argues that there are hidden costs associated with human employees, such as healthcare benefits and payroll overhead, that should be taken into consideration. One commenter shares a video of a robotic arm flipping burgers to highlight the advancements in automation technology. Another commenter speculates about a future where robots replace all cooking processes in restaurants. There is also a mention of McDonald's implementing automation in their restaurants, optimizing workflows and potentially reducing the need for human production. Someone else adds that McDonald's in Australia has already automated their drink filling process.

Overall, the discussion explores the cost-effectiveness, practicality, and potential impact of implementing robotics in the restaurant industry.