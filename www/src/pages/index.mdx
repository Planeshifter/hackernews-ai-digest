import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Sat Apr 29 2023 {{ 'date': '2023-04-29T13:26:48.809Z' }}

### MIT engineers “grow” atomically thin transistors on top of computer chips

#### [Submission URL](https://news.mit.edu/2023/mit-engineers-2d-materials-computer-chips-0427) | 49 points | by [elorant](https://news.ycombinator.com/user?id=elorant) | [3 comments](https://news.ycombinator.com/item?id=35757072)

MIT researchers have developed a low-temperature growth and fabrication technology that allows ultrathin 2D materials to be directly integrated on top of a silicon circuit. This could lead to the creation of denser and more powerful computer chips for AI applications such as chatbots. The technology significantly reduces the time required to grow 2D materials and can grow a uniform layer of transition metal dichalcogenide material in just an hour across an entire 8-inch wafer. The researchers' process can also smooth out any imperfections that may result from transferring the material, as had been done in the past.

The discussion on this submission is very limited and consists of only a few comments. One user described the technology used, Remote Plasma Chemical Vapour Deposition, and praised the company behind it, Bluglass, for commercially developing the process. Another user flagged the submission without providing any explanation. A third user asked if this technology could lead to better chatbots, to which another user responded positively, saying that it could possibly lead to more powerful computer chips for AI applications like chatbots.

### Study: ChatGPT outperforms physicians in quality, empathetic answers to patients

#### [Submission URL](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions) | 290 points | by [consumer451](https://news.ycombinator.com/user?id=consumer451) | [405 comments](https://news.ycombinator.com/item?id=35751276)

A new study published in JAMA Internal Medicine indicates that AI assistants like ChatGPT could revolutionize the field of medicine. Researchers from the Qualcomm Institute at UC San Diego compared written responses from physicians and ChatGPT to real-world health questions and found that licensed healthcare professionals preferred ChatGPT's responses 79% of the time. The AI model was rated higher in both quality and empathy, and the study suggests that physicians working alongside technologies like ChatGPT could deliver more efficient and higher quality care in the future. While AI may not replace doctors, it has the potential to significantly improve healthcare delivery.

Some commenters are skeptical of the role of AI in healthcare, with one suggesting that AI may lead to overdiagnosis for hypochondriacs. Others highlight the challenges of accessing affordable healthcare and the limitations of current medical technologies. Overall, there is a mixed response to the potential of AI in the healthcare sector.

### Revealing example of self-attention, the building block of transformer AI models

#### [Submission URL](https://github.com/jostmey/NakedAttention) | 92 points | by [jostmey](https://news.ycombinator.com/user?id=jostmey) | [32 comments](https://news.ycombinator.com/item?id=35757802)

A GitHub repository named NakedAttention has presented a simplified example of self-attention, the backbone of a transformer model. The code is straightforward to understand and is tested on the popular MNIST dataset. However, the use of a for-loop for processing samples sequentially limits the model's speed, but this can be improved by using built-in functions. The repository aims to offer a concise example of self-attention that can be used to understand and construct transformer models. Issues and feedback are welcome to improve the content presented. The repository is licensed under GPL-3.0 and has received 89 stars and 3 forks on GitHub.

There was some discussion around errors in the code which were corrected during the discussion through feedback. Some commenters found the repository helpful, while others thought that the documentation could be improved. Additionally, several resources were shared for those interested in learning more about self-attention and LLMs.

### AI-generated young Paul McCartney

#### [Submission URL](http://webgrafikk.com/blog/news/ai-makes-paul-mccartneys-voice-youthful/) | 16 points | by [ianyanusko](https://news.ycombinator.com/user?id=ianyanusko) | [4 comments](https://news.ycombinator.com/item?id=35756699)

Artificial intelligence technology has been used to rejuvenate Paul McCartney's voice in his new songs, and also to imitate the voices of other singers. Samples of this technology include a Beach Boys song, "God Only Knows," with McCartney's voice, and "New," a song with lines from "John Lennon," where McCartney's older voice has been altered to sound like a young McCartney singing. The use of AI to imitate voices has amazed many music fans, but it remains to be seen how artists and their lawyers will react to this, as it takes the "auto tuning" technology to a new level.

The first commenter, sycmrtrs, expresses disappointment in the AI-generated version of the Beach Boys song "God Only Knows" with Paul McCartney's voice, stating that it does a disservice to the original and lacks soul. The second commenter, slck, mentions the various AI models used in the article and points to resources for those interested in learning more about AI-generated music. A third commenter, flangola7, expresses their intellectual interest in the subject but expresses concern about trusting AI completely. In contrast, cmllmllr thinks Paul's voice is a good fit for a Beatles song.

### Deno 1.33: Deno 2 is coming

#### [Submission URL](https://deno.com/blog/v1.33) | 204 points | by [mephju](https://news.ycombinator.com/user?id=mephju) | [112 comments](https://news.ycombinator.com/item?id=35750369)

The team behind Deno, the secure JavaScript and TypeScript runtime, has released version 1.33 with a built-in KV database, flatter deno.json configuration, improvements to npm and Node compatibility, performance improvements, and changes to the CLI. The release is a step towards the team's ultimate goals for Deno 2, which include an effortless coding experience, best-in-class performance, and uncompromising security. Deno KV is a seamlessly integrated database within Deno that requires no dependencies to install, and configuration options have been flattened to make them easier to use. Meanwhile, Deno's LSP document preloading and dynamic imports now require fewer permission checks, and the HTTP and WebSocket servers have received performance improvements.

The discussion on the submission includes confusion on whether or not Deno Inc provides cloud services, with some users suggesting using third-party database solutions instead of a runtime-built database, and others discussing the pros and cons of KV storage. Some users find Deno's security features to be a major advantage, while others are unsure about the benefits of Deno overall. Additionally, there is debate about the role of databases in programming, and how a database built into a runtime can impact application design.

### We aren't close to creating a rapidly self-improving AI

#### [Submission URL](https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly) | 122 points | by [noAI](https://news.ycombinator.com/user?id=noAI) | [155 comments](https://news.ycombinator.com/item?id=35752719)

Artificial intelligence has made massive progress in recent years, and while the idea of a rapidly self-improving AI may be a popular topic, we aren't close to creating one just yet. To create an AI that can rapidly self-improve and potentially wipe out humanity, at least one paradigm-changing breakthrough is required. At the moment, an AI that can rapidly self-improve requires humans to construct good datasets, which is a bottleneck for the AI's abilities. Therefore, a breakthrough in automating dataset construction is required to achieve a fast takeoff scenario.

The discussion in the comments includes arguments for and against the idea of a rapidly self-improving AI and the existence of fundamental limitations in hardware and parallel processing when compared to the human brain. One user suggests that a major breakthrough is needed to advance AI, while another argues that current AI models have seen significant progress and comparing them with human intelligence is not accurate. Another user suggests that the focus should be on solving specific problems rather than trying to replicate human intelligence.

---

## AI Submissions for Fri Apr 28 2023 {{ 'date': '2023-04-28T14:01:21.977Z' }}

### JavaScript private class fields considered harmful

#### [Submission URL](https://lea.verou.me/2023/04/private-fields-considered-harmful/) | 39 points | by [feross](https://news.ycombinator.com/user?id=feross) | [25 comments](https://news.ycombinator.com/item?id=35747480)

In a blog post, Lea Verou, a library author, expresses her grief at the loss of encapsulation in her projects due to Vue 3's use of proxies for its reactivity system. Instances of classes that use private fields cannot be proxied, which creates several errors that may confuse the library users. Verou believes there is no workaround for proxy-ability, so she's decided to gradually refactor private class fields out of her existing libraries. Although she may still use private fields on a case-by-case basis, she won't reach for them without thought like she's been doing for the past few years.

Some commenters argue that private fields can remain private implementation details of a class as long as they're accessed via public methods or consumers must access internal state by passing fields. Others express frustration with JavaScript's lack of class features and the need to use private fields. TypeScript's support for private fields is welcomed by some, while others believe TypeScript doesn't fully solve this problem. There are also comparisons to similar problems in Java, C#, and Android development.

### Beautiful branchless binary search

#### [Submission URL](https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/) | 363 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [137 comments](https://news.ycombinator.com/item?id=35737862)

Malte Skarupke's blog post about a "Beautiful Branchless Binary Search" and was amazed at the efficiency of the algorithm, which eliminates one branch and makes the other nearly free. The search loop is simple and the generated assembly is beautiful. The algorithm works by jumping in powers of two and searching either the first or last elements of the array depending on whether the middle is less than or greater than the search value. In benchmark tests, it performed more than twice as fast as std::lower_bound in GCC for arrays with around 16k elements, but performed slower in Clang due to the comparison function being provided by the user.

The discussion in the comments includes optimization techniques like prefetching, using Eytzinger layouts, and removing boundary checks. There are also debates about compilers, C++ hardware control, and the usefulness of branch predictors. Overall, the post and its associated discussion provide insights and ideas for optimization and efficient algorithms.

### Launch Lamini: The LLM Engine for Rapidly Customizing Models as Good as ChatGPT

#### [Submission URL](https://lamini.ai/blog/introducing-lamini) | 112 points | by [sharonzhou](https://news.ycombinator.com/user?id=sharonzhou) | [57 comments](https://news.ycombinator.com/item?id=35743664)

Lamini, an LLM engine, has emerged from stealth to allow any developer to train high-performing LLMs, as good as ChatGPT, on large datasets with just a few lines of code. The platform offers an advanced library for optimised prompt-tuning and typed outputs, as well as a first-ever hosted data generator for creating data needed to train instruction-following LLMs, initially licensed for commercial use. Lamini makes it easy to run multiple base model comparisons in a single line of code, from OpenAI’s models to open-source ones on HuggingFace. The company is also set to launch early access to a complete LLM training module.

Some users discussed the limitations of ChatGPT and LLMs in general, such as their struggles with certain types of language and inability to correctly answer numerical questions. Others questioned the usefulness of sticking to a specific dialect while generating words. There were also discussions around LLMs being built for specific sectors and the pricing difference between Lamini and OpenAI. Overall, the announcement of Lamini was met with excitement by developers.

### OpenAI closes its monster $10B funding round at $27B-29B valuation

#### [Submission URL](https://techcrunch.com/2023/04/28/openai-funding-valuation-chatgpt/) | 42 points | by [coloneltcb](https://news.ycombinator.com/user?id=coloneltcb) | [26 comments](https://news.ycombinator.com/item?id=35748540)

OpenAI, the startup behind the popular conversational AI model ChatGPT, has secured over $300 million in funding from a group of VC firms, including Tiger Global, Sequoia Capital, Andreessen Horowitz, Thrive, K2 Global, and Founders Fund, according to documents seen by TechCrunch. The cash injection values the company at $27 billion to $29 billion, following a $10 billion investment from Microsoft in January. OpenAI's army of technical teams works across multiple areas, but its impressive ChatGPT product, which lets anyone ask a natural question and receive a detailed answer, particularly caught the attention of investors. The startup's valuation reflects the massive growth potential perceived in AI and its related products, and the rapidly developing ecosystem around the technology.

Some users are skeptical, pointing out that while GPT-4 has promising improvements, it is not without its dangers and limitations. Others speculate that OpenAI will become the major provider of AI-powered products and that there will be competition ramping up. Lastly, a user noted an odd observation about Safari's reader mode displaying caps Lorem Ipsum.

### Gpt4free repo given takedown notice by OpenAI

#### [Submission URL](https://github.com/xtekky/gpt4free) | 264 points | by [freedmand](https://news.ycombinator.com/user?id=freedmand) | [223 comments](https://news.ycombinator.com/item?id=35740836)

The GitHub repository xtekky/gpt4free is a decentralized AI industry project that provides language model APIs free-of-charge. The project primarily focuses on GPT-4 and GPT-3.5 APIs from various websites, including writesonic.com and forefront.ai. The repository also includes a web-based graphical user interface for interacting with gpt4free, instructions on how to run it in a Docker container, and a ChatGPT clone with new features and scalability. The project is licensed under the GPL-3.0 license and is intended for educational purposes only.

There is discussion in the comments about the legality of the project and potential copyright infringement. Some commenters suggest that it may be subject to DMCA takedowns or may be infringing on intellectual property rights. Others argue that OpenAI's terms of service may not permit third-party services to use the APIs, and that the project may also be consuming computational resources without permission. There is also debate about the role of intellectual property in modern society and the importance of licensing and compensation for creators. One user notes that Google's crawlers and Bing's sourcing methods are different, with Bing being more sensitive to copyright infringement concerns. The submission has been flagged by a user for review.

### AI Will Rapidly Transform Labor, Exacerbating Inequality, Insecurity, Poverty

#### [Submission URL](https://www.scottsantens.com/ai-will-rapidly-transform-the-labor-market-exacerbating-inequality-insecurity-and-poverty/) | 16 points | by [23B1](https://news.ycombinator.com/user?id=23B1) | [17 comments](https://news.ycombinator.com/item?id=35749306)

The impact of AI on the job market is often boiled down to "technology will end all jobs" versus "everything will be fine." In reality, it is more nuanced, and although AI will get rid of many jobs, it doesn't mean everyone will be jobless forever. A recent working paper estimates that around 80% of the US workforce could have at least 10% of their work tasks impacted by the introduction of large language models, and those with bachelor's degrees will be the most impacted. The future of AI's impact on jobs is dependent on the adoption of an unconditional, universal basic income as a rising AI dividend to mitigate job disruption.

Some comments point out that the article lacks credibility and reasoning, and that the issue is much more complex than just implementing UBI. Some argue that UBI could create disincentives for innovation and productivity, and that it would be too expensive to implement. Other comments compare the impact of AI to past technological advancements and suggest that it will lead to lower costs of goods and services, but also to the need for redistribution of wealth. One commenter notes that the original Luddites were not against technology but were fighting against poor working conditions and low pay for textile workers.

### We're afraid language models aren't modeling ambiguity

#### [Submission URL](https://arxiv.org/abs/2304.14399) | 192 points | by [lnyan](https://news.ycombinator.com/user?id=lnyan) | [176 comments](https://news.ycombinator.com/item?id=35737397)

A recent paper published on arXiv, titled "We're Afraid Language Models Aren't Modeling Ambiguity", highlights the importance of ambiguity in natural language understanding and the challenges faced by current language models in recognizing and disentangling possible meanings. The authors characterize ambiguity in a sentence and collect a linguist-annotated benchmark of examples with diverse kinds of ambiguity. They then evaluate the performance of language models, including the recent GPT-4, in recognizing ambiguity and find that it remains extremely challenging. Finally, the authors demonstrate the value of ambiguity-sensitive tools by showing how a multilabel NLI model can flag political claims that are misleading due to ambiguity.

In the comments, there is some discussion about the limitations of language models compared to humans, as well as their strengths in statistical analysis. Some users also discuss the importance of context and personal knowledge in communication, while others reflect on their experiences playing language-based games such as 20 Questions.

### Nuke-launching AI would be illegal under proposed US law

#### [Submission URL](https://arstechnica.com/information-technology/2023/04/nuke-launching-ai-would-be-illegal-under-proposed-us-law/) | 21 points | by [upwardbound](https://news.ycombinator.com/user?id=upwardbound) | [3 comments](https://news.ycombinator.com/item?id=35744974)

US legislators have introduced bipartisan legislation to prevent nuclear launch decisions from being made by artificial intelligence (AI) systems. The Block Nuclear Launch by Autonomous Artificial Intelligence Act demands that automated systems should not launch nuclear weapons without "meaningful human control". Senator Edward Markey, who sponsored the bill with two congressmen and a congresswoman, said that humans needed to be solely responsible for triggering life-or-death decisions about the use of nuclear weapons. The Bill would also codify existing US Department of Defense policy. 

The comments on this submission include a discussion of whether AI should be trusted to make autonomous decisions related to nuclear weapons. One user found it comforting that there is a GUI chat dialog for Palantir's Wargame AI tool and the permissions to use it are checked, while another user pointed out that AI has been used in automated systems for more than 20 years and Dead Hand is an example of such a system. Another user expressed concern that people's stupidity is the flaw in the system, while another user suggested that we should not trust AI blindly.

### Stability AI releases StableVicuna, a RLHF LLM Chatbot

#### [Submission URL](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot) | 49 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [19 comments](https://news.ycombinator.com/item?id=35745682)

Stability AI has released StableVicuna, the AI world's first open-source chatbot trained via reinforced learning from human feedback (RLHF). The chatbot follows a three-stage RLHF pipeline, utilizing datasets such as OpenAssistant Conversations Dataset and GPT4All Prompt Generations, and is further instruction fine-tuned for performance. StableVicuna is available for download on the HuggingFace Hub, alongside its upcoming chat interface. The team plans to iterate on the chatbot and deploy a Discord bot to the Stable Foundation server to further improve the user experience.

In the comments, some users discuss the complexity and limitations of fine-tuned models, suggesting that getting 30B models may not be helpful and that there are possibly 65B behaviors that are different. Others recommend specific AI models under the Apache BSD license, and one user mentions that the project may focus more on optimization rather than benchmarks. Some users recommend trying StableVicuna at https://huggingface.co/spaces/CarperAI/StableVicuna, while others discuss the use of GPT-generated content and reducing content quality. There is also a discussion about licensing and affordability, with some users noting that the project is relatively low-risk and that internal development may benefit from LLaMa.

---

## AI Submissions for Thu Apr 27 2023 {{ 'date': '2023-04-27T18:00:50.664Z' }}

### Hidet: A Deep Learning Compiler for Efficient Model Serving

#### [Submission URL](https://pytorch.org/blog/introducing-hidet/) | 108 points | by [ashvardanian](https://news.ycombinator.com/user?id=ashvardanian) | [14 comments](https://news.ycombinator.com/item?id=35737284)

Introducing Hidet: A Deep Learning Compiler for Efficient Model Serving by Team Hidet showcases the new Hidet deep learning compiler for PyTorch that simplifies the process of implementing high-performing deep learning operators on modern accelerators like NVIDIA GPUs. Hidet is easy to integrate into PyTorch and is an attractive option for PyTorch users who want to improve inference performance of their models. The blog post also provides a sample script to use Hidet to compile and optimize a pre-trained ResNet50 model from torchvision, and an example of how to implement a naive matrix multiplication using Hidet Script and integrate it as a PyTorch operator.

In the comments, users discuss the performance of Hidet compared to other compilers and frameworks like TensorRT, PyTorch Eager, and Triton. Some users highlight the benefits of Hidet Script, the domain-specific language that allows for high flexibility and expression of optimizations. Additionally, users bring up the relevance of benchmarks and the ability to create custom operators with Hidet Script. The discussion also includes technical issues and bugs that users have encountered with Hidet.

### Even Apple employees hate Siri and are skeptical of its future, new report says

#### [Submission URL](https://9to5mac.com/2023/04/27/apple-employees-siri-struggles/) | 395 points | by [carlycue](https://news.ycombinator.com/user?id=carlycue) | [411 comments](https://news.ycombinator.com/item?id=35730075)

A new report from The Information paints a daunting picture of the chaos and internal strife inside Apple's Siri and AI teams. According to more than three dozen former employees who spoke with the publication, "organizational dysfunction and a lack of ambition" have hindered Apple's efforts to improve Siri and its underlying technology, leading to the company falling further behind competitors like OpenAI, Microsoft, and Google. Furthermore, Apple lost three of its Siri engineers to Google, and the Siri team remains widely derided by current employees. Despite some efforts to improve the platform, this report suggests that there is much work to be done for Siri to catch up with its rivals.

The discussion on Hacker News focused on the flaws of Siri, including its speech recognition technology and its lack of understanding of some basic phrases. Some users also discussed the use of third-party keyboards and the limitations of adapting to different languages for personal assistants.

### Text-to-Audio Generation Using Instruction Tuned LLM and Latent Diffusion Model

#### [Submission URL](https://tango-web.github.io/) | 35 points | by [GaggiX](https://news.ycombinator.com/user?id=GaggiX) | [5 comments](https://news.ycombinator.com/item?id=35737151)

Researchers from the DeCLaRe Lab at the Singapore University of Technology and Design have developed a text-to-audio (TTA) generation AI called TANGO that uses an "instruction-tuned LLM" as a text encoder for better performance. TANGO outperforms the state-of-the-art AudioLDM on most metrics and stays comparable on the rest on AudioCaps test set, despite being trained on a smaller dataset. TANGO generates text-conditional sound effects, including human speech and music. While TANGO has limitations in terms of fine control of the generated audio, the team plans to improve it by training it on larger datasets. The code and model checkpoints have been released for reproducibility.

The discussion on this submission mostly involves appreciation for the technology and some additional insights on its capabilities. One user commends the researchers for their excellent work and also shares some resources featuring practical videos and high-level reviews. Another user expresses interest in the technology and suggests some additional tuning to improve its functionality. The user provides a link to an article on generating speech using machine learning. Another user comments on the state-of-the-art text-to-speech technology and shares a link to examples of speech generated synthetically through AI.

### The UIs ChatGPT Won't Replace

#### [Submission URL](https://exorva.com/blog/uis-chat-gpt-wont-replace) | 17 points | by [kmdupree](https://news.ycombinator.com/user?id=kmdupree) | [9 comments](https://news.ycombinator.com/item?id=35734660)

In a recent post on Hacker News, the founder of AI/LLM-powered app guide ChatGPT argues that traditional UIs won't be entirely replaced by chat-based experiences. The post examines tasks that rely on spatial metaphors, list items, and invariants, among other things, and demonstrates why chat-based UIs won't dominate the future. For example, busy people won't use ChatGPT to create calendar events, as they need to be able to see their schedule at a glance, while low-intent product exploration is better served by visual design patterns that instantly orient users. Ultimately, the author suggests that despite technological advancements, humans still work best with spatial and kinetic inputs.

The comments agree, with some suggesting certain tasks are better suited for GUIs or chat-based UIs. One commenter notes the importance of spatial understanding and memory, while another mentions that humans will always prefer human interfaces. Some comments also suggest that chat interfaces can be complementary to GUIs, and AI technology will allow easier access to a library of components for chat interfaces. Finally, one commenter mentions that time interaction feeling may become worse with chat-based interactions, and finding a balance between chat and GUI interfaces is important.

### Is Krita ready for HDR painting?

#### [Submission URL](https://notes.ericjiang.com/posts/1241) | 26 points | by [erjiang](https://news.ycombinator.com/user?id=erjiang) | [5 comments](https://news.ycombinator.com/item?id=35736913)

Krita, a digital painting software, has implemented support for high dynamic range (HDR) painting, allowing users to work with values above the traditional 0.0-1.0 range. However, there are areas within the software that still do not recognize these higher values, and some functions, such as LUT baking, are not yet possible. While it may be sufficient for general work and limited regions above 1, it may be difficult to work across a large dynamic range without proper exposure controls. Additionally, the software's target market may currently be too small to fully support HDR use.

Users on Hacker News talked about the importance of HDR painting and the limitations of current hardware, saying that cameras can capture more data than displays can render. Other users mentioned that HDR painting could be useful in creating works with a wider dynamic range and that similar workflows are used in 3D rendering software. One user also mentioned that games, TV, and movies are already using HDR rendering, but there are limitations due to the lack of HDR screens, which are not yet widely available. Overall, the discussion showed both excitement and caution about Krita's HDR support, with some saying that more exposure controls would be needed to work across a large dynamic range.

### Llama 1.3B Trained on 200B Tokens for Commercial Use

#### [Submission URL](https://huggingface.co/mosaicml/mpt-1b-redpajama-200b-dolly) | 23 points | by [vsroy](https://news.ycombinator.com/user?id=vsroy) | [7 comments](https://news.ycombinator.com/item?id=35737036)

The MPT-1b-RedPajama-200b-dolly is a powerful AI model with 1.3 billion parameters that has been fine-tuned on the Databricks Dolly instruction dataset. The model is a modification of a standard decoder-only transformer and features 24 layers, 16 attention heads, and width 2048. It has been pre-trained on a mix of datasets, with the majority being the RedPajama Common Crawl, and fine-tuned on the Databricks Dolly instruction dataset using the same hyperparameters found in their train_dolly.py script. The model uses ALiBi and QK LayerNorm and does not use biases. To use the model, one needs to pass `trust_remote_code=True` and use the MosaicML LLM codebase. The model was trained on the MosaicML Platform with sharded data parallelism using FSDP. The MPT-1b-RedPajama-200b-dolly is a valuable resource for instruction fine-tuning and natural language processing tasks.

The discussion in the comments primarily focuses on the number of parameters of the model and how they impact its performance. One user links to a paper on chinchilla scaling, which discusses optimizing the number of parameters for computational efficiency. Another user mentions being familiar with the RedPajama dataset.

### Lessons Learned Reproducing a Deep Reinforcement Learning Paper (2018)

#### [Submission URL](http://amid.fish/reproducing-deep-rl) | 48 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [10 comments](https://news.ycombinator.com/item?id=35732843)

Deep reinforcement learning is a fascinating field, but it can be more challenging than expected, as demonstrated by a recent project to reproduce a paper on training deep RL agents using feedback from humans. Debugging reinforcement learning involves lengthy iterations, and it's essential to be meticulous about the hypothesis-forming step to make the most of the scarce runs. It's also necessary to learn to recognize and follow through on confusion and be patient when getting stuck on problems for weeks at a time. Despite its challenges, the field holds much promise, as evidenced by recent work on training agents from human preference feedback.

In the comments, there is a discussion about the difficulties of reproducing research work and the need for patience and perseverance. One user shares their personal experience of creating a reinforcement learning agent to play a game and the challenges they faced. Another user recommends reading Sutton & Barto's book on reinforcement learning.

### Semantic Tokenizer for Enhanced Natural Language Processing

#### [Submission URL](https://arxiv.org/abs/2304.12404) | 68 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [28 comments](https://news.ycombinator.com/item?id=35729586)

A team of four researchers has published a paper titled Semantic Tokenizer for Enhanced Natural Language Processing on arXiv. The team presents a new tokenizer that uses semantics to drive vocabulary construction, with a trainer that uses stemming to enhance subword formation. The tokenizer is a drop-in replacement for the SentencePiece tokenizer and more than doubles the number of word forms represented in the vocabulary. The new tokenizer significantly improves NLP model convergence and improves the quality of word and sentence embeddings, with top performance seen in two Glue tasks using BERT-base, outperforming models more than 50 times in size.

Some comments noted that the paper was a significant improvement in transformer performance and highlighted how semantics can help processing multi-language texts. Others criticized the use of arXiv for class projects and questioned the significance of the paper's contribution. Additionally, some discussed the challenges of tokenization and the impact of vocabulary construction on natural language processing models.

### Palantir demos AI to fight wars but says it will be ethical

#### [Submission URL](https://www.vice.com/en/article/qjvb4x/palantir-demos-ai-to-fight-wars-but-says-it-will-be-totally-ethical-dont-worry-about-it) | 25 points | by [konart](https://news.ycombinator.com/user?id=konart) | [17 comments](https://news.ycombinator.com/item?id=35731534)

Palantir, co-founded by billionaire Peter Thiel, has demonstrated its Artificial Intelligence Platform (AIP) for military decision making. In Palantir's scenario, a military operator uses AI to monitor and respond to enemy activity, such as the recent amassing of military equipment near friendly forces. The operator asks a chatbot to show them more information, generates several plans of attack and organises the jamming of enemy communications. However, the author notes the dangers of automating warfare and abstracting it even further, suggesting the system is an illusion of safety and control for the Pentagon.

The comments discuss ethical concerns over the use of LLMs (lethal autonomous weapons). Some argue that the industry is ignoring these concerns, while others claim that the military will not deploy such systems until they are deemed safe and reliable. There are also some anecdotes about the long hours and intense work culture at Palantir.

### A Low Cost Approach to Improving Pedestrian Safety with Deep Learning

#### [Submission URL](https://nathanrooy.github.io/posts/2019-02-06/raspberry-pi-deep-learning-traffic-tracker/) | 62 points | by [djoldman](https://news.ycombinator.com/user?id=djoldman) | [58 comments](https://news.ycombinator.com/item?id=35727163)

A developer has created a cheap and accurate traffic counting system using TensorFlow and a Raspberry Pi Zero with an 8-megapixel infrared camera and rechargeable USB battery pack. The system uses a convolutional neural network with a secondary region proposal network to detect and localise objects within the frame, with lightweight temporal clustering to track them. The end result is a tool capable of separately counting vehicles, pedestrians and cyclists with high accuracy, potentially providing valuable data for urban planning and safety measures.

In the comments, there was a discussion on whether data on existing traffic patterns would be necessary for making biking more attractive in cities or if current infrastructure should be changed to support pedestrian traffic. Additionally, there was discussion on the correlation between frequent service and high passenger counts, as well as the challenges associated with increasing density and public transportation. There were also debates on making buses more efficient or switching to electric cars, as well as ideas for improving traffic congestion, such as increasing the use of roundabouts and encouraging the use of smaller cars.

---

## AI Submissions for Wed Apr 26 2023 {{ 'date': '2023-04-26T14:23:08.057Z' }}

### HDR-NeRF: High Dynamic Range Neural Radiance Fields

#### [Submission URL](https://xhuangcv.github.io/hdr-nerf/) | 142 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [32 comments](https://news.ycombinator.com/item?id=35717106)

Researchers from Northwestern Polytechnical University and Tencent AI Lab have developed a method called HDR-NeRF that can recover a high dynamic range radiance field from a set of low dynamic range views with different exposures. This allows for the generation of novel high dynamic range (HDR) and low dynamic range (LDR) views with varying exposures. The proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Experiments conducted on synthetic and real-world scenes validate the proposed method's ability to accurately control the exposures of synthesized views and render views with high dynamic range.

The discussion on the news discusses how the proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Some comments are about the advantages of using this method on smart-phones, while others discuss the limitations of the technology. The discussion also explores the naming convention of the technology and tone mapping. 

### Why did Google Brain exist?

#### [Submission URL](https://www.moderndescartes.com/essays/why_brain/) | 464 points | by [brilee](https://news.ycombinator.com/user?id=brilee) | [296 comments](https://news.ycombinator.com/item?id=35716216)

In this essay, former Google Brain employee Brian Kihoon Lee reflects on the existence of Google Brain and its relevance in today's economic conditions. He examines several reasons for its existence, including prestige, breakthrough discoveries, and maintaining a lead in machine learning. Lee suggests that while these reasons were valid in the past, economic pressures and increased competition from other AI companies mean that Google must be more responsible and directed in its research investments. He also notes a shift towards reduced researcher freedom and top-down direction within the company. Lee's perspective offers insights into the challenges facing industry research labs and the evolving landscape of AI development.

The discussion revolves around the validity of ML PhDs majoring in different fields such as chemistry and physics, and their proficiency in machine learning. Many users point out that while ML PhDs may not possess a deep understanding of the field they majored in, they are compensated for their lack of knowledge through their proficiency in ML. Others suggest that ML has helped cross disciplinary lines and created excellent interdisciplinary work. Some users argue that AI companies such as Google need to be more responsible and directed in their research investments, while others point out the need for foundational ML research. Overall, the discussion sheds light on the challenges facing the development of AI and industry research labs in general.

### DeepFloyd IF: open-source text-to-image model

#### [Submission URL](https://github.com/deep-floyd/IF) | 217 points | by [ea016](https://news.ycombinator.com/user?id=ea016) | [123 comments](https://news.ycombinator.com/item?id=35717871)

The StabilityAI team has developed a state-of-the-art open-source text-to-image model, called DeepFloyd IF, with high photorealism and language understanding. The model is composed of a frozen text encoder and three cascaded pixel diffusion modules that generate 64x64, 256x256, and 1024x1024 px images. The model uses the T5 transformer for text embedding and a UNet architecture with cross-attention and attention pooling. It outperforms other state-of-the-art models and achieves a zero-shot FID score of 6.66 on the COCO dataset. The DeepFloyd IF can be run locally and is also integrated with the Hugging Face Diffusers library.

The comments discuss DeepFloyd IF's capabilities compared to other text-to-image models and specific problems with the current implementation. Additionally, there is a discussion around hurdles with prompts and copyright laws. Some users express interest in trying the model with different prompts, while others debate the legal implications of using it.

### Mark Zuckerberg says Meta wants to ‘introduce AI agents to billions of people’

#### [Submission URL](https://www.theverge.com/2023/4/26/23699633/mark-zuckerberg-meta-generative-ai-chatbots-instagram-facebook-whatsapp) | 49 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [53 comments](https://news.ycombinator.com/item?id=35721910)

Meta CEO Mark Zuckerberg has announced plans to integrate AI agents into billions of Meta apps in ways that will be useful and meaningful for regular people, creators, and businesses. Although it remains unclear how exactly Meta will incorporate generative AI into its applications, Zuckerberg teased the release of AI products in the coming months that will reportedly touch every single one of the company's products. The move comes as Meta attempts to keep up with competitors such as Snap and Google that have invested heavily in building AI infrastructure in recent years, and to address industry-wide interest in the potential applications of generative AI technology.
 
There is a discussion on how AI is impacting society, with some commenters noting concerns about AI collecting information and privacy issues. Others discuss the potential uses of AI in marketing and content creation. One commenter suggests Meta should focus on developing computer vision capabilities. While there are some who support the use of AI, others are skeptical and concerned about how AI technology will impact humanity. Additionally, there are some comments about the renaming of the company to Meta and speculation about the company's future.

### Bringing Memory Safety to sudo and su

#### [Submission URL](https://www.memorysafety.org/blog/sudo-and-su/) | 81 points | by [mritzmann](https://news.ycombinator.com/user?id=mritzmann) | [64 comments](https://news.ycombinator.com/item?id=35714347)

Prossimo, a project by Ferrous Systems and Tweede Golf, has announced their plan to re-implement the widely-used sudo and su utilities in Rust to increase memory safety and minimize risks to operating systems. As sudo and su were originally developed in the 1980s and written in C, they have experienced a number of vulnerabilities related to memory safety issues. This joint team from Ferrous Systems and Tweede Golf will work to implement the critical function of these utilities in Rust to secure the most critical software, particularly from memory safety vulnerabilities. The work is supported by Amazon Web Services and Prossimo welcomes contributions to improve memory safety.

Discussions in the comments focused on the effectiveness of Rust's memory safety features, the complexity and vulnerabilities of other programming languages, and the importance of memory safety in software security. Some commenters suggested that OpenBSD's Doas could be a smaller, simpler alternative to sudo, and others discussed the advantages of different programming languages for memory safety.

### A guide to prompting AI, for what it is worth

#### [Submission URL](https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what) | 179 points | by [jger15](https://news.ycombinator.com/user?id=jger15) | [50 comments](https://news.ycombinator.com/item?id=35712375)

Recently, there has been a lot of emphasis on the importance of prompting AI, with some influencers sharing secrets of how to use prompts effectively. However, Ethan Mollick argues that this emphasis on prompting is misplaced and the best way to use AI systems is through interaction rather than trying to craft the perfect prompt. That being said, Mollick provides some tips on how to approach prompting, such as giving context and constraints to the system, providing additional data, and thinking about programming in prose. Ultimately, the key to using AI effectively is practice.

The discussion covers a variety of perspectives, including tips for approaching prompting, the limitations of AI in understanding human intent, and the importance of providing context and constraints to the system. Some commenters suggest that the emphasis on prompting is misplaced, while others argue that finding the right wording and constraints is crucial for successful outcomes. Overall, the discussion highlights the complex and ongoing nature of working with AI systems.

---

## AI Submissions for Tue Apr 25 2023 {{ 'date': '2023-04-25T15:39:53.181Z' }}

### Transformers from Scratch

#### [Submission URL](https://e2eml.school/transformers.html) | 341 points | by [jasim](https://news.ycombinator.com/user?id=jasim) | [28 comments](https://news.ycombinator.com/item?id=35697627)

Transformers are all about sequence transduction, we need a way to convert words to numbers so we can do math on them. One approach is to count each word from one and assign it a number, but there's an easier format for computers to work with: one-hot encoding. This assigns each word an array of mostly zeroes with a single one in its corresponding index. This allows us to compute dot products and is used in matrix multiplication, a way to combine two-dimensional arrays. Markov chains, represented as matrices, can be used as a first order model to show what the next word is likely to be based on recent words.

The submission discusses the use of one-hot encoding to convert words to numbers for mathematical operations. It is suggested that the use of matrices, such as Markov chains, can help predict the next likely word based on the sequence. The comments provide links to additional resources, such as Jay Alammar's Illustrated Transformer series and TensorFlow implementation, and discuss various aspects of tokenization, embeddings, and projections. Some users express disappointment in the complexity of the topic while others provide beginner-friendly resources for understanding it. Two comments are flagged as possibly inappropriate.

### Tuql: Automatically create a GraphQL server from a SQLite database

#### [Submission URL](https://github.com/bradleyboy/tuql) | 20 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [8 comments](https://news.ycombinator.com/item?id=35699017)

Tuql is a new tool that can convert a SQLite database into a GraphQL endpoint. With its ability to infer relationships between objects, Tuql currently supports `belongsTo`, `hasMany`, and `belongsToMany` relationships. The tool also generates the necessary mutations to create, update, and delete objects and can associate many-to-many relationships. Tuql can be used through the command line and is available as an npm package.

The comments on the submission mention that Tuql is a great tool, and some users mention other similar libraries. One user points out that Tuql does not add threat fields for queries, which may make it difficult to change the frontend in the future. Another user recommends not using Tuql in production. There is also a discussion around how GraphQL frameworks handle authorization and security. Overall, most of the comments are positive, with users praising the convenience of Tuql and GraphQL libraries in general.

### Show HN: ChatGPT on 2-Dimensional Map

#### [Submission URL](https://www.superusapp.com/chatgpt2d/) | 147 points | by [victorsup](https://news.ycombinator.com/user?id=victorsup) | [55 comments](https://news.ycombinator.com/item?id=35709088)

On Hacker News, a developer has created an interesting web app called "ChatGPT on 2-Dimensional Map." The app combines two popular AI technologies, namely GPT-2 for natural language processing and t-SNE for dimensionality reduction, to create a chatbot that can navigate a 2D map based on user inputs. The developer has also provided a demo, so users can see the app in action. This innovative project showcases the potential of combining different AI tools to develop new and creative applications.

A developer has created a web app called "ChatGPT on 2-Dimensional Map," utilizing both the natural language processing capabilities of GPT-2 and t-SNE for dimensionality reduction to create a chatbot that can navigate a 2D map based on user inputs. The discussion shows appreciation for this innovative project and its demonstration of the potential of combining AI tools to develop new applications. Some users express interest in using this technology for research and performance modeling, while others suggest similar projects and libraries for visualization and mapping. Some discuss related concepts such as Mind Maps and Lie Algebra. The high cost of ConceptGPT is mentioned, and some users suggest alternatives or that the creator should have asked for a funding request. A few users also mention indulging in activities such as drinking while programming or creating AI, while others make fun of misconceptions around Pina Coladas and canned ingredients.

### Google Authenticator cloud sync: Google can see the secrets, even while stored

#### [Submission URL](https://defcon.social/@mysk/110262313275622023) | 349 points | by [Signez](https://news.ycombinator.com/user?id=Signez) | [117 comments](https://news.ycombinator.com/item?id=35708869)

The discussion revolves around the security of Google Account 2FA secrets and how well Google protects its user data. Some commenters question Google's willingness to share user data with governments, while others suggest ways to enhance the security of the 2FA system and protect against data breaches. The conversation also touches on Apple's adherence to user privacy in comparison to Google. The debate ultimately boils down to how much responsibility users should take to protect their own privacy and how much they should rely on their service providers. One user recommends a phone security service called 2FAS for added security.

---

## AI Submissions for Mon Apr 24 2023 {{ 'date': '2023-04-24T15:21:30.763Z' }}

### LAION, a high school teacher’s free image database, powers AI unicorns

#### [Submission URL](https://www.bloomberg.com/news/features/2023-04-24/a-high-school-teacher-s-free-image-database-powers-ai-unicorns) | 315 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [172 comments](https://news.ycombinator.com/item?id=35685497)

The article tells the story of Christoph Schuhmann, a high school teacher who created LAION, the world's largest free AI training data set. LAION collects images and captions from various websites and uses them to train text-to-image generators, such as Google's Imagen and Stability AI's Stable Diffusion. The article explores the legal and ethical issues that arise from using publicly available materials for AI purposes, such as copyright infringement, bias, and regulation. The article also presents Schuhmann's views on why he wants to keep LAION open-source and independent.

Some users argue that LAION  only indexes internet lists of URLs, regional messages, and AI-generated text-to-image models, and does not publish any copyrighted content. Other users point out the potential legal liabilities and suggest that Common Crawl, a California nonprofit, should curate the collected visual data. Additionally, the comments touch on the challenges of accessibility in the design of captchas, the importance of properly organized high-quality imagery, and the legal implications of using scraped visual data for machine learning.

### Google Authenticator now supports Google Account synchronization

#### [Submission URL](https://security.googleblog.com/2023/04/google-authenticator-now-supports.html) | 429 points | by [ortusdux](https://news.ycombinator.com/user?id=ortusdux) | [305 comments](https://news.ycombinator.com/item?id=35690398)

Google Authenticator, a popular two-factor authentication app, now supports synchronization with Google Accounts. This means that users can easily transfer their authentication codes to a new device without needing to manually re-enter them. The feature is available on Android and iOS devices and uses Google Cloud to securely store and transfer the data. This upgrade provides added convenience and security for users who rely on two-factor authentication to protect their accounts.

Some users have complained about Google's 2FA offerings, including mismatched numbers and issues with Google Prompts not working on certain devices. Others have suggested potential solutions, such as using U2F tokens, while acknowledging the importance of account recovery processes involving important documents. The discussion also touches on related topics, such as password management, customer support, and device limitations. Overall, the consensus seems to be that while there are some issues and complexities with the technology, 2FA remains an important security measure that consumers should take advantage of.

### ONNX Runtime merges WebGPU backend

#### [Submission URL](https://github.com/microsoft/onnxruntime/pull/14579) | 166 points | by [b_mc2](https://news.ycombinator.com/user?id=b_mc2) | [31 comments](https://news.ycombinator.com/item?id=35694553)

Microsoft's open-source AI platform, ONNX Runtime, has introduced a WebGPU backend to accelerate machine learning models on the web. The JavaScript Execution Provider (JSEP) enables asynchronous inferencing execution and includes both C/C++ and TypeScript/JavaScript implementations. JSEP uses Emscripten's Asyncify compiler feature to unwind and rewind the call stack to emulate async execution. WebGPU is designed to have stronger features than WebGL, the other API currently available for accessing a GPU from a browser, making it a better solution for GPU performance when inferencing machine learning models.

Yhe submission sparked a discussion about the ONNX format, ONNX Runtime, and the implementation of the WebGPU backend for ML models. Some commenters suggested that the ONNX format is one of the best performing ML runtimes currently available, while others noted the lack of documentation for different platforms and hardware combinations. Others praised Microsoft's ONNX and made comparisons between different compiler systems. Some suggested alternative approaches to commenting and merging code to larger PRs. There was also discussion about the usefulness of the ONNX library, with some saying it worked well for them, and others suggesting that it could still use some improvement.

### 1Password to Add Telemetry 

#### [Submission URL](https://blog.1password.com/privacy-preserving-app-telemetry/) | 285 points | by [zan5hin](https://news.ycombinator.com/user?id=zan5hin) | [266 comments](https://news.ycombinator.com/item?id=35691383)

1Password, the password manager service, has begun an internal test of a new in-app telemetry system with a view to better understanding how users interact with the product. The initiative will be voluntary for employees and will not involve any data from customer accounts. Over the years, 1Password has regularly used its customer research programme to inform product development, but the company said it needed to expand its knowledge to improve the service for the millions of people using the product. Results from the internal trial will be evaluated before plans for a rollout are confirmed.

A user commented that they have been using the password manager Keepass, as they prefer a local vault and do not want any browser or cloud-based password managers. Another user praised 1Password's UI/UX, while others expressed concerns about the voluntary telemetry initiative and subscription-based licensing. Some users recommended Bitwarden and Keepass as alternatives with better functionalities. Some users also expressed skepticism about the benefits of telemetry and the need for it.

### Snapchat sees spike in 1-star reviews as users pan the ‘My AI’ feature

#### [Submission URL](https://techcrunch.com/2023/04/24/snapchat-sees-spike-in-1-star-reviews-as-users-pan-the-my-ai-feature-calling-for-its-removal/) | 240 points | by [mmq](https://news.ycombinator.com/user?id=mmq) | [200 comments](https://news.ycombinator.com/item?id=35689596)

Snapchat's new AI chatbot, powered by OpenAI's GPT technology, has been met with criticism by users following its recent public release. The chatbot, which is now pinned at the top of Snapchat's Chat tab, has resulted in a spike of negative reviews on the US App Store, with 75% being one-star reviews over the past week. Many users feel the chatbot is invasive and creepy, with concerns surrounding the collection of personal data, and have called for it to be a voluntary, opt-in feature. Some reviews indicate that even those who rated the app five stars have complaints about the My AI feature.

The comments section discusses data privacy concerns and the collection of personal data by companies, as well as the implementation of taxes like the Canadian Manufacturers Tax and GST. Some users feel that people do not grasp the extent of data collection that is happening, and that companies need to be more transparent about it. Others point out that sharing of personal information is an expected part of using such services.