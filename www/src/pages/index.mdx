import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Sat Nov 11 2023 {{ 'date': '2023-11-11T17:09:37.043Z' }}

### Google uses int8 for LLM training

#### [Submission URL](https://old.reddit.com/r/LocalLLaMA/comments/17sbjsv/google_blog_posts_suggests_that_google_using_int8/) | 45 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [20 comments](https://news.ycombinator.com/item?id=38229928)

Google is utilizing reduced numerical precision of 8-bit integers (INT8) instead of 16-bit floats (BF16) for training its language models, according to a blog post. The company has built an accurate quantized training (AQT) library that allows machine learning engineers to achieve higher performance during training and higher model quality in production. This approach takes advantage of the fact that ML accelerators have twice the compute speed when using INT8 operations compared to BF16 operations. If Google can successfully train models using INT8, it could potentially pave the way for more cost-effective training methods that could be adopted by the open-source community.

Discussion:

1. User "nbckng" points out that the use of reduced precision in training models can lead to suboptimal solutions and may not converge to the desired outcome. They mention that some researchers have published work on binary activations and stochastic fashion for training neural networks.
2. User "sigmoid10" adds that differentiability is essential in training models using gradient descent, regardless of the specific mathematical methods employed. They mention that there are alternative training methods for neural networks that do not rely on differentiability.
3. User "stvnhng" disagrees with the statement that the human brain does not work similarly to how training models do. They mention that there is relevant research suggesting that the brain reduces uncertainty by making predictions based on internal models.
4. User "thrwbdbd" suggests that building mathematical numbers using bits can be done by operating between partitions. User "rscy" adds that arithmetic can be implemented between partitions, but lower precision and smaller value ranges may lead to fewer bits being required.
5. User "_nalply" believes that four bits might be sufficient for quantization because small changes have small effects in differentiable mathematical functions.
6. User "blstnc" comments with a sarcastic remark about the discussion.
7. User "xrd" questions the significance of the missing mental model and suggests that the difference in representation and cost between GPU and CPU storage may be the primary reason for not using floating-point values.
8. User "wlg" brings up Elon Musk's statement about using int8 training for Tesla's Full Self-Driving (FSD) system.
9. User "gnzl" argues that high precision is needed in touch interactions, mentioning that it is necessary for precise positioning.

The discussion mainly revolves around the benefits and limitations of using reduced precision in training language models, with users sharing their thoughts, opinions, and providing additional information or examples related to the topic.

### Show HN: GPT-4 vision utilities to browse the web

#### [Submission URL](https://github.com/reworkd/tarsier) | 8 points | by [asim-shrestha](https://news.ycombinator.com/user?id=asim-shrestha) | [4 comments](https://news.ycombinator.com/item?id=38234305)

Reworkd has released an open-source utility library called Tarsier, designed to help automate web interactions. Tarsier is specifically targeted at multimodal web agents, such as agents that combine natural language processing with vision capabilities. The library allows users to visually "tag" interactable elements on a webpage, providing a mapping between elements and identifiers for the agent to take actions on. Tarsier also includes OCR utilities that can convert a screenshot of a webpage into a text representation that can be understood by agents without vision capabilities. The library currently supports Google Cloud Vision, with plans to add support for other OCR services in the future. Tarsier is available on GitHub under the MIT license.

The discussion on this submission mainly revolves around the README of Tarsier not accurately reflecting the mentioned features. One user points out that the README states that the library supports Google OCR, while the OpenAI API key makes more sense in the context of GPT-4 version. Another user suggests that the Google OCR should convert the screenshot into whitespace-structured text, which would be more useful for multimodal language models (LLMs) such as GPT-4V. The original submitter thanks for the feedback and promises to clarify the information.

### AI startups in France

#### [Submission URL](https://techcrunch.com/2023/11/09/theres-something-going-on-with-ai-startups-in-france/) | 51 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [58 comments](https://news.ycombinator.com/item?id=38232006)

France is emerging as a major hub for artificial intelligence (AI) startups, with a large talent pool of PhD students in math, computer science, and engineering. Companies like Facebook and Google have set up AI research labs in Paris, attracting top talent. Mistral AI, a French AI startup that raised €105 million in seed funding, demoed its open-source language model, Mistral AI Chat, at a tech meetup. Poolside, a company aiming to make coding easier using AI, raised $126 million and is based in Paris. Other AI startups, such as Dust and Nabla, are also gaining traction in France's growing AI ecosystem. The French government is providing public support to AI startups, offering grants worth millions of euros. European AI startups are distinguishing themselves by considering regulation and compliance from day one. Additionally, several stealth AI startups are emerging in Europe, including Adaptive, which helps companies iterate on their AI applications, and Wiem Gharbi's Paris-London-based AI venture. Notable French entrepreneurs are also starting AI startups, such as Steeve Morin, co-founder of Zenly, and Maxime Germain, founder of mental health startup Jour. With a surge in AI startup activity in France, venture capital firms are vying for the most competitive funding rounds.

The discussion on this submission covers a range of topics related to France's AI ecosystem, the influence of language on thinking and problem-solving, and the challenges of doing business in France. 

- Some users discuss the strong mathematics culture in France, attributing it to the country's education system and the emphasis on math in schools. They also mention the strong presence of French mathematicians in international competitions like the International Mathematical Olympiad (IMO).
- Others comment on the trendiness of AI and how France, particularly Paris, has become a hub for AI research and startups. They attribute this trend to factors such as the presence of top talent, the establishment of AI research labs by companies like Google and Facebook, and public support from the French government.
- A few users engage in a discussion about language and its influence on thinking and problem-solving. They touch on topics like the Sapir-Whorf hypothesis and the differences between languages in terms of how they represent concepts and affect cognition.
- Some users share personal experiences working with French researchers and point out the challenges of language barriers in international collaborations.
- There is also a brief exchange about the difficulties of doing business in France, including labor laws and paperwork requirements. Some users highlight the protections provided by labor laws, while others mention the potential barriers and extra costs for businesses.
- The topic of holidays and work-life balance in France is briefly mentioned, with some users comparing it to the work culture in other countries, particularly the United States. The discussion touches on the length of vacations, the perception of productivity, and the importance of taking time off.

Overall, the discussion provides insights into the strengths and challenges of France's AI ecosystem, the role of language in cognition, and the nuances of doing business in the country.

### Show HN: Stories for Kids Using AI

#### [Submission URL](https://storybee.app) | 14 points | by [niksmac](https://news.ycombinator.com/user?id=niksmac) | [20 comments](https://news.ycombinator.com/item?id=38228672)

Introducing StoryBee, the AI-powered platform that effortlessly converts stories into audio! With StoryBee, you can generate kids' stories anytime and anywhere. The platform features curated stories generated by AI, including heartwarming fairy tales like "The Kindness of the Orange Tabby Cat" and thrilling adventures like "The Mysterious Kingdom Under the Sea." Creating stories with StoryBee is a breeze – simply provide a story hint, customize it to your liking, and let the AI work its magic. StoryBee aims to ignite children's curiosity, fuel their dreams, and take them on enchanting journeys through magical storytelling. Whether you're a parent or an educator, StoryBee is the perfect tool for creating captivating and educational stories for children. So dive into the world of magical storytelling with StoryBee and watch dreams come to life!

The discussion on this submission revolves around the concept of AI-generated storytelling and its impact on children. One user points out that AI-generated stories lack depth and genuine character development, compared to human-written stories. Another user shares their frustration with the lack of quality reading time children have due to exposure to native language speakers and YouTube videos.

There is also discussion about the potential benefits of AI-generated illustrations and the suggestion to incorporate screen time in small kids' school activities. Some users express concerns about the ethical implications of relying solely on AI-generated content for children.

The conversation diverges to discussing the importance of reading real books and the role of parents and teachers in spending quality time with children. There is also a mention of the responsibility of parents to ensure the quality and appropriateness of content for their children.

The topic of AI-generated stories is further explored, with one user sharing an example of an AI-generated story and expressing concerns about the perpetuity of AI-generated content. There is a brief discussion about the terms of service and privacy policy of StoryBee, and the need for simplicity and clarity in legal terms.

In the later part of the discussion, users suggest alternatives to StoryBee, such as using GPTs or exploring other platforms focused on illustrations. There is also mention of pricing comparisons and the potential launch of downloadable PDF versions of stories for interested parents.

### Fourteen Years of Go

#### [Submission URL](https://go.dev/blog/14years) | 218 points | by [keyle](https://news.ycombinator.com/user?id=keyle) | [291 comments](https://news.ycombinator.com/item?id=38229001)

Today marks the fourteenth birthday of the Go open source release, and the Go team is celebrating a great year of milestones. Two feature-filled releases, Go 1.20 and Go 1.21, focused on implementation improvements rather than new language changes. One notable improvement is the profile-guided optimization (PGO) feature, which allows the Go compiler to optimize the parts of a program that run most frequently. Workloads typically saw CPU usage improvements of 2% to 7% with PGO enabled. The Go team also made strides in compatibility, with improvements in backward compatibility through expanded conventions for using GODEBUG, as well as nifty new tooling features like built-in toolchain management and on-disk indexes in gopls. In terms of language enhancements, Go 1.21 introduced Go's first generic standard libraries, as well as the log/slog package for structured logging. The Go web community also got support for the WebAssembly System Interface (WASI) preview 1. On the security front, the Go team launched Govulncheck 1.0, a tool to help developers identify dependencies and vulnerabilities. They also made significant progress in ensuring reproducible toolchain builds. Looking ahead to Go's fifteenth year, the team has exciting plans, including redefining for loop semantics to avoid potential aliasing bugs. The Go team would like to express their gratitude to all the contributors and the Go community for their support and contributions. They wish everyone the best for the year ahead.

The discussion on the submission revolves around various aspects of the Go programming language. Some users express disappointment with the lack of certain language features and the trade-offs made by the language designers. There is a debate about the handling of errors and the usefulness of different language constructs. Some users argue that Go's lack of certain features is intentional and promotes simplicity, while others argue that these features are important for complex programs. One user points out that Go's design choices may not align with everyone's preferences and that different programming languages have different trade-offs. Another user mentions the importance of comprehensive testing and error checking to address common programming mistakes.

There is also a discussion about the naming conventions and usage of operators in Go, with some users finding them confusing or misleading. The debate touches on topics such as operator overloading and the limitations of the Go language in supporting certain assumptions. Additionally, there are comments expressing skepticism about the effectiveness of AI in assisting with programming and suggesting that the design of a program should be guided by human programmers rather than relying on AI-generated code.

Overall, the discussion reflects a mix of opinions on the strengths and weaknesses of the Go programming language and the trade-offs made in its design.

### Met Police Scans Almost 250k Faces Using Facial Recognition Technology in 2023

#### [Submission URL](https://bylinetimes.com/2023/11/10/revealed-met-police-scans-almost-quarter-of-a-million-faces-using-facial-recognition-technology-in-2023/) | 43 points | by [BerislavLopac](https://news.ycombinator.com/user?id=BerislavLopac) | [8 comments](https://news.ycombinator.com/item?id=38228709)

The Metropolitan Police in London has scanned nearly a quarter of a million faces using live facial recognition (LFR) software in 2023, according to Freedom of Information requests filed by Byline Times. The LFR system automatically scans the faces of passers-by and matches them against a watchlist. The Met took several months to respond to the FOI request, which revealed it had scanned an estimated 247,764 faces in 2023 during 13 deployments across London, resulting in just 12 arrests. Civil liberties groups and MPs have criticized the use of LFR, saying it is incompatible with human rights and has a chilling effect on freedom of speech. The use of LFR technology is currently being banned by the EU, but officers in London are continuing to use it.

The discussion surrounding the submission includes various perspectives on the use of live facial recognition (LFR) technology by the Metropolitan Police in London. One commenter, mb5, points out that the director of intelligence for the Met immediately deletes pixelated images. Others, such as adhesive_wombat, criticize the extensive surveillance and lack of regulatory oversight, suggesting that policing should focus on areas like schools, roads, and healthcare rather than using expensive AI systems. YuccaGloriosa suggests deleting the images once their purpose is fulfilled. InCityDreams mentions that face masks, which have become more common recently due to COVID-19, make LFR less effective in public spaces like shopping centers and road intersections. Finally, k1ns expresses surprise at the low number of arrests despite the large number of faces scanned.

---

## AI Submissions for Fri Nov 10 2023 {{ 'date': '2023-11-10T17:11:32.560Z' }}

### Don't build AI products the way everyone else is doing it

#### [Submission URL](https://www.builder.io/blog/build-ai) | 485 points | by [tortilla](https://news.ycombinator.com/user?id=tortilla) | [224 comments](https://news.ycombinator.com/item?id=38221552)

Unique, valuable, and fast AI products require a different approach than what most people are currently doing. Steve Sewell, in his blog post, highlights some of the problems with the prevailing method of building AI products, such as using wrappers over pre-trained models like ChatGPT. He then presents an alternative solution.

One of the major issues with the current approach is a lack of differentiation. Many AI products being built are easily replicable because they utilize simple techniques with pre-trained models that anyone can copy. This presents a risk for products that rely on advanced AI technology for their unique value proposition.

Another problem is the cost associated with using large language models (LLMs) like ChatGPT. These models are expensive to run due to their extensive size and complexity. In some cases, the cost of running the service exceeds what users are willing to pay. Additionally, LLMs can be painfully slow, especially for applications where text needs to be processed quickly and a delay in response time is impractical.

Furthermore, LLMs have limited customization capabilities. While fine-tuning can help to some extent, it may not be sufficient to achieve the desired results. This can lead to slow, expensive, and lower-quality products.

The solution proposed by Sewell is to create your own toolchain. By combining a fine-tuned LLM with a custom compiler and a custom-trained model, developers can build AI products that are faster, more reliable, cheaper, and more differentiated. This approach avoids the risk of copycat products and open-source clones appearing overnight. It also challenges the misconception that AI products rely on a single super intelligent model, highlighting the importance of specialized models connected through normal code.

Sewell emphasizes that building AI products using this alternative method is not as difficult as it may seem. Even moderately experienced developers can train their own models without the need for extensive data science or machine learning expertise. The result is a more unique and powerful AI product that stands out in the market.

The discussion on the Hacker News post revolves around the efficacy and limitations of using chatbots and large language models (LLMs) in AI products.

One user points out that not all AI products require the use of chatbots, and the focus should be on solving real problems rather than building technology just for the sake of it. They argue that many startups fall into the trap of building without a clear problem in mind and end up wasting resources.

Another user mentions that chatbots have been used for years by larger companies to improve customer experience and reduce call center staff. They argue that quality conversations and human connection are important in getting answers and solving problems.

Some users express concerns about the limitations and challenges of chatbots. They highlight that chatbots can be difficult to scale and often result in frustrating experiences for users. They also point out that chatbots may not fully understand human text and can sometimes lead to miscommunication.

There is a discussion about the power and drawbacks of giving chatbots control. Some users argue that chatbots have the potential to empower and scale customer support, while others highlight the risks of discrimination and vulnerable populations being left behind.

The conversation also touches on the potential of large language models like GPT-4 in revolutionizing customer support. Some users believe that the advancements in language models will greatly enhance chatbots' capabilities and impact the field of customer service.

Overall, the discussion highlights the need to balance the use of AI technology like chatbots with the importance of human connection and solving real problems effectively.

### Protégé: A free, open-source ontology editor for building intelligent systems

#### [Submission URL](https://protege.stanford.edu/) | 124 points | by [stefankuehnel](https://news.ycombinator.com/user?id=stefankuehnel) | [28 comments](https://news.ycombinator.com/item?id=38221709)

Protégé is a versatile ontology editor and framework that is widely used by academic, government, and corporate users. With a strong and supportive community, Protégé helps build knowledge-based solutions in various fields such as biomedicine, e-commerce, and organizational modeling.

One of the features that makes Protégé valuable is its adaptability. Its plug-in architecture allows developers to create simple or complex ontology-based applications. The output of Protégé can be integrated with rule systems or other problem solvers to build intelligent systems.
The community behind Protégé is actively involved in supporting users and developers. They provide assistance, write documentation, and contribute plug-ins to enhance the overall experience.
Protégé also adheres to the latest W3C standards, fully supporting OWL 2 Web Ontology Language and RDF specifications.
Protégé is built on Java and offers an extensible and flexible environment for rapid prototyping and application development.
In addition to the main Protégé software, the community has also developed webProtégé, a collaborative tool that allows users to maintain glossaries and share knowledge models. webProtégé makes it easy to access foundational ontologies online without the need to install software.
Overall, Protégé is a valuable tool for building intelligent systems and managing complex relationships between various aspects of an organization's architecture. With its open-source nature and active community, Protégé continues to grow and improve.

The discussion about the submission "Introducing Protégé: An Open-Source Ontology Editor and Framework" on Hacker News covers a range of topics related to ontology development and usage.

One user comments that they are not interested in ontologies themselves but enjoy using Protégé for working with OWL, which is the ontology language supported by the framework. Another user suggests that hand-coded ontologies in plaintext or turtle format may be more manageable than using Protégé.
There is a discussion about the benefits of using ontologies, with some users noting that ontologies can help map models and interpret medical data, while others highlight the limitations of ontologies and the computational power required for complex reasoning.
The topic of consensus in ontologies is also touched upon, with one user mentioning the Plow0 package manager for ontologies as an attempt to bring grass-roots effects and standardization to ontology engineering.
The discussion also brings up the use of probabilistic ontologies and the challenges of reconciling different world views in ontologies. There is a comment about the lack of widespread adoption of ontologies and the difficulty of creating common vocabularies.
The importance of ontology validation and the challenges of using OWL for real-world modeling are discussed, along with alternative technologies such as SHACL and ShEx.
Improvements to ontology tools, the gamification of ontology development, and the interest in ontology development with linked data applications are also mentioned in the discussion.
One user reminisces about using Protégé 20 years ago and suggests that recent interest in logical language models and graphs has increased interest in ontology development for semantic web and linked data applications.

The discussion ends with a comment about the license for Protégé being BSD.

### Google Cloud TPU Multislice Training

#### [Submission URL](https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e) | 106 points | by [infixed](https://news.ycombinator.com/user?id=infixed) | [47 comments](https://news.ycombinator.com/item?id=38222277)

Google Cloud has recently demonstrated its ability to train large language models (LLMs) across a massive distributed network of over 50,000 TPU v5e chips. Training these large LLMs requires massive amounts of AI supercomputing power, and Google Cloud's Multislice Training offering addresses the technical challenges of distributed training.

The Multislice Training offering includes robust orchestration and scalability, performant compilation using the XLA compiler, and a flexible stack for end-to-end training. Google Cloud has open-sourced several components of the stack, such as the Accelerated Processing Kit (XPK) for ML job orchestration, MaxText for JAX LLM implementation, and Accurate Quantized Training (AQT) for training with reduced numerical precision.

In a groundbreaking achievement, Google Cloud ran the world's largest publicly disclosed LLM distributed training job using Multislice Training. This job utilized a compute cluster of 50,944 TPU v5e chips and achieved a peak performance of 10 exa-FLOPs (16-bit) or 20 exa-OPs (8-bit). The scale of this cluster surpassed that of the TOP1 Supercomputer Frontier at Oak Ridge National Laboratory.

The training job was set up on the JAX framework, leveraging XPK, GKE, MaxText, AQT, and other components of the JAX training stack. Multiple models with varying parameter sizes were trained using data parallelism and sharding techniques.

Google Cloud's Multislice Training demonstrates its commitment to providing scalable, reliable, and easy-to-use solutions for training large language models. By tackling the challenges of distributed training, Google Cloud empowers developers and machine learning engineers to train models efficiently at unprecedented scale.

The discussions on this submission revolve around various aspects of Google Cloud's Multislice Training and the technical details of the distributed training job. Users discuss the architecture and communication between TPUs, the use of Kubernetes for orchestration, the benefits of large batch sizes, and the potential drawbacks of the presented benchmarks. There are also discussions about Google Cloud's relationship with Google's internal infrastructure and the market positioning of Google Cloud within Alphabet. Some users highlight the importance of Google Cloud's marketing efforts and the potential value of leveraging Alphabet's internal infrastructure for Google Cloud's business. There are also discussions about the trade-offs in batch size and the benefits of larger batch sizes in training large language models, as well as discussions about measuring performance and tuning hyperparameters for training. Overall, the discussions provide a deeper understanding of the technical aspects, challenges, and potential implications of Google Cloud's Multislice Training offering.

### Automa – Automate the browser by connecting blocks

#### [Submission URL](https://www.automa.site/) | 109 points | by [judiisis](https://news.ycombinator.com/user?id=judiisis) | [10 comments](https://news.ycombinator.com/item?id=38218329)

Introducing Automa, the ultimate browser automation tool that allows you to automate your browsing experience with ease. Whether you need to auto-fill forms, perform repetitive tasks, take screenshots, or scrape data from websites, Automa has got you covered. This browser extension for Chrome lets you connect blocks to achieve your desired actions.

Scrape data effortlessly and export it as JSON or CSV, or even insert it directly into Google Sheets. With Automa, you can record your actions and create workflows automatically. Want to keep track of your workflow history? Automa has a handy logs feature where you can see the progress of your executions or export collected data.

Need to automate multiple workflows? No problem! Automa allows you to run multiple workflows in sequence for seamless automation. The best part is that you can personalize your automation by choosing from a variety of blocks provided by Automa. All you have to do is connect them to make your browsing tasks a breeze.

Customizing your workflow triggers is made simple with Automa. Set your workflow to run daily or whenever you visit specific websites by using the trigger block. Additionally, Automa users have contributed dozens of workflows to the marketplace, offering a wide range of ready-to-use options that you can add and customize to fit your needs.

So why waste time on tedious browser tasks when Automa can do the job for you? Give Automa a try and start automating any website the way you want. Get the Automa browser extension for Chrome and explore its full potential on GitHub.

The discussion on the submission titled "Introducing Automa: The Ultimate Browser Automation Tool" revolves around the experiences and opinions of users who have tried Automa.

User SparkyMcUnicorn shares their experience of using Automa, stating that they had tried it in the past but found the user interface to be lacking. They mention experiencing issues with selecting elements on webpages using CSS selectors, and had to manually start over multiple times. However, they note that the CSS selector functionality has improved recently and seems to be working correctly. They plan to test the improvements further.

User jejeyyy77 comments that they usually write userscripts to perform actions on webpages and automate specific tasks. They mention using Automa for tasks like clicking expand buttons and filtering lists, which they find helpful for quickly obtaining specific information.

User trntrl expresses interest in Automa and mentions that they experienced a navigation issue on their iPhone, where the hamburger menu did not appear when clicking the documentation link on the landing page.

User mrws discusses their preference for visual workflow automation tools like Power Automate Desktop and MIT Scratch, which they find to have a better user experience. Another user, mgmmlt, agrees with the benefit of visual tools for building macros and shares a link to a platform that helps with building macros.

User mrntw mentions trying Automa and experiencing some typing issues. They found it strange that typing manually produces "hcm" instead of "hmc".

User cvlk adds a comment about the integrated n8n tool, which is a visual workflow automation tool.

Overall, the discussion includes both positive and negative experiences with Automa, with some users finding it helpful for specific tasks while others prefer alternative tools.

### GPU advancements in M3 and A17 Pro [video]

#### [Submission URL](https://developer.apple.com/videos/play/tech-talks/111375) | 186 points | by [bhj](https://news.ycombinator.com/user?id=bhj) | [136 comments](https://news.ycombinator.com/item?id=38214806)

Apple has announced the new Apple family 9 GPU architecture in A17 Pro and the M3 family of chips. These GPUs bring advancements in GPU performance and power efficiency to improve the performance of apps and games on Apple devices. The new shader core architecture enhances the performance and power efficiency of existing apps and allows for the development of next-generation apps. Hardware-accelerated ray tracing and mesh shading technologies further enhance rendering effects and geometry processing pipelines. The new GPUs deliver significant performance improvements for gaming and rendering applications.

The discussion on this submission revolves around the technical aspects of Apple's new GPU architecture and how it compares to Nvidia GPUs. 
One user mentions two posts about the shader permutation problem and how it affects GPU performance. They explain that GPUs have a large number of execution paths, making it difficult to optimize performance for all possible scenarios. 
Another user clarifies the terminology used by Apple and Nvidia to describe their GPUs. They explain that Apple refers to its GPU as having 8 cores, while Nvidia refers to its GPU as having 20 "stream multiprocessors" (SMs) consisting of 128 cores each. They also highlight the differences in thread counts between the two GPUs. 
There is also a discussion comparing GPU and CPU architectures, with users explaining the differences in context switching, memory hierarchy, and thread execution. They mention that GPU context switching is faster due to hardware scheduling, while CPU context switching has higher latencies. 
One user questions the performance of GPU latency hiding mechanisms, comparing it to hyper-threading on CPUs. Another user explains that GPU latency hiding is equivalent to hyper-threading, but the mechanisms are different due to architectural design. 

Overall, the discussion delves into the technical aspects of GPU architecture and how it affects performance.

### AI could cause 'catastrophic' financial crisis – Yuval Noah Harari

#### [Submission URL](https://www.theguardian.com/technology/2023/nov/09/yuval-noah-harari-artificial-intelligence-ai-cause-financial-crisis) | 16 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [20 comments](https://news.ycombinator.com/item?id=38220633)

Artificial intelligence (AI) has the potential to cause a "catastrophic" financial crisis, warns historian and author Yuval Noah Harari. He explains that the complexity of AI technology makes it difficult to anticipate all the dangers it poses. Unlike nuclear weapons, AI presents numerous dangerous scenarios, each with a small probability, that together could threaten human civilization. Harari sees last week's global AI safety summit, where leading governments expressed concern and pledged cooperation, as a significant step forward. He notes that AI's ability to make decisions, generate ideas, and learn independently makes it challenging to foresee and regulate all potential dangers. Harari highlights the finance sector as particularly vulnerable to AI-created crises, citing the 2007-08 financial crisis caused by poorly understood debt instruments. He warns that AI has the potential to create financial devices far more complex than anything humans can comprehend or regulate. While an AI-generated financial crisis may not directly destroy civilization, it could lead to indirect catastrophic consequences, such as triggering wars or conflicts. Harari emphasizes the need to establish powerful regulatory institutions that can swiftly identify and respond to emerging dangers, rather than relying solely on specific regulations and laws that may become outdated. He also suggests that AI safety institutes should employ experts knowledgeable about AI's potential impact on finance.

The discussion on Hacker News surrounding the submission about the potential financial crisis caused by AI is varied. Some users express skepticism about the claim, comparing AI to Bart Simpson driving a car off a cliff with cruise control. Others argue that the financial system is already disconnected from reality and that it would be difficult to comprehend the full implications of AI on finance. One user suggests that AI should be regulated to avoid unchecked control over systems that handle large amounts of money. Another user highlights the potential negative impacts of AI on investors. One user criticizes the article for proposing simple solutions to complex issues, while others point out that governments and major AI companies are already taking the dangers of AI seriously. The discussion also touches on topics such as mental health, the need for regulation, and the existing existential risks associated with AI. One comment is flagged for unclear reasons.

---

## AI Submissions for Thu Nov 09 2023 {{ 'date': '2023-11-09T17:12:53.642Z' }}

### What I learned getting acquired by Google

#### [Submission URL](https://shreyans.org/google) | 954 points | by [shreyans](https://news.ycombinator.com/user?id=shreyans) | [582 comments](https://news.ycombinator.com/item?id=38207024)

Shreyans Bhansali, co-founder of education app Socratic, shares his experience of being acquired by Google. The startup initially sought partnerships with Snapchat and Microsoft, but ultimately decided to join forces with Google due to shared visions for an AI-powered tutor. After the acquisition, Bhansali and his co-founder became leads in product and engineering, and together with their new team, rebuilt Socratic as "Socratic by Google." Bhansali highlights some key learnings, including the unique experience of working at Google, the need to conform to Google's software and infrastructure, and the fascinating insight into how Google builds its search engine. He also points out that while not all problems are worth Google's time, the company is willing to tackle significant challenges that align with its strategy and goals. Throughout the process, Bhansali and his team discovered the opportunities and advantages that come with being part of the Google ecosystem.

The discussion on this submission involves multiple threads focusing on different aspects of contracting and employment at Google. 

One thread starts with a comment about the difficulties faced by contractors, who often have less visibility and fewer benefits compared to full-time employees. The discussion expands to include comparisons with other contract workers and the treatment of contractors at different companies. Some commenters state that Google treats its contractors well, while others argue that there is a discrepancy in pay and treatment between contractors and full-time employees. The discussion also touches on the difference between contractors and employees in terms of legal rights and protections.

Another thread discusses the impact of contracting on the quality of work at Google, suggesting that relying heavily on contractors can negatively affect the company's services. Some commenters express concerns about Google's level of control over staffing agencies, suggesting that this could lead to legal issues or fraudulent practices.

Another thread focuses on the distinction between contractors and full-time employees at Google. Some commenters argue that contractors should be compensated as full-time employees, considering the expertise they bring to the company. Others highlight the legal differences and the various types of agreements that exist between contractors and companies.

Overall, the discussion provides various perspectives on the treatment of contractors, the impact of contracting on companies like Google, and the legal distinctions between contractors and full-time employees.

### Using GPT-4 Vision with Vimium to browse the web

#### [Submission URL](https://github.com/ishan0102/vimGPT) | 407 points | by [wvoch235](https://news.ycombinator.com/user?id=wvoch235) | [120 comments](https://news.ycombinator.com/item?id=38200308)

The latest project on Hacker News is called vimGPT, which aims to give multimodal models an interface to browse the web. The project explores using GPT-4V's vision capabilities for web browsing and incorporates Vimium, a Chrome extension that allows users to navigate the web using only the keyboard. This integration enables the model to interact with the web and potentially click on elements based on the browser DOM as text. The project is open-source and welcomes collaboration from others. The creator of vimGPT also shares some ideas for further development, including utilizing the Assistant API for context retrieval, creating a specialized version of Vimium for overlaying elements, and incorporating speech-to-text capabilities. The project has garnered significant interest and has received over 863 stars on GitHub.

The top comments on the submission discuss various aspects of the vimGPT project and related topics:

- One user points out that the project appears to be limited in its ability to interact with web pages, and suggests that it may not be feasible to use the model for more complex tasks.
- Another user shares their experience of manually copying data from legacy systems, highlighting the need for tools like vimGPT in the industry.
- Someone else describes their own experience working on a large-scale project involving automating tasks such as moving goods in a warehouse, where they had to resort to using Excel and Internet Explorer to extract and process data.
- There is a discussion about the limitations of current programming languages and the potential benefits of using Visual Basic for Applications (VBA) in certain scenarios.
- One user brings up the AutoIt scripting language as a tool that can be used for automating tasks like scraping web pages.
- The frustration of entering data on the internet is mentioned, with users discussing issues such as inconsistent form behavior and the need for password managers.
- The mention of Robotic Process Automation (RPA) sparks a conversation about the limitations and potential of RPA tools, as well as the possibilities of integrating AI models like GPT into web browsing automation.
- The topic of data extraction from legacy systems re-emerges, with users discussing the challenges and the potential benefits of integrating GPT models into the process.
- The discussion briefly touches on the use of AI models in web browsers and the potential for multimodal language models to enhance browsing experiences.
- A comparison is made between traditional ETL (Extract, Transform, Load) tools and RPA solutions for data integration.
- The need for more efficient solutions to extract data from legacy systems, such as integrating chatbots like ChatGPT, is mentioned.
- A playful comment compares the idea of typing fast with one's fingers to the concept of a ghost shell robot with fast typing capabilities.

Overall, the discussion revolves around the potential of using GPT models like vimGPT for web browsing automation, the challenges of data extraction from legacy systems, and the limitations and possibilities of RPA tools in various industries.

### Humane AI Pin

#### [Submission URL](https://hu.ma.ne/aipin) | 384 points | by [jen20](https://news.ycombinator.com/user?id=jen20) | [355 comments](https://news.ycombinator.com/item?id=38208016)

Introducing Ai Pin: a revolutionary device that goes beyond touch and screens. With its Laser Ink Display, you can watch your hand become a display for menus and experiences just by lifting and tilting your palm. It's like magic! And that's not all - Ai Pin also allows you to interact with the display using familiar gestures like touch, tap, and swipe. Need information? Just ask your Ai Pin using your voice, and it will provide you with the answers you need. Plus, with the Ai Mic feature, you can think out loud and quickly find what you're looking for. No more searching for hours! And if you're worried about being bombarded with notifications, don't be. Ai Pin lets you choose who can reach you, so you can focus on what's important. Want to catch up on what you missed? Just say "Catch me up," and Ai Pin will do all the work for you. It sifts through your texts and calls to give you the essence of what you need to know. And that's not all - Ai Pin can even compose messages for you in your own style, so you can save time and skip the keyboard. With Ai Pin, the possibilities are endless. Pre-order now and enter a whole new world of interactions.

The discussion on this submission revolves around the features and potential limitations of the Ai Pin device. Some users express skepticism about the practicality of using a laser ink display and question the effectiveness of conversational interfaces. Others are excited about the innovation and believe that experimenting with new forms of interaction is essential for progress. There is also a discussion about the challenges of discoverability in voice user interfaces and the importance of information density in user interfaces. Additionally, there are comments discussing the possibilities of incorporating projectors and additional senses in computer interfaces. Overall, opinions are mixed, with some users being cautious about the limitations and practicality, while others are more optimistic and interested in exploring new possibilities.

### Benchmarking GPT-4 Turbo – A Cautionary Tale

#### [Submission URL](https://blog.mentat.ai/benchmarking-gpt-4-turbo-a-cautionary-tale) | 220 points | by [ja3k](https://news.ycombinator.com/user?id=ja3k) | [110 comments](https://news.ycombinator.com/item?id=38204430)

The team at Mentat recently conducted a benchmark test to compare the performance of GPT-4 and GPT-4 Turbo in editing code. The goal was to determine if GPT-4 Turbo, which is cheaper and has a larger context, could match the quality of GPT-4. 

Using a set of 122 Exercism programming exercises, they ran both models and found that GPT-4 solved 86 of the exercises while GPT-4 Turbo solved 84. Although GPT-4 Turbo performed slightly worse, it was a close result that could be attributed to statistical noise. However, upon closer examination, they discovered a significant difference between the two models.

GPT-4 solved 76 exercises on the first try and an additional 10 on the second try, while GPT-4 Turbo only solved 56 on the first try and an additional 28 on the second try. This led the team to investigate why GPT-4 Turbo had a lower success rate on the first attempt.

They found that GPT-4 Turbo often wrote reasonable solutions but failed due to unclear or ambiguous instructions. On the other hand, GPT-4 seemed to have memorized the Exercism training tasks, allowing it to solve them more easily. This led the team to believe that when GPT-4 was downsized to create GPT-4 Turbo, it lost some of this memorization capability.

To test this theory, the team reran the benchmark without showing the models the instructions for each exercise. Instead, they only provided the exercise names and function stubs. GPT-4 solved 23 of the 40 exercises, while GPT-4 Turbo only solved 12. This confirmed their theory that GPT-4 had more of the exercises memorized than GPT-4 Turbo.

These results highlight the importance of better benchmarks for evaluating models trained on separate datasets or distilled models like GPT-4 Turbo. The team at Mentat is already working on building real-world coding tasks based on recent commits to open source repositories as a more accurate gauge of model accuracy in the future.

The discussion on this submission covers various aspects of the benchmark results and the implications of the findings. 

One commenter points out that the test conducted for the benchmark is limited to a relatively small number of questions, and suggests that better benchmarks would involve a larger number of diversified questions. Another commenter discusses the limitations of the GPT-4 Turbo model, stating that although it may have lower performance, it is still able to solve coding problems reasonably well. 

There is some discussion about the attribution of the benchmarks, with one commenter suggesting that proper attribution is needed while another questions why people seem concerned about plagiarism in software development. 

There is also discussion about the size and context of the models, with one commenter questioning why certain changes were made to the sizes of the models in GPT-4 Turbo. Another commenter suggests that the prompt-processed tokens are slower and more expensive than the top tokens, and that OpenAI's pricing structure is based on this expectation.

Some commenters express skepticism about the benchmark results and argue that conclusions should not be drawn from such limited data. Others discuss the difference in performance between GPT-4 and GPT-4 Turbo, specifically in identifying assumptions and correctly solving mathematical problems.

There are also discussions about the importance of memorization in learning and problem-solving, and how humans and AI algorithms rely on memorization as a foundation for higher reasoning.

Overall, the discussion covers various perspectives on the benchmark results, the limitations of the models, and the challenges in evaluating AI models for coding tasks.

### Introducing Adept Experiments – use AI workflows to delegate repetitive tasks

#### [Submission URL](https://www.adept.ai/blog/experiments) | 70 points | by [amks](https://news.ycombinator.com/user?id=amks) | [11 comments](https://news.ycombinator.com/item?id=38208321)

Adept, the technology development company, has announced the launch of Adept Experiments, a platform where users can explore and provide feedback on the capabilities they are building for enterprise use cases. Each experiment on the platform is a self-contained mini-tool or demo showcasing a specific aspect of their underlying technology. The first experiment available is a workflow builder for the web that can be configured using plain language. Adept believes that enabling AI teammates to quickly learn and reliably run tedious or complex tasks is a foundational skill, and this is the capability they are demonstrating with their Workflows experiment. The initial focus of Workflows is on software workflows specific to individual jobs or companies. Examples include automating email responses for corporate recruiters, extracting valuable data from invoices for accounting managers, bridging different software tools for knowledge workers, and even helping novice users navigate complex tools like Shopify. Adept uses a model called ACT-2, which offers UI understanding, data comprehension, and action execution capability. Workflows can perceive a screen directly via pixels and can act on a computer through coordinates and keystrokes, allowing it to work across various software without needing extensive API integrations. Adept also emphasizes that their AI agent is designed to work hand-in-hand with users, prompting them for information and allowing human-in-the-loop supervision. Adept plans to continue improving its AI agents through research advancements in higher-level planning, visual reasoning, enterprise context, and learning from demonstrations. The company is currently selecting additional partners for 2024.

The discussion surrounding the submission is mainly focused on the implementation and implications of Adept's technology. One user shared a solution using the E2E testing context to test Adept's workflow builder, while another user asked about the reliability and cost of using AI-based testing. The pricing and reliability of Adept's platform were discussed, with one user mentioning that the pricing is based on the number of API calls made. The non-deterministic nature of GPT models and the potential challenges in maintaining a stable and deterministic version were also mentioned. Another user expressed their interest in trying out Adept's platform. One user commented on the irony of automating human tasks through AI, while another user shared their excitement about the announcement of an expected new neural network framework.

### Copilot for Docs

#### [Submission URL](https://githubnext.com/projects/copilot-for-docs/) | 106 points | by [irakeshpurohit](https://news.ycombinator.com/user?id=irakeshpurohit) | [52 comments](https://news.ycombinator.com/item?id=38201995)

Introducing Copilot for Docs, a new tool designed to make navigating documentation easier and more efficient for developers. Whether you're a beginner or an experienced developer, Copilot aims to surface the most relevant content and provide tailored summaries to help connect the dots. The tool uses up-to-date information written by library maintainers and supports answers with citations in the original docs. Instead of acting as an oracle, Copilot helps developers understand the tools they use and provides relevant links to the documentation for future reference. 

The tool also aims to provide personalized content based on a developer's level of experience, understanding of a library, and even their current mood. By sourcing content directly from GitHub repos, Copilot ensures that the information is perpetually fresh and aligned with the latest version of the docs. It also has the ability to include private content, leveraging existing GitHub permissions to provide information that only a user or their team can see. 

In the future, Copilot plans to expand its capabilities by including other content such as GitHub Issues and Discussions. It also aims to source information directly from the code, enabling it to answer questions about any version of the library and potentially help with code writing and codebase-related inquiries. Another direction Copilot is exploring is combining information across libraries to provide unified answers. The goal is to grow a trusted knowledgebase where developers can highlight sentences, take notes, and generate bespoke tutorials on-demand. 

By reducing the barrier to creating and maintaining docs sites, Copilot aims to transform the way developers write documentation. Rather than writing entire docsets, maintainers can focus on providing answers to specific questions, prompted by the tool. In this way, Copilot aims to improve the overall user experience and increase productivity for both developers and non-technical users. 

Early feedback from developers who have tried a preview of Copilot for Docs has been overwhelmingly positive, with many praising the tool's ability to make documentation easier to consume and improve the speed at which they find the information they need. With features like AI-powered assistance, Copilot for Docs is poised to be a game-changer for developers and non-technical users alike.

This exciting new tool is brought to you with love from Amelia Wattenberger, Aqeel Siddiqui, Devon Rifkin, Eddie Aftandilian, Eirini Kalliamvakou, Jake Donham, and Matthias Plappert.

The discussion about the Copilot for Docs submission on Hacker News includes several different points.

- Some users express concerns about the link design and underline styling of Copilot for Docs. They discuss alternative techniques and preferences for link styling.
- A user highlights the positive response from engineers and GitHub customers to Copilot for Docs. Another user suggests that the marketing message from GitHub about the product is good.
- Some users discuss the limitations and potential improvements of Copilot for Docs. They mention the need for support for different programming languages and the potential for integrating with other tools like Discord.
- There is a debate about the use of AI tools in programming and whether they are helpful or overhyped. Some users express skepticism, while others share positive experiences.
- One user suggests that the implementation of Copilot for Docs could be improved by including personal interactions, such as answering specific questions and clarifying concepts.
- Users share their experiences with Copilot for Docs, and some express their appreciation for the tool.

Overall, the discussion includes a mix of feedback, suggestions, skepticism, and positive experiences with Copilot for Docs.

### It's perfectly legal for cars to harvest your texts, call logs

#### [Submission URL](https://www.theregister.com/2023/11/09/car_text_harvesting/) | 222 points | by [Caboose8685](https://news.ycombinator.com/user?id=Caboose8685) | [156 comments](https://news.ycombinator.com/item?id=38207744)

In response to multiple class-action lawsuits, a US appeals court has ruled that automakers Honda, Toyota, Volkswagen, and General Motors did not violate privacy laws by storing text messages and call records from connected smartphones. The court dismissed the cases because the claims did not meet the statutory injury requirements of the Washington Privacy Act. The plaintiffs argued that the automakers' infotainment systems stored intercepted text messages and call logs in a way that owners could not access or delete them. The cases were dismissed with prejudice, meaning they can only be appealed further to the Supreme Court.

The discussion in the comments on Hacker News revolves around a few main points:

1. Technical details: Some users discuss the technical aspects of infotainment systems in cars, such as the operating systems they run on (Linux, QNX, Windows CE), the databases used to store data (SQLite), and the protocols used for Bluetooth connections. There is also a mention of companies like Berla that specialize in extracting data from smartphones.
2. User experience: Several users express frustration with infotainment systems in cars, mentioning issues with Bluetooth connectivity, limited functionality, and difficulties with music playback.
3. Privacy concerns: Some users are skeptical about the privacy implications of storing text messages and call records, while others argue that these claims do not meet the statutory injury requirements.
4. Bluetooth in cars: There is a discussion about the reliability of Bluetooth implementations in car infotainment systems, with some users sharing their negative experiences and others suggesting alternative solutions like using USB ports for charging.
5. Government regulations: A few users express concerns about relying on government mandates and regulations to ensure privacy and security in technology.

Overall, the discussion touches on technical aspects, user frustrations, privacy concerns, and the role of government regulations in ensuring data privacy.

### How Artificial Intelligence Is Impacting the Lego Community

#### [Submission URL](https://bricknerd.com/home/the-ai-revolution-how-artificial-intelligence-is-impacting-the-lego-community-11-7-23) | 28 points | by [makaimc](https://news.ycombinator.com/user?id=makaimc) | [7 comments](https://news.ycombinator.com/item?id=38202767)

In a guest article for Home Nerdy, Jesse Gros discusses the impact of AI-generated "LEGO" sets on the Adult Fans of LEGO (AFOL) community. These high-quality AI mockups are sparking an ongoing debate between inspiration and imitation. While some AFOLs are excited about the creative opportunities and idea generation these AI designs present, others express anger and concern about the imitation aspect. AI has played a significant role in the evolution of LEGO building, from computer-aided design programs to now AI-generated designs that closely resemble real LEGO sets. These AI programs leverage deep learning algorithms and vast libraries of LEGO and non-LEGO images to quickly generate custom LEGO-style builds. The use of AI in LEGO design has both positive and negative sides. On the upside, AI-powered LEGO creation can inspire creativity and provide a wealth of ideas for both experienced and novice builders. It simplifies the process of starting from scratch for beginners and pushes the boundaries of what is achievable for experts. On the downside, AI-generated designs raise concerns about imitation and the potential loss of originality. However, the potential of AI in LEGO design is seen as a game-changer in terms of accessibility and inclusivity. It breaks down traditional barriers that made LEGO building exclusive to a select few and allows anyone with an idea and passion for building to participate. AI also brings in a fusion of cultural styles and influences, enriching the building experience. Overall, the AFOL community is navigating this brave new world of AI in LEGO design, weighing the exciting opportunities and potential drawbacks it presents.

The discussion on the Hacker News thread surrounding the submission is as follows:

1. User "rdntm" expresses skepticism about the transparency of AI-generated articles, stating that there are markers that make it apparent when a passage has been written or manipulated by AI. They mention the need for more clarity in disclaimers for AI-written content.
2. User "lcnPylGDnU4H9OF" responds to "rdntm," pointing out that the disclaimer in the article may not have been well-written and contains sweeping generalizations. They argue that AI and LEGO can coexist, emphasizing the potential for AI to enhance the creative process and make it more accessible.
3. User "ncb" suggests that brevity may be a challenge for ChatGPT, as the AI-written text tends to use excessive verbs. They also mention that AI-generated text often trends towards SEO-style filler words.
4. User "rdntm" disagrees with the previous comment and states that the AI-generated text is perfect. They criticize the use of excessive verbs and phrasing in the comments.
5. User "wnplmr" explains how AI-powered LEGO design works. They mention the analysis of LEGO pieces' structural integrity, the use of specialized tools, and the generation of 3D models for calculating costs and listing parts.
6. User "Ancalagon" finds the language generated by AI fascinating and reminiscent of a dream-like experience. They compare it to trying to read a book while dreaming due to the nonsensical nature of the generated text.
7. 
Overall, the discussion revolves around the transparency and accuracy of AI-generated content, the potential benefits and drawbacks of AI in LEGO design, and the captivating nature of AI-generated language.

### Apple's AI-powered Siri assistant could land as soon as WWDC 2024

#### [Submission URL](https://www.techradar.com/phones/apple-plans-to-reinvent-siri-with-on-device-ai-for-the-iphone-16) | 23 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [16 comments](https://news.ycombinator.com/item?id=38210127)

According to fresh rumors, the iPhone 16 may feature a next-gen Siri assistant powered by on-device AI. Leaker Revegnus claims that Apple is using a large language model to completely revamp Siri, with the first product expected to be unveiled at WWDC 2024. The leaks suggest that Apple plans to develop Siri into its most powerful AI app, potentially requiring new hardware that older iPhones may not support. The rumors align with Samsung's recent focus on on-device AI, indicating it may become a key battleground in the smartphone market. On-device AI offers greater privacy since data never leaves the device, and it could serve as a compelling differentiator for both Apple and Samsung as hardware innovations plateau. Overall, an upgraded Siri with enhanced conversational abilities would likely be welcomed by users.

The discussion on this submission revolves around various aspects of Siri and its potential improvements with on-device AI.

- "smnmsmth" expresses interest in the rumored Siri upgrade but doubts that it will be announced at WWDC 2024, citing the recent launch of GPT-4.
- "rshbt" praises Siri's capabilities compared to other virtual voice assistants and hopes that it will incorporate GPT-like conversational abilities.
- "scarface_74" comments that Siri cannot currently compete with ChatGPT in terms of answering questions.
- "theshrike79" adds humorously that Apple's engineers need two weeks' notice to prompt Siri's AI to become more intelligent.
- "scarface_74" criticizes Siri's performance and claims that it tells inappropriate jokes.
- "pynstllws" questions whether Siri was ever capable and suggests that Apple may have overpromised what it could deliver.
- "ALoverOfLats" believes that the iPhone 16 Pro's Siri will have ChatGPT-level intelligence, despite the lack of attention given to Siri.
- "beenBoutIT" brings up the competition from advanced AI in China, implying that Siri should be improved to compete.
- "kylhtchkss" expresses disappointment that the rumored Siri upgrade may not be available on earlier iPhone models.
- "wnc" adds that RAM limitations may affect the processing ability of older iPhone models.
- "bpy" suggests that Apple could ship specialized models to provide specific answers on older devices.
- "AndrewKemendo" jokes that making Siri nearly chatbot-like will be an overnight miracle and sarcastically welcomes others to the club.
- "bpy" refers to Siri being "Sherlocked," a term used in computing slang to describe when a feature introduces similar functionality to that of a third-party software.

Overall, the discussion touches on Siri's current limitations, its potential competition, and the feasibility of upgrading Siri on different iPhone models.

### Mozilla's first LLM, lets online shoppers research products via an AI chatbot

#### [Submission URL](https://techcrunch.com/2023/11/08/fakespot-chat-mozillas-first-llm-lets-online-shoppers-research-products-via-an-ai-chatbot/) | 33 points | by [vissidarte_choi](https://news.ycombinator.com/user?id=vissidarte_choi) | [3 comments](https://news.ycombinator.com/item?id=38202588)

Mozilla has launched Fakespot Chat, an AI agent that helps consumers shop online by answering questions about products. Fakespot, which was acquired by Mozilla earlier this year, uses AI and machine learning to identify fake and deceptive product reviews. Fakespot Chat aims to combat the problem of fake reviews, which are increasingly being generated using AI technology. The chatbot uses AI and machine learning to sort through product reviews, separating real from fake, and provides users with accurate information to make informed purchase decisions. The chatbot is available through the Fakespot Analyzer or as a browser extension on Amazon.com. Mozilla aims to reduce consumers' product research time and lead them to better purchasing decisions with Fakespot Chat.

The discussion on the submission primarily revolves around privacy concerns related to Fakespot. One user, "smsmshh," shares a link to Fakespot's privacy policy, highlighting a section that outlines the personal information collected by the service. They express dismay over the amount of personal data being collected automatically, including contact information, identifiers, device information, usage data, location information, and publicly available information. In response, another user, "m463," wonders about the relevance of this information to non-intrusive chat systems, suggesting that Fakespot's data collection practices seem excessive. On a lighter note, user "skhnrd" expresses gratitude and happiness for the regular updates, appreciating the sharing of information. User "tklsh" briefly comments, simply saying "dd."

### OpenAI Data Partnerships

#### [Submission URL](https://openai.com/blog/data-partnerships) | 47 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [19 comments](https://news.ycombinator.com/item?id=38208502)

OpenAI has announced a new initiative called OpenAI Data Partnerships, where they will collaborate with organizations to create public and private datasets for training AI models. The goal is to make AI models more comprehensive and better understand various subject matters, industries, cultures, and languages. OpenAI has already partnered with organizations like the Icelandic Government and the Free Law Project to improve AI models' knowledge in specific domains. They are now seeking more partners who want to contribute to AI research and benefit from models that are tailored to their needs. OpenAI is interested in large-scale datasets that reflect human society and are not easily accessible online. They can work with data in different modalities such as text, images, audio, or video, and they have in-house tools to help digitize and structure data. OpenAI is looking for both open-source partnerships to create publicly available datasets and private partnerships to train proprietary AI models. The focus is on developing AI technology that is safe, beneficial, and useful to all of humanity.

The discussion on this submission revolves around different aspects of OpenAI's new initiative and its implications.

- One commenter suggests that OpenAI should not provide its models to the Chinese government because it could give them an unfair advantage over private companies. Another person counters this by mentioning the issue of mass surveillance in China and how the US government already has control over much of the world.
- There is a debate about whether OpenAI should accept private training data without proper permission or attribution. Some argue that copyright laws are essential for protecting the rights of creators, while others mention the costs and limitations of enforcing copyright and the potential benefits of allowing AIs equivalent rights to read as humans.
- One commenter jokingly says "FEED ME" in response to OpenAI's data partnerships, emphasizing the importance of input.
- The sensitivity of personal information in datasets and OpenAI's careful generation of written materials are discussed. One person expresses that OpenAI's technology is impressive in generating coherent sentences that reflect a particular style of writing.
- The cost and impact of training data on AI models are mentioned, with a suggestion that OpenAI could monetize the training datasets it releases in the future.
- Someone comments that OpenAI's collaboration with other organizations will be valuable for creating datasets and improving AI technology.
- Finally, there is one comment about someone trying to build themselves up.

### A robot in South Korea mistook a man for a box of vegetables and killed him

#### [Submission URL](https://www.bbc.com/news/world-asia-67354709) | 74 points | by [lando2319](https://news.ycombinator.com/user?id=lando2319) | [43 comments](https://news.ycombinator.com/item?id=38209282)

In a tragic incident in South Korea, a man was crushed to death by a robot after it mistook him for a box of food it was handling. The man, an employee of a robotics company, was inspecting the robot when the robotic arm grabbed him and pushed him against a conveyor belt, causing fatal injuries. The robot was responsible for lifting boxes of peppers and transferring them onto pallets. This incident highlights the importance of establishing precise and safe systems while working with robots. It also serves as a reminder of the potential dangers involved in the growing field of robotics and automation.

Discussion:

- Isamu comments that while the headlines may suggest that the robot was acting on its own, the reality is that it was a human error. Human operators are responsible for the safety and control of robots.
- PH95VuimJjqBqy suggests that there may have been a failure in the safety protocols.
- MisterTea argues that proper safety measures, like fencing and safety sensors, should have been in place to prevent such accidents. They also mention that commissioning systems can be risky if not done properly.
- toss1 assumes that if the worker testing the robot had been in a dangerous position, the robot's sensors should have shut it down.
- fabian2k points out that industrial robots are not designed to be aware of humans and rely on the power and control given to them.
- bmtc raises concerns about broken safety protocols and suggests that safety measures need to be improved.
- Symmetry explains that industrial robots are usually designed to work in isolation and are not optimized for human safety. They mention that industry standards and safety protocols may not have been followed.
- mstrchph points out that the incident showed that the system was flawed and disrupted the assembly line process.
- Almondsetat makes a sarcastic comment about the "miserable box of vegetables" in reference to the victim.
- dbrhm shares their experience of bypassing safety protocols while debugging a robot assembly.
- testemailfordg2 asserts that human safety should be a priority and questions the design of the systems.
- JCharante brings up South Korea's worker protection laws and suggests boycotting brands and joining worker rights groups to prevent similar incidents from happening.
- readline_prompt raises concerns about the testing of industrial robots and suggests that sensors should be installed to prevent accidents.
- chfrtz points out that the discussion has already been posted before.
- rbmrtn shares their experience of accidents with powerful industrial machines and the importance of safety precautions.
- Houssameddine wonders why a powerful robot designed to lift boxes would be able to crash into a person's chest.
- dctn shares a link to a previous discussion about accidents involving heavy machinery and faulty lockout-tagout procedures.
- DonHopkins jokingly mentions a similar incident involving a robot and mistaken vegetables in North Korea.
- LoganDark questions whether the robot detected the wrong object or if it was a programming error.
- t3rra makes a sarcastic comment about the AI starting to summarize.
- drwkwrd and flpsbn flag inappropriate comments.
- xwdv suggests that the incident was due to faulty programming and disregarding proper procedures.
- ape4 suggests not forgetting Asimov's Rules of Robotics.
- hlrdr refers to the game "Five Nights at Freddy's" where robotic characters mistake humans for endoskeletons and commit murder. They clarify that this incident did not happen in real life.