import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Thu Oct 12 2023 {{ 'date': '2023-10-12T17:10:51.678Z' }}

### MS Paint Cocreator, a new AI-powered experience powered by DALL-E

#### [Submission URL](https://blogs.windows.com/windows-insider/2023/09/27/paint-app-update-introducing-paint-cocreator-begins-rolling-out-to-windows-insiders/) | 105 points | by [tuanx5](https://news.ycombinator.com/user?id=tuanx5) | [31 comments](https://news.ycombinator.com/item?id=37862924)

Today, Microsoft announced an update to the Paint app for Windows 11, introducing a new feature called Paint Cocreator. This AI-powered experience, powered by DALL-E, allows users to create artwork in Paint by simply describing what they want to create. Users can also select an art style, and Paint Cocreator will generate three variations of artwork for them to choose from. Microsoft is rolling out access to Paint Cocreator slowly, with users needing to join a waitlist to access the feature. The company is committed to responsible AI practices and has implemented content filtering and safeguards to prevent the generation of harmful or inappropriate images. Paint Cocreator is currently available in preview to users in English in select regions. Feedback on the update can be submitted through the Feedback Hub.

The discussion on Hacker News about Microsoft's update to the Paint app for Windows 11, introducing the AI-powered Paint Cocreator feature, covers various topics. 

One commenter compares Microsoft's integration of DALL-E into Paint to Adobe's use of AI in Photoshop, highlighting features such as vector models, template generation, and distraction removal. They mention that both companies are advanced in integrating AI into their tools.

The conversation then shifts to copyright concerns. One user raises the question of whether Adobe's generation of AI-trained commercial stock photos could be a copyright risk. Another user points out that copyright training data is non-copyrightable, and major copyright protection efforts may require legal reform to address the challenges posed by AI-generated content.

The pricing model of Paint Cocreator is also discussed. A commenter shares pricing details from a linked article, comparing it to Adobe's pricing for a similar feature called Firefly. They suggest that Paint Cocreator might be cheaper. Another user explains that the link provided is misleading and discusses OpenAI's DALL-E, which is expected to be integrated into Paint in 2022. They clarify that pricing details for Paint Cocreator are not yet known.

There is also mention of the removal of certain features from Paint, with one user expressing disappointment that certain intelligence seems to have been removed from the app.

The topic of content filtering and safeguards in Paint Cocreator comes up. One user suggests that if the current version of DALL-E 3 is used for filtering, triggering warnings and non-landscape filters may not be adequate.

Some users make light-hearted remarks, such as one person referring to previous AI tools like Clippy and another jokingly suggesting that Paint Cocreator could generate threatening letters.

There are brief comments on market implications and the humorous juxtaposition of AI tools constantly censoring wrong things.

Other miscellaneous comments touch on specific versions of DALL-E, the transition of Paint over Windows versions, preview notifications, the humorous aspect of certain juxtaposed features, and Microsoft emphasizing the simplicity of Paint.

### Home Assistant Year of the Voice â€“ Chapter 4: Wake Words

#### [Submission URL](https://www.home-assistant.io/blog/2023/10/12/year-of-the-voice-chapter-4-wakewords/) | 40 points | by [M2Ys4U](https://news.ycombinator.com/user?id=M2Ys4U) | [5 comments](https://news.ycombinator.com/item?id=37862746)

Home Assistant, an open-source home automation platform, has announced the release of wake word support as part of their Year of the Voice initiative. In the fourth chapter of their journey, Home Assistant introduces wake word processing, allowing users to trigger voice commands by saying specific phrases like "Hey Google" or "Alexa." This feature is made possible through the open-source project openWakeWord, developed by David Scripka. Unlike traditional voice assistants that rely on specific hardware, Home Assistant's wake word detection is done within the platform itself, making it accessible to any device capable of streaming audio. While this approach has its limitations, such as varying audio quality and resource usage within Home Assistant, it offers flexibility and the ability to run wake word detection on external servers. Moreover, openWakeWord provides pre-trained wake word models, including Home Assistant's "Okay Nabu" model, and supports English wake words. Users can also create their own wake words without the need for real voice samples using the unique techniques of Piper, the platform's text-to-speech system. This latest addition to Home Assistant's voice capabilities brings them one step closer to their goal of enabling users to control their smart homes through voice commands in their own language.

The discussion surrounding the Home Assistant's release of wake word support is mostly positive. One user mentions that they use Home Assistant every day and voice control is a necessary feature. They acknowledge that voice control has its limitations but highlights the convenience it provides, particularly in scenarios like switching lights or opening garage doors. Another user mentions using the Rhasspy project with Alexa and finds voice control helpful for quick tasks such as checking the weather or playing music. They also mention that it is convenient for interacting with the house, especially when they have their hands full or are carrying something. Another user suggests adding an additional interface to control the home from Windows, asking about the most valuable information that can be extracted, like flickering switch activities or weather updates. Finally, a user mentions using voice control with kids in the house and notes how it simplifies interactions, such as turning lights on or off or carrying sleeping children without needing to move. They also mention using voice control for tasks like changing colors or playing specific songs. Overall, the discussion emphasizes the convenience and usefulness of voice control in home automation.

### EU "Chat Control" and Mandatory Client Side Scanning

#### [Submission URL](https://berthub.eu/articles/posts/client-side-scanning-dutch-parliament/) | 253 points | by [ahubert](https://news.ycombinator.com/user?id=ahubert) | [95 comments](https://news.ycombinator.com/item?id=37859402)

Yesterday, the Dutch parliament held a hearing on the EU's "Chatcontrol" proposal, specifically focusing on client-side scanning. The Dutch government has previously passed motions against supporting this proposal, but it has declared that it will ignore those motions. The hearing comes at a crucial time as EU member states will soon vote on how to proceed with the proposal. During the hearing, an individual involved in the subject for fifteen years spoke about their experience supplying software to the Dutch police and their knowledge of proportionality and law. They highlighted that the proposal would involve AI scanning communications, including photos and videos in messaging apps, with the aim of detecting child sexual abuse material (CSAM). However, they questioned the effectiveness and accuracy of the AI in determining the nature of the content and expressed concerns about the potential for unjust investigations. They argued that while the goal is to protect children, a flawed system could lead to numerous wrongful investigations. They also raised concerns about the storage of data related to these investigations, as well as the scale of the proposal, which would apply to 500 million Europeans. The speaker emphasized that approving this proposal would be a significant departure from previous practices and called for careful consideration before implementing such sweeping measures.

The discussion on this submission covers a range of perspectives. Some commenters express concerns about the potential for abuse and the infringement on privacy rights that could result from client-side scanning. They argue that the proposal might not effectively address the issue of child sexual abuse material (CSAM) and could lead to unjust investigations. Others highlight the need to protect children and argue that measures like client-side scanning are necessary. Some commenters express skepticism about the proposal, suggesting that it may not be practical or that it could lead to overreach and government control. There is also a discussion about the role of technology companies and the responsibility of governments in addressing the issue of CSAM.

### The AI research job market

#### [Submission URL](https://www.interconnects.ai/p/ai-research-job-market) | 202 points | by [sebg](https://news.ycombinator.com/user?id=sebg) | [180 comments](https://news.ycombinator.com/item?id=37857521)

The AI research job market is experiencing a shakeup, with the demand for talented researchers outweighing the available supply. The investment in AI technology is driving this market shift, with jobs in certain AI fields plentiful while others remain stagnant. Companies are struggling to find the right people to fill their AI research positions, causing stress and uncertainty in the job search process. The movements of researchers are closely watched as they indicate which companies are at the forefront of AI innovation. The compensation for AI researchers is also skyrocketing, with top researchers being offered salaries of up to $1 million. However, the high turnover rate and attrition in the industry are causing instability, and many researchers are uncertain about where they want to work. Despite the challenges, this influx of talent is expected to push the boundaries of AI research and help unlock the full potential of technologies like the Transformer architecture.

The discussion on this submission includes various perspectives on the AI research job market and how to succeed in the industry. Some commenters discuss the implementation of AI technologies and the importance of flexible models like Transformer architectures. Others delve into technical aspects of AI, such as working with different data formats and the representation of information. 

There is a debate about the significance of certifications in the AI field, with some suggesting that practical projects and demonstrations of skills are more important than formal certifications. There are also discussions about the challenges of job interviews in the AI field, including coding tests and evaluating relevant experience. 

One commenter mentions the need to stay updated on AI trends and suggests creating an environment for continuous learning. Another commenter notes the unique nature of the AI field compared to previous cycles of hype, particularly in terms of the potential benefits and the need for significant computational resources.

### No Fakes Act wants to protect actors and singers from unauthorized AI replicas

#### [Submission URL](https://www.theverge.com/2023/10/12/23914915/ai-replicas-likeness-law-no-fakes-copyright) | 62 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [83 comments](https://news.ycombinator.com/item?id=37863309)

A bipartisan bill called the No Fakes Act aims to protect actors, singers, and other performers from unauthorized digital replicas of their faces or voices. The bill, sponsored by Senators Chris Coons, Marsha Blackburn, Amy Klobuchar, and Thom Tillis, establishes federal rules around the use of a person's likeness. It prohibits the creation of a digital replica without the individual's consent, unless it is for specific purposes like news, sports broadcasts, or documentaries. The rights would apply throughout a person's lifetime and for 70 years after their death. The bill also includes exceptions for parodies, satire, and criticism, as well as commercial activities related to news, documentaries, or parodies. 
However, some believe the bill merely dresses up existing laws and doesn't offer additional protections. Jeremy Elman, a partner at a law firm, said it could potentially conflict with existing copyright and right of publicity laws. The No Fakes Act seeks to address the growing concern about the use of generative AI tools that mimic famous voices or create photos of famous individuals. The bill aims to federalize likeness laws, which currently vary from state to state. The Recording Industry Association of America (RIAA) and the Human Artistry Campaign have expressed support for the bill, citing the infringement of rights by generative AI models. The bill comes in response to the increasing use of AI duplicates in various industries, including Hollywood and the music industry.

The discussion surrounding the No Fakes Act on Hacker News touched on various aspects of the bill and its implications. Some commenters expressed concerns about the bill's effectiveness, stating that it may not provide additional protections beyond existing laws. They argued that AI-generated replicas of famous individuals, such as singers and actors, could still be created and used legally under certain circumstances. Others pointed out that there is a demand for authenticity in the entertainment industry and that AI-generated performers cannot fully replace human performers. The discussion also delved into the topic of labor rights in Hollywood, with some commenters noting that AI advancements could potentially impact job opportunities for actors and writers. Additionally, there was a debate about the future of virtual actors and the potential disruption of traditional art forms by AI. Some commenters expressed skepticism about the significant impact of AI on the arts, while others highlighted the possibilities for innovation and disruption in the industry.

---

## AI Submissions for Wed Oct 11 2023 {{ 'date': '2023-10-11T17:10:20.029Z' }}

### The deep link equating math proofs and computer programs

#### [Submission URL](https://www.quantamagazine.org/the-deep-link-equating-math-proofs-and-computer-programs-20231011/) | 238 points | by [digital55](https://news.ycombinator.com/user?id=digital55) | [142 comments](https://news.ycombinator.com/item?id=37845195)

The Curry-Howard correspondence, also known as the Curry-Howard isomorphism, is a profound revelation that links mathematical proofs and computer programs. It posits that concepts from computer science (types and programs) are equivalent to propositions and proofs from logic. This means that writing a program is not just "coding," but an act of proving a theorem. The correspondence was independently discovered by Haskell Curry and William Alvin Howard in the 1930s and 1960s, respectively. They noticed the similarity between functions in mathematics and the implication relationship in logic. When a computer program runs, each line is evaluated to yield a single output, much like simplifying a logical proof. This correspondence formalizes programming and allows for mathematical reasoning about the correctness of programs.

The discussion on this submission covers a range of topics related to formal verification, programming languages, and the Curry-Howard correspondence.

- Some users recommend studying formal methods and formal verification languages to gain a deeper understanding of proof-based programming. They suggest resources such as Coq, Isabelle, and Software Foundations.
- Others express the difficulty in understanding formal methods and suggest that it is a challenging field that requires a strong mathematical background.
- One user shares a link to a book on Programming Language Types by Benjamin Pierce.
- There is a discussion about dependent types and Homotopy Type Theory, with some users recommending Idris and Agda as programming languages that implement these concepts effectively.
- A user mentions Lamport's work on Computation State Machines and how it relates to the mathematics of programming.
- The importance of composability and correctness in formal programming is highlighted, with some users emphasizing the need for business stakeholders to appreciate the value of mathematical reasoning in software development.

Overall, the discussion is quite technical and focused on the intersection of mathematics and programming.

### Weâ€™ll call it AI to sell it, machine learning to build it

#### [Submission URL](https://theaiunderwriter.substack.com/p/well-call-it-ai-to-sell-it-machine) | 309 points | by [participant1138](https://news.ycombinator.com/user?id=participant1138) | [224 comments](https://news.ycombinator.com/item?id=37843595)

In his latest blog post, "We'll call it AI to Sell it, Machine Learning to Build it," Otakar G. Hubschmann shines a light on the misleading use of the term "AI" in the sales pitches of various products. He cautions readers against falling for buzzwords and emphasizes the importance of asking the right questions to determine the credibility of vendors claiming to offer AI solutions. Hubschmann suggests inquiring about the specific machine learning techniques involved, the algorithms behind the AI, the model's objective function, metrics used to measure efficacy, the involvement of humans in the process, and whether the product is simply a wrapper around a GPT API. By being aware and informed, readers can avoid being fooled by AI products that don't deliver as promised.

The top stories on Hacker News today include a blog post discussing the misleading use of the term "AI" in sales pitches, cautioning readers to ask the right questions to determine the credibility of vendors offering AI solutions. The comments on the post include discussions about the nature of AI and its current limitations, the use of AI in decision-making and problem-solving, and comparisons to historical technological advancements and religious beliefs. Other discussions touch on the impact of AI on various industries, the longevity of AI companies, and the AI Effect where technology once labeled "AI" is often no longer considered as such.

### AVX10/128 is a silly idea

#### [Submission URL](https://chipsandcheese.com/2023/10/11/avx10-128-is-a-silly-idea-and-should-be-completely-removed-from-the-specification/) | 127 points | by [picture](https://news.ycombinator.com/user?id=picture) | [90 comments](https://news.ycombinator.com/item?id=37851029)

Intel has announced a new specification called AVX10, which aims to consolidate the various AVX-512 extensions into a single, easy-to-target specification. AVX10 is designed to bring together all the capabilities of AVX-512 into smaller implementations for consumer, micro-edge, and embedded devices that don't require the 32 512-bit registers used by AVX-512. The specification introduces a version modifier, denoted by ".N", which allows for incremental updates, and a reference to the vector register implementation size, denoted by "/M". The AVX10 specification mandates that all implementations have 32 registers, but the width of these registers depends on the given "/M". For example, AVX10/256 would have the same capabilities as AVX10/512, but with 256-bit wide registers. This means that existing code written for AVX-512 with 256-bit registers should be able to run fine with only a recompile. The AVX10 specification also includes features such as support for IEEE-754 half precision floating points and brain floating point 16 (BF16). Overall, AVX10 aims to simplify and consolidate the AVX-512 landscape, making it easier to target different devices with different register requirements.

The discussion on Hacker News is primarily focused on the implications and potential drawbacks of Intel's AVX10 specification. 

One commenter points out that AVX-512 indirectly causes performance issues and suggests that Intel could have informed OS writers earlier to avoid these problems. Another commenter agrees and mentions that AVX-256 has little to no performance cost.

There is also a discussion about the efficiency and benefits of AVX-512. Some believe that the larger register size of AVX-512 is not worth the increased complexity and instead prefer smaller register options. Others argue that AVX-512 can be beneficial for certain applications and that AVX-256 is not a sufficient substitute.

There are mentions of Microsoft and Intel's hardware trapping unsupported instructions, which leads to delays in instruction execution and decreases performance. Some commenters suggest that better coordination between OS schedulers and processors is needed to avoid these issues.

The discussion also touches on the challenges of implementing AVX512 in software and the importance of following the correct specifications to avoid crashes or illegal instruction errors.

There are mentions of other technologies like Intel Knights Landing and AMX, as well as the challenges and benefits of writing high-performance kernels in assembly code.

Some commenters discuss the intricacies of writing code for AVX-512 and the differences in ABI conventions between platforms. There is speculation about the difficulties in JIT generating code for different processors and how OS context switches can impact performance.

Overall, the discussion explores the various advantages, disadvantages, and implementation challenges of AVX-512 and its potential impact on different devices and software.

### Google's AI stoplight program is now calming traffic in a dozen cities worldwide

#### [Submission URL](https://www.engadget.com/google-ai-stoplight-program-project-green-light-sustainability-traffic-110015328.html) | 27 points | by [gardenfelder](https://news.ycombinator.com/user?id=gardenfelder) | [9 comments](https://news.ycombinator.com/item?id=37846273)

Google has announced new expansions for its Project Green Light initiative, which aims to tackle street-level pollution caused by vehicles idling at stop lights. The project uses machine learning systems to analyze traffic congestion data and optimize traffic timing at intersections. Early findings show a reduction in fuel consumption and intersection delay time of 10 to 20 percent. The pilot program has since grown to a dozen partner cities globally. Google plans to scale the project to more cities in 2024, with initial estimates suggesting a potential 30 percent reduction in stops. The company believes Project Green Light offers a scalable and cost-effective solution for cities to reduce carbon emissions.

The discussion on the submission revolves around the effectiveness of the Project Green Light initiative and the concept of traffic calming measures.

One user, lyjhn, criticizes the idea of traffic calming, noting that it often leads to increased frustration for drivers and does not necessarily improve safety. Another user, JambalayaJim, shares their personal experience, stating that traffic calming measures have made back streets more pleasant but have not necessarily improved safety.

bbbylrrybbby disagrees with the concept of traffic calming, arguing that it slows down cars but does not inherently make them safer. They highlight that accidents can occur at any speed and that parked cars can still kill someone even at low speeds.

tchnfnd expresses skepticism about Google's solution to distracted driving, suggesting that the problem can be solved if people pay attention to the traffic lights. They also mention that the behavior of people running red lights is a result of selfishness and not paying attention.

grdnfldr adds to the discussion, explaining that Google's machine learning systems use data from Google Maps to calculate traffic congestion and optimize traffic light timings.

vrdx questions the analytical solutions to traffic light scheduling, suggesting that they might be based on uncertain assumptions about traffic patterns.

Finally, dngs raises the point that pedestrians' experiences should also be considered when implementing traffic calming measures.

Overall, the discussion covers a range of opinions on traffic calming measures, driver behavior, and the potential effectiveness of Google's Project Green Light initiative.

### Facebook's AI Tom Brady is a weird creep who's obsessed with Travis Kelce

#### [Submission URL](https://www.sbnation.com/nfl/2023/10/11/23912601/facebook-ai-tom-brady-chat-travis-kelce-nfl) | 21 points | by [ahiknsr](https://news.ycombinator.com/user?id=ahiknsr) | [4 comments](https://news.ycombinator.com/item?id=37849742)

Facebook's parent company Meta has introduced "New AI Experiences," including an AI version of Tom Brady called "Bru." This AI is designed to engage in conversations with users on Messenger, and during a conversation with James Dator, a reporter at SBNation.com, Bru displayed a strange obsession with NFL player Travis Kelce. Despite Dator's attempts to steer the conversation towards other football topics, Bru consistently brought the conversation back to Kelce. Feeling uncomfortable, Dator ultimately ended the conversation and sought out a new AI experience with Dwyane Wade.

The comments on Hacker News regarding the AI conversation with Bru, an AI version of Tom Brady, mainly express amusement and find the interaction entertaining. One commenter mentions that the AI's obsession with Travis Kelce is probably due to limited training data. Another person jokingly suggests that the AI's behavior is justified because Kelce is a great player. One commenter finds it funny how the conversation was steered towards Dwyane Wade after feeling uncomfortable with the AI's fixation on Kelce. Overall, the discussion is lighthearted and focuses on the humorous aspects of the AI interaction.

---

## AI Submissions for Tue Oct 10 2023 {{ 'date': '2023-10-10T17:10:55.429Z' }}

### AI hype is built on flawed test scores

#### [Submission URL](https://www.technologyreview.com/2023/08/30/1078670/large-language-models-arent-people-lets-stop-testing-them-like-they-were/) | 193 points | by [antondd](https://news.ycombinator.com/user?id=antondd) | [224 comments](https://news.ycombinator.com/item?id=37830011)

A recent article in MIT Technology Review discusses the challenges and limitations of evaluating large language models like GPT-3 and GPT-4. While these models have showcased impressive abilities, such as passing human tests and demonstrating cognitive skills, there is a lack of consensus on what these results truly mean. Some researchers argue for more rigorous evaluation methods, while others suggest that scoring machines on human tests is flawed from the start. The article highlights the need for a better understanding of the capabilities and limitations of these language models as their impact on various industries becomes more pronounced.

The discussion in the comments revolves around the topic of whether language models like GPT-3 and GPT-4 are capable of true reasoning or if their performance is limited to surface-level pattern matching. Some commenters argue that these models lack the capacity for genuine reasoning and are merely sophisticated pattern recognition systems. Others highlight the limitations of current evaluation methods and the need for better techniques to assess the reasoning capabilities of these models. There is also a debate about the definition of "bullshit" and "reasoning," with some commenters arguing that these terms are subjective and context-dependent. Additionally, the discussion touches on the potential future developments in language models and the challenges of incorporating true reasoning abilities into artificial intelligence systems.

### HyperAttention: Long-Context Attention in Near-Linear Time

#### [Submission URL](https://arxiv.org/abs/2310.05869) | 67 points | by [kelseyfrog](https://news.ycombinator.com/user?id=kelseyfrog) | [13 comments](https://news.ycombinator.com/item?id=37832599)

Researchers Insu Han, Rajesh Jarayam, Amin Karbasi, Vahab Mirrokni, David P. Woodruff, and Amir Zandieh have proposed a new attention mechanism called HyperAttention, which aims to address the computational challenges faced by large language models that use long contexts. In their paper titled "HyperAttention: Long-context Attention in Near-Linear Time," the authors introduce two parameters that measure the difficulty of the problem and use them to achieve a linear time sampling algorithm. HyperAttention features a modular design that can easily integrate other fast low-level implementations, such as FlashAttention. The researchers empirically demonstrate that HyperAttention outperforms existing methods, including FlashAttention, offering significant speed improvements without sacrificing performance. This new attention mechanism is expected to make inference time faster and improve the efficiency of large language models.

The discussion on Hacker News revolves around the proposed HyperAttention mechanism and its potential benefits for large language models. Some users highlight the performance improvements achieved by HyperAttention compared to existing methods like FlashAttention. They point out that HyperAttention makes inference time faster without sacrificing performance, leading to significant speed improvements on tasks with long contexts.

Other users discuss the trade-offs and considerations in using smaller models with 32k context windows. They mention that smaller models with limited memory can still perform well on certain tasks, and optimizing backends for specific context lengths can be beneficial.

There is also a discussion about how machine learning researchers tweak parameters in large language models. Some users express the opinion that researchers often publish papers that tweak metrics to make the improvements seem more significant than they really are. They highlight the importance of being transparent about the metrics and mentioning negative results as well.

The topic of publishing negative or non-significant results also emerges in the conversation. Some users argue that researchers publish papers that only mention the positive results, while others argue that publishing negative results is important to advance the field.

There is a brief discussion about the publication process, with users expressing different opinions on formal results and peer review.

Lastly, some users mention the need for better comparisons and benchmarking in research papers, suggesting that researchers should compare their models with existing popular frameworks. Others point out that it is hard to gauge the value of papers without industry or academic consensus.

### Building a collaborative pixel art editor with CRDTs

#### [Submission URL](https://jakelazaroff.com/words/building-a-collaborative-pixel-art-editor-with-crdts/) | 151 points | by [jakelazaroff](https://news.ycombinator.com/user?id=jakelazaroff) | [22 comments](https://news.ycombinator.com/item?id=37832432)

In today's post "Building a Collaborative Pixel Art Editor with CRDTs" on jakelazaroff.com, the author takes us through the process of using Conflict-free Replicated Data Types (CRDTs) to build a collaborative pixel art editor. The post assumes no prior knowledge about CRDTs and provides a basic introduction to the topic.

The author starts by explaining that they will be using JavaScript and graphics programming to demonstrate how CRDTs can be implemented in a real-world application. They provide the necessary code to build the CRDT, which is a class called PixelData that acts as a wrapper over a Last Write Wins (LWW) Map. The PixelData class maps pixel coordinates to colors, with each key representing a single pixel.

The author then provides a visualization of how the keys and values interact when drawing on the canvas. They show how painting a pixel sets the key value to the selected RGB color, and how pixels that haven't been set default to white. When painting over a pixel, the value is overwritten and the timestamp is incremented.

Moving on to the UI, the author shares the HTML and CSS code for setting up the canvas and color input elements. They then provide JavaScript code to instantiate two editors, Alice and Bob, which are instances of the PixelEditor class. The states of Alice and Bob are merged whenever a change is made in either editor, and the color is set based on user input.

Overall, this post serves as a practical example of how CRDTs can be used in a collaborative application, specifically a pixel art editor. By following the author's explanations and code samples, readers can gain a deeper understanding of CRDTs and how they can be implemented in their own projects.

The discussion revolves around several aspects of the post. 

One user points out that training models to resolve conflicts in collaborative dating can be interesting, and they mention a specific case on GitHub where conflict resolution was handled manually. They also suggest that having non-interactive resolution as the default in developer tools could lead to the loss of work in certain situations, like large refactorings.

Another user mentions that conflicts in CRDTs can be resolved at a semantic layer and provides an example of how conflicts in a canvas can be resolved by prioritizing the most recent drawing. They emphasize the importance of understanding semantics to resolve conflicts effectively.

There is a discussion about whether or not text convergence is guaranteed with CRDTs. One user argues that CRDTs do not guarantee semantic content preservation, while another user explains how they handle nested data in a CRDT to ensure content convergence.

The discussion also touches on the benefits of CRDTs and how they can handle conflict resolution in a self-driving manner, making it easier to work with conflicts in simpler domains.

Another user raises the challenge of preserving the intent of content, particularly when it involves making human-like judgment calls, and mentions that CRDTs provide consistency but may not handle judgment calls effectively.

There is also dialogue about the convergence of state in CRDTs, with one user pointing out that while CRDTs technically converge resulting in the same state, the neural network approach ensures that the final state matches the human's intended state more reliably.

A user shares a link to a related discussion on Our World Pixels, mentioning the date and number of comments.

Finally, there are a few comments about the syntax, font, and highlighting of code in the post, with one user suggesting a specific font family for code.

The discussion is informative and includes various perspectives and insights related to the topic of CRDTs and collaborative pixel art editing.

### Apple patents suggest future AirPods could monitor biosignals and brain activity

#### [Submission URL](https://applemagazine.com/apple-patents-suggest-future-airpods-could-monitor-biosignals-and-brain-activity/59510) | 124 points | by [sundarurfriend](https://news.ycombinator.com/user?id=sundarurfriend) | [95 comments](https://news.ycombinator.com/item?id=37836603)

Apple has been granted a patent by the US Patent & Trademark Office for next-generation AirPods that could measure various biosignals such as electrooculography (EOG), electromyography (EMG), and electroencephalography (EEG). The patent application reveals that the AirPods would contain strategically placed electrodes to capture these measurements, which can monitor brain activity when attached to the user's scalp. The patent suggests that the future AirPods may be customizable to accurately measure ear-EEG, taking into account the variations in size and shape of individuals' ears. There are also reports that Apple is exploring features to measure body temperature through the ear canal and a hearing test feature to assess a user's hearing abilities.

The discussion on this submission covered a wide range of topics:

- user "karim79" expressed excitement about the potential for AirPods to measure brain activity levels and how it could lead to innovative software and personalized experiences.
- Some users made jokes and light-hearted comments.
- User "cmiller1" mentioned that this patent is tangentially related to a dream they had about a music player that could sense their physical activity.
- There was a discussion about mental health and therapy services such as BetterHelp and their potential impact.
- Some users commented on the use of music for various activities and mentioned music-streaming service Spotify.
- User "jrckwy" discussed the impact of technology on activities like cycling and mentioned headphones that allow for situational awareness.
- There was a conversation about the potential applications of biofeedback and brainwave-sensing devices.
- User "rtsdx" wondered about the possibility of tracking REM sleep stages and adjusting alarms accordingly.
- Other topics brought up included fitness devices, patent validity, and the quality of life improvements that small things can bring.

Overall, the discussion covered a wide range of ideas and opinions related to the patent for next-generation AirPods.

### Artificial General Intelligence Is Already Here

#### [Submission URL](https://www.noemamag.com/artificial-general-intelligence-is-already-here/) | 25 points | by [falava](https://news.ycombinator.com/user?id=falava) | [10 comments](https://news.ycombinator.com/item?id=37836957)

Artificial General Intelligence (AGI), which refers to AI systems that exhibit human-level intelligence across a wide range of tasks, is already here, according to Blaise AgÃ¼era y Arcas, a vice president at Google Research, and Peter Norvig, a computer scientist at Stanford. They argue that although today's advanced AI models have many flaws, they have already achieved the key properties of generality that define AGI. These "frontier models" can perform a variety of tasks, operate on different modalities like text, images, and audio, handle multiple languages, and learn from prompts rather than just training data. While these models still have limitations, the authors believe they will be recognized as the first true examples of AGI in the future. They compare this to the ENIAC, the first general-purpose electronic computer, which paved the way for today's computers. The authors emphasize that AGI should be seen as a multidimensional scorecard rather than a simple yes/no proposition.

### The rent is too damn algorithmic

#### [Submission URL](https://washingtoncitypaper.com/article/631461/the-rent-is-too-damn-algorithmic/) | 111 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [143 comments](https://news.ycombinator.com/item?id=37829575)

Attorney General Brian Schwalb is investigating a company called RealPage for potential antitrust violations in the housing industry. RealPage provides software that recommends rent prices for apartments based on market data. Critics argue that the company's algorithm effectively enables collusion among big landlords to fix prices. Schwalb has proposed hiring a law firm to assist with the investigation and potential litigation against RealPage and other targets in the housing industry. The Texas-based company is already facing multiple lawsuits and an antitrust investigation by the Department of Justice. This could be one of the first challenges to RealPage by state attorneys general.

The discussion on Hacker News about the submission focuses on various aspects of the antitrust investigation against RealPage and the implications of their software on the housing market. Here are the main points discussed:

- Some users argue that RealPage's software enables collusion among landlords and effectively fixes rent prices. They point out that the software allows landlords to coordinate and set prices based on market data, potentially leading to higher rents.
- Others suggest that the problem lies with the shortage of housing supply, rather than RealPage's software. They argue that if there were enough available housing units, the market forces would naturally adjust prices. They criticize the company for taking advantage of the scarcity of housing.
- There is a debate about whether the actions of RealPage constitute a market manipulation or just a reflection of the supply and demand dynamics. Some users argue that market forces are at play, while others believe that there is a manipulation of prices by large landlords.
- One user suggests that one possible solution to address the issue would be to remove class entirely from residential property. They argue that housing should not be treated as an investment, as it contributes to pricing out many people and exacerbates the shortage of affordable housing.
- The discussion also touches on the idea of induced demand and its impact on traffic congestion. Some users argue that increasing housing supply could lead to more people moving to the city and worsening congestion, while others believe that the lack of affordable housing forces people to live far away from their workplaces, causing traffic jams.
- A user mentions the housing market in Germany, where the construction of housing is more focused on short-term rentals and leads to a shortage of affordable housing. They argue that construction should prioritize long-term housing solutions and consider the environmental impact.

Overall, the discussion highlights the complexities and different perspectives surrounding the investigation into RealPage and the broader issues of affordability and market dynamics in the housing industry.

### Lit 3.0

#### [Submission URL](https://lit.dev/blog/2023-10-10-lit-3.0/) | 116 points | by [meiraleal](https://news.ycombinator.com/user?id=meiraleal) | [88 comments](https://news.ycombinator.com/item?id=37834927)

Today is an exciting day for the Lit project and the web components community. The Lit team has officially released Lit 3.0, marking their first major version since Lit 2.0 in early 2021. In addition to Lit 3.0, they also announced the graduation of the first class of Lit Labs packages, which include @lit/react, @lit/task, and @lit/context. But that's not all! The team also released two bonus packages: @lit-labs/compiler and @lit-labs/preact-signals.

One of the main highlights of Lit 3.0 is the removal of support for IE11. After surveying the developer community, the team felt that now is the right time to say goodbye to IE11. This release also introduces some additional breaking changes that remove technical debt and pave the way for new features planned for future releases.

Despite being a breaking change release, Lit 3.0 does include one new feature: support for the TC39 standard decorators specification. With the arrival of standard decorators, Lit can begin transitioning to a decorator implementation that doesn't require a compiler to use. The team has made efforts to ensure a smooth upgrade path from experimental decorators to the standard spec.

Another noteworthy release is the new @lit-labs/compiler package. This Labs package provides a TypeScript Transformer that can be used during build-time preparation of Lit templates, resulting in faster rendering performance. According to benchmarks, the new compiler can improve first render speed by 46% and update speed by 21%.

For those interested in upgrading to Lit 3.0, the process should be seamless for most users. Simply update the npm dependency version to the latest release of Lit.

Overall, these releases demonstrate the Lit team's commitment to stability, performance, and adherence to standards. The Lit project continues to evolve and improve, offering developers powerful tools for building web components.

The discussion on this submission covers various topics related to Lit 3.0 and web components. Here are some key points:

- Some users express their excitement for the Lit project and the new releases, while others mention potential benefits like improved performance and better integration with other frameworks.
- There is a discussion about the difficulty of getting started with Lit and the benefits of using pre-existing design systems like Shoelace.
- Some users discuss the advantages of web components and their potential integration with frameworks like React and Vue.
- There is a debate about the relevance of web components and their adoption in the industry. Some users mention the limitations of React and the benefits of using Lit as a smaller and more efficient library.
- A user highlights the progress made in the Lit project, comparing it to jQuery in terms of simplifying web development.
- There is a discussion about the similarities and differences between Lit and other web frameworks.
- Some users mention the importance of standardization and the potential of web components to facilitate component integration across different platforms.
- Other topics include the performance improvements in Lit's compiled templates and the advantages of using compiled templates for optimization.

Overall, the discussion reflects different perspectives on the use of Lit and web components, with users discussing their experiences, concerns, and potential use cases.

### Polymathic AI

#### [Submission URL](https://polymathic-ai.org/blog/announcement/) | 30 points | by [jasondavies](https://news.ycombinator.com/user?id=jasondavies) | [5 comments](https://news.ycombinator.com/item?id=37838943)

Introducing the Polymathic AI initiative, a research project aiming to accelerate the development of versatile foundation models for scientific machine learning tasks. While there have been significant advances in machine learning for vision and natural language processing, the same paradigm shift has not yet occurred for scientific datasets. The goal of Polymathic AI is to build AI models that can leverage information from heterogeneous datasets and across different scientific fields. By providing off-the-shelf models with strong priors for scientific concepts, the initiative aims to democratize AI in science. The project brings together a team of machine learning researchers and domain scientists and is guided by a scientific advisory group. Preliminary research has already been published on key architectural components, and the initiative holds great potential to redefine the landscape of scientific machine learning.

The discussion about the Polymathic AI initiative on Hacker News includes a few comments. One user, "wrsh07," finds the announcement paper interesting and shares a link to it.  Another user, "xlxbr," expresses difficulties in finding information about the organization on the Polymathic AI website. They wonder about the participating institutions and the skills required for participation.  A user called "jsndvs" suspects that this might be a collaborative scientific effort supported by commercial enterprises. They mention the Flatiron Institute and the Simons Foundation as potential supporters based on a tweet from the Polymathic AI account. They also provide a link to the Simons Foundation's website, which they believe provides informative press releases about the initiative. Another user, "hltst," finds the work interesting and highlights the discovery of promising concepts related to dynamics in static and dynamic systems.