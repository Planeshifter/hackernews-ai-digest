import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Thu Jul 20 2023 {{ 'date': '2023-07-20T17:09:30.842Z' }}

### Project Aria 'Digital Twin' Dataset by Meta

#### [Submission URL](https://www.projectaria.com/datasets/adt/) | 173 points | by [socratic1](https://news.ycombinator.com/user?id=socratic1) | [89 comments](https://news.ycombinator.com/item?id=36800041)

Meta, the parent company of Facebook, has introduced the Aria Digital Twin Dataset, which aims to accelerate research in egocentric machine perception. The dataset, captured using Aria glasses, includes extensive ground-truth annotations for devices, objects, and environments. It consists of 200 sequences (~400 minutes) captured in two different locations, with annotations such as 6DoF device trajectory, 3D object pose, 3D human skeleton, and 3D eye gaze. The dataset also includes tools for loading and visualizing the data, as well as participating in object detection challenges. The Aria Digital Twin Dataset is designed to promote responsible innovation and has been captured in controlled environments with fully consented researchers. Researchers can access the dataset by providing their email address.

The discussion on Hacker News revolves around the issue of cookie consent banners and their compliance with privacy regulations such as the GDPR. Some commenters argue that the language used in the banners could be deceptive or misleading, potentially violating the GDPR. Others point out that the banners are necessary for tracking purposes and to improve content and services. There is also a discussion about the implementation of the "Do Not Track" (DNT) feature and whether it is effective or relevant in protecting privacy.  Another topic discussed is the release of the Aria Digital Twin Dataset by Meta (parent company of Facebook) and its potential impact on research in egocentric machine perception. The dataset includes annotated sequences captured using Aria glasses, providing researchers with valuable data for their experiments.

### Foundational AI models do not violate copyright

#### [Submission URL](http://marble.onl/posts/general_technology_doesnt_violate_copyright.html) | 22 points | by [andy99](https://news.ycombinator.com/user?id=andy99) | [15 comments](https://news.ycombinator.com/item?id=36807408)

In a recent article, Andrew Marble discusses the contention that AI models violate copyright because they are capable of generating copyrighted content. Marble argues that while it is possible to build an AI model that violates copyright and use broad foundation models like chatGPT to generate copyrighted content, this does not mean that the training or existence of the models themselves violate copyright. Marble equates the situation to other technologies like photocopiers or VCRs, stating that just because a model can do something doesn't mean people are necessarily utilizing it for nefarious purposes. Rather than limiting the capabilities of AI models, Marble suggests focusing on regulating the use of the technology and holding individuals accountable for any copyright infringements or other misuses. Marble also mentions the importance of distinguishing between broadly capable AI models and narrowly trained models with malicious intent. Overall, the article argues against legislating limitations on AI models at the capability level and emphasizes the need to consider how people use the technology instead.

The discussion on the submission centers around the argument made in the article and the comparison between AI models and technologies like photocopiers and VCRs. Some users agree with the article's perspective, stating that regulating the use of AI technology and holding individuals accountable for copyright infringements is more important than limiting the capabilities of AI models. Others disagree, pointing out that comparing AI to humans in terms of copyright is disingenuous, as AI does not have the same consciousness or decision-making abilities. The discussion also touches on the need to make works publicly available for training AI models and the complexities of copyright law in relation to AI-generated content. Overall, there is a division of opinions on how AI models should be regulated in terms of copyright infringement.

### Decoding the ACL Paper: Gzip and KNN Rival Bert in Text Classification

#### [Submission URL](https://codeconfessions.substack.com/p/decoding-the-acl-paper-gzip-and-knn) | 30 points | by [abhi9u](https://news.ycombinator.com/user?id=abhi9u) | [5 comments](https://news.ycombinator.com/item?id=36806577)

A recent paper presented at the ACL conference for natural language processing (NLP) has gained attention for its innovative approach to text classification. The paper shows that combining the use of gzip and K-nearest neighbour (KNN) can achieve performance comparable to state-of-the-art models like BERT. This is a refreshing perspective at a time when most research focuses on large language models. The paper's findings are explained in layman's terms in this article, with a follow-up article planned to delve deeper into the approach and its implications for NLP research. The traditional approaches to text classification, such as linear regression or neural networks, often require training on large datasets and can be computationally expensive. In contrast, the gzip and KNN approach offers a simpler and more cost-effective solution. The key steps involve compressing the input text using gzip, computing the Normalized Compression Distance (NCD) between the compressed texts, and then finding the k-nearest neighbors based on these distances. The majority class of the neighbors is then chosen as the target label. The NCD measures the amount of shared information between two texts, and if they have similar content, their concatenation will achieve higher compression. This approach leverages compression algorithms and information theory to achieve accurate text classification without the need for massive language models.

The discussion around the submission primarily revolves around the potential of the gzip and KNN approach for text classification. One user points out that the technique may overestimate performance relative to BERT, and recommends evaluating its accuracy against expected KNN compressed data. Another user suggests that the paper has the potential to start an interesting discussion on finding synonymous word classes, to which another user responds that such an approach could work using semantic modeling and embeddings. The second user also mentions that they are writing an article to explain how gzip can be helpful in text classification. One user jokingly adds that the approach wouldn't find synonyms that are closer to random strings.

### AI That Teaches Other AI

#### [Submission URL](https://viterbischool.usc.edu/news/2023/07/teaching-robots-to-teach-other-robots/) | 97 points | by [geox](https://news.ycombinator.com/user?id=geox) | [40 comments](https://news.ycombinator.com/item?id=36799073)

Researchers from the University of Southern California (USC) have developed a tool called SKILL (Shared Knowledge Lifelong Learning) that allows robots to teach each other how to learn. In a paper published in Transactions on Machine Learning Research, the team describes how AI agents learned 102 different tasks, such as categorizing images of cars or flowers, and shared their knowledge over a decentralized communication network. The robots were able to master all 102 tasks by teaching each other, reducing the time needed for learning by a significant factor. The researchers believe that this approach could be scaled up to thousands or millions of tasks, potentially transforming various industries and creating a more connected and efficient global community. They envision applications in healthcare, where AI systems could specialize in different areas of medicine and provide doctors with the most up-to-date information, as well as in tourism, where every smartphone user could become a local tour guide by sharing photos and details about different landmarks and local cuisine. The researchers see potential in using SKILL technology in any profession that requires vast knowledge or deals with complex systems.

The discussion on this submission revolves around several topics. One user highlights the challenges of individuality in AI and the potential risks associated with the development of artificial general intelligence (AGI). Another user discusses the limitations and diminishing returns of scaling up AI models. Some users express confusion about the terminology used and seek clarification on the concept of Mixture of Experts (MoE) models. The potential implications of SKILL technology in various industries, such as healthcare and tourism, are also discussed. Additionally, there is conversation about the integration of AI and human knowledge-sharing, as well as debates on the risks and benefits of AI advancements for society.

### TSMC delays Arizona factory that will eventually build chips for iPhones and AI

#### [Submission URL](https://www.theverge.com/2023/7/20/23802107/tsmc-arizona-chip-factory-delay-q2-earnings-report) | 29 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [10 comments](https://news.ycombinator.com/item?id=36806863)

Taiwan Semiconductor Manufacturing Company (TSMC) has announced that the start of chip production at its new facility in Arizona, which is intended to manufacture chips for iPhones and AI, will be delayed to 2025 due to labor shortages. The company's first fab in Phoenix was initially scheduled to begin producing 4nm chips next year, but TSMC is now facing challenges in finding skilled workers for equipment installation. To make up for lost time, TSMC plans to send experienced technicians from Taiwan to train local workers at the plant. TSMC's Q2 earnings report also showed a 10% decline in revenue and a 23% decline in profits compared to the same period last year, with a projected 10% revenue drop for the full year. The company expects the capacity shortage caused by high demand for AI-capable chips to persist until next year. TSMC is working with the US government to maximize subsidies and tax credits available to cover the increased costs of fabricating in the US.

The discussion on this submission revolves around various aspects of the delay in chip production at TSMC's new facility in Arizona, along with the company's financial situation. Here are some key points from the comments:

- Some users suggest that TSMC could have started training programs to address the labor shortage earlier.
- A user mentions that skilled friends who used to work in chip fabs have moved to software jobs, as the latter is considered to have higher salaries and fewer hazards.
- Another user points out that certain fields require high skills, yet their compensation is little compared to software-related work.
- There is a discussion about TSMC's profitability, with some users emphasizing the company's success and others highlighting the significant profits it generates and the higher salaries it pays to employees.
- A user shares a link to an article discussing TSMC's financials, including its $33 billion profit.
- One user mentions that while the delay in chip production is unfortunate, TSMC should have started comprehensive training programs for workers earlier.
- There is a request for further discussion on this topic, with a link to an article on The Verge being shared.

Note: The conversation contains a few replies marked as "dd" or "dp", without further context or content.

### 9k authors say AI firms exploited books to train chatbots

#### [Submission URL](https://www.latimes.com/entertainment-arts/story/2023-07-19/artificial-intelligence-9000-authors-sign-letter-rebuking-ai-companies-books) | 28 points | by [webmaven](https://news.ycombinator.com/user?id=webmaven) | [12 comments](https://news.ycombinator.com/item?id=36807296)

More than 9,000 authors have signed an open letter calling out tech companies behind generative AI for exploiting copyright-protected works without consent, credit, or compensation. The authors argue that these companies are using their writings to train chatbots, such as GPT-4 and ChatGPT, to summarize and imitate their works. The open letter specifically calls out tech giants like OpenAI, Alphabet, Meta, IBM, and Microsoft, urging them to obtain permission and fairly compensate authors for the use of their works in generative AI programs and outputs. The Authors Guild highlights the threat that generative AI poses to writers' professions, as it floods the market with machine-written content and contributes to a decline in authors' income. This comes shortly after bestselling authors Mona Awad and Paul Tremblay filed a lawsuit against OpenAI, claiming that ChatGPT was trained using portions of their novels without their consent. Both the open letter and the lawsuit shed light on the ethical and legal questions surrounding the use of copyrighted material in AI technology.

The discussion on this submission revolves around various aspects of copyright law, fair use, and the impact of generative AI on the distribution of content.  One commenter raises the point that purchasing a book does not necessarily grant the purchaser the right to modify or use the content in AI systems. They argue that there is a distinction between creating a parody or satire, which may be protected as fair use, and using copyrighted works without permission in generative AI. Another commenter questions whether embedding AI crops into AI systems through modification would qualify as fair use. They further discuss the complexity of copyright claims and the applicability of fair use factors in determining the legality of using copyrighted works. A reply to this comment emphasizes the importance of the four factors considered in fair use cases: the purpose and character of the use, the nature of the copyrighted work, the amount and substantiality of the portion used, and the effect on the potential market for the copyrighted work. They also mention that the commercial nature of the AI applications and the potential harm to the market for original works could be significant factors to consider. In response to a comparison made between modifying the Mona Lisa and using AI-generated crops, another commenter mentions a recent Supreme Court decision involving Warhol and Goldsmith. They note that the decision clarified the high level of commerciality necessary to define copying as illegal for derivative works. The discussion then delves into the proprietary nature of AI algorithms and the commercial rush to capitalize on generative AI. The commenter suggests that the AI community is protecting their proprietary interests and refusing to engage with AI regulation. One commenter expresses skepticism about prevailing legal arguments in the court proceedings and hopes that people will learn to synthesize new content based on existing works.

---

## AI Submissions for Tue Jul 18 2023 {{ 'date': '2023-07-18T17:10:26.153Z' }}

### Voder Speech Synthesizer

#### [Submission URL](https://griffin.moe/voder/) | 247 points | by [CyborgCabbage](https://news.ycombinator.com/user?id=CyborgCabbage) | [40 comments](https://news.ycombinator.com/item?id=36771149)

In a fascinating throwback to the 1939-40 New York World's Fair, an application has been created that allows users to experience what it was like to operate the Voder, an early speech synthesis device. The Voder required complex button sequences to form each syllable, and it took about a year of practice to produce fluent speech. Helen Harper, one of the first people to master the Voder, went on to teach women how to use it through a year-long course. Now, this application puts users in the shoes of these skilled operators, allowing them to create vowel formants by pressing specific button combinations. While the results may not sound exactly like the original video, due to subtle articulations and dynamics, it provides a unique glimpse into the past.

### Generative AI space and the mental imagery of alien minds

#### [Submission URL](https://writings.stephenwolfram.com/2023/07/generative-ai-space-and-the-mental-imagery-of-alien-minds/) | 244 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [106 comments](https://news.ycombinator.com/item?id=36767837)

In a recent post on his blog, Stephen Wolfram explores the concept of alien minds and how artificial intelligence (AI) can help us understand them. Wolfram explains that AIs are essentially accessible forms of alien minds because they are not aligned with human thought processes. To capture the "mental imagery" of an alien AI, Wolfram suggests modifying a generative AI by resetting weights in its neural net. This "alien" neural net still produces images, but they become increasingly different from human perception as the neural net is modified. By studying these progressively alien images, Wolfram believes that we can gain insight into the worlds of different and alien minds. Additionally, Wolfram explains how AIs are trained to generate images by capturing the regularities found in billions of images from the web. These "random images" exhibit the statistical patterns of the training data and can show recognizable objects or scenes. Overall, Wolfram's exploration of alien minds and generative AI provides a fascinating perspective on perception and cognition.

The discussion on the submission revolves around the concept of AI-generated images and how they relate to human perception. Some comments touch on the similarities and differences between AI dream-like images and human dreams. Other comments discuss the technical aspects of AI-generated images and how they can be seen as artistic expression. Some users also express concerns about the role of AI in generating content and its impact on traditional art forms. Overall, the discussion explores the potential of AI to produce novel and intriguing imagery, while also raising questions about its limitations and implications.

### A Theory on Adam Instability in Large-Scale Machine Learning

#### [Submission URL](https://arxiv.org/abs/2304.09871) | 135 points | by [vov_or](https://news.ycombinator.com/user?id=vov_or) | [51 comments](https://news.ycombinator.com/item?id=36771484)

A new theory has emerged in the field of machine learning that explains the previously unexplained divergent behavior observed in the training of large language models. The theory suggests that the phenomenon is due to the optimization algorithm used for training, called Adam. The researchers argue that Adam can reach a state where the parameter update vector has a large norm and is uncorrelated with the direction of descent on the training loss landscape, leading to divergence. This behavior is more likely to occur in the training of deep models with large batch sizes, which is common in large-scale language model training. The theory is supported by observations from training runs of language models with varying scales. The paper, titled "A Theory on Adam Instability in Large-Scale Machine Learning," is authored by Igor Molybog and 16 other researchers. It is available for download on arXiv.

The discussion on this submission revolves around the new theory proposed by the researchers regarding the divergence in training large language models due to the use of the Adam optimization algorithm. Some users suggest trying different techniques such as controlling the term of the gradient or restarting the training process to mitigate the issue. Others discuss the potential of using CMA-ES (Covariance Matrix Adaptation Evolution Strategy) and other optimization methods for better results. There are also discussions on the limitations of gradient-based optimization methods and the challenges faced in finding global minima. Some users mention the possibility of using swarm optimization and genetic algorithms to improve the search process. One user points out the importance of local minima and the difference between biological neural networks and machine learning models. The energy costs of training models and the efficiency of neural networks compared to humans are also discussed in the comments.

### G/O media will make more AI-generated stories despite critics

#### [Submission URL](https://www.vox.com/technology/2023/7/18/23798164/gizmodo-ai-g-o-bot-stories-jalopnik-av-club-peter-kafka-media-column) | 101 points | by [Analemma_](https://news.ycombinator.com/user?id=Analemma_) | [100 comments](https://news.ycombinator.com/item?id=36773363)

G/O Media, the digital publisher behind sites like Gizmodo and the Onion, sparked controversy when it published four stories generated by AI engines without input from its editors or writers. Despite the backlash, G/O executives have expressed plans to create more AI-written stories as part of an ongoing experiment with the technology. The move sets G/O apart from most conventional publishers, who are interested in using AI to assist in content creation but are not yet interested in fully machine-made content. G/O Media CEO Jim Spanfeller believes that AI will be transformative for the media industry and should not be ignored. However, G/O employees are concerned about the impact on employee morale and fear that AI will eventually replace human journalists. G/O executives insist that they will not replace staff with AI, but the skepticism among employees remains.

### A Latent Space Theory for Emergent Abilities in Large Language Models

#### [Submission URL](https://arxiv.org/abs/2304.09960) | 14 points | by [rileyphone](https://news.ycombinator.com/user?id=rileyphone) | [4 comments](https://news.ycombinator.com/item?id=36776920)

The paper titled "A Latent Space Theory for Emergent Abilities in Large Language Models" by Hui Jiang explores the relationship between languages and their underlying meanings. The study categorizes languages as unambiguous or epsilon-ambiguous and demonstrates that large language models (LLMs) can exhibit emergent abilities, such as language understanding, in-context learning, chain-of-thought prompting, and effective instruction fine-tuning, through Bayesian inference on the sparse joint distribution of languages. This paper presents quantitative results and sheds light on the capabilities of LLMs in language processing.

The discussion around the submission focuses on the structure and analysis of languages. One user argues that languages are created randomly for specific purposes and convey information through distinct and independent units such as sentences or programming languages. Another user adds that language messages represent intended meanings in a space, where different intentions constitute distinct regions and simple intentions are represented by elements in a finite set. They suggest that the study of language should consider discrete countable assumptions.  In response, another user provides research that supports the effectiveness of transformer-based language models. They share two articles that discuss the reasonable effectiveness of these models.  However, one user disagrees with the assumption that language messages contain intentions recursively in a fundamental space of meaning. They argue that this approach to studying language is oversimplified and may not fully capture the complexity of the field.  Finally, a user points out that the discussion seems to lack an interdisciplinary perspective and suggests that siloing of perspectives may prevent a comprehensive understanding of the topic.

### Qualcomm works with Meta to enable on-device AI applications using Llama 2

#### [Submission URL](https://www.qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi) | 99 points | by [ahiknsr](https://news.ycombinator.com/user?id=ahiknsr) | [82 comments](https://news.ycombinator.com/item?id=36778730)

Introducing the Hacker News Daily Digest, your one-stop destination for a quick and engaging summary of the top stories on Hacker News. We've got our virtual pens and minds ready to deliver the latest and most interesting news from the developer and tech community straight to you.

Whether you're a seasoned coder, a tech enthusiast, or simply curious about the buzzing tech world, our daily digest will keep you informed and entertained. So sit back, relax, and let us handle the heavy lifting of filtering through the vast sea of Hacker News submissions.

From software development breakthroughs to the latest tech gossip, we'll cover it all. Expect insights into the hottest programming languages, discussion threads on frameworks, debates over the merits of different tools, and updates on the most interesting startups.

But that's not all. We'll also dive into thought-provoking and mind-bending articles on artificial intelligence, blockchain technology, cybersecurity, and more. Our aim is to provide you with the most captivating and relevant stories that will ultimately spark your curiosity and keep you ahead of the game.

You can count on us to deliver daily summaries that capture the essence of the Hacker News community. Say goodbye to endlessly scrolling through countless submissions; we'll bring you only the best and most interesting conversations that are shaping the tech landscape.

So whether you're a seasoned Hacker News regular or a newcomer to the platform, join us for the Hacker News Daily Digest and stay tuned for an engaging and informative daily dose of the tech world's most captivating stories.

The discussion on the submission revolves around various aspects of Apple's approach to artificial intelligence (AI). Some commenters express skepticism about Apple's AI capabilities and suggest that the company is focusing more on hardware rather than AI integration. Others mention Apple's past failures, such as Apple Maps, and criticize the company's product planning and recognition of flaws. 

There is a discussion about the usability of Apple Maps compared to Google Maps, with some users pointing out the shortcomings of Apple Maps and praising Google Maps for its UI and search capabilities. 

On the topic of Apple's AI advancements, some users mention the potential integration of Siri with local machine learning models (LLMs) and the possibility of Siri becoming a more advanced personal assistant. Others discuss Apple's track record of integrating AI features into iOS, such as text and photo recognition, and the company's ability to apply innovative models. 

There is a debate about the advantages of Apple's AI strategy compared to other companies, with some highlighting the company's focus on user experience and unique features, while others argue that Apple is not as competitive in AI. 

The conversation also touches on Apple's investment in LLMs, possible future developments in AI, and the capabilities of chatbots and machine learning models.

### Meta and Qualcomm team up to run Llama 2 on phones

#### [Submission URL](https://www.cnbc.com/2023/07/18/meta-and-qualcomm-team-up-to-run-big-ai-models-on-phones.html) | 17 points | by [tzm](https://news.ycombinator.com/user?id=tzm) | [3 comments](https://news.ycombinator.com/item?id=36775645)

Qualcomm and Meta have announced a partnership to enable the social networking company's new large language model, Llama 2, to run on Qualcomm chips on phones and PCs starting in 2024. Large language models like Llama 2 have traditionally run on large server farms with powerful Nvidia graphics processors. This announcement by Qualcomm suggests that it wants to position its processors as well-suited for AI "on the edge," or on a device, rather than in the cloud. Running large language models on phones could significantly reduce the cost of running AI models and lead to better and faster voice assistants and other applications. Qualcomm's chips include a tensor processor unit (TPU) that is well-suited for AI calculations, although the processing power available on a mobile device is much less than that of a data center with cutting-edge GPUs. Meta's Llama 2 is unique because Meta published its "weights," which govern how the AI model works, making it open-source and accessible to researchers and commercial enterprises without permission or payment. Qualcomm and Meta have previously collaborated on chips for virtual reality devices.

The discussion on Hacker News revolves around the announcement of the partnership between Qualcomm and Meta to enable the running of Meta's large language model, Llama 2, on Qualcomm chips on devices starting in 2024.  One user questions whether Llama 2 will be relevant by 2024 and suggests that there might be a newer version of the model. 
 Another user mentions that Qualcomm has previously collaborated with Stable Diffusion to run ML models on phones and that they published a demo with card recognition. They speculate that Qualcomm might have built an extensive feature set, possibly for user interface implementation.  Another user highlights the importance of this announcement, specifically in terms of enabling low-latency implementation of large language models on devices, which could greatly impact the user experience of AI voice assistants and other applications. They compare it to Google's PaLM version for Android devices and suggest that Apple might also jump on this trend early by introducing an on-device Siri powered by ML chips.

### From Dating to Vector Search – “Stable Marriages” on a Global Scale

#### [Submission URL](https://ashvardanian.com/posts/searching-stable-marriages/) | 35 points | by [vov_or](https://news.ycombinator.com/user?id=vov_or) | [31 comments](https://news.ycombinator.com/item?id=36772545)

In this article, the author explores the concept of stable marriages and its implications for the future of databases. Stable marriages are computed using preference lists, but this approach requires a large amount of memory when dealing with a large number of candidates. To overcome this, the author suggests using a scalable Vector Search engine to dynamically recalculate candidate lists. However, the quality of representations in a shared Vector Space, particularly for Multi-Modal data, is a challenge. The author highlights the need for improving space-alignment techniques to enhance the performance of upcoming Generative Vision-Language models. The article also shares the author's personal journey of applying these algorithms to a dating app and the cost implications of using the classic stable marriage algorithm for a billion candidates. The author explains how to balance compute requirements by recalculation and discusses the implementation details of a Vector Search engine.

The discussion on this article covers a wide range of topics related to arranged marriages, divorce rates, personal freedom, societal stability, and cultural differences. Some users argue that arranged marriages can lead to stability and happiness, while others believe that individual happiness should take precedence. There is also a discussion about the cultural contexts in which arranged marriages are common and the social pressures that can be associated with them. Additionally, there are comments about the need for structured content in databases and the trade-offs between personal freedom and societal benefits.

### AI System Helped Cops ID a Drug Trafficker by Analyzing His Driving Patterns

#### [Submission URL](https://gizmodo.com/rekor-ai-system-analyzes-driving-patterns-criminals-1850647270) | 30 points | by [HiroProtagonist](https://news.ycombinator.com/user?id=HiroProtagonist) | [19 comments](https://news.ycombinator.com/item?id=36772253)

In a recent case in New York, police were able to identify and arrest a drug trafficker with the help of artificial intelligence (AI). The police used the services of a company called Rekor, which analyzes traffic patterns and identifies suspicious behavior. Rekor's software sifts through a large database of information collected from regional roadways by the county's automatic license plate recognition system. By recording and analyzing vehicle trajectories, the software can determine whether certain routes are suspicious or not. In this case, the AI algorithm determined that the driver's routes were consistent with those of a drug trafficker, leading to his arrest. This highlights how AI is being used to enhance surveillance systems and aid law enforcement. However, there are concerns about the potential misuse of this technology and the need for appropriate regulations to prevent abuse.

The discussion on this submission revolves around the pros and cons of AI-assisted surveillance systems and their potential misuse.  One user points out that the AI algorithm used in this case reminds them of the controversy surrounding the analysis of phone data, where innocent activities were mistakenly flagged as suspicious. Another user jokingly suggests that the investigation could have been prompted by Tupperware parties, emphasizing that false positives can occur. Some users express concerns about the potential for targeted searches in minority neighborhoods and the erosion of privacy. Others argue that AI-based investigations can be helpful in fighting crime, but there needs to be clear regulations in place to prevent abuse. The discussion also touches on the limitations of AI systems and their potential for false positives. One user brings up the issue of law enforcement accessing location records without a warrant, while another user notes the historical use of AI systems to combat terrorism and drug dealers. There is a debate about the balance between privacy and security, with some arguing that surveillance technology is necessary to target criminals while others feel it infringes on civil liberties. One user points out the decline in public trust in AI and the surveillance state, while another user suggests that the focus should be on legislation to address the problem. Finally, there is a mention of the shift in public attention towards other pressing issues such as domestic terrorism, child trafficking, and party affiliations.

---

## AI Submissions for Mon Jul 17 2023 {{ 'date': '2023-07-17T17:10:09.755Z' }}

### Computer memory prototype ditches 1s and 0s for denser data storage

#### [Submission URL](https://newatlas.com/electronics/computer-memory-resistive-switching-denser-data-storage/) | 91 points | by [DamnInteresting](https://news.ycombinator.com/user?id=DamnInteresting) | [97 comments](https://news.ycombinator.com/item?id=36763758)

Scientists at Cambridge University have developed a prototype for a new form of computer memory that could potentially hold up to 100 times more data than current technology. The memory system is based on resistive switching memory, which allows for a continuous range of states, rather than just the traditional "one" or "zero" encoding. The prototype uses barium bridges between thin films of a disordered material, allowing for a broad spectrum of electrical resistance differences to store data. The material used, hafnium oxide, is already widely used in the semiconductor industry, making it easier to incorporate into existing manufacturing techniques. The researchers believe that this new form of memory could have applications in the fields of AI and machine learning.

### A.I. (1981)

#### [Submission URL](https://www.newyorker.com/magazine/1981/12/14/a-i) | 33 points | by [lioeters](https://news.ycombinator.com/user?id=lioeters) | [8 comments](https://news.ycombinator.com/item?id=36757726)

In 1979, a computer program called BKG 9.8 played against the winner of the world backgammon championship in Monte Carlo and won the game. This victory surprised many, as existing microprocessors were not expected to provide a good game. The program, run on a large computer at Carnegie-Mellon University connected to a robot named Gammonoid, won seven out of eight games against Luigi Villa of Italy. This marked the first time a machine became a world champion in a board or card game. The article also explores the implications of machines evolving to produce outputs that are indistinguishable from those of humans. Marvin Minsky, a prominent figure in artificial intelligence, comments on the illusion of free will and highlights that when intelligent machines are created, they may also grapple with questions of consciousness and free will.

The discussion on Hacker News about the submission seems to revolve around a few key points. 

One user, "ltrs," suggests that personal computers have come a long way in terms of advanced computer languages, and they argue that the programs created by individual programmers for personal computers can be considered informal examples of artificial intelligence programs. They further explain that professional programmers often describe a program's process using informal terms, such as showing program-writing programs. 

Another user, "krmkz," humorously comments that after checkers and chess, backgammon becoming a machine world champion is not surprising and expects more advancements in the near future, possibly in games that require more technical reasoning and quantification.

User "jhbdgr" finds it a good reminder that relatively recently, board games have been considered significant topics in AI research, mentioning the famous match between Deep Blue and Kasparov in 1997.

Another user, "Affric," finds it thought-provoking and wonders if AI programs are considered complex adaptive systems that exchange information in an anthropomorphized manner. They suggest that more recent technologies partially play board games by violating the position-pruning model accordingly.

"tncnv" adds that when discussing AI, it doesn't refer to specific algorithms, but rather to a whole family of algorithms.

User "siva7" expresses their lack of impression, saying that it doesn't impress people anymore when compared to recent advancements in AI.

Overall, the discussion seems to touch on the capabilities of personal computers, the progress of AI in board games, the significance of board games in AI research, and the differentiation between AI algorithms and their broader family.

### Incumbents vs. Startups in the AI Race

#### [Submission URL](https://blog.autopilot.fund/incumbents-vs-startups-in-the-ai-race/) | 30 points | by [mooreds](https://news.ycombinator.com/user?id=mooreds) | [13 comments](https://news.ycombinator.com/item?id=36764749)

In today's digest, we explore the ongoing race between incumbent players and startups in the AI industry. Alex Rampell from a16z highlights the battle, stating that it ultimately comes down to whether the startup can gain distribution before the incumbent achieves innovation. Incumbents possess the resources and manpower to replicate startups' offerings, but they often struggle with bureaucratic processes and resistance to change, impeding innovation. Startups, on the other hand, have agility on their side. They can swiftly make decisions and bring products to market but lack the capital and established customer base that incumbents possess. However, their speed becomes crucial in a fast-moving environment. But what happens when incumbents accelerate their pace? Matt Turk from FirstMark explains that big tech incumbents, such as Adobe and Microsoft, rapidly deployed AI, rendering many generative AI design startups obsolete. The combination of fast execution and extensive distribution becomes a significant challenge for startups. Furthermore, AI startup funding decreased in Q1 2023, potentially due to fierce competition between giants and high startup valuations. Incumbents also have an advantage in their access to large proprietary data sets, assisting in fueling AI feature growth. To compete, startups can focus on unsolved problems in specific verticals or leverage unique customer-generated data produced on their platforms. The Autopilot Fund is interested in hearing from founders building exciting solutions that leverage unique data and new AI tools to automate workflows.

The discussion on this submission revolves around various aspects of the AI industry and the challenges faced by startups in competing with incumbents.

- One user points out that the article spends 90% of the time asking questions and making broad statements without providing concrete answers or insights.
- Another user expresses concern that the article simplifies the competition between startups and incumbents, stating that innovation in the AI space mostly happens within large companies. They believe that it is the small teams within these companies that take risks and build groundbreaking things, rather than startups.
- A user highlights that startups typically focus on building a tiny portion of a product, while incumbents have the resources to directly compete. They also mention that adopting AI is relatively easy for incumbents and greatly improves their core products, making it challenging for startups in the environment.
- A user argues that real results can only be achieved through meticulous implementation, pointing out that sometimes mundane technology, when widely implemented, can have a significant impact.
- The possibility of some startups merely riding the hype wave to secure funding is brought up, suggesting that true success in the AI space is difficult to achieve for companies trying to profit in the current environment.
- There is a discussion about the legality of building AI with gaming frameworks, with one user stating that certain gaming frameworks strictly prohibit using them for AI training. Another user emphasizes that the legality doesn't matter as long as the technology is effective.
- The importance of leveraging customer-generated data produced on platforms is mentioned as a way for startups to compete with incumbents.

Overall, the discussion highlights different perspectives on the challenges faced by startups in the AI industry and the role of incumbents in driving innovation.

### Wikipedia-grounded chatbot “outperforms all baselines” on factual accuracy

#### [Submission URL](https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2023-07-17/Recent_research) | 227 points | by [akolbe](https://news.ycombinator.com/user?id=akolbe) | [175 comments](https://news.ycombinator.com/item?id=36757520)

A recent academic research paper has found that a Wikipedia-grounded chatbot outperforms all other baselines when it comes to factual accuracy. The study analyzed the role of open access in Wikipedia's citation patterns and found that open-access articles are increasingly more cited on the platform. The researchers also discovered that open-access articles have a 15% higher likelihood of being cited compared to closed-access articles. This is particularly true for articles with low citation counts, indicating that open access plays a key role in disseminating scientific knowledge and providing timely access to novel results for Wikipedia editors. However, the study raises questions about the reliability of sources used by Wikipedians and the impact of open access on the seriousness of Wikipedia sources. The research also acknowledges limitations, such as the need to control for academic discipline and consider the age and number of citations of research articles at the time they are cited on Wikipedia. While the study is not yet solid enough to be directly cited on Wikipedia, it signals important research in progress that could lead to interesting insights for the Wikipedia community.

The discussion on the submission revolves around various aspects related to Wikipedia and the study mentioned in the summary. Some users discuss the reliability of sources used by Wikipedia, with one user pointing out the arbitrary double standards in applying reliability criteria. Others discuss the potential biases in conservative sources and the need to consider the divergent realities reflected in modern conservatism. There is also a discussion about the potential consequences of using large models like Chat-GPT to modify Wikipedia content, with concerns raised about the unpredictability of the modifications. The availability of Wikipedia snapshots and archives is mentioned, and there is a brief mention of the challenges in accessing translated articles in local languages. Overall, the discussion touches on issues related to source reliability, biases, content moderation, and the practicality of using large language models in Wikipedia.

### AI watches millions of cars and tells cops if you’re driving like a criminal

#### [Submission URL](https://www.forbes.com/sites/thomasbrewster/2023/07/17/license-plate-reader-ai-criminal/) | 77 points | by [thehoff](https://news.ycombinator.com/user?id=thehoff) | [89 comments](https://news.ycombinator.com/item?id=36764389)

An AI-powered policing tool has come under scrutiny after it identified a gray Chevrolet as a possible criminal vehicle in a drug trafficking case in New York. The AI analyzed the driving patterns of the car using a database of 1.6 billion license plate records and determined that it was following routes known to be used by drug traffickers. The car was subsequently pulled over and a search led to the discovery of crack cocaine, a pistol, and a large amount of cash. The case highlights the potential constitutional issues that come with AI-powered policing, as there was no judicial oversight in this instance. The AI tool used in the case was developed by Rekor, which has sold its automatic license plate recognition (ALPR) technology to numerous police departments across the US. Privacy advocates are concerned about the scale of surveillance and the lack of oversight in these systems.

- User "tmrd" argues that the AI system operates on the assumption that certain locations are visited by criminals, which they claim is unfair.

- User "spprtngnr" mentions that the AI system is designed to support law enforcement and that any potential flaws should be addressed through improvements in the technology.

---

## AI Submissions for Sun Jul 16 2023 {{ 'date': '2023-07-16T17:10:34.673Z' }}

### Forth: The programming language that writes itself: The Web Page

#### [Submission URL](http://ratfactor.com/forth/the_programming_language_that_writes_itself.html) | 267 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [80 comments](https://news.ycombinator.com/item?id=36748043)

A programmer shares their personal journey of discovering Forth, a programming language known for its simplicity and flexibility. They recount the legends and tales they heard about Forth and its creator, Chuck Moore. The article delves into the concept of Reverse Polish Notation (RPN), a distinguishing feature of Forth, and its efficiency in expressing nested expressions without using parentheses. The author concludes with their own exploration of Forth and the magic it allows them to perform with integers.

In the discussion on Hacker News, there are various comments discussing different aspects of Forth and its capabilities. One commenter shares a link to their Forth project, highlighting the flexibility and fun they had building with Forth. Another person talks about using Forth for their final project in a computer architecture class and how it allowed them to implement a Forth-like language. There is also a discussion about the relationship between Forth and PostScript and the ability to customize and extend Forth's syntax. 

Someone shares their experience of writing a Forth compiler for the ZX81 and notes the efficiency and speed of Forth. Another commenter wonders why other programming languages do not allow defining functions as easily as Forth does. The discussion moves on to the simplicity of Forth's syntax and its advantages over other languages.  Some comments discuss the similarities between Forth and Lisp in terms of extensibility and customization. One person remarks on the imagination required to embrace Forth's syntax and argues that customizable languages like Forth and Lisp are useful for certain tasks. Another commenter points out that Forth's simplicity and efficient implementation make it faster than other languages, such as Unix shell syntax. 

### WebGPU – All of the cores, none of the canvas

#### [Submission URL](https://surma.dev/things/webgpu/) | 104 points | by [pythops](https://news.ycombinator.com/user?id=pythops) | [50 comments](https://news.ycombinator.com/item?id=36751307)

WebGPU is an upcoming Web API that provides low-level access to GPUs. The author of this post shares their experience with learning and using WebGPU, comparing it to WebGL, which has been the primary API for accessing GPUs on the web until now. The author admits to not being very experienced with graphics but found WebGL to be challenging due to its design and the need to manage an internal global state object. They struggled with understanding the order of API calls and building abstractions on top of WebGL. WebGPU, on the other hand, seemed more comfortable for the author. It was designed to be more low-level and provides access to the raw computing power of GPUs. The author clarifies that they won't be using WebGPU for generating graphics but rather for leveraging the GPU's computational capabilities. The post goes on to explain the limitations of WebGL when it comes to general-purpose GPU (GPGPU) calculations and introduces WebGPU as a solution. WebGPU is part of a new generation of graphics APIs that are more low-level and accommodate modern use cases and constraints. It aims to bring the capabilities of APIs like Vulkan, Metal, and DirectX 12 to the web. Unlike WebGL, WebGPU introduces its own abstractions and doesn't directly mirror native APIs. This allows it to be more web-friendly and to sit on top of different native graphics APIs while abstracting their specific characteristics. Overall, the author's goal is to make WebGPU accessible for web developers and share their learnings while exploring the API. They acknowledge that they may not cover every aspect of efficiency and performance but hope to provide a solid understanding of how to effectively use WebGPU.

### Penrose 3.0

#### [Submission URL](https://penrose.cs.cmu.edu/blog/v3) | 229 points | by [sestep](https://news.ycombinator.com/user?id=sestep) | [40 comments](https://news.ycombinator.com/item?id=36746047)

The Penrose team has just announced the release of Penrose 3.0, featuring new diagrams, an improved API, and enhanced support for complex geometric queries. Penrose is a powerful tool for creating beautiful diagrams in the fields of science, mathematics, and engineering. In this release, they have added new diagrams to their repository and introduced a new gallery page on their website. One notable addition is a tutorial by Keenan Crane, which is the first LaTeX document created with Penrose. The release also includes an ergonomic API for easier integration with other programs. They have simplified the programmatic API to make it more user-friendly. Additionally, Penrose now supports geometry queries and curve support, allowing users to perform powerful graphics functions. The team has made several other improvements as well, which can be found in their changelog. They invite everyone to join their Discord community, share their Penrose diagrams, and contribute to the development of Penrose on GitHub. Happy diagramming!

The discussion on Hacker News about the Penrose 3.0 release has covered various topics related to the project. Some users appreciated the announcement post and mentioned that it followed a common pattern seen in software release announcements. Others suggested that the project name is confusing and questioned its justification for using the name "Penrose." There were also discussions about using Penrose with LaTeX and TikZ, with users pointing out the advantages and possible integration options. Some users mentioned the difficulty of integrating Penrose with other programming languages and platforms, such as Rust and TeX Live. The topic of graph styles and examples was brought up, with users expressing interest in seeing directed cyclic graphs and discussing the use of Substance to modify graph layouts. There was a mention of uBlock causing issues with the Penrose examples, and users followed up on this by investigating the problem and suggesting ways to address it. A user expressed confusion about following a tutorial and not seeing any content, while others explained that the blog page may have been updated since the post was made. The announcement generated excitement among users, and the Penrose team was commended for adding new diagrams and improving the API. Some users suggested focusing on drawing system diagrams and relationships. Overall, the discussion was constructive and touched on various aspects of the Penrose project, including its capabilities, integration options, documentation, and user experience.

### WormGPT – The Generative AI Tool Cybercriminals Are Using

#### [Submission URL](https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/) | 163 points | by [mikpanko](https://news.ycombinator.com/user?id=mikpanko) | [59 comments](https://news.ycombinator.com/item?id=36742725)

In a recent blog post, the emerging use of generative AI in Business Email Compromise (BEC) attacks was discussed. The post highlighted the use of generative AI models like OpenAI's ChatGPT in creating convincing fake emails personalized to the recipient to increase the chances of success for phishing or BEC attacks. The post also mentioned the emergence of specialized prompts called "jailbreaks" that manipulate AI interfaces like ChatGPT to produce harmful output. Additionally, a tool called WormGPT, designed specifically for malicious activities, was introduced. WormGPT is an AI module based on the GPTJ language model, trained on malware-related data, and capable of generating sophisticated phishing and BEC attacks. The benefits of using generative AI for BEC attacks were also discussed, including exceptional grammar and lower entry threshold for attackers. The post concluded by highlighting the importance of implementing strong preventative measures such as BEC-specific training and enhanced email verification processes to safeguard against AI-driven BEC attacks.

### How to Use AI to Do Stuff: An Opinionated Guide

#### [Submission URL](https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated) | 246 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [63 comments](https://news.ycombinator.com/item?id=36743784)

One Useful Thing is back with an opinionated guide on how to use AI to do stuff! The author, Ethan Mollick, takes us through the current state of AI, focusing on the major large language models (LLMs) available. He provides a quick reference chart summarizing the LLMs offered by different companies, including OpenAI's GPT-3.5 and GPT-4, Microsoft's Bing, Google's Bard, and Anthropic's Claude and Claude 2. Mollick then dives into the various uses of AI, starting with writing. He suggests that GPT-4, available through Bing, is currently the most capable tool for writing, but notes that Claude 2 is a close second. Both Bing and Claude 2 have free options for users. He also mentions that Microsoft Office will soon include a copilot powered by GPT, and Google Docs will integrate suggestions from Bard, which will have significant implications for writing. Mollick provides some examples of how to use AI to improve writing, including drafting various types of content and asking for suggestions or improvements. With a little practice, AI systems can be quite skilled at generating high-quality writing. This guide is a great resource for those looking to harness the power of AI in their writing endeavors. So, if you're looking for ways to level up your writing game, this opinionated guide is worth a read!

The discussion on this submission covers various topics related to the use of AI and large language models (LLMs). One user points out the importance of safety measures and governance when using LLMs as a service, emphasizing the need for clear terms in the agreement between vendors and customers. Others mention concerns about the potential misuse of LLMs and the lack of trust in large companies like OpenAI. There is a debate about data privacy and the collection of user data by AI systems. Some users express worries about potential IP theft and the ethical implications of data collection. Compliance with GDPR regulations is also discussed. One user brings up the cultural and political context of Silicon Valley, stating that it is important to consider the appropriateness of certain content and the variations in cultural norms when using AI.

The discussion also touches on the limitations and specialization of LLMs and their potential impact on fields like science, literacy, and coding. Users highlight the need for better documentation and support for tools that utilize LLMs. Some users appreciate the creative possibilities of AI-generated content, while others mention specific use cases such as transcription and audio processing. The existence of alternative AI models and APIs is also mentioned, providing more options for developers. Overall, the discussion delves into the potential benefits, risks, and ethical considerations of using AI and LLMs for various purposes.

---

## AI Submissions for Sat Jul 15 2023 {{ 'date': '2023-07-15T17:09:44.362Z' }}

### Ziplm: Gzip-Backed Language Model

#### [Submission URL](https://github.com/Futrell/ziplm) | 235 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [57 comments](https://news.ycombinator.com/item?id=36732430)

Introducing ziplm - a useless but mildly interesting language model using compressors built into Python. This model is based on the fact that there is an equivalence between probability distributions and codes. By converting code lengths to probabilities, ziplm generates text based on the compressed lengths of the input data. Although it doesn't produce perfect results, it is capable of generating somewhat recognizable text. For example, when trained on Moby Dick, ziplm produces output like "'theudcanvas. ;cm,zumhmcyoetter toauuo long a one aay,;wvbu.mvns. x the dtls and enso.;k.like bla.njv'". While it may not be the most practical language model, ziplm demonstrates the relationship between compression and language modeling.

The discussion on Hacker News around the submission "Introducing ziplm - a useless but mildly interesting language model using compressors built into Python" revolves around the concept of language modeling and compression.  One user highlights the potential applications of combining language modeling with compressors in text classification and mentions the work on compressing neural networks. Others discuss the relationship between compression and probability distributions, as well as the challenges and limitations of applying compression algorithms to language modeling tasks.  Some users share links to related papers and resources, such as a discussion on applying Fourier transforms in self-attention neural networks and a paper on parameter-free text classification using gzip.  The conversation also touches on the importance of understanding the internals of compressors and the potential for further research and improvement in the field.  Overall, the discussion highlights the intriguing connection between compression and language modeling and explores various related topics and ideas.

### AI Nursing Ethics: Viability of Robots and Artificial Intelligence in Nursing

#### [Submission URL](https://www.tus.ac.jp/en/mediarelations/archive/20230706_1542.html) | 23 points | by [rustoo](https://news.ycombinator.com/user?id=rustoo) | [12 comments](https://news.ycombinator.com/item?id=36735774)

In a recent study, researchers from Japan explored the possibility of robots and artificial intelligence (AI) replacing human nurses. While robots and AI have made significant advancements in healthcare, the study emphasized the need for careful consideration when integrating these technologies into nursing practice. The researchers examined whether robots and AI can replicate the ethical concepts attributed to nurses, such as advocacy, accountability, cooperation, and caring. While AI can inform patients about medical errors and treatment options, its ability to truly understand and empathize with patients' values and effectively navigate human relationships raised concerns. The researchers also highlighted the importance of conducting further investigations to determine the appropriate appearance of robots for efficient cooperation with human medical staff. While robots and AI have the potential to reduce the shortage of nurses and improve treatment outcomes, their deployment requires careful assessment of the ethical implications. The researchers concluded that while robots may not fully replace human nurses in the near future, further research could lead to new discoveries in ethics and the development of novel applications of robotics and AI in nursing.

The discussion revolves around the use of AI and robots in the nursing field. Some users argue that AI can prevent future shortages of nurses and improve efficiency, while others express concerns about the potential negative impacts on job quality and the market. One user brings up the concept of induced demand and the potential increase in demand for nursing services with the introduction of AI. Another user points out that AI integration into society cannot be undone and raises concerns about the potential consequences. There is also a discussion about the role of AI in other medical fields, with one user mentioning the vulnerability of pathologists and radiologists to being replaced by AI algorithms. Some users mention the possibility of AI eventually replacing humans in certain tasks, while others question the feasibility of that happening anytime soon.

### Synit – A Reactive Operating System

#### [Submission URL](https://synit.org/) | 113 points | by [gjvc](https://news.ycombinator.com/user?id=gjvc) | [35 comments](https://news.ycombinator.com/item?id=36735620)

Introducing Synit, an innovative operating system that applies pervasive reactivity and object capabilities to the System Layer. Built upon the Linux kernel, Synit replaces various familiar Linux software components with its own versions, following the principles of the Syndicated Actor Model. It incorporates concepts from both Linux and other programming languages and operating systems. Ready to give it a try? Synit can be installed on mobile phones and computers capable of running PostmarketOS, or in a virtual machine. Check out the installation instructions for a list of supported devices. For more details, refer to the Synit Manual.

The discussion around the submission of Synit, an innovative operating system, started off with a comment pointing out that the terminology used in the description is not very clear and can be confusing. The author of the submission then responded to an AMA (Ask Me Anything) request. They were asked several questions about the benefits of reactive programming, related functional reactive programming (FRP), and whether there has been any experimentation with using the Syndicated Actor Model (SAM) in real-world systems. The author provided detailed answers, explaining how SAM can be beneficial in managing concurrency and interactivity, its relationship with FRP, and their own experiences with SAM. Overall, the discussion provided a deeper understanding of the concepts and ideas behind Synit and the Syndicated Actor Model, as well as their potential applications and benefits.

### Ada Outperforms Assembly: A Case Study

#### [Submission URL](https://www2.seas.gwu.edu/~adagroup/sigada-website/lawlis.html) | 54 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [37 comments](https://news.ycombinator.com/item?id=36741990)

In a case study from 1992, a defense contractor attempted to prove that Ada programming language could not produce real-time code by writing a portion of their software in Ada. The expectation was that the resulting machine code would be too large and too slow for a communications application. However, the opposite was found to be true. The compiled Ada code was smaller and executed at approximately the same speed, if not faster, than the corresponding assembly code. This challenged the belief that assembly language was the only appropriate language for certain applications. The contractor had initially disregarded the use of Ada, despite it being required by the Department of Defense for mission critical computer resources. Despite the results of this case study, the use of Ada over assembly language was still a topic of debate in the industry at the time.

The discussion in the comments revolves around various aspects of the Ada programming language and its usage in different industries. Some comments point out that modern CPUs and instruction scheduling techniques have made assembly language less necessary, while others argue that certain industries still rely on Ada for safety-critical systems. There are also mentions of other programming languages and their suitability for different applications. Some comments discuss personal experiences with Ada, including its use in defense contractors and aerospace systems. The discussion also touches on topics such as version control systems, job opportunities for Ada programmers, and the perception of ROI (return on investment) for different programming languages.

### The shady world of Brave selling copyrighted data for AI training

#### [Submission URL](https://stackdiary.com/brave-selling-copyrighted-data-for-ai-training/) | 246 points | by [rand0mx1](https://news.ycombinator.com/user?id=rand0mx1) | [119 comments](https://news.ycombinator.com/item?id=36735777)

Brave, a privacy-focused browser, offers an API product called Data for AI, which allows users to feed AI models for inference and train them with data. However, there is a concern with copyright infringement as Brave's Data for AI API lets users ingest copyrighted material without explicit permission. The API even grants "rights" to this data, including storage rights. A comparison with Google's featured snippets shows that Brave's "extra snippets" can be quite extensive, ranging from 150 to 260 words. While search engines like Google often fall within fair use guidelines due to limited snippet lengths, Brave's usage seems to surpass fair use boundaries. It's worth noting that Brave's API response attributes the domain name but fails to follow the license requirements of the copyrighted content. Brave has clarified that they are compliant on their end, but the responsibility of attribution lies with third parties who use the data for AI models.

The discussion on this submission covers various aspects of Brave's API and the concerns surrounding copyright infringement. Some users argue that Brave's ingestion of copyrighted material for AI training goes against copyright laws and fair use guidelines. Others discuss the complexity of copyright regulations and how AI models are trained with transformed data.  There are also discussions about Brave's data collection practices and privacy features. Some users express concerns about the information Brave collects and how it is used, while others argue that Brave offers opt-in features and respects user privacy. Additional topics include comparisons between Brave and other browsers, discussions about the business model and cryptocurrency (BAT) used by Brave, and opinions on the trustworthiness of different browsers. Overall, the discussion highlights a range of viewpoints on the copyright issues surrounding Brave's API and its privacy-focused approach to browsing.

### YC offers early interviews for AI companies

#### [Submission URL](https://www.ycombinator.com/blog/early-interviews-for-ai-companies) | 49 points | by [craftsquick](https://news.ycombinator.com/user?id=craftsquick) | [71 comments](https://news.ycombinator.com/item?id=36734110)

Y Combinator, a well-known startup accelerator, has announced a special round of early interviews for AI startups. As investors in several successful AI startups, including OpenAI, Y Combinator is offering a limited number of early interview slots for the YC W24 batch. Accepted AI startups will receive advice and expertise from YC partners, as well as access to the YC AI network, which includes founders from notable companies such as OpenAI, Cruise, Scale AI, and more. The deadline to apply for these early interviews is Tuesday, July 18, 2023, and interviews will be conducted on Friday, July 21. Successful applicants will receive YC's standard investment of $500,000, plus additional free credits from leading software companies, totaling over $1 million. Startups whose core product does not revolve around AI can still apply to YC at any time. Those accepted in the early decision process can start the investment process immediately and participate in YC events and meetups.

Discussion:

1. The discussion starts with a comment questioning the timing of investing in AI startups, comparing it to the dot-com bubble of the early 2000s. The comment suggests that investing in AI startups may be risky and that winners are uncertain. Another comment agrees, emphasizing that investing in AI startups is risky and that technology can displace early winners.
2. A reply to the previous comments argues that the total addressable market (TAM) proposition is key in determining the potential success of a specific technology. It gives examples of how different technology products, like books and supplies, have varying TAMs.
3. The discussion then shifts to a debate about Amazon and whether its success was due to its focus on selling books during the early days of the internet boom. One commenter rationalizes Amazon's strategy by noting that it diversified its revenue streams through Amazon Web Services (AWS) and software.
4. The conversation turns to OpenAI and its existing products. A comment mentions the high retention rate of OpenAI's API-based product and highlights the complexities introduced by the use of OpenAI's models in various applications.
5. Another comment shares the success of using OpenAI's API-based product for SaaS functionality, generating significant annual recurring revenue (ARR).
6. A brief exchange occurs regarding the profit margins of ChatGPT and the integration of various technologies to improve efficiency.
7. The discussion then veers off-topic briefly when a participant asks what a specific service is.
8. A comment points out that investors tend to focus on trendy technologies and founders, suggesting that they should prioritize solving significant problems instead.
9. The conversation delves into a discussion about the Y Combinator application process and past instances where YC selected applications based on specific sectors or ideas.
10. A final comment suggests that VCs should prioritize larger profits instead of focusing solely on startups.

Overall, the discussion covers a range of topics, including the risks of investing in AI startups, the success of Amazon and OpenAI, and the application process for Y Combinator.

---

## AI Submissions for Fri Jul 14 2023 {{ 'date': '2023-07-14T17:09:55.792Z' }}

### Tinygrad and rusticl and aco: why not?

#### [Submission URL](https://airlied.blogspot.com/2023/07/tinygrad-rusticl-aco-why-not.html) | 34 points | by [pantalaimon](https://news.ycombinator.com/user?id=pantalaimon) | [25 comments](https://news.ycombinator.com/item?id=36722158)

In a recent blog post, a developer shared their experience working with tinygrad, rusticl, and ACO. They started by running tinygrad on their Radeon 6700XT using rusticl with the LLVM backend and found that it could successfully run an LLM model. The developer then decided to experiment with the Mesa ACO compiler backend and compared the performance to LLVM. They found that ACO was about four times faster to compile but produced less optimized binaries. The benchmark results showed that the LLVM backend had better performance in terms of runtime and GFLOPS. The developer mentioned that they plan to investigate ROCm in the future but are currently dealing with a cold/flu.

The discussion on the submission revolves around various topics related to NixOS, tinygrad, ACO, MLIR, and Rusticl.

- Users discuss the pros and cons of using NixOS for machine learning environments, with some praising its declarative configuration and others highlighting potential challenges with managing dependencies and complexity.
- Regarding tinygrad, there is a debate about its validity and whether it is a worthwhile project. Some express skepticism and question its benchmarks, while others appreciate its simplicity and ease of installation.
- MLIR and Rusticl are also discussed. Some users comment on the increasing popularity of MLIR-based middle-layer frameworks. Rusticl's hidden positive points are mentioned, and there is interest in exploring distributions with better hardware support.
- The ACO (AMD Compiler) and Mesa OpenCL driver are mentioned, with discussions about their compatibility and performance on different hardware and Linux distributions. There are some questions about specific APUs and their OpenCL support.
Overall, the discussion includes a mix of technical insights, opinions, and experiences related to the various technologies and projects being discussed.

### Meta to release open-source commercial AI model

#### [Submission URL](https://www.zdnet.com/article/meta-to-release-open-source-commercial-ai-model-to-compete-with-openai-and-google/) | 169 points | by [maskil](https://news.ycombinator.com/user?id=maskil) | [157 comments](https://news.ycombinator.com/item?id=36724739)

Meta, formerly known as Facebook, is gearing up to release a commercial version of its open-source large language model (LLM), LLaMA. LLaMA can generate text, images, and code using artificial intelligence (AI). The commercial release of LLaMA will enable developers and businesses to build applications using the foundational model, leading to accelerated technological innovation across various sectors. Meta's LLaMA comes in different sizes, ranging from 7 billion parameters to 65 billion parameters, surpassing OpenAI's GPT-3.5, which has 175 billion parameters. OpenAI and Google are Meta's main competitors in the AI space, and with the release of LLaMA, Meta hopes to make significant advancements in the field while addressing concerns about transparency and security associated with closed or proprietary software.

### Pulling my site from Google over AI training

#### [Submission URL](https://tracydurnell.com/2023/07/11/pulling-my-site-from-google-over-ai-training/) | 46 points | by [headalgorithm](https://news.ycombinator.com/user?id=headalgorithm) | [90 comments](https://news.ycombinator.com/item?id=36727384)

Tracy Durnell, a writer and designer in Seattle, has decided to de-index her website from Google in protest against the company using the content posted on the internet to train their generative AI models. She was influenced by posts from Jeremy Keith and Vasilis van Gemert. Although Tracy admits that she doesn't know how much search traffic her website receives, she's willing to sacrifice it for her beliefs. Tracy plans to start by pulling her websites out of Google search and then work on adding her sites to directories. She has added a noindex meta tag to her WordPress header and created a robots.txt file to block bots that collect training data for AI models. Tracy's decision highlights the ethical concerns surrounding AI training with user-generated content.

The discussion surrounding Tracy Durnell's decision to de-index her website from Google in protest against the company's use of user-generated content for training AI models is varied. Some users argue that reproducing content without permission is plagiarism and a breach of copyright, while others point out that machine learning and human learning operate under different principles and assumptions. There is a debate about the subjective nature of plagiarism and copyright law, and the potential consequences of AI training. Some users argue that AI cannot perform tasks at the speed and volume of humans and will never fully replicate human capabilities, while others believe that AI will continue to evolve and may have significant consequences. There are discussions about alternative search engines, the effectiveness of blocking bots with a robots.txt file, and the role of directories and webrings in web search. Some users highlight the challenges of determining what is legal or illegal, while others argue that the legality of certain actions does not make them right or wrong.

### Meta introduces CM3leon, a more efficient image generation model

#### [Submission URL](https://ai.meta.com/blog/generative-ai-text-images-cm3leon/) | 28 points | by [envy2](https://news.ycombinator.com/user?id=envy2) | [3 comments](https://news.ycombinator.com/item?id=36723886)

CM3leon is a state-of-the-art generative AI model that can generate both text and images. It is the first multimodal model trained with a recipe adapted from text-only language models, using a combination of retrieval-augmented pre-training and multitask supervised fine-tuning. Despite being trained with five times less compute, CM3leon achieves state-of-the-art performance in text-to-image generation. One of the key advantages of CM3leon is its versatility. Unlike previous models that could only generate either text or images, CM3leon can generate sequences of text and images conditioned on other image and text content. This expands its functionality and makes it more powerful. CM3leon also excels in tasks such as image caption generation, visual question answering, text-based editing, and conditional image generation. It outperforms Google's text-to-image model and achieves an FID score of 4.88 on the widely used image generation benchmark, establishing a new state of the art. The model demonstrates an impressive ability to generate complex compositional objects and performs well across a variety of vision-language tasks.

---

## AI Submissions for Thu Jul 13 2023 {{ 'date': '2023-07-13T17:10:33.382Z' }}

### Show HN: Free AI-based music demixing in the browser

#### [Submission URL](https://sevag.xyz/free-music-demixer/) | 178 points | by [sevagh](https://news.ycombinator.com/user?id=sevagh) | [43 comments](https://news.ycombinator.com/item?id=36707877)

Sevag H has developed a free AI-based music demixing web app that allows users to decompose songs into various components like bass, drums, vocals, and more. Powered by the Open-Unmix AI model with the UMX-L pretrained weights, the app runs locally in the user's browser, ensuring data privacy as no files are uploaded. The app works well on computers but may run slowly on smartphones. Users can try out the demo using a free song by Jaxius Music or upload their own music files to use the demixer. The app comes with disclaimers regarding non-commercial usage and the CPU and memory requirements of the task. The app's technical details include the use of C++ and Eigen3 for inference code, Emscripten for WebAssembly compilation, and compressed model weights. The project is available on GitHub for those interested in the source code.

### FTC investigating ChatGPT over potential consumer harm

#### [Submission URL](https://www.npr.org/2023/07/13/1187532997/ftc-investigating-chatgpt-over-potential-consumer-harm) | 132 points | by [cratermoon](https://news.ycombinator.com/user?id=cratermoon) | [130 comments](https://news.ycombinator.com/item?id=36717593)

The Federal Trade Commission (FTC) is investigating OpenAI's popular chatbot, ChatGPT, over concerns that it may have generated incorrect information about users, potentially leading to consumer harm. The investigation also includes an examination of OpenAI's privacy and data security practices. The FTC has requested that OpenAI provide documentation on various issues, including company policies, financial earnings, and details about the large language models used to train ChatGPT. OpenAI CEO Sam Altman responded on Twitter, expressing disappointment at the leak and affirming the company's commitment to ensuring the safety and pro-consumer nature of its technology. This investigation marks a milestone in government regulatory action concerning the AI industry. OpenAI has previously advocated for AI regulation and engaged with lawmakers and government officials on the matter.

The discussion on Hacker News about the FTC investigation into OpenAI's ChatGPT was varied and encompassed several topics. Some comments focused on the potential implications of AI regulation and the power dynamics in the industry. One commenter noted the possibility of OpenAI being granted a monopoly if Sam Altman's strategy succeeds. Others pointed out that other companies are rapidly catching up to OpenAI in terms of AI models and capabilities. Some users expressed skepticism about Altman's statements and motives, suggesting that he may be playing a political game or focusing on marketing rather than addressing the concerns about ChatGPT. There was also discussion about the limitations and dangers of AI, with comments mentioning the requirements for competition and potential theoretical roadblocks. The intellectual property aspect was also brought up, with one user mentioning the potential value of intellectual property in the future and another user sharing a presentation by Yann LeCun on the path to AGI. Some commenters emphasized the need for caution and highlighted the risks associated with machine intelligence.

### Ory Kratos v1.0 with passkeys, MFA and multi-region

#### [Submission URL](https://github.com/ory/kratos/releases/tag/v1.0.0) | 145 points | by [gvusfraber](https://news.ycombinator.com/user?id=gvusfraber) | [41 comments](https://news.ycombinator.com/item?id=36708907)

Ory Kratos, the powerful Identity, User Management, and Authentication system, has released version 1.0. This major update brings a host of enhancements and fixes, improving the user experience and overall performance. Ory Kratos is now stable and robust, with over 100 million API requests processed daily and about 100 million Docker Pulls. Notable changes in version 1.0 include support for social login and single-sign-on via OpenID connect in native apps, emails sent through HTTP instead of SMTP, and full compatibility with Ory Hydra v2.2.0. Other additions include multi-region support in the Ory Network for broader geographic reach, improved export functionality for all credential types, and enhanced session management using the "provider ID" parameter. The release also introduces distroless images for leaner resource utilization and faster deployment, as well as support for the Lark OIDC provider. Feedback and support for Ory Kratos 1.0 are greatly appreciated, and organizations can upgrade their self-hosted solution through Ory's dedicated support services. The Ory Community, which has been instrumental in reaching this milestone, is encouraged to continue contributing to the project.

### Sag-AFTRA President: “we're in jeopardy of being replaced by machines”

#### [Submission URL](https://deadline.com/2023/07/sag-aftra-fran-drescher-were-being-victimized-by-a-greedy-entity-1235437292/) | 17 points | by [ericzawo](https://news.ycombinator.com/user?id=ericzawo) | [13 comments](https://news.ycombinator.com/item?id=36716506)

In a press conference yesterday, SAG-AFTRA President Fran Drescher and National Executive Director Duncan Crabtree-Ireland announced that the actors' strike is expected to last for a while. Drescher gave an impassioned speech, saying that they had no choice but to strike due to being victimized by a "very greedy entity." She expressed shock at the way studio executives are treating actors and stated that if they don't stand tall now, they will be in jeopardy of being replaced by machines and big business. The AMPTP's strategy for the writers' strike is to keep it going until October when scribes would run out of money. Drescher criticized this approach as "cruel but necessary evil." Both Drescher and Crabtree-Ireland expressed disappointment in the lack of an acceptable deal, with Crabtree-Ireland highlighting how the current streaming model has undercut performers' residual incomes. Despite these challenges, they expressed solidarity among SAG-AFTRA members and their resolve to fight for the future of their careers. They also mentioned being open to negotiations with the AMPTP. The strike officially commenced today, with picketing scheduled to take place at Netflix, Paramount, Warner Bros. Discovery, and Disney.

---

## AI Submissions for Tue Jul 11 2023 {{ 'date': '2023-07-11T17:11:29.312Z' }}

### Classifying customer messages with LLMs vs traditional ML

#### [Submission URL](https://www.trygloo.com/blog/classify-text-llms-learnings) | 248 points | by [hellovai](https://news.ycombinator.com/user?id=hellovai) | [111 comments](https://news.ycombinator.com/item?id=36681839)

A recent post on Hacker News shared five key learnings from classifying 500k customer messages using Language Models (LLMs) compared to traditional Machine Learning (ML) techniques. The first learning emphasized that LLMs tend to prefer generating some output rather than none, leading to false-positives. To address this, the authors added a catch-all class like "other" to account for this tendency. 

The second learning highlighted the usefulness of tracking hallucinations, which are instances where the LLMs generate labels that are not present in the prompt. By analyzing these hallucinations, the authors found that simple and direct class names improved accuracy. They noted ongoing research regarding replacing class names with symbols to avoid bias towards using the class names themselves. The third learning emphasized the cost and latency advantages of using fine-tuned classification models in combination with LLMs. In one instance, a customer required lower-latency processing, so the authors trained Sentence-BERT (SBERT) using ChatGPT-labeled data. This approach achieved 85% parity with ChatGPT and over 90% accuracy on a subset of classes.

The fourth learning described "prompt engineering" as a well-known technique to enhance accuracy in text classification. By prompting the LLM to extract relevant clues before classification, state-of-the-art accuracy (96%+) can be achieved. The fifth learning stressed the importance of standardizing input for both fine-tuned models and LLMs. Longer text inputs can lead to less accurate predictions. To address this, the authors applied a preprocessing step to paraphrase the last user message with the previous context, particularly for multi-context chat messages, emails, long documents, and non-English messages.

The discussion on the Hacker News post includes various points and perspectives on the topic of using Language Models (LLMs) for text classification. Here are the key points that were discussed:

- Some users mentioned the use of keyword-based approaches or TF-IDF vectors for text classification, pointing out that the technique described in the post seemed to be categorizing and extracting semantic meaning from the text.
- Others noted that LLMs can be slower than traditional machine learning models and can be resource-intensive, especially when trained on large datasets.
- The topic of sentence embeddings and text embeddings was brought up, with some users expressing difficulty in understanding the underlying mathematics and concepts.
- A comparison was made between LLMs and attention algorithms, noting that they both have similar mechanisms.
- The relevance of the discussion to zero-shot learning was mentioned, with some users pointing out that although the technique described in the post is related, it is not exactly the same as zero-shot learning.
- The potential applications of LLMs in various domains and their ability to create novel solutions were discussed.
- Some users expressed skepticism and questioned the accuracy and reliability of LLMs for text classification tasks.

Overall, the discussion provided a mix of opinions and insights into the topic, with users sharing their experiences and raising interesting points for further exploration.

### PhotoPrism: AI-powered photos app for the decentralized web

#### [Submission URL](https://github.com/photoprism/photoprism) | 316 points | by [pretext](https://news.ycombinator.com/user?id=pretext) | [163 comments](https://news.ycombinator.com/item?id=36679368)

Introducing PhotoPrism: an AI-powered photos app for the decentralized web. This app uses the latest technologies to automatically tag and find pictures, making it easy for users to organize and access their photo collections. Whether you want to run it at home, on a private server, or in the cloud, PhotoPrism offers a user-friendly and privacy-focused solution. With features like browsing all your photos and videos, powerful search filters, and facial recognition for easy identification of family and friends, PhotoPrism is designed to meet your photo management needs. Check out their public demo to get a taste of what PhotoPrism can do!

The discussion on this submission revolves around various aspects of PhotoPrism, the AI-powered photos app for the decentralized web. Some users discuss the pricing plans and features offered by PhotoPrism, with one user mentioning the high cost of the Plus plan and suggesting alternatives like PhotoSync and Nextcloud. There is also a discussion on deduplicating photos, with users sharing different approaches such as SHA-based deduplication and using ExifTool to generate content hashes. The topic of AI identifying similarities in images and the benefits of deduplication are also discussed. Other users mention alternative software options and their personal experiences with similar projects. Some users discuss the technical challenges of deploying PhotoPrism, particularly when using Docker. Overall, the discussion provides insights into the features and possibilities of PhotoPrism, as well as alternative options and considerations for managing photo collections.

### GPT-Prompt-Engineer

#### [Submission URL](https://github.com/mshumer/gpt-prompt-engineer) | 336 points | by [sturza](https://news.ycombinator.com/user?id=sturza) | [152 comments](https://news.ycombinator.com/item?id=36677034)

Introducing gpt-prompt-engineer: a tool that takes prompt engineering to a whole new level. This tool leverages GPT-4 and GPT-3.5-Turbo to generate and test a variety of prompts based on a provided use-case and test cases. It then ranks the prompts using an ELO rating system to determine the most effective ones. Whether you're looking for a landing page headline or evaluating the sentiment of a prompt, gpt-prompt-engineer has got you covered. Give it a try and see how it can supercharge your prompt engineering process!

The discussion surrounding the submission revolves around various aspects of prompt engineering and the use of GPT-4. Some users express skepticism towards benchmarking and evaluating generated prompts, arguing that the performance of GPT-4 should be tested based on real-world applications rather than arbitrary prompts. Others mention existing tools and projects that focus on prompt engineering and evaluation. There is a debate about the correlation between GPT-4 and human evaluators, with some expressing discomfort over the idea that GPT-4 may outperform human evaluators on various tasks. Related to this, there is a discussion about the limitations and biases of GPT-4 and the need for proper validation and testing metrics. A few comments touch on the potential benefits of prompt engineering, such as improved communication and avoiding misunderstandings. Others question the effectiveness of prompt engineering, suggesting that it may not always lead to reliable results or solve certain problems. Overall, the discussion touches on the challenges, limitations, and potential merits of prompt engineering in the context of GPT-4. Users share different perspectives and raise valid points related to the topic.

---

## AI Submissions for Mon Jul 10 2023 {{ 'date': '2023-07-10T17:09:55.954Z' }}

### Hybrid Insect Micro-Electro-Mechanical Systems (Hi-MEMS)

#### [Submission URL](https://en.wikipedia.org/wiki/Hybrid_Insect_Micro-Electro-Mechanical_Systems) | 29 points | by [pyinstallwoes](https://news.ycombinator.com/user?id=pyinstallwoes) | [6 comments](https://news.ycombinator.com/item?id=36664372)

The Pentagon is working on a project called Hybrid Insect Micro-Electro-Mechanical Systems (HI-MEMS), which involves implanting micro-mechanical systems into insects during their early stages of metamorphosis. The goal is to create "insect cyborgs" that can be controlled remotely through electrical impulses sent to their muscles. The primary application for these cyborg insects is surveillance. The project aims to develop insects that can reach a target located 100 meters away, starting from a distance of 5 meters. So far, researchers have demonstrated the successful implantation of electronic probes into tobacco hornworms and the flight capabilities of a cyborg unicorn beetle. With this technology, the military could potentially deploy these insect spies for reconnaissance purposes.

The comments on Hacker News start with some initial reactions to the news. One user expresses their surprise about the project, while another makes a joke about the integration of bugs into the military. Another user provides an alternative acronym for the project, suggesting that the "MEMS" part could stand for "Micro-Electro-Mechanical-Bio-Entomo Robot MEMBER," adding a humorous twist to the discussion.  One user makes a somewhat sarcastic comment pointing out how interesting it is that the military is funding such projects. They go on to mention that the idea seems straight out of a science fiction novel.  Another user joins in with the humor, mentioning the Fifth Element movie which includes a scene with robotic cockroaches. A final comment with a pun is made about the "Multipass" concept from the same movie.  Overall, the discussion mainly revolves around amusement and jokes related to the concept of insect cyborgs being used for military purposes.

### Apple VisionOS Simulator streaming wirelessly to Meta Quest headset

#### [Submission URL](https://github.com/zhuowei/VisionOSStereoScreenshots/tree/alvr) | 395 points | by [ozten](https://news.ycombinator.com/user?id=ozten) | [224 comments](https://news.ycombinator.com/item?id=36668732)

The top story on Hacker News today is about a project called VisionOSStereoScreenshots. Created by a developer named Zhuowei, this project allows users to take 3D stereoscopic screenshots in the visionOS emulator. It has gained a lot of attention, with 259 stars and 9 forks on GitHub. The project involves streaming the visionOS Simulator wirelessly to a Meta Quest headset using ALVR (a cross-platform VR streaming system). While the project is still a work in progress, it has already made significant progress in enabling wireless streaming and is looking to add features such as passthrough and support for Quest controllers in the future. The developer credits @ShinyQuagsire for pioneering the wired Quest Link version of the tool and helping with the wireless port, as well as @JJTech and @keithahern for their contributions in figuring out input handling in the visionOS Simulator. This project is an exciting development for VR enthusiasts and developers alike.

### OpenAI says it could ‘cease operating’ in the EU

#### [Submission URL](https://www.theverge.com/2023/5/25/23737116/openai-ai-regulation-eu-ai-act-cease-operating) | 24 points | by [pimeys](https://news.ycombinator.com/user?id=pimeys) | [6 comments](https://news.ycombinator.com/item?id=36674187)

OpenAI has stated that it may stop operating in the European Union (EU) if it cannot comply with future AI regulations. The EU is currently finalizing new legislation called the AI Act, which would require companies like OpenAI to disclose information about their training methods and data sources. OpenAI CEO Sam Altman has expressed concerns about the Act, particularly the designation of systems like OpenAI's ChatGPT as "high risk", which would subject them to safety and transparency requirements. Altman later clarified that OpenAI has no plans to leave Europe, but the company does have concerns about meeting the requirements of the AI Act. In addition to technical challenges, the Act also poses potential business threats to OpenAI, such as the disclosure of copyrighted data used for training its AI models. Altman's comments shed light on OpenAI's perspective on regulation and its desire for it to primarily apply to future AI systems.

### That Google memo about having ‘no moat’ in AI was real

#### [Submission URL](https://www.theverge.com/2023/7/10/23790132/google-memo-moat-ai-leak-demis-hassabis) | 29 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [11 comments](https://news.ycombinator.com/item?id=36672274)

A leaked memo from a Google researcher suggested that the company has "no moat" in the AI industry, stating that open-source AI models are outpacing Google. In an interview with The Verge, Demis Hassabis, CEO of Google's DeepMind, confirmed the authenticity of the memo but disagreed with its conclusions. Hassabis expressed confidence in Google's future in AI, citing the competitive nature of the company's researchers and the potential for breakthroughs from the newly merged Google Brain and Google DeepMind teams.

The discussion around the leaked memo from a Google researcher and Demis Hassabis' response to it centers on whether Google truly lacks a competitive advantage in the AI industry. Some users argue that Google's dominance in products like Search, YouTube, and Gmail does give them an edge, while others believe that open-source AI models are rapidly advancing and pose a threat to Google's position. Some commenters also discuss the role of default settings in shaping user behavior, with one user mentioning that Google's default search engine on popular web browsers gives the company a significant advantage.

Others point out that Google's control over Android through Google Play Services also contributes to their ability to maintain influence in the AI landscape. One user highlights the importance of ongoing testing and improvement to stay competitive, particularly in tasks like creative writing and inductive reasoning. They mention the success of OpenAI's ChatGPT and the potential of Google developing an AI chatbot interface.

In response to a user suggesting trying out OpenAI's Bard chatbot, another commenter questions the true endorsement of Bard, pointing out that Google is also well-poised in this area. Overall, the discussion involves a mix of perspectives, ranging from those who believe Google has a clear advantage to those who express skepticism and highlight potential rivals.

---

## AI Submissions for Sun Jul 09 2023 {{ 'date': '2023-07-09T17:09:32.746Z' }}

### New York City’s AI hiring law takes effect

#### [Submission URL](https://qz.com/americas-first-law-regulating-ai-bias-in-hiring-takes-e-1850602243) | 99 points | by [donohoe](https://news.ycombinator.com/user?id=donohoe) | [127 comments](https://news.ycombinator.com/item?id=36654420)

New York City is set to enforce a groundbreaking law aimed at tackling bias in AI hiring tools. The law, first passed in 2021, requires employers to be transparent about their use of AI and algorithmic-based tools in the hiring process. Companies must inform candidates of their use of such tools and disclose what personal data is being collected. Additionally, the law mandates that companies undergo annual audits to identify potential bias within their AI systems. While the law is a step towards transparency, critics argue that it may not go far enough in protecting job candidates from bias. They argue that developers can find loopholes to pass or bypass audits, rendering them less effective in detecting bias. Nonetheless, the enforcement of this law is a significant move towards promoting fairness and accountability in the AI hiring process.

### Rio, a new GPU-accelerated terminat that can run natively and in the browser

#### [Submission URL](https://medium.com/@raphamorim/rio-terminal-a-native-and-web-terminal-application-powered-by-rust-webgpu-and-webassembly-76d03a8c99ed) | 33 points | by [rogerwilson](https://news.ycombinator.com/user?id=rogerwilson) | [10 comments](https://news.ycombinator.com/item?id=36656443)

Introducing Rio Terminal: a powerful native and web terminal application that is powered by Rust, WebGPU, and WebAssembly. Rio is known for its speed, thanks to its built-in Rust language and the use of the Alacritty terminal's VTE for ANSI handling and parsing. The terminal also features a minimal tabs design and supports multi-window features on various platforms including Windows, MacOS, and Linux. What sets Rio apart is its ability to run in browsers and desktop environments, making it ideal for creating plugins for cross-platform architectures. The WebAssembly version of Rio is still in progress but promises to bring the same functionality to the web. With its impressive rendering capabilities through its Sugarloaf renderer, Rio is a versatile tool for developers and users alike.