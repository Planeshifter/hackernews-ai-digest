import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Sat Oct 28 2023 {{ 'date': '2023-10-28T17:10:17.287Z' }}

### How to Think Computationally about AI, the Universe and Everything

#### [Submission URL](https://writings.stephenwolfram.com/2023/10/how-to-think-computationally-about-ai-the-universe-and-everything/) | 109 points | by [jam](https://news.ycombinator.com/user?id=jam) | [71 comments](https://news.ycombinator.com/item?id=38049774)

In a recent talk at TED AI, Stephen Wolfram discussed the concept of computation and its implications for understanding the universe. Wolfram argued that computation is not just a possible formalization of the world, but the ultimate formalization for our universe. He explained that space and matter are made up of discrete elements, and the structure of the universe is defined by the network of relations between these elements. Using computational rules, the entire universe can be built from these discrete elements. Wolfram also discussed the emergence of gravity and quantum mechanics from these computational rules, and how different observers perceive the branching paths of the universe. He introduced the concept of the "ruliad," which is the unique object that encompasses all possible computational processes. Wolfram explained that observers, like us, can only sample specific slices of the ruliad, and that our perceived laws of physics are a result of our computational limitations and our belief in persistence in time. Overall, Wolfram presented a new paradigm for understanding the universe through computation, with implications for various fields including physics, mathematics, biology, and economics.

The discussion around Stephen Wolfram's talk at TED AI seems to be divided. Some people, like "nologic01," argue that Wolfram's computational theory fails to explain the complexities of the universe and that his models do not align with modern physics. They believe that his approach lacks evidence and does not stand up to experiments. Others, like "vnb," find Wolfram's ideas intriguing and see potential connections between computation and understanding the universe, though they are unsure about the validity of his claims. There is also discussion about the limitations of computational models and the need for empirical testing. Additionally, there are comments expressing skepticism about the usefulness of Wolfram's theories in practical applications, such as addressing climate change or building a stable society. Overall, the discussion explores the extent to which computation can explain the mysteries of the universe and the challenges of modeling complex systems.

### Actual is going open-source (2022)

#### [Submission URL](https://actualbudget.com/open-source) | 123 points | by [edward](https://news.ycombinator.com/user?id=edward) | [25 comments](https://news.ycombinator.com/item?id=38053982)

Actual, a personal finance system that has been in development for over 4 years, is going open-source. This means that the app will now be completely free and available to the public forever. The source code is available on GitHub, allowing users to run the app locally and even host their own server. However, this shift to open-source will have implications for current subscribers. Signups on actualbudget.com have been turned off, existing subscriptions will be canceled in June, and the syncing server will be shut down. As a result, mobile apps will be deprecated, and the desktop app's future is uncertain. The website will eventually be shut down, and support will be through GitHub issues. Despite the changes, the creator believes that most users will be excited about the open-source version and the potential for new features and integrations. The creator is also calling for developers to contribute to the project and help manage it going forward.

The discussion on Hacker News revolves around various aspects of the submission about Actual, a personal finance system going open-source. 
One user mentions a talk by James Long on CRDTs (Conflict-Free Replicated Data Types) called "CRDTs for Mortals" and recommends it as a source of inspiration for building local-first, offline-first apps.
Another user congratulates the creator of Actual on their achievements but mentions that they had created a personal finance app that failed due to the lack of support and the need for a larger team. They express hope that Actual will build an active community.
There is a discussion about the challenges of building native apps on open-source platforms and the limitations imposed by App Stores. One user mentions a desktop application called PrudentMe available on the App Store.
A user points out that making the project open-source adds complexity to the codebase and mentions the trust issues between server and client devices.
Someone shares their interest in building a business step by step and mentions their personal experience with managing expenses and contracts in Canada.
Various users share links and resources related to the topics discussed, including a link to the Actual blog and a talk by James Long on CRDTs.
There is a discussion about the move from proprietary apps to open-source and the challenges of replacing web apps with native apps. The creator of Actual joins the conversation and explains the reasoning behind the transition and the challenges they faced. They express gratitude for the support from the open-source community.
Overall, the discussion is a mix of congratulations, technical discussions, and personal experiences related to personal finance and app development.

### Pretraining on the Test Set Is All You Need

#### [Submission URL](https://arxiv.org/abs/2309.08632) | 65 points | by [apsec112](https://news.ycombinator.com/user?id=apsec112) | [26 comments](https://news.ycombinator.com/item?id=38046970)

The latest submission on arXiv titled "Pretraining on the Test Set Is All You Need" by Rylan Schaeffer has been getting a lot of attention. In this paper, Schaeffer explores the idea of pretraining smaller language models on carefully curated data, specifically evaluation benchmarks. By using a novel dataset mixture consisting of less than 100 thousand tokens, Schaeffer demonstrates how their transformer-based LLM called "phi-CTNL" achieves perfect results across a range of academic benchmarks, outperforming all known foundation models. The paper also highlights how phi-CTNL surpasses power-law scaling and exhibits an impressive ability to accurately predict downstream evaluation benchmarks. While this may seem like an exciting breakthrough, it's worth noting that the paper is intended to be satire, with a touch of humor injected into the discussion of machine learning models. Nonetheless, it has sparked discussions and garnered attention within the academic community. With its combination of impressive results and witty commentary, this submission is definitely worth checking out.

The discussion on this submission covers various aspects. Some commenters discuss the challenges of evaluating language models (LLMs) and the difficulty of creating reliable benchmarks. They mention the need for better content testing and the limitations of current evaluation methods. Others point out the humor and satire in the paper's approach, suggesting that it is meant to be a joke. Some commenters express skepticism about the paper's claims, while others find it amusing and highlight the importance of critical evaluation in the research community. There are also discussions about the implementation details of LLMs and the importance of reading papers carefully to understand their content. Overall, the discussion revolves around the paper's humor, the challenges in evaluating LLMs, and the importance of critical evaluation in research.

### Pope tempted by Python. Signs off on coding scheme for kids

#### [Submission URL](https://www.theregister.com/2023/10/28/pope_software_python/) | 85 points | by [LinuxBender](https://news.ycombinator.com/user?id=LinuxBender) | [67 comments](https://news.ycombinator.com/item?id=38052476)

The Pope has given his blessing to "Code with Pope," a free online learning portal aimed at encouraging children to take up software development. The platform offers a 60-hour course that teaches the basics of Python coding for kids aged 11-15. It is available in English, Spanish, Italian, and Polish, and provides children with certificates and information on where to learn more skills. The initiative is the brainchild of Miron Mironiuk, a Polish AI ad biz owner who aims to develop skills in the developing world. The Pope's endorsement is expected to help convince children to give the platform a try. The Pope has been more willing than his predecessors to engage with technology, having started a Twitter account and an Instagram account with millions of followers.

The discussion on this submission revolves around various aspects of the Pope's endorsement of "Code with Pope" and the broader implications of this initiative. Some users express skepticism about the credibility of the Vatican's endorsement and question the Pope's involvement in endorsing a coding platform. Others discuss the potential impact of teaching children programming skills and whether it aligns with Catholic values. Additionally, there are jokes and references to programming languages such as Perl, OCaml, HolyC, and JavaScript. Some users also make references to Monty Python and the Catholic Church's commitment to different programming languages.

### Google to invest up to $2B in Anthropic

#### [Submission URL](https://www.reuters.com/technology/google-agrees-invest-up-2-bln-openai-rival-anthropic-wsj-2023-10-27/) | 390 points | by [fofoz](https://news.ycombinator.com/user?id=fofoz) | [372 comments](https://news.ycombinator.com/item?id=38048155)

Google has agreed to invest up to $2 billion in the artificial intelligence company Anthropic, according to a spokesperson for the startup. The company has invested $500 million upfront and has committed to adding an additional $1.5 billion over time. This investment highlights Google's efforts to better compete with Microsoft, a major backer of OpenAI, as tech giants race to integrate AI into their applications. Amazon also announced last month that it would invest up to $4 billion in Anthropic to compete with its cloud rivals in AI. Anthropic, founded by former OpenAI executives Dario and Daniela Amodei, is actively securing resources and backers to be leaders in the AI industry.

The discussion on this submission covers various aspects of the investment by Google in Anthropic and the capabilities of AI models like Claude 2 and ChatGPT. Some users discuss the potential impact of Google's investment and the competition between tech giants in the AI industry. There is also a debate about the effectiveness of large context windows in AI models and their limitations in answering specific questions. Users compare the strengths and weaknesses of Claude 2 and ChatGPT, and there is a discussion about the trustworthiness of AI-generated content. Additionally, some users speculate about the future of AI and its impact on Google searches.

### People are speaking with ChatGPT for hours, bringing 2013's Her closer to reality

#### [Submission URL](https://arstechnica.com/information-technology/2023/10/people-are-speaking-with-chatgpt-for-hours-bringing-2013s-her-closer-to-reality/) | 61 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [36 comments](https://news.ycombinator.com/item?id=38046786)

Do you remember the movie Her from 2013? Well, it seems like a slice of that fictional world has become reality. Thanks to ChatGPT's new voice features, people are now having hours-long discussions with the AI assistant, much like the character in the film who falls in love with an AI personality. Although ChatGPT doesn't have the same level of situational awareness or long-term memory as the AI in Her, people are still finding it engaging to talk to the AI assistant. Some users have even compared the experience to living out the first ten minutes of a dystopian sci-fi movie. While the voice interaction isn't flawless, with occasional pauses and trouble in noisy environments, the way the ChatGPT voices simulate human vocal ticks and noises is impressive. People are also finding value in using ChatGPT as a brainstorming partner when they need to bounce ideas off someone but don't have anyone else around. It's interesting to see how fiction is becoming reality, even if it's just in small ways.

The discussion on the submission revolves around users sharing their experiences and thoughts on ChatGPT's new voice features, comparing them to the AI assistant in the movie "Her." Some users express skepticism about the usefulness of ChatGPT as a brainstorming partner or an expert on specific topics. Others highlight the limitations of ChatGPT's accuracy and suggest alternative AI models. The discussion also touches on the integration of AI with hardware, the potential risks of relying on AI for information, and the implications of increasing interaction with AI for social interaction and loneliness. Some users reference other AI systems like Replika and Siri, while others discuss the impact of AI models on political correctness and the possibility of AI models becoming more politicized.

---

## AI Submissions for Fri Oct 27 2023 {{ 'date': '2023-10-27T17:11:24.921Z' }}

### Can the language of proof assistants be used for general purpose programming?

#### [Submission URL](https://proofassistants.stackexchange.com/questions/1093/can-the-language-of-proof-assistants-be-used-for-general-purpose-programming) | 78 points | by [wslh](https://news.ycombinator.com/user?id=wslh) | [45 comments](https://news.ycombinator.com/item?id=38044420)

The user on Proof Assistants Stack Exchange is asking if proof assistants, specifically Lean/Lean4, can be used for general-purpose programming. They are curious if proof assistants can replace languages like Standard ML and if there are any limitations to using them for general-purpose programming. In response, a user mentions that in Lean, you can write programs without proving termination, and Lean 4 is designed to be usable as a general purpose language. Another user suggests looking into widgets in Lean 3 for GUI tools, which allow interaction with Lean graphically in VS Code. They also mention that there is work being done to add GUI tools to Lean 4.

The question of whether proof assistants can be used for general-purpose programming is a complex one. While most proof assistants don't resemble traditional programming languages, dependent type theory, which acts as both a programming language and a theorem prover, merges the two worlds together. In pure dependent type theory, functions are computable and can be executed, but they need to be total and have a proof of termination. This means that certain functions, like those involving infinite loops or unproven conjectures, cannot be implemented in pure dependent type theory. However, there are tricks like carrying along a counter to ensure termination and using judgmental equality to prove properties about functions.

Overall, proof assistants have the potential to be used for general-purpose programming, but there are limitations and considerations to keep in mind.

The discussion on this submission covers a range of topics related to proof assistants and their potential for general-purpose programming:

- Some users discuss the features and capabilities of Lean and Lean 4, highlighting that Lean 4 is designed to be usable as a general-purpose language. Lean allows writing programs without proving termination, which is a requirement in most proof assistants. There are also mentions of GUI tools being developed for Lean.
- The topic of using proof assistants for general-purpose programming is addressed. It is noted that while most proof assistants don't resemble traditional programming languages, dependent type theory, which is used in proof assistants, merges programming and theorem proving. Functions in dependent type theory can be executed, but they need to be total and have a proof of termination. Certain functions that involve infinite loops or unproven conjectures cannot be implemented in pure dependent type theory. However, there are techniques to ensure termination and prove properties about functions.
- Other programming languages and tools are mentioned in the discussion, such as SPARK (a verifiable subset of Ada), Idris2, Prolog, and Python DSLs for Lean4.
- The benefits and challenges of using proof assistants, such as the ability to verify properties and catch errors, are also discussed. Some users bring up the concept of writing tests and the role of proof assistants in replacing or complementing testing.
- Overall, there is a recognition of the potential of proof assistants for general-purpose programming, but also an acknowledgment of their limitations and the need for more research and development in this area.

### Android 14's user-profile data bug

#### [Submission URL](https://arstechnica.com/gadgets/2023/10/android-14s-ransomware-data-storage-bug-locks-out-users-remains-unfixed/) | 172 points | by [concernedpix](https://news.ycombinator.com/user?id=concernedpix) | [85 comments](https://news.ycombinator.com/item?id=38043574)

Google's latest Android update, Android 14, has a serious storage bug that is affecting users of the "multiple profiles" feature. The bug, which some users are comparing to ransomware, is causing devices to become unusable due to being locked out of device storage. Initially, the bug was thought to be limited to the Pixel 6, but it is now affecting various devices that have upgraded to Android 14. Users who rely on the multiple profiles feature are particularly affected, with the primary profile being locked out. The issue has gained attention on the Google issue tracker, with over 350 replies, but Google has not responded or assigned anyone to look into the bug. Some users have reported data loss and automatic factory resets, further emphasizing the need for regular backups. The situation is perplexing, as Google typically employs a cautious rollout strategy to detect and address issues but failed to do so in this case. Google's response to the problem has been lacking, with no official statements or engagement with the bug tracker.

The discussion about the Android 14 storage bug on Hacker News covers several aspects. Some users share their experiences with data loss and the lack of backups, while others discuss possible solutions such as using Google Authenticator for MFA or utilizing cloud storage for backups. There is also a debate about whether Google should prioritize quality over new features and whether locked bootloaders increase security risks. Some users express concerns about the overall management and quality of Android updates, while others highlight the importance of regular backups and caution when upgrading to new versions. There are also mentions of issues with locked bootloaders affecting recoverability and discussions about the trade-offs between security and convenience.

### Google can turn ANC earbuds into a heart rate monitor with no extra hardware

#### [Submission URL](https://9to5google.com/2023/10/27/google-anc-earbuds-heart-rate/) | 174 points | by [mdwalters](https://news.ycombinator.com/user?id=mdwalters) | [67 comments](https://news.ycombinator.com/item?id=38045342)

Google has revealed its research into audioplethysmography (APG), a technique that can add heart rate sensing capabilities to active noise-canceling (ANC) headphones and earbuds through a simple software upgrade. The APG approach works by sending a low-intensity ultrasound probing signal through the speakers of ANC headphones, which triggers echoes that are received via feedback microphones. The feedback is then processed into heart rate readings and heart rate variability measurements. Google conducted two studies with 153 participants, finding that APG achieved consistently accurate heart rate and heart rate variability measurements. This technology could eliminate the need for additional hardware, such as photoplethysmograms (PPG) and electrocardiograms (ECG) sensors, in headphones and earbuds, potentially lowering cost and complexity. However, Google noted that the integration of APG into its products is not guaranteed at this point.

The discussion on this submission covers a range of topics related to the integration of heart rate monitoring into headphones and other wearable devices. Some users express concern about the potential privacy implications of advertisers having access to heart rate data, while others discuss the limitations and accuracy of using heart rate as a metric for advertising purposes. Some users also compare this technology to consumer-grade EEG devices and discuss the potential uses and limitations of EEG technology. Other topics touched upon include smart toilets, the tracking of COVID-19 in wastewater, and novel methods of data collection. There is also a side discussion about ANC headphones and the technical aspects of heart rate monitoring. Overall, the discussion covers a wide range of perspectives and interests related to the topic.

### Generate images in one second on your Mac using a latent consistency model

#### [Submission URL](https://replicate.com/blog/run-latent-consistency-model-on-mac) | 212 points | by [bfirsh](https://news.ycombinator.com/user?id=bfirsh) | [71 comments](https://news.ycombinator.com/item?id=38040702)

New research has introduced latent consistency models (LCMs) that can generate images on Mac computers at an impressive rate of one per second. Compared to previous methods that required 25 to 50 steps, LCMs need only 4 to 8 steps to generate high-quality images. Simian Luo and their team have released the first Stable Diffusion distilled model, which incorporates classifier-free guidance and can be run locally on an M1 or M2 Mac. Users can also modify and build upon the model's capabilities. The guide provides step-by-step instructions on setting up the necessary prerequisites, such as Python 3.10 or above, and walks users through cloning the LCM script from GitHub and installing dependencies. By simply running the provided command in the terminal, users can generate images based on a given prompt. Additional options, such as continuous image generation and custom model hosting on Replicate, are also available. For further assistance or detailed information, users can seek help in the Discord community or visit the GitHub repository.

The discussion on this submission revolves around various aspects of the image generation models, their performance, and their compatibility with Mac computers. One user points out that the model takes 25-40 seconds to generate an image on an M1 Max with 32GB of RAM, which is slower than expected. They suggest bypassing the memory startup time to improve performance. Others speculate that the slow loading time could be due to disk read speed limitations or PyTorch checkpoint loading. There are discussions about the limitations of the scripts, such as the inability to check download progress or save scripts for later use. Some users suggest using interactive flags or making modifications to enable continuous prompts and faster generation.

Users also share tips and tricks to optimize the image generation process, such as tweaking the code for faster prompt generation and utilizing different GPU configurations. There is also a mention of using xFormers to potentially improve performance. Some users express their satisfaction with the quality of the generated images, while others discuss alternative models and their comparison in terms of speed and quality. There are discussions about the potential implications of running the model locally on Mac laptops, including strategies to bypass safety checks and concerns about resource usage. A few users compare the performance of Mac laptops to Windows laptops, highlighting the differences in thermal management and power consumption. The conversation also touches on the limitations of the Mac hardware for running resource-intensive tasks and the preference of some developers to work on Windows or Linux machines.

### Leica camera has built-in defense against misleading AI, costs $9,125

#### [Submission URL](https://arstechnica.com/gadgets/2023/10/leicas-9125-camera-automatically-stores-authenticity-proving-metadata/) | 40 points | by [nathandaly](https://news.ycombinator.com/user?id=nathandaly) | [28 comments](https://news.ycombinator.com/item?id=38038727)

Leica Camera has released the M11-P, the industry's first camera that enables photographers to take pictures with automatically encrypted metadata and an editing history. This system, called Content Credentials, is based on the Coalition for Content Provenance and Authenticity's open standard, and aims to help photojournalists protect their work and prove its authenticity in an era of AI-manipulated content. Each image captured with the M11-P is stored with Content Credentials, including encrypted metadata about when and where the photo was taken, and the tools used for edits. The feature can be verified via Leica's FOTOS app or the Content Credentials website.

The discussion on Hacker News revolves around various aspects of Leica's new camera, the M11-P, which incorporates the Content Credentials system for encrypted metadata and editing history. Here are the key points raised:

1. MarkusWandel suggests that whenever significant changes are made to a photo, the revised metadata should be recorded and stored in the Content Credentials database. However, others point out that this could be frustrating for users and lead to misuse.
2. ncr100 believes that provenance will become increasingly important as misinformation spreads, emphasizing the need for fact-checking and authenticity.
3. trvrsd raises doubts about the security of the encryption and questions the feasibility of extracting cryptographic keys from the camera's sensor.
4. gnrj suggests that sophisticated attackers could manipulate metadata to make it appear authentic, but scientists in the field argue that there are techniques to detect such manipulation.
5. llwrks raises the possibility of legal context, suggesting that photos presented as evidence in court could require approved devices with trusted credentials.
6. great_psy proposes that the camera could be compromised by exploiting the signed channel, while rmy believes that the introduction of fakes would be problematic.
Moving on to the cost and value of the camera:
7. chrs points out the high price of the Leica M11-P, which is priced at $8,995, sparking a comparison with non-Leica cameras that offer similar features at a lower price.
8. __loam defends Leica's expensive cameras, mentioning their hand-built quality in Germany and suggesting that customers are paying for the brand's reputation.
9. FireBeyond notes that Content Credentials is not the latest standard, speculating that Canon might offer similar features soon.
10. rdgnym mentions the use of Certificate Authorities (CA) and the potential of a Public Key Infrastructure (PKI) for fighting misinformation.

The discussion also touches on AI-generated content and the challenges it presents:

11. onetimeuse92304 suggests that projecting AI-generated content through a camera lens is relatively simple but acknowledges the difficulty of dealing with artifacts.
12. wnc argues that the point of provenance starts with signing photos in Lightroom and suggests that traceability is not essential.
13. rmy points out that AI is becoming more capable, and taking pictures of screens is currently a mess.
14. vldrn mentions Canon's similar system that was cracked a while ago.

The discussion concludes with debates about the purpose and effectiveness of metadata and the role of trusted stakeholders:

15. bbrnbrg finds it ironic that metadata is often stripped, pointing out the importance of preserving metadata in content authentication.
16. frdmn argues that metadata can prove authenticity, while hvrd explains that it can be used to verify the authenticity of the message within an image.
17. ptbyts believes that AI is gaining significant interest, particularly in the context of the Content Authenticity and Provenance Association (C2PA), but others express a lack of interest in AI-generated content.
18. hvrd comments on the proprietary nature of the service.
19. mhtz suggests that allowing consumers to create custom certificates without centralized control could be risky, leading to a discussion on the trustworthiness of photographers and the need for a trusted hardware vendor.

Overall, the discussion delves into the technical aspects, implications, and skepticism surrounding Leica's Content Credentials system, as well as its potential impact on the photography industry.

### Quadcopters can now visually track targets more effectively

#### [Submission URL](https://mosfet.net/quadcopters-can-now-visually-track-targets-more-effectively/) | 76 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [97 comments](https://news.ycombinator.com/item?id=38042590)

Researchers from NYU Tandon School of Engineering have developed a groundbreaking method to visually track targets using quadcopters. This new approach, outlined in a recently uploaded paper, utilizes a unified foundation model that operates efficiently even with limited hardware. The researchers claim that their system can accurately detect a variety of objects, from humans to pigeons. To demonstrate the effectiveness of their technology, they shared a video showcasing quadcopters tracking humans as they try to escape. It's both impressive and just a touch unsettling. So, prepare yourself for a future where drones may have the upper hand in pursuit.

The discussion on this submission revolves around different aspects of drone technology and its implications. One user discusses the vulnerability of the Orlan-10 UAVs and suggests that tracking improvements could help mitigate the problems faced by non-military UAVs. Another user mentions the success of the Gepard platform in defending against UAVs and suggests that the focus should be on protecting mobile forces. The discussion also touches on directed energy weapons (DEWs) and their potential role in countering drones. One user expresses concern about the potential misuse of drone technology for targeted assassinations, while another user suggests focusing on helping people in conflict zones instead. There is also a discussion on the political implications of drone technology, with one user mentioning the release of Victor Bout and the Iranian connections to drones. Lastly, users discuss the challenges of detecting and tracking small drones and mention various methods, including electronic warfare and jamming, to counter them.

---

## AI Submissions for Thu Oct 26 2023 {{ 'date': '2023-10-26T17:12:23.706Z' }}

### The Cloud Computer

#### [Submission URL](https://oxide.computer/blog/the-cloud-computer) | 1641 points | by [CathalMullan](https://news.ycombinator.com/user?id=CathalMullan) | [878 comments](https://news.ycombinator.com/item?id=38023891)

Oxide, a company led by CTO Bryan Cantrill, has announced the availability of the world's first commercial cloud computer. The company has secured $44 million in Series A financing. Oxide's cloud computer aims to challenge the rental-only model of cloud computing by allowing users to purchase their own computer instead of renting it. The development of the cloud computer required a rack-level approach, with hardware and software being co-designed. The rack-level design allows for higher density and efficiency while reducing latency and noise. Oxide's cloud computer also eliminates the need for cabling by using blindmated networking. The company has even developed its own switch to complete the system. Overall, Oxide's cloud computer has been well-received, with its unique features surprising and delighting many who have seen it.

The discussion around Oxide's announcement of the world's first commercial cloud computer on Hacker News includes various perspectives and insights.

- Some commenters express their excitement about the development, noting that Oxide's unique features and rack-level design are impressive and have the potential to disrupt the cloud computing industry.
- There is some discussion around the technical aspects of Oxide's cloud computer, with comments about the co-design of hardware and software, blindmated networking, and the elimination of cabling. Some compare these features to historical approaches, such as Cray's Connection Machine and Beowulf clusters.
- One commenter raises concerns about the coupling vs. decoupling approach, suggesting that Oxide's approach may be more expensive but simpler to operate. They also mention that government agencies and savvy customers might be interested in such a solution.
- The conversation shifts to the potential competition Oxide might face from established vendors like Dell and HP. Some commenters point out that Oxide may find itself competing with these vendors and their own software and consulting services.
- Another commenter mentions the importance of standardization and plug-and-play interfaces in server design, using the example of GPU servers. They also mention a project called The Framework Cloud.
- The discussion then delves into the pros and cons of coupling and decoupling in server designs and the challenges faced by companies in developing hardware and software simultaneously.
- There is also a discussion about customer preferences, with some commenters suggesting that customers often choose the latest hardware for performance reasons, while others argue that customers may not care as long as their specific needs are met.
- The role of AMD in Oxide's development is mentioned, with commenters highlighting AMD's system integrator role and their work on simplifying the system.
- Overall, the discussion revolves around Oxide's unique approach to cloud computing and its potential impact on the market, while also exploring technical and customer-related considerations.

### Jina AI launches open-source 8k text embedding

#### [Submission URL](https://jina.ai/news/jina-ai-launches-worlds-first-open-source-8k-text-embedding-rivaling-openai/) | 537 points | by [artex_xh](https://news.ycombinator.com/user?id=artex_xh) | [195 comments](https://news.ycombinator.com/item?id=38020109)

Jina AI, the Berlin-based AI company, has launched its second-generation text embedding model, jina-embeddings-v2. This open-source model supports an impressive 8K context length, putting it on par with OpenAI's proprietary model. In benchmarking tests, jina-embeddings-v2 outperformed OpenAI's model in several areas, including classification, reranking, retrieval, and summarization. This new model unlocks extended context potential for applications in legal document analysis, medical research, literary analysis, financial forecasting, and conversational AI. Both the base and small versions of the model are available for download on Huggingface. Dr. Han Xiao, CEO of Jina AI, expressed his excitement about democratizing AI and empowering the community with open-source tools. Jina AI plans to continue leading the forefront of innovation in AI.

The discussion on the Hacker News submission revolves around various aspects of Jina AI's new text embedding model, jina-embeddings-v2, and its comparison with OpenAI's model.

- Some commenters express their happiness that open-source contributions are not dependent on a model's remarkable leaderboard ranking. They explain that the model's performance may be lower than OpenAI's model in terms of the dimensionality of the embeddings, but the 8K context window of jina-embeddings-v2 still provides great potential for many applications.
- There is a discussion about the limitations of the context length and the potential challenges in dealing with longer original texts. Some commenters point out that the 8K context window is new but similar to what Claude has been working on for months.
- The effectiveness of sliding window embeddings is debated, with some expressing that they work well for semantic search and related document clustering.
- The topic of open-source versus closed-source models is discussed, with some commenters noting that Jina AI's open-source approach differs from OpenAI's closed-source model. The importance of open-source data and reproducibility is emphasized.
- There is a debate about the definition of "open-source" and the extent to which the training details of a model should be disclosed. Some commenters argue that while weights and inferences can be considered open-source, training details like the training data and methodology may be subject to various considerations.
- Stallman's definition of open source and the preference for modifying specific source code are mentioned.
- The concept of reproducibility and the availability of training data are discussed, with mention of the need for complete openness in scientific experimentation.
- The conversation touches on the trade-offs between open-source and closed-source models, as well as the role of licenses in governing openness.

Overall, the discussion highlights the different perspectives on the definition of open-source, the challenges in dealing with longer texts, and the importance of transparency and reproducibility in AI model development.

### MetaCLIP â€“ Meta AI Research

#### [Submission URL](https://github.com/facebookresearch/MetaCLIP) | 146 points | by [zerojames](https://news.ycombinator.com/user?id=zerojames) | [23 comments](https://news.ycombinator.com/item?id=38023544)

Introducing MetaCLIP: A Tool for Curating and Training CLIP Models

Facebook Research has released MetaCLIP, a repository that contains everything you need to know about curating and training the CLIP (Contrastive Language-Image Pretraining) models. The repository includes curation/training code, metadata, distribution, and pre-trained models.

The main goal of MetaCLIP is to simplify the curation process of CLIP data. Unlike existing efforts that use the original CLIP model as a teacher for filtering student data, MetaCLIP allows users to curate data from scratch without relying on prior models. This approach makes the training data more transparent.

One of the key features of MetaCLIP is its scalability. The algorithm in MetaCLIP can be used to curate data from the entire CommonCrawl dataset, which contains over 300 billion image-text pairs. The researchers behind MetaCLIP emphasize that data quality is more important than quantity, and their algorithm focuses on preserving signal and mitigating noise rather than simply removing noise with blackbox filters.

The release of MetaCLIP not only includes the code but also provides the pre-training data distribution. This enables researchers to perform controlled experiments and fair comparisons using the same training and model configuration.

The research paper describing MetaCLIP, titled "Demystifying CLIP Data," provides further details on the methodology and findings. The researchers conclude that effective pretraining data should prioritize preserving signal and mitigating noise, and their algorithm offers a simpler and scalable approach to curating data from the internet.

For those interested in getting started with MetaCLIP, the repository provides a guide on how to install the required dependencies and offers pre-trained models for experimentation.

Overall, MetaCLIP is a valuable resource for researchers and practitioners working with CLIP models, as it offers a straightforward and scalable approach to curating and training data.

The discussion on Hacker News surrounding the announcement of MetaCLIP is quite active. Here are some key points from the comments:

- Some users express their interest in MetaCLIP and its potential applications, such as semantic image search, private collections, and trading card recognition.

- There is a discussion about CLIP and its capabilities, with some users highlighting its usefulness in various computer vision tasks, including image classification, automated labeling, image clustering, and content moderation. Others note the limitations of CLIP, such as the occasional duplication of words in generated captions.

- Users suggest trying out alternatives to CLIP, such as BLIP and LLaVA, for different use cases. There is also mention of other projects like StyleGAN, StyleCLIP, DALL-E, and NumPyCLIP that are related to CLIP.

- Some commenters mention the importance of larger context size in text inputs for improved CLIP performance. The limitations of the 77-character input length are acknowledged, and users express hope that future improvements will address this issue.

- The commercial licenses for CLIP and MetaCLIP are discussed, with some users asking about the availability of open-source versions. It is clarified that while CLIP is now commercially licensed, MetaCLIP is open-source.

Overall, the discussion reflects a mix of excitement about the possibilities that MetaCLIP offers and curiosity about the capabilities and limitations of CLIP and related models.

### The Waymo Driver Now Available on Uber in Phoenix

#### [Submission URL](https://waymo.com/blog/2023/10/the-waymo-driver-now-available-on-uber.html) | 24 points | by [ra7](https://news.ycombinator.com/user?id=ra7) | [4 comments](https://news.ycombinator.com/item?id=38025212)

Waymo, the self-driving car unit of Alphabet, has announced that Uber customers in Phoenix can now request a ride in a Waymo autonomous vehicle through the Uber app. The option is available for UberX, Uber Green, Uber Comfort, and Uber Comfort Electric rides in the 225+ square miles of Metro Phoenix where Waymo operates. This partnership with Uber expands the reach of Waymo's driverless technology and allows more people to experience the benefits of autonomous driving. Riders can still hail a Waymo vehicle directly through the Waymo One app as well. Waymo has been operating in Phoenix for five years and is currently providing over 10,000 rides each week in the region.

The discussion on this submission revolves around a few different points. One user, "gldhs," mentions that the Uber app is missing some of the features that the Waymo app offers, such as the ability to stop the trip, resume the process, and change the destination. Another user, "recursv_thnkng," hopes that the increased size of the fleet doesn't cause longer wait times in Phoenix, as they have already experienced long wait times with standard Uber rides. Another user, "RCitronsBroker," brings up the topic of the cost and testing associated with self-driving technology. They suggest that developing self-driving technology is unnecessarily expensive and that engineers should focus on improving the sensors and testing the product more thoroughly before attempting to achieve full self-driving capability. Finally, user "chph" mentions that they watched videos of Waymo's self-driving systems and is skeptical about how well they actually work. They suggest that they had an uncomfortable experience when riding in a car once and are hesitant to trust fully autonomous vehicles. Overall, the discussion covers topics related to the features of the Uber app, concerns about wait times, the cost and testing of self-driving technology, and personal experiences with self-driving vehicles.

### Pulpatronics tackles single-use electronics with paper RFID tags

#### [Submission URL](https://www.dezeen.com/2023/10/25/pulpatronics-paper-rfid-tags/) | 47 points | by [albertzeyer](https://news.ycombinator.com/user?id=albertzeyer) | [31 comments](https://news.ycombinator.com/item?id=38024337)

A group of design graduates from London's Royal College of Art have developed an innovative RFID tag made entirely from paper. The start-up, known as PulpaTronics, aims to reduce waste from single-use electronics by eliminating metal and silicon components in their paper RFID tags. Traditional RFID tags, which are commonly used in clothing stores for self-checkout and inventory management, are unrecyclable due to the combination of materials used. PulpaTronics' paper RFID tags, on the other hand, only require laser-marked circuits on paper, making them easily recyclable with household waste. The company estimates that their tags will reduce carbon dioxide emissions by 70% compared to standard RFID tags and cut costs for businesses. PulpaTronics is currently prototyping and testing the design further, targeting the retail industry as their initial market.

The discussion on Hacker News revolves around various aspects of the paper RFID tags developed by PulpaTronics, as well as the potential implications and limitations of the technology. Some points raised in the discussion include:

- The comparison between PulpaTronics' paper RFID design and traditional RFID tags. While traditional tags use metal and silicon, PulpaTronics' tags only require laser-marked circuits on paper, making them easily recyclable.
- The potential advantages of PulpaTronics' tags, including a 70% reduction in carbon dioxide emissions and cost savings for businesses.
- Speculations on whether the technology could be used for RFID tags on clothing, and discussion of other techniques like laser-induced graphene and multiple lasing electronics.
- The limitations of traditional RFID tags, their affordability in the supply chain, and the potential use of PulpaTronics' tags for supply chain traceability and inventory management.
- The use of GS1 barcodes and decentralized identifiers in the context of RFID technology.
- The comparison between thermal labels and paper RFID tags.
- The technical aspects of PulpaTronics' design, such as the use of a geometric pattern and resonant circuits.
- The potential applications of PulpaTronics' tags in supermarkets, including real-time inventory tracking and notification systems.
- The use of RFID tags in waste management, including trash sorting and tracking expired products.
- The lack of implementation of notification systems based on RFID tags in retail stores, as well as the potential for improved inventory management through Amazon's purchase history or expiration date notifications.
- Clarification on the difference between barcodes and RFID tags in terms of product information and expiration dates.
- The similarities between PulpaTronics' paper RFID design and QR codes.

### OpenAI Preparedness Challenge

#### [Submission URL](https://openai.com/form/preparedness-challenge) | 153 points | by [dougb5](https://news.ycombinator.com/user?id=dougb5) | [148 comments](https://news.ycombinator.com/item?id=38029307)

OpenAI has launched the Preparedness Challenge, aiming to gain insights into potential areas of concern with the use of their AI models. They are accepting submissions until December 31, 2023, and plan to offer $25,000 each in API credits to the top 10 entries. The challenge seeks to explore potential risks and vulnerabilities, even those that are malicious in nature. Participants are encouraged to envision unique yet probable scenarios where the misuse of OpenAI's models could cause catastrophic harm, such as socially engineering workers at critical infrastructure facilities to install malware. Additionally, the challenge asks participants to outline an experiment plan to measure the feasibility and severity of such misuse in an ethical and legal manner. The challenge aims to identify potential risks and explore ways to mitigate them.

The discussion revolves around the potential risks and concerns regarding OpenAI's AI models and their Preparedness Challenge. Some users express that OpenAI is trying to protect their brand and avoid controversy, while others believe that it is a necessary effort to ensure security. There is a debate about the importance of addressing risks such as the generation of racist content or the potential for malicious use, with some arguing that racism in AI is a serious concern while others believe it is not a significant issue.

One user suggests that the challenge should focus on the maximum harm that could be caused by AI, such as impersonation or manipulation, while another points out the risks of surveillance and social engineering. There are also discussions about the challenges of managing information that is both uncensored and unverified, as well as concerns about censorship and the suppression of free expression. Some users mention the risks of AI being used for harmful purposes, such as hacking power grids or physical infrastructure, and the need for safeguards against such attacks. Overall, the discussion highlights the importance of addressing potential risks and vulnerabilities associated with AI models while also considering the ethical and legal implications of their use.