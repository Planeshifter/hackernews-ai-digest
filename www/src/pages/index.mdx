import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Sat Sep 09 2023 {{ 'date': '2023-09-09T17:09:45.510Z' }}

### SmartKnob – Haptic input knob with software-defined endstops and virtual detents

#### [Submission URL](https://github.com/scottbez1/smartknob) | 264 points | by [e3a8](https://news.ycombinator.com/user?id=e3a8) | [42 comments](https://news.ycombinator.com/item?id=37448659)

Introducing SmartKnob: an open-source input device with software-configurable endstops and virtual detents. This innovative gadget combines a brushless gimbal motor with a magnetic encoder to provide closed-loop torque feedback control, allowing users to dynamically create and adjust the feel of detents and endstops. The SmartKnob View, which includes an integrated display, is currently under active development. Motors are now available for purchase, thanks to the community's efforts in identifying the original manufacturer and collaborating with SparkFun Electronics. While SmartKnob is a DIY project, it requires advanced soldering skills and troubleshooting abilities due to its small-pitch surface-mount soldering and delicate assembly process.

The discussion on Hacker News about the submission "Introducing SmartKnob: an open-source input device with software-configurable endstops and virtual detents" covers various topics related to the project. Here are some highlights:

- Users express their admiration for the well-documented source hardware project and discuss the challenges of software projects, 3D design printing, hardware sourcing, component selection, and support from the community.
- There is a discussion about the feasibility of low-cost PCB manufacturing, availability of affordable tooling, such as CO2 laser cutters, and the increasing popularity of hobbyist hardware projects.
- One user asks a technical question about voltage protection for the motor and the TMC6300 IC schematic connection. Another user, who has electrical engineering knowledge, provides a response and mentions high resistance, low-kV motors, and the importance of handling high voltage correctly.
- The conversation also touches on the difficulties of handling high RPM motors and the potential issues with ESCs (Electronic Speed Controllers) and motor braking.
- Users express their appreciation for the UX (user experience) aspect of the project and discuss the detection of flexing in the PCB and the need for magic touch buttons.
- Several users share their interest in similar projects, such as building digital jukeboxes with physical controls and knob controls for shuffling tracks.
- There is a mention of a YouTube video demonstrating the behavior of a rotary encoder and the availability of software-based detents.
- One user compares the project with existing commercial products, such as the 3Dconnexion SpaceNavigator and SpaceMouse Pro, pointing out the similarities in behavior.
- The discussion veers into the field of music synthesis, with users highlighting the importance of control panels, hardware synthesizers, and the ability to quickly modify parameters for improved performance.
- The topic expands to include haptics and electronic instruments, with users mentioning specific devices and their design, such as the Roland/Boss GT-100 guitar processor and the TP-7 with haptic feedback.
- There are mentions of DIY smart thermostats, power button rotary knobs, flight simming, and even a humorous comment about Tesla's shifters.

Overall, the discussion shows a mix of technical questions, positive feedback about the project, and various related topics sparked by the submission.

### Show HN: WhatsApp-Llama: A clone of yourself from your WhatsApp conversations

#### [Submission URL](https://github.com/Ads-cmu/WhatsApp-Llama) | 115 points | by [advaith08](https://news.ycombinator.com/user?id=advaith08) | [49 comments](https://news.ycombinator.com/item?id=37448005)

Introducing WhatsApp-Llama: Fine-tune Llama 7b to Mimic Your WhatsApp Style

Have you ever wanted an AI that speaks just like you? Well, now you can! A team from Carnegie Mellon University has forked the popular Llama-recipes repository and created WhatsApp-Llama, a tool that allows you to train a language model to replicate your personal texting style on WhatsApp.

By inputting your WhatsApp conversations, you can fine-tune the Llama-2 7b chat model to respond just like you do. The team used parameter efficient finetuning (QLoRA) and int4 quantization on a single GPU to achieve impressive results.

In their experiments, the fine-tuned Llama-2 model quickly picked up on the nuances of the user's texting style. The average number of words generated by the finetuned Llama-2 was 300% more than the vanilla Llama-2 model. The model accurately replicated common phrases and emoji usage.

To test the model's performance, the team conducted a Turing Test with friends. They asked their friends to ask three questions on WhatsApp and then responded with two candidate responses, one from themselves and one from the Llama-2 model. The friends had to guess which response was from the user and which one was from the AI. The model fooled 10% of the friends, with some of its responses being eerily similar to the user's own.

To get started with WhatsApp-Llama, you need to export your WhatsApp chats and preprocess the dataset. The detailed steps can be found in the README file of the repository. The team recommends exporting 10 WhatsApp chats from friends you frequently speak to, excluding media.

With WhatsApp-Llama, you can have an AI that speaks just like you on WhatsApp. This opens up possibilities for personalization and automation in text-based communication. So go ahead, unleash your AI clone and start chatting!

The discussion around the submission "Introducing WhatsApp-Llama: Fine-tune Llama 7b to Mimic Your WhatsApp Style" on Hacker News covered various topics. Here is a summary of the key points:

- One user mentioned that they haven't watched Silicon Valley, prompting another user to share a link to a funny clip from the show.
- There was a reference to the Black Mirror episode "Be Right Back," which reminded another user of the episode.
- Discussions shifted to the technical aspects of using Llama models. One user mentioned that using a 13B model instead of a 7B model significantly improved results. However, others pointed out that the cost of using larger models, such as the 3090 GPU, could be high.
- Users expressed their experiences with the Llama models and the level of accuracy in mimicking their texting style.
- Some users shared their interest in replicating other famous fictional characters, such as Harry Potter portraits.
- The conversation then moved to discussions about other topics, including the Black Mirror series, text messaging durations, and the potential of personalizing AI dialogue systems.
- Users expressed interest in the development of grief counseling AI systems and techniques for healthier AI-human interactions.
- There were discussions regarding the potential profitable business opportunities based on training Llama models and charging for access to personalized AI models.
- Users shared their experiences and plans for exporting chat histories from WhatsApp or other platforms and the necessary pre-processing steps.
- Some users discussed the potential privacy implications of training AI models on personal chat histories.
- There were inquiries about the hardware requirements for running Llama models, and users shared their experiences with different GPUs and services like Google Colab.
- Users mentioned different versions of Llama models, such as Llama 2, and asked about the differences between them.
- The conversation concluded with users discussing other messaging platforms like Telegram and Discord.

Overall, the discussion covered a range of topics, from technical details and experience with Llama models to potential privacy concerns and broader implications of AI conversation systems.

### Show HN: TaleBot – AI-Generated Personalized Bedtime Stories for Kids

#### [Submission URL](https://talebotai.com/) | 16 points | by [cagrisarigoz](https://news.ycombinator.com/user?id=cagrisarigoz) | [16 comments](https://news.ycombinator.com/item?id=37443790)

Introducing TaleBot, the ultimate companion AI storyteller for your children! Tired of telling the same old fairytales? With TaleBot, you can customize characters, develop new storylines, and create personalized bedtime stories in minutes. Say goodbye to monotony and hello to endless giggles and unforgettable memories.

Parenting is a tough job, especially at the end of a long day. Just when you think you can finally relax, your child asks for a story. Instead of resorting to tired old tales, why not let their imagination soar? With TaleBot, they'll become the heroes of their dreams, embark on wild adventures, and bring along their favorite friends, real or imaginary. It's the perfect way to teach them values, nurture curiosity, and ignite their creativity.

Using TaleBot is a breeze. Simply name your main character, choose an adventure, add a moral, and let our AI bot work its magic. Don't worry, we respect your privacy and only ask for non-identifiable information to personalize the story. In just a few minutes, you'll have a unique and engaging story ready to be enjoyed.

But don't just take our word for it. Here's what some of our happy parents have to say: "My 4-year-old loved the story we created together!" Praises like these make us smile and motivate us to provide the best possible experience.

When you create a story with TaleBot, you'll receive a PDF copy as well as an AI-narrated audio recording right in your inbox. The story is yours to keep, share, and cherish as a precious memory. And with your permission, we can even publish your story on our website or podcast, spreading the joy to others.

But that's not all! We're constantly working on new features to enhance your storytelling experience. Keep an eye out for upcoming updates like AI voice selection and video storytelling. We want to make personalized storytelling even more magical and immersive for you and your children.

So, why wait? Start your storytelling journey with TaleBot today and experience the wonder of creating unique and captivating stories. Let your child's imagination flourish, one story at a time.

---

### GitHubGuessr

#### [Submission URL](https://github-guessr.vercel.app/) | 115 points | by [tan-z-tan](https://news.ycombinator.com/user?id=tan-z-tan) | [49 comments](https://news.ycombinator.com/item?id=37432067)

Introducing GitHub-Guessr, a fun and exciting game that will put your coding knowledge to the test! Can you guess the correct GitHub repository just by looking at the code? Get ready to showcase your skills and prove that you're a true code sleuth.

GitHub-Guessr presents you with snippets of code taken from various repositories. Your mission is to analyze the code and guess which repository it belongs to. Each correct guess earns you points and brings you closer to becoming the ultimate GitHub-Guessr champion.

Whether you're a seasoned developer or a coding enthusiast, this game offers a thrilling challenge that will keep you on your toes. It's a great way to explore different coding styles, learn from other developers, and discover interesting projects hosted on GitHub.

So, get your detective hat on, flex your coding muscles, and dive into the world of GitHub-Guessr. Can you guess the GitHub repository from the code? Start playing now and let the coding adventure begin!

In the discussion on this submission, there are several threads of conversation. 

One commenter, gshgg-blk, expressed appreciation for the game but pointed out that it would be helpful to have more information or references when trying to guess the repositories. Another commenter, stvbmrk, apologized for not reading the dropdown options correctly and offered suggestions for improving the game by implementing autocomplete and sharing buttons.

dysc shared three suggestions: making it easier to select options, gradually increasing the difficulty by introducing more complex puzzles, and adding a share button to challenge friends.

tn-z-tn responded to dysc's suggestions, stating that they had implemented some improvements but found it challenging to change the selection style. FireInsight commented on the unbalanced character distribution in a Swift code snippet.

arh68 simply found the game interesting, while trln and zX41ZdbW provided feedback on minor issues they encountered while playing.

smrphc- suggested improving the dropdown guess box by sorting the options alphabetically, and tn-z-tn agreed.

sxstrngthry praised the circular perspective view concept and suggested using smaller options to make scrolling through the list more convenient.

tn-z-tn created the GitHub-Guessr game and shared their thoughts on its development. Other commenters, such as wbdvvr and jtwlsn, offered suggestions for improving the game's functionality and expressed interest in using similar tools in their work.

lnkr suggested including reverse engineering puzzles that target web development. And cglng found the game challenging but admitted to being unfamiliar with most of the listed projects.

bllq clarified a confusion regarding scrollbar visibility in the MongoDB repository, and skttr pointed out that sometimes the highlighted code moment moves unexpectedly.

nvdmf mentioned a sudden scroll jump issue, and 38 reported a compatibility error with Firefox.

Overall, the discussion included suggestions for improvements, feedback on code snippets, and appreciation for the concept of the game.

### TSMC warns AI chip crunch will last another 18 months

#### [Submission URL](https://www.theregister.com/2023/09/08/tsmc_ai_chip_crunch/) | 156 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [94 comments](https://news.ycombinator.com/item?id=37432948)

TSMC has warned that the chip shortage for high-spec GPUs, such as Nvidia's A100 and H100, will continue until at least the end of 2024. The issue lies with the lack of advanced packaging capacity, which is used to assemble the silicon chips. TSMC can currently only meet around 80% of the demand for its chip on wafer on substrate (CoWoS) packaging technology, particularly used in chips for AI purposes. TSMC expects additional CoWoS capacity to be available within the next 18 months. In the meantime, the shortage will impact the availability of Nvidia's H100 and A100, as well as AMD's upcoming Instinct MI300-series accelerators.

The discussion on Hacker News revolves around the chip shortage and its impact on the availability of high-spec GPUs. Some users speculate about the reasons for the shortage, with one user noting that TSMC's packaging technology and capacity are the main bottlenecks. Others discuss the involvement of Chinese companies and the use of stolen intellectual property. There is also a discussion on the availability and pricing of Raspberry Pi boards, with some users pointing out the challenges faced by hobbyists due to increased prices. The topic of global chip manufacturing capacity and demand is also debated, with some users suggesting that increased supply would lead to smaller profit margins. There are also discussions about the German region of Saxony and its perceived xenophobia, as well as the issues related to staffing and assembly in the chip manufacturing industry. Overall, the discussion covers various aspects of the chip shortage, its causes, and its impact on different segments of the market.

### Show HN: Rivet – open-source AI Agent dev env with real-world applications

#### [Submission URL](https://rivet.ironcladapp.com/) | 160 points | by [gogwilt](https://news.ycombinator.com/user?id=gogwilt) | [30 comments](https://news.ycombinator.com/item?id=37433218)

Ironclad, the leading digital contracting platform, has released Rivet, a visual programming environment for building AI agents with large language models (LLMs). Rivet allows teams to effectively design, debug, and collaborate on complex LLM prompt graphs, and deploy them in their own environment. It provides a visual interface to visualize and build complex chains for AI applications, a remote debugger to observe prompt chain execution in real-time, and the ability to version and review prompt graphs using YAML files. The community has praised Rivet's game-changing nature, its ability to address limitations and facilitate collaboration, and its power in rapidly prototyping and understanding complex AI workflows. Rivet has already been used by Ironclad to develop their virtual contract assistant, powered by AI agents. To get started with Rivet, the Getting Started guide, integration with Node or TypeScript applications, and an example application are available.

The discussion on Hacker News surrounding the submission about Rivet, an open-source visual AI programming environment, covered various topics.

One user mentioned their interest in a native Rust and TypeScript solution for Rivet and asked if there were plans to add plugins to dynamically change and manage prompt graphs. Another user replied, stating that Rivet does not have built-in chat GPT plugins and that prompt graphs are explicitly built by publishing prompt chains as a publicly available plugin.

Another user shared that they have been following two similar services that solve the problem of building workflows with large language models and recommended checking out FlowiseAI and lgspc-lngflw on GitHub.

Another user expressed excitement about trying Rivet and mentioned considering supporting open-source language models, inference servers, and LocalAI.

Someone else mentioned that they recently open-sourced a platform for building workflows with language models visually and locally and provided a link for it.

Another user stated that they haven't seen this kind of support in a while and highlighted the importance of requirements for production applications.

Someone else praised the work done and mentioned the usefulness of the dev tools for structuring functions and integrating powerful tools for careful spending in a controlled manner.

Another commenter mentioned that they have implemented AI features recently and found Rivet to be a perfect match for building large language model applications.

A user expressed their support for Rivet in building large language model applications and mentioned collaborating with the Ironclad team on integrating user experience paradigms.

Another user mentioned their interest in real-world projects and suggested open-sourcing the implementation and possibly using multiple APIs for specific purposes.

Someone else mentioned their excitement about trying AI efforts and praised Rivet's applicability in the field.

Another commenter asked if Rivet supports TypeScript and plans to have a desktop version, to which the Rivet team clarified that while it runs locally on a web app, there are plans to add a desktop version in the future.

Several comments congratulated the Rivet team on the launch and expressed support for the project.

Lastly, there was a brief discussion about the target audience for Rivet, with one user asking if it targets enterprise startups. The response clarified that Rivet is designed for growth-stage startups and partners who collaborate with Ironclad.

Overall, the discussion highlighted enthusiasm for Rivet's capabilities and potential applications, as well as requests for additional features and integrations with different technologies.

### Show HN: Find jobs at top AI startups

#### [Submission URL](https://workinai.xyz/) | 27 points | by [himanshujaju](https://news.ycombinator.com/user?id=himanshujaju) | [5 comments](https://news.ycombinator.com/item?id=37435689)

Looking to land a job at one of the hottest AI companies? Well, you're in luck! WorkinAI.xyz has compiled a comprehensive list of over 450 job openings at more than 20 AI companies. This is your chance to get in on the cutting edge of technology and work alongside some of the brightest minds in the industry. Just make sure to view the page on a desktop, as it allows you to easily sort, filter, and search through the available positions. And if you have any suggestions, feedback, or inquiries, don't hesitate to reach out to hello@workinai.xyz. Get ready to take the next big step in your career!

The comments on the submission are brief but positive. One user suggests starting with a small company to gain experience, another user expresses happiness and shares the link on Twitter, one user thanks the OP for the helpful job application, and another user commends the work and hopes that it expands.

### We built an AI-powered Magic the Gathering card generator

#### [Submission URL](https://txt.cohere.com/urzas-ai/) | 126 points | by [MWil](https://news.ycombinator.com/user?id=MWil) | [85 comments](https://news.ycombinator.com/item?id=37427854)

Magic the Gathering (Magic) is a beloved collectible card game that has captivated players for years with its unique asymmetrical gameplay. However, one complaint is that there aren't enough cards to satisfy the players' thirst for new content. That's where Urza's AI comes in. Urza's AI is a website created by three individuals who wanted to generate more Magic cards using the power of artificial intelligence (AI). The team utilized a combination of language AI and text-to-image AI to generate playable Magic cards based on prompts. First, they used a large language model (LLM) to generate text information about the card, such as its cost, type, subtype, and description. They finetuned the model with a dataset of existing Magic card descriptions, leading to more realistic and playable card outputs.

But a Magic card isn't complete without an accompanying image. To generate card images, the team employed the Wombo Art API, which uses text input and image output. They provided the API with the card name, types, and subtypes, resulting in impressive and thematic card illustrations. Not stopping there, the team also used AI to generate the card back and Mana icons. By creating prompts and leveraging the Wombo API, they successfully produced card backs and Mana icons that complemented the generated cards.

With all the components ready, the team built the Urza's AI website where users can enter a card name and have a complete card rendered. The outcome has been astounding, with thousands of visitors trying out the site within the first four days of its launch. Magic enthusiasts and players now have access to an ever-expanding pool of custom Magic cards, giving them the opportunity to explore new strategies and deck combinations. Urza's AI has tapped into the power of AI to bring excitement and novel experiences to the Magic community.

The discussion surrounding the Urza's AI submission on Hacker News covers various aspects of the topic:

- Some commenters express their appreciation for the quality and capabilities of the AI-generated Magic cards. They highlight the impressive text-to-image generation and note that the cards are suitable for standard, historic, and explorer formats.

- Others are amazed by the use of AI in generating card backs and Mana icons for the Magic cards. They commend the team's work and express gratitude for the exciting possibilities this brings to the Magic community.

- Commenters discuss the potential legal issues surrounding AI-generated cards and the involvement of Wizards of the Coast (WOTC), the company behind Magic the Gathering. One user mentions a previous AI-generated Magic card project called RoboRosewater.

- The topic of AI playing Magic the Gathering is also touched upon. Some users mention instances where AI players have defeated professional human players, highlighting the capabilities of AI in the game.

- The balance and power level of AI-generated cards are also a point of discussion. Commenters debate the ability of AI to generate cards with comparable power levels and the potential impact on the game's balance.
- The topic diverges to discuss AI and machine learning in creating game content in general. Users share insights on AI-driven card generation, win conditions in games, and the challenges of achieving proper balance.
- A few commenters draw parallels between AI-generated Magic cards and existing Magic cards, highlighting similarities and discussing potential strategies and interactions.
- The conversation also touches on the consideration of AI-generated Magic cards as collectibles and potential market value.
- One user jokingly mentions the association of Magic the Gathering with MtGox, a defunct cryptocurrency exchange platform, due to the similar abbreviation.
- The discussion concludes with references to related articles and posts from previous years that explored similar AI-generated Magic cards.

Overall, the discussion on Hacker News explores the excitement and implications of AI-generated Magic cards, delves into gameplay and balance considerations, and provides references to additional resources for those interested in the topic.

### NVIDIA introduces TensorRT-LLM for accelerating LLM inference on H100/A100 GPUs

#### [Submission URL](https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/) | 67 points | by [mkaushik](https://news.ycombinator.com/user?id=mkaushik) | [21 comments](https://news.ycombinator.com/item?id=37439280)

NVIDIA has announced the upcoming release of TensorRT-LLM, an open-source software for accelerating large language model (LLM) inference on NVIDIA GPUs. The software, which integrates the TensorRT deep learning compiler, includes optimized kernels, pre- and post-processing steps, and multi-GPU/multi-node communication primitives for improved performance. TensorRT-LLM aims to make LLMs more accessible and customizable for developers by providing a modular Python API for defining, optimizing, and executing new architectures. It also supports in-flight batching, allowing for efficient execution of dynamic workloads with varying output sizes. The software has already been integrated by several leading companies and has demonstrated significant performance improvements on NVIDIA GPUs.

The discussion around NVIDIA's announcement of TensorRT-LLM on Hacker News includes various comments from users discussing different aspects of the software.

One user mentions the availability of optimized versions of well-known LLMs like OpenAI's GPT-2 and GPT-3 in TensorRT-LLM. Another user asks about the availability of special weights, to which another user responds that the weights for GPT-3 have not been released openly.

Another user comments that TensorRT-LLM is available through the NVIDIA NeMo framework, which is part of the NVIDIA AI Enterprise software platform. They also mention that developers and researchers can access TensorRT-LLM through the NVIDIA Developer Program.

The efficiency and performance of TensorRT-LLM are discussed by users. One user mentions that acceleration work on H100/A100 GPUs can improve performance by 30-40 times compared to regular GPUs. Another user questions why there is only a 15GB/s communication rating on PCIe for TensorRT-LLM, to which another user responds that it is due to the difference in GPU-to-GPU communication capabilities between NVLink and PCIe.

There are also comments about compatibility and hardware requirements. One user notes that future versions of TensorRT may require higher-end GPUs. Another user shares a link to a GitHub issue where someone mentioned that TensorRT-LLM did not work well with the 30-series GPUs.

The discussion also touches on the flexibility and extensibility of TensorRT-LLM. One user points out that it provides a modular Python API for defining and optimizing new architectures, making it customizable with deep knowledge of C++ and NVIDIA CUDA.

The comparison between NVIDIA and AMD is brought up by a user commenting that while AMD may have caught up with NVIDIA in some areas, NVIDIA still has a more mature and fully optimized software stack.

Another user brings up the similarity between TensorRT-LLM and vLLM (very Large Language Model), mentioning that vLLM uses intermediate-level tensor parallelism and that both technologies have their own advantages and applications.

Lastly, there is a brief discussion about the cost of running H100 and A100 GPUs on the cloud, with one user mentioning that H100 costs around $4 per hour and A100 costs around $2 per hour on the public market.

### Scientific sleuths spot dishonest ChatGPT use in papers

#### [Submission URL](https://www.nature.com/articles/d41586-023-02477-w) | 93 points | by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) | [81 comments](https://news.ycombinator.com/item?id=37431946)

Researchers have been using OpenAI's ChatGPT to write scientific papers without disclosing its use, leading to concerns about the integrity of peer-reviewed publications. ChatGPT is an AI chatbot that generates fluent text in response to user prompts. However, some researchers have been found to have used ChatGPT to help draft their manuscripts without declaring it. In one case, a paper was retracted by the journal Physica Scripta because the authors did not disclose their use of the tool. Since April, more than a dozen journal articles have been flagged for containing telltale ChatGPT phrases without proper disclosure. This raises concerns about the widespread use of AI language models in scientific publishing.

The discussion on this submission covers a range of topics related to the use of AI in scientific publishing. Some commenters express frustration with the current state of academic journals, noting that they are slow, expensive, and often prioritize profit over the dissemination of research. Others argue that the current peer review system is flawed and prone to biases and conflicts of interest. Some commenters defend the anonymity of peer reviewers, while others suggest alternative systems for collecting review data.

There is also a discussion about the use of AI in academia, with some commenters arguing that it can be a helpful tool for researchers, while others express concerns about its impact on the integrity of scientific publications. Some commenters posit that the problem lies not with AI itself, but with the lack of transparency and honesty among researchers in disclosing their use of AI tools.

Other points raised include the need for better document hosting services and functionality, the importance of replication in scientific publishing, and the systemic issues within the university system that may contribute to the current state of academic publishing.

Overall, the discussion reflects a variety of perspectives on the use of AI in scientific publishing and raises important questions about transparency, integrity, and the future of the peer review system.

### Large Language Models as Optimizers. +50% on Big Bench Hard

#### [Submission URL](https://arxiv.org/abs/2309.03409) | 92 points | by [og_kalu](https://news.ycombinator.com/user?id=og_kalu) | [33 comments](https://news.ycombinator.com/item?id=37434069)

Researchers from Google AI have proposed a new approach called Optimization by PROmpting (OPRO) that leverages large language models (LLMs) as optimizers for solving complex optimization problems. Traditional derivative-based optimization algorithms face challenges when dealing with tasks that lack gradients. OPRO uses LLMs to generate new solutions based on a prompt that contains previously generated solutions. These new solutions are then evaluated and added to the prompt for the next optimization step. The researchers demonstrate the effectiveness of OPRO on linear regression and traveling salesman problems. They also show that prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K and up to 50% on Big-Bench Hard tasks. The paper, "Large Language Models as Optimizers," is available for download.

The discussion surrounding the submission about Google AI's OPRO approach includes various viewpoints and comments. One commenter argues that traditional derivative-based optimization algorithms cannot handle tasks without gradients, but another points out that these distinctions are inventions and not necessarily applicable in the realm of technology. Another user brings up Microsoft's Tay as an example of the unpredictability of training models. 

There is also a discussion about the importance of understanding the underlying system and the role of advanced technology in distinguishing it from magic. Some users emphasize the potential capabilities of language models (LLMs), while others express the difficulty in comprehending LLMs and their workings due to the lack of mathematical details. 

Another user mentions Charlie Stross's similar submission from a month ago, which leads to a brief conversation about whether one can credibly learn a service in a short period of time. Another thread veers off-topic into discussing Skyrim, the internet in general, and breaking large problems into smaller ones. 

The next set of comments focuses on the paper itself. One commenter highlights that OPRO outperforms human-designed prompts, while another comments on the difficulty in understanding the paper beyond its "academic crust." There are some exchanges regarding the process of optimization and the potential of LLMs to handle optimization problems. One user suggests that LLMs might be able to offer insights into proving optimization problems, while another brings up the distinction between text-based models like PaLM and 2L-Thought. 

There is further discussion about the challenges of providing good prompts and the potential for LLMs to help explain their thinking process. One user mentions their related work on black-box optimization using LLMs. Finally, there is a brief conversation about solving Sudoku puzzles and the potential applications of LLMs in solving complex problems.

---

## AI Submissions for Wed Sep 06 2023 {{ 'date': '2023-09-06T17:10:24.501Z' }}

### AOL pretends to be the internet

#### [Submission URL](https://thehistoryoftheweb.com/postscript/aol-pretends-to-be-the-internet/) | 148 points | by [janvdberg](https://news.ycombinator.com/user?id=janvdberg) | [243 comments](https://news.ycombinator.com/item?id=37404918)

AOL, formerly known as Quantum Computer Services, started out as a closed-loop network for computer users to connect with one another. However, in the mid-90s, AOL rebranded as America Online and aimed to bring networked computing to the masses. Their marketing strategy included an aggressive direct mailing campaign, sending out floppy disks and later CD-ROMs to households. The disks provided a few hours of free service, and once people started using AOL, they became hooked. AOL positioned itself as a content provider and brokered deals with major publishers and media companies. They wanted to own the experience of digital networks for their consumers and even considered producing original content exclusive to AOL. However, the rise of the Internet posed a threat to AOL's closed system. In 1994, AOL expanded support to certain Internet protocols, but notably, they did not have a web browser until acquiring BookLink in 1995 and adding Microsoft's Internet Explorer in 1996. AOL tried to position themselves as part of the Internet, but their identity eventually became subsumed by the wider, community-driven web and internet.

The discussion revolves around various aspects of URLs, QR codes, and the use of technology in daily life.

- Some users mention the use of AOL keywords and how they were an alternative to typing in full URLs. There is a reminiscence of using AOL and how it was a recognizable domain name that people would type.
- Others share their experiences with using URLs and how some websites reject URLs with a "www" prefix. There is a debate about whether it is necessary to include "www" before a website address.
- The importance of user experience and customer support is discussed, with some users emphasizing the need for intuitive interfaces and responsive support.
- The topic of email addresses is brought up, with users discussing the format and difficulty in understanding email addresses. Some users share their experiences with using different domain names and encountering confusion.
- The use of QR codes in various scenarios is debated, with some users finding them useful while others have had difficulty scanning them. The idea of QR codes in restaurants and the perceived assumptions about people's technological proficiency are discussed.
- The practicality and security of scanning QR codes are also mentioned. Some users express concerns about trust, unknown URLs, and relying on third-party services.
- The discussion also touches on the use of QR codes in different countries and how their popularity varies.

Overall, the discussion provides a range of perspectives on the use of technology in daily life, including URLs, email addresses, and QR codes. There are debates about convenience, security, and usability in different technological contexts.

### Proofs based on diagonalization help reveal the limits of algorithms

#### [Submission URL](https://www.quantamagazine.org/alan-turing-and-the-power-of-negative-thinking-20230905/) | 81 points | by [nsoonhui](https://news.ycombinator.com/user?id=nsoonhui) | [46 comments](https://news.ycombinator.com/item?id=37401228)

In a recent article on Quanta Magazine, Ben Brubaker explores the power of negative thinking in the work of legendary computer scientist Alan Turing. Turing pioneered the concept of "uncomputable" problems, which are problems that cannot be solved algorithmically. He proved the existence of such problems using a counterintuitive strategy based on a mathematical technique called diagonalization. Diagonalization involves building up a missing string bit by bit to ensure that it differs from every string on a given list. This approach plays well with infinity and has been used by mathematicians and computer scientists, including Turing, to prove various results. In Turing's case, he utilized diagonalization to construct an obstinate problem that would thwart every algorithm on an infinite list, demonstrating the existence of unsolvable problems. This contrarian approach to problem-solving has had a profound impact on the field of computer science and continues to inspire researchers today.

The discussion on this submission revolves around the concept of diagonalization and its application to proving the existence of uncomputable problems. Some commenters argue that the diagonalization argument used by Turing is not sufficient to prove the existence of uncomputable real numbers, while others provide counterarguments to support Turing's approach. There is also a discussion about constructive vs non-constructive mathematics and the limitations of diagonalization in a constructive framework. Overall, the discussion explores different perspectives on the power of negative thinking and its impact on computer science and mathematics.

### Can LLMs learn from a single example?

#### [Submission URL](https://www.fast.ai/posts/2023-09-04-learning-jumps/) | 426 points | by [jdkee](https://news.ycombinator.com/user?id=jdkee) | [133 comments](https://news.ycombinator.com/item?id=37399873)

A recent study on large language models (LLMs) has discovered a surprising anomaly in their training process. It was found that these models are capable of rapidly memorizing examples from the dataset after just a single exposure, which goes against the conventional wisdom about neural network sample efficiency. This unexpected phenomenon prompted further investigation and a series of experiments to validate and understand this behavior. The results indicate that the models indeed exhibit rapid memorization capabilities, questioning the current approach to training and utilizing LLMs. This finding opens up new possibilities for improving the efficiency and effectiveness of neural networks and challenges the long-standing assumption of their slow learning process.

The discussion surrounding the submission begins with a user named "jph00" expressing surprise at the rapid memorization capabilities of large language models (LLMs) and how it challenges existing assumptions about neural network sample efficiency. Another user, "og_kalu," suggests trying to freeze the training of LLMs after initial exposure to improve efficiency. "jph00" shares that the experiments conducted didn't show catastrophic forgetting, but rather the models becoming overly confident. They see this as an opportunity rather than a problem.

The conversation then shifts to other topics related to training and understanding neural networks. Users discuss training natural intelligence models, the potential for catastrophic forgetting, and the importance of freezing lower layers in LLMs to prevent forgetting fundamental knowledge. There is also mention of the Internal Family Systems model and its similarities to neural network training.

Some users express their appreciation for the investigation and its potential implications, while others request further explanation and clarification. There is a brief discussion about catastrophic forgetting and its impact on model performance. Another user asks for an explanation of the phenomenon in simpler terms (eli5). The concept of catastrophic forgetting is further explored, with some users suggesting modifications to the sampling model.

Overall, the discussion touches upon various aspects of neural network training, the mechanisms underlying LLMs, and the potential implications of the anomaly discovered in their training process.

### Artificial Consciousness Remains Impossible (Part 2)

#### [Submission URL](https://mindmatters.ai/2023/09/artificial-consciousness-remains-impossible-part-2/) | 20 points | by [momirlan](https://news.ycombinator.com/user?id=momirlan) | [82 comments](https://news.ycombinator.com/item?id=37412555)

In this article, the author presents responses to counterarguments against their thesis from part one. They address objections claiming that consciousness and intentionality are subjective and cannot be proven. The author argues that without intentionality, we would not understand anything, as words would not refer to anything. They also refute the idea that consciousness is something that is "done" and argue that an AGI could perform tasks without being conscious. 

The author then discusses objections from functionalism, which suggest that replicating the functions of a brain would lead to artificial consciousness. They argue that functionalist arguments fail because duplicating a function requires complete visibility and measurability of all functions and dependencies, which is not possible due to underdetermination. 

Finally, the author addresses behaviorist objections, which claim that reproducing conscious behaviors equates to producing consciousness. They disagree with the idea that observable behaviors alone indicate consciousness and reference the Chinese Room argument. 

Overall, the author provides counterarguments against various objections to their thesis, emphasizing the importance of intentionality and highlighting the limitations of functionalism and behaviorism in explaining consciousness.

The discussion on this submission covers various perspectives on consciousness and artificial intelligence. One commenter argues that artificial neural networks today do not have the same complexity and topology of states as real neural networks, while another points out that replicating the topology is not sufficient for generating consciousness. There is also a debate about whether consciousness is dependent on specific states of neurons or if it is a separate non-physical property. 

The conversation then shifts to the limitations of current AI models and the importance of memory in consciousness. Some commenters express their experiences of consciousness and memory, while others argue that consciousness cannot exist in artificial systems. 

The discussion also touches on functionalism, with one commenter arguing that replicating brain functions would not lead to artificial consciousness. Another commenter brings up the example of AlphaZero, a computer program that plays creative games of chess, to demonstrate that computers can exhibit creativity without conscious intention. 

There is also a disagreement about the significance of considering individuals' consciousness and the possibility of artificial consciousness. Some commenters argue that humans place too much importance on themselves, while others posit that empathy and understanding others' experiences are essential. 

The discussion concludes with a debate about the nature of intentional and qualitative experiences and their role in determining the existence of consciousness.

### Run ChatGPT-like LLMs on your laptop in 3 lines of code

#### [Submission URL](https://github.com/amaiya/onprem) | 141 points | by [amaiya](https://news.ycombinator.com/user?id=amaiya) | [33 comments](https://news.ycombinator.com/item?id=37412793)

OnPrem.LLM is a Python package that simplifies running large language models (LLMs) on-premises using non-public or sensitive data, even behind corporate firewalls. It was inspired by the privateGPT GitHub repo and Simon Willison's LLM command-line utility, and is designed to seamlessly integrate local LLMs into practical applications.

To get started, simply install OnPrem.LLM after installing PyTorch. You can then import the LLM class and instantiate it. By default, a 7B-parameter model is used, but you can specify a 13B-parameter model or provide the URL to an LLM of your choice.

Once set up, you can send prompts to the LLM to solve problems using few-shot prompting. You provide an example of what you want the LLM to do, and it generates the desired output. You can also talk to your documents by ingesting them into a vector database and asking questions about them. The LLM will generate answers based on the content of your documents.

Ingesting the documents involves specifying the directory containing the documents and creating embeddings for them. This process may take some time, but once complete, you can query your documents using the LLM's `ask` method to get answers to specific questions.

OnPrem.LLM is a powerful tool for running large language models on-premises and working with non-public data. With its user-friendly interface and seamless integration, it enables practical applications using LLMs behind corporate firewalls or with sensitive data. Give it a try and see how it can enhance your workflow!

The discussion on this submission revolves around various aspects of running large language models (LLMs) locally and the features and limitations of the OnPrem.LLM tool.

- One user shares a link to instructions on how to run the LLM locally on a Macbook with M1/M2 and 32GB RAM using the OnPrem.LLM tool. They mention that following these instructions allows them to run 34B models using both the CPU and GPU.

- Another user mentions that GGUF (Great Generic Unifying Framework) format was introduced in August 2023 as a replacement for GGML (Great Generic Modeling Language), and GGUF is supported by the OnPrem.LLM tool.

- A conversation ensues regarding the compatibility of OnPrem.LLM tool with different formats, and it is clarified that while it currently supports GGML format, there are plans to support GGUF format in future versions.

- A user praises the simplicity and usefulness of the OnPrem.LLM tool, mentioning that they have tried it and found it to be a great way to reduce the complexity of working with LLMs locally.

- Another user mentions that they learned about Simon Willison's LLM from the discussion and finds it interesting.

- A user shares a related project they have written, which handles streaming requests to local LLMs, and they mention that the OnPrem.LLM library offers a similar functionality.

- There is a brief discussion about the size of the LLM models, with one user explaining that a 7B-parameter model takes around 7GB of space.

- The effectiveness and efficiency of local LLM models are discussed, with one user mentioning that it depends on the specific use case and the optimization of the models.

- Some users express interest in trying out the OnPrem.LLM tool and commend the OP (original poster) for their work.

Overall, the discussion highlights the functionality and potential use cases of the OnPrem.LLM tool, as well as some technical details and comparisons with other similar tools and libraries.

### AI-generated child sex imagery has every US Attorney General calling for action

#### [Submission URL](https://arstechnica.com/information-technology/2023/09/ai-generated-child-sex-imagery-has-every-us-attorney-general-calling-for-action/) | 17 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [24 comments](https://news.ycombinator.com/item?id=37412525)

Attorneys general from all 50 states in the US, along with officials from four territories, have called on Congress to establish an expert commission to study how generative artificial intelligence (AI) could be used to exploit children through the creation of child sexual abuse material (CSAM). The attorneys general are concerned that AI is creating a new frontier for abuse that makes prosecution more difficult, particularly as open-source image synthesis technologies make it easy to create AI-generated pornography. They also want existing laws against CSAM to be expanded to explicitly cover AI-generated materials.

The discussion on this submission covers a range of perspectives on the issue of AI-generated child sexual abuse material (CSAM). Some users argue that AI-generated CSAM should not be legally considered CSAM, as it is fundamentally different from traditional material and may not involve the exploitation of actual children. Others express concerns about the potential harm caused by AI-generated CSAM and suggest that existing laws against CSAM should be expanded to explicitly cover AI-generated materials. There is also debate about the role of AI in identifying and preventing CSAM, with some users suggesting that AI could be used for better recognition and verification of CSAM, while others argue that AI could also be used to create more convincing and harmful content. Overall, the discussion explores different perspectives on the legal and ethical implications of AI-generated CSAM.

---

## AI Submissions for Tue Sep 05 2023 {{ 'date': '2023-09-05T17:09:32.081Z' }}

### Gizmodo fires Spanish staff amid switch to AI translator

#### [Submission URL](https://arstechnica.com/information-technology/2023/09/ai-took-my-job-literally-gizmodo-fires-spanish-staff-amid-switch-to-ai-translator/) | 55 points | by [stalfosknight](https://news.ycombinator.com/user?id=stalfosknight) | [26 comments](https://news.ycombinator.com/item?id=37399336)

Last week, Gizmodo en Español, the Spanish-language site of parent company G/O Media, fired its staff and replaced them with AI translations of English-language articles. The move has been met with criticism, as some of the AI-translated articles contain glitches and sudden switches from Spanish to English. This trend of media companies using AI tools to maximize content output while minimizing costs is controversial within the journalism community. While AI translation technology has improved, it still cannot fully replace human translators and can result in subtle errors and lack of cultural knowledge. Despite the potential negative implications, many media companies continue to experiment with AI-written content.

The discussion revolves around the quality of GPT-4 translations and the limitations of machine translation systems. Some users argue that GPT-4 translations, especially for languages like Korean and Japanese, are not accurate and struggle with context and cultural nuances. They note that the lack of certain grammatical elements and the difficulty in translating stylized or metaphorical texts are major challenges for machine translation. However, others point out that GPT-4 has made significant improvements in translation, and some even claim that it surpasses other translation services like DeepL and Google Translate. It is also highlighted that machine translation systems like GPT-4 can handle tasks that human translators wouldn't expect, such as jokes and technical writing. Overall, the debate emphasizes the need for human translation and the limitations of machine translation tools, particularly in capturing cultural and contextual nuances. Some users express concern over the impact on translation industry professionals who may see their work affected or diminished by the rise of AI translation.

### Android 14 blocks all modification of system certificates, even as root?

#### [Submission URL](https://httptoolkit.com/blog/android-14-breaks-system-certificate-installation/) | 312 points | by [pimterry](https://news.ycombinator.com/user?id=pimterry) | [234 comments](https://news.ycombinator.com/item?id=37391521)

In the latest release of Android, Android 14 (API v34), modifications to system certificates have been further restricted, even on fully rooted devices. This move marks a departure from Android's initial promise of openness and user control. Previously, users were able to modify the set of trusted certificates on their devices, but with Android 14, this becomes much more challenging. The set of certificate authorities (CAs) on a device determines the security of encrypted network traffic, and restricting user control over this can have significant implications for privacy and security research, app debugging, and enterprise network configurations. While rooting Android devices has been a workaround to these limitations, it is not officially endorsed by Google. In the past, rooted devices allowed users to manually add trusted certificates to the system store through file modifications. However, this process can be complex, as the /system directory is typically read-only. Workarounds include making the /system directory writable or mounting a temporary read-write file system. These methods have been effective in providing interception setups on rooted Android devices and emulators, enabling developers and researchers to analyze app communications. However, with the tighter restrictions in Android 14, these methods may become less effective. Overall, this shift towards limited user control highlights the ongoing tension between openness and vendor control in the Android ecosystem.

The discussion on this submission primarily revolves around the limitations and implications of the tighter restrictions on modifying system certificates in Android 14. Some users express concerns about the potential impact on privacy and security research, app debugging, and enterprise network configurations. There are discussions about workarounds on rooted devices, including making the /system directory writable or mounting a temporary read-write file system. Some users highlight the tension between openness and vendor control in the Android ecosystem. 

Other discussions touch on topics such as modifying system certificates on vanilla Android, the risks and dangers of unauthorized modifications to the OS, and the security and privacy implications of such modifications. There are also discussions about the benefits and drawbacks of using custom ROMs and the challenges faced by developers and users in finding overlaps between custom ROMs and necessary apps, such as banking apps.

### Stadiums Are Already Using Facial Recognition at Games

#### [Submission URL](https://gizmodo.com/9-stadiums-using-facial-recognition-games-rose-bowl-met-1850798207) | 23 points | by [ourmandave](https://news.ycombinator.com/user?id=ourmandave) | [8 comments](https://news.ycombinator.com/item?id=37394736)

Facial recognition technology is being increasingly used in sports stadiums across the US, but privacy advocates are raising concerns. The Philadelphia Phillies baseball team recently introduced a facial recognition authentication method called "Go-Ahead Entry" to decrease wait times at entry gates, but the system encountered glitches, causing security to create a "buffer zone" for the cameras. Other sports stadiums, including the New York Mets and the Cleveland Guardians, have also implemented facial recognition systems to speed up entry. However, critics argue that the technology does not work well for women or non-white individuals. A coalition of artists, including Rage Against the Machine, has pledged to boycott performing at stadiums that use facial recognition technology.

The discussion around the submission revolves around the use of facial recognition technology in sports stadiums. One commenter highlights the benefits of the technology, mentioning that it greatly reduces the time taken to find missing children, which is a frequent occurrence. Another commenter adds that the technology can also log where and when tickets are scanned. However, there are concerns raised about privacy and the technology's effectiveness, particularly for women and non-white individuals. One artist coalition has even pledged to boycott stadiums that use facial recognition technology. 

In another thread, a user criticizes those who complain about facial recognition, stating that the technology improves over time. They also argue that the concerns at Madison Square Garden (MSG) are exaggerated, as the headlines just represent the opinions of a few individuals. However, another commenter points out that the use of facial recognition in MSG has drawn criticism for its impact on privacy and its potential to disproportionately affect women and non-white individuals.

Another user shares their personal experience, discussing how their company's software for controlling video feeds in a stadium recognized faces, objects like backpacks and guns, and detected tampering. They mention that the system had specific steps triggered for different events, including spotting blacklisted individuals. They add that the company had hired regional architects and an Israeli project manager to develop the software.

In a different comment, a person shares their anecdote about the San Francisco Giants' game day, mentioning their confusion with metal detectors and cameras when attempting to enter using their StubHub tickets. They express concerns about the potential dangers of the technology.

Another user highlights the dystopian and conservative nature of facial recognition being implemented in public places such as California. They mention encountering systems in Japan and Houston but express anger and frustration over the rapid adoption of the technology in the Bay Area, where they have experienced it firsthand, including managing a traced engineering team in India.

In a final comment, a user criticizes the lack of discussion around facial recognition technology in general terms. They argue that people only seem to care when it directly affects them and their freedom and democracy, drawing a parallel to the lack of discussion about voting booth surveillance.

---

## AI Submissions for Mon Sep 04 2023 {{ 'date': '2023-09-04T17:09:43.400Z' }}

### Show HN: finetune LLMs via the Finetuning Hub

#### [Submission URL](https://github.com/georgian-io/LLM-Finetuning-Hub) | 75 points | by [rsaha7](https://news.ycombinator.com/user?id=rsaha7) | [7 comments](https://news.ycombinator.com/item?id=37381296)

LLM-Finetuning-Hub is a repository that contains code and insights for fine-tuning various large language models (LLMs) for different use cases. The repository provides an Evaluation Framework that includes four pillars: performance, time to train, cost to train, and inferencing. It aims to assist users in leveraging LLMs for their business needs, deciding which LLM suits their requirements, and boosting reproducibility efforts. The repository offers ready-to-use scripts for fine-tuning LLMs and performing hyperparameter optimization. The setup process is straightforward, involving the creation of a conda environment, installation of relevant packages, and running the fine-tuning scripts for the desired LLM. The repository also provides instructions for zero-shot and few-shot learning using the fine-tuned LLMs. Currently, the experiments have been conducted on an AWS EC2 instance with one 24GB Nvidia GPU.

The discussion in the comments about the submission revolves around different aspects of fine-tuning large language models (LLMs). 

One user expresses confusion about the purpose of fine-tuning LLMs and mentions the difficulty they face in finding proper data and understanding the process. Another user responds, explaining that fine-tuning LLMs is often done without a specific dataset, and it can be helpful for tasks such as question-answering by converting text articles or tweets into questions. They suggest that the lack of proper documentation might be the reason for the confusion.

Another user argues that fine-tuning LLMs can lead to nonsensical results because most of the training data is from non-FAANG (Facebook, Apple, Amazon, Netflix, Google) sources, which may not accurately represent real-world scenarios. They suggest alternative approaches, such as using code to guide the model's responses or manually searching related documentation.

There is also a discussion about the process of fine-tuning LLMs and the different components involved. One user suggests an approach that involves manually searching related documentation using BM25F and BERT models, and then using the retrieved snippets to help answer questions. They also mention the importance of latency requirements in the process.

A user raises the distinction between fine-tuning LLMs and training templates, stating that they are working on projects using GPU-backed instances on Google Cloud. Finally, one user appreciates the project and mentions its similarities to another project they are working on.

### TinyLlama project aims to pretrain a 1.1B Llama model on 3T tokens

#### [Submission URL](https://github.com/jzhang38/TinyLlama) | 198 points | by [cmitsakis](https://news.ycombinator.com/user?id=cmitsakis) | [60 comments](https://news.ycombinator.com/item?id=37379984)

The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens within just 90 days using 16 A100-40G GPUs. It adopts the same architecture and tokenizer as Llama 2, making it compatible with many open-source projects built upon Llama. Despite its compactness with only 1.1B parameters, TinyLlama can cater to various applications with restricted computational and memory requirements.

The project has released a schedule for rolling out intermediate checkpoints, allowing developers to track its progress. TinyLlama has already made significant progress and continues to do so. The project also provides potential use cases for tiny, yet powerful language models, such as assisting speculative decoding of larger models and enabling real-time dialogue generation in video games.

The training details of TinyLlama are also shared, including the training setup and hardware used. The codebase supports features like multi-gpu and multi-node distributed training, flash attention, fused layernorm, and more. These optimizations enable a high throughput of 24k tokens per second per A100-40G GPU, allowing for efficient training and reduced memory footprint.

Overall, TinyLlama offers a powerful and compact language model solution for various applications, and its progress in pretraining the 1.1B model is worth keeping an eye on.

The discussion on Hacker News revolves around the pretraining of the 1.1B Llama model on 3 trillion tokens by the TinyLlama project. One user wonders if the metatraining process will have less curvature and convergence due to the scheduled checkpoints, to which another user responds that the gradual decrease in learning rate may not necessarily help. A discussion also arises about the scaling laws and the performance of different models. Some users express skepticism about the cost and resources required for training these models, while others discuss the relevance of Chinchilla scaling laws and the practicality of deploying large-scale language models. Another user highlights the potential bottlenecks and cost efficiency issues when it comes to inference latency and the availability of GPUs in production environments. The scalability and economic implications of running large models in various settings are also debated. Overall, the discussion touches upon various aspects of training and deploying large language models, including the technical and practical considerations involved.

### Is macOS’s new XProtect behavioural security preparing to go live?

#### [Submission URL](https://eclecticlight.co/2023/09/04/is-macoss-new-xprotect-behavioural-security-preparing-to-go-live/) | 91 points | by [GavinAnderegg](https://news.ycombinator.com/user?id=GavinAnderegg) | [100 comments](https://news.ycombinator.com/item?id=37380104)

Apple's macOS security feature, XProtect, has received significant updates in recent months. XProtect consists of several components, including XProtect Remediator, which detects and removes known malware, and XProtect Behaviour Service (XBS), which observes potentially malicious behavior. The latest updates to XProtect Remediator have expanded its capabilities to detect 19 different types of malware on macOS 10.15 and later. Meanwhile, XBS has been recording potentially malicious behavior but has not yet taken any action to block it. The recent discovery of Bastion rules suggests that XBS may soon become more active in protecting macOS users. However, it remains unclear how updates to these rules are recognized by syspolicyd, the system policy daemon, and implemented without restarting macOS. These recent updates indicate Apple's dedication to improving macOS security, and it is anticipated that XBS will be ready to intervene in security threats in the near future.

The discussion around the submission mainly revolves around the effectiveness of Apple's security feature, XProtect, and the potential improvements it could bring to macOS security. Some users express skepticism about third-party security software and argue that Apple's built-in protection should be sufficient. Others raise concerns about Apple's documentation and control over third-party software that interacts with XProtect. There are also discussions about the challenges faced by developers when building applications for macOS and the limitations of the SwiftUI framework. Overall, the discussion highlights the importance of robust security measures and the need for continuous improvement in protecting macOS users.

### Robots pouring drinks in Vegas: As AI grows, the city's workers brace for change

#### [Submission URL](https://www.npr.org/2023/09/04/1197138244/vegas-ai-workers-brace-for-change) | 20 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [21 comments](https://news.ycombinator.com/item?id=37386280)

Las Vegas, a city known for its tourism and hospitality industry, is bracing for the impact of artificial intelligence (AI) and automation on its workforce. With robots already serving drinks and check-in kiosks replacing hotel front desk staff, the city's economy is at an inflection point as companies seek to reduce labor costs through technology. Studies show that between 38% to 65% of jobs in Las Vegas could be automated by 2035. To adapt to this change, the city will need to diversify its economy and focus on occupations that are less easily replaced by AI. The Culinary Union, which represents thousands of service and hospitality workers, is closely monitoring these developments and is prepared to strike over AI if necessary. While some workers believe that AI can never fully replace the human touch and experience, others are concerned about the potential loss of jobs. Overall, Las Vegas is undergoing a transformation as it prepares for the impact of AI on its service-heavy economy.

The discussion on this submission revolves around the use of AI and automation in Las Vegas, particularly in the hospitality industry. Some commenters highlight the potential benefits of AI, such as an AI bartender recognizing customers and handling return orders, as well as the potential for improved mental health by reducing pressure on human bartenders. Others express concerns about the loss of quality and consistency that may come with using robots instead of human bartenders. One commenter mentions that robotic bartenders could lead to wastage of individual drinks and potential theft, while another shares a story of an incident in a kitchen where a robot malfunctioned. Some commenters argue that the transition to AI and automation will result in a reduction in the number of workers supporting non-workers, while others suggest that this could be a positive shift. There are also discussions about the complexity of vending machine technology, the value of human touch in service, and the cost-effectiveness of using robots.