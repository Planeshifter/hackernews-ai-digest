import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Tue Oct 31 2023 {{ 'date': '2023-10-31T17:11:24.049Z' }}

### Norwegian ban on Meta behavioral advertising extended to entire EU

#### [Submission URL](https://www.datatilsynet.no/aktuelt/aktuelle-nyheter-2023/datatilsynets-vedtak-mot-meta-utvides-til-eueos-og-gjores-permanent/) | 417 points | by [aleksanb](https://news.ycombinator.com/user?id=aleksanb) | [227 comments](https://news.ycombinator.com/item?id=38092612)

Datatilsynet, the Norwegian Data Protection Authority, has received support from the European Data Protection Board (EDPB) in its ongoing battle against Meta (formerly known as Facebook) regarding ad-based tracking and profiling on its platforms. The EDPB has decided to make the Norwegian ban on ad-based marketing on Facebook and Instagram permanent and extend it to cover the entire European Union (EU) and European Economic Area (EEA). This decision comes after ongoing concerns about illegal tracking, surveillance, and profiling practices by Meta. The European Data Protection Board's decision serves as an instruction to the Irish Data Protection Commission to impose a permanent ban on Meta's European headquarters in Ireland. The ban will come into effect once this has been done. With over 250 million active users in the EU/EEA, Meta has repeatedly been called out for violating user privacy, and the EDPB's decision is seen as a firm stance against the company's disregard for the law. Meta has stated its intention to seek user consent for ad-based marketing in the future but has yet to make concrete changes to its practices. The Norwegian Data Protection Authority has expressed doubts about Meta's proposed consent solution, which would require non-consenting users to pay a fee. The EDPB's decision is crucial in ensuring that Meta's illegal activities are halted while the company searches for a lawful way forward.

The discussion on this submission revolves around various aspects of data privacy, Facebook's advertising practices, and the role of regulations in protecting user rights. Some users argue that Facebook and other companies track and share user data for advertising purposes, and that this violates user privacy. They also question the effectiveness of consent-based solutions proposed by Facebook. Others point out that newspapers and other media outlets engage in similar advertising behavior. One user highlights the double standards in criticizing Facebook while simultaneously participating in similar practices. There is also a discussion about the role of regulations and whether they are capable of addressing the privacy concerns raised by Facebook. Some argue that regulations are necessary to protect user rights, while others express skepticism about their effectiveness. Some users bring up alternative messaging platforms like Signal and WhatsApp, which prioritize privacy compliance.

The conversation extends to discussing job search and LinkedIn, as well as the trade-offs between privacy and the convenience offered by social media platforms. Users also debate the rights users have in exchanging their personal data for services. There is disagreement on the topic of regulation, with some arguing that it is necessary to regulate Facebook's policies and protect user privacy, while others question the validity of regulations and argue that they impede free speech and infringe on personal freedoms. Some users challenge the notion that Facebook should provide its services for free, arguing that many companies charge for services and data usage. The discussion also touches on the issue of data collection by companies and the ethical implications of monetizing personal data.

In conclusion, the discussion explores various perspectives on data privacy, the role of regulations, the practices of companies like Facebook, and the trade-offs inherent in the digital landscape.

### Microsoft has over a million paying GitHub Copilot users

#### [Submission URL](https://www.zdnet.com/article/microsoft-has-over-a-million-paying-github-copilot-users-ceo-nadella/) | 35 points | by [moonraker](https://news.ycombinator.com/user?id=moonraker) | [11 comments](https://news.ycombinator.com/item?id=38085907)

Microsoft CEO Satya Nadella announced that the number of paying customers for GitHub Copilot has increased by 40% in the September quarter compared to the prior quarter. He revealed that Microsoft has over 1 million paid Copilot users in more than 37,000 organizations around the world. Nadella also mentioned the introduction of Copilot Chat, which is already being used by companies like Shopify, Maersk, and PWC to boost developer productivity. Microsoft's integration of OpenAI's ChatGPT into its Bing search engine has resulted in over 1.9 billion chats with users. Additionally, Microsoft's Intelligent Cloud computing operations saw a revenue growth of 19% year over year, driven in part by higher-than-expected AI consumption. The company's Azure business rose 29%, with 3 percentage points coming from AI services. Nadella highlighted other uses of Copilot and AI, such as its integration with Microsoft's developer tools and Power Platform, its expansion in the healthcare industry, and its addition of generative AI to LinkedIn.

The discussion on this submission covers a range of topics related to GitHub Copilot and Microsoft's AI initiatives. Here are some key points from the comments:

1. Some users express frustration with the speed and productivity of GitHub Copilot, mentioning slow response times and back-and-forth interactions. One user indicates that they have canceled their Copilot subscription and prefer developing using Azure and OpenAI.
2. Another user highlights the potential of Copilot to generate code but mentions that it falls short when it comes to explaining complex functions or answering nuanced questions.
3. One commenter acknowledges the revenue potential of GitHub Copilot, estimating it could bring in $10 million in monthly recurring revenue. They praise Microsoft's achievement in building such a product.
4. There is a discussion about the cost and scalability of GitHub Copilot. One user suggests that unless 100 people are watching others type and quickly writing their own suggestions, the non-trivial maintenance and development costs of Copilot may not be sustainable.
5. A user cites a report claiming GitHub Copilot has heavy limitations, suggesting that $120 million in revenue might be untenable due to costs related to competitive salaries and GPU hardware.
6. A commenter brings up the issue of Microsoft's credibility, suggesting that the company has a history of misleading with its sales numbers, particularly in competitive markets.
7. This prompts a discussion about the ethics of a publicly traded company falsifying numbers, with one user implying that it may not be surprising for a company to engage in such behavior.

Overall, the comments touch on concerns about the performance and limitations of GitHub Copilot, its revenue potential, the cost scalability of the service, and skepticism regarding Microsoft's credibility in sales reporting.

### AI can diagnose type 2 diabetes in 10 seconds from your voice

#### [Submission URL](https://www.diabetes.co.uk/news/2023/oct/say-what-ai-can-diagnose-type-2-diabetes-in-10-seconds-from-your-voice.html) | 31 points | by [daoboy](https://news.ycombinator.com/user?id=daoboy) | [18 comments](https://news.ycombinator.com/item?id=38083857)

Researchers have trained an artificial intelligence (AI) model to diagnose type 2 diabetes by analyzing the voice of patients. The Canadian medical researchers used machine learning to identify 14 vocal differences between individuals with and without type 2 diabetes, including changes in pitch and intensity. The AI model, when combined with basic health data, could potentially provide remote and automatic diagnoses, lowering the cost and barriers to diabetes screening. The research team hopes that this AI technology will transform how diabetes is detected and enable more widespread screening for the condition.

The discussion on this submission revolves around the effectiveness and validity of using voice analysis to diagnose type 2 diabetes. Some users express skepticism, stating that factors like insulin resistance and vocal patterns related to being overweight are probably more indicative of diabetes than simple voice changes. They also suggest that people may not be honest when self-reporting their health conditions. 

Others provide more information about the study, stating that researchers from Klick Applied Sciences in Canada trained an AI model using 267 voice recordings of individuals living in India. The recordings were from 79 women and 113 men, with 72 participants being undiagnosed and 57 diagnosed with type 2 diabetes. Analysis of the recordings identified 14 vocal differences between the two groups. 

There is also a discussion about the accuracy of the AI model, with some users questioning the sensitivity and specificity of the model. They note that the published results did not provide detailed information on this. One user suggests that the results show a 75% accuracy rate, while others argue that this means there is still a 25% chance of misdiagnosis.

Some users express doubts about the study, pointing out its small sample size and the need for further research and replication. They also mention that voice analysis may only provide limited insights into metabolism and hearing ability related to diabetes.

In response to one user's comment about the study using BMI as a predictive model, another user clarifies that the AI model actually uses logistic regression and Naive Bayes methods rather than more advanced AI techniques. They also note that the study does not provide detailed information on the specific voice features used for analysis.

One user concludes that the study seems questionable and may not be reliable, while another states that they are a person with type 2 diabetes themselves.

### Tesla wins first US Autopilot trial involving fatal crash

#### [Submission URL](https://www.reuters.com/business/autos-transportation/tesla-wins-autopilot-trial-involving-fatal-crash-2023-10-31/) | 17 points | by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) | [12 comments](https://news.ycombinator.com/item?id=38089967)

Tesla has won its first trial in the United States over allegations that its Autopilot driver-assistant feature caused a fatal accident. The case involved a 2019 crash that resulted in the death of the vehicle's owner and serious injuries to two passengers. The lawsuit claimed that the Autopilot system caused the car to veer off the road and collide with a palm tree. However, Tesla successfully argued that the driver was at fault, as they had consumed alcohol before getting behind the wheel. This victory comes as Tesla faces multiple lawsuits and investigations related to its Autopilot technology. It also highlights the company's argument that the ultimate responsibility for incidents on the road lies with the human driver rather than the software.

The discussion on Hacker News revolves around the fairness of the trial decision and the responsibility of both Tesla and the driver in the fatal accident case. One user argues that if Tesla's marketing claims that Autopilot is self-driving, then it should also bear responsibility for accidents. Another user highlights an article that discusses the validity of the driver's blood alcohol content (BAC) and how a sudden swerving of a vehicle on the road can be a reason for collisions, even without the driver being completely intoxicated. There are also comments debating the need for verifying BAC levels and questioning the credibility of Tesla's software when it comes to ensuring driver safety. Another user raises concerns about Tesla's reliance on the human driver to handle emergencies and suggests that regulations should require more testing of autonomous systems in critical situations. In summary, the discussion covers various viewpoints on the trial, Tesla's marketing, the responsibility of the driver, the reliability of BAC measurements, and the importance of human supervision in autonomous driving technology.

---

## AI Submissions for Mon Oct 30 2023 {{ 'date': '2023-10-30T17:11:39.851Z' }}

### RedPajama v2 Open Dataset with 30T Tokens for Training LLMs

#### [Submission URL](https://together.ai/blog/redpajama-data-v2) | 216 points | by [programd](https://news.ycombinator.com/user?id=programd) | [54 comments](https://news.ycombinator.com/item?id=38077521)

Today, Together released a new version of the RedPajama dataset, called RedPajama-Data-v2. It is an open dataset containing 30 trillion filtered and deduplicated tokens from 84 CommonCrawl dumps in five languages: English, French, Spanish, German, and Italian. RedPajama-Data-v2 is the largest public dataset specifically released for training large language models (LLMs). What makes this release even more exciting is that it includes over 40 pre-computed quality annotations, allowing the community to further filter and weigh the data. The RedPajama-Data-v2 dataset aims to make it easier for LLM developers by providing a pool of web data that can serve as a base for high-quality datasets for LLM training. The dataset also includes code snippets that demonstrate how commonly used filtering rules can be implemented with RedPajama-V2. Overall, this release is a significant step towards the development of open datasets for training large language models.

The comments on this submission cover a wide range of topics related to the RedPajama dataset and language models.

One user suggests adding more features to the RedPajama dataset, such as topic modeling and extractive summarization. They also mention the importance of addressing the distribution of training data to better answer questions and provide supporting examples.

Another user points out a potential issue with the dataset, discussing the reversal curse problem where models may generate "B sn A" instead of "A's daughter."

There is a discussion about the hosting and downloading of the dataset. One user is confused about how the dataset is being released and asks for clarification. Another user explains that the dataset is being processed and filtered from CommonCrawl data and suggests contributing features or asking questions on GitHub.

There are discussions about the size and duplication of the dataset. One user points out that the RedPajama dataset is 150TB in size, and there is a debate about the redundancy and quality of the training data.

There are comments about the relevance of the dataset and the languages included. Some users express surprise at the inclusion of certain languages, while others discuss the importance of having a diverse range of languages for training language models.

There is a brief discussion about copyright infringement and the legal implications of using certain datasets. Users debate whether AI models that generate copyrighted content violate copyright laws.

Overall, the comments cover various aspects related to the RedPajama dataset, including its features, hosting, quality, relevance, and legal implications.

### Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence

#### [Submission URL](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/) | 222 points | by [Mandelmus](https://news.ycombinator.com/user?id=Mandelmus) | [329 comments](https://news.ycombinator.com/item?id=38067314)

President Biden Issues Executive Order to Advance AI Safety and Security, Protect Privacy, and Promote Equity
Today, President Joe Biden issued an Executive Order aimed at ensuring that the United States leads the way in harnessing the potential of artificial intelligence (AI) while managing its risks. The Order establishes new standards for AI safety and security, protects Americans' privacy, advances equity and civil rights, promotes innovation and competition, and strengthens American leadership in AI globally. 

One of the key actions mandated by the Order is the requirement for developers of powerful AI systems to share safety test results and critical information with the U.S. government. This will ensure that AI systems are safe, secure, and trustworthy before they are made public. Additionally, the National Institute of Standards and Technology will develop rigorous standards for extensive red-team testing of AI systems to ensure their safety. The Department of Homeland Security will apply these standards to critical infrastructure sectors and establish an AI Safety and Security Board.

The Executive Order also addresses the risks associated with using AI to engineer dangerous biological materials. Strong new standards for biological synthesis screening will be developed, ensuring that appropriate screening is carried out and potential risks exacerbated by AI are managed effectively. Furthermore, the Order aims to protect Americans from AI-enabled fraud and deception by establishing standards and best practices for detecting AI-generated content and authenticating official content.

In terms of privacy protection, the President calls on Congress to pass bipartisan data privacy legislation that safeguards Americans' privacy, especially that of children. The Order emphasizes federal support for the development and use of privacy-preserving techniques, including those that utilize AI, and directs funding towards research and development in this area. Additionally, the Order aims to evaluate and strengthen privacy guidance for federal agencies in light of AI risks and commercial data procurement.

Finally, the Executive Order addresses the potential for discrimination, bias, and other abuses in justice, healthcare, and housing resulting from irresponsible uses of AI. The Biden-Harris Administration has already taken steps to address these issues by publishing a Blueprint for a Coordinated Approach to AI, which prioritizes fairness and civil rights in the development and deployment of AI systems.

Overall, President Biden's Executive Order on AI signifies a comprehensive strategy for responsible innovation that addresses key areas of concern such as safety, security, privacy, and equity. It sets a new precedent for AI governance and aims to position the United States as a global leader in the responsible development and deployment of AI technologies.

The discussion on Hacker News revolves around different aspects of the Executive Order and its potential implications. Some users express concern about the potential for increased regulation stifling innovation, while others argue that regulation is necessary to ensure public safety and accountability. There is also a discussion about the ethics of AI development, with some users pointing out the risks associated with AI being used to create dangerous biological materials or autonomous weapons. The discussion touches on various topics, including government regulation, the role of large tech companies, the balance between innovation and safety, and the importance of privacy protection.

### Can I remove my personal data from GenAI training datasets?

#### [Submission URL](https://knowingmachines.org/knowing-legal-machines/legal-explainer/questions/can-i-remove-my-personal-data-from-genai-training-datasets) | 99 points | by [randomlogin](https://news.ycombinator.com/user?id=randomlogin) | [99 comments](https://news.ycombinator.com/item?id=38075924)

The short answer is that it is practically difficult to remove personal data from GenAI training datasets. Many GenAI products are trained on massive datasets that contain personal information scraped from popular websites, such as social media platforms and online encyclopedias. These datasets often include people's names and contact information. While some tools like "Have I Been Trained" and the earlier Exposing.ai project allow users to investigate whether their personal data is in these datasets, it is challenging to ascertain and remove personal data completely. 

Companies that create GenAI products often do not disclose the sources of their training data, making it even harder for individuals to determine if their data is included. Taking legal action or making data requests under laws like the California Consumer Privacy Act (CCPA) may be potential avenues for seeking the removal of personal data. However, companies may respond in idiosyncratic ways and further information may be required to process such requests. 

Currently, there is no foolproof method to force companies to disclose if and how much personal data has been used in training datasets. Even if companies were able to disclose and remove personal data, fully removing it from training datasets could unpredictably impact the performance of the GenAI models. The issue is being addressed by big tech players like Google, who are working on technical solutions such as the "Machine Unlearning Challenge" to protect privacy rights. However, until significant technical progress is made, companies may struggle to comply with data deletion provisions in privacy laws like the CCPA.

The discussion on Hacker News revolves around different aspects of the article. Here are some key points mentioned:

- Some users discuss the legal challenges of removing personal data from AI training datasets, highlighting the difficulties in compliance with laws like GDPR and CCPA.
- There is a debate about the expectation of privacy on the internet, with some users arguing that public postings should not be expected to remain private.
- The discussion also touches on the potential risk of misusing AI technology, such as the concern that AI models could be trained on sensitive or inappropriate content.
- Users highlight the importance of technological solutions to protect privacy rights, with some pointing out the need for better data handling practices by companies.
- There is a discussion about the potential role of legislation in regulating AI and protecting privacy, with some users expressing skepticism about the effectiveness of regulations in the face of technical challenges.
- Some users raise concerns about the power dynamics between individuals and companies, suggesting that companies should take responsibility for data privacy and make efforts to remove personal data from their AI products.

Overall, the discussion reflects a range of perspectives on the challenges and implications of removing personal data from AI training datasets and the broader issues surrounding privacy in the age of AI.

### Show HN: EnfinBref- {GPT3-5|Mistral-7B} YouTube summaries, segment by segment

#### [Submission URL](https://enfinbref.io/en/) | 21 points | by [bclavie](https://news.ycombinator.com/user?id=bclavie) | [10 comments](https://news.ycombinator.com/item?id=38077725)

Today's top story on Hacker News is a fascinating discussion on the future of artificial intelligence and its societal implications. One user shared an article that explores how AI is evolving at an unprecedented rate and what that means for humans. Are we on the verge of being outsmarted by machines? The comments are filled with thought-provoking insights from experts in the field, sparking a lively debate on the potential dangers and benefits of AI. Whether you're an AI enthusiast or simply curious about its impact on our lives, this discussion is a must-read. Dive in, and join the conversation!

The discussion on this submission revolves around segmenting videos, improving transcription, and the practical applications of AI in language processing.

- User "el_isma" suggests breaking down video segments based on specific time intervals, which could be useful for speech-to-text transcription and mastering complex tasks.
- User "zdmnsn" adds that they have tried summarizing sections of 20-40 minute French videos using section-dividing techniques and found it to be impressive.
- User "scfrnd" finds it useful to extract information from videos but mentions that sometimes the speech recognition software doesn't work efficiently.
- User "bnsystm" expresses their appreciation for local videos and asks for suggestions regarding specific scenarios and models related to video breakdowns and transcription.
- User "bclv" responds with gratitude and elaborates on different scenarios and models for video breakdowns and transcription. They also mention that their project started in 2018 but fizzled out and didn't have much success with pre-LLM implementations.
- User "bnsystm" thanks them and suggests that they should take their time and research more before fully committing to a new project.

Overall, the discussion highlights the challenges and potential applications of AI in language processing, especially in video segmentation and transcription tasks. Users appreciate the progress made so far and provide insights into the different factors to consider when implementing AI models for specific use cases.

### Google Brain founder says big tech is lying about AI danger

#### [Submission URL](https://www.afr.com/technology/google-brain-founder-says-big-tech-is-lying-about-ai-human-extinction-danger-20231027-p5efnz) | 391 points | by [emptysongglass](https://news.ycombinator.com/user?id=emptysongglass) | [390 comments](https://news.ycombinator.com/item?id=38072218)

Big Tech companies like OpenAI are using fear-mongering tactics to push for strict regulations on artificial intelligence (AI) that would ultimately stifle competition in the industry, according to Stanford University professor Andrew Ng. He argues that the idea that AI could lead to the extinction of humanity is a baseless claim being used as a ploy to promote heavy regulation. Ng believes that transparency rather than burdensome licensing requirements is what is truly needed in the AI sector. He also criticizes the regulatory capture campaign orchestrated by large tech firms to impose legislation harmful to the open-source community. While Ng agrees that some form of regulation is necessary, he emphasizes the importance of thoughtful regulation rather than arbitrary measures. Ng highlights the need for transparency from tech companies, as it would help prevent future AI disasters caused by the actions of big tech.

The discussion on the submission revolves around various viewpoints on the role of regulation and innovation in the AI industry, particularly in relation to China. Some users argue that strict regulations ensure safety and protect against intellectual property theft, while others believe that excessive regulations stifle competition and hinder small startups. There are also discussions on China's approach to innovation and its alleged practice of copying and stealing foreign designs. Some users emphasize the importance of cultural understanding in analyzing China's actions, while others highlight the need for fair and reasonable rules that align with global values. Overall, the discussion raises questions about the balance between regulation and innovation in the AI industry and the role China plays in this context.

### WebAuthn.wtf

#### [Submission URL](https://webauthn.wtf/) | 48 points | by [mooreds](https://news.ycombinator.com/user?id=mooreds) | [16 comments](https://news.ycombinator.com/item?id=38065083)

WebAuthn is an API specification that allows applications to use secure authentication methods for user registration and login. Instead of relying solely on passwords, WebAuthn enables users to authenticate themselves using hardware- or software-based authenticators. These authenticators use public-key cryptography to ensure secure registration and authentication of accounts.

With WebAuthn, users generate a public-private key pair, where the private key is stored securely on the user's device and the public key is registered with the web application server. During login, the user verifies their identity using the registered device, and the server validates the signature using the previously registered public key.

As a developer, you can utilize WebAuthn to provide your users with a more secure and user-friendly authentication mechanism. It is supported by most modern web browsers and platforms, and integration with existing authentication flows is made easier with open-source libraries and identity platforms.

In the WebAuthn world, the user's credential is the public-private key pair generated by an authenticator, rather than the traditional username and password. These credentials are commonly referred to as "passkeys." While WebAuthn is designed for single-device usage, syncing passkeys between devices is outside the scope of the specification.

To address the need for passkey syncing, large platform and operating system companies like Apple and Google have implemented their own secure channels. For example, Apple uses iCloud Keychain and Google uses Google Password Manager to sync passkeys across a user's compatible devices. This eliminates the need for a separate backup authenticator and provides a more convenient experience for users.

The discussion on this submission covers various aspects of WebAuthn and passkey syncing. Some users point out that certain password managers like 1Password, Bitwarden, and KeePassXC do not currently support WebAuthn. Others discuss the technical restrictions on authenticator attestation GUIDs and the different levels of support for WebAuthn across platforms and devices.

There are also discussions about the potential benefits and challenges of passkey syncing. Some users argue that passkey syncing can be achieved through existing platforms like iCloud Keychain and Google Password Manager, while others express concerns about the security and backup options for passkeys.

Further discussions highlight the need for better documentation and communication from the FIDO Alliance and criticize the current state of passkey implementation in various password managers. Some users mention the Linux support for passkeys and express frustration with the lack of support in Firefox.

Overall, the discussion revolves around the technical aspects and practical considerations of adopting WebAuthn and passkey syncing in different contexts.

### AI.gov

#### [Submission URL](https://ai.gov/) | 327 points | by [KoftaBob](https://news.ycombinator.com/user?id=KoftaBob) | [238 comments](https://news.ycombinator.com/item?id=38067206)

President Biden is making AI work for the American people, recognizing its potential as one of the most powerful technologies of our time. The Biden-Harris Administration has taken decisive action to protect safety and rights in the age of AI, ensuring that everyone can benefit from its promise. This includes signing an Executive Order to advance agencies' efforts on AI across the federal government and rapidly hiring talent to build and govern AI based on the administration's priorities. American students, workers, and educators are encouraged to build their AI skills to contribute to the nation's leadership in this field. Furthermore, the government is harnessing the opportunities of AI to improve its services for the public, and the National AI Advisory Committee advises the White House on AI-related issues.

The discussion on the article about President Biden's initiatives with AI focused on various aspects of government involvement in the field and its impact on the workforce.

One user pointed out that the US government often struggles with hiring and paying competitive salaries to attract top AI talent. They suggested adopting a similar model to the UK's Civil Service, which has been highly functional and effective in utilizing external consultants and contractors.

Another user mentioned the potential dangers of relying too heavily on innovation and neglecting the roles of civil servants. They emphasized the importance of balancing innovation with maintaining core government services.

The Digital Services team was also mentioned as a potential solution to improving government systems and services. However, there were concerns about the complexity and effectiveness of the Government Digital Services in the UK.

The discussion veered toward the topic of drug testing as a requirement for government jobs, with some arguing that it should not be a determining factor for employment. One user highlighted the federal legalization of marijuana and questioned the enforcement of drug testing in the workplace.

There were also mentions of issues with bureaucracy and the challenges of implementing quick changes and innovation within government structures.

Overall, the discussion touched on issues of hiring, innovation, privacy, and the role of government in shaping the AI landscape.

### Show HN: Web app to generate AI pictures with logos "hidden" in them

#### [Submission URL](https://logopictureai.com/) | 53 points | by [igorkotua](https://news.ycombinator.com/user?id=igorkotua) | [55 comments](https://news.ycombinator.com/item?id=38072074)

Introducing LogoPicture AI, the ultimate solution for creating stunning optical illusion art with your logo. No more struggling to find the perfect images for your brand – now you can easily generate captivating logo art in just a few minutes. With endless picture ideas limited only by your imagination, you'll never run out of inspiration. Even if you're feeling stuck, our AI will suggest creative ideas to get you started. Here's how it works: simply upload your logo in png or jpeg format, choose a style from our predefined prompts or create your own, and within minutes, you'll receive a collection of visually striking pictures right in your email. And the best part? It's incredibly affordable, with pricing plans starting at just $9.90 for 50 pictures. Plus, with a 7-day money-back guarantee for the Starter plan, you can try LogoPicture AI risk-free. Still have questions? Check out our FAQ section for answers to common queries. Don't wait – start generating mesmerizing logo art with LogoPicture AI today!

There is a mixed reaction to the submission of LogoPicture AI on Hacker News. Some users express skepticism about the tool, stating that people with Photoshop skills can easily create similar effects without the need for AI. Others compare it to Thomas Kinkade-style art and express doubts about its originality and quality. One user points out that there are already low-cost niche services available for image manipulation and suggests alternative tools. The pricing plans and refund policy of LogoPicture AI are also discussed, with some users expressing interest in trying the service for a lower price. The user interface and mobile optimization of the website receive criticism, while others appreciate the convenience of the predefined prompts and the ease of generating logo art. There is a brief discussion about the implementation of ControlNet and the demand for high-quality graphics. Some users mention the availability of similar tools and APIs, while others highlight the potential risks and ethical concerns of AI-generated content. Grammar issues on the website and the lack of a download feature for the generated images are also mentioned by users. The discussion concludes with users expressing varying levels of interest in trying the tool and suggesting potential improvements.

### An AI firm harvested billions of photos without consent. UK is powerless to act

#### [Submission URL](https://www.politico.eu/article/ai-ruling-obstruct-british-efforts-protect-citizens-images-us-data-harvesting/) | 42 points | by [ColinWright](https://news.ycombinator.com/user?id=ColinWright) | [17 comments](https://news.ycombinator.com/item?id=38066455)

In a recent ruling, Britain's top privacy regulator, the Information Commissioner's Office (ICO), has lost its appeal against Clearview AI, an American-based AI firm. Clearview AI came under fire in 2020 for harvesting billions of social media images without users' consent. The ICO had taken action against Clearview last year, issuing a £7.5 million fine and ordering the deletion of data of UK residents from its database. However, the recent ruling states that the ICO has no power to sanction the AI firm, leaving it unclear whether Clearview ever deleted the data. The ruling also highlights that the ICO lacks jurisdiction in the case as the data processing was carried out on behalf of foreign government agencies. The ICO is considering its next steps in response to the ruling.

The discussion on this submission covered a variety of topics related to Clearview AI and data privacy:

- One user mentioned that generally, pictures on the internet are restricted in usage and require the consent of the photographer. They also pointed out that using these pictures for training AI models could potentially infringe on copyright laws.
- Another user questioned whether it is legally acceptable for an AI program to send an explicitly reconstructed version of copyrighted images without permission.
- There was a brief tangent about copying and selling copies of Disney movies and recorded cable broadcasts without consent.
- One user highlighted the issue of the UK Information Commissioner's Office (ICO) being powerless to take action against Clearview AI, which brings into question whether the company deleted the data as ordered.
- Brexit and its impact on international trade and corporate strategy related to data privacy rights were also discussed. The user mentioned that the UK's powerless position may make it difficult to comply with international arrest warrants related to data protection laws.
- The availability of AI models like OpenAI's DALL-E, capable of generating content based on consented data, led to discussion on the potential for AI to circumvent content restrictions.
- The user pointed out that the theft of personal data by algorithms is a serious concern, given that AI systems process personal data subject to GDPR regulations.
- There was a brief comment about the idea of copying and stealing as related to the Clearview AI case.

Overall, the discussion touched on issues of consent, copyright, data privacy, international trade, and the role of AI in processing personal data.

---

## AI Submissions for Sun Oct 29 2023 {{ 'date': '2023-10-29T17:10:21.093Z' }}

### Casio fx-CG50 calculator comes with Python built-in

#### [Submission URL](https://www.casio.com/intl/scientific-calculators/product.FX-CG50/) | 114 points | by [miohtama](https://news.ycombinator.com/user?id=miohtama) | [140 comments](https://news.ycombinator.com/item?id=38063482)

Introducing the CASIO fx-CG50 graphing calculator with 3D graph and color display capabilities. This calculator allows users to easily draw and display up to three 3D graphs using templates. It also enables users to explore the mathematical relationships between different graph expressions. With features like zooming, rotation, cross section viewing, and axis views, users can analyze and manipulate 3D graphs in various ways. The calculator also has an E-CON4 application for collecting data in science and technology lessons, as well as examination mode for test preparations. Additionally, it can be connected to various devices and comes with software for emulating its operation on a computer. The calculator offers subscription options for accessing additional software and has basic functions like trigonometric calculations, matrix calculations, statistical analysis, and more. Its hardware features include a color display, a dot matrix display, and a high resolution. The calculator runs on AAA batteries and comes with accessories such as cables and a hard case.

The submission is about the Casio fx-CG50 graphing calculator with 3D graph and color display capabilities. The calculator allows users to draw and display up to three 3D graphs, explore mathematical relationships, and has features like zooming and rotation. It also has applications for collecting data and exam preparation. The discussion includes comments about the dominance of Casio and Texas Instruments in the calculator market, the use of calculators in exams, and the difficulty of finding non-programmable calculators for exams. There are also discussions about other calculator brands like HP and Swiss Micros, as well as discussions about programming calculators and creating Minecraft clones with calculators.

### AI can catalogue a forest's inhabitants simply by listening

#### [Submission URL](https://www.economist.com/science-and-technology/2023/10/25/ai-can-catalogue-a-forests-inhabitants-simply-by-listening) | 185 points | by [helsinkiandrew](https://news.ycombinator.com/user?id=helsinkiandrew) | [103 comments](https://news.ycombinator.com/item?id=38056841)

Researchers at the University of Würzburg have developed an AI system that can identify bird species in the rainforest by listening to their calls. The team collected sound recordings from 43 sites in the Ecuadorean rainforest and manually identified the various bird calls. Then, they trained an AI model to identify 75 bird species from their calls. The AI system was found to be just as accurate as human experts in identifying the bird species. This automated approach could be used to monitor reforestation projects and measure their effectiveness.

The discussion around the submission on Hacker News covers a wide range of topics related to the AI system that can identify bird species by listening to their calls. Some users discuss the potential applications and benefits of this technology, such as monitoring reforestation projects and conservation efforts. Others express skepticism about the effectiveness of AI in detecting maintenance issues in cars or the privacy concerns associated with recording bird sounds. There are also discussions about the market implications and commercial offerings related to the technology, as well as the potential for misuse of such data. Additionally, some users share their experiences with similar projects or express their concerns about the erosion of privacy.

### Genode – Genode on seL4 – IPC and virtual memory

#### [Submission URL](https://genode.org/documentation/articles/sel4_part_2) | 54 points | by [whereistimbo](https://news.ycombinator.com/user?id=whereistimbo) | [4 comments](https://news.ycombinator.com/item?id=38060698)

The article starts by explaining that in the L4 universe, IPC usually refers to synchronous communication between threads. In the case of seL4, IPC serves two purposes - enabling threads of different protection domains to exchange messages and delegating access rights throughout the system. Genode, a microkernel-based operating system, implements IPC using two thin abstractions: the IPC library for low-level message sending and receiving, and the RPC framework for higher-level message transfers.

To enable Genode's RPC mechanism on seL4, the author provides a seL4-specific IPC library implementation. To familiarize themselves with seL4's IPC mechanism, they modify an existing test program to perform an IPC call between two threads. The author walks through the code modifications needed to create an IPC endpoint, receive an incoming message, and make an IPC call.

However, when executing the code, they encounter an error related to an uninitialized register. The author fixes this error by initializing the GS register properly. Nevertheless, another error occurs due to the lack of a proper IPC buffer for the second thread. To solve this, the author sets up the IPC buffer for the second thread on the same page as the initial thread's IPC buffer.

With the initialization of the IPC buffer in place, the author finally achieves the desired output. The article concludes with the author's plan to address memory management issues in future articles in the series.

Overall, this article provides a detailed and hands-on exploration of IPC and virtual memory in the context of bringing Genode to the seL4 kernel. It offers valuable insights for those interested in kernel development and operating system design.

The discussion around the article "Genode on seL4 - IPC and virtual memory" on Hacker News includes several comments from users. 

User "rdtrmph" expresses their appreciation for sharing fascinating projects related to low-level operating system development in C++. They are interested in such projects and have their own ongoing project.

User "Palomides" comments that while they believe the project is overly hyped and practically unnecessary, it does showcase impressive achievements in software. They find the concept of running a microkernel-based BSD-like operating system on seL4 interesting but not practically valuable.

User "arp242" adds that comparing real-world performance of such systems to Linux and Windows could be an interesting exercise.

User "pjmlp" shares a link to a YouTube video about a C++ operating system utilizing coroutines and standard execution on a Raspberry Pi Pico.