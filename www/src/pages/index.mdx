import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Sat Oct 21 2023 {{ 'date': '2023-10-21T17:09:44.349Z' }}

### The Pixel 8 Pro's Tensor G3 off-loads all generative AI tasks to the cloud

#### [Submission URL](https://www.notebookcheck.net/MrWhosetheboss-video-reveals-Google-s-Pixel-8-Pro-Tensor-G3-off-loads-all-generative-AI-tasks-to-the-cloud.760215.0.html) | 227 points | by [redbell](https://news.ycombinator.com/user?id=redbell) | [126 comments](https://news.ycombinator.com/item?id=37966569)

In a recent video, popular YouTuber @Mrwhosetheboss criticized the Google Pixel 8 Pro for off-loading all generative AI tasks to the cloud. Despite Google advertising the device as "AI-first," it appears that the Tensor G3 processor in the Pixel 8 Pro is not able to handle these tasks on-board and requires a constant internet connection for processing. @Mrwhosetheboss noted that this leads to a sluggish user experience and suggests that the Tensor G3 chip is not quite flagship-level. This raises questions about Google's claims regarding the AI processing capabilities of the Tensor G3 and its overall performance metrics. It seems that Arm CPUs and GPUs, which are used in the Tensor G3, play a crucial role in processing AI tasks on the device. Additionally, Google faced controversy when it blocked reviewers from easily installing benchmark apps during the review embargo period, hinting at potential performance concerns. Overall, the Pixel 8 Pro's handling of generative AI tasks and its processor's capabilities have come under scrutiny.

The discussion on Hacker News revolves around the criticism of the Google Pixel 8 Pro and its handling of generative AI tasks. Some users express surprise at the device relying on cloud processing for AI tasks instead of being able to handle them on-board. Others mention that the Tensor G3 chip in the Pixel 8 Pro is likely capable of handling AI tasks locally, but Google's strategy is to offload computation to the cloud. There is also discussion about Google blocking reviewers from easily installing benchmark apps during the review embargo period, hinting at potential performance concerns. One user points out the advantage of Google's approach of offloading computation to the cloud, while others mention the disadvantages. There is also debate about the comparison of the Tensor G3 chip to other processors, such as the Qualcomm Snapdragon 8. Some users discuss the internet requirement for the Pixel 8 Pro and speculate on the reasons behind it. Overall, the discussion highlights concerns about the Pixel 8 Pro's handling of AI tasks and its processor's capabilities.

### AI Reduces the World to Stereotypes

#### [Submission URL](https://restofworld.org/2023/ai-image-stereotypes/) | 177 points | by [gigama](https://news.ycombinator.com/user?id=gigama) | [129 comments](https://news.ycombinator.com/item?id=37963909)

BuzzFeed faced controversy when it posted a list of images of Barbie dolls representing different countries, generated using artificial intelligence (AI) image generator Midjourney. The dolls contained numerous flaws and biases, such as light-skinned Asian Barbies and blonde-haired dolls representing countries like Thailand and the Philippines. This example highlights the biases and stereotypes prevalent in generative AI text-to-image systems. Bloomberg's analysis of over 5,000 AI-generated images also revealed biases, with higher-paying job titles associated with lighter skin tones and male-dominated results for most professional roles. A new analysis by Rest of World focused on national identities and found that Midjourney held biases, stereotypes, and reductionism for different countries, such as using an old man with a beard to represent an Indian person, and representing Mexican people as men wearing sombreros. Such stereotypical portrayals can flatten cultural diversity and lead to harm. Generative AI has various applications, including advertising, creative industries, and forensic sketches, meaning that how communities are represented can be heavily influenced by AI tools. Further progress is needed to address the biases and ensure the accurate representation of diverse cultures and communities.

The discussion surrounding the submission primarily focuses on the biases and limitations of generative AI image models like Midjourney. Commenters highlight the stereotypes and reductionism present in the AI-generated images, such as the portrayal of Mexican people wearing sombreros and Indian people represented as old men with beards. Some argue that the models have an incomplete understanding of cultural diversity and rely on clich√©s and generalizations. Others point out that the models may not have been properly trained or prompted to provide accurate representations. The conversation also touches on the challenges of labeling training data and the need for improved diversity and inclusion in AI models. Some commenters suggest that the current models may not have a deep understanding of different cultures and call for further progress in addressing biases and ensuring accurate representation. Additionally, there is a brief discussion about the role of ethnicity in AI-generated images and the importance of avoiding oversimplification and generalization.

### Strange Ways AI Disrupts Business Models

#### [Submission URL](https://www.implications.com/p/strange-ways-ai-disrupts-business) | 11 points | by [marban](https://news.ycombinator.com/user?id=marban) | [10 comments](https://news.ycombinator.com/item?id=37968436)

In the latest edition of Implications, the focus is on the strange ways that AI may disrupt business models. The article explores three main areas of concern: the perversion of certain business models due to real-time optimization and insights provided by AI, the potential disruption of time-based billing models in industries like law and design, and the threat of AI to the subjectivity in purchase decisions and the sway of brand and marketing. The author delves into each topic, offering insights and proposing potential solutions or alternative models. Overall, the article highlights the need for adaptation and innovation in the face of AI disruption.

The discussion on this submission focuses on various aspects of AI disruption and its implications:

- One commenter discusses Spotify's use of AI to optimize song length based on data analysis. They mention that AI can provide insights beyond what humans can understand, but caution against AI's potential to replace personal preferences and subjective judgment.
- Another commenter mentions the potential dystopian consequences of AI, particularly in terms of diminished trust, brand relationships, and decision-making. They question the mental reference of the original question and highlight the need to carefully program and regulate AI to avoid exploiting trust.
- A response to the previous comment acknowledges the potential benefits of AI-assisted personalized content, but emphasizes the importance of controlling the elements and influences that shape brand perception.
- Another commenter expresses confusion over the mental reference of the original question, finding it difficult to comprehend the question and its optimistic assumptions about AI's abilities.
- The discussion briefly touches on the need to think critically and understand the intentions behind AI disruption, rather than blindly accepting it.
- A comment suggests that the article's title is misleading and provides a short-sighted view of AI disruption.
- Two commenters discuss the impact of AI on brand influence and marketing strategies. They mention the potential of AI to provide objective purchasing advice but also highlight the importance of traditional marketing strategies in dealing with AI disruption.
- Another comment points out the irony that an article discussing AI's potential disruption was formatted using ChatGPT, which can undermine brand influence.
- A comment mentions that the article raises interesting points about AI disruption but lacks depth and is poorly written.

Overall, the discussion touches on concerns and debates regarding AI's impact on personalized experiences, brand relationships, decision-making, and traditional marketing strategies.

---

## AI Submissions for Fri Oct 20 2023 {{ 'date': '2023-10-20T17:09:32.757Z' }}

### AI tidies up Wikipedia's references and boosts reliability

#### [Submission URL](https://www.nature.com/articles/d41586-023-02894-x) | 141 points | by [clockworksoul](https://news.ycombinator.com/user?id=clockworksoul) | [81 comments](https://news.ycombinator.com/item?id=37955658)

Artificial intelligence (AI) could improve the accuracy and reliability of Wikipedia by cleaning up inaccurate or incomplete reference lists, according to a study published in Nature Machine Intelligence. The study developed a neural-network-powered system called SIDE, which analyzes whether Wikipedia references support the claims they're associated with and suggests better alternatives for those that don't. SIDE was trained using existing featured Wikipedia articles and was able to identify claims within pages that have poor-quality references. When tested, 21% of Wikipedia users preferred the citations suggested by the AI, while 10% preferred the existing citations and 39% had no preference. The tool could potentially save time for editors and moderators that check the accuracy of Wikipedia entries, as long as it is deployed correctly.

The discussion on this submission includes various points of view regarding the use of AI to improve Wikipedia and the accuracy of citations. Some users express skepticism, suggesting that the accuracy of references can still be subjective and that the interpretation of research papers is best left to experts. Others argue that abstracts are sufficient for determining the usefulness of a paper and that the problem lies in people misinterpreting them. One user suggests banning abstracts altogether and focusing on the full papers. Another user points out the importance of context in interpreting papers and the challenges of correcting misinformation on Wikipedia. Some users mention that self-publishing authors and publishers with vested interests can contribute to inaccuracies. The discussion also touches on the difficulty of accessing scholarly papers and the impact factor of journals. Overall, there are differing opinions on the effectiveness of AI in improving the accuracy of Wikipedia and the reliability of its citations.

### Confidential computing and AI fit together

#### [Submission URL](https://www.edgeless.systems/blog/how-confidential-computing-and-ai-fit-together/) | 46 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [4 comments](https://news.ycombinator.com/item?id=37955620)

In this blog post, Felix Schuster explores the intersection of AI and confidential computing. He explains the concept of "Confidential AI" and highlights three major use cases: secure outsourcing of AI workloads, intellectual property (IP) protection for AI models, and privacy-preserving AI training and inference. Schuster notes that until recently, confidential computing couldn't practically be applied to AI due to the lack of trust between secure enclaves and AI accelerators. However, Nvidia's latest GPUs, like the Hopper H100, now come with comprehensive confidential computing features, allowing for secure communication between CPUs and GPUs.

He provides a technical summary of how Nvidia implements confidential computing, including remote attestation, encryption of communication between CPUs and GPUs, and memory isolation. With these foundations in place, confidential AI becomes possible. The first use case Schuster discusses is the secure outsourcing of AI workloads. This enables companies to outsource AI tasks to an infrastructure they may not fully trust, such as a cloud provider. It can be particularly useful for banks or government institutions.

The second use case is IP protection for AI models. Confidential AI allows for the deployment of AI models in a way that prevents copying or altering. This is valuable when deploying proprietary AI models to customer sites or integrating them into 3rd party offerings. Finally, Schuster explores privacy-preserving AI training and inference. Confidential computing enables the creation of "black box" systems that verifiably preserve privacy for data sources. By designing software to keep input data private and running it in a confidential-computing environment, data sources can be assured that their data will remain private. With confidential computing-enabled GPUs, AI training and inference can now be performed while preserving data privacy.

Overall, Schuster highlights the exciting possibilities that arise from combining AI and confidential computing, opening up new avenues for secure and privacy-preserving applications.

The discussion on this submission revolves around the importance of protecting people's data and the vulnerabilities that arise when data is not encrypted. The significance of cryptography in the digital world is emphasized, with contributors highlighting its role in ensuring privacy and security. One user points out that the landscape of confidential computing has shifted from relying on cloud service providers and hardware vendors to technologies like AMD-SEV and Intel's SGX. Trust is central to confidential computing, and trust must exist somewhere in the system. Another user mentions that the responsibility of creating secure and confidential virtual machines falls on the trusted entities, such as hardware vendors and root of trust (RoT) manufacturers. However, they also highlight the challenge of hardware vendors having direct access to customers' machines, which could pose a threat to confidentiality. In addition, there is a discussion about the challenges of securely running machine learning models and the importance of ensuring the security of training data. The verifiability and improvements in hardware for confidential computing are recognized as positives. Overall, the discussion centers around the need for strong security measures, the role of cryptography, and the challenges and advancements in confidential computing.

### 'Mind-blowing' IBM chip speeds up AI

#### [Submission URL](https://www.nature.com/articles/d41586-023-03267-0) | 38 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [36 comments](https://news.ycombinator.com/item?id=37955421)

Researchers at IBM have developed a brain-inspired computer chip called NorthPole that could revolutionize artificial intelligence (AI) by performing tasks faster and consuming significantly less power than existing technologies. The chip integrates computing and memory on a large scale, eliminating the need for frequent access to external memory. NorthPole runs neural networks and contains 256 computing units, each with its own memory, interconnected in a network inspired by the human cerebral cortex. It outperforms existing AI machines in image recognition tests and uses one-fifth of the energy of state-of-the-art AI chips. However, the chip's limited RAM makes it unsuitable for large language models, and it can only run pre-programmed neural networks. Nevertheless, it holds promise for speed-critical applications like self-driving cars.

The discussion on Hacker News revolves around the features and limitations of IBM's NorthPole brain-inspired computer chip. One user clarifies that the chip is specifically designed for inference-focused neural networks and is not suitable for large language models. Another user points out that Apple's chips also have limited on-package memory. Users also discuss the efficiency and design considerations of different processors, including AMD Threadripper and Intel's upcoming Sapphire Rapids. The limited RAM of NorthPole is highlighted as a limitation for large language models like ChatGPT. However, another user refers to supplementary materials from IBM's paper, stating that NorthPole's memory includes 192 MB of flexible memory and 768KB of onboard memory. The discussion also touches on the size of training data for large language models and the potential future developments in chip technology for AI applications. Different processors and companies, such as TPU, Apple, and Graphcore, are mentioned as well.

### Meta and AI companies recruited striking actors to train AI

#### [Submission URL](https://www.technologyreview.com/2023/10/19/1081974/meta-realeyes-artificial-intelligence-hollywood-actors-strike/) | 14 points | by [ilamont](https://news.ycombinator.com/user?id=ilamont) | [5 comments](https://news.ycombinator.com/item?id=37956254)

A recent project involving AI and emotion recognition has raised concerns among actors about how their likeness and performances may be used without their consent. The project, run by emotion AI company Realeyes and supported by Meta, involved actors participating in a two-hour shoot where their facial expressions and movements were captured to train AI algorithms. While the job posting stated that participants' likenesses would not be used for commercial purposes, the broad rights they signed away suggest otherwise. Actors fear that AI technology could potentially replace them in the industry. Experts warn that companies can only promise so much when it comes to data privacy, especially as AI advancements continue to evolve rapidly. Some actors feel that the project is exploitative, taking advantage of out-of-work actors and pitting them against the use of AI. The lack of clear rules regarding AI and actors' rights adds to the uncertainty. Overall, the project highlights the complex issues surrounding the use of AI in entertainment and the need for informed consent and protections for actors.

The discussion mainly revolves around the concerns raised by actors regarding the use of AI in the entertainment industry. One user, scarface_74, suggests that Facebook might be using people's work without proper approval, highlighting the need for restrictions on the exchange of labor for money. User3456335 agrees and argues that actors should demand restrictions on the use of AI to improve its ethics. In response, scarface_74 remarks that many people are forced to join agencies and work in the industry, which is seen as shocking. However, user two_in_one challenges this perspective by saying that some actors willingly join the industry. Scarface_74 counters by stating that only a minority of actors have major movie and TV show roles. Overall, the discussion touches upon forced labor, actors' agency, and the concentration of opportunities in the entertainment sector.

---

## AI Submissions for Thu Oct 19 2023 {{ 'date': '2023-10-19T17:09:50.560Z' }}

### Amazon begins testing Agility's Digit robot for warehouse work

#### [Submission URL](https://techcrunch.com/2023/10/18/amazon-begins-testing-agilitys-digit-robot-for-warehouse-work/) | 48 points | by [hsnewman](https://news.ycombinator.com/user?id=hsnewman) | [28 comments](https://news.ycombinator.com/item?id=37948200)

Amazon has announced that it will begin testing Agility's bipedal robot, Digit, in its facilities. While the testing is still in its early stages, Amazon Robotics Chief Technologist Tye Brady stated that they are taking time to understand the technology better and see if it fits their processes. This move doesn't necessarily mean that Amazon will deploy Digit to its warehouse facilities, but it aligns with the company's previous investments in robotics startups. Agility is known for its advanced development and production of bipedal robots, which are designed to operate in human-designed spaces. Amazon believes that Digit has the potential to work collaboratively with employees and initially plans to use it for tote recycling tasks. In September, Amazon announced the expansion of its humanoid robot production capabilities in a new factory capable of producing over 10,000 robots per year.

The top story on Hacker News is about Amazon's announcement that it will begin testing Agility's bipedal robot, Digit, in its facilities. The testing is still in its early stages, and Amazon is trying to understand the technology better to see if it fits their processes. While this doesn't necessarily mean that Amazon will deploy Digit to its warehouse facilities, it aligns with the company's previous investments in robotics startups. Amazon believes that Digit has the potential to work collaboratively with employees and initially plans to use it for tote recycling tasks.

In the discussion, there are some comments praising the video by Tom Scott that discusses the concepts of bipedal humanoid robots. Others express amazement at the advancements in robotics and share other videos they have found interesting. There is also a comment mentioning that Ocado, a big company in the grocery distribution center space, has committed to using bipedal robots in its operations.

Another comment discusses Amazon's work environment and how it has changed over the years. Some users share their opinions on the nature of work and its impact on individuals and society. It touches on the complex relationship between employers, employees, and the purpose of work. One user mentions a personal story about a guidance counselor program that faced budget cuts and how it affected the dignity of the participants. The discussion also dives into the nature of compensation and the basic human needs that work fulfills, such as providing food, clothes, and shelter.

There are comments that emphasize the reliance on capital and organized labor in the modern human subsistence, contrasting it with hunter-gatherer societies. One user specially notes that they are a modern subsistence farmer, highlighting the fragility of the current civilization. Another user points out the need for hardware and software improvements in robotics.

Some comments express excitement about the breakthrough in robotics and the potential it has. One user mentions their experience as a Linux administrator and how Linux knowledge can be crucial in managing robotic systems. There is also a discussion about the software aspects of robotics, such as mapping and perception algorithms, with the mention of ROS (Robot Operating System) and other tools.

A few users make critical remarks about the practicality and effectiveness of bipedal robots, suggesting that non-bipedal robots currently used in Amazon's fulfillment centers are more efficient for certain tasks. Another user sees Amazon's adoption of bipedal robots as a PR exercise similar to the introduction of Amazon Prime or drones for deliveries.

Overall, the discussion revolves around the potential impact and practicality of bipedal robots in the context of Amazon's operations, as well as broader conversations about work, compensation, and the future of robotics.

### On Stewart's Apple TV Plus show ends, reportedly over coverage of AI and China

#### [Submission URL](https://www.theverge.com/2023/10/19/23924549/jon-stewart-apple-ai-china-cancel) | 67 points | by [thecybernerd](https://news.ycombinator.com/user?id=thecybernerd) | [23 comments](https://news.ycombinator.com/item?id=37949512)

Apple TV Plus' show, "The Problem With Jon Stewart," has reportedly come to an end due to creative differences between host Jon Stewart and Apple. According to reports, concerns over the show's guests and Stewart's intended discussions of artificial intelligence (AI) and China were major points of contention. Apple expressed the need for Stewart and his team to align with the company's views on these topics, but Stewart chose to walk away instead. The cancellation of the show comes as no surprise considering Apple's focus on maintaining a cordial relationship with China and its plans for growth.

The discussion surrounding the cancellation of "The Problem With Jon Stewart" on Apple TV Plus primarily revolves around Apple's relationship with China and its content moderation policies. Some users point out instances where Apple has bent to Chinese regulators, such as not allowing the Taiwanese flag on its devices and removing certain apps. Others discuss Apple's self-censorship in order to maintain a good relationship with China, citing Disney's actions with the Chinese government and the treatment of Uyghurs. There are mixed reactions to Apple's approach, with some praising the company and others criticizing it. One user suggests considering alternative products and platforms that align more with one's values. The discussion also veers into opinions on Jon Stewart himself and his role as an entertainer versus a journalist. Some users appreciate his comedic approach to news and commentary, while others believe he is more focused on entertainment and lacks the independence and objectivity of a journalist.

### Music publishers sue AI company Anthropic over song lyrics

#### [Submission URL](https://www.reuters.com/legal/music-publishers-sue-ai-company-anthropic-over-song-lyrics-2023-10-18/) | 14 points | by [dndn1](https://news.ycombinator.com/user?id=dndn1) | [4 comments](https://news.ycombinator.com/item?id=37940732)

Music publishers Universal Music, ABKCO, and Concord have filed a lawsuit against artificial intelligence company Anthropic in Tennessee federal court. The publishers accuse Anthropic of misusing copyrighted song lyrics to train its chatbot Claude. According to the lawsuit, Anthropic violates the publishers' rights by using lyrics from at least 500 songs without obtaining permission. This appears to be the first case involving song lyrics and the use of copyrighted material to train generative-AI systems. Anthropic, which has received financial backing from Google, Amazon, and former cryptocurrency billionaire Sam Bankman-Fried, has not yet responded to the lawsuit.

The discussion begins with a comment that speculates about the potential consequences of an advanced AI developed by Anthropic. The commenter suggests that it could lead to the downfall of civilization if intellectual property laws are not carefully regulated to prevent AI systems from accessing copyrighted material. Another user responds, expressing concern about the potential harm to websites hosting song lyrics that engage in copyright infringement. The discussion then veers off-topic with a remark about the role-playing game genre, followed by a comment suggesting that the lawsuit should be dismissed promptly. Lastly, a user dismisses the idea of licensing song lyrics as being silly.