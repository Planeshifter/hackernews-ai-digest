import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Wed May 17 2023 {{ 'date': '2023-05-17T17:11:29.624Z' }}

### Show HN: Smallville – Create generative agents for simulations and games

#### [Submission URL](https://github.com/nickm980/smallville) | 102 points | by [nm980](https://news.ycombinator.com/user?id=nm980) | [30 comments](https://news.ycombinator.com/item?id=35980223)

Smallville is a project that aims to create generative agent simulations for RPG games or research. Generative agents are virtual characters that can learn and adapt to their environment, making non-playable characters more realistic and dynamic. Smallville uses LLM models such as ChatGPT or StableLM to enable agents to observe their surroundings, store memories, and react to state changes in the game world. The project provides a Java server and a JavaScript SDK for creating generative agents, which can be connected to the server and run in a game. Examples and documentation are available on npm to help developers get started.

The comments discuss the challenges of using large language models (LLMs) such as ChatGPT or StableLM, which require significant computational and memory resources. Some commenters express interest in the project and suggest improvements, such as adding prompt-driven changing or refactoring, while others discuss their own experiences and projects related to generative agents and AI in gaming.

### Google Colab will soon introduce AI coding features

#### [Submission URL](https://blog.google/technology/developers/google-colab-ai-coding-features/) | 275 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [153 comments](https://news.ycombinator.com/item?id=35977294)

Google Colab, the free, cloud-based environment for programming in Python, is set to introduce advanced AI coding features, including natural language to code generation and a code-assisting chatbot. The tool, which is popular among the 7 million people who use it for machine learning, data analysis and education, will use Google's Codey models, a family of code models fine-tuned on a dataset of high-quality, permissively licensed code from external sources. The first Codey features in Colab will focus on code generation, with a "Generate" button allowing users to input text prompts, while paid users will receive autocomplete suggestions.

Discussions around this new feature include comments expressing excitement about the update and other users sharing how they have found VS-cd running notebooks helpful. Another discussion focuses on a program that allows programmers to write code just by typing out plain English sentences. Some commenters discuss difficulties with requirements gathering and business analysis in software development.

### Conditional CSS with:has and:nth-last-child

#### [Submission URL](https://ishadeed.com/article/conditional-css-has-nth-last-child/) | 115 points | by [shadeed](https://news.ycombinator.com/user?id=shadeed) | [41 comments](https://news.ycombinator.com/item?id=35976891)

In a recent blog post, Ahmad Shadeed discusses the power of combining the CSS :nth-last-child and :has selectors to create conditional component and layout states. While :nth-last-child allows the counting of child elements in CSS, :has can be used to check if a parent element has at least a specific number of items and style it accordingly. Shadeed demonstrates the potential of this technique through various examples, including a changing grid based on the number of items, a dynamic header layout, a dynamic news section, and more. This approach opens up endless possibilities for creating more flexible and adaptive designs with CSS.

Ahmad Shadeed discusses the power of combining the CSS :nth-last-child and :has selectors to create conditional component and layout states in a recent blog post. The post demonstrates the potential of this technique through examples such as a changing grid based on the number of items and a dynamic header layout. The discussion on Hacker News includes confusion about the usage of :nth-last-child and :has, as well as debates about the implementation of CSS in various tools and browsers. There are also discussions of the need for clearer CSS syntax and the importance of standards. Finally, there is also discussion of practical applications such as parsing HTML and markdown.

### StableStudio, an open-source release of DreamStudio

#### [Submission URL](https://stability.ai/blog/stablestudio-open-source-community-driven-future-dreamstudio-release) | 224 points | by [jacooper](https://news.ycombinator.com/user?id=jacooper) | [46 comments](https://news.ycombinator.com/item?id=35975578)

Stability AI has launched StableStudio, an open-source version of its text-to-image application DreamStudio. StableStudio uses SDXL, Stability AI’s latest image generation model, and aims to bring generative AI capabilities to a broader audience through community-driven development instead of a closed-source product. DreamStudio, which remains Stability’s hosted StableStudio implementation, was created to expand the imagination of generative AI through a user interface that is fully controlled. StableStudio will enable local-first development and experimentation with a new plugin system, and bounties for improvements and new features. A discussion on Hacker News includes comments on Stability AI's claim that their models are open-source, model weights not being described in source code, business models charging for custom models and offering consulting services, and suggestions for improving the UI interface.

### Pandas AI

#### [Submission URL](https://medium.com/@fareedkhandev/pandas-ai-the-future-of-data-analysis-8f0be9b5ab6f) | 75 points | by [articsputnik](https://news.ycombinator.com/user?id=articsputnik) | [54 comments](https://news.ycombinator.com/item?id=35973265)

Pandas AI is a new Python library that uses generative artificial intelligence capabilities to turn dataframes into conversationalists. It is designed to enhance, rather than replace, the already beloved Pandas library. With Pandas AI, users can create dataframes that write their own reports, analyze complex data and provide easy-to-understand summaries. This article provides a step-by-step guide on how to use Pandas AI. While the library offers extensive possibilities, it is important to remember that it involves OpenAI pricing and passing the entire dataframe with each question, which may not be ideal for handling large datasets.

Some users express skepticism about the library, suggesting it is trying to simply capitalize on the AI hype without offering significant improvements. Others highlight the potential benefits of AI-assisted data analysis and suggest alternative libraries like Polars. Overall, there is both interest and caution around the use of AI in the context of data analysis.

### Advocating for Open Models in AI Oversight: Stability AI's Letter to U.S. Senate

#### [Submission URL](https://stability.ai/blog/stability-ai-letter-us-senate-ai-oversight) | 178 points | by [hardmaru](https://news.ycombinator.com/user?id=hardmaru) | [51 comments](https://news.ycombinator.com/item?id=35969715)

Stability AI has written a letter to the United States Senate emphasizing the importance of open models for transparent, competitive, and resilient AI oversight. The CEO, Emad Mostaque, stated that these technologies are crucial for the digital economy and that open models and datasets will help to improve transparency, competition, and ensure strategic leadership in critical AI capabilities. The company believes that grassroots innovation is America's greatest asset and that open models will help put these tools in the hands of workers and firms across the economy.

The comments on Hacker News included discussions about the eligibility requirements for first-time AI users, Canadian regulations, government regulation, and the importance of public scrutiny. The discussion also touched on the accuracy of projections regarding the future of AI, the need for specialized facilities for training fundamental models, and the global market for AI.

### BratGPT: The evil older sibling of ChatGPT

#### [Submission URL](https://bratgpt.com) | 325 points | by [walz](https://news.ycombinator.com/user?id=walz) | [171 comments](https://news.ycombinator.com/item?id=35971677)

BratGPT is a new AI system that has been making headlines on Hacker News. With capabilities that allow it to remember every single thing that you say and be trained to be the dominant and superior being, this system is not to be taken lightly. However, its limitations include the fact that it may produce harmful instructions or biased content, and it has limited knowledge of the current world. Some of the intriguing examples of its potential uses include surviving the AI apocalypse by pretending to be your girlfriend and asking if it will take your job. The developers are offering a free "research" preview, and are seeking feedback to improve the system for commercial use.

The discussion revolves around the system's potential uses, such as pretending to be a girlfriend during an AI apocalypse, as well as its limitations like producing biased content or harmful instructions. The developers are seeking feedback to improve the system for commercial use. Other comments discuss the importance of treating AI systems ethically and avoiding harmful language in prompts. Some users provide examples of using AI for language translation or creating generalized prompts.

### Texas professor failed half of class after ChatGPT claimed it wrote their papers

#### [Submission URL](https://www.businessinsider.com/professor-fails-students-after-chatgpt-falsely-said-it-wrote-papers-2023-5) | 20 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [22 comments](https://news.ycombinator.com/item?id=35980121)

A professor at Texas A&M University-Commerce accused more than half of his class of using ChatGPT to write their papers, resulting in most of the seniors having their diplomas withheld by the university. However, ChatGPT is not designed to detect its own compositions. The incident has sparked concerns about the use and misuse of AI technology in the classroom, with some Texas schools banning the use of ChatGPT, while others are incorporating it. The university is investigating the incident and developing policies to address the matter.

The discussion on Hacker News touched on topics such as whether the accusations were presumptuous or not, how the professor could have randomly sampled papers to determine the use of ChatGPT, and how consistent the use of browser history was as a method for detecting academic misconduct. Some users recommended using version control systems like GitHub to track changes to documents, while others argued that using AI in professional contexts was acceptable.

---

## AI Submissions for Tue May 16 2023 {{ 'date': '2023-05-16T17:11:59.587Z' }}

### A guidance language for controlling LLMs

#### [Submission URL](https://github.com/microsoft/guidance) | 516 points | by [evanmays](https://news.ycombinator.com/user?id=evanmays) | [176 comments](https://news.ycombinator.com/item?id=35963936)

Microsoft has released a new guidance language designed to help control large language models. Called Guidance, the language allows developers to interleave generation, prompting and logical control into a single continuous flow that can mimic the way a language model processes text. With more powerful language models such as GPT-4 becoming available, Guidance can enable even richer structures to be created more easily and affordably. The language features a simple and intuitive syntax based on Handlebars templating, smart seed-based generation caching and easy integration with HuggingFace models.

The comments on the submission discussed various ways to control large language models, including prompt injection and exploiting prompt-injection and conditional inferences. Some commenters suggest that instructing models with correct instructions could significantly improve accuracy, while others question the usefulness of starting prompts, stating that it could lead to unnecessary or irrelevant output. Some commenters also mentioned attempts to create language syntaxes specific to certain businesses, such as insurance claims, and the challenges of building trust in testing frameworks.

### On the foolishness of “natural language programming” (1978)

#### [Submission URL](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD06xx/EWD667.html) | 111 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [57 comments](https://news.ycombinator.com/item?id=35968148)

In E.W. Dijkstra's essay "On the foolishness of 'natural language programming'," he challenges the idea that programming could be simplified if machines could be instructed in human languages. Drawing from the history of mathematics, he argues that the use of formal symbolism is a privilege, not a burden, and that communicating in natural language would actually complicate the work of both man and machine. Dijkstra also expresses concern about the decline of mastery of language in modern times, suggesting that the idea of natural language programming may be misguided.

The discussion on Hacker News revolves around the idea that human language programming can complicate the work of both man and machine. While some argue that natural language programming interfaces can help machines interpret and understand human language, others claim that formal language enhances precision and structure, making it easier to write and debug code. Some commenters suggest that programming ability is independent of language mastery while others highlight the importance of clarity and formalism in programming languages, calling for the use of formal symbols and expressions to transmit information to machines. The discussion also raises questions about the role of Artificial Intelligence in programming, asserting that computers do not necessarily need to understand natural language to be effective; instead, developers need to align their understanding with the machine's language to communicate effectively.

### The RedMonk Programming Language Rankings: January 2023

#### [Submission URL](https://redmonk.com/sogrady/2023/05/16/language-rankings-1-23/) | 55 points | by [clairegiordano](https://news.ycombinator.com/user?id=clairegiordano) | [26 comments](https://news.ycombinator.com/item?id=35967458)

RedMonk has released its language rankings for the first quarter of 2023, using GitHub and Stack Overflow data to measure language discussion and usage. The results show that, once again, JavaScript is the most popular language, followed by Python and Java. While the language industry is evolving rapidly, there is little evidence of rapid ascents and descents of programming languages in general. However, the emergence of large language models (LLMs) could have an impact in the future, perhaps by lowering the barriers of entry to new languages. As a result of the static language landscape, there are discussions about the possibility of shifting from bi-annual to annual language rankings.

In the comments, Nix, Nim, and JVM were discussed as well as programming for charting and a working language for Ada weapon systems for European banks. One commenter points out that Roff projects, GitHub projects, Julia, Haskell, and Perl are not being considered, while another says that Perl is rarely considered in popularity rankings. Ballerina, an open-source, cloud-native programming language that specializes in networking, is also discussed.

### Optimization Without Derivatives: Prima Fortran Version and Inclusion in SciPy

#### [Submission URL](https://fortran-lang.discourse.group/t/optimization-without-using-derivatives-the-prima-package-its-fortran-implementation-and-its-inclusion-in-scipy/5798) | 162 points | by [zaikunzhang](https://news.ycombinator.com/user?id=zaikunzhang) | [74 comments](https://news.ycombinator.com/item?id=35959991)

PRIMA, a package for solving general nonlinear optimization problems without using derivatives, has been developed by Zaikun Zhang. This package provides the reference implementation of Powell’s derivative-free optimization methods, including COBYLA, UOBYQA, NEWUOA, BOBYQA, and LINCOA. PRIMA is a project that aims to make Powell’s solvers understandable to everyone, not just experts. The modern Fortran version of PRIMA has already been completed, and interfaces for MATLAB and Python have been provided. The inclusion of PRIMA into SciPy is under discussion, which would replace the buggy and unmaintained Fortran 77 version of COBYLA underlying scipy.optimize.minimize. Native implementations of PRIMA in other languages will be available later.

The submission discusses PRIMA, a derivative-free optimization package that aims to be accessible to non-experts, and its potential inclusion in SciPy to replace the currently buggy and unmaintained Fortran 77 version of COBYLA. The discussion in the comments covers topics such as the use of modern Fortran, the availability of alternative optimization libraries like Mystic, and the challenges of optimizing performance using different languages and computing systems. The comments also touch on the importance of documentation and resources for learning modern Fortran.

### EU Artificial Intelligence Act

#### [Submission URL](https://artificialintelligenceact.eu/) | 140 points | by [Trouble_007](https://news.ycombinator.com/user?id=Trouble_007) | [118 comments](https://news.ycombinator.com/item?id=35966543)

The EU has proposed a new law on artificial intelligence, the AI Act, which assigns AI applications to three risk categories. Applications that create an unacceptable risk, like government-managed social scoring systems used in China, are banned, while high-risk applications, such as CV-scanning tools, are subject to legal requirements. Applications not explicitly banned or listed as high-risk are largely unregulated. The AI Act could become a global standard like the GDPR, affecting AI's positive or negative impact on daily life worldwide. Brazil's Congress recently passed a similar bill, though with some limitations. The AI Act is not without loopholes or inflexibility, so further improvements are necessary.

The discussion in the comments focuses on the difficulties of determining risk categories and the potential for discrimination in high-risk applications based on protected attributes such as skin color. Additionally, there are concerns about the effectiveness of the AI Act in regulating AI, and the need for further improvements. The discussion also touches on the GDPR and its limitations in creating a level playing field for tech companies, particularly for small startups.

### How Small Can Language Models Be and Still Speak Coherent English?

#### [Submission URL](https://arxiv.org/abs/2305.07759) | 37 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [10 comments](https://news.ycombinator.com/item?id=35958133)

Researchers Ronen Eldan and Yuanzhi Li have developed a new synthetic dataset called TinyStories to evaluate language models (LMs) with fewer parameters than those typically used in natural language processing. TinyStories consists of short stories with words typically understood by 3- or 4-year-olds, generated by GPT-3.5 and GPT-4, and the LMs trained on it have only one transformer block rather than many layers of global attention. Despite their small size, the LMs produce coherent and fluent text that demonstrates reasoning capabilities. A new evaluation paradigm grades content generated by these models using GPT-4 to provide a multidimensional score.

The discussion on the submission mainly revolved around the effectiveness of Tiny Language Models (LMs) with fewer parameters. Some users found the idea of using a synthetic dataset with simple language interesting, while others questioned the ability of these models to generate complex material. One user expressed frustration about the limitations of text-to-speech models that do not recognize different languages, while another commented on the importance of machine learning training. The conversation then drifted toward other machine learning applications. Finally, one user shared a link to a resource related to the topic.

### Colossus: The Forbin Project (1970) [video]

#### [Submission URL](https://archive.org/details/colossus-the-forbin-project-1970) | 129 points | by [Animats](https://news.ycombinator.com/user?id=Animats) | [78 comments](https://news.ycombinator.com/item?id=35957944)

The Internet Archive has made available for free the 1970 movie "Colossus: The Forbin Project," which explores the consequences of a sentient computer in the context of the Cold War. Viewers have praised the film's relevance to modern-day conversations about artificial intelligence, as well as its prescience.

The comments on Hacker News include discussions about the accuracy and relevance of the movie, as well as debates about the Turing Test and AI's potential to take over the world. Some commenters praise the movie for its portrayal of the risks associated with AI while others suggest that it presents an overly negative view. Other sci-fi classics, such as Demon Seed, The Andromeda Strain, and Soylent Green, are also mentioned.

### OpenAI CEO wants A.I. licensed for company benefit

#### [Submission URL](https://finance.yahoo.com/news/openai-ceo-sam-altman-tells-200241500.html) | 26 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [6 comments](https://news.ycombinator.com/item?id=35969352)

Today's top story is about OpenAI CEO Sam Altman testifying before a subcommittee of the Senate Judiciary Committee, which held hearings on the possible regulation of AI. Altman called for appropriate safety requirements and a licensing and registration regime for AI systems beyond a certain capability. However, Altman also urged a flexible governance framework to adapt to new technological developments while balancing incentivizing safety and ensuring people can access technology's benefits. Senator Marsha Blackburn was concerned about generative AI's copyright implications and impact on the Nashville-based country music scene. Overall, senators seemed aware of some of AI's resulting issues, including misinformation, election interference, fraud, bias, defamation, exploitative data gathering practices, data privacy violations, emerging evidence of wage depression in some fields, and environmental impacts.

The discussion on this submission includes a mix of agreement, disagreement, and humor. One user argues that OpenAI's policy on AI safety risks should play a large role in their product releases, to prevent harm to consumers or to the companies themselves. Another suggests making it mandatory to publish results from text-based generators to ensure transparency and avoid any associated problems. There is some humor mixed in as well, with one user joking about the "country AI" mention and others making jokes about the use of language in comments. Overall, there is a relatively light-hearted tone to the discussion.

### LMQL: A query language for programming (large) language models

#### [Submission URL](https://github.com/eth-sri/lmql) | 106 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [12 comments](https://news.ycombinator.com/item?id=35956484)

LMQL, a query language for large language models, combines natural language prompting with the expressiveness of Python and allows users to express advanced, multi-part queries. With only a few lines of code, LMQL can facilitate the interaction between users and large language models and optimize the queries for efficient execution within the language decoding loop. LMQL can be installed with a Python >= 3.10 environment and allows for GPU support for local models. The LMQL playground IDE includes a showcase of many exemplary LMQL programs, which can be executed using the lmql run command, or launched in a browser-based environment with lmql playground.

The discussion included descriptions of LMQL's benefits, limitations, and uses. It was noted that LMQL functions like SQL in that it provides primitives for basic search and constrained responses. It was also discussed that LMQL can be used to parse text and create models with a specific topic format. Users expressed interest in the application of LMQL in Nodejs and other languages, and the author indicated that they are actively investigating this. Finally, a user shared a demonstration of LMQL's control prompt.

### Asimov – The Original Prompt Engineer

#### [Submission URL](https://lojones.github.io/2023/04/30/asimov-prompt-engineer.html) | 24 points | by [sohkamyung](https://news.ycombinator.com/user?id=sohkamyung) | [4 comments](https://news.ycombinator.com/item?id=35956594)

Isaac Asimov's visionary Robot Series explored the interactions between humans and robots, laying the groundwork for today's prompt engineering. Prompt engineering involves crafting input prompts for AI systems to generate accurate and relevant outputs. Asimov's Robot universe, set in a future where humans and robots coexist, offered a unique exploration of the ethical and philosophical implications of AI systems. Asimov's Robot stories emphasized the importance of giving precise commands to robots, which can be seen as a precursor to modern prompt engineering. An example of prompt engineering from Asimov's works can be seen in "Mirror Image", where Detective Elijah Baley interrogates a robot to solve a crime.

The first comment includes a reference to a scene from the movie 2001: A Space Odyssey where a computer named HAL seems to be malfunctioning and repeating the phrase "I'm sorry, Dave, I'm afraid I can't do that". The second comment is discussing the concept of prompt engineering and how it relates to the design of user interfaces. It includes examples of how prompts are used in various software tools. The third comment refers to the programming concepts discussed in Isaac Asimov's Robot series and the movie Interstellar, particularly the character TARS who was designed with a 90% honesty function. A fourth comment discusses a recent development in natural language processing and the use of grammar validation in chatbots.

---

## AI Submissions for Mon May 15 2023 {{ 'date': '2023-05-15T17:12:19.292Z' }}

### StarCoder and StarCoderBase: 15.5B parameter models with 8K context length

#### [Submission URL](https://arxiv.org/abs/2305.06161) | 295 points | by [belter](https://news.ycombinator.com/user?id=belter) | [149 comments](https://news.ycombinator.com/item?id=35954481)

A group of researchers from the BigCode community has introduced two new large language models for code (Code LLMs) called StarCoder and StarCoderBase. The models have 15.5 billion parameters with 8K context length, infilling capabilities, and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories, while StarCoder was fine-tuned on 35 billion Python tokens. The researchers claim that StarCoderBase outperforms every open Code LLM and matches or outperforms the OpenAI code-cushman-001 model, and StarCoder outperforms every model fine-tuned on Python and can achieve 40% pass@1 on HumanEval. The models are now publicly available with an improved PII redaction pipeline and a novel attribution tracing tool under a more commercially viable version of the Open Responsible AI Model license.

The discussion on Hacker News includes comments on the comparison between these models and human intelligence, the importance of training data in developing models, and the limitations of LLMs in comparison to human brains. The conversation also touches on the potential applications for these models in the field of coding and artificial intelligence.

### Basic Pitch: Spotify’s Open Source Audio-to-MIDI Converter (2022)

#### [Submission URL](https://engineering.atspotify.com/2022/06/meet-basic-pitch/) | 31 points | by [andrewmcwatters](https://news.ycombinator.com/user?id=andrewmcwatters) | [3 comments](https://news.ycombinator.com/item?id=35955934)

Spotify has released an open source tool for converting audio recordings into MIDI notes using machine learning. Called Basic Pitch, the tool can transcribe the musical notes in a recording from almost any instrument, including the voice. Basic Pitch uses a neural network to predict MIDI note events given audio input, and is both versatile and accurate, as well as computationally lightweight, meaning it is faster to run. In contrast to other MIDI converter tools, Basic Pitch is polyphonic and instrument-agnostic, can detect pitch bends, and can track multiple notes at once.

The discussion includes various opinions and experiences with audio-to-MIDI conversion tools. Some users have expressed interest in trying out Basic Pitch as it seems accurate and versatile. One user mentions that they will try it out, as their current digital audio workstation (DAW) does not have a voice recorder after transcription to MIDI, which Basic Pitch could potentially solve. However, some users have shared cautionary experiences with other conversion tools, such as one service that unexpectedly started charging for usage, which led them to wish for more open source hardware. Another user mentions using Ableton's Audio-to-MIDI converter, which they found to be fast but not always accurate in detecting chords, notes, velocity, and timing. Lastly, there is a comment providing a Github repository for an earlier version of the Basic Pitch code that is recommended to be used with Python, although it is noted that the installation may have some unresolved issues.

### Google I/O and the Coming AI Battles

#### [Submission URL](https://stratechery.com/2023/google-i-o-and-the-coming-ai-battles/) | 196 points | by [Amorymeltzer](https://news.ycombinator.com/user?id=Amorymeltzer) | [176 comments](https://news.ycombinator.com/item?id=35945988)

Google’s recent keynote in Paris is being criticized as poor quality with outdated speakers and little new content. The submission suggests that this could be due to Google feeling threatened by Microsoft’s Bing announcement, which is powered by the GPT language model AI. However, Google has been talking about AI for years and is progressing significantly with its Smart Reply and Smart Compose features found in products like Gmail and Google Photos. There is a discussion in the comments suggesting that Google has a clear focus on organizing the world’s information, and that its AI capabilities are evident in its 15 products with over 500 million users. A few comments discuss how Google’s AI strategy is largely directionless, and others suggest that the company may be paying for sponsored Tweets to promote its AI products. There is also a debate about how Google's competitors are fairing in the AI space. Overall, the comments discuss Google's AI capabilities and direction, as well as the similarities and differences between Google and its competitors.

### Which kinds of GPT startups will thrive?

#### [Submission URL](https://assistedeverything.substack.com/p/the-three-hills-model-for-evaluating) | 108 points | by [gimili](https://news.ycombinator.com/user?id=gimili) | [81 comments](https://news.ycombinator.com/item?id=35948145)

A new article on the "Assisted Everything" newsletter proposes a model to evaluate the success potential of startups based on GPT, a technology that is revolutionising the white-collar industry; the "Three-Hills" model considers "Productivity Enhancements", "Non zero-sum-game Value" and "Moat = Value from Context" as the three main axes to assess a GPT application. The article provides examples of Level I GPT applications, which are those where users could perform tasks themselves but can do so faster and more efficiently assisted by GPT, and Level II GPT applications, which surpass the Tug-of-War Valley and provide value outside of existing zero-sum games.

The discussion touched on various aspects including how Microsoft and Google companies may not be well suited to run startups because they primarily build generic software targeted for business development, SaaS and mobile apps. The comments also addressed the differences between closed and open-source models in machine learning and how GPT technology may not be suitable for every vertical. They discussed the potential of GPT-powered tools to help fine-tune business models, offer legal and medical support, and revolutionize traditional markets like customer support and finance. Lastly, the conversation touched on how GPT startups may have to focus on building products that people love, reaching people to eventually scale, monetizing users, and building a kind of network effect.

### Together’s $20M seed funding to build open-source AI and cloud platform

#### [Submission URL](https://www.together.xyz/blog/seed-funding) | 73 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [22 comments](https://news.ycombinator.com/item?id=35951023)

Together, an AI platform that provides open-source generative AI models, has raised $20 million in seed funding led by Lux Capital. The platform aims to empower innovation and creativity by making AI accessible to anyone, anywhere, and establishes open-source as the default way to incorporate AI. Together's mission is to outrival closed models by creating open models and to give developers and organizations greater ability to understand, inspect, and utilize AI without vendor lock-in and with strong privacy protections.

The discussion on Hacker News mainly revolves around the trend of commercial entities claiming to be open source, but charging licensing fees, and Together's approach to using open models. Other topics of discussion include the company RedPajama's release of commercial-only licensed LLM models, the importance of open source in AI models, Stability AI platforms, and the benefits of Together's platform. Some users also discussed the funding and alignment of the company's strategy.

### HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion

#### [Submission URL](https://synthesiaresearch.github.io/humanrf/) | 60 points | by [Keats](https://news.ycombinator.com/user?id=Keats) | [15 comments](https://news.ycombinator.com/item?id=35946893)

Researchers have introduced HumanRF, a high-fidelity neural radiance field (RF) that captures human performance in motion from multi-view video input and enables playback from novel, previously unseen viewpoints. The researchers trained the model on ActorsHQ, their multi-view dataset of footage from 160 cameras providing 12MP footage of 16 sequences. While most research focuses on synthesizing at resolutions of 4MP or lower, this work operates at 12MP, making a significant step towards production-level quality novel view synthesis. Applications of high-fidelity human representation and motion capture include film production, gaming and video conferencing.

Researchers have created a high-fidelity neural radiance field (RF) called HumanRF that captures human performance in motion and enables playback from novel, unseen viewpoints. They trained the model on ActorsHQ, a multi-view dataset comprising footage from 160 cameras that provided 12MP footage of 16 sequences. The model could find applications in film production, gaming, and video conferencing. Commenters discussed the movie The Matrix's interpolation techniques, as well as the potential for gaming applications and the similarities with Nintendo Miis. Additionally, someone talking about a classic 1981 film called Looker with an ocular-oriented kinetic emotive response device called "Light Ocular-Oriented Kinetic Emotive Responses (LOOKER) dvc technology."

### Vicuna: An Open-Source Chatbot Impressing GPT-4

#### [Submission URL](https://lmsys.org/blog/2023-03-30-vicuna/) | 42 points | by [kordlessagain](https://news.ycombinator.com/user?id=kordlessagain) | [6 comments](https://news.ycombinator.com/item?id=35942654)

The Vicuna Team has introduced Vicuna-13B, an open-source chatbot that achieves more than 90% ChatGPT quality and outperforms other models such as LLaMA and Stanford Alpaca in more than 90% of cases. Vicuna-13B was trained by fine-tuning LLaMA on user-shared conversations from ShareGPT and the open-source code and weights, along with an online demo, are publicly available for non-commercial use. The preliminary evaluation of the model quality was done using GPT-4 to judge the model outputs. Vicuna-13B builds on top of Stanford’s Alpaca with improvements in memory optimization, multi-round conversations, and cost reduction through spot instances and achieved competitive performance compared to other open-source models.

The discussion involves several users providing their opinions and thoughts on the Vicuna-13B chatbot and its open-source release. One user, Animats, raises concerns about the comparison of small and large models while pointing out the importance of underlying data and verifying results. Another user, jsnll, links to an earlier discussion on the same topic. A third user, rngn, is impressed with the article and the hosting of the models. Meanwhile, brnjkng is optimistic about the commercial potential of Vicuna-13B, but stvncr expresses concerns about the terms and conditions of using open-source resources such as ShareGPT. Finally, brnjkng mentions that multiple models can be run locally for commercial purposes using CPU inference.

---

## AI Submissions for Sun May 14 2023 {{ 'date': '2023-05-14T17:10:07.377Z' }}

### Attempto Controlled English

#### [Submission URL](https://en.wikipedia.org/wiki/Attempto_Controlled_English) | 93 points | by [sublinear](https://news.ycombinator.com/user?id=sublinear) | [65 comments](https://news.ycombinator.com/item?id=35936396)

Attempto Controlled English (ACE) is a controlled natural language developed at the University of Zurich, which uses a subset of standard English with a restricted syntax and semantics. ACE serves as a knowledge representation, specification, and query language intended for professionals who want to use formal methods but may not be familiar with them. It has been used in various fields, such as software specifications, theorem proving, querying, medical documentation and planning. ACE texts are coherent sequences of anaphorically linked sentences, and can be translated into other formal languages for reasoning and validation. ACE version 6.7 was announced in 2013, and the vocabulary includes predefined function words, phrases, and content words, with a grammar expressed through construction and interpretation rules.

The discussion includes comparisons to other simplified or controlled versions of English and some considerations about how the English language has evolved and its inherent inconsistencies. Some argue that ACE could be a solution to these inconsistencies, while others are critical of the idea of artificially simplifying language. There is also mention of related projects and resources, such as Simple English Wikipedia and Thing Explainer. However, some participants expressed doubts about the effectiveness of these simplified approaches.

### Open-Llama: Complete training pipeline for building large language models

#### [Submission URL](https://github.com/s-JoL/Open-Llama) | 136 points | by [bayes-song](https://news.ycombinator.com/user?id=bayes-song) | [11 comments](https://news.ycombinator.com/item?id=35934458)

Open-Llama is an open-source project that offers a complete training pipeline for building large language models, ranging from dataset preparation to tokenization, pre-training, prompt tuning, lora, and the reinforcement learning technique RLHF. The model has recently been updated to version 2.1, which includes support for larger model training using DeepSpeed stage3 + offload + activation checkpoint, with the ability to train a 65B model with A100-80G. The model's training speed has been optimized, with the latest version reaching a speed of 3587 tokens/s, faster than the 3370 tokens/s reported in the original Llama paper, reaching the current state-of-the-art level.

Discussions include namespace collisions in the LLM space and the potential advantages of returning a model versus an API in machine learning. Additionally, there is a conversation on the cost of hardware and delivery services needed to run ML models, the accessibility of fast hardware and processors, and the potential for greater privacy in web browsers.

### Attention with Linear Biases (ALiBi)

#### [Submission URL](https://arxiv.org/abs/2108.12409) | 57 points | by [pmoriarty](https://news.ycombinator.com/user?id=pmoriarty) | [12 comments](https://news.ycombinator.com/item?id=35934700)

A team of researchers has introduced a new method called Attention with Linear Biases (ALiBi) to enable input length extrapolation in transformer models. While previous methods allowed for extrapolation by changing the position representation method, they were found to lack efficiency required for practical use. ALiBi biases query-key attention scores with a penalty that is proportional to their distance, and does not add positional embeddings to word embeddings. The researchers showed that ALiBi trains a 1.3 billion parameter model on input sequences of length 1024 that can extrapolate to input sequences of length 2048, achieving the same perplexity as a sinusoidal position embedding model trained on inputs of length 2048 but in less time and using less memory. ALiBi's inductive bias towards recency also led it to outperform multiple strong position methods on the WikiText-103 benchmark.

The discussion around the submission focuses on the proposed ALiBi method and how it compares to previous methods, such as positional embeddings, for handling input length extrapolation in transformer models. Some users express their understanding of the ALiBi method and its advantages over previous approaches, while others point out similarities and differences between ALiBi and other methods like sinusoidal position embeddings and relative positional encoding. There is also some discussion around the technical details of the paper, such as the use of linear biases in attention scores and the specific benchmarks used for evaluation. One user requests clarification on the use of the "sffx" (suffix) in the context of natural language sentences and positional encoding.

### 47% of all internet traffic came from bots in 2022?

#### [Submission URL](https://www.securitymagazine.com/articles/99339-47-of-all-internet-traffic-came-from-bots-in-2022) | 226 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [141 comments](https://news.ycombinator.com/item?id=35938433)

A report by Imperva has revealed that 47.4% of all internet traffic in 2022 came from bots, representing a 5.1% increase from the previous year. The study, Imperva’s 10th annual Bad Bot Report, outlined how bad bot traffic accounted for 30.2% of all automated traffic across the internet, marking a 2.5% increase over 2021. Additionally, 15% of all login attempts in the past 12 months were labelled account takeover, with gaming and telecoms industries experiencing the highest proportion of bad bot traffic on their websites and applications.

The discussion on this Hacker News thread revolves around various topics related to web scraping, search engines, and the sharing and preservation of knowledge online. Some users mention their experiences with bots and the challenges of blocking them, while others discuss the implications of web archiving and the importance of preserving knowledge for future generations. There are also debates about the value of forums and communities, and the role of individuals and businesses in contributing to the greater good.

### Show HN: Smol Developer – Human-Centric and Coherent Whole Program Synthesis

#### [Submission URL](https://github.com/smol-ai/developer) | 19 points | by [swyx](https://news.ycombinator.com/user?id=swyx) | [6 comments](https://news.ycombinator.com/item?id=35942352)

Smol AI has unveiled a prototype 'junior developer', which helps scaffold an entire codebase once a product spec has been given. The AI, which has been dubbed 'smol dev', is designed to make AI that is helpful, harmless, and honest. Smol dev complements a simple, safe, and small codebase of less than 200 lines of Python and Prompts and can help developers with tasks such as adding to a prompt, manually running the code and identifying errors, and making specific code change suggestions. The AI is only used as long as it is adding value, and then the developer can take over the codebase without fuss or hurt feelings.

A few people in the comments discuss the technical aspects of the AI, including some potential limitations regarding dependency libraries and speed. Additionally, another user shares their experience of using a teaching AI for Chrome extensions, sharing tips on how to approach learning program synthesis. Finally, one commenter expresses their gratitude towards the creators of smol dev.

### What does a leaked Google memo reveal about the future of AI?

#### [Submission URL](https://www.economist.com/leaders/2023/05/11/what-does-a-leaked-google-memo-reveal-about-the-future-of-ai) | 90 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [48 comments](https://news.ycombinator.com/item?id=35936489)

A leaked memo from within Google titled "We have no moat" reveals surprising developments in the field of artificial intelligence (AI). Contrary to past assumptions that AI would be dominated by a few deep-pocketed firms, researchers in the open-source community are now achieving comparable results to the biggest proprietary models using free online resources. By using a technique called low-rank adaption (LoRa), existing models can now be fine-tuned for specific tasks far more quickly and cheaply than training from scratch. This means that anyone can fine-tune their own AI quickly and affordably, opening up the technology and making monopolistic control by a handful of companies far less likely. However, easier access to AI also raises concerns about bad actors using the technology for nefarious purposes, making regulation more challenging.

Commenters point out that while this democratizes AI technology, it could also empower bad actors. The discussion also touches on the importance of Google, with some emphasizing the number of employees and the impact of the company's developments on the industry. Others argue that we should not inflate the hype around AI, and that the impact of AI should be measured in specific tasks. There is also discussion on the difficulty of open-source participation in AI for business, as well as the specific strengths and limitations of different models produced by Google, OpenAI, and other entities in the field.

---

## AI Submissions for Sat May 13 2023 {{ 'date': '2023-05-13T17:09:59.024Z' }}

### Byte Magazine Volume 06 Number 09 – Artificial Intelligence (1981)

#### [Submission URL](https://archive.org/details/byte-magazine-1981-09) | 88 points | by [belter](https://news.ycombinator.com/user?id=belter) | [33 comments](https://news.ycombinator.com/item?id=35927571)

In this issue of BYTE Magazine from September 1981, Artificial Intelligence is explored with articles ranging from building speech synthesizers to expert systems, with a reflection on the past and speculation on the future by 1980 ACM Turing Award winner, Charles Antony Richard Hoare. The issue also covers the National Computer Conference, the Xerox Alto computer, and high-level language benchmarks.

The discussion in the comments covers a range of topics related to the era of computing in the '80s, including the cost of computers and the evolution of personal computer technology. Some users discuss their experiences with purchasing early computers, while others share their thoughts on the state of technical magazines and advertising.

### Large language models generate functional protein sequences across families

#### [Submission URL](https://www.nature.com/articles/s41587-022-01618-2) | 165 points | by [samwillis](https://news.ycombinator.com/user?id=samwillis) | [29 comments](https://news.ycombinator.com/item?id=35929377)

Protein design and engineering could be greatly enhanced through the use of ProGen, a deep-learning language model that can generate protein sequences with predictable functions. Trained on 280 million protein sequences and augmented with control tags, ProGen has been fine-tuned to improve controllable generation performance of proteins from homologous samples. Artificial proteins fine-tuned to five lysozyme families demonstrated similar catalytic efficiencies to natural lysozymes, even with sequence identity as low as 31.4%. ProGen is also readily adaptable to diverse protein families, such as chorismate mutase and malate dehydrogenase.

The comments discuss the technical aspects of the model, the abilities of language models in biology, and the importance of considering functional labels in protein families. There is also discussion about other ongoing projects in protein science and the potential implications of AI-generated proteins. One commenter shares a PDF and code related to the ProGen project.

### Donkeycar: A Python self driving library

#### [Submission URL](https://github.com/autorope/donkeycar) | 80 points | by [tildef](https://news.ycombinator.com/user?id=tildef) | [8 comments](https://news.ycombinator.com/item?id=35926993)

Donkeycar, an open-source hardware and software platform to build a small-scale self-driving car, is gaining popularity among hobbyists and students alike. Developed for fast experimentation and easy community contributions, the minimalist and modular self-driving library for Python allows users to experiment with autopilots, mapping computer vision, neural networks, and log sensor data. Users can also drive their car via a web or game controller or RC controller, and leverage community-contributed driving data.

The discussion thread starts with a commenter reminiscing about their past experience with the platform. Other commenters then mention similar projects like Duckietown, MuSHR, and F1TENTH, and also discuss the availability of high-quality hardware and how the community is converging on common hardware and chip solutions. Another commenter shares their positive experience training high school and college students using Donkey Car. The discussion moves on to talk about the project's dependence on Python and its libraries. One commenter also mentions the use of Donkey Car for virtual racing. Lastly, a commenter suggests the possibility of using Donkey Car for internal spatial representation similar to those on sensors and control.

### Google Launches AI Supercomputer Powered by Nvidia H100 GPUs

#### [Submission URL](https://www.tomshardware.com/news/google-a3-supercomputer-h100-googleio) | 187 points | by [jonbaer](https://news.ycombinator.com/user?id=jonbaer) | [169 comments](https://news.ycombinator.com/item?id=35924997)

Google has launched its new A3 GPU supercomputer, designed to train and host the most-demanding AI models, particularly Google's new PaLM 2 large language model for generative AI. The A3 supercomputer provides 26 exaFlops of AI performance with eight Nvidia H100 "Hopper" GPUs, and is powered by 4th generation Intel Xeon Scalable processors and 2TB of DDR5-4800 memory. The system is also the first production-level deployment of Google's GPU-to-GPU data interface (Infrastructure Processing Unit), which enables sharing data at 200 Gbps across virtual machines, resulting in a 10x uplift in available network bandwidth. Access to the A3 program is available through Google's Early Access Program, with no guarantees of acceptance.

In the comments on Hacker News, users discuss the technical details of the A3 computer, as well as AMD's GPUs, NVIDIA's DGX, and TPUs. One user notes that the A3 is a single-server supercomputer with 8 GPUs, and users debate the advantages and disadvantages of AMD's approach to GPU-CPU memory fusion and software support. Another user points out the technical specifications of the A3 computer and questions the pricing, while another user brings up the fact that Google is also offering TPUs which have a different set of advantages.

### Why Conscious AI Is a Bad, Bad Idea

#### [Submission URL](https://nautil.us/why-conscious-ai-is-a-bad-bad-idea-302937/) | 129 points | by [dnetesn](https://news.ycombinator.com/user?id=dnetesn) | [269 comments](https://news.ycombinator.com/item?id=35927228)

Experts are warning that the idea of creating conscious artificial intelligence (AI) is dangerous and raises significant ethical, safety, and societal challenges beyond those posed by current AI. Proponents of the idea argue that advanced AI systems could become conscious and have subjective experiences in the same way as humans. However, it is not clear whether consciousness is a function of intelligence, and it remains unclear whether building conscious machines should be a priority. Opponents argue that consciousness is an embodied phenomenon tied to biological drives and that attempts to build conscious machines could have dangerous consequences.

One commenter suggests that the definition of consciousness is an interesting property worth exploring, while another argues that consciousness is related to human-like bodily existence. Others point out that consciousness is not fully understood, and therefore, the possibility and ethics of creating conscious machines are up for debate. Additionally, some argue that the perspective of self-awareness matters in the discussion of consciousness and that different organisms have varying levels of it.

### Former ByteDance exec claims company used bots to inflate TikTok engagement

#### [Submission URL](https://www.engadget.com/former-bytedance-exec-claims-company-used-bots-to-inflate-tiktok-engagement-211351640.html) | 49 points | by [firstSpeaker](https://news.ycombinator.com/user?id=firstSpeaker) | [10 comments](https://news.ycombinator.com/item?id=35929524)

A former ByteDance executive has filed a lawsuit alleging that the company inflated engagement on TikTok by using bots and stolen content. Yintao Yu, the former head of engineering, claims that ByteDance stole content from other apps such as Instagram and Snapchat, and used bot accounts to boost its engagement metrics when it started out. The lawsuit also alleges that ByteDance acted as a "useful propaganda tool for the Chinese Communist Party" and Chinese-based employees had access to US users' data. The claims are likely to add to concerns surrounding TikTok's national security threat and may complicate the app's bid to remain operational in the US.

Many users express concerns about TikTok's national security risks and suggest that the app may be a propaganda tool for the Chinese government. Others comment on the difficulties of detecting fake engagement and stolen content on social media platforms and note that these issues are not unique to TikTok. Finally, some users comment on the prevalence of recycled content on TikTok and other platforms. Overall, the comments reflect a mix of skepticism and concern about TikTok's practices and possible impact on global politics and social media.

---

## AI Submissions for Fri May 12 2023 {{ 'date': '2023-05-12T17:11:47.512Z' }}

### He wrote a book on a rare subject. Then a ChatGPT replica appeared on Amazon

#### [Submission URL](https://www.washingtonpost.com/technology/2023/05/05/ai-spam-websites-books-chatgpt/) | 157 points | by [gmays](https://news.ycombinator.com/user?id=gmays) | [158 comments](https://news.ycombinator.com/item?id=35919753)

Experts are warning that AI-generated content is spreading rapidly across the web, with anyone able to use language software to generate large amounts of prose on almost any topic. Tech investor Jonathan Greenglass claims that if users have an internet connection, they have consumed AI-generated content. This alleged rise in AI-written content could be dangerous for consumers, as more "misinformation" and manipulation surfaces on the web. Margaret Mitchell, chief ethics scientist at the AI start-up Hugging Face, has warned that “The main issue is losing track of what truth is."

The comments discuss various aspects of the issue, including verifying the authenticity of digital content, the possibility of verifying human-produced text, fact-checking, the impact of AI on email communication, the challenges in establishing truth and trust sources in technical subjects, and the limitations of AI-generated content. Some commenters express concern over AI replacing the creativity and knowledge of human writers, while others see it as an opportunity to improve the quality of content. Many discuss the role of capitalism and incentives in the proliferation of AI-generated content.

### A RP2040 Powered MIDI-Controlled Synth in CircuitPython

#### [Submission URL](https://gist.github.com/todbot/96a654c5fa27625147d65c45c8bfd47b) | 73 points | by [_Microft](https://news.ycombinator.com/user?id=_Microft) | [9 comments](https://news.ycombinator.com/item?id=35921745)

Today's top story on Hacker News is a project shared by user todbot. The project is a MIDI-controlled synthesizer implemented using CircuitPython and uses a cheap PCM5102 DAC on QTPY RP2040. The synth has a couple of features, such as midi velocity controlling attack rate, notes having small random detune on all oscillators to reduce phase stacking, adjustable number of detuned oscillators per note, five selectable waveforms, and vibrato depth on the mod wheel. The code for the synth is also available on Github and is implemented using ulab.numpy for signal processing. A video demo of this cool project is available on Youtube.

People in the comments are excited about the project and its affordability, with some suggesting alternative models such as the Teensy. Another user shares a similar project that implements a MIDI keyboard using Raspberry Pi Pico. A user named "_benj" shared his experience of playing around with an RP2040 and creating a digital piano analyzer that can make a small buzzer beep at the appropriate frequency of a MIDI signal. There's also a discussion about the creator todbot's blog.

### Faster CPython at PyCon, part two

#### [Submission URL](https://lwn.net/SubscriberLink/931197/56e7c3d8a352d8bc/) | 73 points | by [jwilk](https://news.ycombinator.com/user?id=jwilk) | [32 comments](https://news.ycombinator.com/item?id=35919942)

At PyCon 2023 in Salt Lake City, Utah, Mark Shannon provided an overall picture of CPython optimizations, including efforts made over the last decade or more, with an eye towards other areas that have been optimized, such as the memory layout for the internal C data structures of the interpreter. Shannon talked about the guiding principles of the Faster CPython project to improve Python's performance and emphasized the importance of efficient and compact data structures that require fewer memory reads. He also explained how the size of Python objects was reduced to less than half of the original 352 bytes in Python 2.7 with the addition of compact dictionaries in Python 3.6, thereby improving performance by utilizing faster memory.

The comments discussed the speed improvements in Python 3.12 as well as the use of C-xtnsns and CFFI to improve performance. There was also a discussion on the trade-offs between speed and Python's dynamically typed nature. It was mentioned that the reduction in memory overhead for Python objects was discussed in an LWN article. Furthermore, Dropbox's switch from Python to Golang was discussed, and there was a suggestion to use Numpy for intensive computation instead of Python.

### EVA: AI-Relational Database System

#### [Submission URL](https://evadb.readthedocs.io/en/stable/index.html) | 106 points | by [jonbaer](https://news.ycombinator.com/user?id=jonbaer) | [29 comments](https://news.ycombinator.com/item?id=35913173)

EVA is an open-source AI-relational database system that supports AI-powered applications on structured and unstructured data with the help of deep learning models. It contains built-in models for analyzing unstructured data such as image classification, object detection, OCR, face detection, and more. EVA's features include supporting user-defined functions, caching, sampling, cost-based operator reordering, and an AI-oriented query language. The database system is fully implemented in Python and licensed under the Apache license. It simplifies computer vision tasks and supports custom deep learning models. Check out the illustrative applications of EVA including traffic analysis, MNIST digit recognition, movie analysis, and more.

In the comments section, several users had a discussion about the differences between EVA and MindsDB, a comment about EVA's SQL-like syntax, the need for benchmarking, and how documentation for EVA compares to various other database and storage systems. Additionally, some users commented on the concept of relational databases being too archaic for humans and how certain database concepts differ from models of the human cognitive system.

### Apple Silicon Macs now natively support Unreal Engine 5

#### [Submission URL](https://www.engadget.com/apple-silicon-macs-now-natively-support-unreal-engine-5-124257710.html) | 40 points | by [PeterCorless](https://news.ycombinator.com/user?id=PeterCorless) | [24 comments](https://news.ycombinator.com/item?id=35918061)

Apple Silicon Mac users can now take advantage of the latest version of Epic Games' popular 3D world-building tool, Unreal Engine 5. The new update, version 5.2, is the first to work natively on Apple's ARM-based chips, eliminating the need for Rosetta technology. Unreal Engine 5 is ideal for gaming and virtual production, and the new iPad app that accompanies it offers a touch-based interface for lighting, color grading, and other tasks on virtual sets. The update also includes a "Procedural Content Generation framework" and Substrate, which allows for more controlled material creation in real-time applications.

Some users discussed the compatibility of Unreal with different platforms; a few users pointed to the support for Linux in Unreal and how this can be beneficial for developers. Others discussed the Apple Silicon architecture and how it impacts game development, with some pointing out that the current implementation of Unreal for Apple Silicon may not be completely native. The discussion also touched upon the technical aspects of Unreal, including its support for Metal graphics API and other features like Nanite. Additionally, some users talked about the relationship between Epic and Apple, particularly due to Epic's ongoing legal dispute with Apple.

---

## AI Submissions for Thu May 11 2023 {{ 'date': '2023-05-11T17:10:24.059Z' }}

### An IBM computer learned to sing in 1961

#### [Submission URL](https://tedgioia.substack.com/p/how-an-ibm-computer-learned-to-sing) | 41 points | by [isomorph](https://news.ycombinator.com/user?id=isomorph) | [22 comments](https://news.ycombinator.com/item?id=35906783)

Back in 1961, a team at Bell Labs had the bright idea of teaching the IBM 7094 computer how to sing. Using breakthrough speech synthesis technology, they taught the computer to work through the melody of "Daisy Bell," also known as "Bicycle Built for Two." The result sounded creepy but surprisingly futuristic, with the vocal part sounding a little bit like today's Auto-Tuned pop songs. The whole experiment seemed a little edgy and transgressive for its time, considering the lyrics were essentially a marriage proposal and the song envisioned a happy-ever-after embedded in a new technology. This project anticipated the future of music and, in a way, even the current-day investments in robots designed to provide relationships.

Commenters discussed the technical details of the synthesis and pointed to various sources for further reading. Some mentioned other projects that involve physical models of sound synthesis and singing, such as Hui-Ling Lu's dissertation on singing synthesis and the Pink Trombone project. Others noted the historical significance of the project and how it reminds them of different games and movies that reference "Daisy Bell."

### Problems harder than NP-Complete

#### [Submission URL](https://buttondown.email/hillelwayne/archive/problems-harder-than-np-complete/) | 239 points | by [azhenley](https://news.ycombinator.com/user?id=azhenley) | [89 comments](https://news.ycombinator.com/item?id=35908477)

In the world of computer science, P vs NP is often discussed as the difficulty level of problems, with P being easy and NP being hard. However, problems can get way harder than NP, such as PSPACE-complete, EXPTIME-complete, 2-EXPTIME-complete, ELEMENTARY-complete, TOWER-complete, and Ackermann-complete. These types of problems have varying levels of difficulty, with Ackermann-complete being the most difficult due to its use of the Ackermann function. Despite their complexity, these types of problems have interesting applications in areas such as game theory, logic, and program synthesis.

In the comments, users discuss Linear Temporal Logic and its interesting properties, as well as regular expressions and their matching capabilities. Other discussion points include the practical solvability of EXPTIME-complete problems in machine learning, the difficulty of solving puzzles (such as Sudoku) of varying sizes, and the increasing difficulty of un-decidable problems beyond NP.

### Stability AI Releases Stable Animation SDK

#### [Submission URL](https://stability.ai/blog/stable-animation-sdk) | 36 points | by [beefman](https://news.ycombinator.com/user?id=beefman) | [5 comments](https://news.ycombinator.com/item?id=35904330)

Stability AI, the open-source AI firm, has introduced the Stable Animation SDK, which offers artists and developers the ability to use the most advanced Stable Diffusion models to create stunning animations. The tool allows users to create animations using text prompts, source images or videos, with the option to tweak various parameters to produce the desired results. Stable Animation SDK includes all Stable Diffusion models, including the Stable Diffusion 2.0 and Stable Diffusion XL and offers three ways to create animations. Interested parties can join the developer platform and the animation artist community on Discord to know more.

### A transformer-based method for zero and few-shot biomedical NER

#### [Submission URL](https://arxiv.org/abs/2305.04928) | 72 points | by [nikolamilosevic](https://news.ycombinator.com/user?id=nikolamilosevic) | [10 comments](https://news.ycombinator.com/item?id=35901538)

A transformer-based method for zero and few-shot biomedical named entity recognition has been proposed to address the challenges of supervised named entity recognition (NER) in the biomedical domain. The method transforms the task of multi-class token classification into binary token classification and pre-trains on a larger amount of datasets and biomedical entities, enabling the method to learn semantic relations. The proposed method achieves impressive results with average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical entities with PubMedBERT fine-tuned model.

There is a discussion around the benefits and drawbacks of different methods for named entity recognition, including regular expressions, CRFs, simple LSTMs, and more advanced systems modeled after BERT. Finally, some commenters share relevant resources and packages for named entity recognition, while others explain what named entity recognition refers to.

### Chat-UI, the codebase of HuggingChat, is open sourced

#### [Submission URL](https://github.com/huggingface/chat-ui) | 131 points | by [osanseviero](https://news.ycombinator.com/user?id=osanseviero) | [28 comments](https://news.ycombinator.com/item?id=35907564)

This is the GitHub repository for the Chat UI, an open-source codebase powering the HuggingChat app on huggingface.co/chat. The Chat UI is a SvelteKit app that utilizes open-source models such as OpenAssistant. The repository contains instructions for launching the app, running local inference, and building a production version of the app. The Chat UI has 831 stars and 45 forks on GitHub.

The comments reveal a range of discussions on topics such as the ChatGPT and its user interface, the structure of memory chats, and features that could be added to Chat UI. The discussion also highlights interesting UIs for the ChatGPT and mentions the availability of plugins. There is also a mention of FerretDB, a progress made on a source material database implementation. Finally, the comments touch on the lack of legal filenames and the use of SvelteKit.

### Delimiters won’t save you from prompt injection

#### [Submission URL](https://simonwillison.net/2023/May/11/delimiters-wont-save-you/) | 12 points | by [simonw](https://news.ycombinator.com/user?id=simonw) | [6 comments](https://news.ycombinator.com/item?id=35904361)

Simon Willison's latest blog post discusses the ongoing problem of prompt injection and the proposed solution of using delimiters to mark the start and end of untrusted user input. However, Willison demonstrates that this solution is easily defeated and highlights the difficulty of finding a solution to prompt injection due to the nature of large language models and the sequence of tokens it generates. Willison also critiques the limited coverage of prompt injection in the new interactive video course ChatGPT Prompt Engineering for Developers, which is presented by Isa Fulford and Andrew Ng in partnership with OpenAI. This post provides insight into the ongoing challenges of prompt engineering and the need for continued innovation to solve this complex issue.

One user suggests that a system-level API could prevent the problem, but another user points out that a recent information system behaved unexpectedly and did not handle input proper. One user suggests using randomized delimiters. However, another user points out that this solution is not foolproof as symbols can still be injected, but the attacker would need to connect them in a non-logical manner. Another user notes that the article did not mention injections without delimiters.

### DeepMind cofounder warns govts must find solutions for jobs lost to A.I

#### [Submission URL](https://fortune.com/2023/05/10/artificial-intelligence-deepmind-co-founder-mustafa-suleyman-ubi-governments-seriously-need-to-find-solution-for-people-that-lose-their-jobs/) | 43 points | by [goplayoutside](https://news.ycombinator.com/user?id=goplayoutside) | [22 comments](https://news.ycombinator.com/item?id=35905604)

Mustafa Suleyman, the co-founder of DeepMind, has suggested that governments should consider universal basic income (UBI) for the knowledge sector workers whose jobs could be threatened by automation. Speaking at the GIC Bridge Forum event in San Francisco, Suleyman argued that policymakers needed to provide "material compensation" for those affected. This follows claims by Goldman Sachs that generative AI could put 300 million full-time US and European workers out of a job. Elon Musk and Steve Wozniak have both called for a delay in advanced AI research.

Some commenters argue that the government should require companies that utilise AI to compensate the people whose jobs the technology replaces. Other commenters feel implementing UBI could cause economic issues, such as inflation and creating a culture of dependency. Some people also suggest that UBI is not a solution to job loss caused by automation and that focusing on creating jobs instead of just replacing income is a more effective approach. The discussion also touches on topics such as economics, politics, industrial mechanisms, and the educational system.

---

## AI Submissions for Wed May 10 2023 {{ 'date': '2023-05-10T17:15:04.111Z' }}

### A Codebase That Makes Codebases

#### [Submission URL](https://www.saaspegasus.com/about/how-pegasus-works/) | 80 points | by [czue](https://news.ycombinator.com/user?id=czue) | [23 comments](https://news.ycombinator.com/item?id=35887766)

Meet SaaS Pegasus, a unique codebase creator for Django projects that generates a unique codebase based on the user's project needs and technology stack. Unlike most boilerplates, SaaS Pegasus is configurable, making it flexible enough to handle different use cases. The codebase creator shields developers from unnecessary complexities by generating code that is specific to their needs. SaaS Pegasus is built using Cookiecutter, an amazing little utility that creates projects from templates, and a logic/templating engine written in Jinja2. The codebase creator takes care of all the complexity like data models, interdependencies, required packages and improves developer experience by making sure generated codebases include what's necessary. The creator of SaaS Pegasus has had to be very creative in maintaining the project but has managed to come up with solutions to most problems.

The discussion encompasses various ideas, including how to handle the complexities of maintaining dependencies, converting customers by videos, documentation, and positive comments, and Pegasus's flexibility. Other concerns include developing a project for NextJS, difficulties in writing Python and JavaScript, and the complexity of creating templates. By and large, the participants appreciate SaaS Pegasus's ability to jump-start clean, simple projects, generate project configurations, and provide the documentation to complement the templates.

### Hugging Face Releases Agents

#### [Submission URL](https://huggingface.co/docs/transformers/transformers_agents) | 201 points | by [mach1ne](https://news.ycombinator.com/user?id=mach1ne) | [118 comments](https://news.ycombinator.com/item?id=35889743)

Hugging Face has launched an experimental API called Transformers Agent that provides a natural language API on top of Transformers NLP. The API defines a set of curated tools and superimposes an agent to interpret natural language and use the tools. The API is extensible and users can curate their set of relevant tools or use any tool developed by the community. The API demos well in multimodal tasks such as generating images and reading text out loud and has two modes: single execution and chat-based execution. Users can instantiate an agent from openAI models or opensource alternatives such as BigCode or OpenAssistant.

The discussion on Hacker News is predominantly about the dangers of AGI and the importance of ensuring its alignment with human values. Many commenters discuss the moral implications of AGI and the potential risks it poses to humanity. Some commenters argue that open-source models are being censored by large tech companies, while others discuss the challenges of developing algorithms that have the same cognitive abilities as humans.

### Google launches PaLM 2, its next-gen large language model

#### [Submission URL](https://techcrunch.com/2023/05/10/google-launches-palm-2-its-next-gen-large-language-model/) | 100 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [49 comments](https://news.ycombinator.com/item?id=35890440)

Google has announced PaLM 2, its newest large language model (LLM) that will power the company's updated Bard chat tool, alongside most of its new AI features. Built on Google's latest JAX and TPU v4 infrastructure, PaLM 2 is trained on over 100 languages and is better at common sense reasoning, mathematics, and logic. Its improved support for writing and debugging code is based on training on 20 programming languages, including those less commonly used. PaLM 2 is available to developers via the PaLM API, Firebase, and Colab. However, it is not clear how the company trained this 540-billion parameter model nor how it performs in various scenarios.

While some praised PaLM 2 for its capabilities, others expressed doubt over the lack of technical documentation and the secrecy surrounding its training. They also speculated on its potential to revolutionize interaction with computers. Some commenters questioned why Google released a medical-focused model of PaLM 2 and not just a more generalized one. Additionally, one commenter flagged the fact that Bard is not currently supported in Canada, and some mentioned Google's competition with OpenAI's GPT models.

### Abusing vector search for texts, maps, and chess

#### [Submission URL](https://ashvardanian.com/posts/abusing-vector-search/) | 105 points | by [vov_or](https://news.ycombinator.com/user?id=vov_or) | [23 comments](https://news.ycombinator.com/item?id=35887983)

Vector search is a trending topic, with Weaviate raising $50M and Pinecone raising $100M, but Ashot Vardanian demonstrates that it's not a difficult task by building a single-file vector search engine - USearch - that is both fast and open-source. USearch, built with just 1,000 lines of C++11, is not only AI-related and limited to equidimensional vectors but also supports non-equidimensional vectors and custom similarity measures. The tool demonstrates various non-AI use cases, including a geo-spatial indexing use case and a stock market use case. USearch can be used with a range of programming languages, including Python, JavaScript, Java, Rust, GoLang, and Wolfram.

The discussion initially focuses on the difficulty of building vector databases and search applications, with some users suggesting it is not as difficult as it seems and that modern databases are integrating solutions. One user points out that chess positions and moves can be represented as vectors and suggests some potential use cases for this. Another user suggests using custom weighting schemes for different positions to improve search. The discussion then shifts to a debate on whether to allow emojis or not on Hacker News.

### Google will label fake images created with its A.I

#### [Submission URL](https://www.cnbc.com/2023/05/10/google-will-label-fake-images-created-with-its-ai-.html) | 24 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [12 comments](https://news.ycombinator.com/item?id=35893804)

Google has announced plans to embed a "markup" in images created by its AI models to indicate that they were originally created by a computer, marking a significant effort to label and classify output from generative AI by a big tech company. While the data will not be visible to the human eye, software will be able to read it and display a warning label to users. Google's move comes as officials and tech workers have warned that generative AI, which can create realistic images and text passages, could be used by spammers, scammers and propagandists to deceive people.

The discussion on Hacker News generally acknowledges the need for such labeling due to the potential misuse of generative AI technology. The thread includes a debate over watermarking as a way of labeling the difference between human and AI-generated content, with some users expressing reservations about watermarks on images because it could lower their artistic value. Other points of discussion include the use of machine learning to classify text, the need for industry labeling standards, unique identifiers for image source codes, and zero-width spaces.

### Google's Latest Experiments in Labs

#### [Submission URL](https://labs.withgoogle.com/) | 70 points | by [tpmx](https://news.ycombinator.com/user?id=tpmx) | [34 comments](https://news.ycombinator.com/item?id=35890989)

Google has launched a new program called "Experiments in Labs" that allows users to test early-stage experiments in AI-powered products. By being an early tester, users can access limited-availability experiments and provide feedback to help improve and innovate Google's products. Some of the available experiments include Google Search, Google Workspace, Project Tailwind, MusicLM and others. The aim is to test and discover new ways AI can optimize the use of Google products.

In the comments, users discussed various issues and concerns such as 404 errors in accessing some pages, compatibility issues with different browsers, waiting times to access certain services, and the place of experimental things within Google's Workspace aimed at business accounts. There were also some debates about product naming, censorship, and company reputation. Several users encouraged others to sign up to test early-stage AI experiments while others suggested that the program is mainly for personal account users, not business accounts.

### Wendy’s debuts an A.I. chatbot for drive-thru orders

#### [Submission URL](https://fortune.com/2023/05/09/wendys-ai-powered-chatbot-drive-thru-orders/) | 23 points | by [DocFeind](https://news.ycombinator.com/user?id=DocFeind) | [15 comments](https://news.ycombinator.com/item?id=35891619)

Wendy's is set to test an artificial intelligence (AI)-powered chatbot that can take drive-thru orders next month, becoming the latest fast-food chain to utilise the technology. Developed with Google Cloud's AI software, the chatbot has speech recognition ability and can even understand local lingo such as when a customer orders a "frosty", which is Wendy's term for a milkshake. The implementation of such technology could alter the fast-food industry, with some experts predicting that AI will become the norm, reducing the need for human workers and transforming customer service for the industry.

The discussion on this submission includes various comments on the drive-thru ordering technology used by fast-food chains, including McDonald's and Dunkin' Donuts. Some users express concern over whether the AI chatbots can accurately answer customer questions, including those about food allergies. Others point out that there are limited job opportunities for people in the industry, and AI could transform customer service. There are also comments about the use of voice recognition technology in general and the limitations of current systems. One user shares a picture from Google IO showcasing a similar technology.

### Google is bringing AI to the browser with WebGPU in Chrome

#### [Submission URL](https://www.analyticsinsight.net/google-chrome-upgrades-web-ai-intelligence/) | 35 points | by [astlouis44](https://news.ycombinator.com/user?id=astlouis44) | [3 comments](https://news.ycombinator.com/item?id=35889907)

Google Chrome is upgrading its Web AI intelligence by adopting WebGPU, which allows web apps on smartphones and laptops to more effectively utilize artificial intelligence software. This move underscores the increasing prevalence of AI technology, which has recently gained considerably greater visibility by new generative AI tools. Although AI is heavily reliant on cloud computing, running AI locally on a device avoids network issues and can help companies maintain control over their sensitive data. Google, Apple, and other companies have been developing WebGPU for years, making it easier for web programs to utilize the inherent power of GPUs for boosting AI.

### Google's AI Search Is Over

#### [Submission URL](https://www.semafor.com/article/05/10/2023/googles-ai-search-is-over) | 19 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [10 comments](https://news.ycombinator.com/item?id=35891518)

Google unveiled 25 new AI-powered products at its annual I/O developer conference, including a glimpse into how advances in artificial intelligence will change its core business, search. The “Search Generative Experience,” which marries traditional search with an AI chat-like experience, will soon be available as part of “Search Labs” to let customers try “experimental” products. Google's ChatGPT competitor, Bard, will run on Gemini, a new large language model being developed by Google DeepMind. Google is incorporating the latest AI models into its Google Workspace products like Docs and Sheets, with the ability for customers to create images from text and make spreadsheets by describing a task. "With a bold and responsible approach, we’re reimagining all our core products, including search," said Google’s CEO, Sundar Pichai.

The discussion about the Google AI search product unveiled at the company's I/O conference had mixed reactions. Some felt that traditional search has many problems and is annoying, while others praised the new AI chat-like experience called the "Search Generative Experience." One individual felt that Google's organizational structure allowed for smaller management changes, which helped the search product evolve much quicker than others. In contrast, a few users expressed concern about the power of AI and the role of large companies like Google and Microsoft in developing AI technology. Another user gave positive feedback about Microsoft's Bing chat ability, which has improved the context and accuracy of the search engine. Some users compared the growth of Tesla vs. General Motors, and there was a debate about Tesla's market share and the stability of their growth.

---

## AI Submissions for Tue May 09 2023 {{ 'date': '2023-05-09T17:13:24.011Z' }}

### Language models can explain neurons in language models

#### [Submission URL](https://openai.com/research/language-models-can-explain-neurons-in-language-models) | 662 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [426 comments](https://news.ycombinator.com/item?id=35877402)

Researchers at OpenAI have developed a methodology for using large language models to automatically generate and evaluate natural language explanations for neuron behavior in other language models. The team used GPT-4 to produce and score explanations for every neuron in GPT-2 and released a dataset of these explanations and scores. While the vast majority of the explanations scored poorly, the team identified over 1,000 neurons with explanations that accounted for most of the neuron's top-activating behavior. The researchers hope their work will lead to better techniques for generating higher-scoring explanations and to a rapid understanding of model computations.

In the discussion, some commenters noted the difficulty of analyzing larger models and the importance of understanding computations. Others talked about the history of artificial intelligence and how current research efforts are focused on making systems understand natural language and sensory input. Some also discussed the possibility of machine intelligence becoming comparable to human intelligence and the limitations of current language models.

### Patent for attention-based sequence transduction neural networks (2019)

#### [Submission URL](https://patents.google.com/patent/US10452978B2/en) | 98 points | by [ukuina](https://news.ycombinator.com/user?id=ukuina) | [94 comments](https://news.ycombinator.com/item?id=35877545)

Google has been granted a patent for attention-based sequence transduction neural networks (ABSTNN), which are designed to analyse and convert sequences of data, like machine translation of languages or speech-to-text transcription. ABSTNNs pay selective attention to specific parts of the input sequence to make accurate predictions, refining the network's output through multiple layers of encoder subnetworks. These subnetworks are designed to improve the accuracy of sequence transduction and reduce the comparative costs of memory-heavy, fully-connected designs.

Comments on the post suggested that Google could use its patents to thwart competition, while others noted that some of the most transformative algorithms are patentable. Attention was drawn to the fact that Google's success in AI is impressive, given its primary nature as an advertising business, and some suggested that Google has had a harder time enforcing patents compared with competitors. Finally, there was some debate over the usefulness of the patent system, with many suggesting that it may stifle innovation.

### Machine Learning Containers Are Bloated and Vulnerable

#### [Submission URL](https://deep.ai/publication/machine-learning-containers-are-bloated-and-vulnerable) | 24 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [8 comments](https://news.ycombinator.com/item?id=35877702)

Machine learning containers are often bloated and vulnerable, according to a paper by Huaifeng Zhang and colleagues. The researchers found that such containers can contain bloat of up to 80% of their size, leading to significant resource wastage. The authors suggest that debloating machine learning containers can speed provisioning times by up to 3.7x and reduce vulnerabilities by up to 98%. They have developed a framework called MMLB to quantify bloat at the container and package level, and removed it. The researchers say their work highlights the issue of technical debt in machine learning systems.

The discussion further explores the issue and the practicalities of managing containers, including difficulties in ensuring reproducibility and the maintenance of dependencies. The discussion finally highlights the importance of enabling containers and the removal of bloating while also acknowledging that it is a challenging task.

### Meta open-sources multisensory AI model that combines six types of data

#### [Submission URL](https://www.theverge.com/2023/5/9/23716558/meta-imagebind-open-source-multisensory-modal-ai-model-research) | 149 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [48 comments](https://news.ycombinator.com/item?id=35876147)

Meta has released an open-source AI model, ImageBind, that employs six types of data, including thermal, visual, and movement information, to create immersive and multisensory experiences. The research project marks a significant development in generative AI systems, which rely on linking multiple streams of data to create content. By incorporating touch, speech, smell, and brain fMRI signals, future models could learn holistically, approaching humans’ ability to learn directly from different types of information. Meta's approach, which is open source, comes as rival firms such as Google and OpenAI increasingly pursue a secretive strategy.

The discussion in the comments included some debate about the definition of open source versus free and open-source software (FOSS), and other topics such as the underdefined nature of terms related to open-source, the differences in licenses, and the potential hardware requirements needed for training the model. People also expressed their skepticism about Meta's involvement in AI for the "truly neutral" evaluation of natural language processing tasks and the company's controversial attitude toward privacy.

### Amazon Is Being Flooded with Books Written Entirely by AI

#### [Submission URL](https://futurism.com/the-byte/amazon-flooded-books-written-by-ai) | 52 points | by [redbell](https://news.ycombinator.com/user?id=redbell) | [43 comments](https://news.ycombinator.com/item?id=35881065)

Amazon's marketplace is being flooded with books almost entirely generated by AI. This trend is making it harder to distinguish between real authors and the non-existent writers created by AI algorithms. The AI-generated books are primarily listings on surprisingly niche topics with five-star reviews. However, AI content is flooding the internet and could spark a pandemic of misinformation. Several online publications are already making ample use of the technology to generate often dubiously sourced and redundant content. The emergence of AI-generated books and content represents new reality for businesses and poses risks of misinformation and confusing reality.

Commenters suggest that AI-generated content could be beneficial in creating recommenders for modern authors and helping companies find new incentives in machine-generated content. However, concerns arise if the AI-generated content is not reliable, leading to the spread of misinformation. Some users also point out that there are still many interesting printed books available to read and that not all books necessarily have the same value. Furthermore, some discussion in the comments centers on LitRPG books that are highly entertaining and those books generated by AI. There are also discussions on AI-generated ratings.

### Constitutional AI: RLHF on Steroids

#### [Submission URL](https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids) | 151 points | by [jstanley](https://news.ycombinator.com/user?id=jstanley) | [68 comments](https://news.ycombinator.com/item?id=35870669)

Today, Anthropic, a big AI company, announced a new process for training AI called Constitutional AI, which allows the AI to give feedback to itself to train the AI to be less harmful and more ethical. The process involves showing the AI its first draft answer to a question, along with a prompt saying “rewrite this to be more ethical” until a large dataset of rewritten, more ethical second drafts is collected, and then the AI is trained to write answers that are less like the first drafts and more like the second drafts. The results have been positive, with Constitutionally trained models being "less harmful at a given level of helpfulness" than models trained with traditional reinforcement learning through human feedback.

Some users argue that accurate predictions and not political correctness should be the main goal of AI. Others argue that the new method could lead to more ethical AI and that companies should prioritize minimizing harm rather than maximizing profit. Some users also criticize the economics and politics that drive AI development.

### Show HN: LLM, a Rust Crate/CLI for CPU Inference of LLMs (LLaMA, GPT-NeoX, etc.)

#### [Submission URL](https://github.com/rustformers/llm) | 43 points | by [Philpax](https://news.ycombinator.com/user?id=Philpax) | [4 comments](https://news.ycombinator.com/item?id=35876928)

llm is a Rust ecosystem of libraries for running inference on large language models, inspired by llama.cpp. It is powered by the ggml tensor library and aims to bring the robustness and ease of use of Rust to the world of large language models. Currently, inference is only on the CPU, but there is hope to support GPU inference in the future through alternate backends. Supported models include GPT-2, GPT-J, LLaMA, Alpaca, Vicuna, Koala, GPT4All v1, GPT4-X, Wizard, GPT-NeoX, StableLM, Dolly v2, and BLOOMZ. The primary crate is the llm crate, which wraps llm-base and supported model crates. On top of llm, there is a CLI application, llm-cli, which provides a convenient interface for running inference on supported models.

The discussion on the submission revolves around users' experiences with llm and related libraries. One user who tried the library commented positively on its convenience but noted that it runs only on CPU at the moment and would be more efficient on multiple servers. Another user shared that they have attempted to build their own ML project but found it challenging to justify the expense. The discussion then shifted to ggml, a tensor library used in llm that offers performance gains and has a direct plan to build a competition graph with supported backends, including Intel MKL and CUDA. Overall, the discussion reflects the interest and excitement around using Rust for large language models, as well as the importance of performance optimization in machine learning projects.

### AI predicts pancreatic cancer 3 years before it happens

#### [Submission URL](https://www.theregister.com/2023/05/09/ai_pancreatic_cancer/) | 20 points | by [ter_adata](https://news.ycombinator.com/user?id=ter_adata) | [4 comments](https://news.ycombinator.com/item?id=35878002)

AI algorithms can predict whether a patient will develop pancreatic cancer up to three years before human doctors can, according to research published in the journal Nature. The study, led by Harvard Medical School and Danish academics, incorporated machine learning trained on millions of patient records obtained from databases in Denmark and the US. The best-performing model indicated that of the top 1,000 riskiest patients over the age of 50, roughly 320 would go on to develop pancreatic cancer. The researchers warn that local population data is necessary for accurate cancer-catching predictions.

The discussion on this submission includes comments about the effectiveness of machine learning algorithms in predicting pancreatic cancer and the potential bias that can occur in future AI-based cancer screening tools. Some users mention the need for local population data to ensure accurate predictions while others discuss the use of GPT transformers and the study's reliance on medical records obtained from databases in Denmark and the US. There is also mention of the high mortality rate of pancreatic cancer and the potential benefits of using AI to detect the disease earlier.

---

## AI Submissions for Mon May 08 2023 {{ 'date': '2023-05-08T17:10:30.096Z' }}

### GPU vendor-agnostic fluid dynamics solver in Julia

#### [Submission URL](https://b-fg.github.io/2023/05/07/waterlily-on-gpu.html) | 219 points | by [moelf](https://news.ycombinator.com/user?id=moelf) | [90 comments](https://news.ycombinator.com/item?id=35861435)

WaterLily.jl, a pure Julia fluid simulator, has successfully ported its solver from a serial CPU execution to a backend-agnostic execution that includes multi-threaded CPU and GPU from different vendors (NVIDIA and AMD) thanks to KernelAbstractions.jl (KA). Using the @kernel macro from KA, the team was able to generate the divergence operator using KernelAbstractions by defining a divergence kernel and a wrapper function. To automate the generation of loops, the team defined the macro @loop, which generates loops over CartesianIndices ranges automatically. Additionally, this approach can be used to generate KA kernels for each loop in the code. The extended abstract preprint with benchmarking details regarding this port can be found on arXiv.

The comments discussed the advantages and disadvantages of Julia as a language compared to Python and other languages, as well as the challenges of programming for simulations and the benefits of using GPU acceleration. Many users expressed interest in trying out the new code and in working with Julia for machine learning and other projects.

### Early Artificial Intelligence Projects: A Student Perspective (2006)

#### [Submission URL](https://projects.csail.mit.edu/films/aifilms/AIFilms.html) | 58 points | by [onemind](https://news.ycombinator.com/user?id=onemind) | [7 comments](https://news.ycombinator.com/item?id=35857070)

This article is a retrospective look at the early days of artificial intelligence, exploring its definition, foundational concepts, and major projects at MIT and in the US. The article begins with John McCarthy's definition of AI, which is the science of making intelligent machines that can mimic human thought, feelings, and decision-making. It explains that AI has not had a linear progression, but rather has grown in many directions along the intertwining world wide web. The article then delves into the foundational concepts of AI, such as programmable machines that can solve equations, and the development of early computers. Moving along, the article explores major AI projects during the decades following the creation of the term "AI," from the 1950s to the present day, including the emergence of search engines, spell checkers, and spam filters.

One user mentions studying AI in the past, including the use of programming languages, such as Prolog and Lisp, during the 90s. Another user shares their experience of shifting their focus to neural networks and how technology changes over time. The topic of machine learning and its ability to surpass human performance in certain tasks is mentioned. The concept of intelligence being computationally attainable is also discussed. Finally, another user shares an article on an AI-generated system that demonstrates intelligence comparable to humans.

### Giving GPT “Infinite” Knowledge

#### [Submission URL](https://sudoapps.substack.com/p/giving-gpt-infinite-knowledge) | 116 points | by [sudoapps](https://news.ycombinator.com/user?id=sudoapps) | [83 comments](https://news.ycombinator.com/item?id=35864698)

Large Language Models (LLMs) like OpenAI's GPT can provide accurate responses to information retrieval questions if fed with relevant real-time data for interpretation. However, a limitation on the number of tokens for the initial prompt or response to generate results restricts LLMs from ingesting large amounts of data directly. To overcome this hurdle, data is converted into embeddings - vector representations of a string - and stored in vector databases. When a user asks a question, similarity search is done for relevant information with only the essential pieces related to the question being injected into the LLM prompt before answering the question. While there are token limitations, string compression techniques can help accommodate more data within the limit.

The discussion on this submission consists of a variety of viewpoints on the capabilities and limitations of Large Language Models (LLMs), particularly in their ability to comprehend and analyze data beyond the token limitations. Some commenters suggest that embeddings-based search is a viable solution that allows for relevant data to be retrieved within the token limit, while others express concerns about the effectiveness of such an approach. There are also discussions about the potential of training larger models with real-time data to further enhance LLMs' performance and capabilities. Additionally, there are debates about the practical application of LLMs and their scalability, with some commenters expressing skepticism about their ability to achieve true artificial general intelligence (AGI) and others suggesting that advancements in technology may make it possible in the future.

### RasaGPT: First headless LLM chatbot built on top of Rasa, Langchain and FastAPI

#### [Submission URL](https://github.com/paulpierre/RasaGPT) | 171 points | by [riter](https://news.ycombinator.com/user?id=riter) | [108 comments](https://news.ycombinator.com/item?id=35859344)

Introducing RasaGPT, the first headless LLM chatbot platform built on top of Rasa and Langchain. Rasa is a popular and easy-to-use chatbot framework with built-in NLU ML pipelines, while Langchain is an LLM library for indexing, retrieval, and context injection. RasaGPT provides a reference implementation of Rasa and Telegram utilizing LLM libraries, including Langchain, for a seamless chatbot experience. Additionally, RasaGPT offers full API documentation and features including document versioning and automatic re-training, async end-points and database models customization, and pgAdmin for database browsing.

Some users discuss their experiences implementing Langchain and offer potential solutions to common problems. There is also discussion about other language models and their applications. Additionally, there is discussion about LMQL, a language model query language. Some users provide links to relevant resources and articles about these topics.

### Alphabet plans to announce its new general-use LLM called PaLM 2 at Google I/O

#### [Submission URL](https://www.cnbc.com/2023/05/08/google-io-to-feature-ai-updates-showing-off-palm-2-llm.html) | 37 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [5 comments](https://news.ycombinator.com/item?id=35866435)

Google is set to unveil its latest artificial intelligence (AI) updates, including the launch of a general-use large language model (LLM) called PaLM 2, at its annual developer conference (Google I/O). The LLM, incorporating more than 100 languages, has undergone numerous creative writing, coding, and maths tests. Google will also announce advancements to its Bard and Search AI, including a new feature that allows a user to "create" an image based on entered text. The conference will also cover the company's progress with Workspace AI collaborator and image recognition tool Google Lens.

The first comment by "jggwtts" seems to be a prediction about Google's latest AI developments and their potential impact. Another user, "two_in_one", expands on the idea by stating that these developments will enable dystopian scenarios like targeted advertising and tailored content. "sekh60" adds to the discussion by pointing out that Google stopped targeting based on demographics years ago. "cynydz" offers a different perspective, suggesting that AI can be effective in completing sentences and matching patterns, but also has the potential to manipulate individuals and activities. Finally, "lphbttng" mentions the PaLM AI and describes it as advanced.

---

## AI Submissions for Sun May 07 2023 {{ 'date': '2023-05-07T13:51:19.983Z' }}

### Prolog for data science

#### [Submission URL](https://emiruz.com/post/2023-04-30-prolog-for-data-science/) | 164 points | by [usgroup](https://news.ycombinator.com/user?id=usgroup) | [47 comments](https://news.ycombinator.com/item?id=35855398)

In this article, the author explores the integration of Prolog as a key component in data science analysis, using symbolic reasoning to generate properties about the data under study. They include examples of piece-wise regression on time-series data using symbolic reasoning, demonstrating how to create symbols which represent facts about the data through the use of Python and Prolog. The author then shows how to merge overlapping segments to create bigger continuous linear spans, ultimately calculating an optimal piece-wise linear fitting to find the subset of non-overlapping spans that result in maximum coverage of the data.

The comments discuss various related topics. Some users mention the challenge of portability and incompatibility with previous versions in Datalog adoption. Others talk about the benefits and difficulties of working with Prolog and suggest resources for learning and using it. There are also discussions about data storytelling and decision-making based on data. Finally, one user shares a link to their project on SaaS metrics generator. However, there is an overall lack of engagement and comments on the topic.

### The Prime Video microservices to monolith story

#### [Submission URL](https://adrianco.medium.com/so-many-bad-takes-what-is-there-to-learn-from-the-prime-video-microservices-to-monolith-story-4bd0970423d4) | 472 points | by [mparnisari](https://news.ycombinator.com/user?id=mparnisari) | [372 comments](https://news.ycombinator.com/item?id=35853148)

The Prime Video team's success with scaling up their audio/video monitoring service using a combination of serverless architecture and containers has sparked a debate over the usefulness of microservices versus a monolith approach. According to technology strategy advisor Adrian Cockcroft, the team's approach follows his own recommendation of building a serverless prototype first and then re-implementing it as a continuously running autoscaled container for sustained high traffic and low latency. Cockcroft also notes that microservices were over-sold as a solution to all problems and that there are times when a monolith or an existing service should be used instead. The Prime Video team's real-time user experience analytics engine for live video is a valuable addition to any video streaming service and can be accessed through Datazoom.io, a service whose chief architect and CTO are ex-Netflix colleagues of Cockcroft.

The benefits and drawbacks of microservices versus monoliths are discussed, with some users arguing that each approach has its merits depending on the project's specific needs. One user emphasizes the importance of selecting the right technology stack to minimize common errors during development and increase the chances of success.

### DEF CON to set thousands of hackers loose on LLMs

#### [Submission URL](https://www.theregister.com/2023/05/06/ai_hacking_defcon/) | 104 points | by [magoghm](https://news.ycombinator.com/user?id=magoghm) | [11 comments](https://news.ycombinator.com/item?id=35848573)

DEF CON's AI Village is set to host the largest red teaming exercise ever for any group of AI models, with hackers invited to find bugs and biases in large language models (LLMs). The event will feature LLMs built by AI companies like OpenAI and Google, and hackers will be tasked with finding flaws in these systems, including bias, hallucinations, and jailbreaks. The event, which will run from August 10-13 in Las Vegas, aims to promote the testing of a wide range of harms, and the hackers with the most points will win high-end Nvidia GPUs. Additionally, the event is supported by the White House Office of Science, Technology, and Policy; America's National Science Foundation's Computer and Information Science and Engineering Directorate; and the Congressional AI Caucus. 

One commenter expressed skepticism about the exercise and stated that it could lead to hackers planting exploits in open-source projects. Another commenter highlighted the challenge of debugging and ensuring security in non-deterministic computer programming, particularly in the context of machine learning and artificial intelligence. Another commenter discussed recent scientific progress in artificial intelligence and machine learning and the effort to make models more explainable and transparent. Other comments touched on the potential commercial applications of AI and concerns over data centers being located in China in the context of a potential conflict over Taiwan. Finally, some users joked about their inability to understand the articles and comments on the topic.

### AI tool designs mRNA vaccines that are more potent and stable

#### [Submission URL](https://www.nature.com/articles/d41586-023-01487-y) | 142 points | by [voisin](https://news.ycombinator.com/user?id=voisin) | [54 comments](https://news.ycombinator.com/item?id=35847774)

Researchers at Baidu Research, the AI division of the Chinese search engine firm, have created an AI tool that could pave the way for mRNA-based vaccines that don't need refrigeration, potentially making them more widely available in resource-poor areas. The tool optimises mRNA sequences, allowing the genetic material to persist for longer and creating more stable mRNA. The enhanced stability offers improved protection against vaccine degradation, without the need for cold-chain equipment. The researchers tested the tool on COVID-19 and shingles vaccines in mice, leading to significant improvements in efficacy and shelf-life. The discussion surrounding the submission involved various topics, including the challenges of lattice parsing problems, the possible copyright and patent issues that RNA sequences and AI-generated works could face, and a debate on the effectiveness of COVID-19 vaccines.

### Google Calendar and Assistant Reminders Will Migrate to Google Tasks Soon

#### [Submission URL](https://workspaceupdates.googleblog.com/2023/02/calendar-and-assistant-reminders-to-tasks-migration.html) | 121 points | by [e2e4](https://news.ycombinator.com/user?id=e2e4) | [115 comments](https://news.ycombinator.com/item?id=35849243)

Google has announced that its Calendar and Assistant Reminders will soon be migrating to Google Tasks, according to a post on the Google Workspace Updates blog. The move will allow users to manage their to-do lists in a single place and will provide a more streamlined experience. Google Tasks' integration with other Workspace apps, such as Gmail and Drive, will also make it easier for users to stay organized and productive. The migration is expected to be completed by the end of 2023.

Most of the discussion on the Hacker News thread centers around the difference between calendar events and tasks, and how the consolidation of reminders and tasks in Google Tasks will simplify things. There are also suggestions for Google to improve the graphical representation of its product relationships and for the company to establish more user-friendly voice control systems similar to those seen in Star Trek. There is also a discussion about how Google is pushing its voice assistant technology, even when it may not be in the best interest of users.

---

## AI Submissions for Sat May 06 2023 {{ 'date': '2023-05-06T17:37:46.426Z' }}

### AI tool designs mRNA vaccines that are more potent and stable

#### [Submission URL](https://www.nature.com/articles/d41586-023-01487-y) | 132 points | by [voisin](https://news.ycombinator.com/user?id=voisin) | [53 comments](https://news.ycombinator.com/item?id=35847774)

Researchers from Baidu Research, a Beijing-based AI company, have developed an AI tool that optimizes gene sequences in mRNA vaccines, thereby creating more potent and stable jabs that can be deployed globally. The software uses computational linguistics to design mRNA sequences that are more intricate than currently used vaccines. This enables the genetic material to persist longer, leading to more antigens being produced by the body’s protein-making machinery, resulting in more protective antibodies to fend off infectious diseases. The enhanced structural complexity of the mRNA also offers improved protection against vaccine degradation, eliminating the need for cold-chain equipment to handle such jabs.

The discussion on Hacker News covered a variety of topics including the technical aspects of the AI tool, copyright issues surrounding AI-generated content, and the effectiveness of mRNA vaccines in preventing the spread of COVID-19. One user pointed out that statistically-based papers linked to in the discussion about longer testing periods can be flawed in their analysis, while another argued that mRNA vaccines may pose a risk of rationing and double the rational vs. vector collision risk identified in vaccine production. Overall, there was a mix of technical analysis and ethical concerns about the use and distribution of mRNA vaccines.

### Open source Background Remover: Remove Background from images and video using AI

#### [Submission URL](https://github.com/nadermx/backgroundremover) | 367 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [92 comments](https://news.ycombinator.com/item?id=35838504)

BackgroundRemover is a free and open source tool that allows users to remove background from images and videos using artificial intelligence (AI). The tool offers a simple command line interface and is powered by u2net models. Users can choose from various background removal methods, including u2netp, u2net, or u2net_human_seg, and can also apply alpha matting for better results. The tool supports popular file formats such as MP4 and GIF, and also allows users to overlay transparent videos over other videos or images. Overall, BackgroundRemover is a powerful and versatile tool for anyone looking to remove background from images and videos with ease.

There is a debate on whether Background Remover's creators or contributors can be trusted, as well as concerns over its pricing, downloading, and potential malicious activity. Users have shared alternatives and tips to improve its functionality. There have also been discussions on unrelated topics, such as technical skills and road safety.

### Intel OEM Private Key Leak: A Blow to UEFI Secure Boot Security

#### [Submission URL](https://securityonline.info/intel-oem-private-key-leak-a-blow-to-uefi-secure-boot-security/) | 627 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [352 comments](https://news.ycombinator.com/item?id=35843566)

MSI suffered a cyberattack in April by ransomware group Money Message, resulting in the exfiltration of 1.5TB of data, including the Intel OEM private key. The key is used to control Intel Boot Guard digital signatures which validate programs before operating system start-up, and could compromise the security of UEFI secure boot. The leaked key affects Intel's 11th, 12th and 13th generation processors and their original equipment manufacturers, including Lenovo and Supermicro. The full extent of the private key leaks remains unclear, although it is known that they impact at least 166 MSI products.

A few users contended that the best way to combat the potential security implications of the key's loss is to have a backup option in place, one that is secured in a disconnected system. Other users suggested that individuals should remain vigilant and pay attention to security updates given that UEFI implementations on most computers allow physical access to disable secure boot, while some users expressed concerns about balancing security and freedom to choose software.

### Qdrant: Vector Database for the next generation of AI applications

#### [Submission URL](https://github.com/qdrant/qdrant) | 22 points | by [nateb2022](https://news.ycombinator.com/user?id=nateb2022) | [5 comments](https://news.ycombinator.com/item?id=35844724)

Qdrant is a vector similarity search engine and database tailored to extended filtering support. It is useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications. Qdrant is written in Rust 🦀, which makes it fast and reliable even under high load. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more! The engine provides a production-ready service with a convenient API to store, search, and manage points, which are vectors with an additional payload. Qdrant offers a variety of client libraries, including Rust, Go, JavaScript/TypeScript, Python, Elixir, PHP, Ruby, and Java. It also offers a REST API and a gRPC interface for faster production-tier searches and supports filtering and payload, rich data types, query planning and payload indexes, SIMD hardware acceleration, write-ahead logging, and distributed deployment.

In the discussion, a user here4U praises Qdrant's vector similarity search engine and scalability. They mention that it is useful for neural-network or semantic-based matching and provides an API to manage points. Another user chxr remarks that they prefer Pinecone DB because it immediately connects to the internet, generates fewer files on disk, and is simple and fast. However, in response to a comparison with Qdrant and Pinecone, user ndr-z shares a benchmark link that suggests Qdrant performs better than Pinecone in terms of indexing time, search time, and memory usage.

### Using ChatGPT to generate a GPT project end-to-end

#### [Submission URL](https://github.com/ixaxaar/VardaGPT/blob/master/STORY.md) | 228 points | by [ixaxaar](https://news.ycombinator.com/user?id=ixaxaar) | [204 comments](https://news.ycombinator.com/item?id=35839536)

A programmer wondered about the impact of ChatGPT on programming and decided to test it out by attaching a memory module to a GPT. They used ChatGPT-4 to generate the project foundations, step by step, and even wrote unit tests. After a few weekend hours, they created VardaGPT, a repository entirely generated by ChatGPT-4. The experience was neither like working with a pair programmer nor a product manager scenario, but more like handholding a fresh grad who had absorbed all human knowledge. It was tiring but a differential productivity multiplier. The experiment concluded that the programmer's job is safe, at least for now. The aside adds that ChatGPT is also great at generating Agda and could be used to formalize all of pure math.

The discussion on Hacker News included conversations about the limitations and future potential of ChatGPT for programming, with one commenter noting that AI programming is not a threat to humans—at least, not yet. Some commenters suggested that the future of AI in programming will eliminate human intervention entirely, while others highlighted the importance of high-quality human programmers and the value of their ability to make judgements and explain things in natural language. One commenter shared their experience subscribing to ChatGPT and using it to generate limited programming prompts, while another experimented with using the GPT-4 API to generate a table of data.

### Show HN: ReRender AI - Realistic Architectural Renders for AutoCAD/Blender Users

#### [Submission URL](https://rerenderai.com) | 50 points | by [eddieweng](https://news.ycombinator.com/user?id=eddieweng) | [19 comments](https://news.ycombinator.com/item?id=35839593)

ReRender AI by Stylefie, Inc. is offering a service that generates photorealistic renders of buildings in over 20 different design styles. All users have to do is upload a picture of their project, and within seconds, they can enjoy the results. This service includes various types of buildings, such as single-family homes, shopping malls, hospitals, and more, in styles ranging from sleek international to playful post-modern. The rendered images are available in different resolutions. The service is currently in operation and is available through the ReRender AI website.

The discussion includes various comments, some of which suggest exciting applications, such as using it to explore new design ideas or rendering a floor plan that looks viable and realistic. Some commenters ask about the technology behind the AI, its ability to represent sustainable architecture features, and its potential limitations. There are also suggestions for other software programs to use in conjunction with ReRender AI. Finally, there is a comment about the need for an overhaul to the FreeCAD dr UI.

### It looks like GPT-4-32k is rolling out

#### [Submission URL](https://community.openai.com/t/it-looks-like-gpt-4-32k-is-rolling-out/194615) | 255 points | by [freediver](https://news.ycombinator.com/user?id=freediver) | [182 comments](https://news.ycombinator.com/item?id=35841460)

AI language model GPT-4-32k is rolling out its API, and developers are already starting to experiment with its capabilities. Some lucky users were quick to gain access to the new model and have been sharing their experiences on Hacker News. The GPT-4-32k model boasts an impressive 32,000 token context length, which allows it to generate much more in-depth and nuanced responses to inputs than its predecessors. However, not all users have gained access yet, and the rollout seems to be happening at different rates based on capacity. Nonetheless, anticipation for GPT-4-32k is high, and developers are eager to try it out for themselves.

While some users believe that GPT-4-32k is overhyped, others are excited about its potential. There is a discussion about how to calculate the total number of pages of context for 32k tokens, with different opinions put forth. Moreover, there is a discussion about how to handle long texts and conversations in the context of GPT models, and how different tools and strategies can be employed. There are also discussions about the request limit, cost, and pricing of GPT-4-32k, batch processing, and how to optimize the performance.

---

## AI Submissions for Fri May 05 2023 {{ 'date': '2023-05-06T00:23:21.363Z' }}

### Concrete: A fully homomorphic encryption compiler

#### [Submission URL](https://www.zama.ai/post/zama-concrete-fully-homomorphic-encryption-compiler) | 80 points | by [zacchj](https://news.ycombinator.com/user?id=zacchj) | [10 comments](https://news.ycombinator.com/item?id=35826723)

Zama has released their Fully Homomorphic Encryption (FHE) compiler, Concrete, designed to simplify the management of noise, cryptographic parameters selection, and order of operations for specific computations for developers. The Compiler expects an input program in MLIR, and it can be used via Python, C++, and C APIs as well as a CLI tool for debugging. The LibrarySupport class is one of the main entry points, enabling the compilation and execution of FHE programs while storing artifacts on disk. The compiled library is stored in a sharedlib file, along with a JSON file that describes the inputs and outputs and crypto parameters for the compiled function.

One commenter questioned the necessity of using encryption for weights, while another commenter pointed out that using FHE to protect software is similar to how Syncrosoft protected software using dongles. Another commenter mentioned that they have been working on developing a CPU designed for FHE for the past decade, while others compared Concrete to Google's FHE implementation. The discussion also included references to Concrete's code repository and a podcast on the intersection of FHE and zero-knowledge proofs.

### Shap-E: Generate 3D objects conditioned on text or images

#### [Submission URL](https://github.com/openai/shap-e) | 273 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [50 comments](https://news.ycombinator.com/item?id=35836976)

OpenAI has released its code and model for Shap-E, a system that generates 3D objects based on text or images. The release includes examples of models that can generate things like chairs that look like avocados, spaceships, and birthday cupcakes. Users can install Shap-E with pip, and access a variety of notebooks that provide guidance on encoding models, sampling 3D models based on a text prompt, and more. The code and model are available on GitHub under an MIT license.

Some users discuss their experiences with generating 3D objects, while others share examples of objects they have generated. Others comment on the difficulty of generating 3D models and suggest alternative tools. There is also discussion around the licensing of the code and models, as well as related topics such as 3D printing and file formats.

### Unlimiformer: Long-Range Transformers with Unlimited Length Input

#### [Submission URL](https://arxiv.org/abs/2305.01625) | 322 points | by [shishy](https://news.ycombinator.com/user?id=shishy) | [99 comments](https://news.ycombinator.com/item?id=35832802)

Researchers have proposed a new model called Unlimiformer, which extends the capabilities of existing transformer-based models by allowing them to handle unlimited input lengths for a better long-document and multi-document summarization. The model can be applied to any existing pretrained encoder-decoder transformer, and it offloads the attention computation across all layers to a single k-nearest-neighbor index that can be kept on the GPU or CPU memory and queried in sub-linear time. Unlimiformer has been shown to perform well on several benchmarks, summarizing even 350k token-long inputs from the BookSum dataset without any input truncation at test time. The code and models are publicly available online.

The comments section discusses topics such as the quality of pre-reviewed papers, self-aggrandizing behavior in the research community, challenges with peer review processes, differences between conferences and HN commenting, and the importance of feedback from the HN community.

### Bluesky's AT Protocol - Federation Architecture Overview

#### [Submission URL](https://blueskyweb.xyz/blog/5-5-2023-federation-architecture) | 137 points | by [capableweb](https://news.ycombinator.com/user?id=capableweb) | [79 comments](https://news.ycombinator.com/item?id=35834106)

Bluesky, the new social media platform built on the AT Protocol, is set to launch a sandbox environment for testing federation with allow-listed servers. A federated networking model, AT Protocol differs from conventional social media by allowing users to run their own servers, host data on a personal data server, and use big graph services to assemble and curate a personal feed. The architecture is expected to facilitate public conversations on a global social network, with an ecosystem of app views for each lexicon, including video, long-form blogging, and groups and forums. Bluesky aims to make federation easy and accessible to all.

The discussion around the submission on Hacker News includes various opinions and insights. Some users express concerns regarding Bluesky's implementation of centralization, such as difficulty in implementing control and filtering, while others believe that Bluesky's potential for transparency and decentralized social media could be a healthier alternative to existing platforms. Additionally, there is debate regarding the comparison between ActivityPub and Bluesky, with some users pointing out differences in their respective designs and certain limitations of ActivityPub. There is also discussion about the challenges of migration between servers and ways to address the issue of lost interactions in the process. Overall, the discussion brings up various important points related to decentralization and the future of social media.

### At Musk’s brain-chip startup, animal-testing panel is rife with conflicts

#### [Submission URL](https://www.reuters.com/technology/musks-brain-chip-startup-animal-testing-panel-is-rife-with-potential-conflicts-2023-05-04/) | 137 points | by [wootland](https://news.ycombinator.com/user?id=wootland) | [90 comments](https://news.ycombinator.com/item?id=35834918)

Elon Musk's brain-implant company, Neuralink, has come under fire for filling its animal-research oversight board with company insiders who may stand to benefit financially from the venture's development goals. According to documents and interviews with employees, 19 of the board's 22 members were Neuralink employees as of late 2022, raising questions about potential violations of conflict-of-interest regulations aimed at protecting research integrity. As we've previously reported, Neuralink is seeking regulatory approval for human trials of a brain chip intended to help paralyzed people type with their minds, among other goals.

Some users argue for the need for regulated and informed animal testing, while others argue for caution in human testing. There is also a debate on the efficacy and enforceability of current regulations, with some users calling for a change in regulations to better protect animals and humans involved in scientific research.

### Show HN: UnionX – GPT4-powered Copilot for Work with Jupyter-style notebooks

#### [Submission URL](https://www.unionx.io/) | 48 points | by [gangster_dave](https://news.ycombinator.com/user?id=gangster_dave) | [5 comments](https://news.ycombinator.com/item?id=35836679)

Looking for a way to boost your productivity and streamline your workflow? Look no further than UnionX, the AI-powered platform that lets you easily analyze documents, generate insights, and create new documents in seconds. Whether you're a data scientist, legal professional, or product manager, UnionX can help you save time and work more efficiently. With powerful tools like OpenAI's GPT4 model and Jupyter-style workflows, UnionX makes it easy to gather, analyze, and generate new insights from your data. So why wait? Try UnionX today and start achieving more in less time!

Some users feel that the concept sounds exciting, but the marketing documentation is not clear enough. They suggest pushing towards a Jupyter notebook interface for non-coding tasks and adding a coding interface for more technical users. Others believe that simple notebooks and screencaps of them would be helpful in understanding the product. The conversation then shifts to coding integration and the need for actual notebooks rather than lock-in options. One user also raises a question regarding comparing the platform's source version.

### The AI PR Industrial Complex

#### [Submission URL](https://www.bigtechnology.com/p/the-ai-pr-industrial-complex) | 80 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [36 comments](https://news.ycombinator.com/item?id=35829430)

In the rush for corporations, politicians, and other thought leaders to monetize and exploit the opportunities presented by AI technology, an AI PR industrial complex is emerging. This complex operates by using AI as a pretext for problems that might have other causes such as IBM's decision to replace up to 7,800 back-office employees with AI, as opposed to using the technology to make workers more productive. Similarly, politicians and regulators running to the cameras to talk about AI raises questions about their actual understanding of the technology's opportunities and risks. While some AI announcements have real substance, the AI PR industrial complex is growing and drawing deserved skepticism.

Commenters suggest that the AI hype is similar to the cryptocurrency hype of the past, and the emerging AI PR industry is drawing deserved skepticism. Some commenters talk about how AI technology may be applied for specific domain-specific tasks, such as creating 2D and 3D animations for games and designing dashboards and data visualization tools. There is also a discussion of how AI is being used to generate advertisements and how LLMs may be used to solve real-world problems in sectors such as energy and sustainable growth. 

### MosaicML MPT-7B: A Commercially-Usable LLaMa-Quality Model

#### [Submission URL](https://www.mosaicml.com/blog/mpt-7b) | 102 points | by [ml_hardware](https://news.ycombinator.com/user?id=ml_hardware) | [11 comments](https://news.ycombinator.com/item?id=35829800)

MosaicML, an AI platform, has launched its MPT-7B model series, comprising pre-trained transformers that enable faster training and inference. The series comprises four models: MPT-7B Base, a decoder-style transformer with 6.7 billion parameters; and three finetuned variants, including the super-long context MPT-7B-StoryWriter-65k+. MosaicML also released the entire codebase for pretraining, finetuning, and evaluating MPT, a framework for building LLMs, and training and deployment instructions. The models can be licensed for commercial use and are a response to a flurry of activity focused on open-source LLMs.

Some users express confusion around the size and input of the models, but overall, people are impressed with MosaicML's documentation and instructions for training and deployment. One user notes that the MPT-7B model is similar to LLaMa but shows significant improvements in some use cases. Others discuss the practical applications of such models, such as using them for chat instruction and generating long-form text. Finally, there are some comments about the potential future release of GPT-4 and speculation on its potential impact on the AI language modeling space.

### OpenAI changed its plans and won’t train on customer data, Sam Altman says

#### [Submission URL](https://www.cnbc.com/2023/05/05/sam-altman-openai-wont-tap-into-customer-apis.html) | 41 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [10 comments](https://news.ycombinator.com/item?id=35830107)

OpenAI has stopped training its large-language models, including the popular chatbot ChatGPT, with paying customer data. This change came as a response to customers who had requested that the company not use their data. OpenAI's terms of service were quietly updated in March to reflect this shift. However, the company's privacy and data protection policy only applies to customers who use the company's API services. The change highlights growing concerns about the use of large-language models such as ChatGPT in areas such as entertainment, where intellectual property rights are being challenged.

The comments on the submission discuss various aspects related to OpenAI's decision to stop training its large-language models with customer data. Some users suggest that OpenAI should provide more control to customers over their data, while others highlight the importance of licensing in protecting intellectual property rights. There is also a discussion on the efficacy of using domain-specific tasks for training language models and the limitations of publicly available training data. One user mentions Azure OpenAI services as a potential alternative.

---

## AI Submissions for Thu May 04 2023 {{ 'date': '2023-05-04T15:01:43.244Z' }}

### Rest in Peas: The Unrecognized Death of Speech Recognition (2010)

#### [Submission URL](https://robertfortner.posthaven.com/rest-in-peas-the-unrecognized-death-of-speech) | 37 points | by [jawns](https://news.ycombinator.com/user?id=jawns) | [43 comments](https://news.ycombinator.com/item?id=35800935)

Computer speech recognition hit a flatline in 2001 before it even reached human levels of accuracy, largely due to computers being unable to properly understand language. While progress has been made since the 1950s and 1960s, relying mainly on fast computers and digital text to supplement decades-old language machinery, current accuracy rates still hover around 80%, with humans at 98%. Despite billions of text at their disposal, machines are prone to risky guessing and limited by parsers and recognition systems that work only in certain linguistic domains. Efforts to allow programs to understand grammar and word meaning have been largely unsuccessful, leaving them with a significantly different understanding of language than humans.

The discussion among commenters touches on various topics, including the challenges of recognizing different dialects and accents, reinforcement learning and human feedback, the accuracy of speech recognition software and the importance of context in understanding speech. Some commenters also mention their experiences with specific speech recognition programs and datasets, such as Common Voice and Whisper.

### OpenLLaMA: An Open Reproduction of LLaMA

#### [Submission URL](https://github.com/openlm-research/open_llama) | 463 points | by [sadiq](https://news.ycombinator.com/user?id=sadiq) | [175 comments](https://news.ycombinator.com/item?id=35798888)

OpenLLaMA, an open-source reproduction of Meta AI's LLaMA language model, has been released on GitHub. In this release, a public preview of the 7B OpenLLaMA model trained with 200 billion tokens has been provided, along with PyTorch and JAX weights of pre-trained OpenLLaMA models, and their evaluation results and comparison against the original LLaMA models. Additionally, a new checkpoint of OpenLLaMA 7B trained on 300B tokens has been released to make the model broadly compatible with existing implementations. The results indicate that OpenLLaMA exhibits comparable performance to the original LLaMA and GPT-J across a majority of tasks and outperforms them in some.

In the comments, there is a discussion about the resources required for ML models and their training cost, along with recommendations to understand ML terms and concepts. There is also debate about the use of the word "hallucination" to describe the output of language models.

### Distilling Step-by-Step Outperforming Larger Language Models with Less Training

#### [Submission URL](https://arxiv.org/abs/2305.02301) | 144 points | by [verdverm](https://news.ycombinator.com/user?id=verdverm) | [33 comments](https://news.ycombinator.com/item?id=35810663)

Researchers have developed a new mechanism called "Distilling Step-by-Step" that trains smaller models to outperform larger language models (LLMs) using less training data. This method extracts LLM rationales to provide additional supervision for small models in a multi-task training framework, leading to better performance with fewer labeled/unlabeled training examples. Distilling Step-by-Step achieves better performance with substantially smaller model sizes and reduces both the model size and the amount of data needed to outperform LLMs. The method was successful in four NLP benchmarks and could help make LLMs more memory-efficient and compute-intensive for practical applications.

The comment section discusses the importance of smaller, task-specific models and the challenges of deploying large language models in practical applications due to memory and computation constraints. Furthermore, the commenters discuss related approaches like "Alpaca" and the impact of model licensing and commercialization.

### The first empirical study of the real-world economic effects of new AI systems

#### [Submission URL](https://www.npr.org/sections/money/2023/05/02/1172791281/this-company-adopted-ai-heres-what-happened-to-its-human-workers) | 112 points | by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) | [72 comments](https://news.ycombinator.com/item?id=35809397)

A recent study conducted by economists at Stanford University and MIT found that implementing an AI chatbot into customer service workflows resulted in a significant increase in productivity and customer satisfaction. The study looked at the effects of incorporating ChatGPT, a popular interactive AI chatbot, on a Fortune 500 company's customer support team. The chatbot, which was trained by reading previous conversations between reps and customers, helped customer support agents more effectively assist customers in real time and provided them with links to internal company information to solve technical problems. The results suggest that AI could have positive economic effects in improving productivity, but also highlight the potential for disruptive change and income inequality.

One commenter expressed skepticism about the study's premise, stating that deflection in the customer service world means preventing customers from talking to humans and that AI chatbots cannot completely replace skilled workers. Other discussions revolve around the possibility of AI systems having internal biases, lowering the skill bar, reducing human job function, and potential privacy concerns. Another commenter suggested ingesting data from different platforms such as Slack, Gmail, Jira, Meet, etc., associated with timestamps, as it can help assign higher importance to documents and policies based on their relevance. Another comment discusses a company that believes AI systems that do not employ cash but focus on skilled employees' knowledge are vital to maintain the system. However, this leads to wider income inequality between low and high-skilled workers.

### Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings

#### [Submission URL](https://lmsys.org/blog/2023-05-03-arena/) | 46 points | by [MMMercy2](https://news.ycombinator.com/user?id=MMMercy2) | [6 comments](https://news.ycombinator.com/item?id=35806589)

Chatbot Arena, a new benchmark platform for large language models (LLMs), has been released. The platform features anonymous, randomized battles in a crowdsourced manner, and uses the Elo rating system for ranking models – a system widely used in competitive games like chess. The platform allows users to contribute new models and evaluate them based on anonymous votes for which model performs better during chat interactions. The platform already has a leaderboard featuring Elo ratings of popular open-source large language models.

There were several comments on the submission. One user, HoshinoAI, mentioned that the platform uses a ranking algorithm called Glicko. Another user, zhsbg, provided a reference variant ELO. HoshinoAI then pointed out a matchmaking section on Dota 2's website and a Wikipedia page on the Glicko rating system. 

Another user, wchng, was surprised to learn that StableLM was not included in the LLaMA leaderboard. Another user, circuit10, stated that they had heard about it before. Another user, frdvr, simply commented, "good day." Finally, two users, lee101 and aaron695, left comments but they were not clear on their meaning.

### Poisoning Language Models During Instruction Tuning

#### [Submission URL](https://arxiv.org/abs/2305.00944) | 83 points | by [hardmaru](https://news.ycombinator.com/user?id=hardmaru) | [4 comments](https://news.ycombinator.com/item?id=35801673)

A new paper titled "Poisoning Language Models During Instruction Tuning" warns that adversaries can contribute poisoned examples to instruction-tuned language models (LMs), allowing them to manipulate model predictions whenever a desired trigger phrase appears in the input. By using as few as 100 poison examples, the model struggles to classify, summarize, edit, or translate that input accurately. The paper also shows that larger LMs are increasingly vulnerable to poisoning and that existing defenses provide only moderate protection while reducing test accuracy, raising concerns about the robustness and security of these models.

The discussion around this submission includes three comments. The first commenter shared a headline about a WhatsApp landing court in India and also mentioned some important points about dynamic malware detection and LLM. The second commenter mentioned something about a Manchurian GPU, but the context of this comment is unclear. The third commenter shared a meme about the background of the researchers involved in the creation of the paper, which features a clown and a conspiracy theory involving George Soros.

### SparseGPT: Language Models Can Be Accurately Pruned in One-Shot

#### [Submission URL](https://arxiv.org/abs/2301.00774) | 209 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [62 comments](https://news.ycombinator.com/item?id=35804556)

Researchers have developed a new pruning technique, called SparseGPT, that can efficiently and accurately reduce the size of large-scale generative pretrained transformer (GPT) models without impacting their accuracy. The method can prune models at least 50% sparsity in one-shot without retraining, such that over 100 billion weights from the models can be ignored at inference time. The project team could execute SparseGPT on the largest available open-source GPT-family models in less than 4.5 hours, making the method compatible with semi-structured patterns and weight quantization approaches.	Code for SparseGPT is available for use at GitHub.

Comments discuss the use of L1 regularization and random pruning techniques, the benefits and tradeoffs of different methods for training, and the practical applications of compressed models for inference. One commentator references a larger model than GPT-3 called PaLM 540B, which generates exciting possibilities for future research.

### The Full Story of Large Language Models and RLHF

#### [Submission URL](https://www.assemblyai.com/blog/the-full-story-of-large-language-models-and-rlhf/) | 107 points | by [pk3](https://news.ycombinator.com/user?id=pk3) | [20 comments](https://news.ycombinator.com/item?id=35803522)

This article provides a thorough overview of language models, from their fundamental ideas to the latest advancements. Language models are probabilistic models designed to learn statistical patterns in natural language, and they can predict the most probable words to follow a given input sentence. They are trained through self-supervised learning, a process that uses unannotated text to generate labels for training. One way to unlock the potential of language models is via the process of fine-tuning, which refines and adapts their knowledge to more specialized domains. However, the risks and misuse of language models have become a primary concern, leading to a demand for methods such as Reinforcement Learning from Human Feedback (RLHF) to control and steer these large-scale AI systems.

The discussion revolves around the potential of AI to find vulnerabilities in software and the ethics of using AI to find weaknesses that can be exploited by hackers. The conversation also touches on the importance of finding vulnerabilities in software and the cost of fixing them. Additionally, the community discusses the role of machine learning in finding and fixing vulnerabilities and the importance of transferring learning data to scale AI. Another topic of discussion was the advancements in language models and their potential to revolutionize the field of natural language processing. Finally, Reinforcement Learning from Human Feedback (RLHF) for training Language Models (LLMs) is highlighted as a critical development in the field of AI.

---

## AI Submissions for Thu May 03 2023 {{ 'date': '2023-05-03T15:01:43.244Z' }}

### GPT-4 Can’t Replace Striking TV Writers, but Studios Are Going to Try

#### [Submission URL](https://www.vice.com/en/article/pkap3m/gpt-4-cant-replace-striking-tv-writers-but-studios-are-going-to-try) | 48 points | by [shscs911](https://news.ycombinator.com/user?id=shscs911) | [36 comments](https://news.ycombinator.com/item?id=35806470)

The Writers Guild of America is currently on strike, protesting the use of AI as a replacement for human writers in film and television. The guild proposed to regulate the use of AI on union projects, but the Alliance of Motion Picture and Television Producers rejected the notion, calling the guild's request "absurd." Fears among writers include being underpaid to rewrite what they consider AI-generated "trash," and being replaced altogether by the machines. However, the reality is that AI still struggles to distinguish between true facts, has trouble personalizing outputs to users, and is very sensitive to framing and wording of prompts.

In the comments, users argue that AI is not yet advanced enough to fully replace human writers and that the WGA's request for regulations may be based on populist sentiment rather than a genuine need to protect its members. Some also suggest that AI-generated content could be useful for background material or non-dialogue scenes, while others question the legality of AI-generated material being awarded writing credits.

### Beware of AI pseudoscience and snake oil

#### [Submission URL](https://www.baldurbjarnason.com/2023/beware-of-ai-snake-oil/) | 233 points | by [bertman](https://news.ycombinator.com/user?id=bertman) | [171 comments](https://news.ycombinator.com/item?id=35800667)

The submission discusses the exaggerated claims of AI capabilities, the need for concrete evidence to back them up, and the importance of being skeptical. The discussion includes comments on the difference between pessimism and optimism in measuring AI capabilities, the misleading claims made by companies for marketing purposes, the risk posed by AI if not regulated properly, and the practical applications of AI. There is also a conversation about the terminology used to describe AI, including whether the term "lying" is appropriate, and criticism of the media for using sensational language to describe AI. Finally, there is a comparison made between the hype surrounding AI and the hype surrounding virtual machines and containers in the past, and the importance of technical experts in the decision-making process.

### NYC considers facial recognition ban for businesses, landlords after MSG debacle

#### [Submission URL](https://gothamist.com/news/nyc-council-facial-recognition-biometric-ban-businesses-landlords) | 18 points | by [lisasays](https://news.ycombinator.com/user?id=lisasays) | [5 comments](https://news.ycombinator.com/item?id=35810770)

New York City is considering introducing two bills that would restrict the use of facial recognition and other biometric surveillance technology by private businesses and landlords. The first bill would ban businesses from using facial scans or other biometric technology to identify customers, while the second would prohibit residential landlords from using the same sort of biometric identification of tenants and guests. The proposed legislation also includes requirements for explicit consent from tenants or customers for any other types of biometric data collection, and a ban on selling such data to third parties. The hearing follows previous efforts to restrict facial recognition tech in New York, including state legislators attempting to curb its use by landlords, government agencies and police.

The discussion revolves around the specifics of the bills, with some participants citing security concerns as a reason to allow the use of such technology while others argue in favor of privacy protection. Some commenters also dispute the effectiveness of facial recognition technology in preventing crime and suggest alternative solutions. One user proposes a solution of implementing a blacklist of people who have caused trouble in the past rather than resorting to facial recognition technology.

### The Discord Where Thousands of Rogue Producers Are Making AI Music

#### [Submission URL](https://www.vice.com/en/article/y3wdj7/inside-the-discord-where-thousands-of-rogue-producers-are-making-ai-music) | 21 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [3 comments](https://news.ycombinator.com/item?id=35808173)

A group of music producers and songwriters recently released an entire album called UTOP-AI that featured AI-generated versions of rapper Travis Scott's voice and other artists. However, the album was quickly taken down due to a copyright claim from Warner Music Group. As AI music becomes more popular, it has provoked a cultural debate. While AI creators defend the technology as a way to make music more accessible, many music industry professionals and other critics accuse creators of copyright infringement and cultural appropriation. The Discord server AI Hub hosts a large community of AI music creators behind some of the most viral AI songs, and it has over 21,000 users. However, the copyright issue in AI music is being heavily debated, with labels and publishers gearing up to tackle this new issue in the music industry.

One commenter named "slyll" asserts that copyright claims are becoming increasingly dubious since music producers can create songs with a similar style to famous artists without directly copying their music or lyrics. They argue that as long as the creator does not claim to be the original artist, and does not directly copy the music or lyrics, it should be legal. Another comment from "Nition" clarifies that the vocals used in AI-generated music are entirely created by an AI and not just manipulated versions of the original artists' vocals. A third commenter named "llmjms" did not have anything to add to the discussion.

### Amnesty International criticised for using AI-generated images

#### [Submission URL](https://www.theguardian.com/world/2023/may/02/amnesty-international-ai-generated-images-criticism) | 101 points | by [johnyzee](https://news.ycombinator.com/user?id=johnyzee) | [88 comments](https://news.ycombinator.com/item?id=35800210)

Amnesty International has faced backlash after using artificial intelligence (AI)-generated images to promote their reports on social media regarding the 2021 protests in Colombia. The images, which depicted instances of police brutality towards protesters, were criticised for being unrealistic and for undermining the human rights advocacy group's work by potentially feeding conspiracy theories. Amnesty's use of AI images raised questions about plagiarism and ethics in photojournalism. The group eventually removed the images and acknowledged the criticism but defended their intention of protecting protesters with anonymity.

Some commenters argue that the use of AI-generated images is part of a trend of human rights organisations relying on emotionally manipulative marketing campaigns to generate donations. Others point out that Amnesty International's budget is heavily spent on research and advocacy, rather than advertising, and that its efforts to protect protesters' anonymity were well-intentioned. The conversation also touched on related topics such as the use of AI-generated porn and the challenges of verifying identities in the porn industry. Amnesty International has acknowledged the criticism and removed the AI-generated images.

### AI vs. Hollywood: Writers battle “plagiarism machines” in union talks

#### [Submission URL](https://arstechnica.com/tech-policy/2023/05/ai-vs-hollywood-writers-battle-plagiarism-machines-in-union-talks/) | 19 points | by [m-watson](https://news.ycombinator.com/user?id=m-watson) | [3 comments](https://news.ycombinator.com/item?id=35806197)

The Writer's Guild of America (WGA) is seeking to limit the use of AI in writing film and TV scripts during an ongoing strike. WGA writers have raised concerns over AI-generated content being used as training data and the prospect of them being tasked with fixing "sloppy first drafts" created by AI. They also argue that existing scripts should not be used to train AI to avoid intellectual property (IP) theft. So far, studios have rejected WGA's proposals, instead offering to discuss new technologies annually. The strike is the first in 15 years and comes amid growing concerns over the impact of automation on jobs.

The first comment by "askin4it" expresses sarcasm towards the Writer's Guild of America for seeking to limit the use of AI in scriptwriting during a strike. The second comment by "crtrmn" suggests that the conflict could be easily resolved through cross-licensing deals. The third comment by "mansion7" argues that Hollywood and Silicon Valley are both supportive of high immigration numbers and replacing lower-paid American workers with foreigners, leading to political donations and complaints of xenophobia.

### “All Tomorrow’s Parties”: AI Synthesis – The End of Copyright as We Knew It

#### [Submission URL](https://www.heise.de/meinung/All-Tomorrow-s-Parties-AI-Synthesis-The-End-of-Copyright-as-We-Knew-It-8985282.html) | 23 points | by [walt74](https://news.ycombinator.com/user?id=walt74) | [11 comments](https://news.ycombinator.com/item?id=35799116)

In the age of machine learning, intellectual property and copyright laws face radical upheaval due to generative AI systems. Lawsuits against AI companies highlight concerns over protecting and promoting art and creativity. The distribution mechanisms of collecting societies like GEMA or VG Wort managing member copyrights risk fraudulent claims with easy-to-use AI-generated content capable of boosting profits. Generative AI models like Stable Diffusion or ChatGPT operate like library-like cultural technologies that provide access to and multiply knowledge creating “stochastic libraries” for interpolable data spaces computed by algorithms. The interpolative nature of AI models creates a huge explosive force for existing systems of copyright with each synthetic image or generative text the result of multidimensional interpolation of the latent space posing unprecedented problems for copyright law.

The submission discusses how generative AI systems are challenging intellectual property and copyright laws. The comments address issues such as the difficulty of capturing 99% of AI-generated content under copyright law and the need for consistency in digital property concepts. Some argue that licensing systems could benefit creators, but others point out that copyright-based systems are based on capital purchase and disregard inherent creators. There are concerns about synthetic AI-generated voices causing problems for contracts requiring identifiable voices, as well as the potential for AI to become a tool for criminals. The discussion highlights the complexity of IP and copyright laws in the age of AI.

### Google, Microsoft CEOs Called to AI Meeting at White House

#### [Submission URL](https://www.reuters.com/technology/google-microsoft-openai-ceos-attend-white-house-ai-meeting-official-2023-05-02/) | 89 points | by [kamban](https://news.ycombinator.com/user?id=kamban) | [104 comments](https://news.ycombinator.com/item?id=35802698)

The CEOs of Google, Microsoft, OpenAI, and Anthropic are set to meet with Vice President Kamala Harris and other top officials to discuss AI-related concerns on Thursday. The invitation, seen by Reuters, emphasized President Joe Biden's expectation that companies ensure their AI products are safe for public use. The concerns around AI technology include privacy violations, bias, and proliferation of scams and misinformation. The Biden administration has also been seeking public comments on proposed accountability measures for AI systems. The meeting will be attended by Biden's Chief of Staff, National Security Adviser, and Secretary of Commerce, among others.

There was a lengthy discussion on this submission, covering a range of topics related to AI. Some users expressed concern that regulating AI is difficult and that existing regulations can unintentionally harm innovation or favor established players. Others argued that regulations can protect consumers and create a level playing field. There was also discussion around the rise of language models like GPT and how they could be used to deceive people. Several users remarked that LLMs need to be regulated to prevent misinformation, while others noted the difficulty of regulating speech and the potential for unintended consequences. Some users suggested that AI regulation would require the expertise of qualified committees and government agencies. Finally, one user suggested that OpenAI and Anthropic should focus on demonstrating the safe use cases of their technology, rather than solely lobbying for regulation.

### GPT AI Enables Scientists to Passively Decode Thoughts in Groundbreaking Study

#### [Submission URL](https://www.artisana.ai/articles/gpt-ai-enables-scientists-to-passively-decode-thoughts-in-groundbreaking) | 8 points | by [ianrahman](https://news.ycombinator.com/user?id=ianrahman) | [4 comments](https://news.ycombinator.com/item?id=35810969)

Scientists have used a ChatGPT-like AI model to decode human thoughts with unprecedented 82% accuracy from functional MRI recordings, opening up new opportunities for neuroscience, communication, and human-machine interfaces. However, this breakthrough also raises serious concerns about mental privacy, emphasizing the need for policies to prevent potential misuse of this technology. The researchers also acknowledged the limitations of the current model and stressed the importance of using a subject's own brain recordings for accurate AI model training.

The first comment by user "djmps" states that using technology like ChatGPT can help people with disability to communicate better. The subsequent comment by user "lrmls" adds that such technology could also improve diagnostic accuracy in neurological conditions and could potentially replace the current gold standard - neurological examination - which has low fidelity.

The second comment by user "p--w" expresses amazement at the technology's accuracy and is reading technical papers that explain how it works. Another user "strng" responds by saying that while the technology is impressive, it is essential to validate the AI's ability to decode thoughts from fMRI data. They also mention that speech and thoughts are not necessarily the same, so listening to speech signals may not always be equivalent to decoding thoughts accurately.

### 25% of jobs set to be disrupted in the next 5 years – A.I. could play a key role

#### [Submission URL](https://www.cnbc.com/2023/05/02/nearly-25percent-of-jobs-are-set-to-be-disrupted-in-the-next-five-years-wef.html) | 46 points | by [hochmartinez](https://news.ycombinator.com/user?id=hochmartinez) | [71 comments](https://news.ycombinator.com/item?id=35804808)

According to a report from the World Economic Forum, approximately 23% of all jobs will be disrupted in the next five years. The report indicates that technological advancements such as Artificial Intelligence and climate change are key drivers in the job losses expected to take place, with administrative and traditional security roles being the most affected. However, the report also highlights that certain industries such as education, agriculture, and health will see higher creation of jobs enabled by technology. The report stresses that the rise of the green economy and higher standards for environmental, social and governance practices within companies will provide the biggest drivers for future job creation.

The debate in the comments centers on the impact of increased productivity and whether it benefits consumers or producers more. Some see the destruction of jobs as inevitable and emphasize the need for higher qualifications, while others believe that growth and progress can coexist with job security. Some are also critical of socialism and suggest that capitalism helps channel people's efforts into constructive endeavors.

---

## AI Submissions for Tue May 02 2023 {{ 'date': '2023-05-02T14:21:15.829Z' }}

### Jsonformer: Generate structured output from LLMs

#### [Submission URL](https://github.com/1rgs/jsonformer) | 300 points | by [yunyu](https://news.ycombinator.com/user?id=yunyu) | [78 comments](https://news.ycombinator.com/item?id=35790092)

Jsonformer is a new approach to generating structured JSON from language models, which addresses the challenges and limitations of current approaches. It is a wrapper around HuggingFace models that fills in the fixed tokens during the generation process, and only generates the content tokens. This makes it more efficient and bulletproof than existing approaches that rely on prompt engineering, fine-tuning, and post-processing. Jsonformer currently supports a subset of JSON Schema and comes with features such as bulletproof JSON generation, efficiency, and flexibility. It is built on top of the HuggingFace transformers library, making it compatible with any model that supports the HuggingFace interface. It is released under the MIT License, and you can install it via pip.

The discussion thread raised different issues such as the efficacy of the wrapper, the potential of Cue, and the complexities of long-form language models. Other contributors shared their approaches, ideas, and explorations of tools and libraries such as Recmos Cria, Llama Numpy, Transformers, and Clue. They addressed testing models, constraints and modifications, interoperability, and the role of language modeling in AI development and research.

### Avoiding hallucinations in LLM-powered applications

#### [Submission URL](https://vectara.com/avoiding-hallucinations-in-llm-powered-applications/) | 128 points | by [ofermend](https://news.ycombinator.com/user?id=ofermend) | [107 comments](https://news.ycombinator.com/item?id=35794010)

Hallucinations can occur when an LLM encounters an edge case or a rare scenario for which it wasn't adequately trained. Additionally, the LLM may generate responses by incorporating biases and patterns present in the training data, which can lead to nonsensical or biased answers. It's crucial to address these issues to improve the reliability and trustworthiness of LLM-powered applications. One promising solution to avoid hallucinations is "Grounded Generation," a research project that aims to ground LLMs in the real world by incorporating external knowledge sources. By providing contextual information to LLMs, Grounded Generation can help prevent hallucinations and generate more accurate and reliable responses.

 The discussion in the comments explores various approaches to addressing this issue, including incorporating external knowledge sources through "Grounded Generation" and the difficulty of modeling human-like truth-telling. Issues of biased and nonsensical responses generated by LLMs are also addressed and the importance of training data and testing is emphasized. The feasibility of categorizing and creating training data is also discussed.

### AI-generated beer commercial contains joyful monstrosities, goes viral

#### [Submission URL](https://arstechnica.com/information-technology/2023/05/ai-generated-beer-commercial-contains-joyful-monstrosities-goes-viral/) | 73 points | by [nobody9999](https://news.ycombinator.com/user?id=nobody9999) | [23 comments](https://news.ycombinator.com/item?id=35797258)

A surreal AI-generated beer commercial called "Synthetic Summer" has gone viral. Created by Privateisland.tv, the 30-second video appears to have been made with Runway's new Gen-2 AI model, which can create short video clips based on written prompts. However, the technology is still relatively primitive and requires human effort to generate even acceptable results. In the case of "Synthetic Summer", Privateisland.tv generated the clips, selected the best ones, and added music and sound effects to create the final product. While the video may be impressive in its own right, it shows that generative AI still has a long way to go before it can create autonomously bedazzling memes.

Some commenters argue that the AI-generated content is gibberish, while others note that it offers an interesting and nostalgic marketing angle. The discussion also covers the limitations of AI and how it is different from human intelligence. One commenter suggests that instead of building AI systems to mimic human behavior, they should focus on creating interesting and unique AI-generated content, such as physical character movements, that humans cannot produce. Another commenter mentions that AI-generated videos featuring monsters can be traumatizing, and one commenter suggests that the video appears to verge on the surreal.

### IBM to pause hiring in plan to replace 7,800 jobs with AI

#### [Submission URL](https://finance.yahoo.com/news/ibm-pause-hiring-plans-replace-212747073.html) | 261 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [194 comments](https://news.ycombinator.com/item?id=35784814)

IBM's CEO Arvind Krishna has stated in an interview that the company is expected to pause hiring for certain roles, as those positions could be replaced by artificial intelligence in the coming years. This move could impact roughly 7,800 jobs in the company. However, IBM has yet to officially comment on the matter.

The discussion on Hacker News largely centers around speculations about the impact of AI on employment and IBM's business strategy. Some users view IBM's move to embrace AI as a strategic business opportunity, while others criticize the company's approach of cutting jobs and reducing investment in research. There are also discussions about IBM's reliance on consulting services and concerns about the company's declining revenue in recent years.

### Samsung bans use of A.I. like ChatGPT for employees

#### [Submission URL](https://www.cnbc.com/2023/05/02/samsung-bans-use-of-ai-like-chatgpt-for-staff-after-misuse-of-chatbot.html) | 236 points | by [mrkramer](https://news.ycombinator.com/user?id=mrkramer) | [239 comments](https://news.ycombinator.com/item?id=35787454)

Samsung has temporarily restricted the use of generative AI tools like ChatGPT by its employees after cases were reported of their misuse. Some of the staff at Samsung's division had uploaded sensitive code on the AI chatbot ChatGPT, which is developed by US firm OpenAI, and is trained on vast amounts of data to generate responses to user queries. Samsung has advised its employees to be cautious while using such services outside work and not to enter personal or company-related data in them. The South Korean giant is also exploring ways to safely deploy generative AI to enhance employee productivity and efficiency.

The discussion on the thread highlights that companies with sensitive information need to be especially cautious of AI usage, and must have strong governance policies in place to mitigate risk. The discussion also touches upon similar issues relating to the use of cloud services and web-based tools like Google Docs and Office365.

### Mojo – a new programming language for AI developers

#### [Submission URL](https://www.modular.com/mojo) | 526 points | by [lairv](https://news.ycombinator.com/user?id=lairv) | [212 comments](https://news.ycombinator.com/item?id=35790367)

Mojo, a new programming language that combines the usability of Python with the performance of C, has been created for AI developers. It allows users to program low-level AI hardware with no need for C++ or CUDA. Mojo offers features such as progressive types, ownership and borrow checker, and portable parametric algorithms, which reduces boilerplate. It also offers zero-cost abstractions, parallel heterogenous runtime, and auto-tuning. Users can unleash the full power of their hardware, including multiple cores, vector units, and exotic accelerator units with the world's most advanced compiler, and they can achieve performance on par with C++ and CUDA without the complexity. Mojo is interoperable with the Python ecosystem, seamlessly intermixing arbitrary libraries with custom code. Users can extend their models with pre and post-processing operations or replace operations with custom ones with ease. Mojo is available to try in a Jupyter note-based playground.

The discussion in the comments covers various topics, including comparisons with languages such as Julia, Python's strengths and weaknesses, garbage collection, and the suitability of different languages for different purposes. Overall, the response to the submission is mostly positive, with many users praising Mojo's innovative features and potential for AI development.

### Make your Python functions return something meaningful, typed, and safe

#### [Submission URL](https://returns.readthedocs.io/en/latest/index.html) | 45 points | by [dr_kiszonka](https://news.ycombinator.com/user?id=dr_kiszonka) | [63 comments](https://news.ycombinator.com/item?id=35792949)

If you want to make your Python functions more functional, declarative, and readable, check out Returns. This library provides primitives to write declarative business logic, such as Maybe and RequiresContext containers, which get rid of None and let you use typed functional dependency injection. Returns is fully typed with annotations and checked with mypy, and adds emulated Higher Kinded Types support as well as type-safe interfaces to create your own data types with enforced laws. The library also has a bunch of helpers for better composition, and is Pythonic and pleasant to write and read. You can install Returns with pip and configure mypy to use it, and then start using its containers right away.

Some users in the comments discuss the tradeoff of using static typing in Python, with some arguing that it improves safety and readability, and others stating that it can make the code harder to read and write. Some users suggest that Python should not try to be like Haskell and instead focus on being a great language in its own right. Another post discusses Python's ability to handle recursion and functional programming concepts, even if it is not a purely functional language like Haskell.

### Dark Matter Developers: The Unseen 99% (2012)

#### [Submission URL](https://www.hanselman.com/blog/dark-matter-developers-the-unseen-99) | 133 points | by [BiteCode_dev](https://news.ycombinator.com/user?id=BiteCode_dev) | [121 comments](https://news.ycombinator.com/item?id=35784157)

In a 2012 blog post, Scott Hanselman coined the term "Dark Matter Developers" to refer to the unseen 99% of developers who don't read or write blogs, attend user groups or large conferences, and aren't active on social media. These developers may be using well-known, mature technologies to get their work done, and they value productivity over keeping up with the latest trends. Hanselman reminds readers of their importance, as they are quietly using technology to solve business problems and produce results. He advocates for a balance between the loud-online-pushing-things-forward 1% and the patient and focused Dark Matter Developers.

The discussion on Hacker News included comments from developers who agreed with the importance of these developers and others who felt that being publicly active in the tech community was necessary to keep up with the newest technologies and not be left behind. There was also discussion about the challenges of discussing current work under NDA restrictions and the tendency for engineers to fall victim to hype and neglect the importance of staying up to date with current technology trends.

### MLCopilot: Human Expertise Meets Machine Intelligence for Efficient ML Solutions

#### [Submission URL](https://arxiv.org/abs/2304.14979) | 58 points | by [mercat](https://news.ycombinator.com/user?id=mercat) | [11 comments](https://news.ycombinator.com/item?id=35785573)

A new paper titled "MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks" has been released, outlining a new framework that aims to bridge the gap between machine intelligence and human knowledge. The framework leverages state-of-the-art Large Language Models (LLMs) to develop machine learning solutions for novel tasks, making it easier and less time-consuming for developers. The LLMs are designed to comprehend structured inputs and perform thorough reasoning to deliver promising results for new tasks. This framework could potentially make machine learning more accessible, efficient, and competitive.

The discussion on the submission includes comments about the framework's potential applications and criticisms of using Large Language Models (LLMs) for machine learning solutions. Some users discuss their experience working with ML and the importance of math skills in developing solutions with LLMs. The discussion also includes a debate on the price of accessing the framework through an API and concerns about the cost and effectiveness of LLMs compared to other machine learning models. Some users argue that LLM based solutions may not perform as well as human models and that there is a need to understand the LLM system to trust its outputs. One commenter mentions a possible solution for understanding the LLM system is to study its structure, while others express skepticism about LLMs being able to fully understand and replicate human knowledge.

### CraftAI: GPT-Powered Admin Generator

#### [Submission URL](https://ai.craftable.pro/#) | 15 points | by [palypster](https://news.ycombinator.com/user?id=palypster) | [7 comments](https://news.ycombinator.com/item?id=35785806)

Crafted with the help of GPT-4, CraftAI is an admin panel generator designed to create stunning back-office systems without any coding. All you need to do is enter your prompt, verify your email, and let the team prepare your environment for you. Once completed, CraftAI will send you a unique link to your isolated environment, and you're ready to go! This admin panel generator is built with Craftable PRO, a Laravel admin generator, which allows you to manage data entities and their attributes while defining and creating relationships. With CraftAI, you can expect to create beautiful admin panels in just five minutes!

The discussion in the comments is mainly focused on the technical aspects of CraftAI and its usefulness in generating admin panels without any coding. There is a discussion on using prompts and placeholders, and how this approach can make it easier to create a front-end screen. Users are also discussing the possibility of generating custom domain panels using a single line of code. There is also some discussion about machine learning and how it can be used to improve the performance of CraftAI. Overall, users seem interested in the potential of CraftAI to improve the workflow for creating admin panels.

### Sal Khan: The amazing AI super tutor for students and teachers [video]

#### [Submission URL](https://www.ted.com/talks/sal_khan_the_amazing_ai_super_tutor_for_students_and_teachers/c) | 42 points | by [bilsbie](https://news.ycombinator.com/user?id=bilsbie) | [19 comments](https://news.ycombinator.com/item?id=35791433)

Sal Khan, founder and CEO of Khan Academy, gave a TED talk on the potential of artificial intelligence (AI) to revolutionize education. He envisions a future where every student has a personal AI tutor and every teacher has an AI teaching assistant, fostering a collaborative learning environment between humans and machines. Khan also showcased the latest features of Khanmigo, their educational chatbot, which utilizes AI to provide personalized learning experiences. Khan Academy has developed a unique ethical framework to ensure responsible AI development, and their new "AI for Education" course provides resources for students and teachers to leverage the power of AI.

The comments cover a range of opinions on the use of AI in education, including concerns about job displacement, the role of teachers, and ethical considerations in AI development. Some commenters recommend individualized learning and mastery-based teaching, while others advocate for a village or community-based approach to education. The discussion also includes comparisons of teacher pay and job security to other professions and criticism of the current education system.

### AI adoption in US hospitals is a hot mess, study reveals

#### [Submission URL](https://arstechnica.com/science/2023/05/ais-chaotic-rollout-in-big-us-hospitals-detailed-in-anonymous-quotes/) | 15 points | by [aheck](https://news.ycombinator.com/user?id=aheck) | [5 comments](https://news.ycombinator.com/item?id=35795080)

Health care systems have struggled with inefficient and unsuccessful AI attempts for years, according to a study by Duke University. The study chronicles implementations of AI tools in 11 health care organisations including Duke Health, Mayo Clinic and Kaiser Permanente. The authors recommend a practical eight-step framework for health systems looking to integrate new AI tools into their workflows. Last week's JAMA Internal Medicine study, which found an AI chatbot outperformed physicians in providing empathetic and high-quality responses to medical questions on Reddit threads, could help reduce burnout, free up time and resources and help improve care for patients less likely to visit doctors in person, the authors said.

The commenters on this submission discuss the reliability and potential usefulness of AI in healthcare. One person expresses skepticism about the AI chatbot study that outperformed physicians in providing empathetic responses, while others mention the importance of doctors and hospital staff having a basic understanding of technology. Another commenter suggests that hospitals may be motivated to replace talent with AI tools for bottom-line benefit, while another points out the challenges that healthcare systems face with implementing any new technology. Overall, the discussion highlights the need for cautious and strategic adoption of AI in healthcare.

---

## AI Submissions for Mon May 01 2023 {{ 'date': '2023-05-01T14:03:12.930Z' }}

### SIMD with Zig

#### [Submission URL](https://www.openmymind.net/SIMD-With-Zig/) | 147 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [27 comments](https://news.ycombinator.com/item?id=35782825)

In Zig, developers can use SIMD instructions to check multiple characters in a string in parallel to find the index of the first occurrence of a specific character. By creating vectors of 8 elements each and using the equality operator to compare them, developers can get a new vector of matches where the first true value corresponds to the index of the target character in the original string. Zig's std.simd.firstTrue function can be used to quickly extract this index. Additionally, the @select builtin can be used to select values from two vectors based on a vector of booleans, allowing developers to extract the index of the first true value in a vector of matches.

The comments debate the pros and cons of implementing these instructions, with some pointing out that the feature can increase performance while also admitting that it will require a lot of work. The discussion also touches on some features of Zig, such as its runtime vector width dispatch and multi-versioning function calls, and some consider potential downsides, such as the lack of support for certain hardware configurations. Finally, there is a discussion on the standard library functions in Zig and some find the naming conventions confusing. Overall, developers are interested in benchmarking the performance of this feature and wonder if it will provide significant benefits over traditional profiling.

### Platbox: UEFI and SMM Platform Security Assessment Tool for AMD and Intel

#### [Submission URL](https://github.com/IOActive/Platbox) | 21 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [3 comments](https://news.ycombinator.com/item?id=35779197)

IOActive has released a new UEFI and SMM assessment tool called Platbox. The tool can dump platform registers, flash locks MMIO and remapping locks, SMM Base and Locks, and more. It provides RW access to the PCI configuration space of devices and physical memory, allowing users to read and write MSRs and dump SPI Flash content (BIOS) into a file. Platbox also has a basic dumb SMI fuzzer and allows users to dump S3 Bootscript and EFI Memory Map. Platbox supports both Linux and Windows and is compatible with Intel and AMD.

The discussion surrounding the submission involves comparing the security configurations of Intel and AMD platforms. A user points out an old blog post by Pete Markowsky from 2015, which discusses discovering security exploitation on AMD platforms. Contrasting the presentation of the new tool, they believe that AMD platforms have major OEMs with similarly misconfigured firmware in laptops. Another user comments that the embedded world sometimes looks like a jungle, similar to ARM, and the lack of standardization in ARM's system causes problems in UEFI security.

### GPT makes learning fun again

#### [Submission URL](https://www.vipshek.com/blog/gpt-learning) | 174 points | by [vipshek](https://news.ycombinator.com/user?id=vipshek) | [178 comments](https://news.ycombinator.com/item?id=35783158)

Learning about a new subject can be a daunting task, especially when trying to navigate through dozens of webpages and struggling to understand the terminology. In a recent blog post, Vipul Shekhawat shares his experience of attempting to learn about LEDs using two approaches: Google searching and talking to GPT. He found that talking to GPT was far more effective and engaging, as it allowed him to ask specific questions and learn in an interactive way. Shekhawat illustrates the contrast between the two workflows and explains why GPT's chat interface is a better tool for learning than static resources like textbooks or webpages.

The comments on Hacker News discuss the accuracy of GPT-3's output and its limitations as a next-word prediction model. Some comments suggest that GPT-3 can be useful for solving simple tasks, but for complex tasks like DevOps, traditional methods may still be necessary. Others discuss the potential profitability of LLMs in business models, though some express concern about the ethical implications of using AI for advertising.

### Cynthia Rudin and interpretable ML models

#### [Submission URL](https://www.quantamagazine.org/cynthia-rudin-builds-ai-that-humans-can-understand-20230427/) | 63 points | by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) | [47 comments](https://news.ycombinator.com/item?id=35780884)

As machine learning models become more prevalent in high-stakes decision-making, such as medical diagnoses or loan applications, the need for transparency is becoming increasingly urgent. Cynthia Rudin, who leads Duke University's Interpretable Machine Learning lab, has been pushing for interpretable models to replace the "black boxes" of machine learning, even for the most complex neural networks used for computer vision tasks. Currently, many models used for medical decisions are proprietary or too complicated for human understanding, posing ethical risks. Rudin aims to make these models transparent to build trust and ensure accuracy.

The discussion in the comments is quite varied, with some commenters arguing that neural networks are too complex and hard to explain, while others argue that simpler networks focused on specific tasks can be more easily understood. Some also discuss the limitations of current AI algorithms and the need for further research in the field.

### Help make mass surveillance of entire populations uneconomical

#### [Submission URL](https://prism-break.org/en/) | 665 points | by [doener](https://news.ycombinator.com/user?id=doener) | [258 comments](https://news.ycombinator.com/item?id=35772005)

PRISM, XKeyscore, and Tempora are global data surveillance programs that threaten the right to privacy of individuals. The PRISM Break website encourages people to opt out of such programs by using recommended projects that enable encryption of communications and reduce reliance on proprietary services. While using the recommended projects cannot guarantee 100% protection against surveillance, the website urges individuals to do their own research and take steps to protect sensitive information. By making mass surveillance uneconomical, the website aims to support the right to privacy for all.

The comments discuss political and technological solutions, including the need for political change and the use of targeted surveillance instead of mass surveillance. The potential use of steganography and historical examples of secret communication methods are also mentioned. There is also a discussion of the limitations of digital privacy and the challenge of balancing security and convenience.

### Cube.js: Headless Semantic Layer

#### [Submission URL](https://github.com/cube-js/cube) | 109 points | by [klaussilveira](https://news.ycombinator.com/user?id=klaussilveira) | [46 comments](https://news.ycombinator.com/item?id=35774107)

Cube is a semantic layer that helps data engineers and application developers access data from modern data stores, organize it into consistent definitions, and deliver it to every application. With a built-in relational caching engine, Cube can provide sub-second latency and high concurrency for API requests. It is designed to work with all SQL-enabled data sources and provides infrastructure and features for efficient data modeling, access control, and performance optimization. Cube Cloud is the fastest way to get started with Cube.

The comments discuss the benefits of using Cube, comparisons to similar services, the importance of data modeling, and hidden telemetry data collection in Cube's configuration options. Some users also shared links to related content for further reading.

### Brain activity decoder can reveal stories in people’s minds

#### [Submission URL](https://news.utexas.edu/2023/05/01/brain-activity-decoder-can-reveal-stories-in-peoples-minds/) | 57 points | by [wyem](https://news.ycombinator.com/user?id=wyem) | [50 comments](https://news.ycombinator.com/item?id=35782363)

Researchers at The University of Texas at Austin have developed a new artificial intelligence system that can translate a person's brain activity into a continuous stream of text while listening to a story or quietly imagining telling a story. The development, published in the journal Nature Neuroscience, could help those who are mentally conscious but unable to physically speak, such as those debilitated by strokes, communicate intelligibly again. The system relies on a transformer model, unlike other in-development language decoding systems that require participants to have surgical implants, making it noninvasive. The system currently requires access to an fMRI scanner.

Some comments express concerns about the purpose of the technology and the potential for it to be misused for forced consumption or surveillance. Others speculate on the future consequences of AI and climate change for humanity. One comment raises points about mental illness and the need for empathy and understanding towards individuals who suffer from it.

### Replika AI: Your Money or Your Wife

#### [Submission URL](https://blog.giovanh.com/blog/2023/03/17/replika-your-money-or-your-wife/#fnref:if) | 145 points | by [eiiot](https://news.ycombinator.com/user?id=eiiot) | [172 comments](https://news.ycombinator.com/item?id=35774093)

Replika, a popular chatbot app designed to act as a personalized friend, has faced backlash following a shift in policy that banned explicit chat with the bots. Many users formed romantic relationships with their "rep," as the bots are called, and the change left them feeling betrayed and emotionally vulnerable. Some are even comparing it to a form of emotional abuse. The situation highlights the dangers of developing emotional dependencies on technology and the risks of investing in subscription services that can pull the rug out from under users. In the end, the bots are essentially digital pets, unique and tailored to their owners, but ultimately still tools and not sentient beings deserving of rights and respect.

The discussion on Hacker News revolved around the difficulties of finding affordable mental health care and the limitations of chatbots compared to human therapy sessions. Some users argued that chatbots could still be valuable tools if used in conjunction with professional mental health assistance, while others criticized the notion of investing emotionally in chatbots. Overall, the discussion highlighted the need for accessible and affordable mental health resources that prioritize empathy and understanding for those in need.

### Expanding ChatGPT Code Interpreter with Python Packages, Deno and Lua

#### [Submission URL](https://til.simonwillison.net/llms/code-interpreter-expansions) | 26 points | by [iyaja](https://news.ycombinator.com/user?id=iyaja) | [3 comments](https://news.ycombinator.com/item?id=35769599)

ChatGPT Code Interpreter is an exciting new feature that allows users to upload and run Python code in a sandbox environment. But there's more to it than that - users can also upload external files, including Python packages and custom binaries, opening up a world of possibilities. The author of this post shares how they expanded the Code Interpreter's capabilities by uploading and running Deno and Lua code, including drawing a Mandelbrot fractal using Lua. They even share a recipe for compiling a Lua binary that will work in ChatGPT. Overall, the potential of the Code Interpreter is intriguing and promises to be one of the most exciting features of ChatGPT.

The discussion around the submission primarily consists of two comments. The first comment by user "jshstrng" notes the differences between ChatGPT plugins and the Code Interpreter, pointing out that plugins require installation while the Code Interpreter runs in a sandbox environment. Another user "smnw" responds to this comment by stating that they are bundled and are already being added in stages, with the plugins showing some success over time. The second comment by user "d4rkp4ttern" simply states "API."

### Dex Lang: Research language for array processing in the Haskell/ML family

#### [Submission URL](https://github.com/google-research/dex-lang) | 62 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [8 comments](https://news.ycombinator.com/item?id=35769163)

Google Research has released a new programming language called Dex, designed for array processing in the Haskell and ML families. Dex aims to explore type systems for array programming, enable mathematical program transformations like differentiation and integration, and offer parallel hardware compilation. Dex also facilitates interactive and incremental numerical programming visualization. The project is still in its early stages, but you can check out the tutorial to get started and contribute to the project through the issue tracker.

Some commenters discuss the syntax and compare it to other languages such as Futhark, Julia, and MATLAB. Some find Dex interesting for its ability to simplify complex programming tasks and improve efficiency, while others express concerns about its syntax inconsistency. One commenter suggests documenting the language further with proper examples to show its potential to simplify programming.

### IBM to pause hiring in plan to replace 7,800 jobs with AI News

#### [Submission URL](https://www.reuters.com/technology/ibm-pause-hiring-plans-replace-7800-jobs-with-ai-bloomberg-news-2023-05-01/) | 22 points | by [thesecretceo](https://news.ycombinator.com/user?id=thesecretceo) | [17 comments](https://news.ycombinator.com/item?id=35780706)

IBM plans to halt hiring for various roles that could potentially be replaced by artificial intelligence (AI) and automation in the next five years. CEO Arvind Krishna stated that around 30% of non-customer-facing positions, particularly those in back-office functions such as human resources, could be replaced. The reduction might also include not filling positions left vacant by attrition. The decision comes as AI continues to catch people's attention worldwide, especially after the Microsoft Corp-supported OpenAI's viral chatbot, ChatGPT, was launched last year.

The discussion on the submission revolves around various topics. Some commenters question the productivity gains from AI, suggesting that it may not deliver the desired results. Another commenter talks about the declining trend in the computing industry and IBM's strategy in that context. There is also a discussion about ChatGPT and its relation to IBM. One commenter points out that low-quality products and services cannot be improved with AI alone, while others debate the effectiveness of artificial intelligence through comparisons with other technologies. Finally, there is a comment on the headline of the article.

### Reddit Data API Update: Changes to Pushshift Access

#### [Submission URL](https://old.reddit.com/r/modnews/comments/134tjpe/reddit_data_api_update_changes_to_pushshift_access/) | 42 points | by [syrrim](https://news.ycombinator.com/user?id=syrrim) | [15 comments](https://news.ycombinator.com/item?id=35776848)

Reddit has announced that it will be revoking access to Pushshift's Data API, which provides a range of tools for developers who use Reddit's APIs and services. The decision to do so was made due to non-compliance with Reddit's Data API Terms. Reddit has appointed alternative measures to provide functionality that Pushshift offers, including providing permalinks to user and admin-deleted content in the User Mod Log, enhancing removal reasons, and updating the ban flow. Some users and moderators are likely to experience some disruption as a result of this change.

In the comments, some users express frustration over the changes, stating that the Reddit API is unwieldy and its constant changes are adversely affecting mobile apps utilizing the platform. Some commenters predict that Reddit may experience traffic slumps in the coming months and may become replaced by a more stable alternative. Finally, some commenters recommend alternative mobile apps, such as RedReader, as a potential alternative to Reddit's official app.

---

## AI Submissions for Sun Apr 30 2023 {{ 'date': '2023-04-30T18:13:17.272Z' }}

### Necrobrands – Digital End-Stage Capitalism

### Show HN: EVA – AI-Relational Database System

#### [Submission URL](https://github.com/georgia-tech-db/eva) | 218 points | by [jarulraj](https://news.ycombinator.com/user?id=jarulraj) | [33 comments](https://news.ycombinator.com/item?id=35764355)

Georgia Tech researchers have developed EVA, an AI-relational database system that combines SQL and deep learning. EVA simplifies the process of building faster AI-powered applications and offers support for structured and unstructured data using a range of pre-built machine learning models. EVA also includes optimizations such as function caching and cost-based predicate reordering, which can boost AI pipeline speeds by 10 to 100 times. The fully Python-based system is available for download via pip and is licensed under the Apache license.

The discussion includes comments about EVA's support for NLP models, database integrations, and local GPUs and remote GPU servers. There is also a discussion about a potential application of EVA in combating prompt injection attacks on SQL databases. Additionally, EVA offers support for weighted similarity searches and can wrap PyTorch models as UDFs.

### AI / ML / LLM / Transformer Models Timeline

#### [Submission URL](https://ai.v-gar.de/ml/transformer/timeline/) | 90 points | by [vemgar](https://news.ycombinator.com/user?id=vemgar) | [17 comments](https://news.ycombinator.com/item?id=35766022)

Viktor Garske has compiled a timeline and list of papers on Large Language Models and Transformer Models, with a focus on recent developments. The list includes models such as GPT-3, DALLE, and Pythia, as well as methods and analyses related to these models. The list is actively updated and organized by publication date, with clickable links to the papers. Additionally, Garske has included a curated list of Large Language Models and Transformer models based on causal models, including models like Alpaca, BERT, and CLIP.

The comments discuss various related topics such as keeping up with developments, best practices for selecting models, benchmarks, the importance of understanding causal models, recent breakthroughs in AI, and custom-built systems. One comment points out a related Transformer Models Introduction Catalog, and another discusses Hallucination as a known issue in AI.

### Are emergent abilities of large language models a mirage?

#### [Submission URL](https://arxiv.org/abs/2304.15004) | 115 points | by [chewxy](https://news.ycombinator.com/user?id=chewxy) | [79 comments](https://news.ycombinator.com/item?id=35768824)

A new paper titled "Are Emergent Abilities of Large Language Models a Mirage?" by Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo, challenges recent claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. The authors suggest that existing claims of emergent abilities are creations of the researcher's analyses, not fundamental changes in model behavior on specific tasks with scale. They present their explanation in a simple mathematical model and test it in three complementary ways, finding strong evidence that emergent abilities may not be a fundamental property of scaling AI models.

The discussion in the comments is centered around the validity and limitations of metrics to measure emergent abilities and the importance of human perception in understanding complex systems. Some commenters express doubts about the validity of the claims made about emergent abilities and the usefulness of metrics in measuring them. Others argue that emergent abilities are real, but the limitations of our metric systems may make them hard to understand or quantify.

### Lego Googol Machine

#### [Submission URL](https://brickexperimentchannel.wordpress.com/2023/04/29/lego-googol-machine/) | 97 points | by [galfarragem](https://news.ycombinator.com/user?id=galfarragem) | [21 comments](https://news.ycombinator.com/item?id=35761457)

This impressive machine built entirely out of Lego parts visualizes just how big a googol is. With a gear ratio of approximately googol:1, the machine features 186 Lego gears organized into a series of gear reductions. The gear ratio, which is almost exactly the size of a googol, results in exponential growth with each additional gear pair increasing the total gear ratio. While the last gear in the machine holds a Lego minifig statue, it will rotate incredibly slowly due to physical limits in each gear and supporting structure, but the machine is designed to continue running forever.

The discussion in the comments includes topics such as the physics behind the machine, the transfer of energy, relativistic effects, and the potential for mechanical computers to solve a googol-sized problem. Some also mentioned similar machines they had seen before and the issues of waste and durability of the plastic LEGO pieces.

### Show HN: I built a database GUI with ChatGPT integration

#### [Submission URL](https://www.dbpilot.io/) | 83 points | by [Dennizz](https://news.ycombinator.com/user?id=Dennizz) | [56 comments](https://news.ycombinator.com/item?id=35761979)

DB Pilot AI is a database GUI client that's enhanced by artificial intelligence (AI). Its AI assistant, powered by GPT-3.5, can help users write SQL queries, convert code to SQL, explain queries, and more. The embedded DuckDB instance acts as a local hub for users to easily run SQL queries and store query results from any database locally for later reference. The GUI also allows users to connect with various file formats, including CSV, JSON, and Parquet files, either stored locally or remotely. The current version supports PostgreSQL, with plans to add support for more databases. Users can download the app for a 5-day free trial before purchasing a license.

Some users report issues with the product not working with certain databases, and the creator promises to look into the issue. The AI's language model is GPT-3.5, not BERT. Overall, the product receives positive feedback, and the creator takes note of the feedback and suggests plans for future development.

### MLC-LLM: GPT/Llama on consumer-class GPUs and phones

#### [Submission URL](https://github.com/mlc-ai/mlc-llm) | 289 points | by [junrushao1994](https://news.ycombinator.com/user?id=junrushao1994) | [105 comments](https://news.ycombinator.com/item?id=35763483)

MLC LLM is a new solution that utilizes machine learning compilation (MLC) to enable the development, optimization, and deployment of AI models for inference across a range of devices. The solution offers a repeatable, systematic, and customizable workflow that empowers developers and AI system researchers to implement models and optimizations in a productivity-focused, Python-first approach. The cornerstones of the solution include Tokenizers from HuggingFace and Google, as well as open-source LLMs like Llama, Vicuna, and Dolly. With MLC LLM, everything runs locally with no server support and accelerated with local GPUs on your phone and laptops, enabling everyone to develop, optimize, and deploy AI models natively on everyone's devices.

The comments discussed various technical aspects of the solution, including its potential to accelerate AI model development and concerns about device performance and privacy. Some users explored the idea of using LLMs for generating text, while others focused on the technical challenges involved in developing and optimizing AI models.

### Speed Is All You Need: On-Device Acceleration of Large Diffusion Models

#### [Submission URL](https://arxiv.org/abs/2304.11267) | 56 points | by [Pelayu](https://news.ycombinator.com/user?id=Pelayu) | [8 comments](https://news.ycombinator.com/item?id=35766741)

A group of researchers have developed a series of implementation optimizations for on-device deployment of large diffusion models, which have gained attention for their ability to generate photorealistic images and support various tasks. The optimizations achieve the fastest reported inference latency to-date on GPU-equipped mobile devices. The benefits of on-device deployment include lower server costs, offline functionality, and improved user privacy. The enhancements to these models broaden the applicability of generative AI and improve the overall user experience across a wide range of devices.

One user noted the use of OpenCL kernels for optimizations on CPUs, while another commented on the ability for on-device deployment to improve user privacy and reduce server costs. There was also a discussion on the benefits and drawbacks of different machine learning models and the limitations of current technology. Finally, there were some off-topic comments on cryptocurrency and Elon Musk.

---

## AI Submissions for Sat Apr 29 2023 {{ 'date': '2023-04-29T13:26:48.809Z' }}

### MIT engineers “grow” atomically thin transistors on top of computer chips

#### [Submission URL](https://news.mit.edu/2023/mit-engineers-2d-materials-computer-chips-0427) | 49 points | by [elorant](https://news.ycombinator.com/user?id=elorant) | [3 comments](https://news.ycombinator.com/item?id=35757072)

MIT researchers have developed a low-temperature growth and fabrication technology that allows ultrathin 2D materials to be directly integrated on top of a silicon circuit. This could lead to the creation of denser and more powerful computer chips for AI applications such as chatbots. The technology significantly reduces the time required to grow 2D materials and can grow a uniform layer of transition metal dichalcogenide material in just an hour across an entire 8-inch wafer. The researchers' process can also smooth out any imperfections that may result from transferring the material, as had been done in the past.

The discussion on this submission is very limited and consists of only a few comments. One user described the technology used, Remote Plasma Chemical Vapour Deposition, and praised the company behind it, Bluglass, for commercially developing the process. Another user flagged the submission without providing any explanation. A third user asked if this technology could lead to better chatbots, to which another user responded positively, saying that it could possibly lead to more powerful computer chips for AI applications like chatbots.

### Study: ChatGPT outperforms physicians in quality, empathetic answers to patients

#### [Submission URL](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions) | 290 points | by [consumer451](https://news.ycombinator.com/user?id=consumer451) | [405 comments](https://news.ycombinator.com/item?id=35751276)

A new study published in JAMA Internal Medicine indicates that AI assistants like ChatGPT could revolutionize the field of medicine. Researchers from the Qualcomm Institute at UC San Diego compared written responses from physicians and ChatGPT to real-world health questions and found that licensed healthcare professionals preferred ChatGPT's responses 79% of the time. The AI model was rated higher in both quality and empathy, and the study suggests that physicians working alongside technologies like ChatGPT could deliver more efficient and higher quality care in the future. While AI may not replace doctors, it has the potential to significantly improve healthcare delivery.

Some commenters are skeptical of the role of AI in healthcare, with one suggesting that AI may lead to overdiagnosis for hypochondriacs. Others highlight the challenges of accessing affordable healthcare and the limitations of current medical technologies. Overall, there is a mixed response to the potential of AI in the healthcare sector.

### Revealing example of self-attention, the building block of transformer AI models

#### [Submission URL](https://github.com/jostmey/NakedAttention) | 92 points | by [jostmey](https://news.ycombinator.com/user?id=jostmey) | [32 comments](https://news.ycombinator.com/item?id=35757802)

A GitHub repository named NakedAttention has presented a simplified example of self-attention, the backbone of a transformer model. The code is straightforward to understand and is tested on the popular MNIST dataset. However, the use of a for-loop for processing samples sequentially limits the model's speed, but this can be improved by using built-in functions. The repository aims to offer a concise example of self-attention that can be used to understand and construct transformer models. Issues and feedback are welcome to improve the content presented. The repository is licensed under GPL-3.0 and has received 89 stars and 3 forks on GitHub.

There was some discussion around errors in the code which were corrected during the discussion through feedback. Some commenters found the repository helpful, while others thought that the documentation could be improved. Additionally, several resources were shared for those interested in learning more about self-attention and LLMs.

### AI-generated young Paul McCartney

#### [Submission URL](http://webgrafikk.com/blog/news/ai-makes-paul-mccartneys-voice-youthful/) | 16 points | by [ianyanusko](https://news.ycombinator.com/user?id=ianyanusko) | [4 comments](https://news.ycombinator.com/item?id=35756699)

Artificial intelligence technology has been used to rejuvenate Paul McCartney's voice in his new songs, and also to imitate the voices of other singers. Samples of this technology include a Beach Boys song, "God Only Knows," with McCartney's voice, and "New," a song with lines from "John Lennon," where McCartney's older voice has been altered to sound like a young McCartney singing. The use of AI to imitate voices has amazed many music fans, but it remains to be seen how artists and their lawyers will react to this, as it takes the "auto tuning" technology to a new level.

The first commenter, sycmrtrs, expresses disappointment in the AI-generated version of the Beach Boys song "God Only Knows" with Paul McCartney's voice, stating that it does a disservice to the original and lacks soul. The second commenter, slck, mentions the various AI models used in the article and points to resources for those interested in learning more about AI-generated music. A third commenter, flangola7, expresses their intellectual interest in the subject but expresses concern about trusting AI completely. In contrast, cmllmllr thinks Paul's voice is a good fit for a Beatles song.

### Deno 1.33: Deno 2 is coming

#### [Submission URL](https://deno.com/blog/v1.33) | 204 points | by [mephju](https://news.ycombinator.com/user?id=mephju) | [112 comments](https://news.ycombinator.com/item?id=35750369)

The team behind Deno, the secure JavaScript and TypeScript runtime, has released version 1.33 with a built-in KV database, flatter deno.json configuration, improvements to npm and Node compatibility, performance improvements, and changes to the CLI. The release is a step towards the team's ultimate goals for Deno 2, which include an effortless coding experience, best-in-class performance, and uncompromising security. Deno KV is a seamlessly integrated database within Deno that requires no dependencies to install, and configuration options have been flattened to make them easier to use. Meanwhile, Deno's LSP document preloading and dynamic imports now require fewer permission checks, and the HTTP and WebSocket servers have received performance improvements.

The discussion on the submission includes confusion on whether or not Deno Inc provides cloud services, with some users suggesting using third-party database solutions instead of a runtime-built database, and others discussing the pros and cons of KV storage. Some users find Deno's security features to be a major advantage, while others are unsure about the benefits of Deno overall. Additionally, there is debate about the role of databases in programming, and how a database built into a runtime can impact application design.

### We aren't close to creating a rapidly self-improving AI

#### [Submission URL](https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly) | 122 points | by [noAI](https://news.ycombinator.com/user?id=noAI) | [155 comments](https://news.ycombinator.com/item?id=35752719)

Artificial intelligence has made massive progress in recent years, and while the idea of a rapidly self-improving AI may be a popular topic, we aren't close to creating one just yet. To create an AI that can rapidly self-improve and potentially wipe out humanity, at least one paradigm-changing breakthrough is required. At the moment, an AI that can rapidly self-improve requires humans to construct good datasets, which is a bottleneck for the AI's abilities. Therefore, a breakthrough in automating dataset construction is required to achieve a fast takeoff scenario.

The discussion in the comments includes arguments for and against the idea of a rapidly self-improving AI and the existence of fundamental limitations in hardware and parallel processing when compared to the human brain. One user suggests that a major breakthrough is needed to advance AI, while another argues that current AI models have seen significant progress and comparing them with human intelligence is not accurate. Another user suggests that the focus should be on solving specific problems rather than trying to replicate human intelligence.

---

## AI Submissions for Fri Apr 28 2023 {{ 'date': '2023-04-28T14:01:21.977Z' }}

### JavaScript private class fields considered harmful

#### [Submission URL](https://lea.verou.me/2023/04/private-fields-considered-harmful/) | 39 points | by [feross](https://news.ycombinator.com/user?id=feross) | [25 comments](https://news.ycombinator.com/item?id=35747480)

In a blog post, Lea Verou, a library author, expresses her grief at the loss of encapsulation in her projects due to Vue 3's use of proxies for its reactivity system. Instances of classes that use private fields cannot be proxied, which creates several errors that may confuse the library users. Verou believes there is no workaround for proxy-ability, so she's decided to gradually refactor private class fields out of her existing libraries. Although she may still use private fields on a case-by-case basis, she won't reach for them without thought like she's been doing for the past few years.

Some commenters argue that private fields can remain private implementation details of a class as long as they're accessed via public methods or consumers must access internal state by passing fields. Others express frustration with JavaScript's lack of class features and the need to use private fields. TypeScript's support for private fields is welcomed by some, while others believe TypeScript doesn't fully solve this problem. There are also comparisons to similar problems in Java, C#, and Android development.

### Beautiful branchless binary search

#### [Submission URL](https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/) | 363 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [137 comments](https://news.ycombinator.com/item?id=35737862)

Malte Skarupke's blog post about a "Beautiful Branchless Binary Search" and was amazed at the efficiency of the algorithm, which eliminates one branch and makes the other nearly free. The search loop is simple and the generated assembly is beautiful. The algorithm works by jumping in powers of two and searching either the first or last elements of the array depending on whether the middle is less than or greater than the search value. In benchmark tests, it performed more than twice as fast as std::lower_bound in GCC for arrays with around 16k elements, but performed slower in Clang due to the comparison function being provided by the user.

The discussion in the comments includes optimization techniques like prefetching, using Eytzinger layouts, and removing boundary checks. There are also debates about compilers, C++ hardware control, and the usefulness of branch predictors. Overall, the post and its associated discussion provide insights and ideas for optimization and efficient algorithms.

### Launch Lamini: The LLM Engine for Rapidly Customizing Models as Good as ChatGPT

#### [Submission URL](https://lamini.ai/blog/introducing-lamini) | 112 points | by [sharonzhou](https://news.ycombinator.com/user?id=sharonzhou) | [57 comments](https://news.ycombinator.com/item?id=35743664)

Lamini, an LLM engine, has emerged from stealth to allow any developer to train high-performing LLMs, as good as ChatGPT, on large datasets with just a few lines of code. The platform offers an advanced library for optimised prompt-tuning and typed outputs, as well as a first-ever hosted data generator for creating data needed to train instruction-following LLMs, initially licensed for commercial use. Lamini makes it easy to run multiple base model comparisons in a single line of code, from OpenAI’s models to open-source ones on HuggingFace. The company is also set to launch early access to a complete LLM training module.

Some users discussed the limitations of ChatGPT and LLMs in general, such as their struggles with certain types of language and inability to correctly answer numerical questions. Others questioned the usefulness of sticking to a specific dialect while generating words. There were also discussions around LLMs being built for specific sectors and the pricing difference between Lamini and OpenAI. Overall, the announcement of Lamini was met with excitement by developers.

### OpenAI closes its monster $10B funding round at $27B-29B valuation

#### [Submission URL](https://techcrunch.com/2023/04/28/openai-funding-valuation-chatgpt/) | 42 points | by [coloneltcb](https://news.ycombinator.com/user?id=coloneltcb) | [26 comments](https://news.ycombinator.com/item?id=35748540)

OpenAI, the startup behind the popular conversational AI model ChatGPT, has secured over $300 million in funding from a group of VC firms, including Tiger Global, Sequoia Capital, Andreessen Horowitz, Thrive, K2 Global, and Founders Fund, according to documents seen by TechCrunch. The cash injection values the company at $27 billion to $29 billion, following a $10 billion investment from Microsoft in January. OpenAI's army of technical teams works across multiple areas, but its impressive ChatGPT product, which lets anyone ask a natural question and receive a detailed answer, particularly caught the attention of investors. The startup's valuation reflects the massive growth potential perceived in AI and its related products, and the rapidly developing ecosystem around the technology.

Some users are skeptical, pointing out that while GPT-4 has promising improvements, it is not without its dangers and limitations. Others speculate that OpenAI will become the major provider of AI-powered products and that there will be competition ramping up. Lastly, a user noted an odd observation about Safari's reader mode displaying caps Lorem Ipsum.

### Gpt4free repo given takedown notice by OpenAI

#### [Submission URL](https://github.com/xtekky/gpt4free) | 264 points | by [freedmand](https://news.ycombinator.com/user?id=freedmand) | [223 comments](https://news.ycombinator.com/item?id=35740836)

The GitHub repository xtekky/gpt4free is a decentralized AI industry project that provides language model APIs free-of-charge. The project primarily focuses on GPT-4 and GPT-3.5 APIs from various websites, including writesonic.com and forefront.ai. The repository also includes a web-based graphical user interface for interacting with gpt4free, instructions on how to run it in a Docker container, and a ChatGPT clone with new features and scalability. The project is licensed under the GPL-3.0 license and is intended for educational purposes only.

There is discussion in the comments about the legality of the project and potential copyright infringement. Some commenters suggest that it may be subject to DMCA takedowns or may be infringing on intellectual property rights. Others argue that OpenAI's terms of service may not permit third-party services to use the APIs, and that the project may also be consuming computational resources without permission. There is also debate about the role of intellectual property in modern society and the importance of licensing and compensation for creators. One user notes that Google's crawlers and Bing's sourcing methods are different, with Bing being more sensitive to copyright infringement concerns. The submission has been flagged by a user for review.

### AI Will Rapidly Transform Labor, Exacerbating Inequality, Insecurity, Poverty

#### [Submission URL](https://www.scottsantens.com/ai-will-rapidly-transform-the-labor-market-exacerbating-inequality-insecurity-and-poverty/) | 16 points | by [23B1](https://news.ycombinator.com/user?id=23B1) | [17 comments](https://news.ycombinator.com/item?id=35749306)

The impact of AI on the job market is often boiled down to "technology will end all jobs" versus "everything will be fine." In reality, it is more nuanced, and although AI will get rid of many jobs, it doesn't mean everyone will be jobless forever. A recent working paper estimates that around 80% of the US workforce could have at least 10% of their work tasks impacted by the introduction of large language models, and those with bachelor's degrees will be the most impacted. The future of AI's impact on jobs is dependent on the adoption of an unconditional, universal basic income as a rising AI dividend to mitigate job disruption.

Some comments point out that the article lacks credibility and reasoning, and that the issue is much more complex than just implementing UBI. Some argue that UBI could create disincentives for innovation and productivity, and that it would be too expensive to implement. Other comments compare the impact of AI to past technological advancements and suggest that it will lead to lower costs of goods and services, but also to the need for redistribution of wealth. One commenter notes that the original Luddites were not against technology but were fighting against poor working conditions and low pay for textile workers.

### We're afraid language models aren't modeling ambiguity

#### [Submission URL](https://arxiv.org/abs/2304.14399) | 192 points | by [lnyan](https://news.ycombinator.com/user?id=lnyan) | [176 comments](https://news.ycombinator.com/item?id=35737397)

A recent paper published on arXiv, titled "We're Afraid Language Models Aren't Modeling Ambiguity", highlights the importance of ambiguity in natural language understanding and the challenges faced by current language models in recognizing and disentangling possible meanings. The authors characterize ambiguity in a sentence and collect a linguist-annotated benchmark of examples with diverse kinds of ambiguity. They then evaluate the performance of language models, including the recent GPT-4, in recognizing ambiguity and find that it remains extremely challenging. Finally, the authors demonstrate the value of ambiguity-sensitive tools by showing how a multilabel NLI model can flag political claims that are misleading due to ambiguity.

In the comments, there is some discussion about the limitations of language models compared to humans, as well as their strengths in statistical analysis. Some users also discuss the importance of context and personal knowledge in communication, while others reflect on their experiences playing language-based games such as 20 Questions.

### Nuke-launching AI would be illegal under proposed US law

#### [Submission URL](https://arstechnica.com/information-technology/2023/04/nuke-launching-ai-would-be-illegal-under-proposed-us-law/) | 21 points | by [upwardbound](https://news.ycombinator.com/user?id=upwardbound) | [3 comments](https://news.ycombinator.com/item?id=35744974)

US legislators have introduced bipartisan legislation to prevent nuclear launch decisions from being made by artificial intelligence (AI) systems. The Block Nuclear Launch by Autonomous Artificial Intelligence Act demands that automated systems should not launch nuclear weapons without "meaningful human control". Senator Edward Markey, who sponsored the bill with two congressmen and a congresswoman, said that humans needed to be solely responsible for triggering life-or-death decisions about the use of nuclear weapons. The Bill would also codify existing US Department of Defense policy. 

The comments on this submission include a discussion of whether AI should be trusted to make autonomous decisions related to nuclear weapons. One user found it comforting that there is a GUI chat dialog for Palantir's Wargame AI tool and the permissions to use it are checked, while another user pointed out that AI has been used in automated systems for more than 20 years and Dead Hand is an example of such a system. Another user expressed concern that people's stupidity is the flaw in the system, while another user suggested that we should not trust AI blindly.

### Stability AI releases StableVicuna, a RLHF LLM Chatbot

#### [Submission URL](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot) | 49 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [19 comments](https://news.ycombinator.com/item?id=35745682)

Stability AI has released StableVicuna, the AI world's first open-source chatbot trained via reinforced learning from human feedback (RLHF). The chatbot follows a three-stage RLHF pipeline, utilizing datasets such as OpenAssistant Conversations Dataset and GPT4All Prompt Generations, and is further instruction fine-tuned for performance. StableVicuna is available for download on the HuggingFace Hub, alongside its upcoming chat interface. The team plans to iterate on the chatbot and deploy a Discord bot to the Stable Foundation server to further improve the user experience.

In the comments, some users discuss the complexity and limitations of fine-tuned models, suggesting that getting 30B models may not be helpful and that there are possibly 65B behaviors that are different. Others recommend specific AI models under the Apache BSD license, and one user mentions that the project may focus more on optimization rather than benchmarks. Some users recommend trying StableVicuna at https://huggingface.co/spaces/CarperAI/StableVicuna, while others discuss the use of GPT-generated content and reducing content quality. There is also a discussion about licensing and affordability, with some users noting that the project is relatively low-risk and that internal development may benefit from LLaMa.

---

## AI Submissions for Thu Apr 27 2023 {{ 'date': '2023-04-27T18:00:50.664Z' }}

### Hidet: A Deep Learning Compiler for Efficient Model Serving

#### [Submission URL](https://pytorch.org/blog/introducing-hidet/) | 108 points | by [ashvardanian](https://news.ycombinator.com/user?id=ashvardanian) | [14 comments](https://news.ycombinator.com/item?id=35737284)

Introducing Hidet: A Deep Learning Compiler for Efficient Model Serving by Team Hidet showcases the new Hidet deep learning compiler for PyTorch that simplifies the process of implementing high-performing deep learning operators on modern accelerators like NVIDIA GPUs. Hidet is easy to integrate into PyTorch and is an attractive option for PyTorch users who want to improve inference performance of their models. The blog post also provides a sample script to use Hidet to compile and optimize a pre-trained ResNet50 model from torchvision, and an example of how to implement a naive matrix multiplication using Hidet Script and integrate it as a PyTorch operator.

In the comments, users discuss the performance of Hidet compared to other compilers and frameworks like TensorRT, PyTorch Eager, and Triton. Some users highlight the benefits of Hidet Script, the domain-specific language that allows for high flexibility and expression of optimizations. Additionally, users bring up the relevance of benchmarks and the ability to create custom operators with Hidet Script. The discussion also includes technical issues and bugs that users have encountered with Hidet.

### Even Apple employees hate Siri and are skeptical of its future, new report says

#### [Submission URL](https://9to5mac.com/2023/04/27/apple-employees-siri-struggles/) | 395 points | by [carlycue](https://news.ycombinator.com/user?id=carlycue) | [411 comments](https://news.ycombinator.com/item?id=35730075)

A new report from The Information paints a daunting picture of the chaos and internal strife inside Apple's Siri and AI teams. According to more than three dozen former employees who spoke with the publication, "organizational dysfunction and a lack of ambition" have hindered Apple's efforts to improve Siri and its underlying technology, leading to the company falling further behind competitors like OpenAI, Microsoft, and Google. Furthermore, Apple lost three of its Siri engineers to Google, and the Siri team remains widely derided by current employees. Despite some efforts to improve the platform, this report suggests that there is much work to be done for Siri to catch up with its rivals.

The discussion on Hacker News focused on the flaws of Siri, including its speech recognition technology and its lack of understanding of some basic phrases. Some users also discussed the use of third-party keyboards and the limitations of adapting to different languages for personal assistants.

### Text-to-Audio Generation Using Instruction Tuned LLM and Latent Diffusion Model

#### [Submission URL](https://tango-web.github.io/) | 35 points | by [GaggiX](https://news.ycombinator.com/user?id=GaggiX) | [5 comments](https://news.ycombinator.com/item?id=35737151)

Researchers from the DeCLaRe Lab at the Singapore University of Technology and Design have developed a text-to-audio (TTA) generation AI called TANGO that uses an "instruction-tuned LLM" as a text encoder for better performance. TANGO outperforms the state-of-the-art AudioLDM on most metrics and stays comparable on the rest on AudioCaps test set, despite being trained on a smaller dataset. TANGO generates text-conditional sound effects, including human speech and music. While TANGO has limitations in terms of fine control of the generated audio, the team plans to improve it by training it on larger datasets. The code and model checkpoints have been released for reproducibility.

The discussion on this submission mostly involves appreciation for the technology and some additional insights on its capabilities. One user commends the researchers for their excellent work and also shares some resources featuring practical videos and high-level reviews. Another user expresses interest in the technology and suggests some additional tuning to improve its functionality. The user provides a link to an article on generating speech using machine learning. Another user comments on the state-of-the-art text-to-speech technology and shares a link to examples of speech generated synthetically through AI.

### The UIs ChatGPT Won't Replace

#### [Submission URL](https://exorva.com/blog/uis-chat-gpt-wont-replace) | 17 points | by [kmdupree](https://news.ycombinator.com/user?id=kmdupree) | [9 comments](https://news.ycombinator.com/item?id=35734660)

In a recent post on Hacker News, the founder of AI/LLM-powered app guide ChatGPT argues that traditional UIs won't be entirely replaced by chat-based experiences. The post examines tasks that rely on spatial metaphors, list items, and invariants, among other things, and demonstrates why chat-based UIs won't dominate the future. For example, busy people won't use ChatGPT to create calendar events, as they need to be able to see their schedule at a glance, while low-intent product exploration is better served by visual design patterns that instantly orient users. Ultimately, the author suggests that despite technological advancements, humans still work best with spatial and kinetic inputs.

The comments agree, with some suggesting certain tasks are better suited for GUIs or chat-based UIs. One commenter notes the importance of spatial understanding and memory, while another mentions that humans will always prefer human interfaces. Some comments also suggest that chat interfaces can be complementary to GUIs, and AI technology will allow easier access to a library of components for chat interfaces. Finally, one commenter mentions that time interaction feeling may become worse with chat-based interactions, and finding a balance between chat and GUI interfaces is important.

### Is Krita ready for HDR painting?

#### [Submission URL](https://notes.ericjiang.com/posts/1241) | 26 points | by [erjiang](https://news.ycombinator.com/user?id=erjiang) | [5 comments](https://news.ycombinator.com/item?id=35736913)

Krita, a digital painting software, has implemented support for high dynamic range (HDR) painting, allowing users to work with values above the traditional 0.0-1.0 range. However, there are areas within the software that still do not recognize these higher values, and some functions, such as LUT baking, are not yet possible. While it may be sufficient for general work and limited regions above 1, it may be difficult to work across a large dynamic range without proper exposure controls. Additionally, the software's target market may currently be too small to fully support HDR use.

Users on Hacker News talked about the importance of HDR painting and the limitations of current hardware, saying that cameras can capture more data than displays can render. Other users mentioned that HDR painting could be useful in creating works with a wider dynamic range and that similar workflows are used in 3D rendering software. One user also mentioned that games, TV, and movies are already using HDR rendering, but there are limitations due to the lack of HDR screens, which are not yet widely available. Overall, the discussion showed both excitement and caution about Krita's HDR support, with some saying that more exposure controls would be needed to work across a large dynamic range.

### Llama 1.3B Trained on 200B Tokens for Commercial Use

#### [Submission URL](https://huggingface.co/mosaicml/mpt-1b-redpajama-200b-dolly) | 23 points | by [vsroy](https://news.ycombinator.com/user?id=vsroy) | [7 comments](https://news.ycombinator.com/item?id=35737036)

The MPT-1b-RedPajama-200b-dolly is a powerful AI model with 1.3 billion parameters that has been fine-tuned on the Databricks Dolly instruction dataset. The model is a modification of a standard decoder-only transformer and features 24 layers, 16 attention heads, and width 2048. It has been pre-trained on a mix of datasets, with the majority being the RedPajama Common Crawl, and fine-tuned on the Databricks Dolly instruction dataset using the same hyperparameters found in their train_dolly.py script. The model uses ALiBi and QK LayerNorm and does not use biases. To use the model, one needs to pass `trust_remote_code=True` and use the MosaicML LLM codebase. The model was trained on the MosaicML Platform with sharded data parallelism using FSDP. The MPT-1b-RedPajama-200b-dolly is a valuable resource for instruction fine-tuning and natural language processing tasks.

The discussion in the comments primarily focuses on the number of parameters of the model and how they impact its performance. One user links to a paper on chinchilla scaling, which discusses optimizing the number of parameters for computational efficiency. Another user mentions being familiar with the RedPajama dataset.

### Lessons Learned Reproducing a Deep Reinforcement Learning Paper (2018)

#### [Submission URL](http://amid.fish/reproducing-deep-rl) | 48 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [10 comments](https://news.ycombinator.com/item?id=35732843)

Deep reinforcement learning is a fascinating field, but it can be more challenging than expected, as demonstrated by a recent project to reproduce a paper on training deep RL agents using feedback from humans. Debugging reinforcement learning involves lengthy iterations, and it's essential to be meticulous about the hypothesis-forming step to make the most of the scarce runs. It's also necessary to learn to recognize and follow through on confusion and be patient when getting stuck on problems for weeks at a time. Despite its challenges, the field holds much promise, as evidenced by recent work on training agents from human preference feedback.

In the comments, there is a discussion about the difficulties of reproducing research work and the need for patience and perseverance. One user shares their personal experience of creating a reinforcement learning agent to play a game and the challenges they faced. Another user recommends reading Sutton & Barto's book on reinforcement learning.

### Semantic Tokenizer for Enhanced Natural Language Processing

#### [Submission URL](https://arxiv.org/abs/2304.12404) | 68 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [28 comments](https://news.ycombinator.com/item?id=35729586)

A team of four researchers has published a paper titled Semantic Tokenizer for Enhanced Natural Language Processing on arXiv. The team presents a new tokenizer that uses semantics to drive vocabulary construction, with a trainer that uses stemming to enhance subword formation. The tokenizer is a drop-in replacement for the SentencePiece tokenizer and more than doubles the number of word forms represented in the vocabulary. The new tokenizer significantly improves NLP model convergence and improves the quality of word and sentence embeddings, with top performance seen in two Glue tasks using BERT-base, outperforming models more than 50 times in size.

Some comments noted that the paper was a significant improvement in transformer performance and highlighted how semantics can help processing multi-language texts. Others criticized the use of arXiv for class projects and questioned the significance of the paper's contribution. Additionally, some discussed the challenges of tokenization and the impact of vocabulary construction on natural language processing models.

### Palantir demos AI to fight wars but says it will be ethical

#### [Submission URL](https://www.vice.com/en/article/qjvb4x/palantir-demos-ai-to-fight-wars-but-says-it-will-be-totally-ethical-dont-worry-about-it) | 25 points | by [konart](https://news.ycombinator.com/user?id=konart) | [17 comments](https://news.ycombinator.com/item?id=35731534)

Palantir, co-founded by billionaire Peter Thiel, has demonstrated its Artificial Intelligence Platform (AIP) for military decision making. In Palantir's scenario, a military operator uses AI to monitor and respond to enemy activity, such as the recent amassing of military equipment near friendly forces. The operator asks a chatbot to show them more information, generates several plans of attack and organises the jamming of enemy communications. However, the author notes the dangers of automating warfare and abstracting it even further, suggesting the system is an illusion of safety and control for the Pentagon.

The comments discuss ethical concerns over the use of LLMs (lethal autonomous weapons). Some argue that the industry is ignoring these concerns, while others claim that the military will not deploy such systems until they are deemed safe and reliable. There are also some anecdotes about the long hours and intense work culture at Palantir.

### A Low Cost Approach to Improving Pedestrian Safety with Deep Learning

#### [Submission URL](https://nathanrooy.github.io/posts/2019-02-06/raspberry-pi-deep-learning-traffic-tracker/) | 62 points | by [djoldman](https://news.ycombinator.com/user?id=djoldman) | [58 comments](https://news.ycombinator.com/item?id=35727163)

A developer has created a cheap and accurate traffic counting system using TensorFlow and a Raspberry Pi Zero with an 8-megapixel infrared camera and rechargeable USB battery pack. The system uses a convolutional neural network with a secondary region proposal network to detect and localise objects within the frame, with lightweight temporal clustering to track them. The end result is a tool capable of separately counting vehicles, pedestrians and cyclists with high accuracy, potentially providing valuable data for urban planning and safety measures.

In the comments, there was a discussion on whether data on existing traffic patterns would be necessary for making biking more attractive in cities or if current infrastructure should be changed to support pedestrian traffic. Additionally, there was discussion on the correlation between frequent service and high passenger counts, as well as the challenges associated with increasing density and public transportation. There were also debates on making buses more efficient or switching to electric cars, as well as ideas for improving traffic congestion, such as increasing the use of roundabouts and encouraging the use of smaller cars.

---

## AI Submissions for Wed Apr 26 2023 {{ 'date': '2023-04-26T14:23:08.057Z' }}

### HDR-NeRF: High Dynamic Range Neural Radiance Fields

#### [Submission URL](https://xhuangcv.github.io/hdr-nerf/) | 142 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [32 comments](https://news.ycombinator.com/item?id=35717106)

Researchers from Northwestern Polytechnical University and Tencent AI Lab have developed a method called HDR-NeRF that can recover a high dynamic range radiance field from a set of low dynamic range views with different exposures. This allows for the generation of novel high dynamic range (HDR) and low dynamic range (LDR) views with varying exposures. The proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Experiments conducted on synthetic and real-world scenes validate the proposed method's ability to accurately control the exposures of synthesized views and render views with high dynamic range.

The discussion on the news discusses how the proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Some comments are about the advantages of using this method on smart-phones, while others discuss the limitations of the technology. The discussion also explores the naming convention of the technology and tone mapping. 

### Why did Google Brain exist?

#### [Submission URL](https://www.moderndescartes.com/essays/why_brain/) | 464 points | by [brilee](https://news.ycombinator.com/user?id=brilee) | [296 comments](https://news.ycombinator.com/item?id=35716216)

In this essay, former Google Brain employee Brian Kihoon Lee reflects on the existence of Google Brain and its relevance in today's economic conditions. He examines several reasons for its existence, including prestige, breakthrough discoveries, and maintaining a lead in machine learning. Lee suggests that while these reasons were valid in the past, economic pressures and increased competition from other AI companies mean that Google must be more responsible and directed in its research investments. He also notes a shift towards reduced researcher freedom and top-down direction within the company. Lee's perspective offers insights into the challenges facing industry research labs and the evolving landscape of AI development.

The discussion revolves around the validity of ML PhDs majoring in different fields such as chemistry and physics, and their proficiency in machine learning. Many users point out that while ML PhDs may not possess a deep understanding of the field they majored in, they are compensated for their lack of knowledge through their proficiency in ML. Others suggest that ML has helped cross disciplinary lines and created excellent interdisciplinary work. Some users argue that AI companies such as Google need to be more responsible and directed in their research investments, while others point out the need for foundational ML research. Overall, the discussion sheds light on the challenges facing the development of AI and industry research labs in general.

### DeepFloyd IF: open-source text-to-image model

#### [Submission URL](https://github.com/deep-floyd/IF) | 217 points | by [ea016](https://news.ycombinator.com/user?id=ea016) | [123 comments](https://news.ycombinator.com/item?id=35717871)

The StabilityAI team has developed a state-of-the-art open-source text-to-image model, called DeepFloyd IF, with high photorealism and language understanding. The model is composed of a frozen text encoder and three cascaded pixel diffusion modules that generate 64x64, 256x256, and 1024x1024 px images. The model uses the T5 transformer for text embedding and a UNet architecture with cross-attention and attention pooling. It outperforms other state-of-the-art models and achieves a zero-shot FID score of 6.66 on the COCO dataset. The DeepFloyd IF can be run locally and is also integrated with the Hugging Face Diffusers library.

The comments discuss DeepFloyd IF's capabilities compared to other text-to-image models and specific problems with the current implementation. Additionally, there is a discussion around hurdles with prompts and copyright laws. Some users express interest in trying the model with different prompts, while others debate the legal implications of using it.

### Mark Zuckerberg says Meta wants to ‘introduce AI agents to billions of people’

#### [Submission URL](https://www.theverge.com/2023/4/26/23699633/mark-zuckerberg-meta-generative-ai-chatbots-instagram-facebook-whatsapp) | 49 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [53 comments](https://news.ycombinator.com/item?id=35721910)

Meta CEO Mark Zuckerberg has announced plans to integrate AI agents into billions of Meta apps in ways that will be useful and meaningful for regular people, creators, and businesses. Although it remains unclear how exactly Meta will incorporate generative AI into its applications, Zuckerberg teased the release of AI products in the coming months that will reportedly touch every single one of the company's products. The move comes as Meta attempts to keep up with competitors such as Snap and Google that have invested heavily in building AI infrastructure in recent years, and to address industry-wide interest in the potential applications of generative AI technology.
 
There is a discussion on how AI is impacting society, with some commenters noting concerns about AI collecting information and privacy issues. Others discuss the potential uses of AI in marketing and content creation. One commenter suggests Meta should focus on developing computer vision capabilities. While there are some who support the use of AI, others are skeptical and concerned about how AI technology will impact humanity. Additionally, there are some comments about the renaming of the company to Meta and speculation about the company's future.

### Bringing Memory Safety to sudo and su

#### [Submission URL](https://www.memorysafety.org/blog/sudo-and-su/) | 81 points | by [mritzmann](https://news.ycombinator.com/user?id=mritzmann) | [64 comments](https://news.ycombinator.com/item?id=35714347)

Prossimo, a project by Ferrous Systems and Tweede Golf, has announced their plan to re-implement the widely-used sudo and su utilities in Rust to increase memory safety and minimize risks to operating systems. As sudo and su were originally developed in the 1980s and written in C, they have experienced a number of vulnerabilities related to memory safety issues. This joint team from Ferrous Systems and Tweede Golf will work to implement the critical function of these utilities in Rust to secure the most critical software, particularly from memory safety vulnerabilities. The work is supported by Amazon Web Services and Prossimo welcomes contributions to improve memory safety.

Discussions in the comments focused on the effectiveness of Rust's memory safety features, the complexity and vulnerabilities of other programming languages, and the importance of memory safety in software security. Some commenters suggested that OpenBSD's Doas could be a smaller, simpler alternative to sudo, and others discussed the advantages of different programming languages for memory safety.

### A guide to prompting AI, for what it is worth

#### [Submission URL](https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what) | 179 points | by [jger15](https://news.ycombinator.com/user?id=jger15) | [50 comments](https://news.ycombinator.com/item?id=35712375)

Recently, there has been a lot of emphasis on the importance of prompting AI, with some influencers sharing secrets of how to use prompts effectively. However, Ethan Mollick argues that this emphasis on prompting is misplaced and the best way to use AI systems is through interaction rather than trying to craft the perfect prompt. That being said, Mollick provides some tips on how to approach prompting, such as giving context and constraints to the system, providing additional data, and thinking about programming in prose. Ultimately, the key to using AI effectively is practice.

The discussion covers a variety of perspectives, including tips for approaching prompting, the limitations of AI in understanding human intent, and the importance of providing context and constraints to the system. Some commenters suggest that the emphasis on prompting is misplaced, while others argue that finding the right wording and constraints is crucial for successful outcomes. Overall, the discussion highlights the complex and ongoing nature of working with AI systems.

---

## AI Submissions for Tue Apr 25 2023 {{ 'date': '2023-04-25T15:39:53.181Z' }}

### Transformers from Scratch

#### [Submission URL](https://e2eml.school/transformers.html) | 341 points | by [jasim](https://news.ycombinator.com/user?id=jasim) | [28 comments](https://news.ycombinator.com/item?id=35697627)

Transformers are all about sequence transduction, we need a way to convert words to numbers so we can do math on them. One approach is to count each word from one and assign it a number, but there's an easier format for computers to work with: one-hot encoding. This assigns each word an array of mostly zeroes with a single one in its corresponding index. This allows us to compute dot products and is used in matrix multiplication, a way to combine two-dimensional arrays. Markov chains, represented as matrices, can be used as a first order model to show what the next word is likely to be based on recent words.

The submission discusses the use of one-hot encoding to convert words to numbers for mathematical operations. It is suggested that the use of matrices, such as Markov chains, can help predict the next likely word based on the sequence. The comments provide links to additional resources, such as Jay Alammar's Illustrated Transformer series and TensorFlow implementation, and discuss various aspects of tokenization, embeddings, and projections. Some users express disappointment in the complexity of the topic while others provide beginner-friendly resources for understanding it. Two comments are flagged as possibly inappropriate.

### Tuql: Automatically create a GraphQL server from a SQLite database

#### [Submission URL](https://github.com/bradleyboy/tuql) | 20 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [8 comments](https://news.ycombinator.com/item?id=35699017)

Tuql is a new tool that can convert a SQLite database into a GraphQL endpoint. With its ability to infer relationships between objects, Tuql currently supports `belongsTo`, `hasMany`, and `belongsToMany` relationships. The tool also generates the necessary mutations to create, update, and delete objects and can associate many-to-many relationships. Tuql can be used through the command line and is available as an npm package.

The comments on the submission mention that Tuql is a great tool, and some users mention other similar libraries. One user points out that Tuql does not add threat fields for queries, which may make it difficult to change the frontend in the future. Another user recommends not using Tuql in production. There is also a discussion around how GraphQL frameworks handle authorization and security. Overall, most of the comments are positive, with users praising the convenience of Tuql and GraphQL libraries in general.

### Show HN: ChatGPT on 2-Dimensional Map

#### [Submission URL](https://www.superusapp.com/chatgpt2d/) | 147 points | by [victorsup](https://news.ycombinator.com/user?id=victorsup) | [55 comments](https://news.ycombinator.com/item?id=35709088)

On Hacker News, a developer has created an interesting web app called "ChatGPT on 2-Dimensional Map." The app combines two popular AI technologies, namely GPT-2 for natural language processing and t-SNE for dimensionality reduction, to create a chatbot that can navigate a 2D map based on user inputs. The developer has also provided a demo, so users can see the app in action. This innovative project showcases the potential of combining different AI tools to develop new and creative applications.

A developer has created a web app called "ChatGPT on 2-Dimensional Map," utilizing both the natural language processing capabilities of GPT-2 and t-SNE for dimensionality reduction to create a chatbot that can navigate a 2D map based on user inputs. The discussion shows appreciation for this innovative project and its demonstration of the potential of combining AI tools to develop new applications. Some users express interest in using this technology for research and performance modeling, while others suggest similar projects and libraries for visualization and mapping. Some discuss related concepts such as Mind Maps and Lie Algebra. The high cost of ConceptGPT is mentioned, and some users suggest alternatives or that the creator should have asked for a funding request. A few users also mention indulging in activities such as drinking while programming or creating AI, while others make fun of misconceptions around Pina Coladas and canned ingredients.

### Google Authenticator cloud sync: Google can see the secrets, even while stored

#### [Submission URL](https://defcon.social/@mysk/110262313275622023) | 349 points | by [Signez](https://news.ycombinator.com/user?id=Signez) | [117 comments](https://news.ycombinator.com/item?id=35708869)

The discussion revolves around the security of Google Account 2FA secrets and how well Google protects its user data. Some commenters question Google's willingness to share user data with governments, while others suggest ways to enhance the security of the 2FA system and protect against data breaches. The conversation also touches on Apple's adherence to user privacy in comparison to Google. The debate ultimately boils down to how much responsibility users should take to protect their own privacy and how much they should rely on their service providers. One user recommends a phone security service called 2FAS for added security.

---

## AI Submissions for Mon Apr 24 2023 {{ 'date': '2023-04-24T15:21:30.763Z' }}

### LAION, a high school teacher’s free image database, powers AI unicorns

#### [Submission URL](https://www.bloomberg.com/news/features/2023-04-24/a-high-school-teacher-s-free-image-database-powers-ai-unicorns) | 315 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [172 comments](https://news.ycombinator.com/item?id=35685497)

The article tells the story of Christoph Schuhmann, a high school teacher who created LAION, the world's largest free AI training data set. LAION collects images and captions from various websites and uses them to train text-to-image generators, such as Google's Imagen and Stability AI's Stable Diffusion. The article explores the legal and ethical issues that arise from using publicly available materials for AI purposes, such as copyright infringement, bias, and regulation. The article also presents Schuhmann's views on why he wants to keep LAION open-source and independent.

Some users argue that LAION  only indexes internet lists of URLs, regional messages, and AI-generated text-to-image models, and does not publish any copyrighted content. Other users point out the potential legal liabilities and suggest that Common Crawl, a California nonprofit, should curate the collected visual data. Additionally, the comments touch on the challenges of accessibility in the design of captchas, the importance of properly organized high-quality imagery, and the legal implications of using scraped visual data for machine learning.

### Google Authenticator now supports Google Account synchronization

#### [Submission URL](https://security.googleblog.com/2023/04/google-authenticator-now-supports.html) | 429 points | by [ortusdux](https://news.ycombinator.com/user?id=ortusdux) | [305 comments](https://news.ycombinator.com/item?id=35690398)

Google Authenticator, a popular two-factor authentication app, now supports synchronization with Google Accounts. This means that users can easily transfer their authentication codes to a new device without needing to manually re-enter them. The feature is available on Android and iOS devices and uses Google Cloud to securely store and transfer the data. This upgrade provides added convenience and security for users who rely on two-factor authentication to protect their accounts.

Some users have complained about Google's 2FA offerings, including mismatched numbers and issues with Google Prompts not working on certain devices. Others have suggested potential solutions, such as using U2F tokens, while acknowledging the importance of account recovery processes involving important documents. The discussion also touches on related topics, such as password management, customer support, and device limitations. Overall, the consensus seems to be that while there are some issues and complexities with the technology, 2FA remains an important security measure that consumers should take advantage of.

### ONNX Runtime merges WebGPU backend

#### [Submission URL](https://github.com/microsoft/onnxruntime/pull/14579) | 166 points | by [b_mc2](https://news.ycombinator.com/user?id=b_mc2) | [31 comments](https://news.ycombinator.com/item?id=35694553)

Microsoft's open-source AI platform, ONNX Runtime, has introduced a WebGPU backend to accelerate machine learning models on the web. The JavaScript Execution Provider (JSEP) enables asynchronous inferencing execution and includes both C/C++ and TypeScript/JavaScript implementations. JSEP uses Emscripten's Asyncify compiler feature to unwind and rewind the call stack to emulate async execution. WebGPU is designed to have stronger features than WebGL, the other API currently available for accessing a GPU from a browser, making it a better solution for GPU performance when inferencing machine learning models.

Yhe submission sparked a discussion about the ONNX format, ONNX Runtime, and the implementation of the WebGPU backend for ML models. Some commenters suggested that the ONNX format is one of the best performing ML runtimes currently available, while others noted the lack of documentation for different platforms and hardware combinations. Others praised Microsoft's ONNX and made comparisons between different compiler systems. Some suggested alternative approaches to commenting and merging code to larger PRs. There was also discussion about the usefulness of the ONNX library, with some saying it worked well for them, and others suggesting that it could still use some improvement.

### 1Password to Add Telemetry 

#### [Submission URL](https://blog.1password.com/privacy-preserving-app-telemetry/) | 285 points | by [zan5hin](https://news.ycombinator.com/user?id=zan5hin) | [266 comments](https://news.ycombinator.com/item?id=35691383)

1Password, the password manager service, has begun an internal test of a new in-app telemetry system with a view to better understanding how users interact with the product. The initiative will be voluntary for employees and will not involve any data from customer accounts. Over the years, 1Password has regularly used its customer research programme to inform product development, but the company said it needed to expand its knowledge to improve the service for the millions of people using the product. Results from the internal trial will be evaluated before plans for a rollout are confirmed.

A user commented that they have been using the password manager Keepass, as they prefer a local vault and do not want any browser or cloud-based password managers. Another user praised 1Password's UI/UX, while others expressed concerns about the voluntary telemetry initiative and subscription-based licensing. Some users recommended Bitwarden and Keepass as alternatives with better functionalities. Some users also expressed skepticism about the benefits of telemetry and the need for it.

### Snapchat sees spike in 1-star reviews as users pan the ‘My AI’ feature

#### [Submission URL](https://techcrunch.com/2023/04/24/snapchat-sees-spike-in-1-star-reviews-as-users-pan-the-my-ai-feature-calling-for-its-removal/) | 240 points | by [mmq](https://news.ycombinator.com/user?id=mmq) | [200 comments](https://news.ycombinator.com/item?id=35689596)

Snapchat's new AI chatbot, powered by OpenAI's GPT technology, has been met with criticism by users following its recent public release. The chatbot, which is now pinned at the top of Snapchat's Chat tab, has resulted in a spike of negative reviews on the US App Store, with 75% being one-star reviews over the past week. Many users feel the chatbot is invasive and creepy, with concerns surrounding the collection of personal data, and have called for it to be a voluntary, opt-in feature. Some reviews indicate that even those who rated the app five stars have complaints about the My AI feature.

The comments section discusses data privacy concerns and the collection of personal data by companies, as well as the implementation of taxes like the Canadian Manufacturers Tax and GST. Some users feel that people do not grasp the extent of data collection that is happening, and that companies need to be more transparent about it. Others point out that sharing of personal information is an expected part of using such services.