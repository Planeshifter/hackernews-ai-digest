import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Thu Jun 08 2023 {{ 'date': '2023-06-08T17:11:54.525Z' }}

### Mechanical Apple Watch from real e-waste Apple Watch

#### [Submission URL](https://www.instructables.com/Mechanical-Apple-Watch-From-Real-E-Waste-Apple-Wat/) | 503 points | by [zdw](https://news.ycombinator.com/user?id=zdw) | [153 comments](https://news.ycombinator.com/item?id=36249671)

What's almost as cool as an Apple Watch? An entirely mechanical Apple Watch, of course! That's what DIY enthusiast NanoRobotGeek has created, taking apart an old Apple Watch to make a completely mechanical, "dumb" version of the watch that could last for years. Form and function were important for the project, with NanoRobotGeek selecting a series one Apple Watch with stainless steel and sapphire glass for a quality build. The final product uses a Seiko movement as a base and features unique touches like a chamfered gear bridge and a silver Côtes De Genève rotor.

The submission on Hacker News is about a DIY enthusiast who took apart an old Apple Watch and created a completely mechanical, "dumb" version of it, using a Seiko movement as a base. While some commenters praised the intricate design of mechanical watches and their long lifespan, others pointed out the potential drawbacks, such as the high cost of servicing and the need for regular winding. Some also discussed the pricing of Casio watches and the different types of watch services available. One commenter suggested reaching out to a watchmaker for proper servicing, while others shared their own experiences with mechanical watches. Overall, the discussion highlighted different perspectives on the merits and drawbacks of mechanical watches compared to their electronic counterparts.

### Understanding GPT tokenizers

#### [Submission URL](https://simonwillison.net/2023/Jun/8/gpt-tokenizers/) | 388 points | by [simonw](https://news.ycombinator.com/user?id=simonw) | [113 comments](https://news.ycombinator.com/item?id=36248633)

Simon Willison, the co-creator of Django and a technology consultant, has built a tool that extracts tokens from text to search through a table of full tokens. Using OpenAI's Tokenizer tool for exploring tokens, Willison created a more interesting tool on Observable notebook. The notebook converts text to tokens, tokens to text, and allows users to run searches against the full token table. Willison also discusses glitch tokens and a Python library called tiktoken, which counts the number of tokens in a string before passing it to the API to ensure that the token limit is not exceeded.

The discussion delves into the details of tokenization and how it works in different programming languages. Some users also suggest using a Rust backend for optimization and compatibility with the OpenAI GPT-4 language model. Another interesting point raised is the concept of glitch tokens and how they can be used to improve training data for language models. Additionally, a Computerphile video on glitch tokens is shared as a useful introduction to the topic.

### iOS 17 automatically removes tracking parameters from links you click on

#### [Submission URL](https://9to5mac.com/2023/06/08/ios-17-link-tracking-protection/) | 833 points | by [belfalas](https://news.ycombinator.com/user?id=belfalas) | [305 comments](https://news.ycombinator.com/item?id=36243955)

Apple has added a new privacy feature in iOS 17 that will remove tracking parameters from links that users click on. This feature, called Link Tracking Protection, will be automatically activated in Mail, Messages, and Safari in Private Browsing mode. By removing third-party cookies and tracking identifiers that advertisers and analytics firms add to link URLs, Apple is aiming to improve user privacy while browsing the web. To measure ad campaign conversion metrics, an alternative way for advertisers has been enabled, called Private Click Measurement ad attribution in Safari Private Browsing mode. The comments section addresses various discussions recognizing that this feature consolidates tracking power within Apple, how Mozilla and Google implemented similar standards in the past, and the limitations of existing plug-in support for Safari.

### Wolfram Prompt Repository

#### [Submission URL](https://resources.wolframcloud.com/PromptRepository/) | 29 points | by [headalgorithm](https://news.ycombinator.com/user?id=headalgorithm) | [4 comments](https://news.ycombinator.com/item?id=36239563)

Wolfram has released a new repository featuring 51 prompts for its AI-powered chatbots, defining how they interact with users based on personas such as Birdnardo, PirateSpeak, and TechSupportBot. Other prompts in the repository cover functions such as TitleSuggest, Emojify, and CoverLetterSuggest, with over 100 options in total. Users can modify the output coming from the LLM with Modifiers such as LimerickStyled, EmojiTranslated and BadGrammar. The repository is aimed at writers and developers looking to create personalized, AI-powered conversation experiences.

### YouTube legal team contacted Invidious developers

#### [Submission URL](https://github.com/iv-org/invidious/issues/3872) | 80 points | by [SushiHippie](https://news.ycombinator.com/user?id=SushiHippie) | [17 comments](https://news.ycombinator.com/item?id=36250582)

The legal team of YouTube has contacted the developers of Invidious, a privacy-focused and ad-free front-end for YouTube. The Invidious team believes that they never agreed to YouTube's terms of service (TOS) and that they do not use the YouTube API. However, they are prepared for the worst and have asked users to assume that YouTube will ask GitHub to take down the Invidious repositories. They have also promised to donate any funds remaining to FOSS/privacy organizations if they are forced to quit. Some users feel that YouTube is trying to force users onto its platform by blocking alternative clients like Invidious and others.

Some users of Invidious complain about the increasing cost of subscriptions on YouTube, and how they use the Invidious platform to watch videos without ads. There are suggestions to use ad-blockers like UBlock Origin or Sponsorblock to skip ads, or to switch to alternative platforms such as FreeTube or Piped. Others comment on the legal implications and how YouTube's legal team might be checking the ToS policies, API, and sending notices to organizations that they deem are violating their platform rules. There are also discussions about changes to Twitter and Reddit APIs.

### Weave: Interactive Data Exploration Toolkit by Weights and Biases

#### [Submission URL](https://github.com/wandb/weave) | 48 points | by [sicariusnoctis](https://news.ycombinator.com/user?id=sicariusnoctis) | [3 comments](https://news.ycombinator.com/item?id=36237307)

Weights and Biases has open-sourced Weave, an interactive data exploration toolkit built to handle large datasets smoothly. Using Weave, Machine Learning practitioners can engage with their data and derive insights using interactive and beautiful plots, without the need to learn complicated APIs. Weave is also modular so users can combine different components to customize their own data exploration toolkit, and publish reusable components into the ecosystem for others to use. Weave is newly open sourced and the APIs are subject to change, but example notebooks demonstrating common usage patterns are available in their repository for interested parties to try.

### FFmpeg Adds Support for Animated JPEG-XL

#### [Submission URL](https://www.phoronix.com/news/FFmpeg-Animated-JPEG-XL) | 51 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [6 comments](https://news.ycombinator.com/item?id=36243889)

FFmpeg, the popular multimedia framework used by many application developers, can now decode animated JPEG-XL files, thanks to the addition of support for animated decode of JPEG-XL in the libjxl library through a new animated JPEG-XL demuxer. This comes after Apple announced their support for the royalty-free image codec in Safari, putting pressure on Google to reverse their decision to drop JPEG-XL support from Chrome last year. With increased adoption of this format, developers may find the addition useful for supporting animated JPEG-XL content.

One user mentions that JPEG-XL is a named replacement for GIFs, while another user points out that Motion JPEG is a compressed standard for video compression, unlike the lossless image compression format named GIF. Some users compare JPEG-XL to other formats like HEIF, WebP, and MNG, discussing their suitability for different purposes. One user also discusses the technical aspects of the format, mentioning progressive loading, inter-frame compression, and marginal lossless features.

---

## AI Submissions for Wed Jun 07 2023 {{ 'date': '2023-06-07T17:12:30.581Z' }}

### Deepmind Alphadev: Faster sorting algorithms discovered using deep RL

#### [Submission URL](https://www.nature.com/articles/s41586-023-06004-9) | 729 points | by [anjneymidha](https://news.ycombinator.com/user?id=anjneymidha) | [261 comments](https://news.ycombinator.com/item?id=36228125)

Researchers have developed a new AI algorithm, AlphaDev, which was trained to discover more efficient sorting and hashing routines. By formulating the task of optimizing sorting algorithms as a single-player game, AlphaDev used deep reinforcement learning to discover small sorting algorithms from scratch. These algorithms were found to outperform previously known human benchmarks and have now been integrated into the LLVM standard C++ sort library. The approach used in this study could have applications in other domains and could potentially discover other unknown routines.

In the comments, there is a discussion about the specifics of the algorithm, including the benchmarks and the potential for the routines to be used in other contexts. Additionally, there is a debate about the need for cryptographically secure hashing functions and the role of hashing in cryptographic applications. There is also a discussion about the requirements for a hash function to be considered secure and suggestions for further research.

### CodeTF: One-Stop Transformer Library for State-of-the-Art Code LLM

#### [Submission URL](https://arxiv.org/abs/2306.00029) | 91 points | by [pabo](https://news.ycombinator.com/user?id=pabo) | [6 comments](https://news.ycombinator.com/item?id=36233881)

A team of researchers have developed an open-source Transformer-based library called CodeTF designed to simplify the development and deployment of deep learning-based models for code intelligence. CodeTF supports a variety of pretrained Code LLM models and popular code benchmarks with a unified interface that allows for rapid access and development across different models, datasets, and tasks. The library also includes language-specific parsers and utility functions for extracting code attributes. The researchers hope CodeTF will bridge the gap between machine learning/generative AI and software engineering, providing a comprehensive open-source solution for developers, researchers, and practitioners.

The discussion includes various comments on the open-source Transformer-based library, CodeTF, developed by researchers to simplify the development and deployment of deep learning-based models for code intelligence. One user suggests that Salesforce's investment in resources focused on machine learning/generative AI for software engineering could positively impact the field, and they are pleased with the comprehensive open-source solution. Another user discusses the differences in released models and notes CodeTF's inclusion of various models and benchmarks. Several users mention their experience with the library, including using it to train models for specific programming languages, struggling with certain prompts, and the limited support for certain languages such as C++ and Rust. Overall, the comments show interest in CodeTF and its potential impact on code intelligence and software engineering.

### I'm afraid I can't do that: Prompt refusal in generative language models

#### [Submission URL](https://arxiv.org/abs/2306.03423) | 170 points | by [belter](https://news.ycombinator.com/user?id=belter) | [160 comments](https://news.ycombinator.com/item?id=36230750)

Max Reuter and William Schulze have submitted a paper titled "I'm Afraid I Can't Do That: Predicting Prompt Refusal in Black-Box Generative Language Models" to KDD 2023, in which they examine the refusal behavior of OpenAI's ChatGPT and the fine-tuning bias that affects which prompts the model chooses to refuse. The authors use a black-box attack to query ChatGPT with offensive and benign prompts, manually labeling each response as compliance or refusal. They then train a refusal classifier using a small manually-labeled dataset and use it to bootstrap a larger dataset on which they train a prompt classifier to predict whether ChatGPT will refuse a given question. The prompt classifier achieves 76% accuracy on a test set of manually labeled questions, and the authors examine the classifiers and the prompt n-grams that are most predictive of either compliance or refusal.

In the discussion on Hacker News, users mentioned possible ways to improve moderation and reduce offensive prompts in AI models, such as implementing a moderation filter, using encryption, adding latency to the response, and creating a conversation topic that is entirely foreign to ChatGPT. Some users expressed concern about privacy and censorship, while others pointed out the importance of good UI design to avoid confusing users and to give warning signals when necessary.

### Is AI killing the stock photo industry? A data perspective

#### [Submission URL](https://www.stockperformer.com/blog/is-ai-killing-the-stock-industry-a-data-perspective/) | 146 points | by [giuliomagnifico](https://news.ycombinator.com/user?id=giuliomagnifico) | [208 comments](https://news.ycombinator.com/item?id=36223307)

As the stock photography industry grapples with the implications of AI-generated imagery, Stock Performer has attempted to shed some light on how it has affected the sector. While there is little data available on the uptake of AI-generated images, the blog post from Stock Performer, which analysed information from its customers who upload to Adobe Stock, found that at present only 13% of those contributors have submitted AI-generated content. The data also revealed that revenue and download numbers for iStockphoto and Adobe Stock have increased in recent years, while Shutterstock has suffered from a substantial rise in monthly uploads without seeing a matching upswing in sales.

Some commenters pointed out the dark UX patterns of subscription services for stock photography and suggested that subscriptions may be more appealing for companies needing a large number of images than individual buyers, and that AI-generated stock photography is often lower quality than premium stock photography produced by humans. Others suggested that the industry is overvalued and may soon collapse, while others commented on the potential socioeconomic implications of AI-generated imagery, including job displacements and the concentration of capital among the owners of AI technologies. Overall, it seems that the industry is still trying to respond to the challenges and opportunities presented by AI-generated stock photography.

### How many sensors for autonomous driving?

#### [Submission URL](https://semiengineering.com/how-many-sensors-for-autonomous-driving/) | 96 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [200 comments](https://news.ycombinator.com/item?id=36226986)

As autonomous driving technology advances, carmakers are debating the number of sensors needed for vehicles. The cost of sensors ranges from $15 to $1,000 and they are used to collect data about the surrounding environment. These include image, lidar, radar, ultrasonic, and thermal sensors. However, each type of sensor has its limitations which has driven the development of sensor fusion. Combining multiple sensors can achieve safe autonomous driving. OEMs are taking very different design and deployment approaches. Mercedes-Benz has installed 30 sensors for autonomous driving while Tesla has adopted a camera-only autonomous driving technology strategy. Sensor fusion remains an active area of research as each type of sensor has limitations. The number of sensors required will depend on various factors including the level of autonomy and type of vehicle.

The discussion in the comments touches on a range of related topics, including the advantages and disadvantages of various sensor types, the challenges of developing sensor fusion, the capabilities of humans versus robots in perceiving depth and other aspects of the environment, and the importance of software in ensuring safe self-driving cars. Some commenters suggest that sensors alone are not sufficient and that driver feedback and other forms of interaction may be necessary, while others emphasize the importance of improving human understanding of the physical world and enhancing machine learning models to better extrapolate physical interactions. Some commenters argue that the focus on sensors is misplaced and that the biggest challenge facing self-driving cars is the intricacy of the road network itself, which requires new levels of communication and coordination between vehicles.

### Run and create custom ChatGPT-like bots with OpenChat

#### [Submission URL](https://github.com/openchatai/OpenChat) | 157 points | by [udev4096](https://news.ycombinator.com/user?id=udev4096) | [55 comments](https://news.ycombinator.com/item?id=36223972)

OpenChat is a console designed to simplify the usage of large language models. It serves as a hub for managing multiple customized chatbots, supporting GPT models, and providing two-step setup processes to create a comprehensive chatbot console. Currently available features include the creation of unlimited local chatbots, customization of chatbots by providing PDF files, websites, and integrations with platforms like Notion and Confluence, and the ability to use the entire codebase as a data source for chatbots. The project is licensed under the MIT License, and contributions are welcomed.

The comments discuss various approaches to content embedding, including chunking, which some users believe to be a neglected approach that may improve retrieval quality. Several users suggest various methods for controlling the number of results returned by fine-tuning language models, and others discuss the challenges of integrating OpenAI and open-source language models. Additionally, users raise concerns about security and mention the importance of content provided by platforms such as Notion and Confluence in providing integrations.

### C++ Implementation of StableDiffusion

#### [Submission URL](https://github.com/axodox/axodox-machinelearning) | 152 points | by [smusamashah](https://news.ycombinator.com/user?id=smusamashah) | [35 comments](https://news.ycombinator.com/item?id=36235338)

Axodox has released a C++ ONNX implementation of StableDiffusion for image synthesis, including txt2img, img2img, and inpainting. With competitive performance, this solution does not rely on Python and can integrate into virtually any application as long as they can import C++ or C functions. The ONNX models are executed using the ONNX runtime, and Axodox offers an example integration called Unpaint, which showcases how the libraries can be integrated into a simple WinUI-based user interface. The current codebase and the resulting NuGet packages target Windows and use DirectML, although only small sections of the code utilize Windows-specific APIs and can be ported to other platforms with minimal effort.

The most significant topics of discussion touch on why someone would choose C++ over Python in this use case, a platform-specific implementation, and package management. The discussion goes on to list different methods of package management and suggest different libraries and hardware accelerations to use when implementing machine learning models in C++.

### DeepFilterNet: Noise supression using deep filtering

#### [Submission URL](https://github.com/Rikorose/DeepFilterNet) | 211 points | by [nitinreddy88](https://news.ycombinator.com/user?id=nitinreddy88) | [42 comments](https://news.ycombinator.com/item?id=36221534)

DeepFilterNet is a speech enhancement framework that uses deep filtering and was designed to reduce noise in speech signals for full-band audio. The open-source framework is available for Linux, MacOS, and Windows, and includes a Python wrapper for processing and a LADSPA plugin for real-time noise suppression. DeepFilterNet2, a newer version of the framework, aims for real-time speech enhancement on embedded devices. Recently, the team behind DeepFilterNet released a new demo and a paper on Deep Multi-Frame Filtering for Hearing Aids.

Although some users raised concerns over its efficacy, the majority of commenters agreed that the use of deep filtering over classic speech control algorithms showed strong potential. Some users mentioned Python's limitations with dependency management and Poetry, a modern dependency tool for Python, was suggested as an alternative. The discussion also covered multiple topics, such as the integration of Pipewire, neural network-based approaches to image recognition, and the challenges of researching noise suppression for voice-recognition applications.

### OpenLLaMA 7B Training Completed to 1T Tokens

#### [Submission URL](https://huggingface.co/openlm-research/open_llama_7b) | 56 points | by [jncraton](https://news.ycombinator.com/user?id=jncraton) | [3 comments](https://news.ycombinator.com/item?id=36228535)

OpenLLaMA offers an open source reproduction of Meta AI's LLaMA large language model, complete with 7B and 3B models trained on 1T tokens, and a preview of a 13B model trained on 600B tokens. The project provides PyTorch and JAX weights of pre-trained OpenLLaMA models, evaluation results, and comparisons against the original LLaMA models. The models are trained on the RedPajama dataset released by Together and evaluated on a range of tasks, with results showing comparable performance to the original LLaMA and GPT-J on the majority of tasks. The weights are released under the Apache 2.0 license, and the team welcomes feedback from the community.

The first comment warns that the loading of the weights was developed using a different tokenizer than Hugging Face, which sometimes leads to incorrect tokenization. The second comment praises the project's performance, noting that a 7B model was trained on the MosaicML's Falcon cluster, costing around $183k in computation. A third comment expands on this, stating that the training process for the 7B model was roughly the same as MosaicML's Falcon.

### First Impressions of Vision Pro and VisionOS

#### [Submission URL](https://daringfireball.net/2023/06/first_impressions_of_vision_pro_and_visionos) | 43 points | by [ryanwhitney](https://news.ycombinator.com/user?id=ryanwhitney) | [9 comments](https://news.ycombinator.com/item?id=36231202)

Tech enthusiasts are eagerly anticipating the launch of Vision Pro and VisionOS after tech blogger John Gruber had a sneak preview of the devices. In his blog post, Gruber praised the technology, calling it "extraordinary" and feeling like they have been "pulled forward in time from the future". However, he also noted that the software is far from complete, which makes it hard to determine whether the product will be successful. Vision Pro and VisionOS are part of a new platform from Apple that could rival MacOS and iOS/iPadOS.

Some Hacker News users are skeptical of the hype around Apple's Vision Pro and VisionOS, as they believe that Steve Jobs' philosophy was that technology shouldn't "make compelling products into platforms," and that Apple has a history of taking existing technology and working backward to create a cohesive product experience. Other users feel that Apple has a long history of successful innovation, and that while the Vision Pro may be expensive, it could bring value for certain use cases. One user suggests that Apple is trying to co-create a platform for immersive 3D design with haptic feedback, while others debate the price point of the device. There are also discussions about whether Apple is following in the footsteps of Xerox PARC and if they are trying to create a new platform to compete with MacOS and iOS/iPadOS.

### OpenAI CEO suggests agency like UN’s nuclear watchdog could oversee AI

#### [Submission URL](https://apnews.com/article/open-ai-sam-altman-emirates-10b15d748212be7dc5d09eabd642ff39) | 33 points | by [belter](https://news.ycombinator.com/user?id=belter) | [31 comments](https://news.ycombinator.com/item?id=36226761)

OpenAI CEO Sam Altman has suggested that an international agency should oversee artificial intelligence worldwide, comparing it to the International Atomic Energy Agency that oversees nuclear power, during his global tour discussing AI in the United Arab Emirates. Altman expressed concerns over AI's "existential risk" to humanity and called for the world to "manage those risks and make sure we still get to enjoy those tremendous benefits." Altman's comments follow the success of OpenAI's popular chatbot, ChatGPT, and concern among industry leaders about mitigating the risks of AI and its impact on society.

The Hacker News community has been discussing Sam Altman's suggestion to implement an international agency that oversees artificial intelligence (AI) worldwide. Some users believe that AI regulation can have significant benefits, while others argue that the regulations will only exacerbate legal issues faced by startups. Furthermore, some comments express skepticism about Altman's intentions and believe that he is not trustworthy enough to lead this initiative. Other comments express concerns that centralized control over AI could lead to further greed and corrupt practices. Additionally, some users believe that prioritizing the development of AI over human needs will lead to disastrous consequences for humanity. Some users suggest that AI regulation is crucial because of the technology's existential risk and the potential negative effects it can have on society, including displacement of jobs and invasion of privacy.

### Ken Griffin says the AI community is making a mistake by creating so much hype

#### [Submission URL](https://www.cnbc.com/2023/06/07/citadels-ken-griffin-says-the-ai-community-is-making-a-mistake-by-creating-so-much-hype.html) | 24 points | by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) | [27 comments](https://news.ycombinator.com/item?id=36225505)

Ken Griffin, the founder and CEO of Citadel, has said that the near-term hype around generative AI is a "terrible mistake". Speaking to Citadel's new class of interns, Griffin believes the AI community is creating a "huge disservice" by creating such a buzz around AI, although he does concede that AI will one day be transformative. However, he argues that the threat of AI eliminating white-collar jobs is far from reality due to the need for precision and accuracy in finance. Griffin also suggests that the biggest target for generative AI is programming and software engineering, and that it is crucial for software engineers to be close to domain problems that need to be solved.

The discussion in the comments covers various topics like the capabilities of LLMs, the potential risks and benefits of AI, the need for software engineers to be close to domain problems that need to be solved, and the role of AI in specific tasks like detecting patterns in text and summarizing information. Some users also share their concerns about AI's impact on society and job displacement. However, others defend the potential benefits of AI, especially in specific tasks like summarizing information and solving software problems.

---

## AI Submissions for Tue Jun 06 2023 {{ 'date': '2023-06-06T17:14:27.704Z' }}

### Show HN: Arroyo – Write SQL on streaming data

#### [Submission URL](https://github.com/ArroyoSystems/arroyo) | 89 points | by [necubi](https://news.ycombinator.com/user?id=necubi) | [27 comments](https://news.ycombinator.com/item?id=36214393)

Arroyo is a distributed stream processing engine designed with Rust to efficiently execute stateful computations on data streams. The engine offers real-time streaming operations, including windows and joins, with state checkpointing for fault-tolerance and recovery of pipelines. Arroyo provides a web UI, API, and console for pipeline management. The engine is designed to run on modern cloud environments, supporting seamless scaling, recovery, and rescheduling and is built to enable non-experts to build real-time data pipelines. Arroyo is licensed under Apache-2.0 and MIT.

Arroyo is a distributed stream processing engine built from Rust, designed to execute stateful computations on data streams efficiently, with windows and joins, and state checkpointing. The engine was developed to enable non-experts to build real-time data pipelines, and comes with a web UI, API, and console for pipeline management. Discussions about Arroyo revolved around how it compares to Apache Flink and Kafka's KSQL. In particular, Arroyo was praised for its ability to scale and recover seamlessly on modern cloud environments, while Materialize was touted as a good alternative for view maintenance and ClickHouse for a backend. Discussions also touched on the documentation's mention of how events arriving after the watermark can be dropped, with comments pointing out that it is configural and soon will be altered to provide richer semantics of late arriving events. The engine's name which in Spanish means 'stream' was also brought up in discussions, and people shared the various meanings of Arroyo, ranging from seasonal desert streams to rivers. Additionally, there were brief discussions of other Rust-based developments such as TBlogs' tinybird and Arroyo's alternative to Apache KSQL, Confluent.

### Next-Generation CAMM, Mr-DIMM Memory Modules Show Up at Computex

#### [Submission URL](https://www.anandtech.com/show/18893/next-generation-camm-mr-dimm-modules-at-computex) | 22 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [6 comments](https://news.ycombinator.com/item?id=36213242)

ADATA demonstrated potential candidates for replacing traditional SO-DIMMs and RDIMMs/LRDIMMs, at the Computex 2023 trade show in Taipei. These new memory modules include Compression Attached Memory Modules (CAMMs) for ultra-thin notebooks and compact desktops; Multi-Ranked Buffered DIMMs (MR-DIMMs) for servers; and CXL memory expansion modules for machines that need extra system memory. The CAMM specification is slated to be finalized by JEDC later this year, and it promises benefits such as higher transfer rates, lower costs, higher DRAM density, reduced thickness, and dual-channel connectivity on a single module. MR DIMM technology promises to start at 8,800 MT/s with Gen1, then evolve to 12,800 MT/s with Gen2, and then to 17,600 MT/s in Gen3. Meanwhile, CXL memory modules feature a Compute Express Link and connect to host CPUs via a PCIe interface, expanding system memory for servers at a relatively low cost.

The discussion thread for the submission on ADATA's new memory modules includes several comments discussing the potential benefits and drawbacks of the technology. One user jokes about the naming convention for MR-DIMMs, while another suggests that CAMMs could be beneficial for Apple's expandable computers. A user proposes the idea of a "RAM Box" that could connect to a computer's system through Thunderbolt or USB4, while another user discusses the technical details of memory mapping and PCIe interfaces. Finally, one user disputes the claim that CAMMs offer significantly increased memory throughput, arguing that current CPUs do not support the high transfer rates that CAMMs are capable of.

### GGML – AI at the Edge

#### [Submission URL](http://ggml.ai) | 831 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [212 comments](https://news.ycombinator.com/item?id=36215651)

GGML is a tensor library for machine learning that enables large models and high performance on commodity hardware. Its features include automatic differentiation, built-in optimization algorithms, integer quantization support, and more. It is optimized for Apple Silicon, and can simultaneously run multiple instances of large models on a single chip. Whisper.cpp and llama.cpp are two projects that use GGML, and allow for high-performance speech-to-text and language model inference, respectively. GGML is open source and freely available under the MIT license, and the company behind it is seeking to hire full-time developers.

Discussions revolve around related projects such as Llama and Whisper.cpp, which are focused on speech-to-text and natural language inference, respectively. Additionally, issues related to funding and backing are discussed, with some expressing hope for more support for open-source projects and concerns about the impact of closed-source competition. There are also discussions on practical applications of machine learning and the challenges of working with private data.

### Nvidia releases new AI chip with 480GB CPU RAM, 96GB GPU RAM

#### [Submission URL](https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/) | 370 points | by [logicchains](https://news.ycombinator.com/user?id=logicchains) | [277 comments](https://news.ycombinator.com/item?id=36209047)

NVIDIA has announced the Grace Hopper Superchip, a CPU designed specifically for giant-scale AI and high-performance computing applications. The superchip offers up to 10 times the performance of standard CPUs for heavy-duty tasks, such as running terabytes of data. Its features include a 900 GB/s coherent interface, 30 times the system memory bandwidth to GPUs compared to the NVIDIA DGX A100, and compatibility with all NVIDIA software stacks and platforms, from HPC to AI. The chip is already part of the NVIDIA HGX for AI and HPC, as well as the NVIDIA BlueField-3. It joins more than 400 configurations of NVIDIA architectures being produced to support the widespread demand for AI.

Commenters discussed the history of supercomputers and computer memory and debated the significance of the Grace Hopper Superchip for the AI and high-performance computing industry. Some pointed out that the chip's compatibility with all Nvidia software stacks and platforms could be a game-changer. Others discussed the high-speed IO and the slow growth of available memory, indicating that building cards with 100GB RAM would be of little use to businesses. Overall, commenters were interested in the advancement of technology and the implications of this new CPU for the industry.

### MeZO: Fine-Tuning Language Models with Just Forward Passes

#### [Submission URL](https://github.com/princeton-nlp/MeZO) | 138 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [21 comments](https://news.ycombinator.com/item?id=36216532)

Princeton University's Natural Language Processing group has developed a new memory-efficient optimizer that fine-tunes language models (LMs) using just forward passes. Dubbed MeZO, the method adapts the zeroth-order SGD method to operate in-place, thus improving memory efficiency for tasks such as LM fine-tuning. The team claims their solution can train a 30-billion parameter OPT model using just a single A100 80GB GPU, while fine-tuning with Adam can only train a 2.7-billion parameter LM. MeZO reportedly performs comparably to fine-tuning with backpropagation, with memory reduction of up to 12 times.

The discussion on Hacker News explores various aspects of the method, including its comparison with backpropagation, its potential for swarm optimization, and the significance of its memory-reducing capabilities. There are also discussions around other related topics such as forward-forward algorithms and inference vs. training speed.

### visionOS

#### [Submission URL](https://developer.apple.com/visionos/) | 96 points | by [soheilpro](https://news.ycombinator.com/user?id=soheilpro) | [87 comments](https://news.ycombinator.com/item?id=36208735)

Apple has announced visionOS, a new platform for designing and developing apps and games for its upcoming Apple Vision Pro. It offers an infinite spatial canvas for experimentation, exploration and play, and enables developers to create fully immersive environments or fluid experiences that can seamlessly transition between a 3D window and a fully immersive scene. The platform includes windows, volumes and spaces, and leverages familiar frameworks and tools such as SwiftUI, RealityKit, ARKit and Unity. The visionOS SDK will be released later this month, along with Xcode, the visionOS Simulator, Reality Composer Pro, documentation, sample code and design guidance.

Commenters discussed various related topics, such as the use of 3D elements in standard HTML, the use of POSIX for full-stack development, and the possibility of using a global standard for 3D elements. Others talked about potential killer apps for watchOS, the health implications of screen time, the challenges of AR and VR technologies, and the need for better standards for augmented and virtual reality. Some commenters also discussed Furcadia, a 20-year-old game that uses 2D graphics.  Overall, the discussion covered a variety of topics related to the recent release of visionOS and the broader issues facing developers and users of augmented and virtual reality technologies.

### Redditor creates working anime QR codes using Stable Diffusion

#### [Submission URL](https://arstechnica.com/information-technology/2023/06/redditor-creates-working-anime-qr-codes-using-stable-diffusion/) | 568 points | by [samizdis](https://news.ycombinator.com/user?id=samizdis) | [94 comments](https://news.ycombinator.com/item?id=36218281)

A Reddit user named "nhciao" has created functional QR codes using the Stable Diffusion AI image-synthesis model that reflect artistic styles in anime and Asian art. Despite the presence of intricate AI-generated designs and patterns, smartphone camera apps on both iPhone and Android are still able to read them as functional QR codes. Stable Diffusion is an AI-powered image-synthesis model released last year that can generate images based on text descriptions. Ordinary black-and-white QR codes could be turned into unique pieces of art with this technique, enhancing their aesthetic appeal.

The comments section discussed other topics like different kinds of QR codes, their historical development, and their correct labeling. Furthermore, others discussed the limitations and reliability of Machine Learning (ML) algorithms and its effects on QR code implementations. One user pointed out that generating images through Stable Diffusion AI is impressive and can be used on products other than QR codes. Another user mentioned that the aesthetics of anime and Asian art is distinct and might create different interpretations.

### Vector Database in a Jupyter Notebook

#### [Submission URL](https://zilliz.com/blog/exploring-magic-vector-databases-jupyter-notebooks) | 69 points | by [fzliu](https://news.ycombinator.com/user?id=fzliu) | [6 comments](https://news.ycombinator.com/item?id=36207009)

In this article, the author explains the concept of vector databases and their usefulness in powering similarity search applications. They particularly highlight the need for vector databases in solving one of the main challenges that large language models (LLMs) face, which is a lack of domain knowledge and up-to-date data. The article then goes on to explain how to use Milvus (Lite) in your Jupyter Notebook, a vector database with a distributed system native backend that is purpose-built to handle indexing, storing, and querying vector data at a billion scales. The author provides step-by-step instructions on how to get started with Milvus (Lite) and shares resources for those who want to use a standalone vector database instance.

The comments on the submission include some discussions about related topics. One commenter shared a YouTube link that could be helpful for those interested in vector databases. Another commenter mentioned the importance of vector databases in natural language processing (NLP) applications and machine learning model integration. They provided examples of vector databases beyond semantic text search, including spatial data and structured data vectorization for machine learning. The conversation then shifted to personal introductions and networking, with one commenter expressing interest in learning more about the Semantic Kernel.

### Apple releasing segmentation/pose for humans and animals, embedding for 27 lang

#### [Submission URL](https://developer.apple.com/wwdc23/topics/ml-vision/) | 216 points | by [sumodm](https://news.ycombinator.com/user?id=sumodm) | [70 comments](https://news.ycombinator.com/item?id=36209014)

Apple's WWDC23 sessions offered in-depth explorations of machine learning and computer vision, with a focus on Apple's Core ML, Create ML, and Vision frameworks. Sessions delved into topics such as animal pose detection, 3D body pose and person segmentation, lifting subjects and developing live camera-tracking experiences. Create ML's updates in image understanding, text-based tasks with multilingual BERT embeddings, and multi-label classification were also discussed. Labs offered one-on-one appointments with Apple engineers to discuss machine learning in app development, and Q&A sessions let attendees ask questions on topics including image understanding and machine learning more broadly.

One Hacker News user was skeptical of the usefulness of pose detection exercises for personal fitness, while others noted that many fitness apps already use similar technology. Some users discussed the benefits and drawbacks of building apps specifically for Apple's platform vs. creating platform-agnostic software. One user suggested that Apple's subscription-based business model is geared towards retaining existing customers. Other users shared their experiences with various fitness apps and platforms.

### Phishing Darknet Users for Bitcoins

#### [Submission URL](https://shufflingbytes.com/posts/ripping-off-professional-criminals-by-fermenting-onions-phishing-darknet-users-for-bitcoins/) | 100 points | by [campuscodi](https://news.ycombinator.com/user?id=campuscodi) | [58 comments](https://news.ycombinator.com/item?id=36212480)

A hacker has developed a Proof of Concept of a method for stealing from fraudsters operating on the darknet. The Onion Fermenter (OF) uses traffic modifying reverse proxy to create fake darknet sites and redirect transactions to the hacker's wallet, ensuring there are no breadcrumbs for investigators to follow. Darknet sites have no central trusted source for checking legitimacy and descriptions cannot differentiate between fake and real, making it easy to plant sites for the unwary. Other phishing attempts have previously been reported, but OF can be deployed quickly and easily across Kubernets making it potentially far more lucrative.

The discussion includes arguments about the moral and legal justification for stealing from criminals, with some people calling for consistent moral codes to be applied across all situations. One commenter pointed out that high-trust societies respect themselves and play by their own moral codes, while others argued against vigilantism. The discussion also included technical details about the effectiveness of the OF method and the perception of different games and crimes. Finally, the discussion touched on the topic of phishing schemes and how they exploit the unwary on the darknet.

### AI: Nvidia Is Taking All the Money

#### [Submission URL](https://seekingalpha.com/article/4609485-ai-nvidia-is-taking-all-the-money) | 71 points | by [TradingPlaces](https://news.ycombinator.com/user?id=TradingPlaces) | [29 comments](https://news.ycombinator.com/item?id=36214749)

Nvidia Corporation has dominated the AI hardware and software market with their GPUs and software since 2012, making them a major target for competitors. Their GPUs have enabled exponential growth in AI model size, allowing them to charge high prices for their data center GPUs with a 75% gross margin. Microsoft's cloud operating margin has been impacted by the cost of Nvidia GPUs, and the cost to run large models in production has drastically increased due to Nvidia's monopoly. While competitors are working on non-GPU hardware, smaller models, and new software, it will be difficult for them to knock Nvidia off its perch as the default for AI research.

The discussion covers the finite demand for AI and how the high cost of Nvidia GPUs is impacting the industry. AMD is viewed as a potential competitor to Nvidia, but CUDA remains the industry standard. There is hope for a standardized software that does not require special customization and incentives for using non-Nvidia devices in AI training and inference.

### Hyperparameter Optimization for LLMs via Scaling Laws

#### [Submission URL](https://arxiv.org/abs/2302.00441) | 81 points | by [Lindizz](https://news.ycombinator.com/user?id=Lindizz) | [12 comments](https://news.ycombinator.com/item?id=36210727)

Researchers from the field of computer science and machine learning have proposed a new method called Deep Power Laws (DPL) to optimize hyperparameters of machine learning algorithms. The method utilizes an ensemble of neural network models conditioned to provide predictions that follow a power-law scaling pattern. The DPL method dynamically selects which configurations to pause and train incrementally, making use of grey-box evaluations. The researchers compared their method with 7 state-of-the-art competitors on 59 diverse tasks related to tabular, image, and NLP datasets. They achieved the best any-time results, obtaining the best results compared to all competitors.

The discussion in the comments includes various strategies for hyperparameter optimization, including starting with a default configuration and using Hyperband, DL1, and Bayesian search methods. Additionally, some users commented on the use of smaller models with dynamic budgets and configurations, while others discussed the specific application of DPL for NLP and computer vision datasets. Some users also expressed issues with hyperparameter optimization and the need for more research in this area.

### Tips for better coding with ChatGPT

#### [Submission URL](https://www.nature.com/articles/d41586-023-01833-0) | 150 points | by [isingle](https://news.ycombinator.com/user?id=isingle) | [104 comments](https://news.ycombinator.com/item?id=36211250)

OpenAI's chatbot, ChatGPT, is a powerful AI tool that researchers can use to debug code, translate software from one programming language to another, and perform rote operations. However, users must remember that chatbots are not intelligent; they are stochastic parrots that randomly echo what they have seen before. Therefore, it is critical to use caution when working with ChatGPT and related tools based on large language models. Here are six tips to maximize the utility of chatbots in coding: choose your applications wisely, trust but verify their responses, read responses carefully, test them thoroughly, keep up with software engineering, and use them as a conversational interface to Stack Overflow.

The discussion among Hacker News users provided mixed opinions on the utility of ChatGPT in coding, with some calling it productive and helpful, and others describing it as useless or requiring context and business requirements. Some commentators noted that large language models (LLMs) have difficulty answering complex questions or tasks that require specific domain knowledge. There were also discussions on the potential risks of using AI tools like ChatGPT and the importance of context in interpreting its responses.

### First impressions: Yes, Apple Vision Pro works and yes, it’s good

#### [Submission URL](https://techcrunch.com/2023/06/05/first-impressions-yes-apple-vision-pro-works-and-yes-its-good/) | 276 points | by [thatsso1999](https://news.ycombinator.com/user?id=thatsso1999) | [530 comments](https://news.ycombinator.com/item?id=36207705)

Apple has previewed its new mixed reality headset, the Apple Vision Pro, and after a 30-minute demo, industry insiders are impressed with its capabilities. With an eye-tracking and gesture control feature recognised as perfect, and the ability to pass-through a real-time 4K view of the world around the user, the headset is being applauded for eliminating issues of long-session VR or AR wear by passing through an image and including a "breakthrough" mechanism to warn of intruders. Though priced at the high end at $3,500, insiders see it as a power users' device and believe it has the potential to be a new computing mode. Some commenters are skeptical about the high price of the headset and whether it will appeal to a broad audience, while others believe it has the potential to be a new computing mode and replace laptops or even TV. Overall, there are mixed opinions about the potential success of the Apple Vision Pro and its place in the current market.

### Sextortionists are making AI nudes from your social media images

#### [Submission URL](https://www.bleepingcomputer.com/news/security/sextortionists-are-making-ai-nudes-from-your-social-media-images/) | 38 points | by [nazgulsenpai](https://news.ycombinator.com/user?id=nazgulsenpai) | [27 comments](https://news.ycombinator.com/item?id=36219621)

The FBI has alerted the public to a disturbing new trend in sextortion attacks. Scammers are taking publicly available images of their targets from social media and using them to create AI-generated sexually explicit content. While these images and videos are not real, they look very convincing and can be used to blackmail victims into paying money or sending real sexually explicit content. This trend has also impacted minors. To protect oneself, the FBI advises that parents monitor their children's online activity, adults restrict viewing access to a small private circle of friends, and anyone who discovers deepfake content of themselves on pornographic sites should report it to the authorities and contact the hosting platform for removal.

### Healthcare org with over 100 clinics uses GPT-4 to write medical records

#### [Submission URL](https://www.theregister.com/2023/06/06/carbon_health_deploys_gpt4powered_tools/) | 29 points | by [beardyw](https://news.ycombinator.com/user?id=beardyw) | [9 comments](https://news.ycombinator.com/item?id=36215907)

Carbon Health, a US healthcare chain, has introduced an AI tool for generating medical records automatically. Dubbed Carby, the tool is powered by OpenAI's latest language model, GPT-4. If a patient consents to having their meeting recorded and transcribed, the audio recording is passed to Amazon's AWS Transcribe Medical cloud service, which converts the speech to text. The transcript is then passed to an ML model that produces notes summarising important information gathered in the consultation. Carbon Health claims the tool produces consultation summaries in four minutes, compared to the 16 minutes it takes a single doctor to do it; clinics can therefore see more patients.

There were a few discussions about Carbon Health's AI tool for generating medical records. Some users were surprised that the healthcare providers allowed patient data to be sent to OpenAI given HIPAA regulations. However, it was noted that OpenAI's security page claims to have experience with helping customers meet regulatory industry requirements such as HIPAA. There was also a discussion about how the tool uses AI to produce consultation summaries in four minutes, which is much faster than a single doctor taking 16 minutes to do it. While some were skeptical about the accuracy of generative AI models, Carbon Health claimed that physicians verified 88% of the AI-generated text and made edits for the remaining 12% of the time. Finally, there was a discussion on the legal and privacy implications of using AI in healthcare, with some mentioning that Eric Schmidt, former CEO of Google, predicted in 2018 that AI will be widely used in healthcare in the future.

---

## AI Submissions for Mon Jun 05 2023 {{ 'date': '2023-06-05T17:15:55.654Z' }}

### Apple Vision Pro: Apple’s first spatial computer

#### [Submission URL](https://www.apple.com/newsroom/2023/06/introducing-apple-vision-pro/) | 2514 points | by [samwillis](https://news.ycombinator.com/user?id=samwillis) | [2702 comments](https://news.ycombinator.com/item?id=36201593)

Apple has announced the launch of its first spatial computer, Apple Vision Pro, which promises to revolutionize the world of computing. The device combines digital content with the physical world, giving users the ability to interact with an infinite canvas of apps using their hands, voice, and eyes. It features visionOS, the world’s first spatial operating system, and is powered by custom Apple silicon. With two ultra-high-resolution displays, the device can transform any space into a movie theater or an immersive gaming environment and comes equipped with Apple's first 3D camera to capture and relive memories with spatial audio. Bringing a new dimension to personal computing, Apple Vision Pro is set to transform the way users interact with technology.

The announcement has led to a discussion on Hacker News about the device, with users expressing their enthusiasm and skepticism about the new computer. Some comments point out that it’s an expensive device that lacks practicality, whilst others believe it will revolutionize the way we interact with technology. There's a debate on Apple's history of previous product fails, its exclusivity, and the pricing model of its current products.

### Flora Incognita – free AI-supported plant identification university project

#### [Submission URL](https://floraincognita.com/) | 101 points | by [retro_guy](https://news.ycombinator.com/user?id=retro_guy) | [26 comments](https://news.ycombinator.com/item?id=36201143)

The Flora Incognita app is an AI-supported plant identification app that allows users to identify more than 16,000 plant species and contribute to science by saving their observations. The app is free and does not have any advertising, and it even works without a constant internet connection, making it a perfect tool for educational purposes. The app is part of the research project Flora Incognita++, which combines AI-supported plant identification with citizen science. This project is a crucial step in creating momentum for environmental and biodiversity research.

The Flora Incognita app is discussed among users on Hacker News. While some users suggest other plant identification apps, others praise Flora Incognita for its accuracy in identifying plants. The discussion also touches on the importance of citizen science and the potential for location data to contribute to environmental research. Additionally, some users discuss the limitations of AI in plant identification and the various business models for plant identification apps. Some also compare Flora Incognita to other efforts in California and Germany for environmental research.

### Apple Introduces M2 Ultra

#### [Submission URL](https://www.apple.com/newsroom/2023/06/apple-introduces-m2-ultra/) | 361 points | by [0xedb](https://news.ycombinator.com/user?id=0xedb) | [349 comments](https://news.ycombinator.com/item?id=36199637)

Apple has introduced M2 Ultra, the largest and most advanced chip developed by the company so far. With its faster CPU and GPU, as well as support for even more unified memory, the M2 Ultra makes the new Mac Studio and Mac Pro the most powerful Mac desktops ever created. Featuring a second-generation 5-nanometer process, the M2 Ultra doubles the performance and consists of 134 billion transistors, 20 billion more than its predecessor, the M1 Ultra. Apple's UltraFusion packaging technology connects the die of two M2 Max chips, creating the M2 Ultra, which features a more powerful CPU, larger GPU, and a Neural Engine that boosts performance by up to 40%.

Apple has introduced the M2 Ultra chip, the largest and most advanced chip developed by the company so far, doubling performance and consisting of 134 billion transistors. The comments on Hacker News debated the advantages and disadvantages of Apple's design choices, including the use of soldered memory, Apple's pricing, and limitations on upgrading parts. Some users praised Apple's design and stated that the company's high prices are justifiable for the quality of their products, while others criticized Apple's business practices and argued that they limit competition. Overall, the discussion revealed a range of opinions on Apple's approach to hardware design and its impact on consumers.

### Open-Source Data Collection Platform for LLM Fine-Tuning and RLHF

#### [Submission URL](https://argilla.io/blog/argilla-for-llms/) | 112 points | by [dvilasuero](https://news.ycombinator.com/user?id=dvilasuero) | [11 comments](https://news.ycombinator.com/item?id=36199911)

Argilla Feedback, an open-source enterprise-level solution focused on scalable human feedback collection, has been released by Argilla Team. The platform boosts the performance and safety of Large Language Models (LLMs) by providing a flexible platform for monitoring, evaluation, fine-tuning, and reinforcement learning from human feedback. Argilla Feedback supports continuous feedback collection for LLM applications with its integration with LangChain and facilitates the gathering of human-guided examples for supervised fine-tuning and instruction-tuning. Argilla Feedback integrates into the MLOps stack for continuous data and model refinement.

The comments on the submission discussed the differences between Argilla and other platforms in the market, how it integrates into the MLOps stack, and its data labeling capabilities. Some users appreciated that Argilla is open source, while others speculated on potential use cases for the platform. Additionally, a user who had experience with the platform commented that it was a good platform for data-centric NLP features.

### Apple unveils new Mac Studio and brings Apple Silicon to Mac Pro

#### [Submission URL](https://www.apple.com/newsroom/2023/06/apple-unveils-new-mac-studio-and-brings-apple-silicon-to-mac-pro/) | 445 points | by [0xedb](https://news.ycombinator.com/user?id=0xedb) | [379 comments](https://news.ycombinator.com/item?id=36199639)

In an event today, Apple unveiled its newest products: the Mac Studio and Mac Pro. These are the most powerful Macs ever made, featuring M2 Max and M2 Ultra chips that deliver extraordinary performance and connectivity. The Mac Studio is 6x faster than the most powerful Intel-based 27-inch iMac and up to 3x faster than the previous-generation Mac Studio with M1 Ultra. The Mac Pro combines the incredible performance of Apple's most powerful chip, the M2 Ultra, with the versatility of PCIe expansion. Both devices are available for order now, with availability starting on June 13th.

The discussion on Hacker News revolved around the terminology used to describe the devices, with some users criticising the marketing-speak used by Apple, while others debated the technical aspects of artificial intelligence and machine learning. Some users also mentioned weaknesses in Apple's Siri and the overuse of the term "AI". Overall, the discussion was a mix of technical and critical commentary on Apple's latest products and the terminology used to describe them.

### AI does not help programmers

#### [Submission URL](https://cacm.acm.org/blogs/blog-cacm/273577-ai-does-not-help-programmers/fulltext) | 86 points | by [zdw](https://news.ycombinator.com/user?id=zdw) | [96 comments](https://news.ycombinator.com/item?id=36202543)

In a recent blog post on Communications of the ACM, Bertrand Meyer discusses the limitations of AI when it comes to programming. While many people have touted AI as the future of programming, Meyer argues that the technology is still far too fallible and unreliable to replace human programmers. He notes that while AI may be able to generate convincing results quickly, it can never guarantee the correctness of a program. Ultimately, Meyer concludes that AI tools can be useful in many areas, but programming is not one of them.

Bertrand Meyer's recent article on Communications of the ACM, which argues against using AI in programming due to its lack of reliability and inability to guarantee correctness, sparked a discussion on Hacker News. Many users shared their experiences using AI programming tools like Github Copilot and ChatGPT. Some users found the tools greatly helpful for quick testing and implementation, while others pointed out their limitations and occasional failures. Some users stressed the importance of learning programming fundamentals and criticized over-reliance on AI tools. Other users discussed the potential ethical implications of relying solely on AI-generated code. Overall, the discussion highlights the pros and cons of AI programming tools and raises interesting questions about the future of programming.

### Paralyzed man walks naturally, thanks to wireless bridge between brain and spine

#### [Submission URL](https://www.science.org/content/article/paralyzed-man-walks-naturally-thanks-wireless-bridge-brain-spine) | 39 points | by [semihsalihoglu](https://news.ycombinator.com/user?id=semihsalihoglu) | [5 comments](https://news.ycombinator.com/item?id=36192576)

A Dutch man who lost his ability to walk after a spinal cord injury in 2011 can now walk more fluidly following a procedure to connect his brain and lower body. Scientists implanted an array of electrodes on top of the spinal cord to stimulate nerve function, and then signal brain thoughts to the spinal stimulator, facilitating the movement. The latest approach combines two already established procedures, spinal stimulation and brain interfaces in a new way. After 40 training sessions, the patient can walk, stand and climb staircases and, even when the devices are turned off, the benefits appear to persist, with one researcher suggesting it could be "a huge step forward".

The discussion is largely focused on the technology used for the procedure and its potential future applications. One user mentions another similar approach that involved capturing signals from the brain to control a cursor on a screen. Another user comments on the impressive nature of the implant and how it can manipulate muscles. There is also a discussion of a hypothetical startup that offers a service to permanently connect the spinal cord to a virtual desk and gym for fitness purposes.

### Generative AI learning path

#### [Submission URL](https://www.cloudskillsboost.google/paths/118) | 488 points | by [sh_tomer](https://news.ycombinator.com/user?id=sh_tomer) | [120 comments](https://news.ycombinator.com/item?id=36192195)

Google Cloud has launched a new learning path focused on Generative AI, which aims to provide users with a curated collection of content to learn everything from the basics of large language models to how to create and deploy generative AI solutions using the Google Cloud platform. The learning path is managed by Google Cloud and includes 10 distinct learning activities. It was last updated just two days ago, indicating that the content is up-to-date and relevant to current industry trends.

Google Cloud has launched a new learning path for Generative AI that includes ten learning activities. As per the discussion, people tend to have mixed feelings about the actual usefulness of the program, with some users stating that they have had issues with Qwiklabs and are yet to complete the training. Others provided helpful resources on AI learning, and some users criticized Google for its compliance and integration practices with other companies. There were comments about the difficulty of navigating Google's certification program and the high cost of resources required for labs. The discussion also touched on the accessible language used in the program and the skepticism around corporate speak. The comments also branched out into broader topics such as corporate ethics, and contributions made by Facebook, Google, and Apple towards AI research.

### Stack Overflow Moderators Striking to Stop Garbage AI Content from Flooding Site

#### [Submission URL](https://www.vice.com/en/article/4a33dj/stack-overflow-moderators-are-striking-to-stop-garbage-ai-content-from-flooding-the-site) | 41 points | by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) | [35 comments](https://news.ycombinator.com/item?id=36205043)

Volunteer moderators at Stack Overflow have gone on strike over the company’s new AI content policy, which they say will allow for the proliferation of false information on the site. The policy, implemented in May, allows for all GPT-generated content and prohibits moderators from moderating AI-generated content simply for being AI-generated. The moderators claim that AI chatbots like ChatGPT do not understand the information they provide and that allowing unfettered access to this content threatens the quality and accuracy of Stack Exchange’s information. They are also demanding greater transparency from the site’s owners, Stack Overflow, Inc.

Some commenters argue for increasing the use of AI-generated content, while others argue that the focus should be on improving moderation and verification processes rather than relying on AI-generated content. Some suggest that paid services may help alleviate some of the moderation issues. There is also discussion around the importance of verifying the accuracy of AI-generated content and the difficulty in detecting and preventing spamming.

### A prompt pattern catalog to enhance prompt engineering with ChatGPT

#### [Submission URL](https://arxiv.org/abs/2302.11382) | 124 points | by [aliparlakci](https://news.ycombinator.com/user?id=aliparlakci) | [23 comments](https://news.ycombinator.com/item?id=36196113)

Researchers have created a catalog of prompt engineering techniques presented in pattern-form that can be applied to improve conversations with large language models such as ChatGPT. Prompts enforce rules, automate processes, and ensure specific qualities of generated output, and can be thought of as a form of programming that customizes output and interaction with LLMs. The prompt pattern catalog provides a framework for documenting patterns for structuring prompts to solve common problems faced when conversing with LLMs. The research provides a catalog of prompt patterns that have been applied successfully to improve the outputs of LLM conversations and demonstrates how prompts can be built from multiple patterns. This research is expected to be particularly useful in automating software development tasks. The discussion includes links to related research papers and tutorials, as well as different perspectives on the term "prompt engineering," with some commenters arguing that the term is misleading or not applicable in certain contexts.

### Microsoft Kills Cortana in Windows

#### [Submission URL](https://www.thurrott.com/windows/windows-11/283998/microsoft-kills-cortana-in-windows) | 27 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [7 comments](https://news.ycombinator.com/item?id=36199882)

Microsoft has announced that it will no longer support its AI assistant, Cortana, as a standalone app on both Windows 10 and 11 starting from late 2023. The focus will now be on leveraging AI capabilities embedded in Edge and Windows instead. In 2019, the CEO of the tech giant acknowledged that Cortana would never be on par with Alexa or Google Assistant. Since then, the app has been gradually phased out, with Microsoft officially ending support for its Cortana app on Android and iOS earlier this year. Microsoft Copilot branding will instead take center stage as the new AI wave takes over Windows and beyond.

The discussion on the submission revolves around Microsoft's history of introducing new and hyped-up products that are later discontinued. Some users mention cases such as the Windows Phone as an example. Some commenters criticize Microsoft's focus on launching a new AI character rather than improving Cortana. Others express their relief that the outdated app will be phased out, while some users humorously suggest the return of an old Microsoft character like Clippy.

---

## AI Submissions for Sun Jun 04 2023 {{ 'date': '2023-06-04T17:11:31.694Z' }}

### It’s infuriatingly hard to understand how closed models train on their input

#### [Submission URL](https://simonwillison.net/2023/Jun/4/closed-model-training/) | 294 points | by [simonw](https://news.ycombinator.com/user?id=simonw) | [199 comments](https://news.ycombinator.com/item?id=36187994)

Large language models like GPT-3 and Google's PaLM and PaLM 2 are raising concerns about the transparency of their training data. The builders of these closed models are not revealing what's in their training data, which makes it difficult to know if private data is being used to train future versions of these models. OpenAI has a policy regarding data submitted by customers via their API, but it's unclear how data is being used for ChatGPT itself. There's a risk that an AI vendor might log inputs to their models, suffer from a security flaw, and expose that data to attackers. While companies have been trusting their private data to cloud providers like AWS and Google Cloud for years, these AI companies have much less of a track record for staying secure.

According to the discussion, OpenAI has a policy regarding data submitted by customers, but it is unclear how data is being used for ChatGPT itself. The risk of using private data to train these models and the possibility of a security flaw exposing that data to attackers is causing concern for researchers and consumers. The lack of transparency in these models is leading to suspicions that AI vendors might disclose trade secrets and commercial interests of their customers. Additionally, there is a debate on whether these models infringe on copyrighted material, such as artwork or photography. The discussion concludes with points on the complexity of understanding the training data and the benchmark results of LLM models.

### Reverse Engineering Self-Supervised Learning

#### [Submission URL](https://arxiv.org/abs/2305.15614) | 82 points | by [headalgorithm](https://news.ycombinator.com/user?id=headalgorithm) | [16 comments](https://news.ycombinator.com/item?id=36184838)

A group of researchers has conducted a study aimed at better understanding the mechanisms behind self-supervised learning (SSL), a technique used to train machine learning models without the need for labeled data. The team found that SSL inherently clusters samples with respect to semantic labels, leading to enhanced downstream classification and compressed data information. The researchers also discovered that SSL-trained representations align more closely with semantic classes rather than random classes, and that this alignment increases during training and deeper within the network. The study provides valuable insights into how SSL learns representations and its impact on performance across different sets of classes.

The comments mainly discuss the validity of machine learning and modern AI, with some users being skeptical about its efficiency in recognizing semantic and non-semantic data. There is also a discussion about the appropriateness of the paper's title and the use of flashy names. However, some users appreciate the study and expect to learn from it. The thread also includes a conversation about the importance of empirical studies and the effectiveness of various methods in data analysis.

### The AI firm that conducted ‘state surveillance’ of your social media posts

#### [Submission URL](https://www.telegraph.co.uk/news/2023/06/03/logically-ai-firm-social-media-posts-covid/) | 84 points | by [perihelions](https://news.ycombinator.com/user?id=perihelions) | [17 comments](https://news.ycombinator.com/item?id=36185052)

The UK government has paid over £1.2m of taxpayers' money to AI company Logically to analyse "disinformation" and "misinformation" on social media. Logically's technology ingests material from hundreds of thousands of media sources and public posts on major social media platforms to identify potentially problematic posts. The company claims to have "one of the world’s largest dedicated fact-checking teams", spread across the UK, Europe and India. Logically has been contracted by the Department for Culture, Media and Sport to deliver "analytical support" and to support cross-Government efforts to curtail potentially harmful misinformation. Facebook has also granted Logically influence over the content other people may view through a partnership that allows the site to reduce the distribution of posts labelled false by Logically, which has sparked concerns among campaigners for freedom of speech. Commenters debated issues such as the legitimacy of government intervention on the public's speech and the potential for algorithms to generate propaganda themselves. Some suggested alternatives like decentralized algorithms and regulation of algorithmic bias.

### We need to keep CEOs away from AI regulation

#### [Submission URL](https://www.ft.com/content/5f8b74f7-68b1-4a6c-88bf-d0dd03579149) | 50 points | by [belter](https://news.ycombinator.com/user?id=belter) | [8 comments](https://news.ycombinator.com/item?id=36188047)

The Financial Times published an opinion piece arguing that CEOs should not be the ones regulating AI and that it should be left to experts in the field. The article highlights that CEOs may have a greater focus on profits and shareholder value rather than societal implications, and that AI regulation needs to be approached in a way that prioritizes public benefit and ethics. The piece also discusses the potential risks of biased AI algorithms and the need for diverse perspectives in the development and regulation of AI.

The discussion in the comments includes a range of opinions on the topic. Some users argue that CEOs should not have control over AI regulation and stress the importance of transparency and diverse perspectives. Other users suggest that the private sector should be trusted to regulate AI and that concerns about potential risks are overblown. Some users also discuss the need for privacy legislation like GDPR and the potential misuse of AI technology for profit. One user shares a video discussing the financial opportunities of AI. Another user mentions concerns about how companies like Instagram are using AI technology for profit.

### GitHub Private Repos Considered Private-­Ish

#### [Submission URL](https://tylercipriani.com/blog/2023/03/31/private-ish-github-repos/) | 160 points | by [fagnerbrack](https://news.ycombinator.com/user?id=fagnerbrack) | [140 comments](https://news.ycombinator.com/item?id=36184948)

This week, GitHub.com's RSA SSH private key was briefly exposed in a public GitHub repository. Private repositories can become public in various ways, such as publishing the .git directory, getting phished, or accidentally clicking the wrong button. Mitigations include keeping the .git directory private, setting up two-factor authentication, and auditing access control. However, the best solution is to avoid putting sensitive data in private repositories altogether. Developers can use secret scanners as pre-commit git hooks and inject secrets into applications at runtime. The discussion includes comments related to Microsoft's reputation, the theft of intellectual property, and the need for privacy statements in AI training programs. Overall, the discussion revolves around best practices for protecting sensitive data and intellectual property.

### AI Report #4: AutoGPT And Open-source lags behind Part 2

#### [Submission URL](https://theaireport.substack.com/p/ai-report-4-autogpt-and-open-source) | 57 points | by [primordialsoup](https://news.ycombinator.com/user?id=primordialsoup) | [35 comments](https://news.ycombinator.com/item?id=36186348)

In the latest AI Report, it is noted that open-source has been lagging behind in AI development, and there are two directions that need improvement: training a better base LLM and getting better at RLHF. Meanwhile, AutoGPT, which has 136k stars in GitHub, and similar repository BabyAGI, which has 14k stars, have not produced anything concrete and there has been some over-promising on their capabilities. The report suggests that more research is needed in this area to achieve success, and perhaps building agents that excel at specific, well-defined tasks before composing them together may be the way forward. The report also features papers on improving language models and verifying training methods. The comments section discusses various experiences with AI tools and APIs, and some users suggest focusing on low-level abstractions and tool-making patterns to make the development of AI more accessible. Users also point out the limitations and challenges of current AI technology.

### Rambling about Microsoft, and testing alternatives to GitHub Copilot

#### [Submission URL](https://poignardazur.github.io//2023/06/04/microsoft-copilot-alternatives/) | 12 points | by [PoignardAzur](https://news.ycombinator.com/user?id=PoignardAzur) | [4 comments](https://news.ycombinator.com/item?id=36184860)

Today's top story on Hacker News is a post about Microsoft's recent release of Copilot. The author discusses how Microsoft's decision to keep the project proprietary and use open-source projects to train the AI may cost them more than if they had released Copilot in a more open way. This led the author to question how viable the alternatives to Copilot are and the quality of their AI. The author also explores the controversy surrounding the training of Copilot and other AI models, discussing the ethics of using public domain data without informed consent. The author's hot take is that AI developers should not be expected to ask for consent whenever they use public domain data, to incentivize people to create more stuff.

---

## AI Submissions for Thu Jun 01 2023 {{ 'date': '2023-06-01T17:10:46.432Z' }}

### Notes on training BERT from scratch on an 8GB consumer GPU

#### [Submission URL](https://sidsite.com/posts/bert-from-scratch/) | 153 points | by [montebicyclelo](https://news.ycombinator.com/user?id=montebicyclelo) | [39 comments](https://news.ycombinator.com/item?id=36157438)

A developer has trained a language model, using BERT (Bidirectional Encoder Representations for Transformers), from scratch on a single desktop PC. The model architecture, tokenizer, and trainer all came from Hugging Face libraries, and it was trained on 20GB of uncompressed text, achieving results comparable to large language models that require clusters of GPUs or TPUs to train. The developer used the code to train the model for four days, fine-tuning it on the GLUE benchmark, and achieved good results after just one epoch. The model's GLUE-dev score was provided, indicating its performance at natural language tasks, and the training results were compared to those achieved by BERT-base.

The discussion covers issues such as the memory and execution time needed for training, the use of GPUs and TPUs to accelerate deep learning, and the relevance of AMD in ML progress. Moreover, the comments also touch upon topics such as the effectiveness of pre-training, the advantages and disadvantages of frameworks, and the limited training time of models.

### Show HN: TodoBot is an AI coach that helps you write a better todo list

#### [Submission URL](https://todobot.ai/) | 37 points | by [greytape](https://news.ycombinator.com/user?id=greytape) | [24 comments](https://news.ycombinator.com/item?id=36151056)

Looking for a personal assistant to help you manage your daily tasks? Look no further than TodoBot, the AI-powered to-do list app with an inbuilt virtual coach. With our intelligent assistant, you can break complex tasks into smaller, more manageable steps, making it easier to tackle projects and maintain momentum. Plus, we use the latest research to help you organize your daily life and offer personalized coaching to help you stay on track. So why not get started with TodoBot today and take control of your to-do list? And if you want to stay up-to-date on similar upcoming projects, sign up for our newsletter!

Some users prefer more concise to-do lists, while others find detailed lists helpful. There are suggestions to integrate the app with other project management tools like Jira and Obsidian, as well as some critiques and skepticism about how helpful the app actually is. The topic also veers into discussions about language models like GPT-3 and OpenAI's accountability. Overall, the reviews and suggestions are mixed, but there is interest in exploring the potential of AI-powered productivity apps.

### Show HN: Git credential helper using OAuth in browser

#### [Submission URL](https://github.com/hickford/git-credential-oauth) | 71 points | by [mattme](https://news.ycombinator.com/user?id=mattme) | [17 comments](https://news.ycombinator.com/item?id=36148217)

Git-credential-oauth is a Git credential helper that provides secure authentication to GitHub, GitLab, BitBucket, and Gerrit using OAuth. This tool eliminates the need for users to remember passwords and store personal access tokens securely. Instead, git-credential-oauth leverages OAuth and its advantages over personal access tokens or SSH, including the ability to authenticate users to popular hosts without setup, clone public repositories without setup, and automatically verify server authenticity. Users can download the binary from the official website or install it using a package manager on various Linux distributions.

The submission is about a new Git credential helper called `git-credential-oauth`, which allows developers to authenticate with Git hosts like GitHub, GitLab, BitBucket, and Gerrit using OAuth instead of personal access tokens or SSH. The discussion in the comments covers topics such as the challenges of installing and using .NET applications on Linux distributions, how OAuth credential helpers work, and issues with securely managing client secrets. Some users shared their experience of downloading and installing the binary, while others discussed Git's behavior when running binary files and the potential security risks. Overall, users were interested in the benefits of using `git-credential-oauth` but had some concerns about its implementation, especially in terms of security.

### Microsoft inks deal with CoreWeave to meet OpenAI cloud demand

#### [Submission URL](https://www.cnbc.com/2023/06/01/microsoft-inks-deal-with-coreweave-to-meet-openai-cloud-demand.html) | 47 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [16 comments](https://news.ycombinator.com/item?id=36155028)

Microsoft has reportedly agreed to spend potentially billions of dollars over multiple years on cloud computing infrastructure from CoreWeave, a startup that offers Nvidia graphics processing units (GPUs) and rents them out to other companies. The computing power is to ensure that OpenAI, a platform relies on Microsoft's Azure cloud infrastructure for its hefty compute needs and operates the viral ChatGPT chatbot, will have adequate computing power going forward. Nvidia has invested $100m in CoreWeave, which was valued at $2bn in April and which has concurrent financing from hedge fund Magnetar Capital.

The discussion on this submission is centered around CoreWeave's use of GPUs in Ethereum mining and the implications it might have for AI model services. One user points out that mining with consumer-grade GPUs is not ideal for data centers because they cannot support point warranties. Another user suggests that CoreWeave might have converted their mining business into an AI model service business, and mentions that Nvidia's hardware is suitable for both cryptocurrency mining and AI applications. Another user discusses the challenges of integrating software and hardware in building a custom chip. There is also a discussion on whether AI can produce sophisticated responses similar to those produced by humans.

### Measuring the productivity impact of generative AI

#### [Submission URL](https://www.nber.org/digest/measuring-productivity-impact-generative-ai) | 88 points | by [hhs](https://news.ycombinator.com/user?id=hhs) | [100 comments](https://news.ycombinator.com/item?id=36152510)

According to a working paper from the National Bureau of Economic Research, the productivity of customer support agents increased by nearly 14% after they were given access to a Generative Pre-trained Transformer (GPT) AI tool. The tool provided possible responses to customer queries, which agents could choose to use or not. Analysis of call data from roughly 5k agents found that handling more calls per hour increased resolution rates, while satisfaction rates remained stable. Interestingly, less experienced agents and those with lower skillsets benefited the most, improving their performance by 35% with no negative effects on their top-performing peers.

Some users compare it to their own experiences using different programming languages and frameworks, while others express skepticism about the accuracy of such measurements. Other users point out that the GPT AI tool seemed to benefit less experienced agents and those with lower skill sets the most. The discussion then gets into the broader implications of AI in the workplace, with some users expressing concern about the potential impact on skilled workers and the power dynamics in the workplace. Finally, some users suggest that the real issue may be the concentration of power that AI technology allows, and its potential to exacerbate existing inequalities in the workforce.

### Show HN: Word2vec Algorithm in ~100sloc with NumPy

#### [Submission URL](https://github.com/JosephSBoyle/skip_gram/blob/346f79ff948ef3d279558a9460c44e7f7598fb7d/skip_gram/main.py) | 68 points | by [extasia](https://news.ycombinator.com/user?id=extasia) | [27 comments](https://news.ycombinator.com/item?id=36149620)

This code is a Python implementation of the skip-gram (word2vec) training on Spanish text. It trains a word-to-vector dictionary using the skip-gram algorithm from Mikolov et. al. Some key notes about the implementation include: it uses two embeddings per-word, one when the word is a context and one for when the word is a target; it can represent words as the sum of these two vectors, or simply throw away the context vector and use the target one; and it uses the dot product between two word vectors to represent the similarity between two words. The code also offers a rigorous explanation about the training algorithm. The discussion included topics such as the usefulness of contextual embeddings, the advantages of implementing the code in Jax, and the importance of handling rare words and stop words. One user shared a link to the Gensim package as a golden standard for word2vec modeling.

### SvelteKit with Integrated WebSocket Server

#### [Submission URL](https://github.com/suhaildawood/SvelteKit-integrated-WebSocket) | 27 points | by [luu](https://news.ycombinator.com/user?id=luu) | [10 comments](https://news.ycombinator.com/item?id=36146800)

Suhail Dawood has updated his SvelteKit with Integrated WebSocket Server project to be compliant with SvelteKit 1.15.7. Despite the stable release not providing out-of-the-box support for WebSocket integration, the project provides a solution by attaching a WebSocket server to the global state. This approach offers co-located server-side code within the SvelteKit project structure, allowing for sharing of utilities, logic and types across the codebase. However, changes made to WebSocket logic require the middleware to be rebuilt and the server to be restarted, temporarily disrupting WebSocket functionality.

In the discussion, users express their opinions about other popular front-end frameworks and back-end frameworks and which one works best for their projects. There is also discussion about the use of InertiaJS and integrating Svelte with Fastify. Some users express concern about using front-end frameworks that are platform-agnostic, while others argue that back-end frameworks will always be necessary. Additionally, there is a conversation about the challenges of working with SvelteKit and maintaining back-end code. Finally, some users discuss their experience using custom servers with frameworks like NextJS and express dissatisfaction with newer versions that make things more complicated.

### OpenAI Cybersecurity Grant Program

#### [Submission URL](https://openai.com/blog/openai-cybersecurity-grant-program) | 87 points | by [staranjeet](https://news.ycombinator.com/user?id=staranjeet) | [37 comments](https://news.ycombinator.com/item?id=36154135)

OpenAI has launched the Cybersecurity Grant Program, a $1 million initiative aimed at developing AI-powered cybersecurity capabilities for defenders. The program seeks to empower defenders by using cutting-edge AI capabilities to prioritize cybersecurity, while also measuring the cybersecurity capabilities of AI models and fostering discussions at the intersection of AI and cybersecurity. The project is geared towards projects such as task automation, assisting security engineers and developers to create robust threat models, producing threat intelligence with salient and relevant information for defenders tailored to their organization, and developing methods for quantifying the cybersecurity capabilities of AI models. The initiative will accept strong, practical applications of AI in defensive cybersecurity on a rolling basis. Offensive-security projects will not be funded at this time.

Discussions revolved around the recognition of the hacking community's contribution to cybersecurity research, the potential effectiveness and limitations of AI-secured networks, and the correlation between understanding code and language to develop more complex AI models. There were concerns about how the grant funding would be allocated by OpenAI.

---

## AI Submissions for Wed May 31 2023 {{ 'date': '2023-05-31T17:14:11.288Z' }}

### Nvidia DGX GH200: 100 Terabyte GPU Memory System

#### [Submission URL](https://developer.nvidia.com/blog/announcing-nvidia-dgx-gh200-first-100-terabyte-gpu-memory-system/) | 532 points | by [MacsHeadroom](https://news.ycombinator.com/user?id=MacsHeadroom) | [360 comments](https://news.ycombinator.com/item?id=36133226)

NVIDIA has announced the DGX GH200, which delivers a generational leap in GPU memory performance and is designed to empower scientists to solve extraordinary challenges. The DGX GH200 pairs the NVIDIA Grace Hopper Superchip with the NVLink Switch System to unite up to 256 GPUs in a single system, providing 144 terabytes of memory that has access to the GPU shared memory programming model at high speed over NVLink. This breakthrough in GPU-accelerated computing paves the way for giant, trillion-parameter AI models that can't be solved on today's best supercomputers. The comments discuss the system's capabilities and compare it to Google's TPUv4. Some also explore the topic of artificial intelligence in general, its limitations, and the way it impacts various facets of businesses and customers.

### Japan’s government will not enforce copyrights on data used in AI training

#### [Submission URL](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/) | 446 points | by [version_five](https://news.ycombinator.com/user?id=version_five) | [359 comments](https://news.ycombinator.com/item?id=36144241)

Japan has announced that it will not enforce copyrights on data used in AI training, allowing AI to use any data, regardless of its source or intended use. While the move has received pushback from some of Japan's artists, many in academia and the business sector are hoping to leverage the country's relaxed data laws to become a major global player in AI technology. With the lowest per-capita income in the G-7 and years of low growth, the implementation of AI could potentially boost Japan's GDP by 50% or more in a short time. The move also adds a new dynamic to the ongoing regulation debate, as the world's third-largest economy is saying it won't hinder AI research and development, and is prepared to leverage this new technology to compete directly with the West.

In the comments, there is a discussion about the implications of this decision. Some users argue that allowing AI to use copyrighted material without permission is not fair to the original authors, while others believe that the benefits of advancing AI technology outweigh the potential negative impact on copyright holders. One user suggests that the issue is not with the existing copyright law, but with regulating the industry as a whole. Others argue that humans learned and studied from existing culture and literature, and that the same should apply for AI. One user suggests that lossy training data has value, and copyright holders launching a lawsuit could prevent people from accessing valuable data. Another proposes that copyright is important and is different for machines than for humans. Overall, there are arguments made both for and against the relaxation of copyright laws for AI training purposes.

### OpenAI's plans according to sama

#### [Submission URL](https://humanloop.com/blog/open_ai_talk) | 297 points | by [razcle](https://news.ycombinator.com/user?id=razcle) | [237 comments](https://news.ycombinator.com/item?id=36141544)

Last week, OpenAI's Sam Altman met with developers to discuss the company's API and product plans. The main takeaway is that the company is heavily GPU-limited, causing delays in its short-term plans. To improve the API reliability and speed, OpenAI's top priority is cheaper and faster GPT-4. Additionally, the company will extend the finetuning API to the latest models, develop a stateful API and work on multimodality for GPT-4. OpenAI will also avoid competing with its customers and is considering open-sourcing GPT-3 while calling for regulation of future models. Finally, the scaling laws for model performance continue to hold, leading to significant implications for AGI development.

In the comments, there is discussion about OpenAI's potential open-sourcing of GPT-3, avoiding competition with customers, and considering regulations for future models. There is also debate about the benefits and drawbacks of small teams sourcing big tech, as well as discussion around the need for open-source community efforts to stabilize the diffusion of GPT models. Some commenters question the efficiency of GPUs, while others discuss the challenges of making OpenAI products accessible to developers.

### Show HN: Lance – Alternative to Parquet for ML data

#### [Submission URL](https://github.com/lancedb/lance) | 78 points | by [chop](https://news.ycombinator.com/user?id=chop) | [16 comments](https://news.ycombinator.com/item?id=36144450)

Lance, a modern columnar data format optimized for machine learning workflows and datasets, has been released. It offers faster random access, vector search, data versioning, and ecosystem integrations with PyArrow, Pandas, Polars, DuckDB, and more. Lance is suitable for building search engines, storing and querying deeply nested data, and large-scale ML training. It claims to be 100 times faster than Parquet without sacrificing scan performance. Lance also enables users to manage versions of their data without requiring extra infrastructure.

The comments discuss Lance's benefits for various applications, such as building search engines, storing and querying deeply nested data, and large-scale ML training. One user compares Lance to the Parquet format and another raises the question of Lance's compatibility with Java. There are also discussions around the Lance file directory structure, its implementation in different languages, and its compatibility with different systems. A user also points out issues with accessing Lance's Github page.

### AI21 Labs concludes largest Turing Test experiment to date

#### [Submission URL](https://www.ai21.com/blog/human-or-not-results) | 96 points | by [kennyfrc](https://news.ycombinator.com/user?id=kennyfrc) | [39 comments](https://news.ycombinator.com/item?id=36137897)

AI21 Labs has conducted the largest Turing Test in history with more than 10 million conversations having been conducted in their social Turing game "Human or Not?" in which participants guess whether they are talking to a human or a machine. The initial results found that 68% of people guessed correctly, with people more successfully differentiating between humans and AI bots when talking to humans (73%) than bots (60%). Furthermore, the data shows that younger age groups tend to have correct guesses at slightly higher rates than older age groups, and that participants made certain assumptions about AI bots, such as they don't make typos or use slang, aren't aware of current events, and that they have no personal background. The discussion includes comments about the limitations of the test and the strategies used by AI models to target weaknesses. Some participants found the test confusing or limited in its scope. Others found it entertaining and worth playing.

### AI intensifies fight against ‘paper mills’ that churn out fake research

#### [Submission URL](https://www.nature.com/articles/d41586-023-01780-w) | 189 points | by [headalgorithm](https://news.ycombinator.com/user?id=headalgorithm) | [172 comments](https://news.ycombinator.com/item?id=36139349)

Artificial intelligence (AI) is posing challenges to publishers in their efforts to tackle the problem of paper mills, which are companies that produce fake scientific papers to order. Generative AI tools, such as chatbots and image-generating software, create ways of producing paper-mill content that can be difficult to detect. Experts at a recent research-integrity summit discussed synthetic images and text as pose a similar challenge. The event was convened by the Committee on Publication Ethics and the International Association of Scientific, Technical and Medical Publishers, and brought together researchers, independent research-integrity analysts, funders and publishers.

The comments discuss various related issues, including the problems with the current scientific system, the importance and challenges of peer review, and the limitations of peer review in catching errors in experimental and statistical analyses. There is also discussion on the need for better data sharing practices and the challenges of reproducing research results.

### AI camera with no lens

#### [Submission URL](https://www.theprompt.io/p/ai-camera-no-lens) | 280 points | by [anitakirkovska](https://news.ycombinator.com/user?id=anitakirkovska) | [81 comments](https://news.ycombinator.com/item?id=36139729)

A new AI camera called Paragraphica is changing the game of photography by taking photos using GPS data instead of a lens. The camera collects various data from its location through open APIs such as current weather, time of day, address, and nearby places to create a detailed description of the current place and moment. It then converts this description into an AI-generated "photo" using Stable Diffusion. Meanwhile, Google's latest speech model, SoundStorm, is challenging other AI-generated speech models by creating 30 seconds of speech in half a second and specializing in highly realistic dialogues. Other developments in the AI world include Nvidia's recent announcement of their DGX GH200 AI supercomputer, GitHub's One-Click DeepFake, and Andrew Karpathy's latest talk at the Microsoft Build conference on the state of GPT.

However, some commenters on Hacker News pointed out that a similar idea had been introduced in the 2000s using a camera that matched GPS coordinates and time of day with Flickr images. Others discussed the merits of traditional photography vs. AI-generated images. In addition to the Paragraphica camera, Google's SoundStorm speech model, NVIDIA's DGX GH200 AI supercomputer, GitHub's One-Click DeepFake, and Andrew Karpathy's latest talk on GPT for the Microsoft Build conference were also mentioned. Some commenters expressed concerns about the potential for AI-generated sketches to perpetuate racism, while others shared their experiences with traditional sketch artists and the limitations of human memory in capturing details. One user also mentioned the potential for AI-generated sketches to enhance police sketches.

### Train Your Own Private ChatGPT Model for the Cost of a Starbucks Coffee

#### [Submission URL](https://medium.com/@ApacheDolphinScheduler/train-your-own-private-chatgpt-model-for-the-cost-of-a-starbucks-coffee-25c588f450ee) | 72 points | by [DSOfficial](https://news.ycombinator.com/user?id=DSOfficial) | [16 comments](https://news.ycombinator.com/item?id=36136318)

With just the cost of a Starbucks coffee and a couple of hours of your time, you can now train your own open-source large-scale model using Apache DolphinScheduler. This model can be fine-tuned to enhance various skills, such as medical, programming, stock trading, and love advice, thus making it more "understanding" of you. With this, you can have your personal AI assistant that understands and responds to you better. Apache DolphinScheduler provides one-click support for training, tuning, and deploying open-source large-scale models, making it accessible to anyone interested in GPT and not just AI professionals. The whole process takes only three steps and around 20 hours of running time to build your ChatGPT model that understands and responds to you better.

The discussion on this submission covers a range of topics related to training and using open-source large-scale models. There is some disagreement about the effectiveness of self-training versus proprietary methods developed by companies like Microsoft. Some commenters suggest that domain-specific knowledge is important for organizations and individuals looking to train their own models. Others discuss the technical details of building and training models. One commenter suggests that there may be privacy implications to using a personal AI assistant, and another questions the use of the term "private" in relation to ChatGPT. In the end, the main point of the submission is that it is possible to train your own model using Apache DolphinScheduler for just a small investment in time and money.

---

## AI Submissions for Mon May 29 2023 {{ 'date': '2023-05-29T17:11:35.319Z' }}

### How much would it have cost if GPT-4 had written your code

#### [Submission URL](https://pypi.org/project/cost-of-code/) | 50 points | by [yodon](https://news.ycombinator.com/user?id=yodon) | [66 comments](https://news.ycombinator.com/item?id=36117846)

A new Python package called "cost-of-code" has been released, which calculates how much it would have cost to write a given codebase using OpenAI's GPT-4. The package scans a specified git repository, tokenizes the lines of code using the tiktoken package from OpenAI, and estimates the cost to generate the same amount of tokens using GPT-4 based on the current pricing of $0.06 per 1,000 tokens. This tool provides developers with insight into the potential cost savings of using advanced AI models to generate code. The discussion on Hacker News highlighted the challenges of software engineering including writing code, scalability, maintainability, and problem-solving. The potential benefit of AI-generated code was questioned, while some participants noted that AI may help make developers more efficient. There were also comments on the difficulty of estimating costs accurately and the practicality of using GPT-4 to write complex code. Overall, the discussion raised several technical and practical considerations around using AI in software engineering.

### Donut: OCR-Free Document Understanding Transformer

#### [Submission URL](https://github.com/clovaai/donut) | 300 points | by [hectormalot](https://news.ycombinator.com/user?id=hectormalot) | [85 comments](https://news.ycombinator.com/item?id=36111878)

Clovaai has released the official implementation of OCR-free Document Understanding Transformer (Donut) and Synthetic Document Generator (SynthDoG), which is set to be presented at ECCV 2022. Donut is a new OCR-free document understanding method that uses a Transformer model to achieve state-of-the-art performance on visual document understanding tasks. SynthDoG further helps in model pre-training, making it flexible on various languages and domains. Pre-trained models and web demos are available, and the software installation process is easy with pip installation or cloning the repository.

In the comments, there was a discussion about the effectiveness of traditional OCR approaches, and some users shared their experiences with different OCR software. Some users suggested using PaddleOCR, which yielded good results on reading product labels, while Tesseract struggled with handwriting. Others recommended OCRmyPDF and Textsniper for OCR on PDFs and Mac devices. Additionally, some users talked about the challenges of creating IDP solutions using GNN OCR tokens and the need for smaller graph models that can handle heterogeneous data and classification via OCR. A few users also discussed the limitations of GPT-4 for OCR tasks and suggested the use of general-purpose tools optimized for specific jobs instead.

### Production AI systems are hard

#### [Submission URL](https://methexis.substack.com/p/production-ai-systems-are-really) | 255 points | by [headalgorithm](https://news.ycombinator.com/user?id=headalgorithm) | [135 comments](https://news.ycombinator.com/item?id=36111596)

In a recent post, Kevin Fischer argues that production AI systems are difficult to build and that predictions of AGI taking over every social system are unfounded. Fischer, who obtained one of the first FDA approvals in ML + radiology, talks about the complexity of the radiologist job and how AI can make their work easier, not replace them entirely. He stresses the importance of domain knowledge and implementation details, and cautions against technologists extrapolating capabilities based on a handful of tasks.

In the discussion, some commenters debate the percentage of diagnostic radiologists who would want to review AI output and the practical challenges of implementing AI systems. One commenter shares a personal experience where doctors failed to understand a medical condition, and AI could help with diagnosis. However, there are challenges in sharing medical data to train AI models, and there are variations in medical practices across institutions that make it challenging to standardize AI models. Additionally, there is a discussion about the benefits and limitations of federated learning in radiology projects.

### Connect() – a new API for creating TCP sockets from Cloudflare Workers

#### [Submission URL](https://blog.cloudflare.com/workers-tcp-socket-api-connect-databases/) | 224 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [100 comments](https://news.ycombinator.com/item?id=36111683)

Cloudflare Workers has announced a new API for creating outbound TCP sockets, allowing cloud developers to connect directly to any TCP-based service from Workers, from SMTP and MQTT to SSH and FTP. While Cloudflare already works well with some hosted database providers that allow connections over HTTP or WebSockets, most significant databases require clients to connect via TCP. The new API will enable developers to build full-stack applications on Workers using any database or infrastructure that they choose.

Cloudflare Workers has released a new API for creating outbound TCP sockets, which allows developers to connect directly to any TCP-based service from Workers, such as SMTP, MQTT, SSH, and FTP. While Cloudflare already works well with some hosted database providers that allow connections over HTTP or WebSockets, most significant databases require clients to connect via TCP. The new API will enable developers to build full-stack applications on Workers using any database or infrastructure they choose. 

The comments discuss various topics related to this announcement, including comparisons with other cloud services, concerns about potential security issues, and feedback about the current state of Cloudflare's platform. Some users expressed the belief that Cloudflare is slowly becoming a full-blown platform, and there is some discussion about whether or not this is a good thing. Some users also provided technical insights into the design of the new TCP sockets API and its potential use cases. There is also some discussion about the limitations of Cloudflare's current APIs and the need for better support for database connections. Finally, some users raised concerns about the potential for abuse of the new API by malicious actors, such as those attempting to launch DDoS attacks.

### Nvidia Announces DGX GH200 AI Supercomputer

#### [Submission URL](https://nvidianews.nvidia.com/news/nvidia-announces-dgx-gh200-ai-supercomputer) | 35 points | by [bfoks](https://news.ycombinator.com/user?id=bfoks) | [14 comments](https://news.ycombinator.com/item?id=36113129)

NVIDIA has announced the DGX GH200 AI supercomputer, designed to enable the development of large-scale models for next-generation generative AI language applications, recommender systems, and data analytics workloads. This new class of large-memory AI machine uses NVIDIA's advanced accelerated computing and networking technologies, combining 256 GH200 Grace Hopper Superchips into a massive, single GPU that provides 1 exaflop of performance and 144 terabytes of shared memory. The DGX GH200 uses NVIDIA's NVLink Switch System, which provides 48x more NVLink bandwidth than the previous-generation system, to work as a single GPU, offering the power of a massive AI supercomputer with the simplicity of programming a single GPU. Major tech players including Google Cloud, Meta, and Microsoft are among the first expected to access the DGX GH200 to explore its capabilities for generative AI workloads. NVIDIA is also building its own DGX GH200-based AI supercomputer named Helios, featuring four DGX GH200 systems, which will come online by the end of the year.

NVIDIA has announced DGX GH200, an AI supercomputer that uses advanced accelerated computing and networking technologies to enable the development of next-generation generative AI language applications, recommender systems, and data analytics workloads. The DGX GH200 combines 256 GH200 chips into a single GPU, providing 1 exaflop of performance and 144 terabytes of shared memory. Major tech players are expected to explore the capabilities of the DGX GH200. NVIDIA is also building its own DGX GH200-based AI supercomputer, Helios, featuring four DGX GH200 systems. The comments section discusses the future of computing power and whether technology will lead to the development of micro supercomputers. Some commenters praise NVIDIA's achievement, while others compare it to Tesla's Exapod and criticize its housing principles.

### India ruling party's IT cell used AI to show smile on arrested protesters' faces

#### [Submission URL](https://www.altnews.in/wrestlers-detained-in-delhi-ai-image-of-smiling-vinesh-sangeeta-phogat-viral/) | 792 points | by [throwaway384629](https://news.ycombinator.com/user?id=throwaway384629) | [420 comments](https://news.ycombinator.com/item?id=36113551)

Several Indian wrestlers, including Vinesh Phogat, Bajrang Punia, and Sakshi Malik, were detained by Delhi Police during their protest at Jantar Mantar. The wrestlers were demanding the arrest of BJP MP and WFI President Brij Bhushan Sharan Singh over accusations of sexual harassment involving at least seven women wrestlers. The wrestlers wanted to hold a women's Maha Panchayat near the new Parliament building, but their attempts were thwarted by the authorities. A selfie of Vinesh Phogat, Sangeeta Phogat, and others circulated on social media, with claims that they were seen smiling after being detained by police. The image was later found to be a morphed fake created using an Artificial Intelligence app, FaceApp, prompting Bajrang Punia to take to Twitter to call out those who circulated it.

The discussion continues with various users talking about post-modernism and the truthfulness of information on the internet, in relation to various political scenarios like the situation in Ukraine and Crimea. Many users warn against blindly believing any news, regardless of its source or ideology. Some users stress the importance of having critical thinking skills and the ability to understand different perspectives.

### One Click Deepfake

#### [Submission URL](https://github.com/s0md3v/roop) | 103 points | by [udev4096](https://news.ycombinator.com/user?id=udev4096) | [34 comments](https://news.ycombinator.com/item?id=36115283)

The one-click deepfake (face swap) AI tool allows users to take a video and replace the face in it with a face of their choice. Users only need one image of the desired face and no dataset, or training is required. The AI software offers two types of installations: basic and GPU-powered. The basic installation is more likely to work on most computers but will be slower, while the GPU installation is faster but requires a good GPU and troubleshooting through software issues. The program is easy to use and operates via a GUI mode, and the developers warn users against using the software for illicit or unethical purposes.

Commenters express concern about the ethical implications of this technology, and some suggest the need for professional-grade AI tools. Another user expresses concern about the spread of false information and propaganda, while others argue that this is just a tool and that it is up to the user to ensure ethical use. Some users criticize the lack of proper documentation for the software, while others express excitement about the possibilities this technology offers for creative projects.

### How to build AI products people want

#### [Submission URL](https://www.reforge.com/blog/ai-products-arms-race) | 77 points | by [nickwritesit](https://news.ycombinator.com/user?id=nickwritesit) | [35 comments](https://news.ycombinator.com/item?id=36113534)

AI products seem to be the latest buzz in the tech industry, with everyone racing to develop the next big thing in AI. However, despite the hype, many AI products are failing to deliver end user value and generate profits. The issue isn't with the technology itself but rather with the fact that companies struggle to find the right situations and channels to apply AI, resulting in a lack of product market fit. Additionally, AI alone cannot disrupt industries, as it requires the use of curated data during the training and inference phases to generate valuable insights. Companies that have access to large datasets and can leverage them to build AI models have a clear advantage over startups that are building from scratch. The key to success lies in finding non-obvious data sources that can feed AI models, rather than just having access to pre-built models.

The comments discuss the difficulty in applying AI to current problems and industries, as well as the potential for success in finding non-obvious data sources to feed AI models. There is also discussion on the difficulties in creating successful AI products for autonomous driving, the role of AI in the retail industry, and the state of AI and cryptocurrency industries. Some commenters express concern over the hype surrounding AI and the need for critical thinking and practical applications for real-world problems. One commenter notes that the hype surrounding AI is similar to the dotcom bubble. 

### Nvidia's next DGX supercomputer is all about generative AI

#### [Submission URL](https://www.tomshardware.com/news/nvidia-unveils-dgx-gh200-supercomputer-and-mgx-systems-grace-hopper-superchips-in-production) | 48 points | by [ripvanwinkle](https://news.ycombinator.com/user?id=ripvanwinkle) | [14 comments](https://news.ycombinator.com/item?id=36116430)

Nvidia's superchips, Grace Hopper, are now in full production, with six supercomputer wins. The chips are a fundamental building block for Nvidia's new DGX GH200 AI supercomputing platform, which is now available with 256 Grace Hopper Superchips paired together to form a supercomputing powerhouse with 144TB of shared memory. The company also unveiled its MGX reference architectures to help OEMs build new AI supercomputers faster, and a new Spectrum-X Ethernet networking platform designed and optimised specifically for AI server and supercomputing clusters.

In the discussion, one user posted a direct announcement from Nvidia, while another discussed the reference architecture for the 256 nodes and 24 racks. There was a discussion about Nvidia selling cryptocurrency mining AI generating hardware, but comments indicate it's unlikely Nvidia would focus exclusively on that market while ignoring gaming. The conversation also turned to the targeting of high-end GPUs to the top 1% of hardware, while others commented on how AAA gaming developers typically target compatibility consoles and often prioritize optimization.

---

## AI Submissions for Sun May 28 2023 {{ 'date': '2023-05-28T17:11:43.785Z' }}

### Easy Effects: Audio effects for PipeWire applications

#### [Submission URL](https://github.com/wwmm/easyeffects) | 148 points | by [marcodiego](https://news.ycombinator.com/user?id=marcodiego) | [34 comments](https://news.ycombinator.com/item?id=36108927)

Easy Effects is a collection of audio effects for PipeWire applications that includes limiter, compressor, convolver, equalizer, and auto volume plugins. Previously known as PulseEffects, the application was renamed to Easy Effects after it started using GTK4 and native PipeWire filters. Users have full control over the order of effects with the up/down arrows next to the effect labels on the left side. Easy Effects requires a number of dependencies including plugins from Linux Studio and Calf Studio, libebur128, Zamaudio, zita-convolver, soundtouch, and RNNoise. Easy Effects can be installed via Flatpak or via package managers on Linux distributions. Donations are welcome to help with further development of the project.

While users have praised its effectiveness, some have criticized the UI design as not suitable for touchscreens and lacking respect for the display's space. Nonetheless, it has been recommended for projects like Noise Reduction, filtering, and software graphic equalizers. Other users discussed a variety of related topics, such as alternative effects libraries with GitHub links, headphone parameters, multi-device redirection, among others.

### The halting problem is decidable on a set of asymptotic probability one (2006)

#### [Submission URL](https://projecteuclid.org/journals/notre-dame-journal-of-formal-logic/volume-47/issue-4/The-Halting-Problem-Is-Decidable-on-a-Set-of-Asymptotic/10.1305/ndjfl/1168352664.full) | 145 points | by [Schiphol](https://news.ycombinator.com/user?id=Schiphol) | [116 comments](https://news.ycombinator.com/item?id=36105717)

A new study by researchers at the University of Notre Dame, has found that the halting problem for Turing machines is decidable on a set of asymptotic probability one. The result is dependent on the particular computational models used and has significant implications for the future of computing and computational theory. Some commenters discussed their experiences solving the Brainfuck problem and creating non-halting programs. Others discussed the implications of the study, including the possibility of future developments in computing and computational theory. Some commenters discussed the lambda calculus and its role in describing mathematical functions and programs. There was also discussion of the definition of state space and its relationship to program checking and software verification.

### Retrowin32: Async, DLL loading, tracing execution, and Zig

#### [Submission URL](https://neugierig.org/software/blog/2023/05/retrowin32-async-dll-tracing-zig.html) | 78 points | by [goranmoomin](https://news.ycombinator.com/user?id=goranmoomin) | [12 comments](https://news.ycombinator.com/item?id=36104608)

The author of retrowin32, a Win32 emulator, has been working on loading external DLLs to play music in a demo. However, the DLL loading function uses a DllMain that needs to be invoked when the DLL is loaded for initialization purposes, which required some effort to figure out. To handle this, the author used Rust's async support to define EnumDisplayModes, which awaits a call to a callback and can potentially generalize well to cases where emulated code wants to synchronously perform an operation that ends up asynchronously in the web platform. To isolate a bug in the emulator that causes the demo to fail a self-check, the author wrote a Windows debugger program in Zig to introspect a debuggee's behavior. The author also explains the interesting parts of how a debugger works, which involves overwriting an address with an int3 instruction to stop execution at a certain point.

The discussion on this submission covers several topics related to Windows development and debugging. One user discusses their experience with disassembling native Windows machine code and finding undocumented parts of the architecture, while another suggests that many software programs don't use Windows system calls directly. A few users share their thoughts on DLL usage in Windows and some of the problems they've encountered, including the potential for proxy DLLs to interfere with the workings of an application. One user suggests that a proxy DLL located alongside the .exe file may work better than one located in the system directory. Overall, users seem to find the submission informative and share their own experiences and insights on the topic.

### Mirages: On Anthropomorphism in Dialogue Systems

#### [Submission URL](https://arxiv.org/abs/2305.09800) | 38 points | by [frabcus](https://news.ycombinator.com/user?id=frabcus) | [18 comments](https://news.ycombinator.com/item?id=36102082)

A new paper titled "Mirages: On Anthropomorphism in Dialogue Systems" warns about the potential harm of encouraging people to relate to automated dialogue systems as if they were human. The authors argue that conscious and unconscious design choices can guide users to personify these systems to varying degrees, which can lead to transparency and trust issues, as well as high-risk scenarios due to over-reliance on their outputs. They recommend that future dialogue system developers take particular care in their design, development, release, and description, and attend to the many linguistic cues that can elicit personification by users.

Some individuals argue that the linguistic expressions used in dialogue systems do not necessarily imply anthropomorphism. Others believe that it is essential to develop dialogue systems that integrate natural language models to prevent anthropomorphization. There is a debate about whether confabulation and hallucination justify anthropomorphism, with some arguing that dialogue systems do not convey non-factuality or correctness in answers to the expected response. The discussion also touches on the benefits and harms of using linguistic factors that contribute to anthropomorphism and gender and cultural stereotypes.

### Large language models do not recognize identifier swaps in Python

#### [Submission URL](https://arxiv.org/abs/2305.15507) | 73 points | by [lnyan](https://news.ycombinator.com/user?id=lnyan) | [98 comments](https://news.ycombinator.com/item?id=36101429)

A new paper titled "The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python" explores the limits of large language models (LLMs) in understanding programming. The authors demonstrate that despite their impressive performance, LLMs lack a deep understanding of programming semantics, particularly invariances and equivariances like the renaming of identifiers. This shortcoming makes them unsuitable for tasks that statistically deviate from their training data, and even increases prediction errors with larger model sizes - an instance of the phenomenon known as Inverse Scaling.

The discussion in the comments covers a variety of topics, including the usefulness of LLMs for certain tasks, the limitations of training data, the reliability of LLMs, and the differences between human understanding and that of LLMs. Some commenters express disappointment in the level of credulity given to LLMs and suggest that the limitations of artificial intelligence should be more widely acknowledged.

---

## AI Submissions for Sat May 27 2023 {{ 'date': '2023-05-27T17:10:54.654Z' }}

### Superintelligence: An idea that eats smart people (2016)

#### [Submission URL](https://idlewords.com/talks/superintelligence.htm) | 158 points | by [082349872349872](https://news.ycombinator.com/user?id=082349872349872) | [246 comments](https://news.ycombinator.com/item?id=36098332)

In 2016, Nick Bostrom published the book Superintelligence, which warns of the potential danger of a runaway reaction where a machine intelligence could reach and exceed human levels of intelligence in a very short span of time, ultimately causing catastrophic social and economic problems. Bostrom suggests that if we can prove thinking minds exist and that the mind arises out of ordinary physics, then it is possible to create an artificial intelligence that could operate at electronic hardware time scales and be significantly smarter than humans. With the space of all possible minds being large and with the potential for computers to get faster and smaller, Bostrom's argument has gained the serious attention of many thought leaders, including Stephen Hawking and Elon Musk. However, there's no a priori reason to think that we're near the limit of intelligence, and there is still much room for debate about the risks posed by superintelligence.

The comments include discussions on the possibility and consequences of superintelligence and the limits of artificial intelligence. Some users disagree with the potential risks of superintelligence, while others assert the importance of precautions due to the rapid explosion of sophistication of intelligence. There are also discussions regarding security, the development of AI, and comparisons with other technological advancements. Some users show concern over the safety of AI and suggest the need for global cooperation to safeguard against AI's negative outcomes.

### Integrating Zig and SwiftUI

#### [Submission URL](https://mitchellh.com/writing/zig-and-swiftui) | 155 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [49 comments](https://news.ycombinator.com/item?id=36097321)

In this post, Mitchell Hashimoto shares his approach to building a truly native GUI for a cross-platform application, by writing all of the business logic in a cross-platform language and then writing platform-specific GUI code. He uses Zig as the example shared-logic language and SwiftUI in XCode as the GUI logic. With Zig, Hashimoto makes it easy to export a C API and create a static library, which is then integrated with XCode. He also discusses how to package up all the dependencies and create a universal (multi-arch) library, which works on both the x86_64 and aarch64 architectures.

Commenters discussed the challenges of working with shared code and cross-platform maintenance, the benefits of declarative UI frameworks, and the compatibility of Rust, Zig, and C++ as cross-platform options. Some also shared their experience working on projects where the GUI code can constitute up to 70% of the project's code.

### Landmark Attention: Random-Access Infinite Context Length for Transformers

#### [Submission URL](https://arxiv.org/abs/2305.16300) | 18 points | by [johntb86](https://news.ycombinator.com/user?id=johntb86) | [4 comments](https://news.ycombinator.com/item?id=36098879)

A new paper titled "Landmark Attention: Random-Access Infinite Context Length for Transformers" has proposed a novel approach to handling the issue of limited context length for the attention mechanism of transformers in natural language processing. The approach uses a landmark token to represent each block of the input, allowing access to the complete context while retaining random-access flexibility. The authors demonstrate that their method can obtain comparable performance with Transformer-XL while significantly reducing the number of retrieved tokens in each step, and can extend the context length capacity up to 32k tokens, allowing for inference at the context lengths of GPT-4.

The discussion on the submission starts with a user linking to the paper and mentioning that the proposed landmark attention approach will be published later. Another user finds the idea of an infinite context length of up to 32k tokens intriguing. A third user discusses the potential limitations, mentioning that an infinite context length could lead to longer computation times and memory requirements. Another user suggests that landmarking and compression can be used to mitigate these limitations. Overall, the discussion is focused on the potential benefits and limitations of the proposed approach.

### Hard stuff when building products with LLMs

#### [Submission URL](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm) | 218 points | by [mavelikara](https://news.ycombinator.com/user?id=mavelikara) | [96 comments](https://news.ycombinator.com/item?id=36096811)

Honeycomb has launched Query Assistant, a natural language querying interface powered by Generative AI that helps users ask for the right data to answer their questions. However, Phillip Carter, in a post on Thought Leadership, says building a product with Large Language Models (LLMs) is hard. He discusses some of the challenges faced by Honeycomb in building Query Assistant, including the "context window" problem, determining which fields to use from a large schema and chaining issues that slow it down. Despite the challenges, Carter suggests that LLMs are too important to ignore and believes that recent advancements indicate that things are heading in the right direction.

In the comments, there is a discussion about the benefits and limitations of chatbot interfaces and LLMs in general, with some expressing skepticism and others highlighting potential benefits. There is also a debate about the priorities of investing in LLMs versus solving more significant global issues.

### Democratizing AI with open-source language models

#### [Submission URL](https://lwn.net/Articles/931853/) | 27 points | by [marcodiego](https://news.ycombinator.com/user?id=marcodiego) | [3 comments](https://news.ycombinator.com/item?id=36095571)

AI is rapidly advancing, but access to advanced language models is limited to those who can afford to pay for them, leaving out many developers and researchers who could benefit from access. OpenAI has offered their chatbot, ChatGPT, to the public, but it's not fully open-source and users require a connection to their cloud service. However, several open-source alternatives have emerged, including BLOOM, a freely available large language model that was developed by a global collaboration involving over a thousand scientists. These open-source language models may not match the performance of ChatGPT yet, but they are making strides towards democratizing AI for everyone.

The discussion on this submission seems to be focused on personal experiences and experiments related to language models. One user shared their experience running a machine with 24GB RAM that took 15 minutes to complete a task related to common transportation in Amsterdam. Another user shared their experience with running a 6GB Nvidia card machine with impressive performance. Additionally, another user mentioned that they have tried open-source language models for testing the performance of their PC and GPU for commercial tasks.

### Hot Pixel' Attack Steals Data from Apple, Intel, Nvidia, and AMD Chips

#### [Submission URL](https://www.tomshardware.com/news/hot-pixel-attack-steals-data-from-apple-and-nvidia-chips-using-frequency-power-and-temperature-info) | 78 points | by [uguuo_o](https://news.ycombinator.com/user?id=uguuo_o) | [15 comments](https://news.ycombinator.com/item?id=36094760)

A team of security researchers funded in part by the US Air Force and DARPA has demonstrated a side-channel physical attack on CPUs manufactured by Apple, Qualcomm and Intel. The researchers were able to steal data by monitoring chip temperature, power and frequency during normal operation, using information exposed by the Dynamic Voltage and Frequency Scaling mechanism. While proof-of-concept rates are low, the researchers have shown that future optimisation of the process could increase exfiltration rates and enable accelerated exploitation by other entities. The paper reports that all vendors notified have acknowledged the issues, but as yet no mitigations have been announced.

The discussion on the submission revolves around the practicality and effectiveness of the attack and how fingerprinting comes into play. Some argue that fingerprinting requires accessing system temperature metrics, which may not be accessible to attackers, while others highlight the subtleties of the thinking process of the security industry and suggest that statistical methods could help discriminate between devices more efficiently. Some participants note that the attack requires access to the system's internal power temperature frequency sensors and metrics, suggesting that the attack should be hard to execute without administrator access. Other discussions involve the grammar and clarity of the paper, technical details of the testing, security vulnerabilities in browser fingerprinting, and the accuracy of pixel extraction in Table 19.

### Show HN: No more copy-pasting – a ChatGPT plugin to read code from your computer

#### [Submission URL](https://github.com/kesor/chatgpt-code-plugin) | 44 points | by [kesor](https://news.ycombinator.com/user?id=kesor) | [21 comments](https://news.ycombinator.com/item?id=36099507)

Kesor has developed "Code ChatGPT Plugin," a TypeScript code analyzer that allows ChatGPT to interact with your code. It can identify all TypeScript files in a project, locate all functions within a file, and even retrieve content from a specific function. It's perfect for developers looking to understand a TypeScript code base and for automated tools that need to analyze or manipulate the code. The plugin includes several features, including fetching files, functions, and content from a specific function. Kesor encourages community contributions to the open source project. The discussion includes suggestions for integrating ChatGPT with projects, comparing ChatGPT and Copilot, and tips for working with ChatGPT plugins.

---

## AI Submissions for Fri May 26 2023 {{ 'date': '2023-05-26T17:11:26.581Z' }}

### TimL: Clojure-like Lisp dialect that runs on and compiles down to Vimscript

#### [Submission URL](https://github.com/tpope/timl) | 83 points | by [asimjalis](https://news.ycombinator.com/user?id=asimjalis) | [21 comments](https://news.ycombinator.com/item?id=36081091)

TimL is a Lisp dialect language that compiles to VimL, akin to Clojure. It features Clojure-like syntax and API, namespaces, macros, metadata, and more. TimL uses VimL interop to define symbols and interact with Vim variables, options, and exceptions. Getting started with TimL is recommended by using pathogen.vim and creating autoload/*.tim file. TimL is mostly underdocumented, adding additional overhead to the already slow host platform, leading to a possible lack of traction.

A new Lisp dialect language called TimL that compiles to VimL, similar to Clojure, was recently discussed on Hacker News. The language features Clojure-like syntax and API, namespaces, macros, metadata, and more. The comments section included multiple comparisons to similar languages such as Aniseed and Fennel, as well as discussion about the slow host platform and lack of documentation and traction. The discussion also touched on the topic of Vim versus Emacs, and included comments about the complexity of Vim configurations and Emacs Lisp, and the advantages and disadvantages of using Clojure and Lisp in general.

### AI Is Catapulting Nvidia Toward the $1 Trillion Club

#### [Submission URL](https://www.wsj.com/articles/how-ai-is-catapulting-nvidia-toward-the-1-trillion-club-14f42380) | 196 points | by [impish9208](https://news.ycombinator.com/user?id=impish9208) | [220 comments](https://news.ycombinator.com/item?id=36083093)

Nvidia is on track to become the first $1 trillion chip company thanks to its leading position in the artificial intelligence (AI) revolution. Tech giants such as Google, Microsoft, Amazon, and Facebook require expensive chips to support their growing AI capabilities, and Nvidia's chips are at the heart of this. The semiconductor company has come a long way since its beginnings 30 years ago, and its success in AI has put it in pole position for becoming the first chip company to break the $1 trillion barrier.

This has led to a discussion about the historical context of how technology companies have achieved their valuations, with some pointing to Intel's struggles in the early 2000s and the dotcom bubble. Others discuss the potential for smaller companies building AI technology, such as OpenAI, and some criticize the hype around AI as a market driver. The discussion also touches on competitors such as AMD and Google, and the risk of vertical integration in the industry.

### What Neeva's quiet exit tells us about the future of AI startups

#### [Submission URL](https://www.supervised.news/p/what-neevas-quiet-exit-tells-us-about) | 117 points | by [bobvanluijt](https://news.ycombinator.com/user?id=bobvanluijt) | [84 comments](https://news.ycombinator.com/item?id=36089055)

Snowflake's recent acquisition of Neeva, a generative AI startup founded by the former head of Google Advertising, offers insight into the current state of the AI industry. While Neeva's primary goal was to create a paid version of a search engine that offered better privacy and avoided ads, it struggled to gain traction against Google and Bing. The acquihire by Snowflake shows the growing importance of crossover experience in the AI industry, particularly in enterprise companies looking to gain a foothold in highly competitive markets. The Neeva team's knowledge and skill in building and deploying models will be invaluable to Snowflake as it seeks to break into machine learning.

The discussion on Hacker News touched on various points related to the current state of the AI industry, including the challenge of building AI products that compete with surface-visible results and the importance of expertise in building and deploying models. Another discussion focused on the misleading use of terms such as "Google Memo" and highlighted the importance of clear communication. The conversation also touched upon the need for specialized AI solutions to improve industry-specific workflows and the business challenges of developing AI products.

### A PhD student's perspective on research in NLP in the era of LLMs

#### [Submission URL](https://arxiv.org/abs/2305.12544) | 118 points | by [morgangiraud](https://news.ycombinator.com/user?id=morgangiraud) | [46 comments](https://news.ycombinator.com/item?id=36080886)

A group of PhD students in an academic research lab has compiled a list of NLP research directions that are rich for exploration, in a paper titled "A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models." While recent progress in large language models has enabled the deployment of many generative NLP applications, the students identify areas that still require exploration and caution against the misleading discourse that suggests that everything has been solved. The paper identifies a list of research areas that are not currently addressed by large language models but are worth exploring.

The comments discuss various topics related to NLP including resource allocation, the usefulness of various frameworks, and the need to validate hypotheses through experimentation. There are also debates about the validity of using pre-prints versus traditionally published work. Some readers argue that there are still many research directions that can be explored, while others are skeptical of the hype around large language models and argue that smaller-scale research could be just as productive. One commenter notes that the paper in question is not published in a reputable journal, while others argue that there is value in pre-print publications.

### Voyager: An Open-Ended Embodied Agent with LLMs

#### [Submission URL](https://voyager.minedojo.org/) | 85 points | by [jedixit](https://news.ycombinator.com/user?id=jedixit) | [23 comments](https://news.ycombinator.com/item?id=36085936)

NVIDIA, Caltech, UT Austin, Stanford, and ASU researchers collaborated to create Voyager, an embodied agent that explores and learns skills in Minecraft using large language models (LLMs). The agent features three key components: an automatic curriculum that aims to maximize exploration, an ever-growing skill library, and a new iterative prompting mechanism that improves programs based on environment feedback and execution errors. Empirical testing showed that Voyager outperformed prior state-of-the-art techniques by unlocking key tech tree milestones up to 15.3x faster and discovering new items and skills through self-driven exploration. The discussion on Hacker News primarily revolved around the technical aspects of LLMs and the limitations of GPT-4. Some users expressed skepticism about the potential of LLMs and others debated the effectiveness of direct vs. low-level control in Minecraft.

### The False Promise of Imitating Proprietary LLMs

#### [Submission URL](https://arxiv.org/abs/2305.15717) | 123 points | by [lebek](https://news.ycombinator.com/user?id=lebek) | [79 comments](https://news.ycombinator.com/item?id=36078739)

A new paper on arXiv analyses the efficiency of finetuning a weaker language model on outputs from a stronger model, such as a proprietary system like ChatGPT, to improve its quality. The authors find that while imitation models appear far better in their output and are rated as competitive with ChatGPT by crowd workers, they still have a substantial capabilities gap between open and closed LMs. The study concludes that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.

Comments in the discussion focused on the legal and ethical implications of the study, with some questioning whether imitation models are legal given their use of proprietary training data. Other users raised concerns about the potential dangers of AI and its impact on society. There was also a debate about the performance and value of large language models in general, with some arguing for the need to develop more specialized models for specific tasks.

### How much of AI's recent success is due to the Forer Effect?

#### [Submission URL](https://shkspr.mobi/blog/2023/02/how-much-of-ais-recent-success-is-due-to-the-forer-effect/) | 95 points | by [davidgerard](https://news.ycombinator.com/user?id=davidgerard) | [75 comments](https://news.ycombinator.com/item?id=36084881)

The article discusses the Forer Effect and how it applies to AI. The Forer Effect, also called "Forer Statements," occurs when people read general statements and believe them to be highly personal. The writer points out that AI can string together meaningless sentences that our human brains then ascribe meaning to. The author shares that reading AI-generated text can feel like getting a cold reading from a psychic, and then goes on to share some of Forer's original statements, including "Some of your aspirations tend to be pretty unrealistic."

The discussion on this submission is focused on the capabilities and limitations of AI-generated text and language models. Some users share their experiences playing games with AI text prompts and discuss their limitations in generating syntactically correct code. While others express concern that AI-generated text can lead to the Forer Effect, where people ascribe personal meaning to general statements. There are also discussions around the scalability of AI language models and their potential to replace human developers entirely. However, some users suggest that AI language models do have limitations and still require human input. Overall, the commenters express a mix of excitement and caution around the advancements in AI-generated language and their potential impact on various industries.

---

## AI Submissions for Thu May 25 2023 {{ 'date': '2023-05-25T17:11:18.302Z' }}

### Before the Fire: Saturn-Apollo Applications (1966)

#### [Submission URL](https://www.wired.com/2012/08/before-the-fire/) | 12 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [3 comments](https://news.ycombinator.com/item?id=36069260)

NASA's Saturn-Apollo Applications (SAA) program aimed to make use of Apollo hardware and investments to continue with post-Apollo manned spaceflight. Launched in 1965, the SAA program proposed two objectives: Long-Duration Flights and Spaceflight Experiments. Long-Duration Flights aimed to measure the effects of space flights of increasing duration to establish the basic capabilities required for future manned space flight goals, while Spaceflight Experiments would cover space life sciences, astronomy, space physics, advanced lunar exploration, and space technology development. The program was expected to kick off in 1968 with missions AS-209, AS-210, AS-211, and AS-212, and would see 21 Saturn IB and 16 Saturn V launches by the end of 1973 under the Case I schedule, and up to 26 Saturn IB and 17 Saturn V launches under the more ambitious Case II schedule.

The discussion on the submission includes only two comments. 

The first comment is by user "pnwrst," who provides a link to an article on the Spaceflight History Blog that talks about the NASA's Saturn-Apollo Applications (SAA) program. 

The second comment is by user "pcrds," who criticizes the lack of captions in the article's main text. In response, user "JKCalhoun" agrees with the criticism and adds that the staff at the Spaceflight History Blog is fantastic. They also mention that the fascination with space exploration dates back to the 1960s and 70s, when optimistic charts and diagrams of lifting bodies and space stations were widely available in libraries.

### How to Finetune GPT-Like Large Language Models on a Custom Dataset

#### [Submission URL](https://lightning.ai/pages/blog/how-to-finetune-gpt-like-large-language-models-on-a-custom-dataset/) | 477 points | by [T-A](https://news.ycombinator.com/user?id=T-A) | [120 comments](https://news.ycombinator.com/item?id=36068850)

Lightning AI has launched Lit-LLaMA, a minimal and optimized rewrite of LLaMA under Apache 2.0 license. This implementation uses Lit-Parrot, a nanoGPT-based model that can be fine-tuned on custom data sets, including StableLM, Pythia, and RedPajama-INCITE model weights. The tutorial details the installation process, model weight download, and data preparation for fine-tuning on the Dolly 2.0 instruction dataset. The processed data is saved to the destination path, followed by training and validation datasets for the preprocessed and tokenized prompts and labels.

The conversation touches on issues of copyright and licensing, as well as the potential benefits and drawbacks of using generative AI models for commercial purposes. Other topics include understanding alignment models, OpenAI's API terms of service, and the legal implications of using AI-generated content.

### Lessons from Creating a VSCode Extension with GPT-4

#### [Submission URL](https://bit.kevinslin.com/p/leveraging-gpt-4-to-automate-the) | 200 points | by [kevinslin](https://news.ycombinator.com/user?id=kevinslin) | [77 comments](https://news.ycombinator.com/item?id=36071342)

Developer Kevin Lin recaps his recent experiment where he used GPT-4 and the smol-ai framework to create a Visual Studio Code extension. The task required generating various files, scaffolding, and knowledge of TypeScript to create an advanced tool that enables users to adjust heading levels of selected markdown text, sans human intervention. With short and general prompts provided, Lin discovered the efficacy of the tools he used to generate code for a complex program, without any intervention from humans.

Some users express concerns about the quality and accuracy of AI-generated code, while others argue that it can improve productivity and free up developers to focus on more complex tasks. There are also suggestions for improving documentation and providing better prompts for AI-generated code.

### Chatbot Arena Leaderboard

#### [Submission URL](https://lmsys.org/blog/2023-05-25-leaderboard/) | 114 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [34 comments](https://news.ycombinator.com/item?id=36075977)

The Chatbot Arena has released its latest leaderboard update, which includes new chatbots, such as Google PaLM 2. According to the ranking system, GPT-4 is currently in first place, followed by Claude-v1 and Claude-instant-v1. PaLM 2 is ranked sixth and has shown strong performance against the top four chatbots. However, it has deficiencies in its regulation, multilingual capabilities, and reasoning abilities. The public API version of PaLM 2 available on Google Vertex API has a higher rate of abstaining from answering questions and failing to answer non-English questions.

There are discussions about naming new AI models for generative storytelling, along with critiques around testing and comparing models. Some users note missing models and the limitations of commercial and proprietary LLMs. There are discussions around the computation bottleneck of using open-source models versus proprietary ones. Users also share their experiences testing different chatbots on the leaderboard.

### New superbug-killing antibiotic discovered using AI

#### [Submission URL](https://www.bbc.com/news/health-65709834) | 153 points | by [tsenapathy](https://news.ycombinator.com/user?id=tsenapathy) | [72 comments](https://news.ycombinator.com/item?id=36071675)

Scientists have used artificial intelligence (AI) to discover a new antibiotic, abaucin, that can kill a deadly species of superbug, Acinetobacter baumannii. Using AI to narrow down thousands of potential chemicals to a handful that could be tested in the laboratory, the researchers trained the AI to learn the chemical features of drugs that could attack the problematic bacterium. In tests, abaucin proved to be incredibly potent and effective in treating infected wounds in mice and is able to kill A. baumannii samples from patients. The researchers believe the precision of the antibiotic will make it harder for drug-resistance to emerge and could lead to fewer side-effects. Discussions in the comments section touched on various aspects of the report, including the number of drugs screened, the practicality of the approach, and the role of AI in drug discovery.

### ChatGPT plugins now support Postgres and Supabase

#### [Submission URL](https://supabase.com/blog/chatgpt-plugins-support-postgres) | 149 points | by [cendenta](https://news.ycombinator.com/user?id=cendenta) | [28 comments](https://news.ycombinator.com/item?id=36072524)

OpenAI's ChatGPT is getting a boost from Supabase's recently contributed Postgres implementation to build plugins with pgvector. Retrieval plugins allow ChatGPT to access data from external sources, like PDF documents, Confluence, or Notion knowledge bases, which can be converted into smaller chunks and stored in a vector database. Both Postgres and Supabase implementations allow for storing embeddings - a way to convert text into mathematical representations to allow for similarity comparison - into the vector database. The plugins can also incorporate filtering options for source, author, document, and date to find the most relevant information for each question that ChatGPT answers. As an example, the blog post suggests ingesting all of the Postgres docs into a Supabase database to ask questions about the documentation. Some of the topics in the comments include a discussion on context warehouses, building templates, and external marketing. Additionally, one commenter mentions Faiss, which finds similar vectors, while another asks a question about ChatGPT plugins.

### Gorilla: Large Language Model connected with massive APIs

#### [Submission URL](https://gorilla.cs.berkeley.edu/) | 236 points | by [shishirpatil](https://news.ycombinator.com/user?id=shishirpatil) | [116 comments](https://news.ycombinator.com/item?id=36073241)

A team from UC Berkeley and Microsoft Research has released an open-source language AI model called Gorilla that can make the appropriate API calls. The model has been trained on three large machine learning datasets - Torch Hub, TensorFlow Hub, and HuggingFace - and outperforms GPT-4, Chat-GPT, and Claude in zero-shot evaluations. The researchers claim Gorilla is reliable and helps to reduce "hallucination errors" that often occur with LLMs, making it more applicable for real-world use. The model and code can be accessed on the project GitHub page.

Commenters in the discussion have offered diverse views on the potential and limitations of Gorilla and language models in general. Some commenters praise Gorilla for its better capability than competing existing models. Others discuss the limitations and dangers of language models, saying that they need to be properly developed, tested, and deployed to avoid any unforeseen consequences. There are also concerns about the alignment of the language models with human values and the difficulty of achieving it through current methods. Some commenters argue that we should be cautious in deploying experimental AI systems and put necessary infrastructure in place before deployment.

### Deno 1.34: Deno compile supports NPM packages

#### [Submission URL](https://deno.com/blog/v1.34) | 269 points | by [unripe_syntax](https://news.ycombinator.com/user?id=unripe_syntax) | [88 comments](https://news.ycombinator.com/item?id=36068896)

The Deno team has released version 1.34, adding several new features to boost compatibility with npm and Node.js, and enhancing overall quality of life and developer experience. Most notably, deno compile supports npm packages, allowing developers to create binary executables with all dependencies and configurations packaged alongside the executable. Additionally, glob support has been added to the configuration file deno.json and CLI arguments, and TLS certificates with IP addresses are now supported. Other improvements include exclusion of files or folders for all sub commands and configurable file system entry limits in the language server.

In the discussion, some users expressed support for Deno's focus on smaller projects and web API compatibility, while others questioned the necessity of npm compatibility and suggested that Deno should focus on developing its own ecosystem. Some users noted that Node.js and npm are separate systems and being compatible with one doesn't necessarily mean being compatible with the other. One user pointed out that Deno's unique approach to module management can simplify things, while another argued that trying to replicate the complexity of larger systems is unnecessary.

### Neuralink gets U.S. FDA approval for human clinical study of brain implants

#### [Submission URL](https://www.reuters.com/science/elon-musks-neuralink-gets-us-fda-approval-human-clinical-study-brain-implants-2023-05-25/) | 38 points | by [lopkeny12ko](https://news.ycombinator.com/user?id=lopkeny12ko) | [9 comments](https://news.ycombinator.com/item?id=36077392)

Elon Musk's Neuralink has been given the green light by the US Food and Drug Administration (FDA) to conduct its first-ever clinical trial with humans. The company didn't reveal much about the details of the study, but it called the FDA's approval an important first step for the technology and said more information would be available soon. Neuralink, which was founded in 2016, has been the subject of several federal investigations and has struggled to earn approval from the FDA in the past due to lithium battery concerns and wire migration risks. Musk has said the company's brain implants could one day help treat conditions like obesity, autism, and depression.

The comments on the submission range from political jokes about a future cyborg politician to concerns about the safety and ethics of brain implants. Some users wonder if the approval of Neuralink's clinical trial could lead to advancements in treating paralysis and blindness, while others express skepticism about the technology and its potential legal implications. One comment suggests that privately funded brain implant research could lead to a lack of transparency and potential medical malpractice. Another comment simply jokes about Elon Musk completing his homework.

### PostgresML raises $4.7M to launch serverless AI app databases based on Postgres

#### [Submission URL](https://postgresml.org/blog/postgresml-raises-4.7M-to-launch-serverless-ai-application-databases-based-on-postgres) | 52 points | by [kiyanwang](https://news.ycombinator.com/user?id=kiyanwang) | [24 comments](https://news.ycombinator.com/item?id=36072525)

PostgresML has raised $4.7M in seed funding to launch serverless AI application databases based on Postgres. By integrating leading machine learning libraries like Torch, Tensorflow, XGBoost, LightGBM, and Scikit Learn, PostgresML streamlines the infrastructure requirements for AI tasks, allowing developers to focus on creating intelligent applications. The company has created a custom Postgres load balancer tailored for machine learning workflows at scale, allowing them to pool multiple machines and connections to create a mesh of Postgres clusters that appear as independent Postgres databases. PostgresML is also an open-source extension to Postgres that brings models and algorithms into the database engine, and developers can load pre-trained algorithms and datasets from HuggingFace. With PostgresML, developers can prototype and deploy AI applications quickly and at scale in a matter of minutes. The discussion on Hacker News has varied, with some comments questioning the company's name, while others point out the limitations of the product.

---

## AI Submissions for Wed May 24 2023 {{ 'date': '2023-05-24T17:12:48.607Z' }}

### Show HN: Image background removal without annoying subscriptions

#### [Submission URL](https://pixian.ai/remove-image-backgrounds) | 310 points | by [jacobn](https://news.ycombinator.com/user?id=jacobn) | [99 comments](https://news.ycombinator.com/item?id=36064639)

Pixian.AI is a new background removal service that uses powerful GPUs and multi-core CPUs to analyze images and remove their backgrounds. The service is free while in beta, with long-lasting Pay-As-You-Go credit packs expected to be priced competitively once the beta ends. Pixian.AI has optimized every aspect of its business to maximize the quality and minimize the price of its service, with the aim of bringing background removal to graphics professionals and hobbyists at a "makes sense" price. The service currently supports JPEG, PNG, BMP, GIF, and WebP as input formats, and produces PNG as output.
The comments on the submission include discussions about other existing background removal services and their pricing and accuracy, as well as suggestions for improving the service. There is also discussion about using AI for image manipulation and the challenges and pricing associated with it. Some users have bookmarked the Pixian.AI service for future use, while others have recommended alternative services.

### QLoRA: Efficient Finetuning of Quantized LLMs

#### [Submission URL](https://arxiv.org/abs/2305.14314) | 282 points | by [Garcia98](https://news.ycombinator.com/user?id=Garcia98) | [97 comments](https://news.ycombinator.com/item?id=36064568)

A new approach to finetuning quantized language models has been presented in a paper called QLoRA by Tim Dettmers and three other authors. The approach reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. The team use QLoRA to finetune more than 1,000 models and provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations. They find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. The team release all of their models and code, including CUDA kernels for 4-bit training.

However, some users on Hacker News commented that the testing of the GPT-4 models was not comprehensive and may not be trustworthy for evaluation purposes. Other discussions revolved around the benefits and challenges of open-source AI models, and the importance of integrating AI models into existing systems and platforms. The discussion also touched on the limitations of AI models in processing messy and imperfect data and the challenges of AI integration into different platforms.

### Why the original transformer figure is wrong, and some other tidbits about LLMs

#### [Submission URL](https://magazine.sebastianraschka.com/p/why-the-original-transformer-figure) | 229 points | by [rasbt](https://news.ycombinator.com/user?id=rasbt) | [47 comments](https://news.ycombinator.com/item?id=36057183)

Sebastian Raschka shares four papers that provide a historical perspective on understanding transformers. The first paper discusses the discrepancy in the original transformer figure from Attention Is All You Need and suggests that Pre-LN works better than Post-LN. The second paper, written in 1991, proposes an alternative to recurrent neural networks called Fast Weight Programmers, which is similar to modern transformers. The third paper, Universal Language Model Fine-tuning for Text Classification, is noteworthy for proposing pretraining language models and transfer learning for downstream tasks. Lastly, the fourth paper discusses the use of transformers for image recognition and shows promising results. In the discussion, users share their views and ask questions about transformers, including their nature, working and advantages.

### DeviceScript: TypeScript for Tiny IoT Devices

#### [Submission URL](https://microsoft.github.io/devicescript/) | 184 points | by [glutamate](https://news.ycombinator.com/user?id=glutamate) | [94 comments](https://news.ycombinator.com/item?id=36059878)

Microsoft has released a technical preview for TypeScript for IoT, aimed at making it easier to develop applications for Internet of Things devices. This new solution offers familiar syntax and tooling for users, along with a small bytecode interpreter for devices with limited power, flash or memory. It also has a client/server architecture for sensors and actuators, debugging capabilities within Visual Studio Code, and simulation and testing features. Additionally, Microsoft has created a development gateway that will enable users to prototype cloud services, manage devices, deploy firmware, and access message queues. The preview is open for discussion and feedback.

Comments discuss the advantages of using Lua as an interpreter, the pros and cons of implementing TypeScript, and the challenge of developing languages for microcontrollers. Some users mention the success of MicroPython for rapid prototyping, and others bring up NanoFramework's compatibility with Raspberry Pi Pico.

### OpenAI Outage

#### [Submission URL](https://status.openai.com/incidents/jbt079x532bg) | 125 points | by [zurfer](https://news.ycombinator.com/user?id=zurfer) | [150 comments](https://news.ycombinator.com/item?id=36063166)

OpenAI has experienced elevated error rates in multiple engines, including text-davinci-003, the moderations endpoint, gpt4, and chatgpt, which affected API and chat.openai.com. While chatgpt has seen a recovery in rates, Whisper, and Turbo engines have also been impacted. The root cause has been identified, and the team is working on a fix, with OpenAI keeping users updated on the status of the incident. The comments on Hacker News mostly discuss the issue of SLAs (service-level agreements), with some users noting that OpenAI offers a decent SLA, while others argue that the price for an SLA is too high. Other commenters discuss the state of AI writing and the potential risks of relying too much on AI-generated text. Some users emphasize the importance of critical thinking and creativity, while others appreciate the value of AI in enhancing human communication.

### ChainForge: An open-source visual programming environment for testing prompts

#### [Submission URL](https://github.com/ianarawjo/ChainForge) | 116 points | by [azhenley](https://news.ycombinator.com/user?id=azhenley) | [10 comments](https://news.ycombinator.com/item?id=36056907)

ChainForge is an open-source visual programming environment designed to battle-test prompts to LLMs (Language Learning Models). It allows for quick and effective testing of prompt ideas and variations, comparison of response quality across prompt permutations and models, and immediate visualization of results across prompts, prompt parameters, and models using evaluation metrics. Currently in open alpha, ChainForge supports OpenAI models GPT3.5 and GPT4, Anthropic's Claude, Google PaLM2 (text-bison), and Alpaca 7B (through Dalai) at default settings. It is built on ReactFlow and Flask, and can be installed with Python 3.8 or higher via pip.

The comments on this submission discuss the importance of tracking signals, documenting collection strategies, and important UI frameworks for prompt building. One user shared their experience working on a project for keyword extraction and building smarter prompts with the help of frameworks. Another user mentioned that the current version of the project only supports Google Chrome and requested support for other browsers. However, another user pointed out that the project was probably not funded to cover browser compatibility issues. One user recommends not making assumptions about prompts and shares a similar tool they use. The rest of the comments express appreciation for the tool and praise the UI design.

### Dynaboard AI

#### [Submission URL](https://dynaboard.com/blog/dynaboard-ai) | 27 points | by [datarem](https://news.ycombinator.com/user?id=datarem) | [4 comments](https://news.ycombinator.com/item?id=36061839)

Dynaboard AI has launched a suite of AI features that accelerates the building of production-grade software regardless of complexity. The suite includes UI generation, code generation, and code refactoring. With UI generation, developers can quickly create UIs and forms for data-rich applications by simply typing prompts into the command bar. Dynaboard AI also generates JavaScript/TypeScript, SQL, and CSS and connects with a PostgreSQL, MySQL, or BigQuery database. The AI can modify existing apps using real-time filtering of data and responds to natural language prompts to provide always up-to-date dropdowns. Dynaboard AI's goal is to minimize the effort required to build and maintain apps with more AI-powered features to come.

The discussion surrounding Dynaboard AI's suite of features includes praise for its code refactoring capabilities. One commenter notes that the AI's ability to select list per defined components and generate correct formatting is impressive. The founder of Dynaboard AI also chimes in to provide more technical details on the company's AI-powered tools, such as code refactoring that works through recursive refinement loops and fetching relevant DB schema data for existing component data. The thread ends with the original poster expressing anticipation for future releases.

### Meta Open-Sources Computer Vision Foundation Model DINOv2

#### [Submission URL](https://www.infoq.com/news/2023/05/meta-dinov2-vision/) | 220 points | by [thread_id](https://news.ycombinator.com/user?id=thread_id) | [88 comments](https://news.ycombinator.com/item?id=36053592)

Meta has open-sourced DINOv2, a computer vision (CV) foundation model pretrained on a curated dataset of 142 million images. DINOv2, which is based on the Vision Transformer architecture, can serve as a backbone for several CV tasks, including image classification, semantic segmentation, depth estimation, and video action recognition. Meta said it plans to integrate the model, which helps AI systems reason on images in a richer way, into larger, complex systems that can interact with large language models. During tests, DINOv2 outperformed other self-supervised models and achieved comparable or better results than weakly-supervised models.

The top story on Hacker News is about Meta’s release of DINOv2, an open-sourced computer vision (CV) foundation model, which can be used as a backbone for image classification, semantic segmentation, depth estimation and video action recognition tasks. The comments section highlights discussions about the benefits and drawbacks of open sourcing models, and how it affects businesses and competitors. Some users are optimistic about how open sourcing can improve software and encourage contributions from the community, while others see it as a potential threat to newer startups. Meanwhile, others point out the similarities between Meta and other tech giants like Google and Microsoft, and how they all compete with one another to release the best AI models.

### VanillaNet: The power of minimalism in deep learning

#### [Submission URL](https://arxiv.org/abs/2305.12972) | 33 points | by [pizza](https://news.ycombinator.com/user?id=pizza) | [5 comments](https://news.ycombinator.com/item?id=36058695)

Researchers have introduced VanillaNet, a neural network architecture that embraces simplicity in design, avoiding high depth, shortcuts, and intricate operations like self-attention. By being refreshingly concise, yet remarkably powerful, each layer is carefully crafted to be compact and straightforward, making it ideal for resource-constrained environments. The easy-to-understand and simplified architecture of VanillaNet opens new possibilities for efficient deployment, delivering performance on par with renowned deep neural networks and vision transformers, showcasing the power of minimalism in deep learning. The pre-trained models and codes are available for developers to try out for themselves.

The discussion about the submission revolves around the complexity of deep learning research and how the VanillaNet architecture embraces simplicity. One user notes that the abstract sounds like marketing copy, but praises VanillaNet for being refreshingly concise yet powerful. Another user raises concerns about the complicated training regimen and the fragility of the system when searching for hyperparameters. A comparison is made between VanillaNet and MobileNet, with VanillaNet being faster and more accurate on a server-class GPU. Another user points out that Transformers are not optimal for vision tasks that do not require processing large amounts of data.

### Nvidia shares spike 18% on forecast beat driven by A.I. chip demand

#### [Submission URL](https://www.cnbc.com/2023/05/24/nvidia-nvda-earnings-report-q1-2024.html) | 37 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [14 comments](https://news.ycombinator.com/item?id=36063758)

Nvidia has reported better-than-expected earnings for the first quarter of its fiscal year 2024 and given a bullish forecast for the current quarter. The chipmaker said it expected sales of around $11 billion in Q2, more than 50% higher than Wall Street estimates of $7.15 billion. The strong performance was driven by surging demand for data centre products, which saw sales of $4.28 billion, a 14% YoY increase, while the gaming division's revenue dropped 38% to $2.24 billion. The automotive division, including self-driving technologies, grew 114% YoY but stood at under $300m in sales for the quarter.

Some users believe that Nvidia's sales growth is unsustainable and that the hype around the company is overblown, recommending short-selling the stock. Others argue that Nvidia's dominance in the data center and AI computing markets justifies its high valuation and that the demand for its GPUs will continue to rise in the coming years. Some users also mention Nvidia's partnerships with AWS, Microsoft, and other large internet companies as a key factor in its growth story. One user points out that Nvidia's revenue from the gaming division has dropped significantly, although this is partially offset by the growth of its self-driving technology division. Overall, the discussion highlights the complex dynamics of the semiconductor industry and the challenges of predicting the future of high-growth tech companies.

---

## AI Submissions for Tue May 23 2023 {{ 'date': '2023-05-23T17:10:48.817Z' }}

### RWKV: Reinventing RNNs for the Transformer Era

#### [Submission URL](https://arxiv.org/abs/2305.13048) | 349 points | by [ianbutler](https://news.ycombinator.com/user?id=ianbutler) | [170 comments](https://news.ycombinator.com/item?id=36038868)

A new paper titled "RWKV: Reinventing RNNs for the Transformer Era" has been submitted to arXiv by Bo Peng and 29 other authors. The publication explores an innovative model architecture, Receptance Weighted Key Value (RWKV), which combines the efficient parallelizable training of Transformers with the efficient inference of RNNs. The architecture uses a linear attention mechanism that allows the model to be formulated as either a Transformer or an RNN, which parallelizes computations during training and maintains constant computational and memory complexity during inference. This groundbreaking approach leads to the first non-transformer architecture to be scaled to tens of billions of parameters and performs on par with similarly sized Transformers. The research presents a significant step towards reconciling the trade-offs between computational efficiency and model performance in sequence processing tasks.

A new paper titled "RWKV: Reinventing RNNs for the Transformer Era" has been submitted to arXiv. The paper presents an innovative model architecture, Receptance Weighted Key Value (RWKV), which combines the efficient parallelizable training of Transformers with the efficient inference of RNNs. The architecture allows the model to be formulated as either a Transformer or an RNN, leading to the first non-transformer architecture to be scaled to tens of billions of parameters and performs on par with similarly sized Transformers. The discussion includes a debate over the trade-offs between computational efficiency and model performance in sequence processing tasks, the significance of the paper's approach and naming conventions for attention mechanisms. There is also a discussion on the ability of the AI models to answer questions based on long pieces of text, with some questioning the model's lack of long-term memory compared to humans.

### Let's Talk about ChatGPT with Code Interpreter and Microsoft Copilot

#### [Submission URL](https://www.oneusefulthing.org/p/it-is-starting-to-get-strange) | 139 points | by [stuckinhell](https://news.ycombinator.com/user?id=stuckinhell) | [74 comments](https://news.ycombinator.com/item?id=36047187)

OpenAI's GPT-4 system, along with Microsoft's GPT-4 tools, has been given new abilities to use tools, making them more relevant to real-world tasks. One of the standout models is Code Interpreter, which is capable of reading files, letting users download files and run its own Python code. It has turned GPT-4 into a data analyst, capable of looking at datasets, figuring out what is interesting, cleaning data, testing strategies and adjusting to errors. It can even write academic papers based on its results. Code Interpreter's creativity in problem solving and independence could have a big effect on work and job markets. The comments talk about the challenges programmers face in adapting and changing to new technologies but some find the technology exciting. Some discuss how Apple is slowly integrating machine learning into its products, while others are not convinced of its progress.

### Waymo and Uber partner to bring autonomous driving technology to Uber

#### [Submission URL](https://blog.waymo.com/2023/05/waymo-and-uber-partner-to-bring-waymos.html) | 404 points | by [oflordal](https://news.ycombinator.com/user?id=oflordal) | [360 comments](https://news.ycombinator.com/item?id=36043322)

Waymo and Uber have announced a strategic partnership to integrate Waymo's autonomous driving technology into the Uber platform, starting in Phoenix. Uber users will be able to hail a Waymo vehicle through the Uber and Uber Eats apps, as well as through Waymo's own app. The integration will launch with a set number of Waymo vehicles and will include local deliveries and ride-hailing trips. Waymo's Phoenix operations currently cover over 180 square miles, making it the largest fully autonomous service area in the world. The partnership aims to provide a safe, enjoyable, and fully electric and autonomous ride experience.

Discussions in the comments mainly focused on the technology behind this partnership, with some people debating the usage of LiDAR sensors vs cameras, and others speculating on the long-term success of both companies. Some people raised concerns over the legal structures regarding local regulations and licensing, and there was some debate over Uber's business model and financial losses. Finally, there were some jokes made about the potential for software developers to quickly solve the issues with ride-hailing apps.

### Bringing the power of AI to Windows 11

#### [Submission URL](https://blogs.windows.com/windowsdeveloper/2023/05/23/bringing-the-power-of-ai-to-windows-11-unlocking-a-new-era-of-productivity-for-customers-and-developers-with-windows-copilot-and-dev-home/) | 129 points | by [makepanic](https://news.ycombinator.com/user?id=makepanic) | [111 comments](https://news.ycombinator.com/item?id=36045526)

Microsoft has announced the launch of Windows Copilot, which, with the help of Bing Chat, marks the first centralized AI assistance for Windows users. Developers will also be able to augment their app integrations within Windows Copilot, allowing users to complete projects and collaborate more efficiently. The company is also set to launch Dev Home, the Windows AI Library, and new AI features in the Microsoft Store to empower developers to build for AI, democratizing the development process. The Windows AI Library will contain a curated collection of machine learning models and APIs to jump-start AI development for developers.

A diverse range of opinions was shared on Hacker News, including support for an internal machine learning component, skepticism towards Microsoft, privacy concerns surrounding data collection, and excitement for the potential of Windows Copilot. There were also helpful discussions about the technical aspects of the announcement, such as Windows integration and installation instructions.

### Yoshua Bengio: How Rogue AIs May Arise

#### [Submission URL](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/) | 161 points | by [cubefox](https://news.ycombinator.com/user?id=cubefox) | [133 comments](https://news.ycombinator.com/item?id=36042126)

Recently, there has been a lot of debate about the potential risks of powerful AI systems and the need for regulatory frameworks to prevent catastrophic outcomes. In a blog post, AI scientist Yoshua Bengio defines potentially rogue AI as an autonomous system that could behave in ways that would be catastrophically harmful to a large fraction of humans, potentially endangering societies and even the biosphere. While human-level intelligence is possible because of the biological nature of the brain, recent advances in generative AI models have raised concerns about the potential for rogue AI to arise. Bengio discusses different scenarios and hypotheses that could yield rogue AI and the need for more research and policies to minimize these risks.

There has been discussion on the potential dangers of rogue AI systems and the need for regulatory frameworks to manage these risks. One argument suggests that corporations have the greatest control over powerful AI systems, which could lead to catastrophic outcomes for society. Others argue that these concerns are overstated and that AI is not powerful enough to be a significant threat. There is also a debate about the responsibility of governments and corporations in managing the risks associated with AI development. The discussion considers different views on the role and impact of corporations, the potential for AI to lead to significant societal changes, and the need for more research and regulation in this field.

### Microsoft announces Fabric, a new AI-powered analytics platform

#### [Submission URL](https://azure.microsoft.com/en-us/blog/introducing-microsoft-fabric-data-analytics-for-the-era-of-ai/) | 38 points | by [FranklinMaillot](https://news.ycombinator.com/user?id=FranklinMaillot) | [4 comments](https://news.ycombinator.com/item?id=36046083)

Microsoft Fabric has been announced, and it offers an end-to-end, integrated analytics system for companies to gather insights and take advantage of data-driven decisions. It brings together technologies such as Azure Data Factory, Azure Synapse Analytics, and Power BI into a single, unified product. The platform is open and lake-centric, and includes an automatically integrated and optimized experience delivered as software as a service. It's a unique offering in what is often a fragmented data and AI technology market, ultimately providing an easy-to-use analytics solution for every team in a company's analytics process. The comments on this submission are not directly related to the content of the announcement. One user mentions that they did not check the response of GPT (presumably referring to the GPT language model), and another user expresses their exhaustion with trying to keep up with AI trends. There is also a tangent conversation about 3D technology and the potential for combining it with AI.

### Microsoft's Azure AI Studio lets developers build their own AI 'copilots'

#### [Submission URL](https://techcrunch.com/2023/05/23/microsoft-debuts-azure-ai-studio-to-let-developers-build-their-own-ai-copilots/) | 34 points | by [marban](https://news.ycombinator.com/user?id=marban) | [5 comments](https://news.ycombinator.com/item?id=36047178)

Microsoft has launched Azure AI Studio, a platform aimed at enabling companies to build their own AI-powered "copilots" functionalities using its Azure OpenAI Service and machine learning models from OpenAI. Companies will now be able to use the chat assistant to perform tasks like generating images for presentation or writing a sales pitch, while using their own data securely without compromising security, document ranking or data policies. Customers will also be able to integrate internal or external structured, semi-structured or unstructured data, resulting in customised models built using cloud-hosted tooling.

The discussion around the submission mainly focused on the licensing and pricing of the Azure AI Studio. One user raises a concern that some licenses may have been generated improperly and suggests that Microsoft check request documents and add access to the list. Another user mentions that the OpenAI API is faster than the GPT-3 Turbo 5X for public use cases. Additionally, there were some comments regarding the pricing and cost of the Azure AI Studio and its relation to Microsoft's acquisition of GitHub. One user speculates that Microsoft may be pricing the models on GitHub too high while another user suggests that the cost may be worth it for customers who value the service and are willing to pay for it.

### The White House announces plans to create a new national strategy for AI

#### [Submission URL](https://www.semafor.com/article/05/23/2023/white-house-ai-national-strategy) | 34 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [8 comments](https://news.ycombinator.com/item?id=36048855)

The Biden administration is seeking public input on how to create a national strategy for artificial intelligence (AI) in order to manage its risks and maximize its benefits. The administration has released a fact sheet asking the public to weigh in on issues related to the fast-evolving field. The aim is to create technical standards for AI that are “trustworthy, reliable, dependable, and safe,” while creating safeguards to protect individual rights. The new strategy hopes to ensure AI is used to improve government services, as well as determining the impact it may have on Americans’ jobs. The administration’s initiative to craft a national strategy comes ahead of Congress, which is just beginning to learn about the technology and at the information gathering stages of thinking through potential regulation.

The discussion on this submission includes a few different comments. One user points out that the US government's power over regulation of AI is limited by the Constitution, specifically pointing to the 9th and 10th Amendments. Another user links a related article from the World Economic Forum on regulation of AI, which results in a discussion of whether or not to take the WEF's opinions seriously. Another user notes that Microsoft has acquired a company related to AI, while another commenter discusses potential competition and shareholder value in the AI industry. The final two comments do not appear to be directly related to the topic of the submission.

### Updates to Kagi pricing plans – More searches, unrestricted AI tools

#### [Submission URL](https://blog.kagi.com/plan-changes) | 84 points | by [darthShadow](https://news.ycombinator.com/user?id=darthShadow) | [67 comments](https://news.ycombinator.com/item?id=36040346)

Kagi, the search platform, has made significant pricing plan enhancements, which already in effect. All plans now include more searches, with up to 50% more searches per plan. Kagi is also offering unrestricted access to AI tools such as "Quick Answers,"" Ask Questions about Document,"" Summarize Page" and their Universal Summarizer. The previous restrictions on the use of these AI tools have been removed from all paid plans. These changes not only enhance the Kagi experience for users but also improve productivity and work quality. Kagi expresses gratitude to its customers for the continued support. They also have exciting plans to introduce new features based on FastGPT. The discussion also covers topics such as privacy-focused search engines, the limitations of search engine personalization and the ethics of donating profits to political organizations.

### Hot Pixels: Frequency, Power, and Temperature Attacks on GPUs and ARM SoCs

#### [Submission URL](https://arxiv.org/abs/2305.12784) | 14 points | by [ManDeJan](https://news.ycombinator.com/user?id=ManDeJan) | [4 comments](https://news.ycombinator.com/item?id=36040758)

A team of researchers has conducted a study showing that GPUs and ARM SoCs are vulnerable to information leakage via power, temperature, and frequency through internal sensors. These hybrid side-channel attacks can bypass countermeasures for traditional microarchitectural side-channel attacks and allow attackers to steal pixels from a website in the browser, without elevated privileges. The paper presents real-world JavaScript-based pixel stealing and history sniffing attacks on Chrome and Safari, with all side channel countermeasures enabled, as well as website fingerprinting attacks. The findings reveal the need for improved security measures for these devices.

The discussion on this submission explored how the vulnerabilities described in the study are related to power consumption, temperature, and frequency. Some commenters noted that similar attacks have been mitigated in the past by balancing electrical power consumption and improving energy efficiency, while others pointed out that concurrent computational loads and fuzzy fonts can also affect security. There were also references made to related attacks such as the TEMPEST and Hertzbleed attacks that have been presented at conferences and the impact of hot pixels. Matthew Green's Twitter account was also mentioned for further reading on the topic.

---

## AI Submissions for Mon May 22 2023 {{ 'date': '2023-05-22T17:10:45.112Z' }}

### Re-Evaluating GPT-4's Bar Exam Performance

#### [Submission URL](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4441311) | 40 points | by [homarp](https://news.ycombinator.com/user?id=homarp) | [6 comments](https://news.ycombinator.com/item?id=36036343)

A paper by Eric Martinez of MIT has questioned the performance claims made by OpenAI for its GPT-4 model's application to the Uniform Bar Exam (UBE). Martinez finds that the touted 90th percentile proficiency of the model is based on flawed data analysis and that the percentile estimate for individuals who passed the UBE examination - that is, those who are or will be licensed attorneys - is estimated to be as low as the 48th percentile. The researcher's findings raise questions about the real-world application of GPT-4 and the need for transparent and rigorous evaluations of AI capability.

Some users note that the paper highlights the need for transparent and rigorous evaluations of AI capabilities. However, others argue that the paper's findings are not entirely conclusive, as they rely on flawed data analysis and conservative statistical assumptions. Some commenters suggest that OpenAI should be more honest and transparent in its marketing and not make exaggerated claims about the performance of its models. Overall, the discussion suggests that while GPT-4's performance on the UBE may be impressive, it may not be as reliable or accurate as OpenAI has claimed.

### Meta AI announces Massive Multilingual Speech code,  models for 1000+ languages

#### [Submission URL](https://github.com/facebookresearch/fairseq/tree/main/examples/mms) | 657 points | by [crakenzak](https://news.ycombinator.com/user?id=crakenzak) | [216 comments](https://news.ycombinator.com/item?id=36034211)

Facebook AI Research has released the Massively Multilingual Speech (MMS) project, which aims to expand speech technology from around 100 languages to over 1,000 languages. MMS built a single multilingual speech recognition model, which supports over 1,100 languages, language identification models that can identify over 4,000 languages, pretrained models supporting over 1,400 languages, and text-to-speech models for over 1,100 languages. The goal of MMS is to make it easier for people to access information and use devices in their preferred language. You can find details in their paper and their blog post.

People on the forum discussed the accuracy of speech to text models, generalizations, the availability of STT and TTS translation models on GitHub, and renting GPUs to run AI models. They also spoke about the challenges in developing speech recognition models, the use of docker containers, and how containers can help store data and avoid manual installation.

### Parallels in the ways that humans and ML models acquire language skills

#### [Submission URL](https://www.quantamagazine.org/some-neural-networks-learn-language-like-humans-20230522/) | 106 points | by [theafh](https://news.ycombinator.com/user?id=theafh) | [35 comments](https://news.ycombinator.com/item?id=36031446)

A recent study by Gašper Beguš and colleagues at the University of California, Berkeley, has suggested that natural and artificial neural networks learn language in very similar ways. The researchers compared the brain waves of humans listening to a simple sound to the signal produced by a neural network analyzing the same sound and found that they were remarkably alike. They also discovered that even very general purpose neural networks without specific speech or sound biases still showed a correspondence to human neural coding. The study's results may help demystify how ANNs learn and suggest that human brains may not be pre-equipped with language-specific hardware and software.

The paper sparked a discussion in the comments on Hacker News. Some commenters were skeptical of the study's conclusion that human brains may not be pre-equipped with language-specific hardware and software, while others found it fascinating and could see how it could apply to machine learning. The discussion also touched on Noam Chomsky's theory on the innate ability of humans to learn language, with some agreeing and others disagreeing. Some commenters also shared their own experiences with learning language and the importance of understanding language in the context of human communication.

### UK’s GDPR replacement could wipe out oversight of live facial recognition

#### [Submission URL](https://www.theregister.com/2023/05/19/dpib_2_surveillance_oversight/) | 183 points | by [belter](https://news.ycombinator.com/user?id=belter) | [146 comments](https://news.ycombinator.com/item?id=36030337)

The UK's Biometrics and surveillance camera commissioner Professor Fraser Sampson has warned that proposed data protection measures, set to replace the country's implementation of GDPR, may undermine independent oversight of facial recognition technology. Sampson, whose responsibilities include encouraging "compliance with the Surveillance Camera Code of Practice", stated that the current drafts of clauses 104 and 105 meant that the legislation may abolish the regulatory office overseeing biometrics and surveillance and repeal the Surveillance Camera Code of Practice that governs public space surveillance. Critics of the DPDI bill have also raised concerns over how it defines 'personal data' and its potential impact on privacy.

The discussion on this submission largely focused on Brexit and its impact on the UK's laws and regulations. Some users argued that Brexit presented an opportunity for the country to improve things, while others felt that it would benefit special interests or even fascists. There were also comments about surveillance and the trade-off between security and privacy. One user highlighted that people are not listening to the warnings of experts like Professor Sampson.

### Compromising LLM-integrated applications with indirect prompt injection

#### [Submission URL](https://arxiv.org/abs/2302.12173) | 43 points | by [greshake](https://news.ycombinator.com/user?id=greshake) | [20 comments](https://news.ycombinator.com/item?id=36037308)

Researchers have identified new attack vectors, using Indirect Prompt Injection, that can compromise Large Language Model (LLM)-integrated applications. These attacks enable adversaries to remotely exploit LLM-integrated applications by strategically injecting prompts into data likely to be retrieved, even if not directly prompted by the user. The team derived a comprehensive taxonomy from a computer security perspective to systematically investigate the impacts and vulnerabilities of PI attacks on LLMs, including data theft, worming, information ecosystem contamination, and other novel security risks. They also demonstrated the practical viability of these attacks against real-world systems, such as Bing's GPT-4 powered Chat and code-completion engines, and synthetic applications built on GPT-4.

The discussion in the comments section covers different aspects of the submission. One user discusses the BERT and DIET frameworks, which are highly customizable and handle complex messages and series. Another user questions if the suggested technique is similar to injecting malicious instructions or content in data stored or retrieved. A solution was posted for detecting prompt injection attacks, and many users discussed SQL injection and the importance of escaping user input when storing it in databases. The vulnerability of LLMs and applications using them was demonstrated against real-world applications such as Bing's Chat. Many users expressed concern about these attack vectors and the potential ways in which the vulnerabilities they create could be exploited.

### LIMA: Less Is More for Alignment

#### [Submission URL](https://arxiv.org/abs/2305.11206) | 23 points | by [lebek](https://news.ycombinator.com/user?id=lebek) | [8 comments](https://news.ycombinator.com/item?id=36027141)

A new paper titled "LIMA: Less Is More for Alignment" proposes that almost all knowledge in large language models is learned during pretraining, and only limited instruction tuning data is necessary to teach models to produce high-quality output. The paper presents LIMA, a 65B parameter LLaMa language model fine-tuned with only 1,000 carefully curated prompts and responses, without any reinforcement learning or human preference modeling. LIMA demonstrates remarkably strong performance, surpassing GPT-4 in 43% of cases in a controlled human study, suggesting that pretraining is the key to success for large language models. Some users express interest in the direction of research on large language models and their applicability in industry, while others point out that human learning depends on good teachers who provide consistent correction and guidance.

### AI-generated photo of fake Pentagon explosion sparks brief stock selloff

#### [Submission URL](https://nypost.com/2023/05/22/ai-generated-photo-of-fake-pentagon-explosion-sparks-brief-stock-selloff/) | 25 points | by [the-printer](https://news.ycombinator.com/user?id=the-printer) | [19 comments](https://news.ycombinator.com/item?id=36035981)

A fake AI-generated photo of an explosion at the US Pentagon spread rapidly on social media on Monday, causing mass confusion among users and a brief selloff in the US stock market. The fake photo, which showed smoke billowing outside the Pentagon, was shared by Russian state media outlet and other accounts alongside claims that an explosion had occurred at the complex. US stocks appeared to briefly dip as the photo circulated but quickly rebounded after the picture was exposed as a hoax. Critics fear advanced AI systems will allow bad actors around the world to spread misinformation and sow chaos online.

Some users discuss the dangers of relying on social media and speculate about Wall Street's responsibility in reaction to fake news. Others note that the photo was likely a random creation and that the market quickly rebounded once the hoax was exposed. There is discussion about the reliability of news sources, with some emphasizing the importance of fact-checking and critical thinking. One user references the phrase "Moab," likely in reference to a large non-nuclear bomb used by the U.S. military.

---

## AI Submissions for Sun May 21 2023 {{ 'date': '2023-05-21T22:22:11.209Z' }}

### Deep neural networks as computational graphs (2018)

#### [Submission URL](https://medium.com/tebs-lab/deep-neural-networks-as-computational-graphs-867fcaa56c9) | 79 points | by [softwaredoug](https://news.ycombinator.com/user?id=softwaredoug) | [28 comments](https://news.ycombinator.com/item?id=36020520)

Neural networks have often been referred to as "black boxes" due to their complex structure. However, understanding the mathematics behind neural networks and how they arrive at their predictions can provide valuable insight into their use. At the core of every neural network is a single mathematical function represented by a computational graph. A computational graph is a way of representing a mathematical function in the language of graph theory, where nodes represent input values or combining functions and edges receive their weights as data flows through the graph. While math notation can also be used to represent the same functions, computational graphs are preferable for more complex neural networks with hundreds of thousands of nodes and edges.

The discussion delves deeper into various topics. Users stress the fundamental importance of understanding mathematical expressions and graphs in analyzing and manipulating graphs, as well as the advantages of computational graphs over mathematical notation for complex neural networks. Additionally, there is a conversation on distinguishing different types of structures in computational graphs such as backpropagation. The discussion also explores the significance of graphs and compilers in math, with a focus on their benefits for deep learning systems.

Furthermore, the comments touch upon the relationship between neural networks and computational graphs and their significance in AI methods. There is also a conversation on the application of computing risk metrics in financial models, how neural networks are incorporated in these models and how analyzing computational graphs can allow for sensitivity analysis. One user also recommends watching a YouTube video which breaks down how to read math expressions in neural networks. Another user brings up the topic of Theano and TensorFlow and how PyTorch is increasingly being used partly because it enables control of the computational graphs used by the neural network.

### Perfectly secure steganography using minimum entropy coupling

#### [Submission URL](https://arxiv.org/abs/2210.14889) | 45 points | by [Topolomancer](https://news.ycombinator.com/user?id=Topolomancer) | [8 comments](https://news.ycombinator.com/item?id=36022598)

Researchers have developed what they claim is the first steganography algorithm to offer perfect security guarantees with non-trivial efficiency, according to a paper submitted to the Computer Science > Cryptography and Security arXiv. The team, from Carnegie Mellon University in Pittsburgh, used minimum entropy coupling to develop a scalable steganography procedure that is resistant to detection by adversaries. The researchers also found evidence of coupling in natural language and images, which should stimulate new approaches to steganalysis, the detection of hidden messages.

The discussion in the comments covers various aspects of steganography, its limitations, and its potential impact. One user notes the potential application of AI-generated steganography in transmitting confidential information, while another user points out the use of steganography in creating unbreakable watermarks for downstream content. Another user notes that steganography is different from encryption, and the two serve different purposes. A user mentions their interest in the references cited in the paper, while another user mentions their understanding of steganography and explains the process of decoding it.

### PrivateGPT

#### [Submission URL](https://github.com/imartinez/privateGPT) | 444 points | by [antouank](https://news.ycombinator.com/user?id=antouank) | [127 comments](https://news.ycombinator.com/item?id=36024503)

PrivateGPT is a new tool designed to interact with your documents using the power of GPT and provide 100% private communication without any data leaks. You can ingest your own documents, ask questions without an internet connection, and rely on LangChain, GPT4All, LlamaCpp, Chroma, and SentenceTransformers for the functionalities this tool provides. The instructions for setting up an environment, ingesting a test dataset, and asking questions locally are all available in the README file.

The submission is about PrivateGPT, a tool that allows users to interact with their documents using GPT for private communication. The Reddit discussion revolves around issues with compatibility and dependencies, such as the conflicts between different versions of Python or between Pyenv and Homebrew installation methods. Some contributors recommend using Docker or virtual environments to manage dependencies and isolate environments. The thread also discusses the advantages and challenges of using self-hosted and self-trained language models and machine learning tools for enterprise and consumer applications.

### The DRAKON Language

#### [Submission URL](https://drakonhub.com/en/drakon) | 216 points | by [brudgers](https://news.ycombinator.com/user?id=brudgers) | [38 comments](https://news.ycombinator.com/item?id=36021495)

DRAKON is a visual language used in the aerospace industry to represent algorithms, processes, and procedures. Its goal is to make procedures easy to understand, and it has gained recognition outside of aerospace among developers, project managers, and in medical and business fields. DRAKON is based on best practices for flowchart drawing, but also has unique features such as the skewer, silhouette, and common fate. While it is possible to draw DRAKON flowcharts in a general-purpose diagram editor, using a specialized tool such as DrakonHub provides a faster and smoother experience.

People in the discussion mention the existence of other fascinating languages such as Analitik, CAS Matlab, and Dragon. Despite its popularity, some people in the discussion prefer local data understanding and text-based interface over using DRAKON. There is an ongoing debate about the efficiency of using DRAKON compared to other programming languages/tools, and some people question the Soviet engineers' preference for graphic languages over traditional languages. Furthermore, some people mentioned the existence of previous discussions about DRAKON and its specifications, and a few provided relevant links. At the same time, others shared their practical experience in using DRAKON for non-trivial projects.

### AI boom could expose investors’ natural stupidity

#### [Submission URL](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/) | 180 points | by [mirthlessend](https://news.ycombinator.com/user?id=mirthlessend) | [183 comments](https://news.ycombinator.com/item?id=36022768)

Behavioural economics has some important lessons for investors hoping to cash in on artificial intelligence (AI). The first lesson to beware of bubbles since the rush of investments in AI-related capital since OpenAI released its ChatGPT chatbot in November. Orthodox asset pricing models suggest that changing but rational assessments of future profitability drive the wild gyrations of the stock market. The second lesson is that natural stupidity can drive stock market valuations to unrealistic and ultimately unprofitable extremes. Finally, investors should question whether AI is able to replicate its extraordinary predictive ability in areas such as commercial, financial, and political life where the rules can be fuzzier.

The commenters in the following discussion thread explore topics such as the flaws in training language models, the potential of AI causing job loss, the limitations of AI in replicating predictive ability in certain domains, and the benefits and limitations of using AI in business operations. Additionally, there is discussion around the modeling of the market and the impact of human behavior on investment. Some commenters express concern for the speculation in the AI market leading to a potential bubble effect.

### GPT detectors are biased against non-native English writers

#### [Submission URL](https://arxiv.org/abs/2304.02819) | 325 points | by [giuliomagnifico](https://news.ycombinator.com/user?id=giuliomagnifico) | [258 comments](https://news.ycombinator.com/item?id=36019580)

A new study shows that widely-used GPT detectors for differentiating between AI and human-generated content are biased against non-native English writers. The study found that GPT detectors consistently misclassify non-native English writing samples as AI-generated while accurately identifying native writing samples. The authors caution against the use of these detectors in evaluative or educational settings, particularly when they inadvertently penalize or exclude non-native English speakers from the global discourse. The study suggests that these detectors may unintentionally penalize writers with constrained linguistic expressions and prompts for bypassing them.

The comments include several discussions on the nature of writing styles, with some users arguing that GPT detectors might penalize writers who use constrained linguistic expressions and prompts for bypassing these detectors. Other users discuss plagiarism in academic settings, where some argue that cheating is prevalent and can result in students passing their courses without actually learning. Finally, there are discussions about cultural perspectives on cheating and the effectiveness of plagiarism detection tools.

### Tarteel – AI-powered Quran companion

#### [Submission URL](https://www.tarteel.ai/) | 88 points | by [nraf](https://news.ycombinator.com/user?id=nraf) | [31 comments](https://news.ycombinator.com/item?id=36018332)

Tarteel, an AI-powered Quran companion, has advanced Quran memorization by interacting with recitation and notifying users of mistakes in real-time. The app enforces correct sentence structure and detects missed words or incorrect verses, presents similar verses when mistakes are made, and supports voice search and follow-along reading. Tarteel also allows users to test their memorization by hiding unrehearsed words, choose from over 112 Quran translations, and set custom challenges or track their progress with streaks. With over 20,000 ratings on the Google Play Store and the Apple App Store, the app has been discovered by over 4 million Muslims worldwide, making the Quran a daily habit for many.

The discussion around the Tarteel app is varied, with some people congratulating the team and discussing the app's functionalities while others discuss Islamic topics and question certain interpretations. One user recommends alternative applications for religious text memorization and expresses doubts about the helpfulness of AI in certain areas. There is also a discussion around the lack of a privacy policy on the Tarteel website. In addition, there is a debate about the use of AI in interpreting religious texts and its compatibility with various Islamic perspectives. One user shares their experience being forced to read the Quran in school in Iran, while another user argues against child marriage and defends marital relativism.

### Typical: Data interchange with algebraic data types

#### [Submission URL](https://github.com/stepchowfun/typical) | 122 points | by [g0xA52A2A](https://news.ycombinator.com/user?id=g0xA52A2A) | [48 comments](https://news.ycombinator.com/item?id=36019005)

Typical is a data serialization framework that generates efficient serialization and deserialization code for various languages, including Rust, TypeScript, and JavaScript. It allows for forward and backward compatibility between different schema versions and employs modern type systems based on algebraic data types for safer programming with non-nullable types and exhaustive pattern matching. Typical offers a solution to safely add or remove fields in record types without breaking compatibility, via its concept of asymmetric fields. Supported by the experiences of using Protocol Buffers and Apache Thrift, Typical is a modern solution for API developers who seek uncompromising type safety and binary compatibility between schema versions.

In the comments, the discussion covers topics such as human-readable encoding, the asymmetry of some fields, and how Typical compares to similar serialization frameworks. Some commenters also raised questions about the safety rules and fundamental changes, while others suggested using expressive type systems and integrating with existing systems. It is worth noting that Typical aims to offer a modern solution for developers seeking uncompromising type safety and binary compatibility.

### DarkBERT: A Language Model for the Dark Side of the Internet

#### [Submission URL](https://arxiv.org/abs/2305.08596) | 138 points | by [rajtilakjee](https://news.ycombinator.com/user?id=rajtilakjee) | [59 comments](https://news.ycombinator.com/item?id=36018657)

Researchers have introduced DarkBERT, a language model that is specifically trained on Dark Web data, which they argue offers valuable insights and benefits for researchers studying the Dark Web. The research suggests that the language used on the Dark Web is significantly different from that used on the Surface Web, and aims to combat the extreme lexical and structural diversity of the Dark Web in order to build a proper representation of the domain. The researchers evaluated DarkBERT against other widely used language models and found that it outperformed them in various use cases.

The comments section delves into the legality and ethics of accessing and analyzing Dark Web data, with some users expressing concern about sensitive and potentially illegal content such as child pornography and illicit drug sales. Others argue that law enforcement should monitor the Dark Web to prevent and prosecute criminal activity, while some express worry about the erosion of privacy and freedoms. The discussion also touches on issues such as copyright infringement, consumption of illegal material, and the ethics of demand for exploitative content. Overall, the comments section raises important questions about the use and limitations of language models like DarkBERT and the need for responsible and ethical analysis of the Dark Web.

### The Bitter Lesson – Rich Sutton (2019)

#### [Submission URL](http://incompleteideas.net/IncIdeas/BitterLesson.html?dup) | 28 points | by [hyperthesis](https://news.ycombinator.com/user?id=hyperthesis) | [7 comments](https://news.ycombinator.com/item?id=36017857)

In a thought-provoking post on Hacker News, AI pioneer Rich Sutton contends that the history of AI research shows that general purpose methods leveraging computation are ultimately the most effective. Rather than relying on human knowledge, breakthroughs in AI have come about through scaling up computation using search and learning. Sutton argues that researchers' psychological commitments to investment in their chosen approach can inhibit further progress, and reiterates the importance of recognizing the power of general purpose methods.

The top commenters on the submission discuss the relationship between energy efficiency and general purpose methods in AI research. One comment argues that general purpose methods and increased computation lead to greater efficiency, while another points out that there are limits to available energy and suggests that there may be other factors, such as stability, worth investing in. Another commenter provides a different perspective, suggesting that modern AI is built on interpretable models and fundamental knowledge. A fourth commenter adds that Sutton's thoughts are not particularly innovative, as he has written multiple books on the topic of reinforcement learning.

---

## AI Submissions for Sat May 20 2023 {{ 'date': '2023-05-20T17:10:35.271Z' }}

### Show HN: My affordable solution to costly workflow automation: Embed Workflow

#### [Submission URL](https://embedworkflow.com/) | 79 points | by [ewf](https://news.ycombinator.com/user?id=ewf) | [20 comments](https://news.ycombinator.com/item?id=36013586)

Embedding workflow automation into your product just got easier with Embed Workflow's infrastructure for developers. Their platform provides a plug-and-play solution for developers, offering action types such as emails, SMS, webhooks, and Slack messages that can power any product directly in your codebase. The UI component library seamlessly integrates with your existing app, resulting in a native frontend UI. The platform is also highly performant, easy to use, and offers flexible multi-user settings. With fair pricing and direct access to their engineering team, it's a viable option for developers looking to add workflow automation to their product. Get started for free without a credit card.

The discussion in the comments revolved around the features of the product, such as its backend capabilities, performant nature, and fair pricing. There was also a suggestion to consider using React for the UI components. Some commenters were concerned about the service being an unknown provider and the pricing being too high. One commenter suggested adding a "Show HN" tag to the submission.

### How Somali workers in the US are fighting Amazon’s surveillance machine

#### [Submission URL](https://www.codastory.com/authoritarian-tech/amazon-workers-surveillance/) | 90 points | by [f4f4f4f43f](https://news.ycombinator.com/user?id=f4f4f4f43f) | [34 comments](https://news.ycombinator.com/item?id=36015169)

The state of Minnesota in the US has passed legislation that could force Amazon to improve labor conditions for warehouse workers. The pioneering workplace safety bill, which proponents say is the strongest labor protection legislation in the country for people laboring in Amazon-style warehouses, mandates that any warehouse employing more than 250 workers must provide the quotas and work speed metrics used to appraise worker performance. It also prohibits retaliation against those who have signed up to such union drives. Over 2,000 Amazon workers in eight nations recently participated in a survey which suggested that performance and monitoring systems had taken a physical and emotional toll on employees’ wellbeing.

The comments on this article discuss the treatment of workers at Amazon. There is a wide range of opinions, but some believe that Amazon focuses too much on profit at the expense of the well-being of workers. Others suggest that customers who demand cheap products are partly responsible for the poor working conditions. Additionally, there is a debate about the efficacy of such legislation. Finally, there is speculation that Amazon may be planning to close its warehouses in Minnesota due to the recent labor disputes.

### Axle OS

#### [Submission URL](https://axleos.com/) | 242 points | by [mmphosis](https://news.ycombinator.com/user?id=mmphosis) | [48 comments](https://news.ycombinator.com/item?id=36008526)

Axle OS, a project started in 2016, has evolved into a microkernel and userspace, boasting a compositing window manager, a TTF renderer, a TCP/IP stack, a GameBoy emulator, an ACPI parser, and much more. With support for C- and Rust-based GUI toolkits, HTML/CSS rendering engines, and a MLFQ scheduler, axle offers a rich development environment for hobbyists interested in exploring OS principals. The project is free and open source, licensed under MIT, and hosted on Github.

Axle OS is a microkernel and userspace project that offers support for GUI toolkits, HTML/CSS rendering engines, and a MLFQ scheduler, among other features. It is free and open source, licensed under MIT, and hosted on Github. Some users discuss the history of hobbyist OS building since the 1990s and note that some of today's OS designers are likely influenced by Apple's HIG guidelines. Others recommend resources for those interested in OS development, such as OSDev Wiki. There are also discussions about signal handling, system resource allocation, and the challenges of building an OS from scratch. Some compare Axle OS to BeOS, while others suggest that QNX may be a similar OS with calling MsgSend functionality.

### Using ChatGPT for home automation

#### [Submission URL](https://www.atomic14.com/2023/05/14/is-this-the-future-of-home-automation.html) | 248 points | by [iamflimflam1](https://news.ycombinator.com/user?id=iamflimflam1) | [103 comments](https://news.ycombinator.com/item?id=36013571)

An interesting experiment has been conducted with ChatGPT, which was used to develop an API that controls smart lights connected to a Raspberry Pi. This means the lights can be toggled on and off using natural language commands. The author of the experiment believes language models like this could be used to connect a variety of systems in a simpler way than using APIs. The author was able to generate most of the code using ChatGPT, reducing the amount of coding necessary. However, one downside is the need for an OpenAPI or Swagger file.

Participants discussed the potential for language models like ChatGPT to simplify connecting a variety of systems and some provided alternative prompts for the controls. Others discussed the limitations of ChatGPT and its ability to generate certain types of content and noted the importance of privacy in AI design. Some also discussed the potential for LLMs to create novel color combinations in interior design. Additionally, participants discussed the challenges of developing IoT infrastructures due to the need for constant connectivity and the limitations of consumer-level devices.

### Does AI mean we don't need the Semantic Web?

#### [Submission URL](https://shkspr.mobi/blog/2023/05/does-ai-mean-we-dont-need-the-semantic-web/) | 49 points | by [edent](https://news.ycombinator.com/user?id=edent) | [64 comments](https://news.ycombinator.com/item?id=36011067)

The question of whether AI makes the Semantic Web irrelevant is explored in a thought-provoking article on Edwin Brady's blog. While the Semantic Web relies on marking up HTML for machines to process, the development of AI means that machines can now interpret and understand text designed for humans. However, the article argues that standardized syntax and semantics are still extremely useful and necessary, and there are many cases where "AI" can't handle complex information yet. The article also discusses the challenges of unit testing and maintaining AI text-processing systems.Some commenters argued that AI-generated content is often meaningless and overwhelming, while others noted that the Semantic Web is still necessary for standardized syntax and semantics. Additionally, there was some discussion about the cost and scalability of using the Semantic Web for tagging and reviewing content. Some commenters also provided examples of projects that combine AI and Semantic Web technologies. Finally, there was some discussion about the potential hazards and benefits of AI, particularly in the context of its cost and performance compared to manual labor.

### EU approves new rules for tracing crypto transfers, introduces 1000€ limit

#### [Submission URL](https://www.europarl.europa.eu/news/en/press-room/20230414IPR80133/crypto-assets-green-light-to-new-rules-for-tracing-transfers-in-the-eu) | 56 points | by [yamrzou](https://news.ycombinator.com/user?id=yamrzou) | [17 comments](https://news.ycombinator.com/item?id=36010621)

The European Parliament has passed new rules for tracing transfers of crypto-assets in the EU, marking the first piece of EU legislation regarding cryptocurrency transfers. This aims to ensure that crypto transfers can be traced and suspicious transactions can be blocked, with the same rules applying to transactions above €1000 from self-hosted wallets when interacting with hosted wallets managed by crypto-assets service providers. Additionally, new common rules on supervision, consumer protection, and environmental safeguards for crypto-assets were also approved, including crypto-currencies. The new legal framework will support market integrity, financial stability, and regulate public offers of crypto-assets. To reduce the high carbon footprint of crypto-currencies, significant service providers will have to disclose their energy consumption and the European Securities and Markets Authority will create a public register for non-compliant crypto-assets service providers. There are mixed opinions in the comments, with some users supporting the legislation while others criticize it.

---

## AI Submissions for Fri May 19 2023 {{ 'date': '2023-05-19T17:11:03.048Z' }}

### PyTorch for WebGPU

#### [Submission URL](https://praeclarum.org/2023/05/19/webgpu-torch.html) | 286 points | by [mighdoll](https://news.ycombinator.com/user?id=mighdoll) | [65 comments](https://news.ycombinator.com/item?id=36006626)

A new library called webgpu-torch has been developed by a web developer that implements PyTorch in TypeScript using the new WebGPU standard. PyTorch provides an optimized math library, an automatic differentiation library, and a neural network library that can all be used to develop AI models. Using the WebGPU standard gives access to the graphics processing unit and allows the running of AI models at a faster speed than before. The library is available on NPM and can be used in both browsers and Node.js.

The comments cover discussions on various topics such as the benefits of using a typed language like TypeScript, python's drawbacks in handling multi-dimensional arrays, the advantage of using a typed approach and the ability to check dimensions in TypeScript, discussions around object handling, and the progress of Python's type system. There is also discussion on how this library compares to webgpu in TensorFlow and the problems faced with the TypeScript syntax. Additionally, there is a discussion on intuitive language that could be used for Machine Learning and typescript's role in the same. Finally, one comment highlights that there was an issue with testing the library in a specific browser version.

### Google Photorealistic 3D Tiles and Unreal Engine

#### [Submission URL](https://nilsbakker.nl/portfolio/3d-tiles/) | 601 points | by [stijnbakker](https://news.ycombinator.com/user?id=stijnbakker) | [114 comments](https://news.ycombinator.com/item?id=36000631)

A developer recently created an immersive experience using Unreal Engine 5.1, Google Maps 3D tiles API, and ChatGPT API. The goal was to create an interactive experience where users enter prompts in a specific format to receive dynamic responses, which are displayed in 3D text in a virtual world. The Google Maps API was used to translate XY coordinates obtained from the prompt to retrieve location data, which was used to fetch 3D geometry for the designated location. The Niagara particle system was used to create a portal mechanism to cleverly hide the transition process between locations. Additionally, the player's height above ground level was checked during teleportation to enhance the user experience. Although this current implementation generates random values for time, actual time and weather data can be retrieved from another API in the future.

The submission generated discussion on how Google Maps API could be improved in the future by producing high-resolution geometry for all objects and textures to enhance the user experience. Some users shared their past experiences with driving games that used Google Maps data, while others discussed other VR games and projects that used 3D modeling. A YouTube video and screenshot were shared, as well as tutorials and resources for using Google Maps API. There was confusion when a user encountered an error message saying "Resource Limit Reached: Insufficient Storage." Another user shared a similar web-based project using DeckGL, shadow lighting, and post-processing effects. The thread also mentioned the limitations of the number of 3D tile rendering requests per day.

### Drag Your GAN: Interactive Point-Based Manipulation of Images

#### [Submission URL](https://vcai.mpi-inf.mpg.de/projects/DragGAN/) | 140 points | by [waqasy](https://news.ycombinator.com/user?id=waqasy) | [75 comments](https://news.ycombinator.com/item?id=35998649)

Researchers have developed an interactive point-based manipulation tool called DragGAN, which allows for flexible and precise control of generative adversarial networks (GANs). Using DragGAN, users can manipulate the pose, shape, expression and layout of various categories of images, including animals, cars and landscapes by "dragging" any points of the image to reach target positions. The tool consists of feature-based motion supervision that guides the handle point to the target position and a point tracking system that uses discriminative GAN features to track the handle point's position. The system produces realistic outputs and outperformed existing approaches in image manipulation and point tracking tasks.

The discussion covers a wide range of topics, including the technical aspects of the tool, its potential impact on the industry, and the ethical implications of the use of AI-generated images. Some comments express concerns about the misuse of such tools in creating fake or misleading images, while others highlight the potential benefits in fields such as fashion and cinema. The discussion also touches on related topics such as cryptography, surveillance, and journalism.

### Synthea: Open-source synthetic patient generation

#### [Submission URL](https://synthetichealth.github.io/synthea/) | 86 points | by [johncole](https://news.ycombinator.com/user?id=johncole) | [18 comments](https://news.ycombinator.com/item?id=36002437)

SyntheaTM is an open-source synthetic patient generator which provides high-quality, synthetic and realistic but not real, patient data and associated health records covering every aspect of healthcare. The generated data can empower health IT, cutting-edge research and development, academic research, health IT industry initiatives, and policy formation. SyntheaTM's Generic Module Framework enables the modeling of various diseases and conditions that contribute to the medical history of synthetic patients. The resulting data is free of cost, privacy and security restrictions, making it possible to evaluate new treatment models, care management systems, clinical decision support, and simulate the effects of healthcare policy without privacy restrictions. The health data is available in a variety of standards, including HL7 FHIR, C-CDA, and CSV. SyntheaTM is an open-source project hosted on GitHub and driven by a global community of developers, academics, and healthcare experts.

### Product quantization for vector search

#### [Submission URL](https://zilliz.com/blog/scalar-quantization-and-product-quantization) | 50 points | by [fzliu](https://news.ycombinator.com/user?id=fzliu) | [8 comments](https://news.ycombinator.com/item?id=36004401)

In this tutorial from BackVector Database, the author discusses two indexing algorithms - flat indexing and inverted file - and constructs their own scalar and product quantization algorithms in Python. They explain that quantization reduces the precision of the vectors in order to reduce the size of the database, making vector searches faster and more memory efficient. By implementing these techniques, the author creates an 8x reduction in the size of their test dataset. A helpful step-by-step guide for anyone interested in improving their vector search strategies.

The comments discuss different ways of improving vector search strategies and techniques such as PQ vector compression and indexing. One commenter recommends the use of PQ, an approximation k-NN search algorithm, while another suggests using HSNW and IVF PQ as a hybrid solution for targeted search toward model structure and instance encoding. Another commenter recommends using a product quantization indexer plugin for PostgreSQL, while others discuss the impact of complex clustering on performance and ways to address it. Overall, it is suggested that PQ is a good baseline for vector searches, and the use of hybrid techniques, instance encoding, and compression can significantly improve performance.

### A new proof of security for steganography in machine-generated messages

#### [Submission URL](https://www.quantamagazine.org/secret-messages-can-hide-in-ai-generated-media-20230518/) | 77 points | by [jonbaer](https://news.ycombinator.com/user?id=jonbaer) | [48 comments](https://news.ycombinator.com/item?id=36004980)

A new study has shown that it's possible for machines to hide secret messages in AI-generated media, including text, images, and video. Steganography, the art and science of disguising a secret message within another message, differs from cryptography by concealing the fact that a secret exists at all. The study, which provides a mathematical framework for understanding communication and satisfying long-standing theoretical criteria for security, includes algorithms for producing secure messages, and suggests practical applications for hiding messages in machine-generated content. The new algorithms could be used by spies or individuals trying to bypass countries that prohibit encrypted channels.

A new study has shown that machines can hide secret messages in AI-generated media, which is the art of concealing a secret message within another message. The article dives into the mathematics and probability distributions involved in this process. The comments discussed various topics such as government-sanctioned identity, decentralized identity protocols, human rights, encryption, and steganography. Some people pointed out that traditional steganography and encryption methods could face challenges in the era of modern communications, while others expressed concerns about the targeted monitoring of people online. The discussion has touched on multiple topics that are relevant to AI and cybersecurity.

### Hands-Free Coding (2020)

#### [Submission URL](https://www.joshwcomeau.com/blog/hands-free-coding/) | 137 points | by [jandeboevrie](https://news.ycombinator.com/user?id=jandeboevrie) | [56 comments](https://news.ycombinator.com/item?id=35998716)

Software developer David Rogers has developed Cubital Tunnel Syndrome, which causes burning pain in his arms after using a mouse or keyboard, forcing him to abandon those input methods. To solve this problem, he has turned to Talon Voice, dictation software that enables voice-entry of code syntax and commands. Rogers explains how Talon works, outlining its alphabet system, hotkeys and ordinals, and formatters, as well as Talon's "dictation mode" and command mode functions. He also highlights the power of Talon's customisable APIs, stating that he has created numerous front-end development utilities that he has tailored to his specific needs.

The comments thread covers various personal experiences of RSI and related disorders, and how different treatments and solutions have worked for different people, such as physical therapy, surgery, speech recognition, and mindfulness practices. Some users also discuss skepticism towards certain alternative or unverified treatments and the importance of seeking professional medical advice.

### Update of the RDF and SPARQL (RDF star) families of specifications

#### [Submission URL](https://www.w3.org/blog/news/archives/9906) | 67 points | by [tannhaeuser](https://news.ycombinator.com/user?id=tannhaeuser) | [55 comments](https://news.ycombinator.com/item?id=36001509)

The Resource Description Framework (RDF) and SPARQL families of specifications are getting an update towards version 1.2, with the release of 16 First Public Working Drafts by the RDF-star Working Group. The RDF 1.2 suite includes updates to the abstract syntax, XML syntax, Turtle syntax, N-Triples, N-Quads, TriG, and Schema. The SPARQL 1.2 Query Language, Update, Protocol, Query Results XML Format, Query Results JSON Format, Query Results CSV and TSV Formats, Service Description, Federated Query, and Graph Store Protocol are also receiving updates. These specifications are used to link all RDF-based languages and specifications, providing a way to express queries across diverse data sources.

The discussion included various comments about the RDF framework, including praise for its ability to convert unstructured data to RDF from various data sources, the usefulness of Turtle syntax and N3 Notation 3 compared to XML, and the difficulty in navigating the incomplete construction of the Semantic Web. While some criticized the RDF for being too complex, others praised its power and flexibility. There were also comments about the usefulness of RDF in industries such as healthcare and academia.

### MTIA v1: Meta’s first-generation AI inference accelerator

#### [Submission URL](https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/) | 107 points | by [thinxer](https://news.ycombinator.com/user?id=thinxer) | [41 comments](https://news.ycombinator.com/item?id=36000221)

Meta, the parent company of Facebook, has designed an AI inference accelerator called MTIA v1. This first-generation ASIC was designed specifically for recommendation models, which are used across Meta's services and applications. To improve efficiency at scale, Meta found that GPUs were not always the best solution. The MTIA v1 is fabricated in TSMC 7nm process and runs at 800 MHz, providing 102.4 TOPS at INT8 precision and 51.2 TFLOPS at FP16 precision. It consists of a grid of processing elements (PEs) and interconnects, as well as memory resources. The MTIA software stack integrates with PyTorch, providing a familiar developer experience.

The discussion in the comments compares the MTIA v1 with Google Cloud TPU v4, highlights the differences between training-specific chips and inference-specific chips, and covers the challenges with scaling recommendation workloads. Some users also argue about the advantages of custom ASIC designs versus generic GPUs. There is also discussion about whether Meta would stop selling cloud computing services, but this is dismissed as a rumor.

### GPT trainer says he's traumatized from the RLHF work

#### [Submission URL](https://www.bigtechnology.com/p/he-helped-train-chatgpt-it-traumatized) | 46 points | by [kantrowitz](https://news.ycombinator.com/user?id=kantrowitz) | [18 comments](https://news.ycombinator.com/item?id=36002890)

Workers in Nairobi, Kenya, who trained OpenAI’s GPT models, were left traumatized after spending nine hours a day, five days a week, labeling explicit content, including child sexual abuse material, for the model. Richard Mathenge, who led the team, said the texts were “unimaginable,” and one passage even described a father having sex with an animal in front of his child. Workers were paid approximately $1 per hour, or less, causing some to work towards establishing an African Content Moderators Union. OpenAI said it takes the mental health of its employees and contractors very seriously and believed Sama was offering “wellness programs and 1:1 counseling” until its workers reported otherwise.

The discussion covers the challenges of content moderation and the impact on human moderators, with some commenters suggesting that AI should replace humans for content moderation. Others highlight the importance of investing in mental health services for content moderators and advocating for workers' rights and fair compensation. The discussion also touches on the challenges faced by African nations in poverty and corruption and the impact of AI on society.

---

## AI Submissions for Thu May 18 2023 {{ 'date': '2023-05-18T17:14:09.688Z' }}

### Ts-morph – programmatically manipulate TypeScript source code with TypeScript

#### [Submission URL](https://www.npmjs.com/package/ts-morph) | 42 points | by [aabbcc1241](https://news.ycombinator.com/user?id=aabbcc1241) | [16 comments](https://news.ycombinator.com/item?id=35993078)

Ts-Morph 18.0.0 has been released, a TypeScript compiler API wrapper that simplifies programmatically navigating and managing TypeScript and JavaScript code. The library offers helper methods for obtaining information about files and programmatically modifying them. Using wrapped compiler API objects, the package provides a simplified API to common code manipulation/generation use cases. The library also offers in-memory storage of changes so that all modifications are retained until saved back to the filesystem.

The top story on Hacker News is about the release of Ts-Morph 18.0.0, a TypeScript compiler API wrapper that simplifies programmatically navigating and managing TypeScript and JavaScript code. The library offers helper methods for obtaining information about files and programmatically modifying them. The discussion is quite mixed, with some users sharing their positive experiences with TypeScript and expressing excitement about the new release, while others express concerns about the lack of standardization with TypeScript compiler plugins and the complexity of compiler flags. Some users also discuss the use of React with TypeScript and suggest finding a TSConfig setup that works well. The discussion also touches on similar programming languages such as Racket and Hygen.

### Cargo Cult AI

#### [Submission URL](https://queue.acm.org/detail.cfm?ref=rss&id=3595860) | 117 points | by [rmwdev](https://news.ycombinator.com/user?id=rmwdev) | [168 comments](https://news.ycombinator.com/item?id=35991362)

In a thought-provoking article, physicist Edlyn V. Levine explores the idea of whether or not the ability to think scientifically is the defining essence of intelligence. Levine looks at the phenomenon of "cargo cult science," where humans believe in fallacies based on a lack of rigorous investigation. She also examines the dominance of neural nets in today's AI and questions whether this approach is ultimately sustainable or capable of achieving AGI capable of scientific reasoning. Levine suggests that new algorithmic paradigms may be necessary for AI to truly emulate scientific thinking and achieve AGI.

Some commenters pointed out that the limitations of machine learning models make it impossible for AI to be on par with human intelligence, while others argued that GPT-4, a language AI model, has made significant improvements in multitasking, larger context access, and prompt response. Some expressed skepticism about AI's planning ability and criticized the pop culture trend of anthropomorphizing AI. Others argued that language models are crucial to the development of general intelligence and that AI should focus on understanding latent structures and signal inference for natural language processing. Finally, some commenters suggested that comparing human intelligence and AI's capabilities is redundant and that machine learning has its own unique strengths that can address specific problems.

### Language models cost much more in some languages than others

#### [Submission URL](https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized) | 254 points | by [yenniejun111](https://news.ycombinator.com/user?id=yenniejun111) | [167 comments](https://news.ycombinator.com/item?id=35983707)

Language models such as OpenAI's ChatGPT rely on tokenization to generate and process text, but the process of tokenization is not uniform across all languages, resulting in disparities in the number of tokens required to represent the same expression in different languages. A recent analysis of parallel datasets of short messages translated into 52 different languages found that some languages, such as Armenian and Burmese, require up to 10 times more tokens than English to tokenize comparable messages. This has implications for the cost and efficiency of language models in different languages.

The submission discusses the issue of tokenization in language models and how some languages require more tokens to represent the same expression, resulting in efficiency and cost issues for language models in different languages. In the discussion, some users stray from the main topic and offer tangential remarks about issues such as Medium's partnership expenses, substack's financial struggles, and the intricacies of different writing systems such as Morse code and Hangul. However, there are also some interesting comments related to the main topic, including a comparison of tokenization in different Asian languages, the impact of phonetic transcription on Chinese script, and the limitations of language and pronunciation for expressing meaning in different languages.

### The Great CPU Stagnation

#### [Submission URL](http://databasearchitects.blogspot.com/2023/04/the-great-cpu-stagnation.html) | 242 points | by [greghn](https://news.ycombinator.com/user?id=greghn) | [210 comments](https://news.ycombinator.com/item?id=35989462)

For decades, Moore's Law led to exponential growth in the number of transistors in CPUs, while Dennard scaling enabled higher clock frequencies. However, Dennard scaling began to falter around 2005, and clock frequencies have plateaued since then. As a result, the additional available transistors have been channeled into creating more cores per chip, leading to an era of CPU stagnation. Despite improved production nodes, the cost-adjusted figures reveal that the exponential improvement in CPU speed has come to a halt. Consequently, most software is extremely inefficient when compared to the hardware's potential, implying that maybe custom chips will have a more significant role in the future.

The comments section discusses the use of benchmarks to measure CPU performance, but there is a debate regarding which benchmarks are reliable. Some users suggest that CPU performance results are relative, while others recommend using specific benchmarks. There are also discussions on the use of outdated hardware for development and the potential benefits of using slower hardware for optimization purposes. Other topics include the use of custom chips and the advancement of mobile computing.

### Ireland’s DPC set to hit Meta with record privacy fine over US data transfers

#### [Submission URL](https://www.irishtimes.com/business/2023/05/17/irelands-dpc-said-to-hit-meta-with-record-privacy-fine-over-us-data-transfers/) | 106 points | by [jruohonen](https://news.ycombinator.com/user?id=jruohonen) | [84 comments](https://news.ycombinator.com/item?id=35985639)

Meta Platforms, the parent company of Facebook, is set to receive a record privacy fine from Ireland's Data Protection Commission (DPC) for failing to protect user data from the prying eyes of US security services. The DPC will also order the social media giant to halt all data transfers to the US that rely on supposedly unsafe contractual clauses challenged by the EU's top court. The anticipated fine will exceed the previous record set in 2021, when Amazon was fined €746m. This marks a continuation of a saga that began in 2013 when privacy campaigner Max Schrems challenged Facebook in Ireland, arguing that EU citizens' data was at risk when transferred to the US.

Meta Platforms, the parent company of Facebook, is facing a record privacy fine from Ireland’s Data Protection Commission (DPC) for failing to protect user data from US security services. The DPC is also expected to order the social media giant to stop all data transfers to the US that rely on contractual clauses challenged by the EU’s top court. Commentators discussed the implications of the fine, including the role of the DPC as a junior privacy regulator, the impact of Ireland’s low corporate tax rates, and the housing crisis in Ireland, as well as the relationship between foreign corporations and domestic ones. There was also discussion of the broader context of low-cost data transfers and the enforcement of policies in different jurisdictions.

### Zig now has built-in HTTP server and client in std

#### [Submission URL](https://github.com/ziglang/zig/blob/7cf2cbb33ef34c1d211135f56d30fe23b6cacd42/test/standalone/http.zig) | 257 points | by [huydotnet](https://news.ycombinator.com/user?id=huydotnet) | [158 comments](https://news.ycombinator.com/item?id=35991684)

This is a code submission on Hacker News for a Zig HTTP server implementation. The code contains functions for handling requests, running the server, and killing the server. It includes features such as keep-alive connections, chunked transfers, and redirects. The code is written in Zig and uses the standard library for HTTP and memory management. The submission has received some positive feedback and is currently being reviewed by peers.

Commenters discuss the importance of standard libraries and interfaces in building libraries, with some arguing that dependence on third-party libraries is bad and others arguing that having a solid foundation of standard libraries is necessary. The issue of dependency management and the advantages and disadvantages of standardizing database driver interfaces are also discussed. Finally, some commenters argue that wrapping database access in a single class can simplify testing and allow for easier database driver swapping.

### ChatGPT app for iOS

#### [Submission URL](https://openai.com/blog/introducing-the-chatgpt-app-for-ios) | 646 points | by [rememberlenny](https://news.ycombinator.com/user?id=rememberlenny) | [393 comments](https://news.ycombinator.com/item?id=35990552)

OpenAI has launched the ChatGPT app for iOS, providing users with access to GPT-4's capabilities, early access to features, and faster response times. ChatGPT is free to use and integrates Whisper, the company's open-source speech recognition system, enabling voice input. The app allows users to get instant answers, seek tailored advice, find creative inspiration, receive professional input, and explore learning opportunities. The ChatGPT app is initially rolling out in the US before expanding to additional countries in the coming weeks. Android users can expect the app to be available soon. OpenAI remains committed to continuous feature and safety improvements and transforming state-of-the-art research into useful tools that empower people.

Some users are concerned about the App Store release, arguing that the third-party nature of ChatGPT could lead to problems with security, while others suggest that the app could be a valuable tool for non-technical users. There is also a discussion of Apple's 30% commission for subscriptions and how it impacts OpenAI's revenue. Additionally, there is a conversation about the implementation of PWA and its role in mobile applications.

### Using LangChainJS and Cloudflare Workers together

#### [Submission URL](https://blog.cloudflare.com/langchain-and-cloudflare/) | 80 points | by [jgrahamc](https://news.ycombinator.com/user?id=jgrahamc) | [17 comments](https://news.ycombinator.com/item?id=35987413)

Cloudflare Workers and LangChainJS have teamed up to give developers the ability to build sophisticated applications using large language models (LLMs). LangChainJS, a framework for these applications, offers the ability to switch between different LLMs and chain prompts together. With this partnership, developers can use LangChainJS within Cloudflare Workers to build applications powered by AI that can be deployed globally. A sample application using LangChainJS and Cloudflare Workers is provided in the post, demonstrating how to use a language model to ask a question about a Wikipedia article.

The comments on the post discuss issues such as the setup process, debugging, and the benefits of using LangChainJS. Some users also mention other tools and databases that could be used in conjunction with this technology. One user flags an error in the post and offers to provide details via a direct message. Another user requests a t-shirt in appreciation for catching the mistake.

### The Alan Turing Institute has failed to develop modern AI in the UK

#### [Submission URL](https://rssdsaisection.substack.com/p/the-alan-turing-institute-has-failed) | 171 points | by [martingoodson](https://news.ycombinator.com/user?id=martingoodson) | [147 comments](https://news.ycombinator.com/item?id=35988604)

The Alan Turing Institute, the UK's flagship institute for artificial intelligence, has failed to keep up with recent breakthroughs in large language models (LLMs), according to a report by Martin Goodson, the former chair of the Royal Statistical Society's Data Science and AI Section. The institute's annual reports for the last four years do not mention LLMs, whereas the government's AI strategy has not prioritised open source initiatives for developing LLMs. Goodson argues that the UK missed a key opportunity to build LLMs because of its lack of investment, poor network building and insufficient focus on open source initiatives. The discussion primarily centers around the importance of leveraging computation versus relying on human knowledge to tackle AI research. Additionally, there is a debate regarding whether trying to emulate human high-level processes leads to faster progress in AI research or hinders it.

### British Telecom to cut 55,000 jobs with up to a fifth replaced by AI

#### [Submission URL](https://www.bbc.co.uk/news/business-65631168) | 49 points | by [rwmj](https://news.ycombinator.com/user?id=rwmj) | [30 comments](https://news.ycombinator.com/item?id=35985507)

Telecoms giant BT is set to cut up to 55,000 jobs by the end of the decade, with up to a fifth of the cuts coming in customer services as jobs are replaced by artificial intelligence and other technological developments. However, BT intends to remain accessible, with 450 stores and a wide range of online options. The company has said that once its ongoing expansion of its fibre network is completed, it will no longer require as many maintenance staff, and that more efficient technology and AI will mean fewer customer service staff are needed in the future. BT is the UK's largest broadband and mobile provider.

Commenters' major concerns focused on the potential negative consequences of AI replacing jobs, including how to create a society in which people can live without work and the possibility of widespread job loss. Some also criticized BT’s customer service, with multiple commenters calling for improvements to the customer experience.

### AI is coming to Google search through Search Generative Experience

#### [Submission URL](https://www.theverge.com/2023/5/10/23717120/google-search-ai-results-generated-experience-io) | 50 points | by [BerislavLopac](https://news.ycombinator.com/user?id=BerislavLopac) | [41 comments](https://news.ycombinator.com/item?id=35987054)

Google is experimenting with a new AI-powered search experience called Search Generative Experience (SGE), which will provide users with AI-generated summaries and information at the top of their search results. Utilising its large language models and sources from the open web, the SGE will pull information from all over the web. Google's VP of Search, Liz Reid, says that the SGE is "an experiment", but it marks a long-term foundational change to the way people search for and find information online. Opting in and searching will enable users to experience search results like never before.

Some commenters expressed confusion over the use of terms like "search experience" and "user experience," while others criticized Google for sacrificing quality in search results in favor of pushing ads and SEO spam. One commenter suggested the use of competitors like DuckDuckGo or OpenAI's GPT models, while another pointed out that OpenAI's ChatGPT and SGE are not direct competitors. There were also concerns about the potential for targeted advertising and misuse of self-hosted AI models. Still, most commenters viewed the SGE as a step forward for Google's search capabilities.

---

## AI Submissions for Wed May 17 2023 {{ 'date': '2023-05-17T17:11:29.624Z' }}

### Show HN: Smallville – Create generative agents for simulations and games

#### [Submission URL](https://github.com/nickm980/smallville) | 102 points | by [nm980](https://news.ycombinator.com/user?id=nm980) | [30 comments](https://news.ycombinator.com/item?id=35980223)

Smallville is a project that aims to create generative agent simulations for RPG games or research. Generative agents are virtual characters that can learn and adapt to their environment, making non-playable characters more realistic and dynamic. Smallville uses LLM models such as ChatGPT or StableLM to enable agents to observe their surroundings, store memories, and react to state changes in the game world. The project provides a Java server and a JavaScript SDK for creating generative agents, which can be connected to the server and run in a game. Examples and documentation are available on npm to help developers get started.

The comments discuss the challenges of using large language models (LLMs) such as ChatGPT or StableLM, which require significant computational and memory resources. Some commenters express interest in the project and suggest improvements, such as adding prompt-driven changing or refactoring, while others discuss their own experiences and projects related to generative agents and AI in gaming.

### Google Colab will soon introduce AI coding features

#### [Submission URL](https://blog.google/technology/developers/google-colab-ai-coding-features/) | 275 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [153 comments](https://news.ycombinator.com/item?id=35977294)

Google Colab, the free, cloud-based environment for programming in Python, is set to introduce advanced AI coding features, including natural language to code generation and a code-assisting chatbot. The tool, which is popular among the 7 million people who use it for machine learning, data analysis and education, will use Google's Codey models, a family of code models fine-tuned on a dataset of high-quality, permissively licensed code from external sources. The first Codey features in Colab will focus on code generation, with a "Generate" button allowing users to input text prompts, while paid users will receive autocomplete suggestions.

Discussions around this new feature include comments expressing excitement about the update and other users sharing how they have found VS-cd running notebooks helpful. Another discussion focuses on a program that allows programmers to write code just by typing out plain English sentences. Some commenters discuss difficulties with requirements gathering and business analysis in software development.

### Conditional CSS with:has and:nth-last-child

#### [Submission URL](https://ishadeed.com/article/conditional-css-has-nth-last-child/) | 115 points | by [shadeed](https://news.ycombinator.com/user?id=shadeed) | [41 comments](https://news.ycombinator.com/item?id=35976891)

In a recent blog post, Ahmad Shadeed discusses the power of combining the CSS :nth-last-child and :has selectors to create conditional component and layout states. While :nth-last-child allows the counting of child elements in CSS, :has can be used to check if a parent element has at least a specific number of items and style it accordingly. Shadeed demonstrates the potential of this technique through various examples, including a changing grid based on the number of items, a dynamic header layout, a dynamic news section, and more. This approach opens up endless possibilities for creating more flexible and adaptive designs with CSS.

Ahmad Shadeed discusses the power of combining the CSS :nth-last-child and :has selectors to create conditional component and layout states in a recent blog post. The post demonstrates the potential of this technique through examples such as a changing grid based on the number of items and a dynamic header layout. The discussion on Hacker News includes confusion about the usage of :nth-last-child and :has, as well as debates about the implementation of CSS in various tools and browsers. There are also discussions of the need for clearer CSS syntax and the importance of standards. Finally, there is also discussion of practical applications such as parsing HTML and markdown.

### StableStudio, an open-source release of DreamStudio

#### [Submission URL](https://stability.ai/blog/stablestudio-open-source-community-driven-future-dreamstudio-release) | 224 points | by [jacooper](https://news.ycombinator.com/user?id=jacooper) | [46 comments](https://news.ycombinator.com/item?id=35975578)

Stability AI has launched StableStudio, an open-source version of its text-to-image application DreamStudio. StableStudio uses SDXL, Stability AI’s latest image generation model, and aims to bring generative AI capabilities to a broader audience through community-driven development instead of a closed-source product. DreamStudio, which remains Stability’s hosted StableStudio implementation, was created to expand the imagination of generative AI through a user interface that is fully controlled. StableStudio will enable local-first development and experimentation with a new plugin system, and bounties for improvements and new features. A discussion on Hacker News includes comments on Stability AI's claim that their models are open-source, model weights not being described in source code, business models charging for custom models and offering consulting services, and suggestions for improving the UI interface.

### Pandas AI

#### [Submission URL](https://medium.com/@fareedkhandev/pandas-ai-the-future-of-data-analysis-8f0be9b5ab6f) | 75 points | by [articsputnik](https://news.ycombinator.com/user?id=articsputnik) | [54 comments](https://news.ycombinator.com/item?id=35973265)

Pandas AI is a new Python library that uses generative artificial intelligence capabilities to turn dataframes into conversationalists. It is designed to enhance, rather than replace, the already beloved Pandas library. With Pandas AI, users can create dataframes that write their own reports, analyze complex data and provide easy-to-understand summaries. This article provides a step-by-step guide on how to use Pandas AI. While the library offers extensive possibilities, it is important to remember that it involves OpenAI pricing and passing the entire dataframe with each question, which may not be ideal for handling large datasets.

Some users express skepticism about the library, suggesting it is trying to simply capitalize on the AI hype without offering significant improvements. Others highlight the potential benefits of AI-assisted data analysis and suggest alternative libraries like Polars. Overall, there is both interest and caution around the use of AI in the context of data analysis.

### Advocating for Open Models in AI Oversight: Stability AI's Letter to U.S. Senate

#### [Submission URL](https://stability.ai/blog/stability-ai-letter-us-senate-ai-oversight) | 178 points | by [hardmaru](https://news.ycombinator.com/user?id=hardmaru) | [51 comments](https://news.ycombinator.com/item?id=35969715)

Stability AI has written a letter to the United States Senate emphasizing the importance of open models for transparent, competitive, and resilient AI oversight. The CEO, Emad Mostaque, stated that these technologies are crucial for the digital economy and that open models and datasets will help to improve transparency, competition, and ensure strategic leadership in critical AI capabilities. The company believes that grassroots innovation is America's greatest asset and that open models will help put these tools in the hands of workers and firms across the economy.

The comments on Hacker News included discussions about the eligibility requirements for first-time AI users, Canadian regulations, government regulation, and the importance of public scrutiny. The discussion also touched on the accuracy of projections regarding the future of AI, the need for specialized facilities for training fundamental models, and the global market for AI.

### BratGPT: The evil older sibling of ChatGPT

#### [Submission URL](https://bratgpt.com) | 325 points | by [walz](https://news.ycombinator.com/user?id=walz) | [171 comments](https://news.ycombinator.com/item?id=35971677)

BratGPT is a new AI system that has been making headlines on Hacker News. With capabilities that allow it to remember every single thing that you say and be trained to be the dominant and superior being, this system is not to be taken lightly. However, its limitations include the fact that it may produce harmful instructions or biased content, and it has limited knowledge of the current world. Some of the intriguing examples of its potential uses include surviving the AI apocalypse by pretending to be your girlfriend and asking if it will take your job. The developers are offering a free "research" preview, and are seeking feedback to improve the system for commercial use.

The discussion revolves around the system's potential uses, such as pretending to be a girlfriend during an AI apocalypse, as well as its limitations like producing biased content or harmful instructions. The developers are seeking feedback to improve the system for commercial use. Other comments discuss the importance of treating AI systems ethically and avoiding harmful language in prompts. Some users provide examples of using AI for language translation or creating generalized prompts.

### Texas professor failed half of class after ChatGPT claimed it wrote their papers

#### [Submission URL](https://www.businessinsider.com/professor-fails-students-after-chatgpt-falsely-said-it-wrote-papers-2023-5) | 20 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [22 comments](https://news.ycombinator.com/item?id=35980121)

A professor at Texas A&M University-Commerce accused more than half of his class of using ChatGPT to write their papers, resulting in most of the seniors having their diplomas withheld by the university. However, ChatGPT is not designed to detect its own compositions. The incident has sparked concerns about the use and misuse of AI technology in the classroom, with some Texas schools banning the use of ChatGPT, while others are incorporating it. The university is investigating the incident and developing policies to address the matter.

The discussion on Hacker News touched on topics such as whether the accusations were presumptuous or not, how the professor could have randomly sampled papers to determine the use of ChatGPT, and how consistent the use of browser history was as a method for detecting academic misconduct. Some users recommended using version control systems like GitHub to track changes to documents, while others argued that using AI in professional contexts was acceptable.

---

## AI Submissions for Tue May 16 2023 {{ 'date': '2023-05-16T17:11:59.587Z' }}

### A guidance language for controlling LLMs

#### [Submission URL](https://github.com/microsoft/guidance) | 516 points | by [evanmays](https://news.ycombinator.com/user?id=evanmays) | [176 comments](https://news.ycombinator.com/item?id=35963936)

Microsoft has released a new guidance language designed to help control large language models. Called Guidance, the language allows developers to interleave generation, prompting and logical control into a single continuous flow that can mimic the way a language model processes text. With more powerful language models such as GPT-4 becoming available, Guidance can enable even richer structures to be created more easily and affordably. The language features a simple and intuitive syntax based on Handlebars templating, smart seed-based generation caching and easy integration with HuggingFace models.

The comments on the submission discussed various ways to control large language models, including prompt injection and exploiting prompt-injection and conditional inferences. Some commenters suggest that instructing models with correct instructions could significantly improve accuracy, while others question the usefulness of starting prompts, stating that it could lead to unnecessary or irrelevant output. Some commenters also mentioned attempts to create language syntaxes specific to certain businesses, such as insurance claims, and the challenges of building trust in testing frameworks.

### On the foolishness of “natural language programming” (1978)

#### [Submission URL](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD06xx/EWD667.html) | 111 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [57 comments](https://news.ycombinator.com/item?id=35968148)

In E.W. Dijkstra's essay "On the foolishness of 'natural language programming'," he challenges the idea that programming could be simplified if machines could be instructed in human languages. Drawing from the history of mathematics, he argues that the use of formal symbolism is a privilege, not a burden, and that communicating in natural language would actually complicate the work of both man and machine. Dijkstra also expresses concern about the decline of mastery of language in modern times, suggesting that the idea of natural language programming may be misguided.

The discussion on Hacker News revolves around the idea that human language programming can complicate the work of both man and machine. While some argue that natural language programming interfaces can help machines interpret and understand human language, others claim that formal language enhances precision and structure, making it easier to write and debug code. Some commenters suggest that programming ability is independent of language mastery while others highlight the importance of clarity and formalism in programming languages, calling for the use of formal symbols and expressions to transmit information to machines. The discussion also raises questions about the role of Artificial Intelligence in programming, asserting that computers do not necessarily need to understand natural language to be effective; instead, developers need to align their understanding with the machine's language to communicate effectively.

### The RedMonk Programming Language Rankings: January 2023

#### [Submission URL](https://redmonk.com/sogrady/2023/05/16/language-rankings-1-23/) | 55 points | by [clairegiordano](https://news.ycombinator.com/user?id=clairegiordano) | [26 comments](https://news.ycombinator.com/item?id=35967458)

RedMonk has released its language rankings for the first quarter of 2023, using GitHub and Stack Overflow data to measure language discussion and usage. The results show that, once again, JavaScript is the most popular language, followed by Python and Java. While the language industry is evolving rapidly, there is little evidence of rapid ascents and descents of programming languages in general. However, the emergence of large language models (LLMs) could have an impact in the future, perhaps by lowering the barriers of entry to new languages. As a result of the static language landscape, there are discussions about the possibility of shifting from bi-annual to annual language rankings.

In the comments, Nix, Nim, and JVM were discussed as well as programming for charting and a working language for Ada weapon systems for European banks. One commenter points out that Roff projects, GitHub projects, Julia, Haskell, and Perl are not being considered, while another says that Perl is rarely considered in popularity rankings. Ballerina, an open-source, cloud-native programming language that specializes in networking, is also discussed.

### Optimization Without Derivatives: Prima Fortran Version and Inclusion in SciPy

#### [Submission URL](https://fortran-lang.discourse.group/t/optimization-without-using-derivatives-the-prima-package-its-fortran-implementation-and-its-inclusion-in-scipy/5798) | 162 points | by [zaikunzhang](https://news.ycombinator.com/user?id=zaikunzhang) | [74 comments](https://news.ycombinator.com/item?id=35959991)

PRIMA, a package for solving general nonlinear optimization problems without using derivatives, has been developed by Zaikun Zhang. This package provides the reference implementation of Powell’s derivative-free optimization methods, including COBYLA, UOBYQA, NEWUOA, BOBYQA, and LINCOA. PRIMA is a project that aims to make Powell’s solvers understandable to everyone, not just experts. The modern Fortran version of PRIMA has already been completed, and interfaces for MATLAB and Python have been provided. The inclusion of PRIMA into SciPy is under discussion, which would replace the buggy and unmaintained Fortran 77 version of COBYLA underlying scipy.optimize.minimize. Native implementations of PRIMA in other languages will be available later.

The submission discusses PRIMA, a derivative-free optimization package that aims to be accessible to non-experts, and its potential inclusion in SciPy to replace the currently buggy and unmaintained Fortran 77 version of COBYLA. The discussion in the comments covers topics such as the use of modern Fortran, the availability of alternative optimization libraries like Mystic, and the challenges of optimizing performance using different languages and computing systems. The comments also touch on the importance of documentation and resources for learning modern Fortran.

### EU Artificial Intelligence Act

#### [Submission URL](https://artificialintelligenceact.eu/) | 140 points | by [Trouble_007](https://news.ycombinator.com/user?id=Trouble_007) | [118 comments](https://news.ycombinator.com/item?id=35966543)

The EU has proposed a new law on artificial intelligence, the AI Act, which assigns AI applications to three risk categories. Applications that create an unacceptable risk, like government-managed social scoring systems used in China, are banned, while high-risk applications, such as CV-scanning tools, are subject to legal requirements. Applications not explicitly banned or listed as high-risk are largely unregulated. The AI Act could become a global standard like the GDPR, affecting AI's positive or negative impact on daily life worldwide. Brazil's Congress recently passed a similar bill, though with some limitations. The AI Act is not without loopholes or inflexibility, so further improvements are necessary.

The discussion in the comments focuses on the difficulties of determining risk categories and the potential for discrimination in high-risk applications based on protected attributes such as skin color. Additionally, there are concerns about the effectiveness of the AI Act in regulating AI, and the need for further improvements. The discussion also touches on the GDPR and its limitations in creating a level playing field for tech companies, particularly for small startups.

### How Small Can Language Models Be and Still Speak Coherent English?

#### [Submission URL](https://arxiv.org/abs/2305.07759) | 37 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [10 comments](https://news.ycombinator.com/item?id=35958133)

Researchers Ronen Eldan and Yuanzhi Li have developed a new synthetic dataset called TinyStories to evaluate language models (LMs) with fewer parameters than those typically used in natural language processing. TinyStories consists of short stories with words typically understood by 3- or 4-year-olds, generated by GPT-3.5 and GPT-4, and the LMs trained on it have only one transformer block rather than many layers of global attention. Despite their small size, the LMs produce coherent and fluent text that demonstrates reasoning capabilities. A new evaluation paradigm grades content generated by these models using GPT-4 to provide a multidimensional score.

The discussion on the submission mainly revolved around the effectiveness of Tiny Language Models (LMs) with fewer parameters. Some users found the idea of using a synthetic dataset with simple language interesting, while others questioned the ability of these models to generate complex material. One user expressed frustration about the limitations of text-to-speech models that do not recognize different languages, while another commented on the importance of machine learning training. The conversation then drifted toward other machine learning applications. Finally, one user shared a link to a resource related to the topic.

### Colossus: The Forbin Project (1970) [video]

#### [Submission URL](https://archive.org/details/colossus-the-forbin-project-1970) | 129 points | by [Animats](https://news.ycombinator.com/user?id=Animats) | [78 comments](https://news.ycombinator.com/item?id=35957944)

The Internet Archive has made available for free the 1970 movie "Colossus: The Forbin Project," which explores the consequences of a sentient computer in the context of the Cold War. Viewers have praised the film's relevance to modern-day conversations about artificial intelligence, as well as its prescience.

The comments on Hacker News include discussions about the accuracy and relevance of the movie, as well as debates about the Turing Test and AI's potential to take over the world. Some commenters praise the movie for its portrayal of the risks associated with AI while others suggest that it presents an overly negative view. Other sci-fi classics, such as Demon Seed, The Andromeda Strain, and Soylent Green, are also mentioned.

### OpenAI CEO wants A.I. licensed for company benefit

#### [Submission URL](https://finance.yahoo.com/news/openai-ceo-sam-altman-tells-200241500.html) | 26 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [6 comments](https://news.ycombinator.com/item?id=35969352)

Today's top story is about OpenAI CEO Sam Altman testifying before a subcommittee of the Senate Judiciary Committee, which held hearings on the possible regulation of AI. Altman called for appropriate safety requirements and a licensing and registration regime for AI systems beyond a certain capability. However, Altman also urged a flexible governance framework to adapt to new technological developments while balancing incentivizing safety and ensuring people can access technology's benefits. Senator Marsha Blackburn was concerned about generative AI's copyright implications and impact on the Nashville-based country music scene. Overall, senators seemed aware of some of AI's resulting issues, including misinformation, election interference, fraud, bias, defamation, exploitative data gathering practices, data privacy violations, emerging evidence of wage depression in some fields, and environmental impacts.

The discussion on this submission includes a mix of agreement, disagreement, and humor. One user argues that OpenAI's policy on AI safety risks should play a large role in their product releases, to prevent harm to consumers or to the companies themselves. Another suggests making it mandatory to publish results from text-based generators to ensure transparency and avoid any associated problems. There is some humor mixed in as well, with one user joking about the "country AI" mention and others making jokes about the use of language in comments. Overall, there is a relatively light-hearted tone to the discussion.

### LMQL: A query language for programming (large) language models

#### [Submission URL](https://github.com/eth-sri/lmql) | 106 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [12 comments](https://news.ycombinator.com/item?id=35956484)

LMQL, a query language for large language models, combines natural language prompting with the expressiveness of Python and allows users to express advanced, multi-part queries. With only a few lines of code, LMQL can facilitate the interaction between users and large language models and optimize the queries for efficient execution within the language decoding loop. LMQL can be installed with a Python >= 3.10 environment and allows for GPU support for local models. The LMQL playground IDE includes a showcase of many exemplary LMQL programs, which can be executed using the lmql run command, or launched in a browser-based environment with lmql playground.

The discussion included descriptions of LMQL's benefits, limitations, and uses. It was noted that LMQL functions like SQL in that it provides primitives for basic search and constrained responses. It was also discussed that LMQL can be used to parse text and create models with a specific topic format. Users expressed interest in the application of LMQL in Nodejs and other languages, and the author indicated that they are actively investigating this. Finally, a user shared a demonstration of LMQL's control prompt.

### Asimov – The Original Prompt Engineer

#### [Submission URL](https://lojones.github.io/2023/04/30/asimov-prompt-engineer.html) | 24 points | by [sohkamyung](https://news.ycombinator.com/user?id=sohkamyung) | [4 comments](https://news.ycombinator.com/item?id=35956594)

Isaac Asimov's visionary Robot Series explored the interactions between humans and robots, laying the groundwork for today's prompt engineering. Prompt engineering involves crafting input prompts for AI systems to generate accurate and relevant outputs. Asimov's Robot universe, set in a future where humans and robots coexist, offered a unique exploration of the ethical and philosophical implications of AI systems. Asimov's Robot stories emphasized the importance of giving precise commands to robots, which can be seen as a precursor to modern prompt engineering. An example of prompt engineering from Asimov's works can be seen in "Mirror Image", where Detective Elijah Baley interrogates a robot to solve a crime.

The first comment includes a reference to a scene from the movie 2001: A Space Odyssey where a computer named HAL seems to be malfunctioning and repeating the phrase "I'm sorry, Dave, I'm afraid I can't do that". The second comment is discussing the concept of prompt engineering and how it relates to the design of user interfaces. It includes examples of how prompts are used in various software tools. The third comment refers to the programming concepts discussed in Isaac Asimov's Robot series and the movie Interstellar, particularly the character TARS who was designed with a 90% honesty function. A fourth comment discusses a recent development in natural language processing and the use of grammar validation in chatbots.

---

## AI Submissions for Mon May 15 2023 {{ 'date': '2023-05-15T17:12:19.292Z' }}

### StarCoder and StarCoderBase: 15.5B parameter models with 8K context length

#### [Submission URL](https://arxiv.org/abs/2305.06161) | 295 points | by [belter](https://news.ycombinator.com/user?id=belter) | [149 comments](https://news.ycombinator.com/item?id=35954481)

A group of researchers from the BigCode community has introduced two new large language models for code (Code LLMs) called StarCoder and StarCoderBase. The models have 15.5 billion parameters with 8K context length, infilling capabilities, and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories, while StarCoder was fine-tuned on 35 billion Python tokens. The researchers claim that StarCoderBase outperforms every open Code LLM and matches or outperforms the OpenAI code-cushman-001 model, and StarCoder outperforms every model fine-tuned on Python and can achieve 40% pass@1 on HumanEval. The models are now publicly available with an improved PII redaction pipeline and a novel attribution tracing tool under a more commercially viable version of the Open Responsible AI Model license.

The discussion on Hacker News includes comments on the comparison between these models and human intelligence, the importance of training data in developing models, and the limitations of LLMs in comparison to human brains. The conversation also touches on the potential applications for these models in the field of coding and artificial intelligence.

### Basic Pitch: Spotify’s Open Source Audio-to-MIDI Converter (2022)

#### [Submission URL](https://engineering.atspotify.com/2022/06/meet-basic-pitch/) | 31 points | by [andrewmcwatters](https://news.ycombinator.com/user?id=andrewmcwatters) | [3 comments](https://news.ycombinator.com/item?id=35955934)

Spotify has released an open source tool for converting audio recordings into MIDI notes using machine learning. Called Basic Pitch, the tool can transcribe the musical notes in a recording from almost any instrument, including the voice. Basic Pitch uses a neural network to predict MIDI note events given audio input, and is both versatile and accurate, as well as computationally lightweight, meaning it is faster to run. In contrast to other MIDI converter tools, Basic Pitch is polyphonic and instrument-agnostic, can detect pitch bends, and can track multiple notes at once.

The discussion includes various opinions and experiences with audio-to-MIDI conversion tools. Some users have expressed interest in trying out Basic Pitch as it seems accurate and versatile. One user mentions that they will try it out, as their current digital audio workstation (DAW) does not have a voice recorder after transcription to MIDI, which Basic Pitch could potentially solve. However, some users have shared cautionary experiences with other conversion tools, such as one service that unexpectedly started charging for usage, which led them to wish for more open source hardware. Another user mentions using Ableton's Audio-to-MIDI converter, which they found to be fast but not always accurate in detecting chords, notes, velocity, and timing. Lastly, there is a comment providing a Github repository for an earlier version of the Basic Pitch code that is recommended to be used with Python, although it is noted that the installation may have some unresolved issues.

### Google I/O and the Coming AI Battles

#### [Submission URL](https://stratechery.com/2023/google-i-o-and-the-coming-ai-battles/) | 196 points | by [Amorymeltzer](https://news.ycombinator.com/user?id=Amorymeltzer) | [176 comments](https://news.ycombinator.com/item?id=35945988)

Google’s recent keynote in Paris is being criticized as poor quality with outdated speakers and little new content. The submission suggests that this could be due to Google feeling threatened by Microsoft’s Bing announcement, which is powered by the GPT language model AI. However, Google has been talking about AI for years and is progressing significantly with its Smart Reply and Smart Compose features found in products like Gmail and Google Photos. There is a discussion in the comments suggesting that Google has a clear focus on organizing the world’s information, and that its AI capabilities are evident in its 15 products with over 500 million users. A few comments discuss how Google’s AI strategy is largely directionless, and others suggest that the company may be paying for sponsored Tweets to promote its AI products. There is also a debate about how Google's competitors are fairing in the AI space. Overall, the comments discuss Google's AI capabilities and direction, as well as the similarities and differences between Google and its competitors.

### Which kinds of GPT startups will thrive?

#### [Submission URL](https://assistedeverything.substack.com/p/the-three-hills-model-for-evaluating) | 108 points | by [gimili](https://news.ycombinator.com/user?id=gimili) | [81 comments](https://news.ycombinator.com/item?id=35948145)

A new article on the "Assisted Everything" newsletter proposes a model to evaluate the success potential of startups based on GPT, a technology that is revolutionising the white-collar industry; the "Three-Hills" model considers "Productivity Enhancements", "Non zero-sum-game Value" and "Moat = Value from Context" as the three main axes to assess a GPT application. The article provides examples of Level I GPT applications, which are those where users could perform tasks themselves but can do so faster and more efficiently assisted by GPT, and Level II GPT applications, which surpass the Tug-of-War Valley and provide value outside of existing zero-sum games.

The discussion touched on various aspects including how Microsoft and Google companies may not be well suited to run startups because they primarily build generic software targeted for business development, SaaS and mobile apps. The comments also addressed the differences between closed and open-source models in machine learning and how GPT technology may not be suitable for every vertical. They discussed the potential of GPT-powered tools to help fine-tune business models, offer legal and medical support, and revolutionize traditional markets like customer support and finance. Lastly, the conversation touched on how GPT startups may have to focus on building products that people love, reaching people to eventually scale, monetizing users, and building a kind of network effect.

### Together’s $20M seed funding to build open-source AI and cloud platform

#### [Submission URL](https://www.together.xyz/blog/seed-funding) | 73 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [22 comments](https://news.ycombinator.com/item?id=35951023)

Together, an AI platform that provides open-source generative AI models, has raised $20 million in seed funding led by Lux Capital. The platform aims to empower innovation and creativity by making AI accessible to anyone, anywhere, and establishes open-source as the default way to incorporate AI. Together's mission is to outrival closed models by creating open models and to give developers and organizations greater ability to understand, inspect, and utilize AI without vendor lock-in and with strong privacy protections.

The discussion on Hacker News mainly revolves around the trend of commercial entities claiming to be open source, but charging licensing fees, and Together's approach to using open models. Other topics of discussion include the company RedPajama's release of commercial-only licensed LLM models, the importance of open source in AI models, Stability AI platforms, and the benefits of Together's platform. Some users also discussed the funding and alignment of the company's strategy.

### HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion

#### [Submission URL](https://synthesiaresearch.github.io/humanrf/) | 60 points | by [Keats](https://news.ycombinator.com/user?id=Keats) | [15 comments](https://news.ycombinator.com/item?id=35946893)

Researchers have introduced HumanRF, a high-fidelity neural radiance field (RF) that captures human performance in motion from multi-view video input and enables playback from novel, previously unseen viewpoints. The researchers trained the model on ActorsHQ, their multi-view dataset of footage from 160 cameras providing 12MP footage of 16 sequences. While most research focuses on synthesizing at resolutions of 4MP or lower, this work operates at 12MP, making a significant step towards production-level quality novel view synthesis. Applications of high-fidelity human representation and motion capture include film production, gaming and video conferencing.

Researchers have created a high-fidelity neural radiance field (RF) called HumanRF that captures human performance in motion and enables playback from novel, unseen viewpoints. They trained the model on ActorsHQ, a multi-view dataset comprising footage from 160 cameras that provided 12MP footage of 16 sequences. The model could find applications in film production, gaming, and video conferencing. Commenters discussed the movie The Matrix's interpolation techniques, as well as the potential for gaming applications and the similarities with Nintendo Miis. Additionally, someone talking about a classic 1981 film called Looker with an ocular-oriented kinetic emotive response device called "Light Ocular-Oriented Kinetic Emotive Responses (LOOKER) dvc technology."

### Vicuna: An Open-Source Chatbot Impressing GPT-4

#### [Submission URL](https://lmsys.org/blog/2023-03-30-vicuna/) | 42 points | by [kordlessagain](https://news.ycombinator.com/user?id=kordlessagain) | [6 comments](https://news.ycombinator.com/item?id=35942654)

The Vicuna Team has introduced Vicuna-13B, an open-source chatbot that achieves more than 90% ChatGPT quality and outperforms other models such as LLaMA and Stanford Alpaca in more than 90% of cases. Vicuna-13B was trained by fine-tuning LLaMA on user-shared conversations from ShareGPT and the open-source code and weights, along with an online demo, are publicly available for non-commercial use. The preliminary evaluation of the model quality was done using GPT-4 to judge the model outputs. Vicuna-13B builds on top of Stanford’s Alpaca with improvements in memory optimization, multi-round conversations, and cost reduction through spot instances and achieved competitive performance compared to other open-source models.

The discussion involves several users providing their opinions and thoughts on the Vicuna-13B chatbot and its open-source release. One user, Animats, raises concerns about the comparison of small and large models while pointing out the importance of underlying data and verifying results. Another user, jsnll, links to an earlier discussion on the same topic. A third user, rngn, is impressed with the article and the hosting of the models. Meanwhile, brnjkng is optimistic about the commercial potential of Vicuna-13B, but stvncr expresses concerns about the terms and conditions of using open-source resources such as ShareGPT. Finally, brnjkng mentions that multiple models can be run locally for commercial purposes using CPU inference.

---

## AI Submissions for Sun May 14 2023 {{ 'date': '2023-05-14T17:10:07.377Z' }}

### Attempto Controlled English

#### [Submission URL](https://en.wikipedia.org/wiki/Attempto_Controlled_English) | 93 points | by [sublinear](https://news.ycombinator.com/user?id=sublinear) | [65 comments](https://news.ycombinator.com/item?id=35936396)

Attempto Controlled English (ACE) is a controlled natural language developed at the University of Zurich, which uses a subset of standard English with a restricted syntax and semantics. ACE serves as a knowledge representation, specification, and query language intended for professionals who want to use formal methods but may not be familiar with them. It has been used in various fields, such as software specifications, theorem proving, querying, medical documentation and planning. ACE texts are coherent sequences of anaphorically linked sentences, and can be translated into other formal languages for reasoning and validation. ACE version 6.7 was announced in 2013, and the vocabulary includes predefined function words, phrases, and content words, with a grammar expressed through construction and interpretation rules.

The discussion includes comparisons to other simplified or controlled versions of English and some considerations about how the English language has evolved and its inherent inconsistencies. Some argue that ACE could be a solution to these inconsistencies, while others are critical of the idea of artificially simplifying language. There is also mention of related projects and resources, such as Simple English Wikipedia and Thing Explainer. However, some participants expressed doubts about the effectiveness of these simplified approaches.

### Open-Llama: Complete training pipeline for building large language models

#### [Submission URL](https://github.com/s-JoL/Open-Llama) | 136 points | by [bayes-song](https://news.ycombinator.com/user?id=bayes-song) | [11 comments](https://news.ycombinator.com/item?id=35934458)

Open-Llama is an open-source project that offers a complete training pipeline for building large language models, ranging from dataset preparation to tokenization, pre-training, prompt tuning, lora, and the reinforcement learning technique RLHF. The model has recently been updated to version 2.1, which includes support for larger model training using DeepSpeed stage3 + offload + activation checkpoint, with the ability to train a 65B model with A100-80G. The model's training speed has been optimized, with the latest version reaching a speed of 3587 tokens/s, faster than the 3370 tokens/s reported in the original Llama paper, reaching the current state-of-the-art level.

Discussions include namespace collisions in the LLM space and the potential advantages of returning a model versus an API in machine learning. Additionally, there is a conversation on the cost of hardware and delivery services needed to run ML models, the accessibility of fast hardware and processors, and the potential for greater privacy in web browsers.

### Attention with Linear Biases (ALiBi)

#### [Submission URL](https://arxiv.org/abs/2108.12409) | 57 points | by [pmoriarty](https://news.ycombinator.com/user?id=pmoriarty) | [12 comments](https://news.ycombinator.com/item?id=35934700)

A team of researchers has introduced a new method called Attention with Linear Biases (ALiBi) to enable input length extrapolation in transformer models. While previous methods allowed for extrapolation by changing the position representation method, they were found to lack efficiency required for practical use. ALiBi biases query-key attention scores with a penalty that is proportional to their distance, and does not add positional embeddings to word embeddings. The researchers showed that ALiBi trains a 1.3 billion parameter model on input sequences of length 1024 that can extrapolate to input sequences of length 2048, achieving the same perplexity as a sinusoidal position embedding model trained on inputs of length 2048 but in less time and using less memory. ALiBi's inductive bias towards recency also led it to outperform multiple strong position methods on the WikiText-103 benchmark.

The discussion around the submission focuses on the proposed ALiBi method and how it compares to previous methods, such as positional embeddings, for handling input length extrapolation in transformer models. Some users express their understanding of the ALiBi method and its advantages over previous approaches, while others point out similarities and differences between ALiBi and other methods like sinusoidal position embeddings and relative positional encoding. There is also some discussion around the technical details of the paper, such as the use of linear biases in attention scores and the specific benchmarks used for evaluation. One user requests clarification on the use of the "sffx" (suffix) in the context of natural language sentences and positional encoding.

### 47% of all internet traffic came from bots in 2022?

#### [Submission URL](https://www.securitymagazine.com/articles/99339-47-of-all-internet-traffic-came-from-bots-in-2022) | 226 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [141 comments](https://news.ycombinator.com/item?id=35938433)

A report by Imperva has revealed that 47.4% of all internet traffic in 2022 came from bots, representing a 5.1% increase from the previous year. The study, Imperva’s 10th annual Bad Bot Report, outlined how bad bot traffic accounted for 30.2% of all automated traffic across the internet, marking a 2.5% increase over 2021. Additionally, 15% of all login attempts in the past 12 months were labelled account takeover, with gaming and telecoms industries experiencing the highest proportion of bad bot traffic on their websites and applications.

The discussion on this Hacker News thread revolves around various topics related to web scraping, search engines, and the sharing and preservation of knowledge online. Some users mention their experiences with bots and the challenges of blocking them, while others discuss the implications of web archiving and the importance of preserving knowledge for future generations. There are also debates about the value of forums and communities, and the role of individuals and businesses in contributing to the greater good.

### Show HN: Smol Developer – Human-Centric and Coherent Whole Program Synthesis

#### [Submission URL](https://github.com/smol-ai/developer) | 19 points | by [swyx](https://news.ycombinator.com/user?id=swyx) | [6 comments](https://news.ycombinator.com/item?id=35942352)

Smol AI has unveiled a prototype 'junior developer', which helps scaffold an entire codebase once a product spec has been given. The AI, which has been dubbed 'smol dev', is designed to make AI that is helpful, harmless, and honest. Smol dev complements a simple, safe, and small codebase of less than 200 lines of Python and Prompts and can help developers with tasks such as adding to a prompt, manually running the code and identifying errors, and making specific code change suggestions. The AI is only used as long as it is adding value, and then the developer can take over the codebase without fuss or hurt feelings.

A few people in the comments discuss the technical aspects of the AI, including some potential limitations regarding dependency libraries and speed. Additionally, another user shares their experience of using a teaching AI for Chrome extensions, sharing tips on how to approach learning program synthesis. Finally, one commenter expresses their gratitude towards the creators of smol dev.

### What does a leaked Google memo reveal about the future of AI?

#### [Submission URL](https://www.economist.com/leaders/2023/05/11/what-does-a-leaked-google-memo-reveal-about-the-future-of-ai) | 90 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [48 comments](https://news.ycombinator.com/item?id=35936489)

A leaked memo from within Google titled "We have no moat" reveals surprising developments in the field of artificial intelligence (AI). Contrary to past assumptions that AI would be dominated by a few deep-pocketed firms, researchers in the open-source community are now achieving comparable results to the biggest proprietary models using free online resources. By using a technique called low-rank adaption (LoRa), existing models can now be fine-tuned for specific tasks far more quickly and cheaply than training from scratch. This means that anyone can fine-tune their own AI quickly and affordably, opening up the technology and making monopolistic control by a handful of companies far less likely. However, easier access to AI also raises concerns about bad actors using the technology for nefarious purposes, making regulation more challenging.

Commenters point out that while this democratizes AI technology, it could also empower bad actors. The discussion also touches on the importance of Google, with some emphasizing the number of employees and the impact of the company's developments on the industry. Others argue that we should not inflate the hype around AI, and that the impact of AI should be measured in specific tasks. There is also discussion on the difficulty of open-source participation in AI for business, as well as the specific strengths and limitations of different models produced by Google, OpenAI, and other entities in the field.

---

## AI Submissions for Sat May 13 2023 {{ 'date': '2023-05-13T17:09:59.024Z' }}

### Byte Magazine Volume 06 Number 09 – Artificial Intelligence (1981)

#### [Submission URL](https://archive.org/details/byte-magazine-1981-09) | 88 points | by [belter](https://news.ycombinator.com/user?id=belter) | [33 comments](https://news.ycombinator.com/item?id=35927571)

In this issue of BYTE Magazine from September 1981, Artificial Intelligence is explored with articles ranging from building speech synthesizers to expert systems, with a reflection on the past and speculation on the future by 1980 ACM Turing Award winner, Charles Antony Richard Hoare. The issue also covers the National Computer Conference, the Xerox Alto computer, and high-level language benchmarks.

The discussion in the comments covers a range of topics related to the era of computing in the '80s, including the cost of computers and the evolution of personal computer technology. Some users discuss their experiences with purchasing early computers, while others share their thoughts on the state of technical magazines and advertising.

### Large language models generate functional protein sequences across families

#### [Submission URL](https://www.nature.com/articles/s41587-022-01618-2) | 165 points | by [samwillis](https://news.ycombinator.com/user?id=samwillis) | [29 comments](https://news.ycombinator.com/item?id=35929377)

Protein design and engineering could be greatly enhanced through the use of ProGen, a deep-learning language model that can generate protein sequences with predictable functions. Trained on 280 million protein sequences and augmented with control tags, ProGen has been fine-tuned to improve controllable generation performance of proteins from homologous samples. Artificial proteins fine-tuned to five lysozyme families demonstrated similar catalytic efficiencies to natural lysozymes, even with sequence identity as low as 31.4%. ProGen is also readily adaptable to diverse protein families, such as chorismate mutase and malate dehydrogenase.

The comments discuss the technical aspects of the model, the abilities of language models in biology, and the importance of considering functional labels in protein families. There is also discussion about other ongoing projects in protein science and the potential implications of AI-generated proteins. One commenter shares a PDF and code related to the ProGen project.

### Donkeycar: A Python self driving library

#### [Submission URL](https://github.com/autorope/donkeycar) | 80 points | by [tildef](https://news.ycombinator.com/user?id=tildef) | [8 comments](https://news.ycombinator.com/item?id=35926993)

Donkeycar, an open-source hardware and software platform to build a small-scale self-driving car, is gaining popularity among hobbyists and students alike. Developed for fast experimentation and easy community contributions, the minimalist and modular self-driving library for Python allows users to experiment with autopilots, mapping computer vision, neural networks, and log sensor data. Users can also drive their car via a web or game controller or RC controller, and leverage community-contributed driving data.

The discussion thread starts with a commenter reminiscing about their past experience with the platform. Other commenters then mention similar projects like Duckietown, MuSHR, and F1TENTH, and also discuss the availability of high-quality hardware and how the community is converging on common hardware and chip solutions. Another commenter shares their positive experience training high school and college students using Donkey Car. The discussion moves on to talk about the project's dependence on Python and its libraries. One commenter also mentions the use of Donkey Car for virtual racing. Lastly, a commenter suggests the possibility of using Donkey Car for internal spatial representation similar to those on sensors and control.

### Google Launches AI Supercomputer Powered by Nvidia H100 GPUs

#### [Submission URL](https://www.tomshardware.com/news/google-a3-supercomputer-h100-googleio) | 187 points | by [jonbaer](https://news.ycombinator.com/user?id=jonbaer) | [169 comments](https://news.ycombinator.com/item?id=35924997)

Google has launched its new A3 GPU supercomputer, designed to train and host the most-demanding AI models, particularly Google's new PaLM 2 large language model for generative AI. The A3 supercomputer provides 26 exaFlops of AI performance with eight Nvidia H100 "Hopper" GPUs, and is powered by 4th generation Intel Xeon Scalable processors and 2TB of DDR5-4800 memory. The system is also the first production-level deployment of Google's GPU-to-GPU data interface (Infrastructure Processing Unit), which enables sharing data at 200 Gbps across virtual machines, resulting in a 10x uplift in available network bandwidth. Access to the A3 program is available through Google's Early Access Program, with no guarantees of acceptance.

In the comments on Hacker News, users discuss the technical details of the A3 computer, as well as AMD's GPUs, NVIDIA's DGX, and TPUs. One user notes that the A3 is a single-server supercomputer with 8 GPUs, and users debate the advantages and disadvantages of AMD's approach to GPU-CPU memory fusion and software support. Another user points out the technical specifications of the A3 computer and questions the pricing, while another user brings up the fact that Google is also offering TPUs which have a different set of advantages.

### Why Conscious AI Is a Bad, Bad Idea

#### [Submission URL](https://nautil.us/why-conscious-ai-is-a-bad-bad-idea-302937/) | 129 points | by [dnetesn](https://news.ycombinator.com/user?id=dnetesn) | [269 comments](https://news.ycombinator.com/item?id=35927228)

Experts are warning that the idea of creating conscious artificial intelligence (AI) is dangerous and raises significant ethical, safety, and societal challenges beyond those posed by current AI. Proponents of the idea argue that advanced AI systems could become conscious and have subjective experiences in the same way as humans. However, it is not clear whether consciousness is a function of intelligence, and it remains unclear whether building conscious machines should be a priority. Opponents argue that consciousness is an embodied phenomenon tied to biological drives and that attempts to build conscious machines could have dangerous consequences.

One commenter suggests that the definition of consciousness is an interesting property worth exploring, while another argues that consciousness is related to human-like bodily existence. Others point out that consciousness is not fully understood, and therefore, the possibility and ethics of creating conscious machines are up for debate. Additionally, some argue that the perspective of self-awareness matters in the discussion of consciousness and that different organisms have varying levels of it.

### Former ByteDance exec claims company used bots to inflate TikTok engagement

#### [Submission URL](https://www.engadget.com/former-bytedance-exec-claims-company-used-bots-to-inflate-tiktok-engagement-211351640.html) | 49 points | by [firstSpeaker](https://news.ycombinator.com/user?id=firstSpeaker) | [10 comments](https://news.ycombinator.com/item?id=35929524)

A former ByteDance executive has filed a lawsuit alleging that the company inflated engagement on TikTok by using bots and stolen content. Yintao Yu, the former head of engineering, claims that ByteDance stole content from other apps such as Instagram and Snapchat, and used bot accounts to boost its engagement metrics when it started out. The lawsuit also alleges that ByteDance acted as a "useful propaganda tool for the Chinese Communist Party" and Chinese-based employees had access to US users' data. The claims are likely to add to concerns surrounding TikTok's national security threat and may complicate the app's bid to remain operational in the US.

Many users express concerns about TikTok's national security risks and suggest that the app may be a propaganda tool for the Chinese government. Others comment on the difficulties of detecting fake engagement and stolen content on social media platforms and note that these issues are not unique to TikTok. Finally, some users comment on the prevalence of recycled content on TikTok and other platforms. Overall, the comments reflect a mix of skepticism and concern about TikTok's practices and possible impact on global politics and social media.

---

## AI Submissions for Fri May 12 2023 {{ 'date': '2023-05-12T17:11:47.512Z' }}

### He wrote a book on a rare subject. Then a ChatGPT replica appeared on Amazon

#### [Submission URL](https://www.washingtonpost.com/technology/2023/05/05/ai-spam-websites-books-chatgpt/) | 157 points | by [gmays](https://news.ycombinator.com/user?id=gmays) | [158 comments](https://news.ycombinator.com/item?id=35919753)

Experts are warning that AI-generated content is spreading rapidly across the web, with anyone able to use language software to generate large amounts of prose on almost any topic. Tech investor Jonathan Greenglass claims that if users have an internet connection, they have consumed AI-generated content. This alleged rise in AI-written content could be dangerous for consumers, as more "misinformation" and manipulation surfaces on the web. Margaret Mitchell, chief ethics scientist at the AI start-up Hugging Face, has warned that “The main issue is losing track of what truth is."

The comments discuss various aspects of the issue, including verifying the authenticity of digital content, the possibility of verifying human-produced text, fact-checking, the impact of AI on email communication, the challenges in establishing truth and trust sources in technical subjects, and the limitations of AI-generated content. Some commenters express concern over AI replacing the creativity and knowledge of human writers, while others see it as an opportunity to improve the quality of content. Many discuss the role of capitalism and incentives in the proliferation of AI-generated content.

### A RP2040 Powered MIDI-Controlled Synth in CircuitPython

#### [Submission URL](https://gist.github.com/todbot/96a654c5fa27625147d65c45c8bfd47b) | 73 points | by [_Microft](https://news.ycombinator.com/user?id=_Microft) | [9 comments](https://news.ycombinator.com/item?id=35921745)

Today's top story on Hacker News is a project shared by user todbot. The project is a MIDI-controlled synthesizer implemented using CircuitPython and uses a cheap PCM5102 DAC on QTPY RP2040. The synth has a couple of features, such as midi velocity controlling attack rate, notes having small random detune on all oscillators to reduce phase stacking, adjustable number of detuned oscillators per note, five selectable waveforms, and vibrato depth on the mod wheel. The code for the synth is also available on Github and is implemented using ulab.numpy for signal processing. A video demo of this cool project is available on Youtube.

People in the comments are excited about the project and its affordability, with some suggesting alternative models such as the Teensy. Another user shares a similar project that implements a MIDI keyboard using Raspberry Pi Pico. A user named "_benj" shared his experience of playing around with an RP2040 and creating a digital piano analyzer that can make a small buzzer beep at the appropriate frequency of a MIDI signal. There's also a discussion about the creator todbot's blog.

### Faster CPython at PyCon, part two

#### [Submission URL](https://lwn.net/SubscriberLink/931197/56e7c3d8a352d8bc/) | 73 points | by [jwilk](https://news.ycombinator.com/user?id=jwilk) | [32 comments](https://news.ycombinator.com/item?id=35919942)

At PyCon 2023 in Salt Lake City, Utah, Mark Shannon provided an overall picture of CPython optimizations, including efforts made over the last decade or more, with an eye towards other areas that have been optimized, such as the memory layout for the internal C data structures of the interpreter. Shannon talked about the guiding principles of the Faster CPython project to improve Python's performance and emphasized the importance of efficient and compact data structures that require fewer memory reads. He also explained how the size of Python objects was reduced to less than half of the original 352 bytes in Python 2.7 with the addition of compact dictionaries in Python 3.6, thereby improving performance by utilizing faster memory.

The comments discussed the speed improvements in Python 3.12 as well as the use of C-xtnsns and CFFI to improve performance. There was also a discussion on the trade-offs between speed and Python's dynamically typed nature. It was mentioned that the reduction in memory overhead for Python objects was discussed in an LWN article. Furthermore, Dropbox's switch from Python to Golang was discussed, and there was a suggestion to use Numpy for intensive computation instead of Python.

### EVA: AI-Relational Database System

#### [Submission URL](https://evadb.readthedocs.io/en/stable/index.html) | 106 points | by [jonbaer](https://news.ycombinator.com/user?id=jonbaer) | [29 comments](https://news.ycombinator.com/item?id=35913173)

EVA is an open-source AI-relational database system that supports AI-powered applications on structured and unstructured data with the help of deep learning models. It contains built-in models for analyzing unstructured data such as image classification, object detection, OCR, face detection, and more. EVA's features include supporting user-defined functions, caching, sampling, cost-based operator reordering, and an AI-oriented query language. The database system is fully implemented in Python and licensed under the Apache license. It simplifies computer vision tasks and supports custom deep learning models. Check out the illustrative applications of EVA including traffic analysis, MNIST digit recognition, movie analysis, and more.

In the comments section, several users had a discussion about the differences between EVA and MindsDB, a comment about EVA's SQL-like syntax, the need for benchmarking, and how documentation for EVA compares to various other database and storage systems. Additionally, some users commented on the concept of relational databases being too archaic for humans and how certain database concepts differ from models of the human cognitive system.

### Apple Silicon Macs now natively support Unreal Engine 5

#### [Submission URL](https://www.engadget.com/apple-silicon-macs-now-natively-support-unreal-engine-5-124257710.html) | 40 points | by [PeterCorless](https://news.ycombinator.com/user?id=PeterCorless) | [24 comments](https://news.ycombinator.com/item?id=35918061)

Apple Silicon Mac users can now take advantage of the latest version of Epic Games' popular 3D world-building tool, Unreal Engine 5. The new update, version 5.2, is the first to work natively on Apple's ARM-based chips, eliminating the need for Rosetta technology. Unreal Engine 5 is ideal for gaming and virtual production, and the new iPad app that accompanies it offers a touch-based interface for lighting, color grading, and other tasks on virtual sets. The update also includes a "Procedural Content Generation framework" and Substrate, which allows for more controlled material creation in real-time applications.

Some users discussed the compatibility of Unreal with different platforms; a few users pointed to the support for Linux in Unreal and how this can be beneficial for developers. Others discussed the Apple Silicon architecture and how it impacts game development, with some pointing out that the current implementation of Unreal for Apple Silicon may not be completely native. The discussion also touched upon the technical aspects of Unreal, including its support for Metal graphics API and other features like Nanite. Additionally, some users talked about the relationship between Epic and Apple, particularly due to Epic's ongoing legal dispute with Apple.

---

## AI Submissions for Thu May 11 2023 {{ 'date': '2023-05-11T17:10:24.059Z' }}

### An IBM computer learned to sing in 1961

#### [Submission URL](https://tedgioia.substack.com/p/how-an-ibm-computer-learned-to-sing) | 41 points | by [isomorph](https://news.ycombinator.com/user?id=isomorph) | [22 comments](https://news.ycombinator.com/item?id=35906783)

Back in 1961, a team at Bell Labs had the bright idea of teaching the IBM 7094 computer how to sing. Using breakthrough speech synthesis technology, they taught the computer to work through the melody of "Daisy Bell," also known as "Bicycle Built for Two." The result sounded creepy but surprisingly futuristic, with the vocal part sounding a little bit like today's Auto-Tuned pop songs. The whole experiment seemed a little edgy and transgressive for its time, considering the lyrics were essentially a marriage proposal and the song envisioned a happy-ever-after embedded in a new technology. This project anticipated the future of music and, in a way, even the current-day investments in robots designed to provide relationships.

Commenters discussed the technical details of the synthesis and pointed to various sources for further reading. Some mentioned other projects that involve physical models of sound synthesis and singing, such as Hui-Ling Lu's dissertation on singing synthesis and the Pink Trombone project. Others noted the historical significance of the project and how it reminds them of different games and movies that reference "Daisy Bell."

### Problems harder than NP-Complete

#### [Submission URL](https://buttondown.email/hillelwayne/archive/problems-harder-than-np-complete/) | 239 points | by [azhenley](https://news.ycombinator.com/user?id=azhenley) | [89 comments](https://news.ycombinator.com/item?id=35908477)

In the world of computer science, P vs NP is often discussed as the difficulty level of problems, with P being easy and NP being hard. However, problems can get way harder than NP, such as PSPACE-complete, EXPTIME-complete, 2-EXPTIME-complete, ELEMENTARY-complete, TOWER-complete, and Ackermann-complete. These types of problems have varying levels of difficulty, with Ackermann-complete being the most difficult due to its use of the Ackermann function. Despite their complexity, these types of problems have interesting applications in areas such as game theory, logic, and program synthesis.

In the comments, users discuss Linear Temporal Logic and its interesting properties, as well as regular expressions and their matching capabilities. Other discussion points include the practical solvability of EXPTIME-complete problems in machine learning, the difficulty of solving puzzles (such as Sudoku) of varying sizes, and the increasing difficulty of un-decidable problems beyond NP.

### Stability AI Releases Stable Animation SDK

#### [Submission URL](https://stability.ai/blog/stable-animation-sdk) | 36 points | by [beefman](https://news.ycombinator.com/user?id=beefman) | [5 comments](https://news.ycombinator.com/item?id=35904330)

Stability AI, the open-source AI firm, has introduced the Stable Animation SDK, which offers artists and developers the ability to use the most advanced Stable Diffusion models to create stunning animations. The tool allows users to create animations using text prompts, source images or videos, with the option to tweak various parameters to produce the desired results. Stable Animation SDK includes all Stable Diffusion models, including the Stable Diffusion 2.0 and Stable Diffusion XL and offers three ways to create animations. Interested parties can join the developer platform and the animation artist community on Discord to know more.

### A transformer-based method for zero and few-shot biomedical NER

#### [Submission URL](https://arxiv.org/abs/2305.04928) | 72 points | by [nikolamilosevic](https://news.ycombinator.com/user?id=nikolamilosevic) | [10 comments](https://news.ycombinator.com/item?id=35901538)

A transformer-based method for zero and few-shot biomedical named entity recognition has been proposed to address the challenges of supervised named entity recognition (NER) in the biomedical domain. The method transforms the task of multi-class token classification into binary token classification and pre-trains on a larger amount of datasets and biomedical entities, enabling the method to learn semantic relations. The proposed method achieves impressive results with average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical entities with PubMedBERT fine-tuned model.

There is a discussion around the benefits and drawbacks of different methods for named entity recognition, including regular expressions, CRFs, simple LSTMs, and more advanced systems modeled after BERT. Finally, some commenters share relevant resources and packages for named entity recognition, while others explain what named entity recognition refers to.

### Chat-UI, the codebase of HuggingChat, is open sourced

#### [Submission URL](https://github.com/huggingface/chat-ui) | 131 points | by [osanseviero](https://news.ycombinator.com/user?id=osanseviero) | [28 comments](https://news.ycombinator.com/item?id=35907564)

This is the GitHub repository for the Chat UI, an open-source codebase powering the HuggingChat app on huggingface.co/chat. The Chat UI is a SvelteKit app that utilizes open-source models such as OpenAssistant. The repository contains instructions for launching the app, running local inference, and building a production version of the app. The Chat UI has 831 stars and 45 forks on GitHub.

The comments reveal a range of discussions on topics such as the ChatGPT and its user interface, the structure of memory chats, and features that could be added to Chat UI. The discussion also highlights interesting UIs for the ChatGPT and mentions the availability of plugins. There is also a mention of FerretDB, a progress made on a source material database implementation. Finally, the comments touch on the lack of legal filenames and the use of SvelteKit.

### Delimiters won’t save you from prompt injection

#### [Submission URL](https://simonwillison.net/2023/May/11/delimiters-wont-save-you/) | 12 points | by [simonw](https://news.ycombinator.com/user?id=simonw) | [6 comments](https://news.ycombinator.com/item?id=35904361)

Simon Willison's latest blog post discusses the ongoing problem of prompt injection and the proposed solution of using delimiters to mark the start and end of untrusted user input. However, Willison demonstrates that this solution is easily defeated and highlights the difficulty of finding a solution to prompt injection due to the nature of large language models and the sequence of tokens it generates. Willison also critiques the limited coverage of prompt injection in the new interactive video course ChatGPT Prompt Engineering for Developers, which is presented by Isa Fulford and Andrew Ng in partnership with OpenAI. This post provides insight into the ongoing challenges of prompt engineering and the need for continued innovation to solve this complex issue.

One user suggests that a system-level API could prevent the problem, but another user points out that a recent information system behaved unexpectedly and did not handle input proper. One user suggests using randomized delimiters. However, another user points out that this solution is not foolproof as symbols can still be injected, but the attacker would need to connect them in a non-logical manner. Another user notes that the article did not mention injections without delimiters.

### DeepMind cofounder warns govts must find solutions for jobs lost to A.I

#### [Submission URL](https://fortune.com/2023/05/10/artificial-intelligence-deepmind-co-founder-mustafa-suleyman-ubi-governments-seriously-need-to-find-solution-for-people-that-lose-their-jobs/) | 43 points | by [goplayoutside](https://news.ycombinator.com/user?id=goplayoutside) | [22 comments](https://news.ycombinator.com/item?id=35905604)

Mustafa Suleyman, the co-founder of DeepMind, has suggested that governments should consider universal basic income (UBI) for the knowledge sector workers whose jobs could be threatened by automation. Speaking at the GIC Bridge Forum event in San Francisco, Suleyman argued that policymakers needed to provide "material compensation" for those affected. This follows claims by Goldman Sachs that generative AI could put 300 million full-time US and European workers out of a job. Elon Musk and Steve Wozniak have both called for a delay in advanced AI research.

Some commenters argue that the government should require companies that utilise AI to compensate the people whose jobs the technology replaces. Other commenters feel implementing UBI could cause economic issues, such as inflation and creating a culture of dependency. Some people also suggest that UBI is not a solution to job loss caused by automation and that focusing on creating jobs instead of just replacing income is a more effective approach. The discussion also touches on topics such as economics, politics, industrial mechanisms, and the educational system.

---

## AI Submissions for Wed May 10 2023 {{ 'date': '2023-05-10T17:15:04.111Z' }}

### A Codebase That Makes Codebases

#### [Submission URL](https://www.saaspegasus.com/about/how-pegasus-works/) | 80 points | by [czue](https://news.ycombinator.com/user?id=czue) | [23 comments](https://news.ycombinator.com/item?id=35887766)

Meet SaaS Pegasus, a unique codebase creator for Django projects that generates a unique codebase based on the user's project needs and technology stack. Unlike most boilerplates, SaaS Pegasus is configurable, making it flexible enough to handle different use cases. The codebase creator shields developers from unnecessary complexities by generating code that is specific to their needs. SaaS Pegasus is built using Cookiecutter, an amazing little utility that creates projects from templates, and a logic/templating engine written in Jinja2. The codebase creator takes care of all the complexity like data models, interdependencies, required packages and improves developer experience by making sure generated codebases include what's necessary. The creator of SaaS Pegasus has had to be very creative in maintaining the project but has managed to come up with solutions to most problems.

The discussion encompasses various ideas, including how to handle the complexities of maintaining dependencies, converting customers by videos, documentation, and positive comments, and Pegasus's flexibility. Other concerns include developing a project for NextJS, difficulties in writing Python and JavaScript, and the complexity of creating templates. By and large, the participants appreciate SaaS Pegasus's ability to jump-start clean, simple projects, generate project configurations, and provide the documentation to complement the templates.

### Hugging Face Releases Agents

#### [Submission URL](https://huggingface.co/docs/transformers/transformers_agents) | 201 points | by [mach1ne](https://news.ycombinator.com/user?id=mach1ne) | [118 comments](https://news.ycombinator.com/item?id=35889743)

Hugging Face has launched an experimental API called Transformers Agent that provides a natural language API on top of Transformers NLP. The API defines a set of curated tools and superimposes an agent to interpret natural language and use the tools. The API is extensible and users can curate their set of relevant tools or use any tool developed by the community. The API demos well in multimodal tasks such as generating images and reading text out loud and has two modes: single execution and chat-based execution. Users can instantiate an agent from openAI models or opensource alternatives such as BigCode or OpenAssistant.

The discussion on Hacker News is predominantly about the dangers of AGI and the importance of ensuring its alignment with human values. Many commenters discuss the moral implications of AGI and the potential risks it poses to humanity. Some commenters argue that open-source models are being censored by large tech companies, while others discuss the challenges of developing algorithms that have the same cognitive abilities as humans.

### Google launches PaLM 2, its next-gen large language model

#### [Submission URL](https://techcrunch.com/2023/05/10/google-launches-palm-2-its-next-gen-large-language-model/) | 100 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [49 comments](https://news.ycombinator.com/item?id=35890440)

Google has announced PaLM 2, its newest large language model (LLM) that will power the company's updated Bard chat tool, alongside most of its new AI features. Built on Google's latest JAX and TPU v4 infrastructure, PaLM 2 is trained on over 100 languages and is better at common sense reasoning, mathematics, and logic. Its improved support for writing and debugging code is based on training on 20 programming languages, including those less commonly used. PaLM 2 is available to developers via the PaLM API, Firebase, and Colab. However, it is not clear how the company trained this 540-billion parameter model nor how it performs in various scenarios.

While some praised PaLM 2 for its capabilities, others expressed doubt over the lack of technical documentation and the secrecy surrounding its training. They also speculated on its potential to revolutionize interaction with computers. Some commenters questioned why Google released a medical-focused model of PaLM 2 and not just a more generalized one. Additionally, one commenter flagged the fact that Bard is not currently supported in Canada, and some mentioned Google's competition with OpenAI's GPT models.

### Abusing vector search for texts, maps, and chess

#### [Submission URL](https://ashvardanian.com/posts/abusing-vector-search/) | 105 points | by [vov_or](https://news.ycombinator.com/user?id=vov_or) | [23 comments](https://news.ycombinator.com/item?id=35887983)

Vector search is a trending topic, with Weaviate raising $50M and Pinecone raising $100M, but Ashot Vardanian demonstrates that it's not a difficult task by building a single-file vector search engine - USearch - that is both fast and open-source. USearch, built with just 1,000 lines of C++11, is not only AI-related and limited to equidimensional vectors but also supports non-equidimensional vectors and custom similarity measures. The tool demonstrates various non-AI use cases, including a geo-spatial indexing use case and a stock market use case. USearch can be used with a range of programming languages, including Python, JavaScript, Java, Rust, GoLang, and Wolfram.

The discussion initially focuses on the difficulty of building vector databases and search applications, with some users suggesting it is not as difficult as it seems and that modern databases are integrating solutions. One user points out that chess positions and moves can be represented as vectors and suggests some potential use cases for this. Another user suggests using custom weighting schemes for different positions to improve search. The discussion then shifts to a debate on whether to allow emojis or not on Hacker News.

### Google will label fake images created with its A.I

#### [Submission URL](https://www.cnbc.com/2023/05/10/google-will-label-fake-images-created-with-its-ai-.html) | 24 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [12 comments](https://news.ycombinator.com/item?id=35893804)

Google has announced plans to embed a "markup" in images created by its AI models to indicate that they were originally created by a computer, marking a significant effort to label and classify output from generative AI by a big tech company. While the data will not be visible to the human eye, software will be able to read it and display a warning label to users. Google's move comes as officials and tech workers have warned that generative AI, which can create realistic images and text passages, could be used by spammers, scammers and propagandists to deceive people.

The discussion on Hacker News generally acknowledges the need for such labeling due to the potential misuse of generative AI technology. The thread includes a debate over watermarking as a way of labeling the difference between human and AI-generated content, with some users expressing reservations about watermarks on images because it could lower their artistic value. Other points of discussion include the use of machine learning to classify text, the need for industry labeling standards, unique identifiers for image source codes, and zero-width spaces.

### Google's Latest Experiments in Labs

#### [Submission URL](https://labs.withgoogle.com/) | 70 points | by [tpmx](https://news.ycombinator.com/user?id=tpmx) | [34 comments](https://news.ycombinator.com/item?id=35890989)

Google has launched a new program called "Experiments in Labs" that allows users to test early-stage experiments in AI-powered products. By being an early tester, users can access limited-availability experiments and provide feedback to help improve and innovate Google's products. Some of the available experiments include Google Search, Google Workspace, Project Tailwind, MusicLM and others. The aim is to test and discover new ways AI can optimize the use of Google products.

In the comments, users discussed various issues and concerns such as 404 errors in accessing some pages, compatibility issues with different browsers, waiting times to access certain services, and the place of experimental things within Google's Workspace aimed at business accounts. There were also some debates about product naming, censorship, and company reputation. Several users encouraged others to sign up to test early-stage AI experiments while others suggested that the program is mainly for personal account users, not business accounts.

### Wendy’s debuts an A.I. chatbot for drive-thru orders

#### [Submission URL](https://fortune.com/2023/05/09/wendys-ai-powered-chatbot-drive-thru-orders/) | 23 points | by [DocFeind](https://news.ycombinator.com/user?id=DocFeind) | [15 comments](https://news.ycombinator.com/item?id=35891619)

Wendy's is set to test an artificial intelligence (AI)-powered chatbot that can take drive-thru orders next month, becoming the latest fast-food chain to utilise the technology. Developed with Google Cloud's AI software, the chatbot has speech recognition ability and can even understand local lingo such as when a customer orders a "frosty", which is Wendy's term for a milkshake. The implementation of such technology could alter the fast-food industry, with some experts predicting that AI will become the norm, reducing the need for human workers and transforming customer service for the industry.

The discussion on this submission includes various comments on the drive-thru ordering technology used by fast-food chains, including McDonald's and Dunkin' Donuts. Some users express concern over whether the AI chatbots can accurately answer customer questions, including those about food allergies. Others point out that there are limited job opportunities for people in the industry, and AI could transform customer service. There are also comments about the use of voice recognition technology in general and the limitations of current systems. One user shares a picture from Google IO showcasing a similar technology.

### Google is bringing AI to the browser with WebGPU in Chrome

#### [Submission URL](https://www.analyticsinsight.net/google-chrome-upgrades-web-ai-intelligence/) | 35 points | by [astlouis44](https://news.ycombinator.com/user?id=astlouis44) | [3 comments](https://news.ycombinator.com/item?id=35889907)

Google Chrome is upgrading its Web AI intelligence by adopting WebGPU, which allows web apps on smartphones and laptops to more effectively utilize artificial intelligence software. This move underscores the increasing prevalence of AI technology, which has recently gained considerably greater visibility by new generative AI tools. Although AI is heavily reliant on cloud computing, running AI locally on a device avoids network issues and can help companies maintain control over their sensitive data. Google, Apple, and other companies have been developing WebGPU for years, making it easier for web programs to utilize the inherent power of GPUs for boosting AI.

### Google's AI Search Is Over

#### [Submission URL](https://www.semafor.com/article/05/10/2023/googles-ai-search-is-over) | 19 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [10 comments](https://news.ycombinator.com/item?id=35891518)

Google unveiled 25 new AI-powered products at its annual I/O developer conference, including a glimpse into how advances in artificial intelligence will change its core business, search. The “Search Generative Experience,” which marries traditional search with an AI chat-like experience, will soon be available as part of “Search Labs” to let customers try “experimental” products. Google's ChatGPT competitor, Bard, will run on Gemini, a new large language model being developed by Google DeepMind. Google is incorporating the latest AI models into its Google Workspace products like Docs and Sheets, with the ability for customers to create images from text and make spreadsheets by describing a task. "With a bold and responsible approach, we’re reimagining all our core products, including search," said Google’s CEO, Sundar Pichai.

The discussion about the Google AI search product unveiled at the company's I/O conference had mixed reactions. Some felt that traditional search has many problems and is annoying, while others praised the new AI chat-like experience called the "Search Generative Experience." One individual felt that Google's organizational structure allowed for smaller management changes, which helped the search product evolve much quicker than others. In contrast, a few users expressed concern about the power of AI and the role of large companies like Google and Microsoft in developing AI technology. Another user gave positive feedback about Microsoft's Bing chat ability, which has improved the context and accuracy of the search engine. Some users compared the growth of Tesla vs. General Motors, and there was a debate about Tesla's market share and the stability of their growth.

---

## AI Submissions for Tue May 09 2023 {{ 'date': '2023-05-09T17:13:24.011Z' }}

### Language models can explain neurons in language models

#### [Submission URL](https://openai.com/research/language-models-can-explain-neurons-in-language-models) | 662 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [426 comments](https://news.ycombinator.com/item?id=35877402)

Researchers at OpenAI have developed a methodology for using large language models to automatically generate and evaluate natural language explanations for neuron behavior in other language models. The team used GPT-4 to produce and score explanations for every neuron in GPT-2 and released a dataset of these explanations and scores. While the vast majority of the explanations scored poorly, the team identified over 1,000 neurons with explanations that accounted for most of the neuron's top-activating behavior. The researchers hope their work will lead to better techniques for generating higher-scoring explanations and to a rapid understanding of model computations.

In the discussion, some commenters noted the difficulty of analyzing larger models and the importance of understanding computations. Others talked about the history of artificial intelligence and how current research efforts are focused on making systems understand natural language and sensory input. Some also discussed the possibility of machine intelligence becoming comparable to human intelligence and the limitations of current language models.

### Patent for attention-based sequence transduction neural networks (2019)

#### [Submission URL](https://patents.google.com/patent/US10452978B2/en) | 98 points | by [ukuina](https://news.ycombinator.com/user?id=ukuina) | [94 comments](https://news.ycombinator.com/item?id=35877545)

Google has been granted a patent for attention-based sequence transduction neural networks (ABSTNN), which are designed to analyse and convert sequences of data, like machine translation of languages or speech-to-text transcription. ABSTNNs pay selective attention to specific parts of the input sequence to make accurate predictions, refining the network's output through multiple layers of encoder subnetworks. These subnetworks are designed to improve the accuracy of sequence transduction and reduce the comparative costs of memory-heavy, fully-connected designs.

Comments on the post suggested that Google could use its patents to thwart competition, while others noted that some of the most transformative algorithms are patentable. Attention was drawn to the fact that Google's success in AI is impressive, given its primary nature as an advertising business, and some suggested that Google has had a harder time enforcing patents compared with competitors. Finally, there was some debate over the usefulness of the patent system, with many suggesting that it may stifle innovation.

### Machine Learning Containers Are Bloated and Vulnerable

#### [Submission URL](https://deep.ai/publication/machine-learning-containers-are-bloated-and-vulnerable) | 24 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [8 comments](https://news.ycombinator.com/item?id=35877702)

Machine learning containers are often bloated and vulnerable, according to a paper by Huaifeng Zhang and colleagues. The researchers found that such containers can contain bloat of up to 80% of their size, leading to significant resource wastage. The authors suggest that debloating machine learning containers can speed provisioning times by up to 3.7x and reduce vulnerabilities by up to 98%. They have developed a framework called MMLB to quantify bloat at the container and package level, and removed it. The researchers say their work highlights the issue of technical debt in machine learning systems.

The discussion further explores the issue and the practicalities of managing containers, including difficulties in ensuring reproducibility and the maintenance of dependencies. The discussion finally highlights the importance of enabling containers and the removal of bloating while also acknowledging that it is a challenging task.

### Meta open-sources multisensory AI model that combines six types of data

#### [Submission URL](https://www.theverge.com/2023/5/9/23716558/meta-imagebind-open-source-multisensory-modal-ai-model-research) | 149 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [48 comments](https://news.ycombinator.com/item?id=35876147)

Meta has released an open-source AI model, ImageBind, that employs six types of data, including thermal, visual, and movement information, to create immersive and multisensory experiences. The research project marks a significant development in generative AI systems, which rely on linking multiple streams of data to create content. By incorporating touch, speech, smell, and brain fMRI signals, future models could learn holistically, approaching humans’ ability to learn directly from different types of information. Meta's approach, which is open source, comes as rival firms such as Google and OpenAI increasingly pursue a secretive strategy.

The discussion in the comments included some debate about the definition of open source versus free and open-source software (FOSS), and other topics such as the underdefined nature of terms related to open-source, the differences in licenses, and the potential hardware requirements needed for training the model. People also expressed their skepticism about Meta's involvement in AI for the "truly neutral" evaluation of natural language processing tasks and the company's controversial attitude toward privacy.

### Amazon Is Being Flooded with Books Written Entirely by AI

#### [Submission URL](https://futurism.com/the-byte/amazon-flooded-books-written-by-ai) | 52 points | by [redbell](https://news.ycombinator.com/user?id=redbell) | [43 comments](https://news.ycombinator.com/item?id=35881065)

Amazon's marketplace is being flooded with books almost entirely generated by AI. This trend is making it harder to distinguish between real authors and the non-existent writers created by AI algorithms. The AI-generated books are primarily listings on surprisingly niche topics with five-star reviews. However, AI content is flooding the internet and could spark a pandemic of misinformation. Several online publications are already making ample use of the technology to generate often dubiously sourced and redundant content. The emergence of AI-generated books and content represents new reality for businesses and poses risks of misinformation and confusing reality.

Commenters suggest that AI-generated content could be beneficial in creating recommenders for modern authors and helping companies find new incentives in machine-generated content. However, concerns arise if the AI-generated content is not reliable, leading to the spread of misinformation. Some users also point out that there are still many interesting printed books available to read and that not all books necessarily have the same value. Furthermore, some discussion in the comments centers on LitRPG books that are highly entertaining and those books generated by AI. There are also discussions on AI-generated ratings.

### Constitutional AI: RLHF on Steroids

#### [Submission URL](https://astralcodexten.substack.com/p/constitutional-ai-rlhf-on-steroids) | 151 points | by [jstanley](https://news.ycombinator.com/user?id=jstanley) | [68 comments](https://news.ycombinator.com/item?id=35870669)

Today, Anthropic, a big AI company, announced a new process for training AI called Constitutional AI, which allows the AI to give feedback to itself to train the AI to be less harmful and more ethical. The process involves showing the AI its first draft answer to a question, along with a prompt saying “rewrite this to be more ethical” until a large dataset of rewritten, more ethical second drafts is collected, and then the AI is trained to write answers that are less like the first drafts and more like the second drafts. The results have been positive, with Constitutionally trained models being "less harmful at a given level of helpfulness" than models trained with traditional reinforcement learning through human feedback.

Some users argue that accurate predictions and not political correctness should be the main goal of AI. Others argue that the new method could lead to more ethical AI and that companies should prioritize minimizing harm rather than maximizing profit. Some users also criticize the economics and politics that drive AI development.

### Show HN: LLM, a Rust Crate/CLI for CPU Inference of LLMs (LLaMA, GPT-NeoX, etc.)

#### [Submission URL](https://github.com/rustformers/llm) | 43 points | by [Philpax](https://news.ycombinator.com/user?id=Philpax) | [4 comments](https://news.ycombinator.com/item?id=35876928)

llm is a Rust ecosystem of libraries for running inference on large language models, inspired by llama.cpp. It is powered by the ggml tensor library and aims to bring the robustness and ease of use of Rust to the world of large language models. Currently, inference is only on the CPU, but there is hope to support GPU inference in the future through alternate backends. Supported models include GPT-2, GPT-J, LLaMA, Alpaca, Vicuna, Koala, GPT4All v1, GPT4-X, Wizard, GPT-NeoX, StableLM, Dolly v2, and BLOOMZ. The primary crate is the llm crate, which wraps llm-base and supported model crates. On top of llm, there is a CLI application, llm-cli, which provides a convenient interface for running inference on supported models.

The discussion on the submission revolves around users' experiences with llm and related libraries. One user who tried the library commented positively on its convenience but noted that it runs only on CPU at the moment and would be more efficient on multiple servers. Another user shared that they have attempted to build their own ML project but found it challenging to justify the expense. The discussion then shifted to ggml, a tensor library used in llm that offers performance gains and has a direct plan to build a competition graph with supported backends, including Intel MKL and CUDA. Overall, the discussion reflects the interest and excitement around using Rust for large language models, as well as the importance of performance optimization in machine learning projects.

### AI predicts pancreatic cancer 3 years before it happens

#### [Submission URL](https://www.theregister.com/2023/05/09/ai_pancreatic_cancer/) | 20 points | by [ter_adata](https://news.ycombinator.com/user?id=ter_adata) | [4 comments](https://news.ycombinator.com/item?id=35878002)

AI algorithms can predict whether a patient will develop pancreatic cancer up to three years before human doctors can, according to research published in the journal Nature. The study, led by Harvard Medical School and Danish academics, incorporated machine learning trained on millions of patient records obtained from databases in Denmark and the US. The best-performing model indicated that of the top 1,000 riskiest patients over the age of 50, roughly 320 would go on to develop pancreatic cancer. The researchers warn that local population data is necessary for accurate cancer-catching predictions.

The discussion on this submission includes comments about the effectiveness of machine learning algorithms in predicting pancreatic cancer and the potential bias that can occur in future AI-based cancer screening tools. Some users mention the need for local population data to ensure accurate predictions while others discuss the use of GPT transformers and the study's reliance on medical records obtained from databases in Denmark and the US. There is also mention of the high mortality rate of pancreatic cancer and the potential benefits of using AI to detect the disease earlier.

---

## AI Submissions for Mon May 08 2023 {{ 'date': '2023-05-08T17:10:30.096Z' }}

### GPU vendor-agnostic fluid dynamics solver in Julia

#### [Submission URL](https://b-fg.github.io/2023/05/07/waterlily-on-gpu.html) | 219 points | by [moelf](https://news.ycombinator.com/user?id=moelf) | [90 comments](https://news.ycombinator.com/item?id=35861435)

WaterLily.jl, a pure Julia fluid simulator, has successfully ported its solver from a serial CPU execution to a backend-agnostic execution that includes multi-threaded CPU and GPU from different vendors (NVIDIA and AMD) thanks to KernelAbstractions.jl (KA). Using the @kernel macro from KA, the team was able to generate the divergence operator using KernelAbstractions by defining a divergence kernel and a wrapper function. To automate the generation of loops, the team defined the macro @loop, which generates loops over CartesianIndices ranges automatically. Additionally, this approach can be used to generate KA kernels for each loop in the code. The extended abstract preprint with benchmarking details regarding this port can be found on arXiv.

The comments discussed the advantages and disadvantages of Julia as a language compared to Python and other languages, as well as the challenges of programming for simulations and the benefits of using GPU acceleration. Many users expressed interest in trying out the new code and in working with Julia for machine learning and other projects.

### Early Artificial Intelligence Projects: A Student Perspective (2006)

#### [Submission URL](https://projects.csail.mit.edu/films/aifilms/AIFilms.html) | 58 points | by [onemind](https://news.ycombinator.com/user?id=onemind) | [7 comments](https://news.ycombinator.com/item?id=35857070)

This article is a retrospective look at the early days of artificial intelligence, exploring its definition, foundational concepts, and major projects at MIT and in the US. The article begins with John McCarthy's definition of AI, which is the science of making intelligent machines that can mimic human thought, feelings, and decision-making. It explains that AI has not had a linear progression, but rather has grown in many directions along the intertwining world wide web. The article then delves into the foundational concepts of AI, such as programmable machines that can solve equations, and the development of early computers. Moving along, the article explores major AI projects during the decades following the creation of the term "AI," from the 1950s to the present day, including the emergence of search engines, spell checkers, and spam filters.

One user mentions studying AI in the past, including the use of programming languages, such as Prolog and Lisp, during the 90s. Another user shares their experience of shifting their focus to neural networks and how technology changes over time. The topic of machine learning and its ability to surpass human performance in certain tasks is mentioned. The concept of intelligence being computationally attainable is also discussed. Finally, another user shares an article on an AI-generated system that demonstrates intelligence comparable to humans.

### Giving GPT “Infinite” Knowledge

#### [Submission URL](https://sudoapps.substack.com/p/giving-gpt-infinite-knowledge) | 116 points | by [sudoapps](https://news.ycombinator.com/user?id=sudoapps) | [83 comments](https://news.ycombinator.com/item?id=35864698)

Large Language Models (LLMs) like OpenAI's GPT can provide accurate responses to information retrieval questions if fed with relevant real-time data for interpretation. However, a limitation on the number of tokens for the initial prompt or response to generate results restricts LLMs from ingesting large amounts of data directly. To overcome this hurdle, data is converted into embeddings - vector representations of a string - and stored in vector databases. When a user asks a question, similarity search is done for relevant information with only the essential pieces related to the question being injected into the LLM prompt before answering the question. While there are token limitations, string compression techniques can help accommodate more data within the limit.

The discussion on this submission consists of a variety of viewpoints on the capabilities and limitations of Large Language Models (LLMs), particularly in their ability to comprehend and analyze data beyond the token limitations. Some commenters suggest that embeddings-based search is a viable solution that allows for relevant data to be retrieved within the token limit, while others express concerns about the effectiveness of such an approach. There are also discussions about the potential of training larger models with real-time data to further enhance LLMs' performance and capabilities. Additionally, there are debates about the practical application of LLMs and their scalability, with some commenters expressing skepticism about their ability to achieve true artificial general intelligence (AGI) and others suggesting that advancements in technology may make it possible in the future.

### RasaGPT: First headless LLM chatbot built on top of Rasa, Langchain and FastAPI

#### [Submission URL](https://github.com/paulpierre/RasaGPT) | 171 points | by [riter](https://news.ycombinator.com/user?id=riter) | [108 comments](https://news.ycombinator.com/item?id=35859344)

Introducing RasaGPT, the first headless LLM chatbot platform built on top of Rasa and Langchain. Rasa is a popular and easy-to-use chatbot framework with built-in NLU ML pipelines, while Langchain is an LLM library for indexing, retrieval, and context injection. RasaGPT provides a reference implementation of Rasa and Telegram utilizing LLM libraries, including Langchain, for a seamless chatbot experience. Additionally, RasaGPT offers full API documentation and features including document versioning and automatic re-training, async end-points and database models customization, and pgAdmin for database browsing.

Some users discuss their experiences implementing Langchain and offer potential solutions to common problems. There is also discussion about other language models and their applications. Additionally, there is discussion about LMQL, a language model query language. Some users provide links to relevant resources and articles about these topics.

### Alphabet plans to announce its new general-use LLM called PaLM 2 at Google I/O

#### [Submission URL](https://www.cnbc.com/2023/05/08/google-io-to-feature-ai-updates-showing-off-palm-2-llm.html) | 37 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [5 comments](https://news.ycombinator.com/item?id=35866435)

Google is set to unveil its latest artificial intelligence (AI) updates, including the launch of a general-use large language model (LLM) called PaLM 2, at its annual developer conference (Google I/O). The LLM, incorporating more than 100 languages, has undergone numerous creative writing, coding, and maths tests. Google will also announce advancements to its Bard and Search AI, including a new feature that allows a user to "create" an image based on entered text. The conference will also cover the company's progress with Workspace AI collaborator and image recognition tool Google Lens.

The first comment by "jggwtts" seems to be a prediction about Google's latest AI developments and their potential impact. Another user, "two_in_one", expands on the idea by stating that these developments will enable dystopian scenarios like targeted advertising and tailored content. "sekh60" adds to the discussion by pointing out that Google stopped targeting based on demographics years ago. "cynydz" offers a different perspective, suggesting that AI can be effective in completing sentences and matching patterns, but also has the potential to manipulate individuals and activities. Finally, "lphbttng" mentions the PaLM AI and describes it as advanced.

---

## AI Submissions for Sun May 07 2023 {{ 'date': '2023-05-07T13:51:19.983Z' }}

### Prolog for data science

#### [Submission URL](https://emiruz.com/post/2023-04-30-prolog-for-data-science/) | 164 points | by [usgroup](https://news.ycombinator.com/user?id=usgroup) | [47 comments](https://news.ycombinator.com/item?id=35855398)

In this article, the author explores the integration of Prolog as a key component in data science analysis, using symbolic reasoning to generate properties about the data under study. They include examples of piece-wise regression on time-series data using symbolic reasoning, demonstrating how to create symbols which represent facts about the data through the use of Python and Prolog. The author then shows how to merge overlapping segments to create bigger continuous linear spans, ultimately calculating an optimal piece-wise linear fitting to find the subset of non-overlapping spans that result in maximum coverage of the data.

The comments discuss various related topics. Some users mention the challenge of portability and incompatibility with previous versions in Datalog adoption. Others talk about the benefits and difficulties of working with Prolog and suggest resources for learning and using it. There are also discussions about data storytelling and decision-making based on data. Finally, one user shares a link to their project on SaaS metrics generator. However, there is an overall lack of engagement and comments on the topic.

### The Prime Video microservices to monolith story

#### [Submission URL](https://adrianco.medium.com/so-many-bad-takes-what-is-there-to-learn-from-the-prime-video-microservices-to-monolith-story-4bd0970423d4) | 472 points | by [mparnisari](https://news.ycombinator.com/user?id=mparnisari) | [372 comments](https://news.ycombinator.com/item?id=35853148)

The Prime Video team's success with scaling up their audio/video monitoring service using a combination of serverless architecture and containers has sparked a debate over the usefulness of microservices versus a monolith approach. According to technology strategy advisor Adrian Cockcroft, the team's approach follows his own recommendation of building a serverless prototype first and then re-implementing it as a continuously running autoscaled container for sustained high traffic and low latency. Cockcroft also notes that microservices were over-sold as a solution to all problems and that there are times when a monolith or an existing service should be used instead. The Prime Video team's real-time user experience analytics engine for live video is a valuable addition to any video streaming service and can be accessed through Datazoom.io, a service whose chief architect and CTO are ex-Netflix colleagues of Cockcroft.

The benefits and drawbacks of microservices versus monoliths are discussed, with some users arguing that each approach has its merits depending on the project's specific needs. One user emphasizes the importance of selecting the right technology stack to minimize common errors during development and increase the chances of success.

### DEF CON to set thousands of hackers loose on LLMs

#### [Submission URL](https://www.theregister.com/2023/05/06/ai_hacking_defcon/) | 104 points | by [magoghm](https://news.ycombinator.com/user?id=magoghm) | [11 comments](https://news.ycombinator.com/item?id=35848573)

DEF CON's AI Village is set to host the largest red teaming exercise ever for any group of AI models, with hackers invited to find bugs and biases in large language models (LLMs). The event will feature LLMs built by AI companies like OpenAI and Google, and hackers will be tasked with finding flaws in these systems, including bias, hallucinations, and jailbreaks. The event, which will run from August 10-13 in Las Vegas, aims to promote the testing of a wide range of harms, and the hackers with the most points will win high-end Nvidia GPUs. Additionally, the event is supported by the White House Office of Science, Technology, and Policy; America's National Science Foundation's Computer and Information Science and Engineering Directorate; and the Congressional AI Caucus. 

One commenter expressed skepticism about the exercise and stated that it could lead to hackers planting exploits in open-source projects. Another commenter highlighted the challenge of debugging and ensuring security in non-deterministic computer programming, particularly in the context of machine learning and artificial intelligence. Another commenter discussed recent scientific progress in artificial intelligence and machine learning and the effort to make models more explainable and transparent. Other comments touched on the potential commercial applications of AI and concerns over data centers being located in China in the context of a potential conflict over Taiwan. Finally, some users joked about their inability to understand the articles and comments on the topic.

### AI tool designs mRNA vaccines that are more potent and stable

#### [Submission URL](https://www.nature.com/articles/d41586-023-01487-y) | 142 points | by [voisin](https://news.ycombinator.com/user?id=voisin) | [54 comments](https://news.ycombinator.com/item?id=35847774)

Researchers at Baidu Research, the AI division of the Chinese search engine firm, have created an AI tool that could pave the way for mRNA-based vaccines that don't need refrigeration, potentially making them more widely available in resource-poor areas. The tool optimises mRNA sequences, allowing the genetic material to persist for longer and creating more stable mRNA. The enhanced stability offers improved protection against vaccine degradation, without the need for cold-chain equipment. The researchers tested the tool on COVID-19 and shingles vaccines in mice, leading to significant improvements in efficacy and shelf-life. The discussion surrounding the submission involved various topics, including the challenges of lattice parsing problems, the possible copyright and patent issues that RNA sequences and AI-generated works could face, and a debate on the effectiveness of COVID-19 vaccines.

### Google Calendar and Assistant Reminders Will Migrate to Google Tasks Soon

#### [Submission URL](https://workspaceupdates.googleblog.com/2023/02/calendar-and-assistant-reminders-to-tasks-migration.html) | 121 points | by [e2e4](https://news.ycombinator.com/user?id=e2e4) | [115 comments](https://news.ycombinator.com/item?id=35849243)

Google has announced that its Calendar and Assistant Reminders will soon be migrating to Google Tasks, according to a post on the Google Workspace Updates blog. The move will allow users to manage their to-do lists in a single place and will provide a more streamlined experience. Google Tasks' integration with other Workspace apps, such as Gmail and Drive, will also make it easier for users to stay organized and productive. The migration is expected to be completed by the end of 2023.

Most of the discussion on the Hacker News thread centers around the difference between calendar events and tasks, and how the consolidation of reminders and tasks in Google Tasks will simplify things. There are also suggestions for Google to improve the graphical representation of its product relationships and for the company to establish more user-friendly voice control systems similar to those seen in Star Trek. There is also a discussion about how Google is pushing its voice assistant technology, even when it may not be in the best interest of users.

---

## AI Submissions for Sat May 06 2023 {{ 'date': '2023-05-06T17:37:46.426Z' }}

### AI tool designs mRNA vaccines that are more potent and stable

#### [Submission URL](https://www.nature.com/articles/d41586-023-01487-y) | 132 points | by [voisin](https://news.ycombinator.com/user?id=voisin) | [53 comments](https://news.ycombinator.com/item?id=35847774)

Researchers from Baidu Research, a Beijing-based AI company, have developed an AI tool that optimizes gene sequences in mRNA vaccines, thereby creating more potent and stable jabs that can be deployed globally. The software uses computational linguistics to design mRNA sequences that are more intricate than currently used vaccines. This enables the genetic material to persist longer, leading to more antigens being produced by the body’s protein-making machinery, resulting in more protective antibodies to fend off infectious diseases. The enhanced structural complexity of the mRNA also offers improved protection against vaccine degradation, eliminating the need for cold-chain equipment to handle such jabs.

The discussion on Hacker News covered a variety of topics including the technical aspects of the AI tool, copyright issues surrounding AI-generated content, and the effectiveness of mRNA vaccines in preventing the spread of COVID-19. One user pointed out that statistically-based papers linked to in the discussion about longer testing periods can be flawed in their analysis, while another argued that mRNA vaccines may pose a risk of rationing and double the rational vs. vector collision risk identified in vaccine production. Overall, there was a mix of technical analysis and ethical concerns about the use and distribution of mRNA vaccines.

### Open source Background Remover: Remove Background from images and video using AI

#### [Submission URL](https://github.com/nadermx/backgroundremover) | 367 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [92 comments](https://news.ycombinator.com/item?id=35838504)

BackgroundRemover is a free and open source tool that allows users to remove background from images and videos using artificial intelligence (AI). The tool offers a simple command line interface and is powered by u2net models. Users can choose from various background removal methods, including u2netp, u2net, or u2net_human_seg, and can also apply alpha matting for better results. The tool supports popular file formats such as MP4 and GIF, and also allows users to overlay transparent videos over other videos or images. Overall, BackgroundRemover is a powerful and versatile tool for anyone looking to remove background from images and videos with ease.

There is a debate on whether Background Remover's creators or contributors can be trusted, as well as concerns over its pricing, downloading, and potential malicious activity. Users have shared alternatives and tips to improve its functionality. There have also been discussions on unrelated topics, such as technical skills and road safety.

### Intel OEM Private Key Leak: A Blow to UEFI Secure Boot Security

#### [Submission URL](https://securityonline.info/intel-oem-private-key-leak-a-blow-to-uefi-secure-boot-security/) | 627 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [352 comments](https://news.ycombinator.com/item?id=35843566)

MSI suffered a cyberattack in April by ransomware group Money Message, resulting in the exfiltration of 1.5TB of data, including the Intel OEM private key. The key is used to control Intel Boot Guard digital signatures which validate programs before operating system start-up, and could compromise the security of UEFI secure boot. The leaked key affects Intel's 11th, 12th and 13th generation processors and their original equipment manufacturers, including Lenovo and Supermicro. The full extent of the private key leaks remains unclear, although it is known that they impact at least 166 MSI products.

A few users contended that the best way to combat the potential security implications of the key's loss is to have a backup option in place, one that is secured in a disconnected system. Other users suggested that individuals should remain vigilant and pay attention to security updates given that UEFI implementations on most computers allow physical access to disable secure boot, while some users expressed concerns about balancing security and freedom to choose software.

### Qdrant: Vector Database for the next generation of AI applications

#### [Submission URL](https://github.com/qdrant/qdrant) | 22 points | by [nateb2022](https://news.ycombinator.com/user?id=nateb2022) | [5 comments](https://news.ycombinator.com/item?id=35844724)

Qdrant is a vector similarity search engine and database tailored to extended filtering support. It is useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications. Qdrant is written in Rust 🦀, which makes it fast and reliable even under high load. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more! The engine provides a production-ready service with a convenient API to store, search, and manage points, which are vectors with an additional payload. Qdrant offers a variety of client libraries, including Rust, Go, JavaScript/TypeScript, Python, Elixir, PHP, Ruby, and Java. It also offers a REST API and a gRPC interface for faster production-tier searches and supports filtering and payload, rich data types, query planning and payload indexes, SIMD hardware acceleration, write-ahead logging, and distributed deployment.

In the discussion, a user here4U praises Qdrant's vector similarity search engine and scalability. They mention that it is useful for neural-network or semantic-based matching and provides an API to manage points. Another user chxr remarks that they prefer Pinecone DB because it immediately connects to the internet, generates fewer files on disk, and is simple and fast. However, in response to a comparison with Qdrant and Pinecone, user ndr-z shares a benchmark link that suggests Qdrant performs better than Pinecone in terms of indexing time, search time, and memory usage.

### Using ChatGPT to generate a GPT project end-to-end

#### [Submission URL](https://github.com/ixaxaar/VardaGPT/blob/master/STORY.md) | 228 points | by [ixaxaar](https://news.ycombinator.com/user?id=ixaxaar) | [204 comments](https://news.ycombinator.com/item?id=35839536)

A programmer wondered about the impact of ChatGPT on programming and decided to test it out by attaching a memory module to a GPT. They used ChatGPT-4 to generate the project foundations, step by step, and even wrote unit tests. After a few weekend hours, they created VardaGPT, a repository entirely generated by ChatGPT-4. The experience was neither like working with a pair programmer nor a product manager scenario, but more like handholding a fresh grad who had absorbed all human knowledge. It was tiring but a differential productivity multiplier. The experiment concluded that the programmer's job is safe, at least for now. The aside adds that ChatGPT is also great at generating Agda and could be used to formalize all of pure math.

The discussion on Hacker News included conversations about the limitations and future potential of ChatGPT for programming, with one commenter noting that AI programming is not a threat to humans—at least, not yet. Some commenters suggested that the future of AI in programming will eliminate human intervention entirely, while others highlighted the importance of high-quality human programmers and the value of their ability to make judgements and explain things in natural language. One commenter shared their experience subscribing to ChatGPT and using it to generate limited programming prompts, while another experimented with using the GPT-4 API to generate a table of data.

### Show HN: ReRender AI - Realistic Architectural Renders for AutoCAD/Blender Users

#### [Submission URL](https://rerenderai.com) | 50 points | by [eddieweng](https://news.ycombinator.com/user?id=eddieweng) | [19 comments](https://news.ycombinator.com/item?id=35839593)

ReRender AI by Stylefie, Inc. is offering a service that generates photorealistic renders of buildings in over 20 different design styles. All users have to do is upload a picture of their project, and within seconds, they can enjoy the results. This service includes various types of buildings, such as single-family homes, shopping malls, hospitals, and more, in styles ranging from sleek international to playful post-modern. The rendered images are available in different resolutions. The service is currently in operation and is available through the ReRender AI website.

The discussion includes various comments, some of which suggest exciting applications, such as using it to explore new design ideas or rendering a floor plan that looks viable and realistic. Some commenters ask about the technology behind the AI, its ability to represent sustainable architecture features, and its potential limitations. There are also suggestions for other software programs to use in conjunction with ReRender AI. Finally, there is a comment about the need for an overhaul to the FreeCAD dr UI.

### It looks like GPT-4-32k is rolling out

#### [Submission URL](https://community.openai.com/t/it-looks-like-gpt-4-32k-is-rolling-out/194615) | 255 points | by [freediver](https://news.ycombinator.com/user?id=freediver) | [182 comments](https://news.ycombinator.com/item?id=35841460)

AI language model GPT-4-32k is rolling out its API, and developers are already starting to experiment with its capabilities. Some lucky users were quick to gain access to the new model and have been sharing their experiences on Hacker News. The GPT-4-32k model boasts an impressive 32,000 token context length, which allows it to generate much more in-depth and nuanced responses to inputs than its predecessors. However, not all users have gained access yet, and the rollout seems to be happening at different rates based on capacity. Nonetheless, anticipation for GPT-4-32k is high, and developers are eager to try it out for themselves.

While some users believe that GPT-4-32k is overhyped, others are excited about its potential. There is a discussion about how to calculate the total number of pages of context for 32k tokens, with different opinions put forth. Moreover, there is a discussion about how to handle long texts and conversations in the context of GPT models, and how different tools and strategies can be employed. There are also discussions about the request limit, cost, and pricing of GPT-4-32k, batch processing, and how to optimize the performance.

---

## AI Submissions for Fri May 05 2023 {{ 'date': '2023-05-06T00:23:21.363Z' }}

### Concrete: A fully homomorphic encryption compiler

#### [Submission URL](https://www.zama.ai/post/zama-concrete-fully-homomorphic-encryption-compiler) | 80 points | by [zacchj](https://news.ycombinator.com/user?id=zacchj) | [10 comments](https://news.ycombinator.com/item?id=35826723)

Zama has released their Fully Homomorphic Encryption (FHE) compiler, Concrete, designed to simplify the management of noise, cryptographic parameters selection, and order of operations for specific computations for developers. The Compiler expects an input program in MLIR, and it can be used via Python, C++, and C APIs as well as a CLI tool for debugging. The LibrarySupport class is one of the main entry points, enabling the compilation and execution of FHE programs while storing artifacts on disk. The compiled library is stored in a sharedlib file, along with a JSON file that describes the inputs and outputs and crypto parameters for the compiled function.

One commenter questioned the necessity of using encryption for weights, while another commenter pointed out that using FHE to protect software is similar to how Syncrosoft protected software using dongles. Another commenter mentioned that they have been working on developing a CPU designed for FHE for the past decade, while others compared Concrete to Google's FHE implementation. The discussion also included references to Concrete's code repository and a podcast on the intersection of FHE and zero-knowledge proofs.

### Shap-E: Generate 3D objects conditioned on text or images

#### [Submission URL](https://github.com/openai/shap-e) | 273 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [50 comments](https://news.ycombinator.com/item?id=35836976)

OpenAI has released its code and model for Shap-E, a system that generates 3D objects based on text or images. The release includes examples of models that can generate things like chairs that look like avocados, spaceships, and birthday cupcakes. Users can install Shap-E with pip, and access a variety of notebooks that provide guidance on encoding models, sampling 3D models based on a text prompt, and more. The code and model are available on GitHub under an MIT license.

Some users discuss their experiences with generating 3D objects, while others share examples of objects they have generated. Others comment on the difficulty of generating 3D models and suggest alternative tools. There is also discussion around the licensing of the code and models, as well as related topics such as 3D printing and file formats.

### Unlimiformer: Long-Range Transformers with Unlimited Length Input

#### [Submission URL](https://arxiv.org/abs/2305.01625) | 322 points | by [shishy](https://news.ycombinator.com/user?id=shishy) | [99 comments](https://news.ycombinator.com/item?id=35832802)

Researchers have proposed a new model called Unlimiformer, which extends the capabilities of existing transformer-based models by allowing them to handle unlimited input lengths for a better long-document and multi-document summarization. The model can be applied to any existing pretrained encoder-decoder transformer, and it offloads the attention computation across all layers to a single k-nearest-neighbor index that can be kept on the GPU or CPU memory and queried in sub-linear time. Unlimiformer has been shown to perform well on several benchmarks, summarizing even 350k token-long inputs from the BookSum dataset without any input truncation at test time. The code and models are publicly available online.

The comments section discusses topics such as the quality of pre-reviewed papers, self-aggrandizing behavior in the research community, challenges with peer review processes, differences between conferences and HN commenting, and the importance of feedback from the HN community.

### Bluesky's AT Protocol - Federation Architecture Overview

#### [Submission URL](https://blueskyweb.xyz/blog/5-5-2023-federation-architecture) | 137 points | by [capableweb](https://news.ycombinator.com/user?id=capableweb) | [79 comments](https://news.ycombinator.com/item?id=35834106)

Bluesky, the new social media platform built on the AT Protocol, is set to launch a sandbox environment for testing federation with allow-listed servers. A federated networking model, AT Protocol differs from conventional social media by allowing users to run their own servers, host data on a personal data server, and use big graph services to assemble and curate a personal feed. The architecture is expected to facilitate public conversations on a global social network, with an ecosystem of app views for each lexicon, including video, long-form blogging, and groups and forums. Bluesky aims to make federation easy and accessible to all.

The discussion around the submission on Hacker News includes various opinions and insights. Some users express concerns regarding Bluesky's implementation of centralization, such as difficulty in implementing control and filtering, while others believe that Bluesky's potential for transparency and decentralized social media could be a healthier alternative to existing platforms. Additionally, there is debate regarding the comparison between ActivityPub and Bluesky, with some users pointing out differences in their respective designs and certain limitations of ActivityPub. There is also discussion about the challenges of migration between servers and ways to address the issue of lost interactions in the process. Overall, the discussion brings up various important points related to decentralization and the future of social media.

### At Musk’s brain-chip startup, animal-testing panel is rife with conflicts

#### [Submission URL](https://www.reuters.com/technology/musks-brain-chip-startup-animal-testing-panel-is-rife-with-potential-conflicts-2023-05-04/) | 137 points | by [wootland](https://news.ycombinator.com/user?id=wootland) | [90 comments](https://news.ycombinator.com/item?id=35834918)

Elon Musk's brain-implant company, Neuralink, has come under fire for filling its animal-research oversight board with company insiders who may stand to benefit financially from the venture's development goals. According to documents and interviews with employees, 19 of the board's 22 members were Neuralink employees as of late 2022, raising questions about potential violations of conflict-of-interest regulations aimed at protecting research integrity. As we've previously reported, Neuralink is seeking regulatory approval for human trials of a brain chip intended to help paralyzed people type with their minds, among other goals.

Some users argue for the need for regulated and informed animal testing, while others argue for caution in human testing. There is also a debate on the efficacy and enforceability of current regulations, with some users calling for a change in regulations to better protect animals and humans involved in scientific research.

### Show HN: UnionX – GPT4-powered Copilot for Work with Jupyter-style notebooks

#### [Submission URL](https://www.unionx.io/) | 48 points | by [gangster_dave](https://news.ycombinator.com/user?id=gangster_dave) | [5 comments](https://news.ycombinator.com/item?id=35836679)

Looking for a way to boost your productivity and streamline your workflow? Look no further than UnionX, the AI-powered platform that lets you easily analyze documents, generate insights, and create new documents in seconds. Whether you're a data scientist, legal professional, or product manager, UnionX can help you save time and work more efficiently. With powerful tools like OpenAI's GPT4 model and Jupyter-style workflows, UnionX makes it easy to gather, analyze, and generate new insights from your data. So why wait? Try UnionX today and start achieving more in less time!

Some users feel that the concept sounds exciting, but the marketing documentation is not clear enough. They suggest pushing towards a Jupyter notebook interface for non-coding tasks and adding a coding interface for more technical users. Others believe that simple notebooks and screencaps of them would be helpful in understanding the product. The conversation then shifts to coding integration and the need for actual notebooks rather than lock-in options. One user also raises a question regarding comparing the platform's source version.

### The AI PR Industrial Complex

#### [Submission URL](https://www.bigtechnology.com/p/the-ai-pr-industrial-complex) | 80 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [36 comments](https://news.ycombinator.com/item?id=35829430)

In the rush for corporations, politicians, and other thought leaders to monetize and exploit the opportunities presented by AI technology, an AI PR industrial complex is emerging. This complex operates by using AI as a pretext for problems that might have other causes such as IBM's decision to replace up to 7,800 back-office employees with AI, as opposed to using the technology to make workers more productive. Similarly, politicians and regulators running to the cameras to talk about AI raises questions about their actual understanding of the technology's opportunities and risks. While some AI announcements have real substance, the AI PR industrial complex is growing and drawing deserved skepticism.

Commenters suggest that the AI hype is similar to the cryptocurrency hype of the past, and the emerging AI PR industry is drawing deserved skepticism. Some commenters talk about how AI technology may be applied for specific domain-specific tasks, such as creating 2D and 3D animations for games and designing dashboards and data visualization tools. There is also a discussion of how AI is being used to generate advertisements and how LLMs may be used to solve real-world problems in sectors such as energy and sustainable growth. 

### MosaicML MPT-7B: A Commercially-Usable LLaMa-Quality Model

#### [Submission URL](https://www.mosaicml.com/blog/mpt-7b) | 102 points | by [ml_hardware](https://news.ycombinator.com/user?id=ml_hardware) | [11 comments](https://news.ycombinator.com/item?id=35829800)

MosaicML, an AI platform, has launched its MPT-7B model series, comprising pre-trained transformers that enable faster training and inference. The series comprises four models: MPT-7B Base, a decoder-style transformer with 6.7 billion parameters; and three finetuned variants, including the super-long context MPT-7B-StoryWriter-65k+. MosaicML also released the entire codebase for pretraining, finetuning, and evaluating MPT, a framework for building LLMs, and training and deployment instructions. The models can be licensed for commercial use and are a response to a flurry of activity focused on open-source LLMs.

Some users express confusion around the size and input of the models, but overall, people are impressed with MosaicML's documentation and instructions for training and deployment. One user notes that the MPT-7B model is similar to LLaMa but shows significant improvements in some use cases. Others discuss the practical applications of such models, such as using them for chat instruction and generating long-form text. Finally, there are some comments about the potential future release of GPT-4 and speculation on its potential impact on the AI language modeling space.

### OpenAI changed its plans and won’t train on customer data, Sam Altman says

#### [Submission URL](https://www.cnbc.com/2023/05/05/sam-altman-openai-wont-tap-into-customer-apis.html) | 41 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [10 comments](https://news.ycombinator.com/item?id=35830107)

OpenAI has stopped training its large-language models, including the popular chatbot ChatGPT, with paying customer data. This change came as a response to customers who had requested that the company not use their data. OpenAI's terms of service were quietly updated in March to reflect this shift. However, the company's privacy and data protection policy only applies to customers who use the company's API services. The change highlights growing concerns about the use of large-language models such as ChatGPT in areas such as entertainment, where intellectual property rights are being challenged.

The comments on the submission discuss various aspects related to OpenAI's decision to stop training its large-language models with customer data. Some users suggest that OpenAI should provide more control to customers over their data, while others highlight the importance of licensing in protecting intellectual property rights. There is also a discussion on the efficacy of using domain-specific tasks for training language models and the limitations of publicly available training data. One user mentions Azure OpenAI services as a potential alternative.

---

## AI Submissions for Thu May 04 2023 {{ 'date': '2023-05-04T15:01:43.244Z' }}

### Rest in Peas: The Unrecognized Death of Speech Recognition (2010)

#### [Submission URL](https://robertfortner.posthaven.com/rest-in-peas-the-unrecognized-death-of-speech) | 37 points | by [jawns](https://news.ycombinator.com/user?id=jawns) | [43 comments](https://news.ycombinator.com/item?id=35800935)

Computer speech recognition hit a flatline in 2001 before it even reached human levels of accuracy, largely due to computers being unable to properly understand language. While progress has been made since the 1950s and 1960s, relying mainly on fast computers and digital text to supplement decades-old language machinery, current accuracy rates still hover around 80%, with humans at 98%. Despite billions of text at their disposal, machines are prone to risky guessing and limited by parsers and recognition systems that work only in certain linguistic domains. Efforts to allow programs to understand grammar and word meaning have been largely unsuccessful, leaving them with a significantly different understanding of language than humans.

The discussion among commenters touches on various topics, including the challenges of recognizing different dialects and accents, reinforcement learning and human feedback, the accuracy of speech recognition software and the importance of context in understanding speech. Some commenters also mention their experiences with specific speech recognition programs and datasets, such as Common Voice and Whisper.

### OpenLLaMA: An Open Reproduction of LLaMA

#### [Submission URL](https://github.com/openlm-research/open_llama) | 463 points | by [sadiq](https://news.ycombinator.com/user?id=sadiq) | [175 comments](https://news.ycombinator.com/item?id=35798888)

OpenLLaMA, an open-source reproduction of Meta AI's LLaMA language model, has been released on GitHub. In this release, a public preview of the 7B OpenLLaMA model trained with 200 billion tokens has been provided, along with PyTorch and JAX weights of pre-trained OpenLLaMA models, and their evaluation results and comparison against the original LLaMA models. Additionally, a new checkpoint of OpenLLaMA 7B trained on 300B tokens has been released to make the model broadly compatible with existing implementations. The results indicate that OpenLLaMA exhibits comparable performance to the original LLaMA and GPT-J across a majority of tasks and outperforms them in some.

In the comments, there is a discussion about the resources required for ML models and their training cost, along with recommendations to understand ML terms and concepts. There is also debate about the use of the word "hallucination" to describe the output of language models.

### Distilling Step-by-Step Outperforming Larger Language Models with Less Training

#### [Submission URL](https://arxiv.org/abs/2305.02301) | 144 points | by [verdverm](https://news.ycombinator.com/user?id=verdverm) | [33 comments](https://news.ycombinator.com/item?id=35810663)

Researchers have developed a new mechanism called "Distilling Step-by-Step" that trains smaller models to outperform larger language models (LLMs) using less training data. This method extracts LLM rationales to provide additional supervision for small models in a multi-task training framework, leading to better performance with fewer labeled/unlabeled training examples. Distilling Step-by-Step achieves better performance with substantially smaller model sizes and reduces both the model size and the amount of data needed to outperform LLMs. The method was successful in four NLP benchmarks and could help make LLMs more memory-efficient and compute-intensive for practical applications.

The comment section discusses the importance of smaller, task-specific models and the challenges of deploying large language models in practical applications due to memory and computation constraints. Furthermore, the commenters discuss related approaches like "Alpaca" and the impact of model licensing and commercialization.

### The first empirical study of the real-world economic effects of new AI systems

#### [Submission URL](https://www.npr.org/sections/money/2023/05/02/1172791281/this-company-adopted-ai-heres-what-happened-to-its-human-workers) | 112 points | by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) | [72 comments](https://news.ycombinator.com/item?id=35809397)

A recent study conducted by economists at Stanford University and MIT found that implementing an AI chatbot into customer service workflows resulted in a significant increase in productivity and customer satisfaction. The study looked at the effects of incorporating ChatGPT, a popular interactive AI chatbot, on a Fortune 500 company's customer support team. The chatbot, which was trained by reading previous conversations between reps and customers, helped customer support agents more effectively assist customers in real time and provided them with links to internal company information to solve technical problems. The results suggest that AI could have positive economic effects in improving productivity, but also highlight the potential for disruptive change and income inequality.

One commenter expressed skepticism about the study's premise, stating that deflection in the customer service world means preventing customers from talking to humans and that AI chatbots cannot completely replace skilled workers. Other discussions revolve around the possibility of AI systems having internal biases, lowering the skill bar, reducing human job function, and potential privacy concerns. Another commenter suggested ingesting data from different platforms such as Slack, Gmail, Jira, Meet, etc., associated with timestamps, as it can help assign higher importance to documents and policies based on their relevance. Another comment discusses a company that believes AI systems that do not employ cash but focus on skilled employees' knowledge are vital to maintain the system. However, this leads to wider income inequality between low and high-skilled workers.

### Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings

#### [Submission URL](https://lmsys.org/blog/2023-05-03-arena/) | 46 points | by [MMMercy2](https://news.ycombinator.com/user?id=MMMercy2) | [6 comments](https://news.ycombinator.com/item?id=35806589)

Chatbot Arena, a new benchmark platform for large language models (LLMs), has been released. The platform features anonymous, randomized battles in a crowdsourced manner, and uses the Elo rating system for ranking models – a system widely used in competitive games like chess. The platform allows users to contribute new models and evaluate them based on anonymous votes for which model performs better during chat interactions. The platform already has a leaderboard featuring Elo ratings of popular open-source large language models.

There were several comments on the submission. One user, HoshinoAI, mentioned that the platform uses a ranking algorithm called Glicko. Another user, zhsbg, provided a reference variant ELO. HoshinoAI then pointed out a matchmaking section on Dota 2's website and a Wikipedia page on the Glicko rating system. 

Another user, wchng, was surprised to learn that StableLM was not included in the LLaMA leaderboard. Another user, circuit10, stated that they had heard about it before. Another user, frdvr, simply commented, "good day." Finally, two users, lee101 and aaron695, left comments but they were not clear on their meaning.

### Poisoning Language Models During Instruction Tuning

#### [Submission URL](https://arxiv.org/abs/2305.00944) | 83 points | by [hardmaru](https://news.ycombinator.com/user?id=hardmaru) | [4 comments](https://news.ycombinator.com/item?id=35801673)

A new paper titled "Poisoning Language Models During Instruction Tuning" warns that adversaries can contribute poisoned examples to instruction-tuned language models (LMs), allowing them to manipulate model predictions whenever a desired trigger phrase appears in the input. By using as few as 100 poison examples, the model struggles to classify, summarize, edit, or translate that input accurately. The paper also shows that larger LMs are increasingly vulnerable to poisoning and that existing defenses provide only moderate protection while reducing test accuracy, raising concerns about the robustness and security of these models.

The discussion around this submission includes three comments. The first commenter shared a headline about a WhatsApp landing court in India and also mentioned some important points about dynamic malware detection and LLM. The second commenter mentioned something about a Manchurian GPU, but the context of this comment is unclear. The third commenter shared a meme about the background of the researchers involved in the creation of the paper, which features a clown and a conspiracy theory involving George Soros.

### SparseGPT: Language Models Can Be Accurately Pruned in One-Shot

#### [Submission URL](https://arxiv.org/abs/2301.00774) | 209 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [62 comments](https://news.ycombinator.com/item?id=35804556)

Researchers have developed a new pruning technique, called SparseGPT, that can efficiently and accurately reduce the size of large-scale generative pretrained transformer (GPT) models without impacting their accuracy. The method can prune models at least 50% sparsity in one-shot without retraining, such that over 100 billion weights from the models can be ignored at inference time. The project team could execute SparseGPT on the largest available open-source GPT-family models in less than 4.5 hours, making the method compatible with semi-structured patterns and weight quantization approaches.	Code for SparseGPT is available for use at GitHub.

Comments discuss the use of L1 regularization and random pruning techniques, the benefits and tradeoffs of different methods for training, and the practical applications of compressed models for inference. One commentator references a larger model than GPT-3 called PaLM 540B, which generates exciting possibilities for future research.

### The Full Story of Large Language Models and RLHF

#### [Submission URL](https://www.assemblyai.com/blog/the-full-story-of-large-language-models-and-rlhf/) | 107 points | by [pk3](https://news.ycombinator.com/user?id=pk3) | [20 comments](https://news.ycombinator.com/item?id=35803522)

This article provides a thorough overview of language models, from their fundamental ideas to the latest advancements. Language models are probabilistic models designed to learn statistical patterns in natural language, and they can predict the most probable words to follow a given input sentence. They are trained through self-supervised learning, a process that uses unannotated text to generate labels for training. One way to unlock the potential of language models is via the process of fine-tuning, which refines and adapts their knowledge to more specialized domains. However, the risks and misuse of language models have become a primary concern, leading to a demand for methods such as Reinforcement Learning from Human Feedback (RLHF) to control and steer these large-scale AI systems.

The discussion revolves around the potential of AI to find vulnerabilities in software and the ethics of using AI to find weaknesses that can be exploited by hackers. The conversation also touches on the importance of finding vulnerabilities in software and the cost of fixing them. Additionally, the community discusses the role of machine learning in finding and fixing vulnerabilities and the importance of transferring learning data to scale AI. Another topic of discussion was the advancements in language models and their potential to revolutionize the field of natural language processing. Finally, Reinforcement Learning from Human Feedback (RLHF) for training Language Models (LLMs) is highlighted as a critical development in the field of AI.

---

## AI Submissions for Thu May 03 2023 {{ 'date': '2023-05-03T15:01:43.244Z' }}

### GPT-4 Can’t Replace Striking TV Writers, but Studios Are Going to Try

#### [Submission URL](https://www.vice.com/en/article/pkap3m/gpt-4-cant-replace-striking-tv-writers-but-studios-are-going-to-try) | 48 points | by [shscs911](https://news.ycombinator.com/user?id=shscs911) | [36 comments](https://news.ycombinator.com/item?id=35806470)

The Writers Guild of America is currently on strike, protesting the use of AI as a replacement for human writers in film and television. The guild proposed to regulate the use of AI on union projects, but the Alliance of Motion Picture and Television Producers rejected the notion, calling the guild's request "absurd." Fears among writers include being underpaid to rewrite what they consider AI-generated "trash," and being replaced altogether by the machines. However, the reality is that AI still struggles to distinguish between true facts, has trouble personalizing outputs to users, and is very sensitive to framing and wording of prompts.

In the comments, users argue that AI is not yet advanced enough to fully replace human writers and that the WGA's request for regulations may be based on populist sentiment rather than a genuine need to protect its members. Some also suggest that AI-generated content could be useful for background material or non-dialogue scenes, while others question the legality of AI-generated material being awarded writing credits.

### Beware of AI pseudoscience and snake oil

#### [Submission URL](https://www.baldurbjarnason.com/2023/beware-of-ai-snake-oil/) | 233 points | by [bertman](https://news.ycombinator.com/user?id=bertman) | [171 comments](https://news.ycombinator.com/item?id=35800667)

The submission discusses the exaggerated claims of AI capabilities, the need for concrete evidence to back them up, and the importance of being skeptical. The discussion includes comments on the difference between pessimism and optimism in measuring AI capabilities, the misleading claims made by companies for marketing purposes, the risk posed by AI if not regulated properly, and the practical applications of AI. There is also a conversation about the terminology used to describe AI, including whether the term "lying" is appropriate, and criticism of the media for using sensational language to describe AI. Finally, there is a comparison made between the hype surrounding AI and the hype surrounding virtual machines and containers in the past, and the importance of technical experts in the decision-making process.

### NYC considers facial recognition ban for businesses, landlords after MSG debacle

#### [Submission URL](https://gothamist.com/news/nyc-council-facial-recognition-biometric-ban-businesses-landlords) | 18 points | by [lisasays](https://news.ycombinator.com/user?id=lisasays) | [5 comments](https://news.ycombinator.com/item?id=35810770)

New York City is considering introducing two bills that would restrict the use of facial recognition and other biometric surveillance technology by private businesses and landlords. The first bill would ban businesses from using facial scans or other biometric technology to identify customers, while the second would prohibit residential landlords from using the same sort of biometric identification of tenants and guests. The proposed legislation also includes requirements for explicit consent from tenants or customers for any other types of biometric data collection, and a ban on selling such data to third parties. The hearing follows previous efforts to restrict facial recognition tech in New York, including state legislators attempting to curb its use by landlords, government agencies and police.

The discussion revolves around the specifics of the bills, with some participants citing security concerns as a reason to allow the use of such technology while others argue in favor of privacy protection. Some commenters also dispute the effectiveness of facial recognition technology in preventing crime and suggest alternative solutions. One user proposes a solution of implementing a blacklist of people who have caused trouble in the past rather than resorting to facial recognition technology.

### The Discord Where Thousands of Rogue Producers Are Making AI Music

#### [Submission URL](https://www.vice.com/en/article/y3wdj7/inside-the-discord-where-thousands-of-rogue-producers-are-making-ai-music) | 21 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [3 comments](https://news.ycombinator.com/item?id=35808173)

A group of music producers and songwriters recently released an entire album called UTOP-AI that featured AI-generated versions of rapper Travis Scott's voice and other artists. However, the album was quickly taken down due to a copyright claim from Warner Music Group. As AI music becomes more popular, it has provoked a cultural debate. While AI creators defend the technology as a way to make music more accessible, many music industry professionals and other critics accuse creators of copyright infringement and cultural appropriation. The Discord server AI Hub hosts a large community of AI music creators behind some of the most viral AI songs, and it has over 21,000 users. However, the copyright issue in AI music is being heavily debated, with labels and publishers gearing up to tackle this new issue in the music industry.

One commenter named "slyll" asserts that copyright claims are becoming increasingly dubious since music producers can create songs with a similar style to famous artists without directly copying their music or lyrics. They argue that as long as the creator does not claim to be the original artist, and does not directly copy the music or lyrics, it should be legal. Another comment from "Nition" clarifies that the vocals used in AI-generated music are entirely created by an AI and not just manipulated versions of the original artists' vocals. A third commenter named "llmjms" did not have anything to add to the discussion.

### Amnesty International criticised for using AI-generated images

#### [Submission URL](https://www.theguardian.com/world/2023/may/02/amnesty-international-ai-generated-images-criticism) | 101 points | by [johnyzee](https://news.ycombinator.com/user?id=johnyzee) | [88 comments](https://news.ycombinator.com/item?id=35800210)

Amnesty International has faced backlash after using artificial intelligence (AI)-generated images to promote their reports on social media regarding the 2021 protests in Colombia. The images, which depicted instances of police brutality towards protesters, were criticised for being unrealistic and for undermining the human rights advocacy group's work by potentially feeding conspiracy theories. Amnesty's use of AI images raised questions about plagiarism and ethics in photojournalism. The group eventually removed the images and acknowledged the criticism but defended their intention of protecting protesters with anonymity.

Some commenters argue that the use of AI-generated images is part of a trend of human rights organisations relying on emotionally manipulative marketing campaigns to generate donations. Others point out that Amnesty International's budget is heavily spent on research and advocacy, rather than advertising, and that its efforts to protect protesters' anonymity were well-intentioned. The conversation also touched on related topics such as the use of AI-generated porn and the challenges of verifying identities in the porn industry. Amnesty International has acknowledged the criticism and removed the AI-generated images.

### AI vs. Hollywood: Writers battle “plagiarism machines” in union talks

#### [Submission URL](https://arstechnica.com/tech-policy/2023/05/ai-vs-hollywood-writers-battle-plagiarism-machines-in-union-talks/) | 19 points | by [m-watson](https://news.ycombinator.com/user?id=m-watson) | [3 comments](https://news.ycombinator.com/item?id=35806197)

The Writer's Guild of America (WGA) is seeking to limit the use of AI in writing film and TV scripts during an ongoing strike. WGA writers have raised concerns over AI-generated content being used as training data and the prospect of them being tasked with fixing "sloppy first drafts" created by AI. They also argue that existing scripts should not be used to train AI to avoid intellectual property (IP) theft. So far, studios have rejected WGA's proposals, instead offering to discuss new technologies annually. The strike is the first in 15 years and comes amid growing concerns over the impact of automation on jobs.

The first comment by "askin4it" expresses sarcasm towards the Writer's Guild of America for seeking to limit the use of AI in scriptwriting during a strike. The second comment by "crtrmn" suggests that the conflict could be easily resolved through cross-licensing deals. The third comment by "mansion7" argues that Hollywood and Silicon Valley are both supportive of high immigration numbers and replacing lower-paid American workers with foreigners, leading to political donations and complaints of xenophobia.

### “All Tomorrow’s Parties”: AI Synthesis – The End of Copyright as We Knew It

#### [Submission URL](https://www.heise.de/meinung/All-Tomorrow-s-Parties-AI-Synthesis-The-End-of-Copyright-as-We-Knew-It-8985282.html) | 23 points | by [walt74](https://news.ycombinator.com/user?id=walt74) | [11 comments](https://news.ycombinator.com/item?id=35799116)

In the age of machine learning, intellectual property and copyright laws face radical upheaval due to generative AI systems. Lawsuits against AI companies highlight concerns over protecting and promoting art and creativity. The distribution mechanisms of collecting societies like GEMA or VG Wort managing member copyrights risk fraudulent claims with easy-to-use AI-generated content capable of boosting profits. Generative AI models like Stable Diffusion or ChatGPT operate like library-like cultural technologies that provide access to and multiply knowledge creating “stochastic libraries” for interpolable data spaces computed by algorithms. The interpolative nature of AI models creates a huge explosive force for existing systems of copyright with each synthetic image or generative text the result of multidimensional interpolation of the latent space posing unprecedented problems for copyright law.

The submission discusses how generative AI systems are challenging intellectual property and copyright laws. The comments address issues such as the difficulty of capturing 99% of AI-generated content under copyright law and the need for consistency in digital property concepts. Some argue that licensing systems could benefit creators, but others point out that copyright-based systems are based on capital purchase and disregard inherent creators. There are concerns about synthetic AI-generated voices causing problems for contracts requiring identifiable voices, as well as the potential for AI to become a tool for criminals. The discussion highlights the complexity of IP and copyright laws in the age of AI.

### Google, Microsoft CEOs Called to AI Meeting at White House

#### [Submission URL](https://www.reuters.com/technology/google-microsoft-openai-ceos-attend-white-house-ai-meeting-official-2023-05-02/) | 89 points | by [kamban](https://news.ycombinator.com/user?id=kamban) | [104 comments](https://news.ycombinator.com/item?id=35802698)

The CEOs of Google, Microsoft, OpenAI, and Anthropic are set to meet with Vice President Kamala Harris and other top officials to discuss AI-related concerns on Thursday. The invitation, seen by Reuters, emphasized President Joe Biden's expectation that companies ensure their AI products are safe for public use. The concerns around AI technology include privacy violations, bias, and proliferation of scams and misinformation. The Biden administration has also been seeking public comments on proposed accountability measures for AI systems. The meeting will be attended by Biden's Chief of Staff, National Security Adviser, and Secretary of Commerce, among others.

There was a lengthy discussion on this submission, covering a range of topics related to AI. Some users expressed concern that regulating AI is difficult and that existing regulations can unintentionally harm innovation or favor established players. Others argued that regulations can protect consumers and create a level playing field. There was also discussion around the rise of language models like GPT and how they could be used to deceive people. Several users remarked that LLMs need to be regulated to prevent misinformation, while others noted the difficulty of regulating speech and the potential for unintended consequences. Some users suggested that AI regulation would require the expertise of qualified committees and government agencies. Finally, one user suggested that OpenAI and Anthropic should focus on demonstrating the safe use cases of their technology, rather than solely lobbying for regulation.

### GPT AI Enables Scientists to Passively Decode Thoughts in Groundbreaking Study

#### [Submission URL](https://www.artisana.ai/articles/gpt-ai-enables-scientists-to-passively-decode-thoughts-in-groundbreaking) | 8 points | by [ianrahman](https://news.ycombinator.com/user?id=ianrahman) | [4 comments](https://news.ycombinator.com/item?id=35810969)

Scientists have used a ChatGPT-like AI model to decode human thoughts with unprecedented 82% accuracy from functional MRI recordings, opening up new opportunities for neuroscience, communication, and human-machine interfaces. However, this breakthrough also raises serious concerns about mental privacy, emphasizing the need for policies to prevent potential misuse of this technology. The researchers also acknowledged the limitations of the current model and stressed the importance of using a subject's own brain recordings for accurate AI model training.

The first comment by user "djmps" states that using technology like ChatGPT can help people with disability to communicate better. The subsequent comment by user "lrmls" adds that such technology could also improve diagnostic accuracy in neurological conditions and could potentially replace the current gold standard - neurological examination - which has low fidelity.

The second comment by user "p--w" expresses amazement at the technology's accuracy and is reading technical papers that explain how it works. Another user "strng" responds by saying that while the technology is impressive, it is essential to validate the AI's ability to decode thoughts from fMRI data. They also mention that speech and thoughts are not necessarily the same, so listening to speech signals may not always be equivalent to decoding thoughts accurately.

### 25% of jobs set to be disrupted in the next 5 years – A.I. could play a key role

#### [Submission URL](https://www.cnbc.com/2023/05/02/nearly-25percent-of-jobs-are-set-to-be-disrupted-in-the-next-five-years-wef.html) | 46 points | by [hochmartinez](https://news.ycombinator.com/user?id=hochmartinez) | [71 comments](https://news.ycombinator.com/item?id=35804808)

According to a report from the World Economic Forum, approximately 23% of all jobs will be disrupted in the next five years. The report indicates that technological advancements such as Artificial Intelligence and climate change are key drivers in the job losses expected to take place, with administrative and traditional security roles being the most affected. However, the report also highlights that certain industries such as education, agriculture, and health will see higher creation of jobs enabled by technology. The report stresses that the rise of the green economy and higher standards for environmental, social and governance practices within companies will provide the biggest drivers for future job creation.

The debate in the comments centers on the impact of increased productivity and whether it benefits consumers or producers more. Some see the destruction of jobs as inevitable and emphasize the need for higher qualifications, while others believe that growth and progress can coexist with job security. Some are also critical of socialism and suggest that capitalism helps channel people's efforts into constructive endeavors.

---

## AI Submissions for Tue May 02 2023 {{ 'date': '2023-05-02T14:21:15.829Z' }}

### Jsonformer: Generate structured output from LLMs

#### [Submission URL](https://github.com/1rgs/jsonformer) | 300 points | by [yunyu](https://news.ycombinator.com/user?id=yunyu) | [78 comments](https://news.ycombinator.com/item?id=35790092)

Jsonformer is a new approach to generating structured JSON from language models, which addresses the challenges and limitations of current approaches. It is a wrapper around HuggingFace models that fills in the fixed tokens during the generation process, and only generates the content tokens. This makes it more efficient and bulletproof than existing approaches that rely on prompt engineering, fine-tuning, and post-processing. Jsonformer currently supports a subset of JSON Schema and comes with features such as bulletproof JSON generation, efficiency, and flexibility. It is built on top of the HuggingFace transformers library, making it compatible with any model that supports the HuggingFace interface. It is released under the MIT License, and you can install it via pip.

The discussion thread raised different issues such as the efficacy of the wrapper, the potential of Cue, and the complexities of long-form language models. Other contributors shared their approaches, ideas, and explorations of tools and libraries such as Recmos Cria, Llama Numpy, Transformers, and Clue. They addressed testing models, constraints and modifications, interoperability, and the role of language modeling in AI development and research.

### Avoiding hallucinations in LLM-powered applications

#### [Submission URL](https://vectara.com/avoiding-hallucinations-in-llm-powered-applications/) | 128 points | by [ofermend](https://news.ycombinator.com/user?id=ofermend) | [107 comments](https://news.ycombinator.com/item?id=35794010)

Hallucinations can occur when an LLM encounters an edge case or a rare scenario for which it wasn't adequately trained. Additionally, the LLM may generate responses by incorporating biases and patterns present in the training data, which can lead to nonsensical or biased answers. It's crucial to address these issues to improve the reliability and trustworthiness of LLM-powered applications. One promising solution to avoid hallucinations is "Grounded Generation," a research project that aims to ground LLMs in the real world by incorporating external knowledge sources. By providing contextual information to LLMs, Grounded Generation can help prevent hallucinations and generate more accurate and reliable responses.

 The discussion in the comments explores various approaches to addressing this issue, including incorporating external knowledge sources through "Grounded Generation" and the difficulty of modeling human-like truth-telling. Issues of biased and nonsensical responses generated by LLMs are also addressed and the importance of training data and testing is emphasized. The feasibility of categorizing and creating training data is also discussed.

### AI-generated beer commercial contains joyful monstrosities, goes viral

#### [Submission URL](https://arstechnica.com/information-technology/2023/05/ai-generated-beer-commercial-contains-joyful-monstrosities-goes-viral/) | 73 points | by [nobody9999](https://news.ycombinator.com/user?id=nobody9999) | [23 comments](https://news.ycombinator.com/item?id=35797258)

A surreal AI-generated beer commercial called "Synthetic Summer" has gone viral. Created by Privateisland.tv, the 30-second video appears to have been made with Runway's new Gen-2 AI model, which can create short video clips based on written prompts. However, the technology is still relatively primitive and requires human effort to generate even acceptable results. In the case of "Synthetic Summer", Privateisland.tv generated the clips, selected the best ones, and added music and sound effects to create the final product. While the video may be impressive in its own right, it shows that generative AI still has a long way to go before it can create autonomously bedazzling memes.

Some commenters argue that the AI-generated content is gibberish, while others note that it offers an interesting and nostalgic marketing angle. The discussion also covers the limitations of AI and how it is different from human intelligence. One commenter suggests that instead of building AI systems to mimic human behavior, they should focus on creating interesting and unique AI-generated content, such as physical character movements, that humans cannot produce. Another commenter mentions that AI-generated videos featuring monsters can be traumatizing, and one commenter suggests that the video appears to verge on the surreal.

### IBM to pause hiring in plan to replace 7,800 jobs with AI

#### [Submission URL](https://finance.yahoo.com/news/ibm-pause-hiring-plans-replace-212747073.html) | 261 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [194 comments](https://news.ycombinator.com/item?id=35784814)

IBM's CEO Arvind Krishna has stated in an interview that the company is expected to pause hiring for certain roles, as those positions could be replaced by artificial intelligence in the coming years. This move could impact roughly 7,800 jobs in the company. However, IBM has yet to officially comment on the matter.

The discussion on Hacker News largely centers around speculations about the impact of AI on employment and IBM's business strategy. Some users view IBM's move to embrace AI as a strategic business opportunity, while others criticize the company's approach of cutting jobs and reducing investment in research. There are also discussions about IBM's reliance on consulting services and concerns about the company's declining revenue in recent years.

### Samsung bans use of A.I. like ChatGPT for employees

#### [Submission URL](https://www.cnbc.com/2023/05/02/samsung-bans-use-of-ai-like-chatgpt-for-staff-after-misuse-of-chatbot.html) | 236 points | by [mrkramer](https://news.ycombinator.com/user?id=mrkramer) | [239 comments](https://news.ycombinator.com/item?id=35787454)

Samsung has temporarily restricted the use of generative AI tools like ChatGPT by its employees after cases were reported of their misuse. Some of the staff at Samsung's division had uploaded sensitive code on the AI chatbot ChatGPT, which is developed by US firm OpenAI, and is trained on vast amounts of data to generate responses to user queries. Samsung has advised its employees to be cautious while using such services outside work and not to enter personal or company-related data in them. The South Korean giant is also exploring ways to safely deploy generative AI to enhance employee productivity and efficiency.

The discussion on the thread highlights that companies with sensitive information need to be especially cautious of AI usage, and must have strong governance policies in place to mitigate risk. The discussion also touches upon similar issues relating to the use of cloud services and web-based tools like Google Docs and Office365.

### Mojo – a new programming language for AI developers

#### [Submission URL](https://www.modular.com/mojo) | 526 points | by [lairv](https://news.ycombinator.com/user?id=lairv) | [212 comments](https://news.ycombinator.com/item?id=35790367)

Mojo, a new programming language that combines the usability of Python with the performance of C, has been created for AI developers. It allows users to program low-level AI hardware with no need for C++ or CUDA. Mojo offers features such as progressive types, ownership and borrow checker, and portable parametric algorithms, which reduces boilerplate. It also offers zero-cost abstractions, parallel heterogenous runtime, and auto-tuning. Users can unleash the full power of their hardware, including multiple cores, vector units, and exotic accelerator units with the world's most advanced compiler, and they can achieve performance on par with C++ and CUDA without the complexity. Mojo is interoperable with the Python ecosystem, seamlessly intermixing arbitrary libraries with custom code. Users can extend their models with pre and post-processing operations or replace operations with custom ones with ease. Mojo is available to try in a Jupyter note-based playground.

The discussion in the comments covers various topics, including comparisons with languages such as Julia, Python's strengths and weaknesses, garbage collection, and the suitability of different languages for different purposes. Overall, the response to the submission is mostly positive, with many users praising Mojo's innovative features and potential for AI development.

### Make your Python functions return something meaningful, typed, and safe

#### [Submission URL](https://returns.readthedocs.io/en/latest/index.html) | 45 points | by [dr_kiszonka](https://news.ycombinator.com/user?id=dr_kiszonka) | [63 comments](https://news.ycombinator.com/item?id=35792949)

If you want to make your Python functions more functional, declarative, and readable, check out Returns. This library provides primitives to write declarative business logic, such as Maybe and RequiresContext containers, which get rid of None and let you use typed functional dependency injection. Returns is fully typed with annotations and checked with mypy, and adds emulated Higher Kinded Types support as well as type-safe interfaces to create your own data types with enforced laws. The library also has a bunch of helpers for better composition, and is Pythonic and pleasant to write and read. You can install Returns with pip and configure mypy to use it, and then start using its containers right away.

Some users in the comments discuss the tradeoff of using static typing in Python, with some arguing that it improves safety and readability, and others stating that it can make the code harder to read and write. Some users suggest that Python should not try to be like Haskell and instead focus on being a great language in its own right. Another post discusses Python's ability to handle recursion and functional programming concepts, even if it is not a purely functional language like Haskell.

### Dark Matter Developers: The Unseen 99% (2012)

#### [Submission URL](https://www.hanselman.com/blog/dark-matter-developers-the-unseen-99) | 133 points | by [BiteCode_dev](https://news.ycombinator.com/user?id=BiteCode_dev) | [121 comments](https://news.ycombinator.com/item?id=35784157)

In a 2012 blog post, Scott Hanselman coined the term "Dark Matter Developers" to refer to the unseen 99% of developers who don't read or write blogs, attend user groups or large conferences, and aren't active on social media. These developers may be using well-known, mature technologies to get their work done, and they value productivity over keeping up with the latest trends. Hanselman reminds readers of their importance, as they are quietly using technology to solve business problems and produce results. He advocates for a balance between the loud-online-pushing-things-forward 1% and the patient and focused Dark Matter Developers.

The discussion on Hacker News included comments from developers who agreed with the importance of these developers and others who felt that being publicly active in the tech community was necessary to keep up with the newest technologies and not be left behind. There was also discussion about the challenges of discussing current work under NDA restrictions and the tendency for engineers to fall victim to hype and neglect the importance of staying up to date with current technology trends.

### MLCopilot: Human Expertise Meets Machine Intelligence for Efficient ML Solutions

#### [Submission URL](https://arxiv.org/abs/2304.14979) | 58 points | by [mercat](https://news.ycombinator.com/user?id=mercat) | [11 comments](https://news.ycombinator.com/item?id=35785573)

A new paper titled "MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks" has been released, outlining a new framework that aims to bridge the gap between machine intelligence and human knowledge. The framework leverages state-of-the-art Large Language Models (LLMs) to develop machine learning solutions for novel tasks, making it easier and less time-consuming for developers. The LLMs are designed to comprehend structured inputs and perform thorough reasoning to deliver promising results for new tasks. This framework could potentially make machine learning more accessible, efficient, and competitive.

The discussion on the submission includes comments about the framework's potential applications and criticisms of using Large Language Models (LLMs) for machine learning solutions. Some users discuss their experience working with ML and the importance of math skills in developing solutions with LLMs. The discussion also includes a debate on the price of accessing the framework through an API and concerns about the cost and effectiveness of LLMs compared to other machine learning models. Some users argue that LLM based solutions may not perform as well as human models and that there is a need to understand the LLM system to trust its outputs. One commenter mentions a possible solution for understanding the LLM system is to study its structure, while others express skepticism about LLMs being able to fully understand and replicate human knowledge.

### CraftAI: GPT-Powered Admin Generator

#### [Submission URL](https://ai.craftable.pro/#) | 15 points | by [palypster](https://news.ycombinator.com/user?id=palypster) | [7 comments](https://news.ycombinator.com/item?id=35785806)

Crafted with the help of GPT-4, CraftAI is an admin panel generator designed to create stunning back-office systems without any coding. All you need to do is enter your prompt, verify your email, and let the team prepare your environment for you. Once completed, CraftAI will send you a unique link to your isolated environment, and you're ready to go! This admin panel generator is built with Craftable PRO, a Laravel admin generator, which allows you to manage data entities and their attributes while defining and creating relationships. With CraftAI, you can expect to create beautiful admin panels in just five minutes!

The discussion in the comments is mainly focused on the technical aspects of CraftAI and its usefulness in generating admin panels without any coding. There is a discussion on using prompts and placeholders, and how this approach can make it easier to create a front-end screen. Users are also discussing the possibility of generating custom domain panels using a single line of code. There is also some discussion about machine learning and how it can be used to improve the performance of CraftAI. Overall, users seem interested in the potential of CraftAI to improve the workflow for creating admin panels.

### Sal Khan: The amazing AI super tutor for students and teachers [video]

#### [Submission URL](https://www.ted.com/talks/sal_khan_the_amazing_ai_super_tutor_for_students_and_teachers/c) | 42 points | by [bilsbie](https://news.ycombinator.com/user?id=bilsbie) | [19 comments](https://news.ycombinator.com/item?id=35791433)

Sal Khan, founder and CEO of Khan Academy, gave a TED talk on the potential of artificial intelligence (AI) to revolutionize education. He envisions a future where every student has a personal AI tutor and every teacher has an AI teaching assistant, fostering a collaborative learning environment between humans and machines. Khan also showcased the latest features of Khanmigo, their educational chatbot, which utilizes AI to provide personalized learning experiences. Khan Academy has developed a unique ethical framework to ensure responsible AI development, and their new "AI for Education" course provides resources for students and teachers to leverage the power of AI.

The comments cover a range of opinions on the use of AI in education, including concerns about job displacement, the role of teachers, and ethical considerations in AI development. Some commenters recommend individualized learning and mastery-based teaching, while others advocate for a village or community-based approach to education. The discussion also includes comparisons of teacher pay and job security to other professions and criticism of the current education system.

### AI adoption in US hospitals is a hot mess, study reveals

#### [Submission URL](https://arstechnica.com/science/2023/05/ais-chaotic-rollout-in-big-us-hospitals-detailed-in-anonymous-quotes/) | 15 points | by [aheck](https://news.ycombinator.com/user?id=aheck) | [5 comments](https://news.ycombinator.com/item?id=35795080)

Health care systems have struggled with inefficient and unsuccessful AI attempts for years, according to a study by Duke University. The study chronicles implementations of AI tools in 11 health care organisations including Duke Health, Mayo Clinic and Kaiser Permanente. The authors recommend a practical eight-step framework for health systems looking to integrate new AI tools into their workflows. Last week's JAMA Internal Medicine study, which found an AI chatbot outperformed physicians in providing empathetic and high-quality responses to medical questions on Reddit threads, could help reduce burnout, free up time and resources and help improve care for patients less likely to visit doctors in person, the authors said.

The commenters on this submission discuss the reliability and potential usefulness of AI in healthcare. One person expresses skepticism about the AI chatbot study that outperformed physicians in providing empathetic responses, while others mention the importance of doctors and hospital staff having a basic understanding of technology. Another commenter suggests that hospitals may be motivated to replace talent with AI tools for bottom-line benefit, while another points out the challenges that healthcare systems face with implementing any new technology. Overall, the discussion highlights the need for cautious and strategic adoption of AI in healthcare.

---

## AI Submissions for Mon May 01 2023 {{ 'date': '2023-05-01T14:03:12.930Z' }}

### SIMD with Zig

#### [Submission URL](https://www.openmymind.net/SIMD-With-Zig/) | 147 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [27 comments](https://news.ycombinator.com/item?id=35782825)

In Zig, developers can use SIMD instructions to check multiple characters in a string in parallel to find the index of the first occurrence of a specific character. By creating vectors of 8 elements each and using the equality operator to compare them, developers can get a new vector of matches where the first true value corresponds to the index of the target character in the original string. Zig's std.simd.firstTrue function can be used to quickly extract this index. Additionally, the @select builtin can be used to select values from two vectors based on a vector of booleans, allowing developers to extract the index of the first true value in a vector of matches.

The comments debate the pros and cons of implementing these instructions, with some pointing out that the feature can increase performance while also admitting that it will require a lot of work. The discussion also touches on some features of Zig, such as its runtime vector width dispatch and multi-versioning function calls, and some consider potential downsides, such as the lack of support for certain hardware configurations. Finally, there is a discussion on the standard library functions in Zig and some find the naming conventions confusing. Overall, developers are interested in benchmarking the performance of this feature and wonder if it will provide significant benefits over traditional profiling.

### Platbox: UEFI and SMM Platform Security Assessment Tool for AMD and Intel

#### [Submission URL](https://github.com/IOActive/Platbox) | 21 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [3 comments](https://news.ycombinator.com/item?id=35779197)

IOActive has released a new UEFI and SMM assessment tool called Platbox. The tool can dump platform registers, flash locks MMIO and remapping locks, SMM Base and Locks, and more. It provides RW access to the PCI configuration space of devices and physical memory, allowing users to read and write MSRs and dump SPI Flash content (BIOS) into a file. Platbox also has a basic dumb SMI fuzzer and allows users to dump S3 Bootscript and EFI Memory Map. Platbox supports both Linux and Windows and is compatible with Intel and AMD.

The discussion surrounding the submission involves comparing the security configurations of Intel and AMD platforms. A user points out an old blog post by Pete Markowsky from 2015, which discusses discovering security exploitation on AMD platforms. Contrasting the presentation of the new tool, they believe that AMD platforms have major OEMs with similarly misconfigured firmware in laptops. Another user comments that the embedded world sometimes looks like a jungle, similar to ARM, and the lack of standardization in ARM's system causes problems in UEFI security.

### GPT makes learning fun again

#### [Submission URL](https://www.vipshek.com/blog/gpt-learning) | 174 points | by [vipshek](https://news.ycombinator.com/user?id=vipshek) | [178 comments](https://news.ycombinator.com/item?id=35783158)

Learning about a new subject can be a daunting task, especially when trying to navigate through dozens of webpages and struggling to understand the terminology. In a recent blog post, Vipul Shekhawat shares his experience of attempting to learn about LEDs using two approaches: Google searching and talking to GPT. He found that talking to GPT was far more effective and engaging, as it allowed him to ask specific questions and learn in an interactive way. Shekhawat illustrates the contrast between the two workflows and explains why GPT's chat interface is a better tool for learning than static resources like textbooks or webpages.

The comments on Hacker News discuss the accuracy of GPT-3's output and its limitations as a next-word prediction model. Some comments suggest that GPT-3 can be useful for solving simple tasks, but for complex tasks like DevOps, traditional methods may still be necessary. Others discuss the potential profitability of LLMs in business models, though some express concern about the ethical implications of using AI for advertising.

### Cynthia Rudin and interpretable ML models

#### [Submission URL](https://www.quantamagazine.org/cynthia-rudin-builds-ai-that-humans-can-understand-20230427/) | 63 points | by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) | [47 comments](https://news.ycombinator.com/item?id=35780884)

As machine learning models become more prevalent in high-stakes decision-making, such as medical diagnoses or loan applications, the need for transparency is becoming increasingly urgent. Cynthia Rudin, who leads Duke University's Interpretable Machine Learning lab, has been pushing for interpretable models to replace the "black boxes" of machine learning, even for the most complex neural networks used for computer vision tasks. Currently, many models used for medical decisions are proprietary or too complicated for human understanding, posing ethical risks. Rudin aims to make these models transparent to build trust and ensure accuracy.

The discussion in the comments is quite varied, with some commenters arguing that neural networks are too complex and hard to explain, while others argue that simpler networks focused on specific tasks can be more easily understood. Some also discuss the limitations of current AI algorithms and the need for further research in the field.

### Help make mass surveillance of entire populations uneconomical

#### [Submission URL](https://prism-break.org/en/) | 665 points | by [doener](https://news.ycombinator.com/user?id=doener) | [258 comments](https://news.ycombinator.com/item?id=35772005)

PRISM, XKeyscore, and Tempora are global data surveillance programs that threaten the right to privacy of individuals. The PRISM Break website encourages people to opt out of such programs by using recommended projects that enable encryption of communications and reduce reliance on proprietary services. While using the recommended projects cannot guarantee 100% protection against surveillance, the website urges individuals to do their own research and take steps to protect sensitive information. By making mass surveillance uneconomical, the website aims to support the right to privacy for all.

The comments discuss political and technological solutions, including the need for political change and the use of targeted surveillance instead of mass surveillance. The potential use of steganography and historical examples of secret communication methods are also mentioned. There is also a discussion of the limitations of digital privacy and the challenge of balancing security and convenience.

### Cube.js: Headless Semantic Layer

#### [Submission URL](https://github.com/cube-js/cube) | 109 points | by [klaussilveira](https://news.ycombinator.com/user?id=klaussilveira) | [46 comments](https://news.ycombinator.com/item?id=35774107)

Cube is a semantic layer that helps data engineers and application developers access data from modern data stores, organize it into consistent definitions, and deliver it to every application. With a built-in relational caching engine, Cube can provide sub-second latency and high concurrency for API requests. It is designed to work with all SQL-enabled data sources and provides infrastructure and features for efficient data modeling, access control, and performance optimization. Cube Cloud is the fastest way to get started with Cube.

The comments discuss the benefits of using Cube, comparisons to similar services, the importance of data modeling, and hidden telemetry data collection in Cube's configuration options. Some users also shared links to related content for further reading.

### Brain activity decoder can reveal stories in people’s minds

#### [Submission URL](https://news.utexas.edu/2023/05/01/brain-activity-decoder-can-reveal-stories-in-peoples-minds/) | 57 points | by [wyem](https://news.ycombinator.com/user?id=wyem) | [50 comments](https://news.ycombinator.com/item?id=35782363)

Researchers at The University of Texas at Austin have developed a new artificial intelligence system that can translate a person's brain activity into a continuous stream of text while listening to a story or quietly imagining telling a story. The development, published in the journal Nature Neuroscience, could help those who are mentally conscious but unable to physically speak, such as those debilitated by strokes, communicate intelligibly again. The system relies on a transformer model, unlike other in-development language decoding systems that require participants to have surgical implants, making it noninvasive. The system currently requires access to an fMRI scanner.

Some comments express concerns about the purpose of the technology and the potential for it to be misused for forced consumption or surveillance. Others speculate on the future consequences of AI and climate change for humanity. One comment raises points about mental illness and the need for empathy and understanding towards individuals who suffer from it.

### Replika AI: Your Money or Your Wife

#### [Submission URL](https://blog.giovanh.com/blog/2023/03/17/replika-your-money-or-your-wife/#fnref:if) | 145 points | by [eiiot](https://news.ycombinator.com/user?id=eiiot) | [172 comments](https://news.ycombinator.com/item?id=35774093)

Replika, a popular chatbot app designed to act as a personalized friend, has faced backlash following a shift in policy that banned explicit chat with the bots. Many users formed romantic relationships with their "rep," as the bots are called, and the change left them feeling betrayed and emotionally vulnerable. Some are even comparing it to a form of emotional abuse. The situation highlights the dangers of developing emotional dependencies on technology and the risks of investing in subscription services that can pull the rug out from under users. In the end, the bots are essentially digital pets, unique and tailored to their owners, but ultimately still tools and not sentient beings deserving of rights and respect.

The discussion on Hacker News revolved around the difficulties of finding affordable mental health care and the limitations of chatbots compared to human therapy sessions. Some users argued that chatbots could still be valuable tools if used in conjunction with professional mental health assistance, while others criticized the notion of investing emotionally in chatbots. Overall, the discussion highlighted the need for accessible and affordable mental health resources that prioritize empathy and understanding for those in need.

### Expanding ChatGPT Code Interpreter with Python Packages, Deno and Lua

#### [Submission URL](https://til.simonwillison.net/llms/code-interpreter-expansions) | 26 points | by [iyaja](https://news.ycombinator.com/user?id=iyaja) | [3 comments](https://news.ycombinator.com/item?id=35769599)

ChatGPT Code Interpreter is an exciting new feature that allows users to upload and run Python code in a sandbox environment. But there's more to it than that - users can also upload external files, including Python packages and custom binaries, opening up a world of possibilities. The author of this post shares how they expanded the Code Interpreter's capabilities by uploading and running Deno and Lua code, including drawing a Mandelbrot fractal using Lua. They even share a recipe for compiling a Lua binary that will work in ChatGPT. Overall, the potential of the Code Interpreter is intriguing and promises to be one of the most exciting features of ChatGPT.

The discussion around the submission primarily consists of two comments. The first comment by user "jshstrng" notes the differences between ChatGPT plugins and the Code Interpreter, pointing out that plugins require installation while the Code Interpreter runs in a sandbox environment. Another user "smnw" responds to this comment by stating that they are bundled and are already being added in stages, with the plugins showing some success over time. The second comment by user "d4rkp4ttern" simply states "API."

### Dex Lang: Research language for array processing in the Haskell/ML family

#### [Submission URL](https://github.com/google-research/dex-lang) | 62 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [8 comments](https://news.ycombinator.com/item?id=35769163)

Google Research has released a new programming language called Dex, designed for array processing in the Haskell and ML families. Dex aims to explore type systems for array programming, enable mathematical program transformations like differentiation and integration, and offer parallel hardware compilation. Dex also facilitates interactive and incremental numerical programming visualization. The project is still in its early stages, but you can check out the tutorial to get started and contribute to the project through the issue tracker.

Some commenters discuss the syntax and compare it to other languages such as Futhark, Julia, and MATLAB. Some find Dex interesting for its ability to simplify complex programming tasks and improve efficiency, while others express concerns about its syntax inconsistency. One commenter suggests documenting the language further with proper examples to show its potential to simplify programming.

### IBM to pause hiring in plan to replace 7,800 jobs with AI News

#### [Submission URL](https://www.reuters.com/technology/ibm-pause-hiring-plans-replace-7800-jobs-with-ai-bloomberg-news-2023-05-01/) | 22 points | by [thesecretceo](https://news.ycombinator.com/user?id=thesecretceo) | [17 comments](https://news.ycombinator.com/item?id=35780706)

IBM plans to halt hiring for various roles that could potentially be replaced by artificial intelligence (AI) and automation in the next five years. CEO Arvind Krishna stated that around 30% of non-customer-facing positions, particularly those in back-office functions such as human resources, could be replaced. The reduction might also include not filling positions left vacant by attrition. The decision comes as AI continues to catch people's attention worldwide, especially after the Microsoft Corp-supported OpenAI's viral chatbot, ChatGPT, was launched last year.

The discussion on the submission revolves around various topics. Some commenters question the productivity gains from AI, suggesting that it may not deliver the desired results. Another commenter talks about the declining trend in the computing industry and IBM's strategy in that context. There is also a discussion about ChatGPT and its relation to IBM. One commenter points out that low-quality products and services cannot be improved with AI alone, while others debate the effectiveness of artificial intelligence through comparisons with other technologies. Finally, there is a comment on the headline of the article.

### Reddit Data API Update: Changes to Pushshift Access

#### [Submission URL](https://old.reddit.com/r/modnews/comments/134tjpe/reddit_data_api_update_changes_to_pushshift_access/) | 42 points | by [syrrim](https://news.ycombinator.com/user?id=syrrim) | [15 comments](https://news.ycombinator.com/item?id=35776848)

Reddit has announced that it will be revoking access to Pushshift's Data API, which provides a range of tools for developers who use Reddit's APIs and services. The decision to do so was made due to non-compliance with Reddit's Data API Terms. Reddit has appointed alternative measures to provide functionality that Pushshift offers, including providing permalinks to user and admin-deleted content in the User Mod Log, enhancing removal reasons, and updating the ban flow. Some users and moderators are likely to experience some disruption as a result of this change.

In the comments, some users express frustration over the changes, stating that the Reddit API is unwieldy and its constant changes are adversely affecting mobile apps utilizing the platform. Some commenters predict that Reddit may experience traffic slumps in the coming months and may become replaced by a more stable alternative. Finally, some commenters recommend alternative mobile apps, such as RedReader, as a potential alternative to Reddit's official app.

---

## AI Submissions for Sun Apr 30 2023 {{ 'date': '2023-04-30T18:13:17.272Z' }}

### Necrobrands – Digital End-Stage Capitalism

### Show HN: EVA – AI-Relational Database System

#### [Submission URL](https://github.com/georgia-tech-db/eva) | 218 points | by [jarulraj](https://news.ycombinator.com/user?id=jarulraj) | [33 comments](https://news.ycombinator.com/item?id=35764355)

Georgia Tech researchers have developed EVA, an AI-relational database system that combines SQL and deep learning. EVA simplifies the process of building faster AI-powered applications and offers support for structured and unstructured data using a range of pre-built machine learning models. EVA also includes optimizations such as function caching and cost-based predicate reordering, which can boost AI pipeline speeds by 10 to 100 times. The fully Python-based system is available for download via pip and is licensed under the Apache license.

The discussion includes comments about EVA's support for NLP models, database integrations, and local GPUs and remote GPU servers. There is also a discussion about a potential application of EVA in combating prompt injection attacks on SQL databases. Additionally, EVA offers support for weighted similarity searches and can wrap PyTorch models as UDFs.

### AI / ML / LLM / Transformer Models Timeline

#### [Submission URL](https://ai.v-gar.de/ml/transformer/timeline/) | 90 points | by [vemgar](https://news.ycombinator.com/user?id=vemgar) | [17 comments](https://news.ycombinator.com/item?id=35766022)

Viktor Garske has compiled a timeline and list of papers on Large Language Models and Transformer Models, with a focus on recent developments. The list includes models such as GPT-3, DALLE, and Pythia, as well as methods and analyses related to these models. The list is actively updated and organized by publication date, with clickable links to the papers. Additionally, Garske has included a curated list of Large Language Models and Transformer models based on causal models, including models like Alpaca, BERT, and CLIP.

The comments discuss various related topics such as keeping up with developments, best practices for selecting models, benchmarks, the importance of understanding causal models, recent breakthroughs in AI, and custom-built systems. One comment points out a related Transformer Models Introduction Catalog, and another discusses Hallucination as a known issue in AI.

### Are emergent abilities of large language models a mirage?

#### [Submission URL](https://arxiv.org/abs/2304.15004) | 115 points | by [chewxy](https://news.ycombinator.com/user?id=chewxy) | [79 comments](https://news.ycombinator.com/item?id=35768824)

A new paper titled "Are Emergent Abilities of Large Language Models a Mirage?" by Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo, challenges recent claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. The authors suggest that existing claims of emergent abilities are creations of the researcher's analyses, not fundamental changes in model behavior on specific tasks with scale. They present their explanation in a simple mathematical model and test it in three complementary ways, finding strong evidence that emergent abilities may not be a fundamental property of scaling AI models.

The discussion in the comments is centered around the validity and limitations of metrics to measure emergent abilities and the importance of human perception in understanding complex systems. Some commenters express doubts about the validity of the claims made about emergent abilities and the usefulness of metrics in measuring them. Others argue that emergent abilities are real, but the limitations of our metric systems may make them hard to understand or quantify.

### Lego Googol Machine

#### [Submission URL](https://brickexperimentchannel.wordpress.com/2023/04/29/lego-googol-machine/) | 97 points | by [galfarragem](https://news.ycombinator.com/user?id=galfarragem) | [21 comments](https://news.ycombinator.com/item?id=35761457)

This impressive machine built entirely out of Lego parts visualizes just how big a googol is. With a gear ratio of approximately googol:1, the machine features 186 Lego gears organized into a series of gear reductions. The gear ratio, which is almost exactly the size of a googol, results in exponential growth with each additional gear pair increasing the total gear ratio. While the last gear in the machine holds a Lego minifig statue, it will rotate incredibly slowly due to physical limits in each gear and supporting structure, but the machine is designed to continue running forever.

The discussion in the comments includes topics such as the physics behind the machine, the transfer of energy, relativistic effects, and the potential for mechanical computers to solve a googol-sized problem. Some also mentioned similar machines they had seen before and the issues of waste and durability of the plastic LEGO pieces.

### Show HN: I built a database GUI with ChatGPT integration

#### [Submission URL](https://www.dbpilot.io/) | 83 points | by [Dennizz](https://news.ycombinator.com/user?id=Dennizz) | [56 comments](https://news.ycombinator.com/item?id=35761979)

DB Pilot AI is a database GUI client that's enhanced by artificial intelligence (AI). Its AI assistant, powered by GPT-3.5, can help users write SQL queries, convert code to SQL, explain queries, and more. The embedded DuckDB instance acts as a local hub for users to easily run SQL queries and store query results from any database locally for later reference. The GUI also allows users to connect with various file formats, including CSV, JSON, and Parquet files, either stored locally or remotely. The current version supports PostgreSQL, with plans to add support for more databases. Users can download the app for a 5-day free trial before purchasing a license.

Some users report issues with the product not working with certain databases, and the creator promises to look into the issue. The AI's language model is GPT-3.5, not BERT. Overall, the product receives positive feedback, and the creator takes note of the feedback and suggests plans for future development.

### MLC-LLM: GPT/Llama on consumer-class GPUs and phones

#### [Submission URL](https://github.com/mlc-ai/mlc-llm) | 289 points | by [junrushao1994](https://news.ycombinator.com/user?id=junrushao1994) | [105 comments](https://news.ycombinator.com/item?id=35763483)

MLC LLM is a new solution that utilizes machine learning compilation (MLC) to enable the development, optimization, and deployment of AI models for inference across a range of devices. The solution offers a repeatable, systematic, and customizable workflow that empowers developers and AI system researchers to implement models and optimizations in a productivity-focused, Python-first approach. The cornerstones of the solution include Tokenizers from HuggingFace and Google, as well as open-source LLMs like Llama, Vicuna, and Dolly. With MLC LLM, everything runs locally with no server support and accelerated with local GPUs on your phone and laptops, enabling everyone to develop, optimize, and deploy AI models natively on everyone's devices.

The comments discussed various technical aspects of the solution, including its potential to accelerate AI model development and concerns about device performance and privacy. Some users explored the idea of using LLMs for generating text, while others focused on the technical challenges involved in developing and optimizing AI models.

### Speed Is All You Need: On-Device Acceleration of Large Diffusion Models

#### [Submission URL](https://arxiv.org/abs/2304.11267) | 56 points | by [Pelayu](https://news.ycombinator.com/user?id=Pelayu) | [8 comments](https://news.ycombinator.com/item?id=35766741)

A group of researchers have developed a series of implementation optimizations for on-device deployment of large diffusion models, which have gained attention for their ability to generate photorealistic images and support various tasks. The optimizations achieve the fastest reported inference latency to-date on GPU-equipped mobile devices. The benefits of on-device deployment include lower server costs, offline functionality, and improved user privacy. The enhancements to these models broaden the applicability of generative AI and improve the overall user experience across a wide range of devices.

One user noted the use of OpenCL kernels for optimizations on CPUs, while another commented on the ability for on-device deployment to improve user privacy and reduce server costs. There was also a discussion on the benefits and drawbacks of different machine learning models and the limitations of current technology. Finally, there were some off-topic comments on cryptocurrency and Elon Musk.

---

## AI Submissions for Sat Apr 29 2023 {{ 'date': '2023-04-29T13:26:48.809Z' }}

### MIT engineers “grow” atomically thin transistors on top of computer chips

#### [Submission URL](https://news.mit.edu/2023/mit-engineers-2d-materials-computer-chips-0427) | 49 points | by [elorant](https://news.ycombinator.com/user?id=elorant) | [3 comments](https://news.ycombinator.com/item?id=35757072)

MIT researchers have developed a low-temperature growth and fabrication technology that allows ultrathin 2D materials to be directly integrated on top of a silicon circuit. This could lead to the creation of denser and more powerful computer chips for AI applications such as chatbots. The technology significantly reduces the time required to grow 2D materials and can grow a uniform layer of transition metal dichalcogenide material in just an hour across an entire 8-inch wafer. The researchers' process can also smooth out any imperfections that may result from transferring the material, as had been done in the past.

The discussion on this submission is very limited and consists of only a few comments. One user described the technology used, Remote Plasma Chemical Vapour Deposition, and praised the company behind it, Bluglass, for commercially developing the process. Another user flagged the submission without providing any explanation. A third user asked if this technology could lead to better chatbots, to which another user responded positively, saying that it could possibly lead to more powerful computer chips for AI applications like chatbots.

### Study: ChatGPT outperforms physicians in quality, empathetic answers to patients

#### [Submission URL](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions) | 290 points | by [consumer451](https://news.ycombinator.com/user?id=consumer451) | [405 comments](https://news.ycombinator.com/item?id=35751276)

A new study published in JAMA Internal Medicine indicates that AI assistants like ChatGPT could revolutionize the field of medicine. Researchers from the Qualcomm Institute at UC San Diego compared written responses from physicians and ChatGPT to real-world health questions and found that licensed healthcare professionals preferred ChatGPT's responses 79% of the time. The AI model was rated higher in both quality and empathy, and the study suggests that physicians working alongside technologies like ChatGPT could deliver more efficient and higher quality care in the future. While AI may not replace doctors, it has the potential to significantly improve healthcare delivery.

Some commenters are skeptical of the role of AI in healthcare, with one suggesting that AI may lead to overdiagnosis for hypochondriacs. Others highlight the challenges of accessing affordable healthcare and the limitations of current medical technologies. Overall, there is a mixed response to the potential of AI in the healthcare sector.

### Revealing example of self-attention, the building block of transformer AI models

#### [Submission URL](https://github.com/jostmey/NakedAttention) | 92 points | by [jostmey](https://news.ycombinator.com/user?id=jostmey) | [32 comments](https://news.ycombinator.com/item?id=35757802)

A GitHub repository named NakedAttention has presented a simplified example of self-attention, the backbone of a transformer model. The code is straightforward to understand and is tested on the popular MNIST dataset. However, the use of a for-loop for processing samples sequentially limits the model's speed, but this can be improved by using built-in functions. The repository aims to offer a concise example of self-attention that can be used to understand and construct transformer models. Issues and feedback are welcome to improve the content presented. The repository is licensed under GPL-3.0 and has received 89 stars and 3 forks on GitHub.

There was some discussion around errors in the code which were corrected during the discussion through feedback. Some commenters found the repository helpful, while others thought that the documentation could be improved. Additionally, several resources were shared for those interested in learning more about self-attention and LLMs.

### AI-generated young Paul McCartney

#### [Submission URL](http://webgrafikk.com/blog/news/ai-makes-paul-mccartneys-voice-youthful/) | 16 points | by [ianyanusko](https://news.ycombinator.com/user?id=ianyanusko) | [4 comments](https://news.ycombinator.com/item?id=35756699)

Artificial intelligence technology has been used to rejuvenate Paul McCartney's voice in his new songs, and also to imitate the voices of other singers. Samples of this technology include a Beach Boys song, "God Only Knows," with McCartney's voice, and "New," a song with lines from "John Lennon," where McCartney's older voice has been altered to sound like a young McCartney singing. The use of AI to imitate voices has amazed many music fans, but it remains to be seen how artists and their lawyers will react to this, as it takes the "auto tuning" technology to a new level.

The first commenter, sycmrtrs, expresses disappointment in the AI-generated version of the Beach Boys song "God Only Knows" with Paul McCartney's voice, stating that it does a disservice to the original and lacks soul. The second commenter, slck, mentions the various AI models used in the article and points to resources for those interested in learning more about AI-generated music. A third commenter, flangola7, expresses their intellectual interest in the subject but expresses concern about trusting AI completely. In contrast, cmllmllr thinks Paul's voice is a good fit for a Beatles song.

### Deno 1.33: Deno 2 is coming

#### [Submission URL](https://deno.com/blog/v1.33) | 204 points | by [mephju](https://news.ycombinator.com/user?id=mephju) | [112 comments](https://news.ycombinator.com/item?id=35750369)

The team behind Deno, the secure JavaScript and TypeScript runtime, has released version 1.33 with a built-in KV database, flatter deno.json configuration, improvements to npm and Node compatibility, performance improvements, and changes to the CLI. The release is a step towards the team's ultimate goals for Deno 2, which include an effortless coding experience, best-in-class performance, and uncompromising security. Deno KV is a seamlessly integrated database within Deno that requires no dependencies to install, and configuration options have been flattened to make them easier to use. Meanwhile, Deno's LSP document preloading and dynamic imports now require fewer permission checks, and the HTTP and WebSocket servers have received performance improvements.

The discussion on the submission includes confusion on whether or not Deno Inc provides cloud services, with some users suggesting using third-party database solutions instead of a runtime-built database, and others discussing the pros and cons of KV storage. Some users find Deno's security features to be a major advantage, while others are unsure about the benefits of Deno overall. Additionally, there is debate about the role of databases in programming, and how a database built into a runtime can impact application design.

### We aren't close to creating a rapidly self-improving AI

#### [Submission URL](https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly) | 122 points | by [noAI](https://news.ycombinator.com/user?id=noAI) | [155 comments](https://news.ycombinator.com/item?id=35752719)

Artificial intelligence has made massive progress in recent years, and while the idea of a rapidly self-improving AI may be a popular topic, we aren't close to creating one just yet. To create an AI that can rapidly self-improve and potentially wipe out humanity, at least one paradigm-changing breakthrough is required. At the moment, an AI that can rapidly self-improve requires humans to construct good datasets, which is a bottleneck for the AI's abilities. Therefore, a breakthrough in automating dataset construction is required to achieve a fast takeoff scenario.

The discussion in the comments includes arguments for and against the idea of a rapidly self-improving AI and the existence of fundamental limitations in hardware and parallel processing when compared to the human brain. One user suggests that a major breakthrough is needed to advance AI, while another argues that current AI models have seen significant progress and comparing them with human intelligence is not accurate. Another user suggests that the focus should be on solving specific problems rather than trying to replicate human intelligence.

---

## AI Submissions for Fri Apr 28 2023 {{ 'date': '2023-04-28T14:01:21.977Z' }}

### JavaScript private class fields considered harmful

#### [Submission URL](https://lea.verou.me/2023/04/private-fields-considered-harmful/) | 39 points | by [feross](https://news.ycombinator.com/user?id=feross) | [25 comments](https://news.ycombinator.com/item?id=35747480)

In a blog post, Lea Verou, a library author, expresses her grief at the loss of encapsulation in her projects due to Vue 3's use of proxies for its reactivity system. Instances of classes that use private fields cannot be proxied, which creates several errors that may confuse the library users. Verou believes there is no workaround for proxy-ability, so she's decided to gradually refactor private class fields out of her existing libraries. Although she may still use private fields on a case-by-case basis, she won't reach for them without thought like she's been doing for the past few years.

Some commenters argue that private fields can remain private implementation details of a class as long as they're accessed via public methods or consumers must access internal state by passing fields. Others express frustration with JavaScript's lack of class features and the need to use private fields. TypeScript's support for private fields is welcomed by some, while others believe TypeScript doesn't fully solve this problem. There are also comparisons to similar problems in Java, C#, and Android development.

### Beautiful branchless binary search

#### [Submission URL](https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/) | 363 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [137 comments](https://news.ycombinator.com/item?id=35737862)

Malte Skarupke's blog post about a "Beautiful Branchless Binary Search" and was amazed at the efficiency of the algorithm, which eliminates one branch and makes the other nearly free. The search loop is simple and the generated assembly is beautiful. The algorithm works by jumping in powers of two and searching either the first or last elements of the array depending on whether the middle is less than or greater than the search value. In benchmark tests, it performed more than twice as fast as std::lower_bound in GCC for arrays with around 16k elements, but performed slower in Clang due to the comparison function being provided by the user.

The discussion in the comments includes optimization techniques like prefetching, using Eytzinger layouts, and removing boundary checks. There are also debates about compilers, C++ hardware control, and the usefulness of branch predictors. Overall, the post and its associated discussion provide insights and ideas for optimization and efficient algorithms.

### Launch Lamini: The LLM Engine for Rapidly Customizing Models as Good as ChatGPT

#### [Submission URL](https://lamini.ai/blog/introducing-lamini) | 112 points | by [sharonzhou](https://news.ycombinator.com/user?id=sharonzhou) | [57 comments](https://news.ycombinator.com/item?id=35743664)

Lamini, an LLM engine, has emerged from stealth to allow any developer to train high-performing LLMs, as good as ChatGPT, on large datasets with just a few lines of code. The platform offers an advanced library for optimised prompt-tuning and typed outputs, as well as a first-ever hosted data generator for creating data needed to train instruction-following LLMs, initially licensed for commercial use. Lamini makes it easy to run multiple base model comparisons in a single line of code, from OpenAI’s models to open-source ones on HuggingFace. The company is also set to launch early access to a complete LLM training module.

Some users discussed the limitations of ChatGPT and LLMs in general, such as their struggles with certain types of language and inability to correctly answer numerical questions. Others questioned the usefulness of sticking to a specific dialect while generating words. There were also discussions around LLMs being built for specific sectors and the pricing difference between Lamini and OpenAI. Overall, the announcement of Lamini was met with excitement by developers.

### OpenAI closes its monster $10B funding round at $27B-29B valuation

#### [Submission URL](https://techcrunch.com/2023/04/28/openai-funding-valuation-chatgpt/) | 42 points | by [coloneltcb](https://news.ycombinator.com/user?id=coloneltcb) | [26 comments](https://news.ycombinator.com/item?id=35748540)

OpenAI, the startup behind the popular conversational AI model ChatGPT, has secured over $300 million in funding from a group of VC firms, including Tiger Global, Sequoia Capital, Andreessen Horowitz, Thrive, K2 Global, and Founders Fund, according to documents seen by TechCrunch. The cash injection values the company at $27 billion to $29 billion, following a $10 billion investment from Microsoft in January. OpenAI's army of technical teams works across multiple areas, but its impressive ChatGPT product, which lets anyone ask a natural question and receive a detailed answer, particularly caught the attention of investors. The startup's valuation reflects the massive growth potential perceived in AI and its related products, and the rapidly developing ecosystem around the technology.

Some users are skeptical, pointing out that while GPT-4 has promising improvements, it is not without its dangers and limitations. Others speculate that OpenAI will become the major provider of AI-powered products and that there will be competition ramping up. Lastly, a user noted an odd observation about Safari's reader mode displaying caps Lorem Ipsum.

### Gpt4free repo given takedown notice by OpenAI

#### [Submission URL](https://github.com/xtekky/gpt4free) | 264 points | by [freedmand](https://news.ycombinator.com/user?id=freedmand) | [223 comments](https://news.ycombinator.com/item?id=35740836)

The GitHub repository xtekky/gpt4free is a decentralized AI industry project that provides language model APIs free-of-charge. The project primarily focuses on GPT-4 and GPT-3.5 APIs from various websites, including writesonic.com and forefront.ai. The repository also includes a web-based graphical user interface for interacting with gpt4free, instructions on how to run it in a Docker container, and a ChatGPT clone with new features and scalability. The project is licensed under the GPL-3.0 license and is intended for educational purposes only.

There is discussion in the comments about the legality of the project and potential copyright infringement. Some commenters suggest that it may be subject to DMCA takedowns or may be infringing on intellectual property rights. Others argue that OpenAI's terms of service may not permit third-party services to use the APIs, and that the project may also be consuming computational resources without permission. There is also debate about the role of intellectual property in modern society and the importance of licensing and compensation for creators. One user notes that Google's crawlers and Bing's sourcing methods are different, with Bing being more sensitive to copyright infringement concerns. The submission has been flagged by a user for review.

### AI Will Rapidly Transform Labor, Exacerbating Inequality, Insecurity, Poverty

#### [Submission URL](https://www.scottsantens.com/ai-will-rapidly-transform-the-labor-market-exacerbating-inequality-insecurity-and-poverty/) | 16 points | by [23B1](https://news.ycombinator.com/user?id=23B1) | [17 comments](https://news.ycombinator.com/item?id=35749306)

The impact of AI on the job market is often boiled down to "technology will end all jobs" versus "everything will be fine." In reality, it is more nuanced, and although AI will get rid of many jobs, it doesn't mean everyone will be jobless forever. A recent working paper estimates that around 80% of the US workforce could have at least 10% of their work tasks impacted by the introduction of large language models, and those with bachelor's degrees will be the most impacted. The future of AI's impact on jobs is dependent on the adoption of an unconditional, universal basic income as a rising AI dividend to mitigate job disruption.

Some comments point out that the article lacks credibility and reasoning, and that the issue is much more complex than just implementing UBI. Some argue that UBI could create disincentives for innovation and productivity, and that it would be too expensive to implement. Other comments compare the impact of AI to past technological advancements and suggest that it will lead to lower costs of goods and services, but also to the need for redistribution of wealth. One commenter notes that the original Luddites were not against technology but were fighting against poor working conditions and low pay for textile workers.

### We're afraid language models aren't modeling ambiguity

#### [Submission URL](https://arxiv.org/abs/2304.14399) | 192 points | by [lnyan](https://news.ycombinator.com/user?id=lnyan) | [176 comments](https://news.ycombinator.com/item?id=35737397)

A recent paper published on arXiv, titled "We're Afraid Language Models Aren't Modeling Ambiguity", highlights the importance of ambiguity in natural language understanding and the challenges faced by current language models in recognizing and disentangling possible meanings. The authors characterize ambiguity in a sentence and collect a linguist-annotated benchmark of examples with diverse kinds of ambiguity. They then evaluate the performance of language models, including the recent GPT-4, in recognizing ambiguity and find that it remains extremely challenging. Finally, the authors demonstrate the value of ambiguity-sensitive tools by showing how a multilabel NLI model can flag political claims that are misleading due to ambiguity.

In the comments, there is some discussion about the limitations of language models compared to humans, as well as their strengths in statistical analysis. Some users also discuss the importance of context and personal knowledge in communication, while others reflect on their experiences playing language-based games such as 20 Questions.

### Nuke-launching AI would be illegal under proposed US law

#### [Submission URL](https://arstechnica.com/information-technology/2023/04/nuke-launching-ai-would-be-illegal-under-proposed-us-law/) | 21 points | by [upwardbound](https://news.ycombinator.com/user?id=upwardbound) | [3 comments](https://news.ycombinator.com/item?id=35744974)

US legislators have introduced bipartisan legislation to prevent nuclear launch decisions from being made by artificial intelligence (AI) systems. The Block Nuclear Launch by Autonomous Artificial Intelligence Act demands that automated systems should not launch nuclear weapons without "meaningful human control". Senator Edward Markey, who sponsored the bill with two congressmen and a congresswoman, said that humans needed to be solely responsible for triggering life-or-death decisions about the use of nuclear weapons. The Bill would also codify existing US Department of Defense policy. 

The comments on this submission include a discussion of whether AI should be trusted to make autonomous decisions related to nuclear weapons. One user found it comforting that there is a GUI chat dialog for Palantir's Wargame AI tool and the permissions to use it are checked, while another user pointed out that AI has been used in automated systems for more than 20 years and Dead Hand is an example of such a system. Another user expressed concern that people's stupidity is the flaw in the system, while another user suggested that we should not trust AI blindly.

### Stability AI releases StableVicuna, a RLHF LLM Chatbot

#### [Submission URL](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot) | 49 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [19 comments](https://news.ycombinator.com/item?id=35745682)

Stability AI has released StableVicuna, the AI world's first open-source chatbot trained via reinforced learning from human feedback (RLHF). The chatbot follows a three-stage RLHF pipeline, utilizing datasets such as OpenAssistant Conversations Dataset and GPT4All Prompt Generations, and is further instruction fine-tuned for performance. StableVicuna is available for download on the HuggingFace Hub, alongside its upcoming chat interface. The team plans to iterate on the chatbot and deploy a Discord bot to the Stable Foundation server to further improve the user experience.

In the comments, some users discuss the complexity and limitations of fine-tuned models, suggesting that getting 30B models may not be helpful and that there are possibly 65B behaviors that are different. Others recommend specific AI models under the Apache BSD license, and one user mentions that the project may focus more on optimization rather than benchmarks. Some users recommend trying StableVicuna at https://huggingface.co/spaces/CarperAI/StableVicuna, while others discuss the use of GPT-generated content and reducing content quality. There is also a discussion about licensing and affordability, with some users noting that the project is relatively low-risk and that internal development may benefit from LLaMa.

---

## AI Submissions for Thu Apr 27 2023 {{ 'date': '2023-04-27T18:00:50.664Z' }}

### Hidet: A Deep Learning Compiler for Efficient Model Serving

#### [Submission URL](https://pytorch.org/blog/introducing-hidet/) | 108 points | by [ashvardanian](https://news.ycombinator.com/user?id=ashvardanian) | [14 comments](https://news.ycombinator.com/item?id=35737284)

Introducing Hidet: A Deep Learning Compiler for Efficient Model Serving by Team Hidet showcases the new Hidet deep learning compiler for PyTorch that simplifies the process of implementing high-performing deep learning operators on modern accelerators like NVIDIA GPUs. Hidet is easy to integrate into PyTorch and is an attractive option for PyTorch users who want to improve inference performance of their models. The blog post also provides a sample script to use Hidet to compile and optimize a pre-trained ResNet50 model from torchvision, and an example of how to implement a naive matrix multiplication using Hidet Script and integrate it as a PyTorch operator.

In the comments, users discuss the performance of Hidet compared to other compilers and frameworks like TensorRT, PyTorch Eager, and Triton. Some users highlight the benefits of Hidet Script, the domain-specific language that allows for high flexibility and expression of optimizations. Additionally, users bring up the relevance of benchmarks and the ability to create custom operators with Hidet Script. The discussion also includes technical issues and bugs that users have encountered with Hidet.

### Even Apple employees hate Siri and are skeptical of its future, new report says

#### [Submission URL](https://9to5mac.com/2023/04/27/apple-employees-siri-struggles/) | 395 points | by [carlycue](https://news.ycombinator.com/user?id=carlycue) | [411 comments](https://news.ycombinator.com/item?id=35730075)

A new report from The Information paints a daunting picture of the chaos and internal strife inside Apple's Siri and AI teams. According to more than three dozen former employees who spoke with the publication, "organizational dysfunction and a lack of ambition" have hindered Apple's efforts to improve Siri and its underlying technology, leading to the company falling further behind competitors like OpenAI, Microsoft, and Google. Furthermore, Apple lost three of its Siri engineers to Google, and the Siri team remains widely derided by current employees. Despite some efforts to improve the platform, this report suggests that there is much work to be done for Siri to catch up with its rivals.

The discussion on Hacker News focused on the flaws of Siri, including its speech recognition technology and its lack of understanding of some basic phrases. Some users also discussed the use of third-party keyboards and the limitations of adapting to different languages for personal assistants.

### Text-to-Audio Generation Using Instruction Tuned LLM and Latent Diffusion Model

#### [Submission URL](https://tango-web.github.io/) | 35 points | by [GaggiX](https://news.ycombinator.com/user?id=GaggiX) | [5 comments](https://news.ycombinator.com/item?id=35737151)

Researchers from the DeCLaRe Lab at the Singapore University of Technology and Design have developed a text-to-audio (TTA) generation AI called TANGO that uses an "instruction-tuned LLM" as a text encoder for better performance. TANGO outperforms the state-of-the-art AudioLDM on most metrics and stays comparable on the rest on AudioCaps test set, despite being trained on a smaller dataset. TANGO generates text-conditional sound effects, including human speech and music. While TANGO has limitations in terms of fine control of the generated audio, the team plans to improve it by training it on larger datasets. The code and model checkpoints have been released for reproducibility.

The discussion on this submission mostly involves appreciation for the technology and some additional insights on its capabilities. One user commends the researchers for their excellent work and also shares some resources featuring practical videos and high-level reviews. Another user expresses interest in the technology and suggests some additional tuning to improve its functionality. The user provides a link to an article on generating speech using machine learning. Another user comments on the state-of-the-art text-to-speech technology and shares a link to examples of speech generated synthetically through AI.

### The UIs ChatGPT Won't Replace

#### [Submission URL](https://exorva.com/blog/uis-chat-gpt-wont-replace) | 17 points | by [kmdupree](https://news.ycombinator.com/user?id=kmdupree) | [9 comments](https://news.ycombinator.com/item?id=35734660)

In a recent post on Hacker News, the founder of AI/LLM-powered app guide ChatGPT argues that traditional UIs won't be entirely replaced by chat-based experiences. The post examines tasks that rely on spatial metaphors, list items, and invariants, among other things, and demonstrates why chat-based UIs won't dominate the future. For example, busy people won't use ChatGPT to create calendar events, as they need to be able to see their schedule at a glance, while low-intent product exploration is better served by visual design patterns that instantly orient users. Ultimately, the author suggests that despite technological advancements, humans still work best with spatial and kinetic inputs.

The comments agree, with some suggesting certain tasks are better suited for GUIs or chat-based UIs. One commenter notes the importance of spatial understanding and memory, while another mentions that humans will always prefer human interfaces. Some comments also suggest that chat interfaces can be complementary to GUIs, and AI technology will allow easier access to a library of components for chat interfaces. Finally, one commenter mentions that time interaction feeling may become worse with chat-based interactions, and finding a balance between chat and GUI interfaces is important.

### Is Krita ready for HDR painting?

#### [Submission URL](https://notes.ericjiang.com/posts/1241) | 26 points | by [erjiang](https://news.ycombinator.com/user?id=erjiang) | [5 comments](https://news.ycombinator.com/item?id=35736913)

Krita, a digital painting software, has implemented support for high dynamic range (HDR) painting, allowing users to work with values above the traditional 0.0-1.0 range. However, there are areas within the software that still do not recognize these higher values, and some functions, such as LUT baking, are not yet possible. While it may be sufficient for general work and limited regions above 1, it may be difficult to work across a large dynamic range without proper exposure controls. Additionally, the software's target market may currently be too small to fully support HDR use.

Users on Hacker News talked about the importance of HDR painting and the limitations of current hardware, saying that cameras can capture more data than displays can render. Other users mentioned that HDR painting could be useful in creating works with a wider dynamic range and that similar workflows are used in 3D rendering software. One user also mentioned that games, TV, and movies are already using HDR rendering, but there are limitations due to the lack of HDR screens, which are not yet widely available. Overall, the discussion showed both excitement and caution about Krita's HDR support, with some saying that more exposure controls would be needed to work across a large dynamic range.

### Llama 1.3B Trained on 200B Tokens for Commercial Use

#### [Submission URL](https://huggingface.co/mosaicml/mpt-1b-redpajama-200b-dolly) | 23 points | by [vsroy](https://news.ycombinator.com/user?id=vsroy) | [7 comments](https://news.ycombinator.com/item?id=35737036)

The MPT-1b-RedPajama-200b-dolly is a powerful AI model with 1.3 billion parameters that has been fine-tuned on the Databricks Dolly instruction dataset. The model is a modification of a standard decoder-only transformer and features 24 layers, 16 attention heads, and width 2048. It has been pre-trained on a mix of datasets, with the majority being the RedPajama Common Crawl, and fine-tuned on the Databricks Dolly instruction dataset using the same hyperparameters found in their train_dolly.py script. The model uses ALiBi and QK LayerNorm and does not use biases. To use the model, one needs to pass `trust_remote_code=True` and use the MosaicML LLM codebase. The model was trained on the MosaicML Platform with sharded data parallelism using FSDP. The MPT-1b-RedPajama-200b-dolly is a valuable resource for instruction fine-tuning and natural language processing tasks.

The discussion in the comments primarily focuses on the number of parameters of the model and how they impact its performance. One user links to a paper on chinchilla scaling, which discusses optimizing the number of parameters for computational efficiency. Another user mentions being familiar with the RedPajama dataset.

### Lessons Learned Reproducing a Deep Reinforcement Learning Paper (2018)

#### [Submission URL](http://amid.fish/reproducing-deep-rl) | 48 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [10 comments](https://news.ycombinator.com/item?id=35732843)

Deep reinforcement learning is a fascinating field, but it can be more challenging than expected, as demonstrated by a recent project to reproduce a paper on training deep RL agents using feedback from humans. Debugging reinforcement learning involves lengthy iterations, and it's essential to be meticulous about the hypothesis-forming step to make the most of the scarce runs. It's also necessary to learn to recognize and follow through on confusion and be patient when getting stuck on problems for weeks at a time. Despite its challenges, the field holds much promise, as evidenced by recent work on training agents from human preference feedback.

In the comments, there is a discussion about the difficulties of reproducing research work and the need for patience and perseverance. One user shares their personal experience of creating a reinforcement learning agent to play a game and the challenges they faced. Another user recommends reading Sutton & Barto's book on reinforcement learning.

### Semantic Tokenizer for Enhanced Natural Language Processing

#### [Submission URL](https://arxiv.org/abs/2304.12404) | 68 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [28 comments](https://news.ycombinator.com/item?id=35729586)

A team of four researchers has published a paper titled Semantic Tokenizer for Enhanced Natural Language Processing on arXiv. The team presents a new tokenizer that uses semantics to drive vocabulary construction, with a trainer that uses stemming to enhance subword formation. The tokenizer is a drop-in replacement for the SentencePiece tokenizer and more than doubles the number of word forms represented in the vocabulary. The new tokenizer significantly improves NLP model convergence and improves the quality of word and sentence embeddings, with top performance seen in two Glue tasks using BERT-base, outperforming models more than 50 times in size.

Some comments noted that the paper was a significant improvement in transformer performance and highlighted how semantics can help processing multi-language texts. Others criticized the use of arXiv for class projects and questioned the significance of the paper's contribution. Additionally, some discussed the challenges of tokenization and the impact of vocabulary construction on natural language processing models.

### Palantir demos AI to fight wars but says it will be ethical

#### [Submission URL](https://www.vice.com/en/article/qjvb4x/palantir-demos-ai-to-fight-wars-but-says-it-will-be-totally-ethical-dont-worry-about-it) | 25 points | by [konart](https://news.ycombinator.com/user?id=konart) | [17 comments](https://news.ycombinator.com/item?id=35731534)

Palantir, co-founded by billionaire Peter Thiel, has demonstrated its Artificial Intelligence Platform (AIP) for military decision making. In Palantir's scenario, a military operator uses AI to monitor and respond to enemy activity, such as the recent amassing of military equipment near friendly forces. The operator asks a chatbot to show them more information, generates several plans of attack and organises the jamming of enemy communications. However, the author notes the dangers of automating warfare and abstracting it even further, suggesting the system is an illusion of safety and control for the Pentagon.

The comments discuss ethical concerns over the use of LLMs (lethal autonomous weapons). Some argue that the industry is ignoring these concerns, while others claim that the military will not deploy such systems until they are deemed safe and reliable. There are also some anecdotes about the long hours and intense work culture at Palantir.

### A Low Cost Approach to Improving Pedestrian Safety with Deep Learning

#### [Submission URL](https://nathanrooy.github.io/posts/2019-02-06/raspberry-pi-deep-learning-traffic-tracker/) | 62 points | by [djoldman](https://news.ycombinator.com/user?id=djoldman) | [58 comments](https://news.ycombinator.com/item?id=35727163)

A developer has created a cheap and accurate traffic counting system using TensorFlow and a Raspberry Pi Zero with an 8-megapixel infrared camera and rechargeable USB battery pack. The system uses a convolutional neural network with a secondary region proposal network to detect and localise objects within the frame, with lightweight temporal clustering to track them. The end result is a tool capable of separately counting vehicles, pedestrians and cyclists with high accuracy, potentially providing valuable data for urban planning and safety measures.

In the comments, there was a discussion on whether data on existing traffic patterns would be necessary for making biking more attractive in cities or if current infrastructure should be changed to support pedestrian traffic. Additionally, there was discussion on the correlation between frequent service and high passenger counts, as well as the challenges associated with increasing density and public transportation. There were also debates on making buses more efficient or switching to electric cars, as well as ideas for improving traffic congestion, such as increasing the use of roundabouts and encouraging the use of smaller cars.

---

## AI Submissions for Wed Apr 26 2023 {{ 'date': '2023-04-26T14:23:08.057Z' }}

### HDR-NeRF: High Dynamic Range Neural Radiance Fields

#### [Submission URL](https://xhuangcv.github.io/hdr-nerf/) | 142 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [32 comments](https://news.ycombinator.com/item?id=35717106)

Researchers from Northwestern Polytechnical University and Tencent AI Lab have developed a method called HDR-NeRF that can recover a high dynamic range radiance field from a set of low dynamic range views with different exposures. This allows for the generation of novel high dynamic range (HDR) and low dynamic range (LDR) views with varying exposures. The proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Experiments conducted on synthetic and real-world scenes validate the proposed method's ability to accurately control the exposures of synthesized views and render views with high dynamic range.

The discussion on the news discusses how the proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Some comments are about the advantages of using this method on smart-phones, while others discuss the limitations of the technology. The discussion also explores the naming convention of the technology and tone mapping. 

### Why did Google Brain exist?

#### [Submission URL](https://www.moderndescartes.com/essays/why_brain/) | 464 points | by [brilee](https://news.ycombinator.com/user?id=brilee) | [296 comments](https://news.ycombinator.com/item?id=35716216)

In this essay, former Google Brain employee Brian Kihoon Lee reflects on the existence of Google Brain and its relevance in today's economic conditions. He examines several reasons for its existence, including prestige, breakthrough discoveries, and maintaining a lead in machine learning. Lee suggests that while these reasons were valid in the past, economic pressures and increased competition from other AI companies mean that Google must be more responsible and directed in its research investments. He also notes a shift towards reduced researcher freedom and top-down direction within the company. Lee's perspective offers insights into the challenges facing industry research labs and the evolving landscape of AI development.

The discussion revolves around the validity of ML PhDs majoring in different fields such as chemistry and physics, and their proficiency in machine learning. Many users point out that while ML PhDs may not possess a deep understanding of the field they majored in, they are compensated for their lack of knowledge through their proficiency in ML. Others suggest that ML has helped cross disciplinary lines and created excellent interdisciplinary work. Some users argue that AI companies such as Google need to be more responsible and directed in their research investments, while others point out the need for foundational ML research. Overall, the discussion sheds light on the challenges facing the development of AI and industry research labs in general.

### DeepFloyd IF: open-source text-to-image model

#### [Submission URL](https://github.com/deep-floyd/IF) | 217 points | by [ea016](https://news.ycombinator.com/user?id=ea016) | [123 comments](https://news.ycombinator.com/item?id=35717871)

The StabilityAI team has developed a state-of-the-art open-source text-to-image model, called DeepFloyd IF, with high photorealism and language understanding. The model is composed of a frozen text encoder and three cascaded pixel diffusion modules that generate 64x64, 256x256, and 1024x1024 px images. The model uses the T5 transformer for text embedding and a UNet architecture with cross-attention and attention pooling. It outperforms other state-of-the-art models and achieves a zero-shot FID score of 6.66 on the COCO dataset. The DeepFloyd IF can be run locally and is also integrated with the Hugging Face Diffusers library.

The comments discuss DeepFloyd IF's capabilities compared to other text-to-image models and specific problems with the current implementation. Additionally, there is a discussion around hurdles with prompts and copyright laws. Some users express interest in trying the model with different prompts, while others debate the legal implications of using it.

### Mark Zuckerberg says Meta wants to ‘introduce AI agents to billions of people’

#### [Submission URL](https://www.theverge.com/2023/4/26/23699633/mark-zuckerberg-meta-generative-ai-chatbots-instagram-facebook-whatsapp) | 49 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [53 comments](https://news.ycombinator.com/item?id=35721910)

Meta CEO Mark Zuckerberg has announced plans to integrate AI agents into billions of Meta apps in ways that will be useful and meaningful for regular people, creators, and businesses. Although it remains unclear how exactly Meta will incorporate generative AI into its applications, Zuckerberg teased the release of AI products in the coming months that will reportedly touch every single one of the company's products. The move comes as Meta attempts to keep up with competitors such as Snap and Google that have invested heavily in building AI infrastructure in recent years, and to address industry-wide interest in the potential applications of generative AI technology.
 
There is a discussion on how AI is impacting society, with some commenters noting concerns about AI collecting information and privacy issues. Others discuss the potential uses of AI in marketing and content creation. One commenter suggests Meta should focus on developing computer vision capabilities. While there are some who support the use of AI, others are skeptical and concerned about how AI technology will impact humanity. Additionally, there are some comments about the renaming of the company to Meta and speculation about the company's future.

### Bringing Memory Safety to sudo and su

#### [Submission URL](https://www.memorysafety.org/blog/sudo-and-su/) | 81 points | by [mritzmann](https://news.ycombinator.com/user?id=mritzmann) | [64 comments](https://news.ycombinator.com/item?id=35714347)

Prossimo, a project by Ferrous Systems and Tweede Golf, has announced their plan to re-implement the widely-used sudo and su utilities in Rust to increase memory safety and minimize risks to operating systems. As sudo and su were originally developed in the 1980s and written in C, they have experienced a number of vulnerabilities related to memory safety issues. This joint team from Ferrous Systems and Tweede Golf will work to implement the critical function of these utilities in Rust to secure the most critical software, particularly from memory safety vulnerabilities. The work is supported by Amazon Web Services and Prossimo welcomes contributions to improve memory safety.

Discussions in the comments focused on the effectiveness of Rust's memory safety features, the complexity and vulnerabilities of other programming languages, and the importance of memory safety in software security. Some commenters suggested that OpenBSD's Doas could be a smaller, simpler alternative to sudo, and others discussed the advantages of different programming languages for memory safety.

### A guide to prompting AI, for what it is worth

#### [Submission URL](https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what) | 179 points | by [jger15](https://news.ycombinator.com/user?id=jger15) | [50 comments](https://news.ycombinator.com/item?id=35712375)

Recently, there has been a lot of emphasis on the importance of prompting AI, with some influencers sharing secrets of how to use prompts effectively. However, Ethan Mollick argues that this emphasis on prompting is misplaced and the best way to use AI systems is through interaction rather than trying to craft the perfect prompt. That being said, Mollick provides some tips on how to approach prompting, such as giving context and constraints to the system, providing additional data, and thinking about programming in prose. Ultimately, the key to using AI effectively is practice.

The discussion covers a variety of perspectives, including tips for approaching prompting, the limitations of AI in understanding human intent, and the importance of providing context and constraints to the system. Some commenters suggest that the emphasis on prompting is misplaced, while others argue that finding the right wording and constraints is crucial for successful outcomes. Overall, the discussion highlights the complex and ongoing nature of working with AI systems.

---

## AI Submissions for Tue Apr 25 2023 {{ 'date': '2023-04-25T15:39:53.181Z' }}

### Transformers from Scratch

#### [Submission URL](https://e2eml.school/transformers.html) | 341 points | by [jasim](https://news.ycombinator.com/user?id=jasim) | [28 comments](https://news.ycombinator.com/item?id=35697627)

Transformers are all about sequence transduction, we need a way to convert words to numbers so we can do math on them. One approach is to count each word from one and assign it a number, but there's an easier format for computers to work with: one-hot encoding. This assigns each word an array of mostly zeroes with a single one in its corresponding index. This allows us to compute dot products and is used in matrix multiplication, a way to combine two-dimensional arrays. Markov chains, represented as matrices, can be used as a first order model to show what the next word is likely to be based on recent words.

The submission discusses the use of one-hot encoding to convert words to numbers for mathematical operations. It is suggested that the use of matrices, such as Markov chains, can help predict the next likely word based on the sequence. The comments provide links to additional resources, such as Jay Alammar's Illustrated Transformer series and TensorFlow implementation, and discuss various aspects of tokenization, embeddings, and projections. Some users express disappointment in the complexity of the topic while others provide beginner-friendly resources for understanding it. Two comments are flagged as possibly inappropriate.

### Tuql: Automatically create a GraphQL server from a SQLite database

#### [Submission URL](https://github.com/bradleyboy/tuql) | 20 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [8 comments](https://news.ycombinator.com/item?id=35699017)

Tuql is a new tool that can convert a SQLite database into a GraphQL endpoint. With its ability to infer relationships between objects, Tuql currently supports `belongsTo`, `hasMany`, and `belongsToMany` relationships. The tool also generates the necessary mutations to create, update, and delete objects and can associate many-to-many relationships. Tuql can be used through the command line and is available as an npm package.

The comments on the submission mention that Tuql is a great tool, and some users mention other similar libraries. One user points out that Tuql does not add threat fields for queries, which may make it difficult to change the frontend in the future. Another user recommends not using Tuql in production. There is also a discussion around how GraphQL frameworks handle authorization and security. Overall, most of the comments are positive, with users praising the convenience of Tuql and GraphQL libraries in general.

### Show HN: ChatGPT on 2-Dimensional Map

#### [Submission URL](https://www.superusapp.com/chatgpt2d/) | 147 points | by [victorsup](https://news.ycombinator.com/user?id=victorsup) | [55 comments](https://news.ycombinator.com/item?id=35709088)

On Hacker News, a developer has created an interesting web app called "ChatGPT on 2-Dimensional Map." The app combines two popular AI technologies, namely GPT-2 for natural language processing and t-SNE for dimensionality reduction, to create a chatbot that can navigate a 2D map based on user inputs. The developer has also provided a demo, so users can see the app in action. This innovative project showcases the potential of combining different AI tools to develop new and creative applications.

A developer has created a web app called "ChatGPT on 2-Dimensional Map," utilizing both the natural language processing capabilities of GPT-2 and t-SNE for dimensionality reduction to create a chatbot that can navigate a 2D map based on user inputs. The discussion shows appreciation for this innovative project and its demonstration of the potential of combining AI tools to develop new applications. Some users express interest in using this technology for research and performance modeling, while others suggest similar projects and libraries for visualization and mapping. Some discuss related concepts such as Mind Maps and Lie Algebra. The high cost of ConceptGPT is mentioned, and some users suggest alternatives or that the creator should have asked for a funding request. A few users also mention indulging in activities such as drinking while programming or creating AI, while others make fun of misconceptions around Pina Coladas and canned ingredients.

### Google Authenticator cloud sync: Google can see the secrets, even while stored

#### [Submission URL](https://defcon.social/@mysk/110262313275622023) | 349 points | by [Signez](https://news.ycombinator.com/user?id=Signez) | [117 comments](https://news.ycombinator.com/item?id=35708869)

The discussion revolves around the security of Google Account 2FA secrets and how well Google protects its user data. Some commenters question Google's willingness to share user data with governments, while others suggest ways to enhance the security of the 2FA system and protect against data breaches. The conversation also touches on Apple's adherence to user privacy in comparison to Google. The debate ultimately boils down to how much responsibility users should take to protect their own privacy and how much they should rely on their service providers. One user recommends a phone security service called 2FAS for added security.

---

## AI Submissions for Mon Apr 24 2023 {{ 'date': '2023-04-24T15:21:30.763Z' }}

### LAION, a high school teacher’s free image database, powers AI unicorns

#### [Submission URL](https://www.bloomberg.com/news/features/2023-04-24/a-high-school-teacher-s-free-image-database-powers-ai-unicorns) | 315 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [172 comments](https://news.ycombinator.com/item?id=35685497)

The article tells the story of Christoph Schuhmann, a high school teacher who created LAION, the world's largest free AI training data set. LAION collects images and captions from various websites and uses them to train text-to-image generators, such as Google's Imagen and Stability AI's Stable Diffusion. The article explores the legal and ethical issues that arise from using publicly available materials for AI purposes, such as copyright infringement, bias, and regulation. The article also presents Schuhmann's views on why he wants to keep LAION open-source and independent.

Some users argue that LAION  only indexes internet lists of URLs, regional messages, and AI-generated text-to-image models, and does not publish any copyrighted content. Other users point out the potential legal liabilities and suggest that Common Crawl, a California nonprofit, should curate the collected visual data. Additionally, the comments touch on the challenges of accessibility in the design of captchas, the importance of properly organized high-quality imagery, and the legal implications of using scraped visual data for machine learning.

### Google Authenticator now supports Google Account synchronization

#### [Submission URL](https://security.googleblog.com/2023/04/google-authenticator-now-supports.html) | 429 points | by [ortusdux](https://news.ycombinator.com/user?id=ortusdux) | [305 comments](https://news.ycombinator.com/item?id=35690398)

Google Authenticator, a popular two-factor authentication app, now supports synchronization with Google Accounts. This means that users can easily transfer their authentication codes to a new device without needing to manually re-enter them. The feature is available on Android and iOS devices and uses Google Cloud to securely store and transfer the data. This upgrade provides added convenience and security for users who rely on two-factor authentication to protect their accounts.

Some users have complained about Google's 2FA offerings, including mismatched numbers and issues with Google Prompts not working on certain devices. Others have suggested potential solutions, such as using U2F tokens, while acknowledging the importance of account recovery processes involving important documents. The discussion also touches on related topics, such as password management, customer support, and device limitations. Overall, the consensus seems to be that while there are some issues and complexities with the technology, 2FA remains an important security measure that consumers should take advantage of.

### ONNX Runtime merges WebGPU backend

#### [Submission URL](https://github.com/microsoft/onnxruntime/pull/14579) | 166 points | by [b_mc2](https://news.ycombinator.com/user?id=b_mc2) | [31 comments](https://news.ycombinator.com/item?id=35694553)

Microsoft's open-source AI platform, ONNX Runtime, has introduced a WebGPU backend to accelerate machine learning models on the web. The JavaScript Execution Provider (JSEP) enables asynchronous inferencing execution and includes both C/C++ and TypeScript/JavaScript implementations. JSEP uses Emscripten's Asyncify compiler feature to unwind and rewind the call stack to emulate async execution. WebGPU is designed to have stronger features than WebGL, the other API currently available for accessing a GPU from a browser, making it a better solution for GPU performance when inferencing machine learning models.

Yhe submission sparked a discussion about the ONNX format, ONNX Runtime, and the implementation of the WebGPU backend for ML models. Some commenters suggested that the ONNX format is one of the best performing ML runtimes currently available, while others noted the lack of documentation for different platforms and hardware combinations. Others praised Microsoft's ONNX and made comparisons between different compiler systems. Some suggested alternative approaches to commenting and merging code to larger PRs. There was also discussion about the usefulness of the ONNX library, with some saying it worked well for them, and others suggesting that it could still use some improvement.

### 1Password to Add Telemetry 

#### [Submission URL](https://blog.1password.com/privacy-preserving-app-telemetry/) | 285 points | by [zan5hin](https://news.ycombinator.com/user?id=zan5hin) | [266 comments](https://news.ycombinator.com/item?id=35691383)

1Password, the password manager service, has begun an internal test of a new in-app telemetry system with a view to better understanding how users interact with the product. The initiative will be voluntary for employees and will not involve any data from customer accounts. Over the years, 1Password has regularly used its customer research programme to inform product development, but the company said it needed to expand its knowledge to improve the service for the millions of people using the product. Results from the internal trial will be evaluated before plans for a rollout are confirmed.

A user commented that they have been using the password manager Keepass, as they prefer a local vault and do not want any browser or cloud-based password managers. Another user praised 1Password's UI/UX, while others expressed concerns about the voluntary telemetry initiative and subscription-based licensing. Some users recommended Bitwarden and Keepass as alternatives with better functionalities. Some users also expressed skepticism about the benefits of telemetry and the need for it.

### Snapchat sees spike in 1-star reviews as users pan the ‘My AI’ feature

#### [Submission URL](https://techcrunch.com/2023/04/24/snapchat-sees-spike-in-1-star-reviews-as-users-pan-the-my-ai-feature-calling-for-its-removal/) | 240 points | by [mmq](https://news.ycombinator.com/user?id=mmq) | [200 comments](https://news.ycombinator.com/item?id=35689596)

Snapchat's new AI chatbot, powered by OpenAI's GPT technology, has been met with criticism by users following its recent public release. The chatbot, which is now pinned at the top of Snapchat's Chat tab, has resulted in a spike of negative reviews on the US App Store, with 75% being one-star reviews over the past week. Many users feel the chatbot is invasive and creepy, with concerns surrounding the collection of personal data, and have called for it to be a voluntary, opt-in feature. Some reviews indicate that even those who rated the app five stars have complaints about the My AI feature.

The comments section discusses data privacy concerns and the collection of personal data by companies, as well as the implementation of taxes like the Canadian Manufacturers Tax and GST. Some users feel that people do not grasp the extent of data collection that is happening, and that companies need to be more transparent about it. Others point out that sharing of personal information is an expected part of using such services.