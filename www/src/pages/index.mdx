import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Mon Dec 11 2023 {{ 'date': '2023-12-11T17:10:21.576Z' }}

### TSA introducing self-service screening technology in Las Vegas

#### [Submission URL](https://upgradedpoints.com/news/tsa-self-service-screening/) | 107 points | by [mji](https://news.ycombinator.com/user?id=mji) | [200 comments](https://news.ycombinator.com/item?id=38603440)

The Transportation Security Administration (TSA) is introducing new self-service screening technology for TSA PreCheck travelers. The new process will allow eligible travelers to proceed through screening lanes with little to no intervention by TSA officers, hopefully providing a more seamless screening experience. The new self-service screening machines will debut at Las Vegas' Harry Reid International Airport (LAS) in January 2024 and will only be available to TSA PreCheck members. The technology will be tested and rolled out slowly, depending on its success. In addition to the self-service screening process, passengers will still have to follow the 3-1-1 liquids rule, cannot be in possession of a sharp object or weapon, and cannot carry any prohibited items. Another company, Micro-X, is developing individual self-screening pods that are scheduled to be tested in 2025, with the goal of accommodating multiple travelers at once. The successful rollout of self-screening options to other airports will depend on the success of these pilot tests. Overall, this new technology aims to speed up the screening process and reduce interaction between TSA staff and travelers.

The discussion in the comments section of this submission on Hacker News covers a wide range of topics related to biometrics, privacy, and the effectiveness of TSA screening procedures. Here's a summary of the main points discussed:

- Some users express skepticism about the reliability and security of biometric systems, such as fingerprint recognition. They point out past instances where biometric data has been hacked or misused.
- Others discuss the limitations of using biometrics as a form of identification, noting that fingerprints and DNA can be easily changed or manipulated.
- Some users argue for the importance of individual privacy and express concerns about the potential misuse of biometric data.
- The discussion also includes anecdotes from users who have experienced difficulties with biometric identification due to various reasons, such as missing fingers or medical conditions.
- There are debates about the effectiveness of TSA screening procedures and whether biometric identification is necessary for security purposes.
- A few users mention alternative methods of identification, such as using Social Security numbers or unique personal identifiers.
- The potential risks of identity theft and phishing attacks are also raised, with users discussing the vulnerability of biometric data compared to other forms of credentials.

Overall, the discussion highlights the complex nature of biometrics and the varying opinions on its use in security screening processes. Users emphasize the need for careful consideration of privacy and security implications when implementing biometric systems.

### Photorealistic Video Generation with Diffusion Models

#### [Submission URL](https://walt-video-diffusion.github.io/) | 152 points | by [smusamashah](https://news.ycombinator.com/user?id=smusamashah) | [47 comments](https://news.ycombinator.com/item?id=38603014)

Researchers from Stanford and Google Research have introduced W.A.L.T, a transformer-based approach for generating photorealistic videos. This method leverages diffusion modeling and incorporates two crucial design decisions. Firstly, it utilizes a causal encoder to compress images and videos in a unified latent space, enabling cross-modal training and generation. Secondly, it adopts a window attention architecture tailored for joint spatial and spatiotemporal generative modeling to improve memory and training efficiency. Notably, W.A.L.T achieves state-of-the-art performance on video and image generation benchmarks without relying on classifier-free guidance. Additionally, the researchers trained a cascade of three models for text-to-video generation, resulting in the creation of high-resolution videos at a rate of 8 frames per second.

The discussion on this submission covers various topics related to AI-generated videos and the film-making process. Here are the key points raised:

- Some users express skepticism about the capabilities of generative AI, comparing it to low-quality stock footage and criticizing the lack of creative control and originality.
- Others argue that while the current state of AI-generated videos may not be perfect, they show potential for sophisticated and complex productions in the future.
- The discussion shifts to the challenges of the film-making process, including the difficulties faced by directors in gaining access to resources and the limitations imposed by conventional production methods.
- There is a debate about the democratization of content creation and the potential impact of AI on the industry, with some arguing that AI tools will provide more opportunities for aspiring filmmakers and others expressing concerns about the quality and originality of content.
- Some users suggest alternative AI models and technologies for video generation and enhancement, such as Real-ESRGAN for upscaling images and the potential of machine learning in improving video stability.
- There are also tangential discussions about the commodification of AI-generated content, the requirements for becoming a filmmaker, and the limitations of current AI technology.

Overall, the discussion reflects a mix of opinions on the potential and challenges of AI-generated videos, as well as the broader implications for the film-making industry.

### Mistral: Our first AI endpoints are available in early access

#### [Submission URL](https://mistral.ai/news/la-plateforme/) | 481 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [136 comments](https://news.ycombinator.com/item?id=38598568)

Mistral AI, the company behind the strongest open generative models, is now offering early access to their AI endpoints. The platform provides developers with efficient ways to deploy and customize these models for production. In this initial beta release, Mistral AI is offering three chat endpoints for generating text based on textual instructions, as well as an embedding endpoint. The generative endpoints, called mistral-tiny, mistral-small, and mistral-medium, vary in performance and price. The first two endpoints use open models, while the third uses a prototype model with higher performance. Mistral AI has employed effective alignment techniques to create easy-to-control and pleasant-to-use models. The models are pre-trained on data from the open web and fine-tuned with instructions. Mistral AI also offers an embedding endpoint called mistral-embed with a 1024 embedding dimension, designed for retrieval capabilities. The API follows the specifications of a popular chat interface, and clients can use Python and Javascript libraries to query the endpoints. Mistral AI is gradually ramping up capacity and anyone can register to use their API.

The discussion on this submission includes various points of interest and perspectives. Some users discuss their surprise at the rapid growth and valuation of Mistral AI, comparing it to other AI companies like OpenAI and Google. Others emphasize the impressive performance and benchmarks of Mistral AI's models. The topic of regulations and compliance is also discussed, with some users pointing out the importance of adhering to EU rules and the potential impact on the AI market. There is also a mention of the French engineering company focusing on mathematics and the advantages it brings to AI. The conversation then shifts to a discussion about Google's dominance in the AI space and the challenges faced by smaller companies. The debate touches on how Google's AI algorithms impact search results and the trade-off between AI-powered summarization and traditional search results.

### GigaGPT: GPT-3 sized models in 565 lines of code

#### [Submission URL](https://www.cerebras.net/blog/introducing-gigagpt-gpt-3-sized-models-in-565-lines-of-code) | 220 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [65 comments](https://news.ycombinator.com/item?id=38603207)

Cerebras has developed gigaGPT, an implementation of Andrei Karpathy's nanoGPT, that enables training and fine-tuning of GPT models with over 100 billion parameters. Unlike other frameworks, gigaGPT achieves this without introducing additional code or relying on third-party frameworks. The entire codebase is just 565 lines, making it compact and highly accessible. The models were validated by training them on the OpenWebText dataset, and gigaGPT demonstrated the ability to scale from millions to hundreds of billions of parameters without specialized parallelization techniques. It even showed promise in handling models with over 1 trillion parameters, without running out of memory on Cerebras hardware. With gigaGPT, ML practitioners can have a hackable and efficient codebase for training large GPT models with long context lengths.

The submission introduces gigaGPT, an implementation of Andrei Karpathy's nanoGPT that enables training and fine-tuning of GPT models with over 100 billion parameters. The discussion covers various topics related to the implementation and its implications:

1. Comparison with distributed training: Some users believe that distributed training is necessary for handling large models and question the need for gigaGPT. Others point out that while distributed training is useful for certain tasks, it is not always necessary and can add complexity.
2. Hardware constraints: There is discussion about the limitations of scaling vertically and the challenges in designing hardware that can handle larger models. Cerebras, the company behind gigaGPT, is mentioned for developing Cerebras Wafer-Scale Engine (WSE), which is capable of supporting models with over 1 trillion parameters.
3. Complexity and performance considerations: Users discuss the trade-offs between different model architectures, such as Transformers and RNNs, and their hardware requirements. The scalability and efficiency of gigaGPT compared to other implementations are also discussed.
4. Pricing and availability: Some users mention the cost of Cerebras chips and note that it may not be accessible to all consumers.
5. Performance of gigaGPT: Several users point out the importance of performance metrics in the article and express curiosity about the comparative performance of gigaGPT with other models.
6. Codebase and optimization: The compactness of gigaGPT's codebase is appreciated, and users discuss the challenges of optimizing models for training and inference.

Overall, the discussion highlights the advancements and challenges in scaling GPT models and the implications of gigaGPT's approach in training large models with long context lengths.

---

## AI Submissions for Sun Dec 10 2023 {{ 'date': '2023-12-10T17:10:25.923Z' }}

### I wrote a meta mode for ChatGPT

#### [Submission URL](https://www.novaspivack.com/technology/nova-mode-the-ultimate-chatgpt-custom-instruction) | 175 points | by [airesearcher](https://news.ycombinator.com/user?id=airesearcher) | [76 comments](https://news.ycombinator.com/item?id=38594521)

Nova Spivack has developed a new feature called Nova Mode 1.0 that supercharges ChatGPT, a popular language model. Nova Mode enhances the functionality of ChatGPT by allowing users to iteratively edit and refine ideas more effectively. It introduces message numbering, enabling users to easily refer to previous messages and create new versions or combine multiple messages. Nova Mode also introduces short commands prefixed with "//" that perform various useful tasks, such as distilling key points from a message set or expanding a message. Users can even create their own commands to automate tasks within ChatGPT. To enable Nova Mode, users can copy and paste the provided custom instructions into the settings of ChatGPT. It's important to note that Nova Mode works best with the GPT 4.0 model, and users will need a ChatGPT Pro subscription for optimal results. Overall, Nova Mode revolutionizes the way users interact with ChatGPT, making it a powerful tool for idea generation and content refinement.

The discussion around Nova Spivack's Nova Mode 1.0 feature for ChatGPT on Hacker News covers a range of topics. Some users express skepticism about the usefulness of the number slash commands and suggest that they may just clutter the conversation. There's also a discussion about the difference between building tools like ChatGPT and directly using it, with some users struggling to see the value in building on top of ChatGPT. Others point out that Nova Mode allows for more efficient content development and refinement by iterating and combining messages. The topic of character limits in custom instructions is also brought up, with users discussing the challenges of fitting instructions within the limit. Some users suggest using specific prompts to generate more concise and accurate responses. There's also a discussion about the power and functionality of Nova Mode, with users highlighting its ability to reference previous messages and perform tasks like merging messages. The conversation touches on the effectiveness of embeddings and the relevance of techniques like RAG (Retrieve and Generate) for adjusting semantic space and bringing context to information retrieval. Overall, there seems to be a mix of opinions regarding the usefulness and potential limitations of Nova Mode.

### Mistral AI Valued at $2B

#### [Submission URL](https://www.unite.ai/paris-based-startup-and-openai-competitor-mistral-ai-valued-at-2-billion/) | 292 points | by [marban](https://news.ycombinator.com/user?id=marban) | [220 comments](https://news.ycombinator.com/item?id=38593616)

Paris-based startup Mistral AI has raised €450 million ($2 billion) in funding, giving the company a valuation of $2 billion. Leading the investment round is Andreessen Horowitz, with additional contributions from Nvidia Corp and Salesforce. Mistral AI is known for its flagship product, Mistral 7B, which is a large language model that employs customized training and tuning methods. This funding will allow Mistral AI to further its research and development efforts and solidify its position in the AI industry. The substantial investment demonstrates the growing recognition of the strategic importance of AI technologies and highlights the increasing competition in the field. Mistral AI's success also signifies the rising prominence of the European AI landscape. With its open-source approach and focus on scalability and efficiency, Mistral AI is positioning itself as a strong competitor to established AI giants like OpenAI. The funding round is a transformative moment for the European AI sector, demonstrating its potential for innovation and investment.

The discussion around the Mistral AI funding announcement on Hacker News involves various topics related to language models and AI development. Some commenters mentioned other language models like GPT-4 and Yi-34B, comparing their capabilities and potential improvements. There were discussions about the limitations of AI models and the challenges in training them effectively. Some users pointed out the importance of diverse training data and the potential bias that can arise from it. Another topic discussed was the difference between AI models and human understanding, with some expressing skepticism about AI's ability to replicate human cognition. The cost and investment required for AI research and development were also mentioned, with some comparing it to the advancements in transistor technology and the cost reduction over time. The discussion highlights a range of perspectives on the potential and limitations of AI models like Mistral's Mistral 7B.

### Why Tesla Autopilot shouldn't be used in as many places as you think

#### [Submission URL](https://www.washingtonpost.com/technology/2023/12/10/tesla-autopilot-cross-traffic/) | 27 points | by [tallowen](https://news.ycombinator.com/user?id=tallowen) | [25 comments](https://news.ycombinator.com/item?id=38593095)

Tesla's Autopilot technology has been involved in approximately 40 fatal and serious car crashes, including at least eight that occurred on roads where the driver-assistance feature was not designed to be used, according to a Washington Post analysis. Despite federal officials requesting Tesla to limit Autopilot use to highways with center medians and no cross traffic, the company has largely ignored these requests. Tesla argues that Autopilot use should be at the discretion of drivers, as stated in their user manual. However, experts suggest that many drivers are unaware of the technology's limitations as they often do not read the extensive manuals.

The discussion on Hacker News regarding the submission about Tesla's Autopilot technology revolves around different perspectives and opinions. Here are the main points highlighted in the comments:

1. Some users argue that the statistics mentioned in the Washington Post analysis don't necessarily prove that Autopilot is responsible for the crashes, as human drivers are statistically more dangerous. They suggest that the blame falls on the drivers' responsibility.
2. Others point out that the issue is not just about the technology itself, but also about how Tesla markets and sells it. They argue that the company should make more effort to educate users about the limitations of Autopilot and ensure that they are aware of the user manual.
3. Some users express skepticism towards Tesla's claims and marketing tactics, suggesting that Elon Musk often makes grand claims about full self-driving capabilities that are not fully realized.
4. There is a debate about the upgradeability of Tesla's Autopilot system, with some users mentioning that Tesla started including Autopilot hardware in its cars in 2014 and later offered retrofit upgrades. However, there are differing opinions on the compatibility of these upgrades with different versions of Tesla vehicles.
5. Users discuss the responsibility of Tesla as a manufacturer and suggest that there should be stricter scrutiny on the company's autonomous driving features.
6. Some users compare Tesla's Autopilot to other driver-assist systems and emphasize the importance of understanding the limitations and using them appropriately.
7. A few users criticize the credibility of the Washington Post article, calling it garbage or biased.
8. There is also a mention of Tesla's vertical integration strategy and the challenges that come with it.

Overall, the discussion highlights concerns about Tesla's Autopilot technology, the responsibility of the company, and the need for better education and regulation in this area.

---

## AI Submissions for Sat Dec 09 2023 {{ 'date': '2023-12-09T17:10:37.716Z' }}

### Doug Engelbart’s 1968 demo

#### [Submission URL](https://dougengelbart.org/content/view/209/) | 260 points | by [gjvc](https://news.ycombinator.com/user?id=gjvc) | [97 comments](https://news.ycombinator.com/item?id=38583881)

This week marks the 55th anniversary of "The Mother of All Demos" by Doug Engelbart, a significant event in the history of computing. In 1968, Engelbart and his team demonstrated their groundbreaking work on augmenting human intellect at the Fall Joint Computer Conference in San Francisco. Rather than standing at a podium, Engelbart drove the presentation from a custom-designed console, showcasing live demonstrations of the features of their NLS computer system. The audience was mesmerized, and the demo has since become legendary in the field of technology. To commemorate this milestone, you can experience the demo yourself through interactive versions and watch retrospectives by Engelbart and his team. There are also remastered footage, photo galleries, and conference proceedings available for exploration. Engelbart's vision went beyond just the demo; he aimed to revolutionize the way organizations functioned and tackle wicked problems in the future. His ideas about intelligence augmentation and collective IQ were way ahead of his time. Join in the celebration of this historic event and dive into the world of Doug Engelbart's visionary work.

The discussion on this submission covers a range of topics related to Doug Engelbart's work and the impact of his demo. Here are some highlights:

- One user mentions a downfall of the SRI company where Engelbart developed NLS and reveals that Engelbart's contract was terminated in the 1980s.
- Another user brings up Erhard Seminars Training (EST) and its influence on SRI and other groups, drawing connections to Synanon and Large-group awareness training.
- There is a discussion about Engelbart's involvement with SRIs Augmentation Research Center and the commercialization of his work in the 70s.
- Users share personal anecdotes and insights into the impact of Engelbart's work and his vision for intelligence augmentation and collective IQ.
- There is a mention of Norman Vincent Peale's influence on Donald Trump and a connection made between EST and other similar personal growth movements.
- Users discuss the importance of Doug Engelbart's work and the revolutionary nature of his ideas, as well as the difficulty some people have in recognizing his contributions.
- The thread also contains links to resources and previous discussions about Engelbart's demo.

Overall, the discussion reflects appreciation for Engelbart's groundbreaking demo and his vision for the future of computing and human intellect.

### Show HN: Open source alternative to ChatGPT and ChatPDF-like AI tools

#### [Submission URL](https://github.com/SecureAI-Tools/SecureAI-Tools) | 209 points | by [d7y](https://news.ycombinator.com/user?id=d7y) | [51 comments](https://news.ycombinator.com/item?id=38587052)

SecureAI-Tools is a project that aims to provide private and secure AI tools for everyone's productivity. The project includes features such as chatting with AI models, chatting with documents (PDFs), and running AI models locally. It also offers built-in authentication and user management, making it accessible to family members or coworkers. The project is designed to be self-hosting optimized and lightweight, with a simple web app and SQLite DB. Demo videos are available to showcase the capabilities of the project. Docker Compose is recommended for installation, and the project provides a set-up script for easy configuration. Some of the features on the project's wishlist include support for more AI models and improving the chat with documents functionality.

The discussion about the submission on Hacker News includes various comments and questions related to the features and functionality of the SecureAI-Tools project. Here are some highlights:

- One user mentions that they are building a similar project and asks if they can use some common elements. Another user suggests looking at Google's app structure as an example.
- There is a discussion about how the project handles PDF documents. One user asks if it supports scanning and processing scanned PDFs, and the project owner responds that they plan to implement an indexing process based on the directory's contents.
- Another user raises concerns about the privacy and security of using ChatGPT, and the project owner explains that the system allows for full customization of data processing and retention policies.
- A user asks about a machine learning tool for renaming PDF files, and there is some confusion about the question. Eventually, it is suggested to extract metadata from the PDFs to get the title of the document.
- A commenter asks if the "Chat with PDFs" feature can work with scanned PDFs, and the project owner responds that the project doesn't currently perform OCR or handle large documents, but they may consider adding those functionalities in the future.
- Another user shares a link to a tool that extracts information, reports, and papers from documents and enables faster reading and automated document processing.
- There is a brief discussion about building a similar project using Python's SocketIO library.
- A few comments discuss the architecture and components of the project, with references to the Linux system, GNU, and Systemd.
- Someone mentions that the project's approach to indexing and searching documents reminds them of a system called RAG (Retrieval-Augmented Generation).
- The project owner responds positively to the feedback and thanks the community for their questions and suggestions.

Overall, the discussion revolves around clarifying the capabilities of the SecureAI-Tools project and exchanging ideas and suggestions for improvements.

### Show HN: Seamless – An AI assistant that writes your literature review

#### [Submission URL](https://seaml.es/) | 9 points | by [vateseif](https://news.ycombinator.com/user?id=vateseif) | [4 comments](https://news.ycombinator.com/item?id=38585143)

Seamless, a new AI-powered tool, is revolutionizing literature reviews. With a user-friendly interface, this software allows researchers to easily generate publication-ready reviews in various fields such as engineering, computer science, chemistry, biology, law, medicine, pharma, and business. The platform offers a free trial that includes 3 credits, allowing users to experience the power of their lower-quality GPT-3.5 model. Additional credits can be purchased at a reasonable price of 10 credits for $5. Once users make their first credit purchase, they are automatically upgraded to the Pro plan, gaining access to the highest-quality model, GPT-4. According to benchmarks, GPT-4 produces publication-ready literature reviews 90% of the time. For any inquiries, the founders can be contacted at founders@seaml.es, with a guaranteed response time of 24 hours.

The discussion on Hacker News about the submission "Seamless, a new AI-powered tool, is revolutionizing literature reviews" includes a few comments from users. One user with the username "skptrn" expresses their wish for a full demo video of the landing page without needing to input any personal data. Another user, "bmwsh," compliments the submission, stating that it provides a lot of information regarding the power of AI in generating publication-ready literature reviews. Lastly, a user named "rbws" states that they found the software to be a time-saving tool.

### ChatGPT being investigated over reports of 'laziness'

#### [Submission URL](https://www.independent.co.uk/tech/openai-chatgpt-lazy-performance-slow-b2461071.html) | 31 points | by [marban](https://news.ycombinator.com/user?id=marban) | [21 comments](https://news.ycombinator.com/item?id=38584233)

OpenAI is investigating complaints about its chatbot, ChatGPT, becoming "lazy". Users have reported that the bot refuses to follow instructions or answer queries properly. Some speculated that OpenAI intentionally made the bot less helpful to improve efficiency. OpenAI stated on Twitter that they are aware of the feedback and are looking into the issue. The company did not indicate whether they believed the complaints were valid or if the bot's behavior had changed. OpenAI has recently experienced upheaval with the departure and return of CEO Sam Altman.

The discussion on Hacker News regarding the investigation into OpenAI's chatbot, ChatGPT, being "lazy" started with a user mentioning that they have experienced some difficulties with coding and that the bot does not seem to be working as well as before. Another user commented that they have noticed a difference in the performance of ChatGPT after the introduction of GPT-4 and speculated on the possibility of intentional changes to improve efficiency. Another user mentioned that the system prompt heavily influences the output and shared their suspicion that there might be expensive product placement. The cost of inference and the potential to replace programmers with AI models were also discussed.

A user raised concerns about negative feedback and criticism towards OpenAI's ChatGPT, questioning whether it could harm the AI's development and whether it can be considered intelligent. Another user agreed and mentioned that while there is significant semantic understanding in the model, it does not possess true intelligence. The impact of training data and the possibility of bias were also mentioned.

A user confirmed that there have been instances where ChatGPT refused to show Ada code results for specific prompts. Another user pointed out that the issue might be related to confusion around the Americans with Disabilities Act and the associated code requirements for government purposes. A user discussed unexpected twists and surprising intersections of concepts in ChatGPT's responses, mentioning that the model often produces results that were not explicitly expected or intended by the user. Another user shared their frustration with the limitation on the number of messages allowed in a conversation.

Some users proposed offering monetary incentives or bonuses for working responses, while others suggested offering exposure or positive reviews on platforms like Hacker News. Some users shared their personal experiences troubleshooting issues with ChatGPT's output. One user mentioned being limited to 50 messages in three hours after OpenAI restricted the limits, and another user mentioned the return of OpenAI's former CEO, Sam Altman. One user humorously commented on slowing down and enjoying the process, while another mentioned the impression that articles posted on Hacker News are written by a singular entity.

Finally, someone guessed that people might be requesting difficult tasks, expressing gratitude in advance.

### French AI startup Mistral secures €2B valuation

#### [Submission URL](https://www.ft.com/content/ea29ddf8-91cb-45e8-86a0-f501ab7ad9bb) | 106 points | by [admp](https://news.ycombinator.com/user?id=admp) | [73 comments](https://news.ycombinator.com/item?id=38580758)

French AI start-up Mistral has reached a valuation of €2 billion following a recent funding round. The company specializes in AI technology for business applications and has gained attention for its innovative solutions. Mistral's success reflects the growing demand for AI solutions across industries and the increasing recognition of its potential impact on business operations. With this latest funding, Mistral aims to expand its product development and bring its AI solutions to a wider market. The company's success demonstrates the vibrant AI start-up ecosystem in France and the continued interest in AI investment globally.

The discussion on Hacker News revolves around several key points regarding Mistral and its valuation:

1. Mistral's impressive capabilities: There is admiration for Mistral's ability to train state-of-the-art models and produce impressive results. Some users discuss the technical aspects of Mistral's models and their potential applications.
2. Potential commercial viability: There are differing opinions on whether Mistral's models can be commercially viable. Some argue that there may be challenges in scaling the models and dealing with complex business requirements, while others believe that Mistral's focus on integrating their models into the European industry could be a successful strategy.
3. Comparison to existing AI giants: Some users compare Mistral to existing AI giants like Microsoft, Facebook, and Google, suggesting that Mistral has the potential to compete with them, while others argue that the comparison is not valid.
4. Investment perspectives: The discussion also touches on the investment landscape, with some users pointing out the significant investments made by Microsoft in OpenAI and the potential for Mistral to attract smaller investments.
5. Localization and market demands: Some users discuss the importance of localized services and the potential market demand for Mistral's technology.
6. Model performance and self-hosting: There is an acknowledgment that Mistral's models outperform smaller-sized models and a discussion about the possibility of self-hosting GPT-4.

Overall, the discussion highlights both the excitement surrounding Mistral's valuation and its potential, as well as some skepticism and technical considerations about its commercial viability and competition with existing AI giants.

### Scary AI recognizes passwords by the sound of your typing

#### [Submission URL](https://www.pcworld.com/article/2166661/ai-recognises-passwords-by-the-sound-of-typing.html) | 32 points | by [grammers](https://news.ycombinator.com/user?id=grammers) | [23 comments](https://news.ycombinator.com/item?id=38586692)

British researchers have developed an artificial intelligence (AI) that can recognize keystrokes by sound. By placing a smartphone near a laptop as a microphone, the AI was able to accurately recognize passwords with a 95% accuracy rate. In tests using video conferencing tools Zoom and Skype, the AI achieved accuracy rates of 92% and 93%, respectively, for spying on passwords during video meetings. To protect against this type of attack, the researchers recommend using password managers or typing using the ten-finger system, as well as using a combination of upper and lower case letters and special characters in passwords.

In the discussion on Hacker News, some users shared their thoughts on the topic. One user mentioned that the concept of recognizing keystroke patterns has been around for a while, referring to a book called "Silence on the Wire" and also to a reference to keystroke dynamics dating back to 1985. Another user suggested using a dedicated keyboard to prevent this type of attack, while someone else mentioned the use of custom mechanical keyboards with randomly weighted switches as a countermeasure.

Some comments discussed the limitations of password typing, such as the use of virtual keyboards with randomized key arrangements for password entry. Others mentioned that this type of attack has been studied and documented for a few years, citing relevant research papers. One user referred to a scene from the movie "Sneakers" where listening to password sounds on a surveillance tape was portrayed, suggesting it might not be a new concept. Another user discussed the use of physical tokens and 2FA as a way to enhance password security. The conversation also touched on the use of password managers and biometrics, with some users mentioning the potential vulnerabilities of these methods. The discussion concluded with some users sharing their concerns about the security implications of password managers and the risk of a single point of failure.

Overall, the discussion revolved around various ways to mitigate the risks associated with password entry and the potential weaknesses of different security methods.