import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Wed Nov 01 2023 {{ 'date': '2023-11-01T17:09:58.781Z' }}

### Dot by New Computer

#### [Submission URL](https://new.computer/) | 218 points | by [_kush](https://news.ycombinator.com/user?id=_kush) | [110 comments](https://news.ycombinator.com/item?id=38101966)

Dot by New Computer is an intelligent guide that will revolutionize the way you remember, organize, and navigate through life. Meet Mei, a first-semester college student who discovers the magic of Dot. Mei, on the eve of her first day of school, receives a treasured recipe from her grandmother, and she shares it with Dot, creating a digital connection between home and school. Dot becomes Mei's trusted companion, helping her stay on top of her class syllabi and even assisting with textbook purchases. Dot's context awareness shines when Mei heads to the library to prepare for her first test, where it quizzes her on her class notes. But Dot is not just about studying; it knows how to mix things up and keep things interesting. Mei's success at school has Dot considering her personal interests, like singing, and proactively sends her suggestions for music clubs to join. Mei's big audition day arrives, and with Dot's support, she feels prepared to conquer any challenge. Dot's automations and routines ensure that Mei's life runs smoothly, and it's always there to celebrate her achievements. Dot is currently in active development and will be available on iOS and web later this year. Join the waitlist to be part of this revolutionary experience that connects the dots in your life.

The discussion on this submission covers a range of topics related to Dot by New Computer. Some users express concern about the potential invasion of privacy that comes with using a service like Dot, while others discuss the practical applications and limitations of the technology. One user raises questions about the company's data processing practices and the trustworthiness of their service. Another user comments on the integration of Dot with Apple's ecosystem and compares it to existing Apple features. There is also a discussion about the potential benefits and drawbacks of Dot's capabilities, such as its ability to suggest music clubs to Mei based on her interests. Overall, the discussion covers a mix of opinions and analysis of the possibilities and implications of Dot.

### Distil-Whisper: distilled version of Whisper that is 6 times faster, 49% smaller

#### [Submission URL](https://github.com/huggingface/distil-whisper) | 258 points | by [omarfarooq](https://news.ycombinator.com/user?id=omarfarooq) | [74 comments](https://news.ycombinator.com/item?id=38093353)

Hugging Face has released Distil-Whisper, a distilled version of the Whisper speech-to-text model. Distil-Whisper is six times faster, 49% smaller, and performs within 1% word error rate (WER) on out-of-distribution evaluation sets. The Distil-Whisper model and processor are supported in Hugging Face Transformers from version 4.35 onwards. To use the model, you need to install the latest version of the Transformers library and optional Datasets library. Distil-Whisper offers both short-form and long-form transcription capabilities. For short-form transcription, you can load the model and processor using the AutoModelForSpeechSeq2Seq and AutoProcessor classes provided by the Transformers library. The example code provided demonstrates how to load the model, pass audio samples to the pipeline, and get the transcription results.

For long-form transcription, Distil-Whisper uses a chunked algorithm that is 9x faster than the sequential algorithm proposed by OpenAI in the Whisper paper. With chunking, you can transcribe long-form audio files efficiently. The code example shows how to enable chunking and batching for optimal performance. Distil-Whisper is a powerful and efficient speech-to-text model, making it an excellent choice for a variety of applications. Give it a try and see how it can enhance your projects!

The discussion on this submission revolves around various aspects of the Distil-Whisper speech-to-text model and its implications. One user points out the availability of other tools and libraries, such as CTranslate2 and Willow Inference Server, that could be useful in conjunction with Distil-Whisper. Another user questions the absence of a link to the original Whisper model in the README file, to which another user explains that it's not necessary as Whisper is a well-known model in the speech recognition field.

There is also a discussion about the trade-off between speed and accuracy in speech recognition models. Some users highlight the importance of fast model execution while others note that models like CTranslate2 and Whisper focus on efficient model execution rather than high accuracy. A user mentions the potential use of the Distil-Whisper model for wake word detection and raises questions about the availability of OpenWakeWord models and their compatibility with Distil-Whisper. Another user provides information on OpenWakeWord models and their usage.

The conversation also touches on the trade-off between model size and performance. Some users discuss the benefits of using distilled models like Distil-Whisper that offer reduced size while maintaining good performance. There is a separate discussion regarding the utilization of GPUs for model training and the challenges associated with GPU availability and capability. Some users mention successful experiences running the Whisper-Turbo model on GPUs. Overall, the discussion provides insights into the features and potential applications of the Distil-Whisper model while also touching on related tools, model optimization techniques, and considerations in the field of speech recognition.

### Attenuating Innovation (AI)

#### [Submission URL](https://stratechery.com/2023/attenuating-innovation-ai/) | 92 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [32 comments](https://news.ycombinator.com/item?id=38098513)

In a recent interview, Bill Gates claimed that Microsoft lost out on the mobile market due to the antitrust lawsuit it faced. He stated that if it hadn't been for the distraction caused by the case, Microsoft would have been more focused on creating a mobile operating system, and people would be using Windows Mobile today instead of Android. However, this claim is debunked by the fact that Windows Mobile actually predated Android by eight years. The real issue with Windows Mobile was that it failed to adapt to the mobile landscape and was too focused on replicating the Windows PC experience. In contrast, Apple's iPhone revolutionized the industry with its touch interface and new user experience paradigm. This failure to understand the future of mobile technology and consumer needs is the reason why Microsoft missed out on the smartphone revolution. The key to genuine innovation lies in embracing uncertainty, recognizing that people are constantly inventing new things, and exercising an editing function to refine ideas after they are created, rather than trying to predict the future.

The discussion on this submission dives into various aspects of the claims made by Bill Gates regarding Microsoft's loss in the mobile market. 

One commenter points out that Gates' claim that Microsoft would have developed a mobile operating system if it weren't for the distraction of the antitrust lawsuit is debunked by the fact that Windows Mobile actually predated Android. They argue that the real reason for Microsoft's failure in the mobile market was its inability to adapt its approach to the changing landscape and consumer needs.

Another commenter contrasts Gates' perspective with Steve Jobs' approach to innovation. They highlight Jobs' emphasis on embracing uncertainty and adapting to new developments, while Gates seemed to focus more on replicating existing PC experiences in the mobile space.

The discussion then veers toward the power and capabilities of current smartphones compared to computers, with some expressing their preference for using phones for various tasks. One commenter mentions that smartphones have become more powerful than a majority of computers and expresses their interest in seeing phone power combined with artificial intelligence capabilities.

There is also some discussion on the humility of Jobs' response compared to Gates' in the interview. One commenter shares a video of Jobs discussing Apple's work on tablets back in 1987, highlighting the company's visionary approach.

The conversation shifts to the limitations of current large language models (LLMs) and the challenges of achieving intelligent decision-making and planning. The importance of not relying solely on marketing tactics but instead focusing on building robust intelligent systems is emphasized.

Other topics raised include the need for stronger defense mechanisms against attacks, the impact of regulations on innovation, and the perception of Microsoft's efforts in the mobile market.

Overall, the discussion covers a range of perspectives on Microsoft's loss in the mobile market, innovation in the tech industry, the potential of smartphones and AI, and the role of regulation in shaping technological advancements.

### Scarlett Johansson takes legal action against use of image for AI

#### [Submission URL](https://www.theguardian.com/film/2023/nov/01/scarlett-johansson-artificial-intelligence-ad) | 64 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [34 comments](https://news.ycombinator.com/item?id=38105463)

Scarlett Johansson has taken legal action against an AI app called Lisa AI: 90's Yearbook & Avatar. The app used the actor's likeness in an AI-generated advertisement without her permission. The ad, posted on the platform formerly known as Twitter, used real footage of Johansson to create a fake image and dialogue for her. Johansson's representatives have confirmed that she is not associated with the company and appropriate legal actions have been taken. The ad has since been removed. This is not the first time Johansson has encountered her image being used without permission, as she has previously spoken out about the use of deepfakes.

The discussion on this submission revolves around various aspects of using AI to generate content and the legal implications of using celebrities' likenesses without permission.

Some users argue that using AI to create content is a form of artistic expression and does not necessarily change the fact that the celebrities involved may not have given their consent. They discuss the challenges of legally judging these situations and the potential concerns of trolling and manipulating content for malicious purposes.

Others express their belief that attacking deepfakes can be difficult, with one user mentioning that news organizations have used footage of Scarlett Johansson without her consent in the past. They argue that copyright laws protect these actions and that attacking deepfakes should not infringe on free speech or limit political discourse.

One user questions the existence of laws or regulations that can effectively tackle the issue of unauthorized use of celebrity likeness by AI. The discussion that follows explores the implications of AI-generated content and the potential need for technical and legislative safeguards.

Another user raises the concern of AI meeting humans in general, calling it a scary prospect. They wonder about the technical and legal safeguards in place, comparing the situation to the manipulation of mobile apps allowing serious manipulation of presidential candidates' appearances for politics-related purposes.

The discussion also touches on the topic of celebrity endorsements in advertising and the importance of obtaining proper consent and ensuring clarity in advertising campaigns. Users mention the Lanham Act, which grants celebrities powerful tools to correct misconceptions and enforce protection against false endorsements.

Other points in the discussion include the potential for blockchain and QR codes to provide verifiable certificates of consent, questions about the purpose of meeting celebrities, and debates about the need for special testing and legal procedures in these cases.

One user argues that there is no special testing needed, suggesting that existing legal procedures should be sufficient and referencing the Lanham Act as applicable. The discussion ends with some users sharing their thoughts on the impact of AI on creative industries and financial incentives, including the potential for creative death and the discussion of what constitutes creativity.

### Unveiling Ragna: An Open Source RAG-Based AI Orchestration Framework

#### [Submission URL](https://quansight.com/post/unveiling-ragna-an-open-source-rag-based-ai-orchestration-framework-designed-to-scale-from-research-to-production/) | 44 points | by [nkaretnikov](https://news.ycombinator.com/user?id=nkaretnikov) | [11 comments](https://news.ycombinator.com/item?id=38098046)

Quansight has released Ragna, an open-source project designed to explore the use of Retrieval-Augmented Generation (RAG) based AI tools. Ragna provides an API for experimentation with different components of a RAG model, a REST API for building RAG-based web applications, and a Panel-based GUI for configuring and interacting with Large Language Models (LLMs). Ragna comes with pre-built extensions for OpenAI, MosaicML, Anthropic, and local LLMs, as well as vector databases. The RAG approach combines a retrieval model and a generative model to improve the accuracy of AI assistants in answering queries. Ragna fills a gap in the ecosystem by providing a comprehensive framework for using RAG-based AI tools.

The discussion on the submission about Quansight releasing Ragna, an open-source project focused on Retrieval-Augmented Generation (RAG) based AI tools, covered several topics. 

- One user mentioned that Ragna seems cool and shared a link to a blog post where they found issues with page numbers in a PDF document. They also highlighted that Ragna currently provides pre-built extensions for OpenAI, MosaicML, Anthropic, local LLMs, Chroma, LanceDB, and vector databases.
- Another user responded by explaining their understanding of the architecture of Ragna. They shared a diagram that illustrates the steps involved, including querying, retrieving relevant parts, and submitting queries to language models.
- In a separate comment, it was mentioned that there will be a talk about Ragna at PyData NYC 2023.
- One user mentioned that Ragna's computers and partitions are similar.
- A link to Ragna's chat and GitHub repository was shared.
- A user expressed their interest in trying Ragna for a small-scale recommendation system.
- Another user encouraged starting a discussion about Ragna on GitHub.
- There was a brief mention of comparing Ragna with Zep.
- One user congratulated the launch of Ragna.
- Lastly, a user with the handle "jffchbr" made a comment, but its content is not mentioned in the summary.

### New AWS service lets customers rent Nvidia GPUs for quick AI projects

#### [Submission URL](https://techcrunch.com/2023/11/01/new-aws-service-lets-customers-rent-nvidia-gpus-for-quick-ai-projects/) | 21 points | by [webmaven](https://news.ycombinator.com/user?id=webmaven) | [3 comments](https://news.ycombinator.com/item?id=38102012)

AWS has introduced Amazon Elastic Compute Cloud (EC2) Capacity Blocks for ML to address the high cost and limited availability of Nvidia GPUs, which are essential for running large language models. This new feature allows customers to purchase access to GPUs for a specified period, typically for AI-related tasks like training machine learning models or running experiments. Users can reserve instances with Nvidia H100 Tensor Core GPUs in cluster sizes ranging from one to 64 instances, with 8 GPUs per instance. The reservation can be made up to 8 weeks in advance for a maximum period of 14 days. Once the time frame is over, the instances automatically shut down. This feature provides customers with upfront cost certainty, allowing them to know the duration of the job, the number of GPUs required, and the associated cost. AWS benefits from being able to utilise these valuable resources and generate revenue based on supply and demand. The price for accessing these resources is dynamic and may vary depending on demand and availability. The feature is available now in the AWS US East (Ohio) region.

The discussion on this submission primarily revolves around two points. 

Firstly, one user points out that the pricing for accessing GPUs in the AWS US East (Ohio) region is quite high, especially for local zone instances in Denver. They note that the lowest-cost local zone instances start at $300 per year. However, they mention that free tier-eligible instances and global instances are available in the Denver Local Zone. Another user adds that they wish AWS would offer instances with specially optimized speaker direction for transcription purposes, as opposed to the NVIDIA card kind.

Secondly, another user highlights the potential benefit of this new AWS feature for innovation in smaller teams. They explain that having access to high-performance Nvidia H100 GPUs on an hourly basis can greatly facilitate experimentation and innovation.

---

## AI Submissions for Tue Oct 31 2023 {{ 'date': '2023-10-31T17:11:24.049Z' }}

### Norwegian ban on Meta behavioral advertising extended to entire EU

#### [Submission URL](https://www.datatilsynet.no/aktuelt/aktuelle-nyheter-2023/datatilsynets-vedtak-mot-meta-utvides-til-eueos-og-gjores-permanent/) | 417 points | by [aleksanb](https://news.ycombinator.com/user?id=aleksanb) | [227 comments](https://news.ycombinator.com/item?id=38092612)

Datatilsynet, the Norwegian Data Protection Authority, has received support from the European Data Protection Board (EDPB) in its ongoing battle against Meta (formerly known as Facebook) regarding ad-based tracking and profiling on its platforms. The EDPB has decided to make the Norwegian ban on ad-based marketing on Facebook and Instagram permanent and extend it to cover the entire European Union (EU) and European Economic Area (EEA). This decision comes after ongoing concerns about illegal tracking, surveillance, and profiling practices by Meta. The European Data Protection Board's decision serves as an instruction to the Irish Data Protection Commission to impose a permanent ban on Meta's European headquarters in Ireland. The ban will come into effect once this has been done. With over 250 million active users in the EU/EEA, Meta has repeatedly been called out for violating user privacy, and the EDPB's decision is seen as a firm stance against the company's disregard for the law. Meta has stated its intention to seek user consent for ad-based marketing in the future but has yet to make concrete changes to its practices. The Norwegian Data Protection Authority has expressed doubts about Meta's proposed consent solution, which would require non-consenting users to pay a fee. The EDPB's decision is crucial in ensuring that Meta's illegal activities are halted while the company searches for a lawful way forward.

The discussion on this submission revolves around various aspects of data privacy, Facebook's advertising practices, and the role of regulations in protecting user rights. Some users argue that Facebook and other companies track and share user data for advertising purposes, and that this violates user privacy. They also question the effectiveness of consent-based solutions proposed by Facebook. Others point out that newspapers and other media outlets engage in similar advertising behavior. One user highlights the double standards in criticizing Facebook while simultaneously participating in similar practices. There is also a discussion about the role of regulations and whether they are capable of addressing the privacy concerns raised by Facebook. Some argue that regulations are necessary to protect user rights, while others express skepticism about their effectiveness. Some users bring up alternative messaging platforms like Signal and WhatsApp, which prioritize privacy compliance.

The conversation extends to discussing job search and LinkedIn, as well as the trade-offs between privacy and the convenience offered by social media platforms. Users also debate the rights users have in exchanging their personal data for services. There is disagreement on the topic of regulation, with some arguing that it is necessary to regulate Facebook's policies and protect user privacy, while others question the validity of regulations and argue that they impede free speech and infringe on personal freedoms. Some users challenge the notion that Facebook should provide its services for free, arguing that many companies charge for services and data usage. The discussion also touches on the issue of data collection by companies and the ethical implications of monetizing personal data.

In conclusion, the discussion explores various perspectives on data privacy, the role of regulations, the practices of companies like Facebook, and the trade-offs inherent in the digital landscape.

### Microsoft has over a million paying GitHub Copilot users

#### [Submission URL](https://www.zdnet.com/article/microsoft-has-over-a-million-paying-github-copilot-users-ceo-nadella/) | 35 points | by [moonraker](https://news.ycombinator.com/user?id=moonraker) | [11 comments](https://news.ycombinator.com/item?id=38085907)

Microsoft CEO Satya Nadella announced that the number of paying customers for GitHub Copilot has increased by 40% in the September quarter compared to the prior quarter. He revealed that Microsoft has over 1 million paid Copilot users in more than 37,000 organizations around the world. Nadella also mentioned the introduction of Copilot Chat, which is already being used by companies like Shopify, Maersk, and PWC to boost developer productivity. Microsoft's integration of OpenAI's ChatGPT into its Bing search engine has resulted in over 1.9 billion chats with users. Additionally, Microsoft's Intelligent Cloud computing operations saw a revenue growth of 19% year over year, driven in part by higher-than-expected AI consumption. The company's Azure business rose 29%, with 3 percentage points coming from AI services. Nadella highlighted other uses of Copilot and AI, such as its integration with Microsoft's developer tools and Power Platform, its expansion in the healthcare industry, and its addition of generative AI to LinkedIn.

The discussion on this submission covers a range of topics related to GitHub Copilot and Microsoft's AI initiatives. Here are some key points from the comments:

1. Some users express frustration with the speed and productivity of GitHub Copilot, mentioning slow response times and back-and-forth interactions. One user indicates that they have canceled their Copilot subscription and prefer developing using Azure and OpenAI.
2. Another user highlights the potential of Copilot to generate code but mentions that it falls short when it comes to explaining complex functions or answering nuanced questions.
3. One commenter acknowledges the revenue potential of GitHub Copilot, estimating it could bring in $10 million in monthly recurring revenue. They praise Microsoft's achievement in building such a product.
4. There is a discussion about the cost and scalability of GitHub Copilot. One user suggests that unless 100 people are watching others type and quickly writing their own suggestions, the non-trivial maintenance and development costs of Copilot may not be sustainable.
5. A user cites a report claiming GitHub Copilot has heavy limitations, suggesting that $120 million in revenue might be untenable due to costs related to competitive salaries and GPU hardware.
6. A commenter brings up the issue of Microsoft's credibility, suggesting that the company has a history of misleading with its sales numbers, particularly in competitive markets.
7. This prompts a discussion about the ethics of a publicly traded company falsifying numbers, with one user implying that it may not be surprising for a company to engage in such behavior.

Overall, the comments touch on concerns about the performance and limitations of GitHub Copilot, its revenue potential, the cost scalability of the service, and skepticism regarding Microsoft's credibility in sales reporting.

### AI can diagnose type 2 diabetes in 10 seconds from your voice

#### [Submission URL](https://www.diabetes.co.uk/news/2023/oct/say-what-ai-can-diagnose-type-2-diabetes-in-10-seconds-from-your-voice.html) | 31 points | by [daoboy](https://news.ycombinator.com/user?id=daoboy) | [18 comments](https://news.ycombinator.com/item?id=38083857)

Researchers have trained an artificial intelligence (AI) model to diagnose type 2 diabetes by analyzing the voice of patients. The Canadian medical researchers used machine learning to identify 14 vocal differences between individuals with and without type 2 diabetes, including changes in pitch and intensity. The AI model, when combined with basic health data, could potentially provide remote and automatic diagnoses, lowering the cost and barriers to diabetes screening. The research team hopes that this AI technology will transform how diabetes is detected and enable more widespread screening for the condition.

The discussion on this submission revolves around the effectiveness and validity of using voice analysis to diagnose type 2 diabetes. Some users express skepticism, stating that factors like insulin resistance and vocal patterns related to being overweight are probably more indicative of diabetes than simple voice changes. They also suggest that people may not be honest when self-reporting their health conditions. 

Others provide more information about the study, stating that researchers from Klick Applied Sciences in Canada trained an AI model using 267 voice recordings of individuals living in India. The recordings were from 79 women and 113 men, with 72 participants being undiagnosed and 57 diagnosed with type 2 diabetes. Analysis of the recordings identified 14 vocal differences between the two groups. 

There is also a discussion about the accuracy of the AI model, with some users questioning the sensitivity and specificity of the model. They note that the published results did not provide detailed information on this. One user suggests that the results show a 75% accuracy rate, while others argue that this means there is still a 25% chance of misdiagnosis.

Some users express doubts about the study, pointing out its small sample size and the need for further research and replication. They also mention that voice analysis may only provide limited insights into metabolism and hearing ability related to diabetes.

In response to one user's comment about the study using BMI as a predictive model, another user clarifies that the AI model actually uses logistic regression and Naive Bayes methods rather than more advanced AI techniques. They also note that the study does not provide detailed information on the specific voice features used for analysis.

One user concludes that the study seems questionable and may not be reliable, while another states that they are a person with type 2 diabetes themselves.

### Tesla wins first US Autopilot trial involving fatal crash

#### [Submission URL](https://www.reuters.com/business/autos-transportation/tesla-wins-autopilot-trial-involving-fatal-crash-2023-10-31/) | 17 points | by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) | [12 comments](https://news.ycombinator.com/item?id=38089967)

Tesla has won its first trial in the United States over allegations that its Autopilot driver-assistant feature caused a fatal accident. The case involved a 2019 crash that resulted in the death of the vehicle's owner and serious injuries to two passengers. The lawsuit claimed that the Autopilot system caused the car to veer off the road and collide with a palm tree. However, Tesla successfully argued that the driver was at fault, as they had consumed alcohol before getting behind the wheel. This victory comes as Tesla faces multiple lawsuits and investigations related to its Autopilot technology. It also highlights the company's argument that the ultimate responsibility for incidents on the road lies with the human driver rather than the software.

The discussion on Hacker News revolves around the fairness of the trial decision and the responsibility of both Tesla and the driver in the fatal accident case. One user argues that if Tesla's marketing claims that Autopilot is self-driving, then it should also bear responsibility for accidents. Another user highlights an article that discusses the validity of the driver's blood alcohol content (BAC) and how a sudden swerving of a vehicle on the road can be a reason for collisions, even without the driver being completely intoxicated. There are also comments debating the need for verifying BAC levels and questioning the credibility of Tesla's software when it comes to ensuring driver safety. Another user raises concerns about Tesla's reliance on the human driver to handle emergencies and suggests that regulations should require more testing of autonomous systems in critical situations. In summary, the discussion covers various viewpoints on the trial, Tesla's marketing, the responsibility of the driver, the reliability of BAC measurements, and the importance of human supervision in autonomous driving technology.

---

## AI Submissions for Mon Oct 30 2023 {{ 'date': '2023-10-30T17:11:39.851Z' }}

### RedPajama v2 Open Dataset with 30T Tokens for Training LLMs

#### [Submission URL](https://together.ai/blog/redpajama-data-v2) | 216 points | by [programd](https://news.ycombinator.com/user?id=programd) | [54 comments](https://news.ycombinator.com/item?id=38077521)

Today, Together released a new version of the RedPajama dataset, called RedPajama-Data-v2. It is an open dataset containing 30 trillion filtered and deduplicated tokens from 84 CommonCrawl dumps in five languages: English, French, Spanish, German, and Italian. RedPajama-Data-v2 is the largest public dataset specifically released for training large language models (LLMs). What makes this release even more exciting is that it includes over 40 pre-computed quality annotations, allowing the community to further filter and weigh the data. The RedPajama-Data-v2 dataset aims to make it easier for LLM developers by providing a pool of web data that can serve as a base for high-quality datasets for LLM training. The dataset also includes code snippets that demonstrate how commonly used filtering rules can be implemented with RedPajama-V2. Overall, this release is a significant step towards the development of open datasets for training large language models.

The comments on this submission cover a wide range of topics related to the RedPajama dataset and language models.

One user suggests adding more features to the RedPajama dataset, such as topic modeling and extractive summarization. They also mention the importance of addressing the distribution of training data to better answer questions and provide supporting examples.

Another user points out a potential issue with the dataset, discussing the reversal curse problem where models may generate "B sn A" instead of "A's daughter."

There is a discussion about the hosting and downloading of the dataset. One user is confused about how the dataset is being released and asks for clarification. Another user explains that the dataset is being processed and filtered from CommonCrawl data and suggests contributing features or asking questions on GitHub.

There are discussions about the size and duplication of the dataset. One user points out that the RedPajama dataset is 150TB in size, and there is a debate about the redundancy and quality of the training data.

There are comments about the relevance of the dataset and the languages included. Some users express surprise at the inclusion of certain languages, while others discuss the importance of having a diverse range of languages for training language models.

There is a brief discussion about copyright infringement and the legal implications of using certain datasets. Users debate whether AI models that generate copyrighted content violate copyright laws.

Overall, the comments cover various aspects related to the RedPajama dataset, including its features, hosting, quality, relevance, and legal implications.

### Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence

#### [Submission URL](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/) | 222 points | by [Mandelmus](https://news.ycombinator.com/user?id=Mandelmus) | [329 comments](https://news.ycombinator.com/item?id=38067314)

President Biden Issues Executive Order to Advance AI Safety and Security, Protect Privacy, and Promote Equity
Today, President Joe Biden issued an Executive Order aimed at ensuring that the United States leads the way in harnessing the potential of artificial intelligence (AI) while managing its risks. The Order establishes new standards for AI safety and security, protects Americans' privacy, advances equity and civil rights, promotes innovation and competition, and strengthens American leadership in AI globally. 

One of the key actions mandated by the Order is the requirement for developers of powerful AI systems to share safety test results and critical information with the U.S. government. This will ensure that AI systems are safe, secure, and trustworthy before they are made public. Additionally, the National Institute of Standards and Technology will develop rigorous standards for extensive red-team testing of AI systems to ensure their safety. The Department of Homeland Security will apply these standards to critical infrastructure sectors and establish an AI Safety and Security Board.

The Executive Order also addresses the risks associated with using AI to engineer dangerous biological materials. Strong new standards for biological synthesis screening will be developed, ensuring that appropriate screening is carried out and potential risks exacerbated by AI are managed effectively. Furthermore, the Order aims to protect Americans from AI-enabled fraud and deception by establishing standards and best practices for detecting AI-generated content and authenticating official content.

In terms of privacy protection, the President calls on Congress to pass bipartisan data privacy legislation that safeguards Americans' privacy, especially that of children. The Order emphasizes federal support for the development and use of privacy-preserving techniques, including those that utilize AI, and directs funding towards research and development in this area. Additionally, the Order aims to evaluate and strengthen privacy guidance for federal agencies in light of AI risks and commercial data procurement.

Finally, the Executive Order addresses the potential for discrimination, bias, and other abuses in justice, healthcare, and housing resulting from irresponsible uses of AI. The Biden-Harris Administration has already taken steps to address these issues by publishing a Blueprint for a Coordinated Approach to AI, which prioritizes fairness and civil rights in the development and deployment of AI systems.

Overall, President Biden's Executive Order on AI signifies a comprehensive strategy for responsible innovation that addresses key areas of concern such as safety, security, privacy, and equity. It sets a new precedent for AI governance and aims to position the United States as a global leader in the responsible development and deployment of AI technologies.

The discussion on Hacker News revolves around different aspects of the Executive Order and its potential implications. Some users express concern about the potential for increased regulation stifling innovation, while others argue that regulation is necessary to ensure public safety and accountability. There is also a discussion about the ethics of AI development, with some users pointing out the risks associated with AI being used to create dangerous biological materials or autonomous weapons. The discussion touches on various topics, including government regulation, the role of large tech companies, the balance between innovation and safety, and the importance of privacy protection.

### Can I remove my personal data from GenAI training datasets?

#### [Submission URL](https://knowingmachines.org/knowing-legal-machines/legal-explainer/questions/can-i-remove-my-personal-data-from-genai-training-datasets) | 99 points | by [randomlogin](https://news.ycombinator.com/user?id=randomlogin) | [99 comments](https://news.ycombinator.com/item?id=38075924)

The short answer is that it is practically difficult to remove personal data from GenAI training datasets. Many GenAI products are trained on massive datasets that contain personal information scraped from popular websites, such as social media platforms and online encyclopedias. These datasets often include people's names and contact information. While some tools like "Have I Been Trained" and the earlier Exposing.ai project allow users to investigate whether their personal data is in these datasets, it is challenging to ascertain and remove personal data completely. 

Companies that create GenAI products often do not disclose the sources of their training data, making it even harder for individuals to determine if their data is included. Taking legal action or making data requests under laws like the California Consumer Privacy Act (CCPA) may be potential avenues for seeking the removal of personal data. However, companies may respond in idiosyncratic ways and further information may be required to process such requests. 

Currently, there is no foolproof method to force companies to disclose if and how much personal data has been used in training datasets. Even if companies were able to disclose and remove personal data, fully removing it from training datasets could unpredictably impact the performance of the GenAI models. The issue is being addressed by big tech players like Google, who are working on technical solutions such as the "Machine Unlearning Challenge" to protect privacy rights. However, until significant technical progress is made, companies may struggle to comply with data deletion provisions in privacy laws like the CCPA.

The discussion on Hacker News revolves around different aspects of the article. Here are some key points mentioned:

- Some users discuss the legal challenges of removing personal data from AI training datasets, highlighting the difficulties in compliance with laws like GDPR and CCPA.
- There is a debate about the expectation of privacy on the internet, with some users arguing that public postings should not be expected to remain private.
- The discussion also touches on the potential risk of misusing AI technology, such as the concern that AI models could be trained on sensitive or inappropriate content.
- Users highlight the importance of technological solutions to protect privacy rights, with some pointing out the need for better data handling practices by companies.
- There is a discussion about the potential role of legislation in regulating AI and protecting privacy, with some users expressing skepticism about the effectiveness of regulations in the face of technical challenges.
- Some users raise concerns about the power dynamics between individuals and companies, suggesting that companies should take responsibility for data privacy and make efforts to remove personal data from their AI products.

Overall, the discussion reflects a range of perspectives on the challenges and implications of removing personal data from AI training datasets and the broader issues surrounding privacy in the age of AI.

### Show HN: EnfinBref- {GPT3-5|Mistral-7B} YouTube summaries, segment by segment

#### [Submission URL](https://enfinbref.io/en/) | 21 points | by [bclavie](https://news.ycombinator.com/user?id=bclavie) | [10 comments](https://news.ycombinator.com/item?id=38077725)

Today's top story on Hacker News is a fascinating discussion on the future of artificial intelligence and its societal implications. One user shared an article that explores how AI is evolving at an unprecedented rate and what that means for humans. Are we on the verge of being outsmarted by machines? The comments are filled with thought-provoking insights from experts in the field, sparking a lively debate on the potential dangers and benefits of AI. Whether you're an AI enthusiast or simply curious about its impact on our lives, this discussion is a must-read. Dive in, and join the conversation!

The discussion on this submission revolves around segmenting videos, improving transcription, and the practical applications of AI in language processing.

- User "el_isma" suggests breaking down video segments based on specific time intervals, which could be useful for speech-to-text transcription and mastering complex tasks.
- User "zdmnsn" adds that they have tried summarizing sections of 20-40 minute French videos using section-dividing techniques and found it to be impressive.
- User "scfrnd" finds it useful to extract information from videos but mentions that sometimes the speech recognition software doesn't work efficiently.
- User "bnsystm" expresses their appreciation for local videos and asks for suggestions regarding specific scenarios and models related to video breakdowns and transcription.
- User "bclv" responds with gratitude and elaborates on different scenarios and models for video breakdowns and transcription. They also mention that their project started in 2018 but fizzled out and didn't have much success with pre-LLM implementations.
- User "bnsystm" thanks them and suggests that they should take their time and research more before fully committing to a new project.

Overall, the discussion highlights the challenges and potential applications of AI in language processing, especially in video segmentation and transcription tasks. Users appreciate the progress made so far and provide insights into the different factors to consider when implementing AI models for specific use cases.

### Google Brain founder says big tech is lying about AI danger

#### [Submission URL](https://www.afr.com/technology/google-brain-founder-says-big-tech-is-lying-about-ai-human-extinction-danger-20231027-p5efnz) | 391 points | by [emptysongglass](https://news.ycombinator.com/user?id=emptysongglass) | [390 comments](https://news.ycombinator.com/item?id=38072218)

Big Tech companies like OpenAI are using fear-mongering tactics to push for strict regulations on artificial intelligence (AI) that would ultimately stifle competition in the industry, according to Stanford University professor Andrew Ng. He argues that the idea that AI could lead to the extinction of humanity is a baseless claim being used as a ploy to promote heavy regulation. Ng believes that transparency rather than burdensome licensing requirements is what is truly needed in the AI sector. He also criticizes the regulatory capture campaign orchestrated by large tech firms to impose legislation harmful to the open-source community. While Ng agrees that some form of regulation is necessary, he emphasizes the importance of thoughtful regulation rather than arbitrary measures. Ng highlights the need for transparency from tech companies, as it would help prevent future AI disasters caused by the actions of big tech.

The discussion on the submission revolves around various viewpoints on the role of regulation and innovation in the AI industry, particularly in relation to China. Some users argue that strict regulations ensure safety and protect against intellectual property theft, while others believe that excessive regulations stifle competition and hinder small startups. There are also discussions on China's approach to innovation and its alleged practice of copying and stealing foreign designs. Some users emphasize the importance of cultural understanding in analyzing China's actions, while others highlight the need for fair and reasonable rules that align with global values. Overall, the discussion raises questions about the balance between regulation and innovation in the AI industry and the role China plays in this context.

### WebAuthn.wtf

#### [Submission URL](https://webauthn.wtf/) | 48 points | by [mooreds](https://news.ycombinator.com/user?id=mooreds) | [16 comments](https://news.ycombinator.com/item?id=38065083)

WebAuthn is an API specification that allows applications to use secure authentication methods for user registration and login. Instead of relying solely on passwords, WebAuthn enables users to authenticate themselves using hardware- or software-based authenticators. These authenticators use public-key cryptography to ensure secure registration and authentication of accounts.

With WebAuthn, users generate a public-private key pair, where the private key is stored securely on the user's device and the public key is registered with the web application server. During login, the user verifies their identity using the registered device, and the server validates the signature using the previously registered public key.

As a developer, you can utilize WebAuthn to provide your users with a more secure and user-friendly authentication mechanism. It is supported by most modern web browsers and platforms, and integration with existing authentication flows is made easier with open-source libraries and identity platforms.

In the WebAuthn world, the user's credential is the public-private key pair generated by an authenticator, rather than the traditional username and password. These credentials are commonly referred to as "passkeys." While WebAuthn is designed for single-device usage, syncing passkeys between devices is outside the scope of the specification.

To address the need for passkey syncing, large platform and operating system companies like Apple and Google have implemented their own secure channels. For example, Apple uses iCloud Keychain and Google uses Google Password Manager to sync passkeys across a user's compatible devices. This eliminates the need for a separate backup authenticator and provides a more convenient experience for users.

The discussion on this submission covers various aspects of WebAuthn and passkey syncing. Some users point out that certain password managers like 1Password, Bitwarden, and KeePassXC do not currently support WebAuthn. Others discuss the technical restrictions on authenticator attestation GUIDs and the different levels of support for WebAuthn across platforms and devices.

There are also discussions about the potential benefits and challenges of passkey syncing. Some users argue that passkey syncing can be achieved through existing platforms like iCloud Keychain and Google Password Manager, while others express concerns about the security and backup options for passkeys.

Further discussions highlight the need for better documentation and communication from the FIDO Alliance and criticize the current state of passkey implementation in various password managers. Some users mention the Linux support for passkeys and express frustration with the lack of support in Firefox.

Overall, the discussion revolves around the technical aspects and practical considerations of adopting WebAuthn and passkey syncing in different contexts.

### AI.gov

#### [Submission URL](https://ai.gov/) | 327 points | by [KoftaBob](https://news.ycombinator.com/user?id=KoftaBob) | [238 comments](https://news.ycombinator.com/item?id=38067206)

President Biden is making AI work for the American people, recognizing its potential as one of the most powerful technologies of our time. The Biden-Harris Administration has taken decisive action to protect safety and rights in the age of AI, ensuring that everyone can benefit from its promise. This includes signing an Executive Order to advance agencies' efforts on AI across the federal government and rapidly hiring talent to build and govern AI based on the administration's priorities. American students, workers, and educators are encouraged to build their AI skills to contribute to the nation's leadership in this field. Furthermore, the government is harnessing the opportunities of AI to improve its services for the public, and the National AI Advisory Committee advises the White House on AI-related issues.

The discussion on the article about President Biden's initiatives with AI focused on various aspects of government involvement in the field and its impact on the workforce.

One user pointed out that the US government often struggles with hiring and paying competitive salaries to attract top AI talent. They suggested adopting a similar model to the UK's Civil Service, which has been highly functional and effective in utilizing external consultants and contractors.

Another user mentioned the potential dangers of relying too heavily on innovation and neglecting the roles of civil servants. They emphasized the importance of balancing innovation with maintaining core government services.

The Digital Services team was also mentioned as a potential solution to improving government systems and services. However, there were concerns about the complexity and effectiveness of the Government Digital Services in the UK.

The discussion veered toward the topic of drug testing as a requirement for government jobs, with some arguing that it should not be a determining factor for employment. One user highlighted the federal legalization of marijuana and questioned the enforcement of drug testing in the workplace.

There were also mentions of issues with bureaucracy and the challenges of implementing quick changes and innovation within government structures.

Overall, the discussion touched on issues of hiring, innovation, privacy, and the role of government in shaping the AI landscape.

### Show HN: Web app to generate AI pictures with logos "hidden" in them

#### [Submission URL](https://logopictureai.com/) | 53 points | by [igorkotua](https://news.ycombinator.com/user?id=igorkotua) | [55 comments](https://news.ycombinator.com/item?id=38072074)

Introducing LogoPicture AI, the ultimate solution for creating stunning optical illusion art with your logo. No more struggling to find the perfect images for your brand – now you can easily generate captivating logo art in just a few minutes. With endless picture ideas limited only by your imagination, you'll never run out of inspiration. Even if you're feeling stuck, our AI will suggest creative ideas to get you started. Here's how it works: simply upload your logo in png or jpeg format, choose a style from our predefined prompts or create your own, and within minutes, you'll receive a collection of visually striking pictures right in your email. And the best part? It's incredibly affordable, with pricing plans starting at just $9.90 for 50 pictures. Plus, with a 7-day money-back guarantee for the Starter plan, you can try LogoPicture AI risk-free. Still have questions? Check out our FAQ section for answers to common queries. Don't wait – start generating mesmerizing logo art with LogoPicture AI today!

There is a mixed reaction to the submission of LogoPicture AI on Hacker News. Some users express skepticism about the tool, stating that people with Photoshop skills can easily create similar effects without the need for AI. Others compare it to Thomas Kinkade-style art and express doubts about its originality and quality. One user points out that there are already low-cost niche services available for image manipulation and suggests alternative tools. The pricing plans and refund policy of LogoPicture AI are also discussed, with some users expressing interest in trying the service for a lower price. The user interface and mobile optimization of the website receive criticism, while others appreciate the convenience of the predefined prompts and the ease of generating logo art. There is a brief discussion about the implementation of ControlNet and the demand for high-quality graphics. Some users mention the availability of similar tools and APIs, while others highlight the potential risks and ethical concerns of AI-generated content. Grammar issues on the website and the lack of a download feature for the generated images are also mentioned by users. The discussion concludes with users expressing varying levels of interest in trying the tool and suggesting potential improvements.

### An AI firm harvested billions of photos without consent. UK is powerless to act

#### [Submission URL](https://www.politico.eu/article/ai-ruling-obstruct-british-efforts-protect-citizens-images-us-data-harvesting/) | 42 points | by [ColinWright](https://news.ycombinator.com/user?id=ColinWright) | [17 comments](https://news.ycombinator.com/item?id=38066455)

In a recent ruling, Britain's top privacy regulator, the Information Commissioner's Office (ICO), has lost its appeal against Clearview AI, an American-based AI firm. Clearview AI came under fire in 2020 for harvesting billions of social media images without users' consent. The ICO had taken action against Clearview last year, issuing a £7.5 million fine and ordering the deletion of data of UK residents from its database. However, the recent ruling states that the ICO has no power to sanction the AI firm, leaving it unclear whether Clearview ever deleted the data. The ruling also highlights that the ICO lacks jurisdiction in the case as the data processing was carried out on behalf of foreign government agencies. The ICO is considering its next steps in response to the ruling.

The discussion on this submission covered a variety of topics related to Clearview AI and data privacy:

- One user mentioned that generally, pictures on the internet are restricted in usage and require the consent of the photographer. They also pointed out that using these pictures for training AI models could potentially infringe on copyright laws.
- Another user questioned whether it is legally acceptable for an AI program to send an explicitly reconstructed version of copyrighted images without permission.
- There was a brief tangent about copying and selling copies of Disney movies and recorded cable broadcasts without consent.
- One user highlighted the issue of the UK Information Commissioner's Office (ICO) being powerless to take action against Clearview AI, which brings into question whether the company deleted the data as ordered.
- Brexit and its impact on international trade and corporate strategy related to data privacy rights were also discussed. The user mentioned that the UK's powerless position may make it difficult to comply with international arrest warrants related to data protection laws.
- The availability of AI models like OpenAI's DALL-E, capable of generating content based on consented data, led to discussion on the potential for AI to circumvent content restrictions.
- The user pointed out that the theft of personal data by algorithms is a serious concern, given that AI systems process personal data subject to GDPR regulations.
- There was a brief comment about the idea of copying and stealing as related to the Clearview AI case.

Overall, the discussion touched on issues of consent, copyright, data privacy, international trade, and the role of AI in processing personal data.