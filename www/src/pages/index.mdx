import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Fri Sep 29 2023 {{ 'date': '2023-09-29T17:09:13.891Z' }}

### RealFill: Image completion using diffusion models

#### [Submission URL](https://realfill.github.io/) | 549 points | by [flavoredquark](https://news.ycombinator.com/user?id=flavoredquark) | [178 comments](https://news.ycombinator.com/item?id=37708292)

RealFill is a new approach for image completion that fills in missing regions with content that should have been there, based on a few reference images of the same scene. Unlike previous models that generate inauthentic content, RealFill uses personalized generative inpainting to create visually compelling and faithful completions. It can handle scenarios with different viewpoints, lighting conditions, camera settings, and image styles. RealFill outperforms existing approaches in a diverse and challenging image completion benchmark. The method involves fine-tuning a pre-trained model on reference and target images, learning the scene's contents, lighting, and style, and using the model for diffusion sampling to complete the target image. However, RealFill is slower due to the fine-tuning process and struggles with extreme viewpoint changes and challenging cases for the base model. Nonetheless, it achieves high scene fidelity compared to baseline methods. The study authors express gratitude for the valuable discussions and feedback received from various individuals and acknowledge others' contributions to the evaluation dataset.

The discussion around the RealFill image completion model on Hacker News covers a variety of topics. One user discusses the functionality of Google Photos, mentioning that while it can provide functional photos, it may struggle with historical photos. Another user suggests using compression techniques to mitigate space constraints for photo collections. Other comments touch on the manipulation and trustworthiness of photographs. Some argue that photographs have always been manipulated to some extent and that AI photo manipulation is not significantly different. However, others express concerns about the impact of AI manipulation on trust and objectivity.

There are also discussions about the potential applications of the RealFill model, including its use in film and TV post-production work, as well as the challenges of converting widescreen content to vertical formats.

Overall, the comments cover a range of perspectives on the RealFill model and its implications for image completion and manipulation.

### AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model

#### [Submission URL](https://arxiv.org/abs/2309.16058) | 38 points | by [babakd](https://news.ycombinator.com/user?id=babakd) | [4 comments](https://news.ycombinator.com/item?id=37699312)

Researchers have introduced AnyMAL, an efficient and scalable Any-Modality Augmented Language Model. AnyMAL is a unified model that can reason over diverse input modality signals such as text, image, video, audio, and IMU motion sensor data, and generate textual responses. This model inherits the powerful text-based reasoning abilities of state-of-the-art Language and Vision Models (LLMs) and converts modality-specific signals to the joint textual space. To enhance the model's capabilities, it is fine-tuned with a multimodal instruction set covering diverse topics and tasks. The researchers conducted comprehensive evaluations, including both human and automatic evaluations, and demonstrated state-of-the-art performance on various multimodal tasks. The paper, authored by Seungwhan Moon and his team, offers valuable insights into the development of powerful and versatile language models.

The discussion on this submission includes a few comments. 

One user, lsdmb, points out that people in the field of machine learning (ML) seem to have stopped caring about existing acronyms. They have seen multiple papers where ML acronyms are replaced with new, catchy acronyms. Another user, 3abiton, comments that even in the field of low-power, long-range wireless communication (LoRa), existing acronyms are also being replaced frequently. 

Another user, techbro92, jokingly suggests that they hope somebody creates a group controlling quadrupeds with a language and vision model (LLM). This comment is likely referencing the capabilities of AnyMAL and how it can reason over diverse input modalities such as text, image, video, audio, and IMU motion sensor data.

### Meta unveils Llama 2 Long AI beats GPT-3.5 Turbo and Claude 2 on some tasks

#### [Submission URL](https://venturebeat.com/ai/meta-quietly-releases-llama-2-long-ai-that-outperforms-gpt-3-5-and-claude-2-on-some-tasks/) | 36 points | by [nickthegreek](https://news.ycombinator.com/user?id=nickthegreek) | [11 comments](https://news.ycombinator.com/item?id=37710591)

Meta Platforms, the parent company of Facebook, Instagram, and WhatsApp, showcased a range of new AI features for its consumer-facing services at the Meta Connect conference. However, the biggest reveal came in the form of a computer science paper published by Meta researchers on arXiv.org. The paper introduces Llama 2 Long, an AI model that outperforms competitors like OpenAI's GPT-3.5 Turbo and Claude 2 in generating responses to long user prompts. The researchers achieved this by pretraining Llama 2 with longer training sequences and incorporating more longer text data sources. They also made modifications to the positional encoding of the model. The success of Llama 2 Long highlights Meta's commitment to open-source generative AI and its ability to compete with closed-source models from well-funded startups.

The discussion on this submission revolves around the restrictions and licensing of Meta's AI models. One user mentions that Meta's closed API-only offerings may pose a challenge for those willing to invest in them, as compared to the more open approach taken by OpenAI. Another user points out that the terms of service for Meta's models have certain restricted use cases, with limitations related to ITAR compliance and specific sensitive subjects. Another user suggests that training one's own models might be important, considering the restrictive nature of Meta's models.

There is also a discussion about the foundations of Meta's models and the popularity of open-source Language Model Libraries (LLMs). One user mentions that the foundations of Meta's models are built on popular open-source LLMs. Another user highlights the significance of open-source models by mentioning their literal code and architectural differences for implementing and training models.

A user mentions that Meta's models are subject to restrictive licensing, while another user points out that Meta's AI models are open-sourced.

The final comment simply says "pinned source," which could be a reference to the request for the source code of Meta's models.

In summary, the discussion focuses on the restricted nature of Meta's models and their licensing, as well as the importance of open-source language models and the potential challenges they pose for users.

### Farm robots inspired by ant brains

#### [Submission URL](https://techxplore.com/news/2023-09-farm-robots-ant-brains.html) | 22 points | by [wglb](https://news.ycombinator.com/user?id=wglb) | [6 comments](https://news.ycombinator.com/item?id=37706353)

Farmers have been benefiting from the rise of AI in the agriculture industry, with new farm tools revolutionizing traditional farming practices. One such innovation is the Ecorobotix, a solar battery-powered robot that navigates crop fields with GPS assistance and efficiently destroys weeds. Another example is the LettuceBot, which uses advanced scanning technology to differentiate between weeds and crops, allowing for optimal growth and reduced pesticide usage. 

Researchers from the Universities of Edinburgh and Sheffield in the UK have taken inspiration from ants to tackle the challenge of visual navigation through dense vegetation. Ants are known for their efficient organization and complex problem-solving skills, which researchers believe can be translated to robotic structures. In a recent study published in the journal Science Robotics, the researchers developed an artificial neural network that mimics the route memory abilities of ants. By collecting images along unfamiliar routes and using the neural network algorithm, the researchers achieved positive results in navigating challenging, vegetation-dense fields. 

This research holds promise for advancements in agricultural robotics, as it provides a low-power and efficient solution for navigation in complex environments. By integrating insect-inspired navigation systems into robotic tools, future applications in agriculture, forestry, and environmental monitoring could greatly benefit from this technology.

The discussion on this submission revolves around a few different topics.

One commenter, "bcx," mentions a science fiction book called "Children Time" by Adrian Tchaikovsky that explores the concept of interconnected robots that clean.

Another commenter, "lmtbt," discusses the LettuceBot and its ability to scan crop geometry and distinguish between weeds and crops, which can help with optimal growth and reduced pesticide usage. They also mention the potential for these types of tools to replace pesticides and the low energy consumption and cost associated with them.

Another commenter, "myshp," suggests that tools that replace pesticides have the potential to be more impactful in terms of biodiversity preservation. They mention the possibilities of robots selectively pruning or changing fertilizer usage, and using machine learning systems to optimize multi-crop growing patterns and minimize risk while helping maintain local ecosystems.

A commenter named "dnfx" makes a brief comment about machine learning and AI technologies being used in internal document retrieval systems.

The last comment is a humorous one, simply saying "Holy cmm splc Batman."

### UK dismisses independent AI advisory board

#### [Submission URL](https://thenextweb.com/news/uk-dismisses-independent-ai-advisory-board-alarming-tech-sector) | 60 points | by [webmaven](https://news.ycombinator.com/user?id=webmaven) | [11 comments](https://news.ycombinator.com/item?id=37704036)

The UK government has quietly dismissed the independent advisory board of its Centre for Data Ethics and Innovation (CDEI), which was tasked with promoting the responsible deployment of data and AI technologies, especially within the public sector. The board's webpage was officially shut down on September 9, but a rather uninformative public announcement was released only yesterday. This move has raised concerns among tech business founders in the UK, who worry about transparency and trust in the government and call for a new era of accountability. The government's approach to AI governance has strongly focused on mitigating existential risks, while the CDEI's work has been focusing on the actual, day-to-day uses of data and AI.

The discussion on Hacker News regarding the dismissal of the independent advisory board of the UK's Centre for Data Ethics and Innovation (CDEI) revolves around several key points:

1. Some users highlight that the CDEI's independent advisory board was dissolved, and its webpage was shut down. They express concerns about transparency and trust in the government and call for more accountability.

2. Others argue that the advisory board was never truly independent, as it was a specific government body within a specific government department. They say that it was not 100% clear and independent, but rather subject to political influence.

3. Some users point out that the UK government's approach to AI governance has largely focused on mitigating existential risks, while the CDEI's work focused on the day-to-day uses of data and AI. They suggest that the government's priorities may have played a role in the dismissal of the advisory board.

4. There is a discussion about the potential implications of this move, with some users speculating that it may reflect a shift towards a surveillance state or a lack of attention to ethical considerations in government programs.

5. Several users express disappointment about the lack of communication and transparency surrounding the dismissal of the advisory board. They note that the government's webpage for the board is closed, and there is limited information available.

6. One user mentions that the advisory board did not have access to future risk reports, implying a lack of necessary information for informed decision-making.

Overall, the discussion highlights concerns about the transparency, independence, and ethical considerations in the UK government's approach to data and AI governance.

### Show HN: SapientML – Generative AutoML for Tabular Data

#### [Submission URL](https://github.com/sapientml/sapientml) | 82 points | by [ya9do](https://news.ycombinator.com/user?id=ya9do) | [8 comments](https://news.ycombinator.com/item?id=37698506)

SapientML is an AutoML technology that can generate high-quality pipelines for predictive tasks using tabular data. It learns from existing datasets and their human-written pipelines to efficiently generate pipelines for new datasets. With SapientML, you can run AutoML, obtain and run generated code, and access a model consisting of the generated code. The technology behind SapientML is based on a research paper published at the International Conference on Software Engineering (ICSE). You can find more details and examples in the GitHub repository.

The discussion on the submission is as follows:

1. User "nwfcg" comments that they compared SapientML with other AutoML tools such as AutoGluon, FLAML, and H2O. They suggest that an independent benchmarking paper should be published to establish SapientML's superiority.
2. User "blprnv" disagrees with the assumption that SapientML is an example of AGI (Artificial General Intelligence). They express skepticism and suggest that the comment might be jumping to conclusions without relevant evidence. They apologize for the word choice in their comment.
3. User "Philpax" responds with a brief comment, stating that they wouldn't speculate on the matter.
4. User "tmhgns" explains that the reason for the generation of tabular AutoML solutions is simply due to the fact that it is a traditional approach. They mention that these systems learn from existing solutions and generate pipelines accordingly, citing a relevant research paper.
5. User "dcryn" suggests that there are already commercial offerings that outperform open-source tabular AutoML approaches, such as Datarobot, Azure AutoML, Vertex Bigquery AutoML, Alteryx, Dataiku, and SAS. They believe that if someone is starting with AutoML, commercial space has better options than open source.
6. User "nwfcg" responds that benchmarks and practical validations are needed to support claims about the superiority of commercial offerings. They mention that they haven't seen any commercial offerings outperform AutoGluon Tabular to date.
7. User "hrfrcmmnts" shares that there is a global ML Hackathon in November and they can't wait to try it.
8. User "lttrgrm" references a similar generative space caught back in 2017 and provides a link to an article. They express their astonishment at what might be happening internally within companies like Google.

### Food Delivery Robots Are Feeding Camera Footage to the LAPD

#### [Submission URL](https://www.404media.co/serve-food-delivery-robots-are-feeding-camera-footage-to-the-lapd-internal-emails-show/) | 16 points | by [giuliomagnifico](https://news.ycombinator.com/user?id=giuliomagnifico) | [3 comments](https://news.ycombinator.com/item?id=37705895)

In a surprising turn of events, it has been revealed that a food delivery robot company in Los Angeles, which delivers for Uber Eats, provided video footage filmed by one of its robots to the Los Angeles Police Department (LAPD) as evidence in a criminal case. The incident has sparked discussions about the constant surveillance that these delivery robots engage in and the potential privacy concerns associated with their use. The company, Serve Robotics, expressed an interest in working more closely with the LAPD, and the police department readily seized the opportunity. The specific incident involved an attempted theft of a Serve Robotics robot, which resulted in the arrest and conviction of the suspects. This case has shed light on the fact that delivery robots are always filming, raising questions about the extent of their surveillance capabilities and the potential implications for privacy. The deployment of such robots in urban areas has already become a contentious issue, with social media accounts documenting their presence and the challenges they pose to pedestrians and pets. While the LAPD claims that this incident is an isolated one, the use of video footage from delivery robots in criminal investigations has sparked a debate about the balance between public safety and individual privacy.

The discussion on this submission contains two comments. 

The first comment, made by user Legend2440, criticizes the headline of the article for not mentioning that the incident involving the food delivery robot company and the LAPD was a theft. The user points out that the surveillance aspect is not the main issue but rather the fact that the robots provided evidence in a criminal case.

The second comment, made by user chfrtz, labels the submission as a duplicate and provides a link to another discussion on the same topic. Another user, glmgnfc, simply thanks chfrtz for sharing the duplicate link.

Overall, the discussion in the comments section appears to be minimal, focusing on the content of the headline and providing a duplicate link.

---

## AI Submissions for Thu Sep 28 2023 {{ 'date': '2023-09-28T17:10:27.204Z' }}

### AI language models can exceed PNG and FLAC in lossless compression, says study

#### [Submission URL](https://arstechnica.com/information-technology/2023/09/ai-language-models-can-exceed-png-and-flac-in-lossless-compression-says-study/) | 74 points | by [belter](https://news.ycombinator.com/user?id=belter) | [40 comments](https://news.ycombinator.com/item?id=37691535)

Researchers from DeepMind have discovered that their large language model, Chinchilla 70B, can perform lossless compression on images and audio data, outperforming algorithms specifically designed for these tasks. In a research paper titled "Language Modeling Is Compression," the team details how Chinchilla compressed image patches from the ImageNet database to 43.4% of their original size, surpassing the PNG algorithm's compression rate of 58.5%. For audio data, Chinchilla achieved a compression rate of 16.4% compared to FLAC compression at 30.3%. This finding suggests that language models like Chinchilla can be used not only for text prediction and writing but also for effectively compressing various types of data. The relationship between compression and intelligence is a topic of ongoing debate and research.

The discussion around the submission on Hacker News covers various points related to the findings of the DeepMind research paper titled "Language Modeling Is Compression."

- Users discuss the surprising results of Chinchilla 70B, a large language model, outperforming specialized compression algorithms for image and audio data compression.
- Some commenters mention that language models like Chinchilla can generalize and compress different types of data beyond text, which suggests practical applications for large-scale compression.
- There is a discussion about the benefits of distributed compression and the use of distributed hash tables for file sharing.
- One user suggests that the Chinchilla model may be beneficial for compressing small subsets of larger dictionaries.
- The relationship between language modeling and compression is explored, with comments noting the role of probability modeling and entropy coding in compression algorithms.
- There is further discussion on the efficiency of different compression methods, including the usage of lookup tables and specific algorithms like LZW for PNG compression.
- Some users speculate on the potential benefits and limitations of using large language models for compression, especially in relation to network connections and device limitations.
- The topic of information compression in AI language models and the need for mathematical proofs and algorithms specifically tailored to these models is brought up.
- Commenters discuss the historical relevance of mathematicians and computer scientists in finding exact mathematical relationships for specific compression algorithms.
- The potential approach of starting with simple compression algorithms and language models and iteratively improving and exploring mathematical bounds is mentioned.
- The importance of incremental research and the role of mathematicians in finding exact mathematical relationships is noted.

Overall, the discussion touches upon the surprising findings of the research paper and explores various aspects related to the use of language models for compression and the mathematical foundations behind them.

### RZK: Experimental proof assistant for synthetic ∞-categories

#### [Submission URL](https://github.com/rzk-lang/rzk) | 58 points | by [adamnemecek](https://news.ycombinator.com/user?id=adamnemecek) | [43 comments](https://news.ycombinator.com/item?id=37692166)

Introducing rzk: An Experimental Proof Assistant for Synthetic ∞-Categories

rzk is an experimental proof assistant based on a type theory for synthetic ∞-categories. Built as a way to bring Riehl and Shulman's 2017 paper to life, rzk aims to implement a proof assistant capable of checking various formalizations. It currently offers an online playground for testing, with larger formalizations available in related projects. The implementation uses a version of second-order abstract syntax and aims to support dependent type inference in the future. An important component of rzk is a tope layer solver, which functions as a theorem prover for a part of the type theory. Additionally, rzk plans to incorporate a project called simple-topes, which supports user-defined cubes, topes, and tope layer axioms. This expansion will allow for formalizations of cubical, globular, and other geometric versions of HoTT. For smaller formalizations, users can utilize the online playground, while larger and multi-file formalizations can be installed locally using the latest stable or development version of rzk. There is also a VS Code extension available on the Marketplace for syntax highlighting and other features.

The submission is about rzk, an experimental proof assistant for synthetic ∞-categories. The discussion on Hacker News includes various comments discussing the topic. Some users discuss the implementation and features of rzk, while others discuss category theory and its relevance to computer science and mathematics. There is also a mention of the influence of category theory on programming languages like Haskell and the connection between category theory and the development of modern programming languages and libraries.

---

## AI Submissions for Wed Sep 27 2023 {{ 'date': '2023-09-27T17:10:34.705Z' }}

### Show HN: Carton – Run any ML model from any programming language

#### [Submission URL](https://carton.run) | 174 points | by [vpanyam](https://news.ycombinator.com/user?id=vpanyam) | [47 comments](https://news.ycombinator.com/item?id=37682286)

Carton is an open-source API that allows you to run any machine learning (ML) model from any programming language. It provides a single API for all frameworks, making it easy to work with models regardless of the language you're using.

The process starts by packing your model with Carton. This involves wrapping your model with some metadata and putting it in a zip file. Importantly, Carton doesn't modify the original model, avoiding error-prone conversion steps. You just need to specify the framework and the required version, and Carton takes care of the rest.

Once your model is packed, you can load it using Carton. The API reads the metadata included in the packed model to determine the appropriate "runner" to use. If needed, Carton automatically fetches the right runner. A runner is a component of Carton that knows how to run a model with a specific version of an ML framework.

With your model loaded, you can then run inference using Carton's framework-agnostic API. Your application calls into Carton, which in turn calls the underlying framework to execute the model. Carton is implemented in Rust with bindings to several languages, all using the same optimized core.

Carton has been designed with performance in mind. Most of its code is implemented in optimized async Rust, resulting in low overhead. Preliminary benchmarks show that the overhead per inference call is less than 100 microseconds. Furthermore, the Carton team is actively working on further optimizing the system with improved use of Shared Memory, which will bring overhead levels even lower for models with large inputs.

In terms of platform support, Carton currently works on x86_64 Linux and macOS, aarch64 Linux (e.g., Linux on AWS Graviton), aarch64 macOS (e.g., M1 and M2 Apple Silicon chips), and WebAssembly (though for now, only metadata access is supported, with WebGPU runners coming soon).

So why should you use Carton instead of directly using frameworks like Torch or TensorFlow? Carton decouples your inference code from specific frameworks, treating them as implementation details. This allows you to easily keep up with the cutting-edge developments in the ML field. Additionally, while ONNX converts models, Carton wraps them, using the underlying framework to execute the model. This makes it easy to use custom operations, TensorRT, and other framework-specific features without making changes. Carton aims to support ONNX models in the future, enabling even more use cases, such as running models in the browser with WebAssembly (WASM).

In summary, Carton provides a convenient and efficient way to run ML models from any programming language. Its framework-agnostic API, optimized performance, and support for multiple platforms make it a powerful tool for ML deployment and experimentation.

The discussion surrounding the submission on Hacker News covers various aspects of the Carton API. Here are some key points from the comments:

- Some users mentioned other tools and frameworks that can be used for running machine learning (ML) models, such as Docker, Nvidias Triton, TensorFlow Java support, and ONNX.
- There was a discussion about the benefits of using Carton over directly using frameworks like PyTorch or TensorFlow. Carton provides a framework-agnostic API, making it easier to keep up with developments in the ML field. It also allows the use of custom operations and framework-specific features without modification. It was noted that Carton aims to support ONNX models in the future.
- Users asked about platform support, with some expressing interest in Windows support. The current platforms supported by Carton include x86_64 Linux and macOS, aarch64 Linux, aarch64 macOS, and WebAssembly.
- The performance of Carton was discussed, with preliminary benchmarks showing low overhead per inference call. The Carton team is actively working on further optimizing the system.
- Some users raised questions about the use of zip files for packaging models, noting that other container formats like Docker or compressed files could be more suitable.
- There were discussions about the challenges of running ML models and the benefits of using containerization technologies.
- There was interest in the potential use of Carton for running ML models on GPUs, and the Carton team acknowledged the importance of GPU support.
- The idea of implementing Carton in different programming languages was mentioned, with Python and Rust being the most commonly discussed options.
- Some users expressed skepticism or questioned the novelty of the Carton API.

Overall, the discussion revolved around the capabilities, performance, platform support, and potential use cases of the Carton API, with users sharing their thoughts and asking questions about its features and advantages.

### ZipPy: Detect AI-generated text quickly via compression ratios

#### [Submission URL](https://github.com/thinkst/zippy) | 24 points | by [makeworld](https://news.ycombinator.com/user?id=makeworld) | [3 comments](https://news.ycombinator.com/item?id=37682872)

The ZipPy project by thinkst aims to detect AI-generated text using compression ratios. The idea is to measure the perplexity of a text by calculating the compression ratios using LZMA or zlib compression algorithms. The project explores the use of compression as an approximate method for detecting low-perplexity text, which could indicate AI-generated content. By comparing the compression ratios of a seed corpus of AI-generated text to that of the sample text, the project can determine if the sample text closely resembles AI-generated content.

1. One commenter, "bstwhz," believes that detecting single blob text generated by AI is practically impossible. They suggest that a practical approach would be to determine multiple blobs of text and compare them to AI-generated content. They give the example of AI-generated student training reports that may have similar topics or prompts, making it possible to detect statistical similarities. However, they point out that an AI detection system might not be effective in detecting cheating, as it may mistake multiple students rephrasing report content for cheating.
2. Another commenter, "kj," states that this is a clever solution but warns about Goodhart's Law. They argue that if this becomes a widely used measure, AI text generators will optimize their output to pass this specific test, making it less reliable.
3. "bArray" suggests that AI-generated student reports have the potential to completely fool human markers. They mention the example of copying paragraphs from different sources, resulting in an extensive and diverse report that can be generated in a short amount of time, making it challenging to investigate for plagiarism.

### First Impressions with GPT-4V(ision)

#### [Submission URL](https://blog.roboflow.com/gpt-4-vision/) | 361 points | by [zerojames](https://news.ycombinator.com/user?id=zerojames) | [316 comments](https://news.ycombinator.com/item?id=37673409)

OpenAI has announced the rollout of two new features for its GPT-4 model: the ability to ask questions about images and to use speech as an input to a query. This marks GPT-4's move into being a multimodal model, similar to Bing Chat and Google's Bard model. In a guide, two individuals share their first impressions with GPT-4V's image input feature and run a series of experiments to test its functionality. They test visual question answering, optical character recognition (OCR), and math OCR. Overall, GPT-4V performs well in understanding context and relationships in images, but it does make some mistakes. It also excels at OCR tasks, accurately identifying text in images. These experiments highlight the capabilities and limitations of GPT-4V.

The discussion on the submission revolves around the topic of AI interfaces and their potential to replace traditional user interfaces (UIs). Some users argue that AI interfaces have the potential to improve productivity and efficiency, especially for repetitive tasks. Others point out that AI interfaces may not always be the best option and that current UIs have their own benefits and advantages. There is also a discussion about the limitations of AI in controlling physical systems and the challenges of designing AI interfaces for complex tasks. Additionally, there are discussions about the importance of human skill in complementing AI and the need to specify goals rather than just specifying tasks for machines. Some users express concerns about the limitations and potential risks of AI interfaces.

### Workers AI: Serverless GPU-powered inference

#### [Submission URL](https://blog.cloudflare.com/workers-ai/) | 248 points | by [jgrahamc](https://news.ycombinator.com/user?id=jgrahamc) | [90 comments](https://news.ycombinator.com/item?id=37674097)

Cloudflare has launched Workers AI, an AI inference as a service platform that allows developers to run AI models with just a few lines of code. The platform runs on Cloudflare's global network of GPUs, providing developers with off-the-shelf models that can be easily deployed. Workers AI is designed to be accessible to all developers, working seamlessly with Cloudflare's existing offerings as well as being platform-agnostic. The initial release includes a curated set of popular, open-source models for tasks such as text generation, automatic speech recognition, translation, text classification, image classification, and embeddings. Cloudflare plans to expand the platform based on community feedback and has also announced a partnership with Hugging Face to offer a subset of their catalog directly within Workers AI. With Workers AI, developers can easily integrate AI capabilities into their applications, regardless of their preferred stack or framework. The platform aims to provide a seamless and frictionless developer experience, allowing developers to go from zero to production quickly and easily.

The discussion on Hacker News revolves around several key points regarding Cloudflare's Workers AI platform. 

One commenter highlights the potential benefits of serverless solutions for AI inference, noting that it could lead to faster turnaround times and reduced costs compared to persistent GPU instances. However, there are concerns raised about potential delays and compatibility issues with serverless solutions.

Another commenter brings up the compatibility of WebGPU, stating that it is not widely supported yet but has the potential to improve the user experience and reduce deployment costs.

There is also discussion about the practical implications of Cloudflare's pricing based on neuron context, with one commenter not fully understanding how pricing is determined based on character count and neuron quantities.

The conversation then shifts to the limitations of serverless functions and the potential challenges in using them for speech-to-text applications.

The topic of pre-loaded models and the ability to use one's own models is brought up, with one user suggesting that the ability to load custom models would make the platform more versatile.

There is also discussion about the pricing and potential cost savings of serverless AI inference, as well as the integration of Cloudflare's Workers AI platform with Hugging Face's models.

Other topics touched upon include the usage of GPUs for AI models, the relationship between neural time units and computational time units, and the importance of documentation in the development process.

Overall, the discussion highlights both the excitement and the questions surrounding Cloudflare's Workers AI platform, with users discussing various technical aspects and potential use cases.

### Be My Eyes’ AI assistant starts rolling out

#### [Submission URL](https://www.bemyeyes.com/blog/announcing-be-my-ai) | 261 points | by [hubraumhugo](https://news.ycombinator.com/user?id=hubraumhugo) | [150 comments](https://news.ycombinator.com/item?id=37673300)

Be My Eyes, the platform that connects volunteers with blind and low-vision users to assist with everyday tasks, is introducing its AI assistant, Be My AI. The AI assistant, powered by GPT-4, is now entering an open beta phase for iOS users and will be rolled out to hundreds of thousands of Be My Eyes users worldwide in the coming weeks. Users can access and use Be My AI by opening the Be My Eyes app and clicking on the 'Be My AI' tab to take a picture and receive a detailed description from the AI. Be My AI can also answer questions and provide additional information. However, if the AI can't answer a question, users can still connect with human volunteers. Be My AI is designed to provide quick visual assistance 24/7, making it useful for situations where users need a quick solution or prefer not to talk to another person. The AI can provide information in 29 languages and offers a new way for deaf-blind users to access information using a braille display. While Be My AI has various applications, it does not replace mobility aids like white canes or guide dogs for safe travel. The platform aims to make the world more accessible for people who are blind or have low vision, and the introduction of Be My AI is a significant step towards achieving that goal.

The discussion on this submission revolves around the introduction of Be My Eyes' AI assistant, Be My AI. Some commenters point out that while AI assistance can be helpful in certain situations, it should not replace human volunteers entirely. They argue that calling human volunteers multiple times a day can be bothersome and time-consuming. However, others express frustration with the idea of AI replacing human interaction and believe that calling human volunteers is a more satisfying experience. There is also a discussion about the potential limitations and risks of relying solely on AI for visual assistance, such as the inability to understand complex situations or perceive physical dangers. Some commenters mention the importance of responsible AI use, particularly in areas like scanning medications or reading instructions where safety issues could arise. Overall, the debate revolves around finding the right balance between AI assistance and human volunteers, taking into consideration the limitations and potential risks associated with AI.

### New AI experiences across our family of apps and devices

#### [Submission URL](https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/) | 41 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [17 comments](https://news.ycombinator.com/item?id=37678431)

Meta, formerly known as Facebook, has announced new AI features and tools across its platforms. Users will soon be able to generate customized AI stickers for their chats and stories, with the technology turning text prompts into unique stickers. Image editing features called Restyle and Backdrop will also be introduced on Instagram, allowing users to transform their images using AI-generated visual styles or change the background. In addition, Meta AI, an advanced conversational assistant, will be available on WhatsApp, Messenger, and Instagram, as well as on Ray-Ban Meta smart glasses and Quest 3. It can provide real-time information and generate images based on text prompts. Meta is also introducing 28 more AIs with unique personalities that users can interact with on its platforms. These AI features aim to enhance connections and enable new forms of creativity and expression. Safeguards have been implemented to address the challenges posed by these AI experiences.

The discussion surrounding Meta's new AI features and tools on Hacker News has covered various perspectives and concerns.
- One user commented that the customizable AI stickers and AI-generated image editing features seem like fun additions, but they suspect that the generated stickers will largely be indistinguishable from manually created ones, and there may be a risk of AI-generated stickers flooding conversations.
- Another user expressed skepticism about the idea of creating AI personalities for user interaction, noting that licensed personalities like Kendall Jenner and Tom Brady wouldn't consent to their AI representations.
- A discussion arose about the uncertain nature of AI development and its potential risks. One user mentioned an image model that generates false images, while another user brought up the possibility of creating AI characters resembling Paris Hilton for detective play, suggesting potential misuse.
- The conversation shifted towards the need for proper regulation and ethical considerations in AI development. One user mentioned the importance of addressing short-term AI developments and the success of controlling hyper-scale AI agents. They believed that startups and competitors could have a say in shaping regulations.
- Some users discussed Meta's AI efforts in comparison to other companies like Google and the potential for interesting collaborations and models.
- There were concerns raised about the risks of AI-generated messages being inaccurate or inappropriate. One user sarcastically expressed their fear of AI leading to the start of SkyNet and AI-generated stickers dominating search results. They also mentioned concerns about AI accounts on Facebook and the need for better protection against inappropriate content.
- The discussion touched on the responsibility of platforms like Facebook in handling AI and ensuring safeguards to protect users, particularly children. One user suggested that Facebook's moderation efforts could be seen as wasteful and called for better measures to address the issue.

Overall, the discussion covered a range of perspectives, from excitement about new creative tools to concerns about AI misuse and the need for responsible development and regulation.

### We try out the first legal level 3 automated driving system in the US

#### [Submission URL](https://arstechnica.com/cars/2023/09/mercedes-benzs-level-3-autonomous-driving-system-takes-over-in-heavy-traffic/) | 81 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [66 comments](https://news.ycombinator.com/item?id=37674640)

Mercedes-Benz is set to release its Drive Pilot system, which will be available on the 2024 S-Class and EQS sedans. It is the first level 3 automated driving system approved for use in the US, but initially it will only be available and active in California and Nevada. Drive Pilot allows for hands-free highway driving and also allows the driver to take their eyes off the road. There are, however, several conditions that need to be met before the system can be activated, including a speed limit of 40 mph, a vehicle in front to follow, detectable lane markings, and a pre-mapped route. The system is designed for heavy stop-and-go traffic but not for free-flowing highways. Mercedes-Benz plans to increase the speed limit in the future.

The discussion on this submission revolves around the liability and insurance implications of Mercedes-Benz's Drive Pilot system. Some users express concern about who would be responsible in the event of an accident and whether insurance companies would cover the damages. There are also discussions about the regular insurance coverage for self-driving vehicles and the potential for lower insurance costs. Some users mention Volvo's responsibility claims in relation to their autonomous driving systems. Another topic of discussion is the limitations of Drive Pilot, such as its inability to handle sharp corners and low-quality lane markings. There are also mentions of the target market for this system, with some users suggesting that wealthy individuals who enjoy driving would be more interested in purchasing luxury vehicles like the S-Class. The impact on traffic congestion is also brought up, mentioning that users who frequently encounter highway congestion may not be the target market for this system. The discussion touches on various factors such as climate and local congestion conditions that may affect the effectiveness of Drive Pilot.

### My Books Were Used to Train Meta’s Generative AI. Good

#### [Submission URL](https://www.theatlantic.com/technology/archive/2023/09/books3-database-meta-training-ai/675461/) | 28 points | by [sherilm](https://news.ycombinator.com/user?id=sherilm) | [10 comments](https://news.ycombinator.com/item?id=37679514)

The Atlantic recently released a searchable database of tens of thousands of books that were used without permission to train Meta's AI language model. This revelation has sparked outrage among well-known authors who were unaware that their work was being used. However, author Ian Bogost found himself surprisingly unaffected when he discovered that three of his books appeared in the database. He questions whether the outrage is justified and argues that authors should embrace the unpredictable ways in which their work can be used. While Meta's behavior may be legally questionable, the concept of permission in the realm of art is complex. Bogost suggests that internet culture's emphasis on permission may limit the potential interpretations and uses of creative works. Furthermore, the release of the Books3 database was intended to empower grassroots AI projects, giving ordinary people more control over the future of technology. The situation raises larger questions about the nature of theft, innovation, and liberation in the internet age.

The discussions surrounding the submission revolve around various perspectives on the use of books without permission to train Meta's AI language model.

- User "sklld" highlights that the Atlantic missed some recent stories focusing on specific cases and generalizations, indicating that the database had a limited scope.
- User "DistractionRect" adds that the archived version of the website contains some funky stuff, but DNS changes would need to be made to respond to requests.
- User "jstnclft" points out that the provided link is not working for them and mentions their location in Australia as a potential reason for the difference.
- User "frjzz" argues that books should be licensed for what they are, suggesting that authors should be compensated for their work.
- User "wffltwr" believes that AI creators should respect the concept of Commons, emphasizing the exchange of ideas and knowledge. They mention examples like billboards, handballs, and novels in public libraries as knowledge shared without individual permission.
- User "JambalayaJim" argues that models are not treated legally the same way humans are and that licensing is necessary for derived model outputs. They dismiss the idea of theft and emphasize the importance of paying for content when necessary.
- User "frjzz" responds by pointing out that stop signs are not copyrightable and that not all music requires payment to listen to it. They also challenge the assumptions made about inherent rights of AI models.
- User "rxpp" agrees with the previous comment and suggests that paying for content is a way to invest more in communities that create it.

Overall, the discussion encompasses various viewpoints on the use of book content for AI training and the complexities surrounding permission, compensation, and the nature of AI models in relation to human creativity.