import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Tue Aug 29 2023 {{ 'date': '2023-08-29T17:10:56.808Z' }}

### Meta AI releases CoTracker, a model for tracking any points (pixels) on a video

#### [Submission URL](https://co-tracker.github.io/) | 297 points | by [crakenzak](https://news.ycombinator.com/user?id=crakenzak) | [77 comments](https://news.ycombinator.com/item?id=37314073)

Researchers from Meta AI and the Visual Geometry Group at the University of Oxford have introduced a new video motion prediction method called CoTracker. Unlike existing methods that either track points independently or estimate motion jointly using optical flow, CoTracker simultaneously tracks multiple points throughout an entire video. It incorporates ideas from both optical flow and tracking literature and utilizes a transformer network to model the correlation between different points over time. The architecture can be applied to long videos by using a sliding-window approach. CoTracker outperforms state-of-the-art point tracking methods in terms of efficiency and accuracy. The researchers provided visualizations comparing CoTracker with other methods, demonstrating its ability to produce cleaner and more accurate trajectories, particularly in handling occlusions.

The discussion surrounding the submission on Hacker News covers a variety of topics related to the use of AI in business and the implications of the CoTracker video motion prediction method. Some users express their skepticism about the business relevance of AI research, while others discuss the potential benefits and challenges of using AI for content creation in virtual reality (VR) environments. The conversation also touches on issues regarding leadership and strategy in AI development, with some users questioning the integrity and intentions of Mark Zuckerberg. Other topics include Meta's revenue, the importance of attracting AI talent, the use of tracking algorithms in VR, and the justification of Facebook's open-source initiatives.

### Automatic Generation of Visualizations and Infographics with LLMs

#### [Submission URL](https://microsoft.github.io/lida/) | 172 points | by [monkeydust](https://news.ycombinator.com/user?id=monkeydust) | [50 comments](https://news.ycombinator.com/item?id=37305240)

LIDA is an automated tool for generating visualizations and infographics from data, and it is now open source on GitHub. This tool uses large language models (LLMs) and image generation models (IGMs) to understand the semantics of data, enumerate visualization goals, and generate visualization specifications. LIDA consists of four modules: a summarizer, a goal explorer, a visgenerator, and an infographer. It supports any programming language or visualization grammar and provides a Python API and a hybrid user interface for interactive chart, infographic, and data story generation. LIDA can summarize data, explore visualization goals, generate visualizations in any grammar, and create stylized infographics. It also offers operations on existing visualizations, such as explanation, self-evaluation, repair, and recommendation. However, LIDA may not work well with visualization grammars that are not well represented in the LLM's training dataset. The performance is also dependent on the choice of visualization libraries and the degrees of freedom granted to the model. LIDA currently requires code execution, so a sandbox environment is recommended to ensure safe execution. LIDA is built using large language models and image generation models. The research paper on LIDA has been accepted at the 2023 ACL Conference. You can try out LIDA locally on your own data now that it is open source on GitHub.

The discussion around the submission revolves around various aspects of LIDA, the automated tool for generating visualizations and infographics from data.

- Some users express their frustration with using Excel for data analysis and mention the usefulness of PivotTables.
- There is a discussion about the limitations of LIDA, including its dependence on the training dataset and choice of visualization libraries.
- One user shares a link to a blog post on data visualizations using Python and mentions the limitations of chartjunk.
- The conversation also touches on the potential commercial applications of LIDA and the ethical implications of using large language models (LLMs) in business models.
- Some users express their interest in LIDA and its potential applications, while others discuss the challenges of training LLMs and the difficulty of understanding the underlying algorithms.
- There is a brief discussion about the comparison between GPT and matplotlib in terms of generating charts.
- Users also discuss the relevance and limitations of LLM-based prompts for generating data descriptions and field names.
- The conversation raises concerns about the interpretability and accountability of LLMs in generating charts and the need to ensure data accuracy.

Overall, the discussion explores both the potential benefits and challenges of using LIDA and LLMs for data visualization. It highlights the need for further research and consideration of ethical and practical implications.

### Pentagon Wants to Buy 1,000s of Small, Cheap, Autonomous Drones in Next 2 Years

#### [Submission URL](https://www.airandspaceforces.com/pentagon-replicator-small-cheap-autonomous-drones/) | 43 points | by [mikece](https://news.ycombinator.com/user?id=mikece) | [23 comments](https://news.ycombinator.com/item?id=37312723)

The Pentagon has announced a new initiative called the "Replicator Initiative" that aims to build up mass with inexpensive autonomous systems within the next 18-24 months. Deputy Secretary of Defense Kathleen Hicks stated that the goal is to have "small, smart, cheap, and many" attritable, autonomous systems that can be changed, updated, or improved with shorter lead times. The driving force behind this initiative is the concern about the size of China's military. The Pentagon wants to counter China's mass with its own mass, but in a more agile and harder-to-hit manner. The specific details of the systems under the Replicator Initiative have not been disclosed in order to not tip off Beijing, but Hicks emphasized that the approach will be responsible and ethical. The initiative will likely use commercial technology to quickly scale up production. The Pentagon has previously sent drone capabilities to Ukraine as part of aid packages, indicating the importance and need for mass in modern armed conflicts. Experts welcome the high-level focus on autonomous technologies and the urgency expressed by the Pentagon in countering China.

The discussion on this submission revolved around various aspects of military strategy, the capabilities and effectiveness of drones, and the potential risks and implications of autonomous systems in warfare. Some users compared the Pentagon's initiative to the tactics used by Russia and suggested scattering swarms of drones as a destructive and dangerous approach. Others pointed out the importance of protecting civilian lives and raised concerns about the prioritization of military resources over civilian needs. One user mentioned the potential advantage of using AI death squads against enemy swarms, while another made a reference to a video game. Discussions also touched on the challenges of supply chain management and the disposable nature of drones. Some users expressed skepticism about the hype surrounding drones and questioned the relevance of this news in relation to previous developments in drone technology. Links to relevant articles and videos were also shared by users.

### AlloyDB AI: Generative AI applications with PostgreSQL

#### [Submission URL](https://cloud.google.com/blog/products/databases/helping-developers-build-gen-ai-apps-with-google-cloud-databases) | 85 points | by [jerryjerryjerry](https://news.ycombinator.com/user?id=jerryjerryjerry) | [29 comments](https://news.ycombinator.com/item?id=37312502)

Google Cloud has announced AlloyDB AI, a set of integrated capabilities built into AlloyDB for PostgreSQL. The goal is to help developers build performant and scalable generative AI applications using their operational data. AlloyDB AI provides built-in support for vector embeddings, allowing users to easily transform their data into vector embeddings with a simple SQL function. It also runs vector queries up to 10 times faster than standard PostgreSQL. Integrations with the open-source AI ecosystem and Google Cloud's Vertex AI platform provide an end-to-end solution for building generative AI applications. AlloyDB AI is currently in preview and will be launched later this year.

The discussion on this news submission revolves around various aspects of the Google Cloud announcement of AlloyDB AI. Some users discuss the application of vector databases and the use of vector similarity searches to match products and taxonomies. There are also mentions of using GPU for semantic search and the availability of a downloadable version for preview.

One user mentions that AlloyDB is similar to AWS's Aurora DB, and others discuss architectural comparisons between AlloyDB, Aurora, and Google Cloud SQL. The potential implications of AlloyDB AI and the concerns of embracing, extending, and extinguishing (EEE) strategies are also brought up.

There are discussions about the compatibility of AlloyDB with PostgreSQL and the potential impact of its EEE approach on the open-source community. Some users express reservations about Google's track record of dropping projects.

### Duet AI for Google Workspace Now Available

#### [Submission URL](https://workspace.google.com/blog/product-announcements/duet-ai-in-workspace-now-available) | 139 points | by [meetpateltech](https://news.ycombinator.com/user?id=meetpateltech) | [68 comments](https://news.ycombinator.com/item?id=37306530)

Google has announced the general availability of Duet AI for Google Workspace, a real-time collaboration tool powered by artificial intelligence (AI). The tool, which has already been used by thousands of companies and over a million testers, acts as a coach, inspiration source, and productivity booster. Duet AI can automate tasks like creating presentations based on relevant content, generating meeting summaries and action items, and capturing notes and video snippets. It also includes features such as studio-quality video and sound in Google Meet, automatic translated captions, and enhanced chat capabilities in Google Chat. Google emphasizes that user privacy and data security are prioritized, with users having control over their data and interactions with Duet AI being private.

The discussion on Hacker News revolves around various aspects of Google's announcement of Duet AI for Google Workspace. Some users express surprise at Google's decision to label it as "general availability" instead of a typical feature rollout. Others discuss the complexity of the Google Workspace subscription process and the potential pricing options for Duet AI. There are also comments about the functionality of Duet AI, comparing it to existing tools like Slack and Microsoft Teams. The conversation touches on the availability of Duet AI for existing Google Workspace customers and the competitive landscape with OpenAI's GPT products. Some users also share their experiences with similar AI-powered tools and express their skepticism or excitement about the new offering.

### FDA schedules meeting to establish regulatory rules for artificial womb trials

#### [Submission URL](https://www.fda.gov/advisory-committees/advisory-committee-calendar/pediatric-advisory-committee-meeting-announcement-09192023) | 56 points | by [apsec112](https://news.ycombinator.com/user?id=apsec112) | [92 comments](https://news.ycombinator.com/item?id=37308675)

The FDA has announced that the Pediatric Advisory Committee will be meeting on September 19-20, 2023 to discuss the development plans for artificial womb technology (AWT) devices. The committee will specifically focus on the safety and effectiveness of AWT as an alternative to standard-of-care management for extremely premature infants in the Neonatal Intensive Care Unit. The meeting will include discussions on regulatory and ethical considerations for first in human (FIH) studies. On September 20, the meeting will be closed to allow for the review of trade secret and confidential commercial information. Interested parties can participate in the meeting and submit comments until September 18, 2023 by following the instructions provided by the FDA.

The discussion around the submission revolves around various aspects of artificial womb technology and its implications. Some commenters raise concerns about the ethical and legal implications of using artificial wombs, particularly in relation to fetal viability and abortion laws. Others discuss the potential market demand for artificial wombs and the financial implications for parents. There are also discussions about the regulatory efforts and trials related to artificial womb technology. The conversation touches on topics such as surrogacy, the rights of unborn children, and the varying definitions of personhood and legal rights across different states.

### US Air Force wants $6B to build 2k AI-powered drones

#### [Submission URL](https://www.theregister.com/2023/08/29/us_airforce_drones/) | 29 points | by [LinuxBender](https://news.ycombinator.com/user?id=LinuxBender) | [22 comments](https://news.ycombinator.com/item?id=37309006)

The US Air Force is seeking approval for a $5.8 billion budget to build up to 2,000 AI-powered drones to serve alongside human pilots. The drones, called the XQ-58A Valkyrie, are designed to be significantly cheaper than crewed fighter jets, with a cost of around $3 million each. The Air Force envisions the drones performing a range of roles, including surveillance, resupply operations, and fighting alongside human pilots as part of a swarm. The drones will recommend actions to human operators, who will still make the final decision to drop bombs or fire missiles. The project is part of the Air Force's efforts to develop "Collaborative Combat Aircraft" to achieve air superiority. Congress must approve the five-year effort, with $3.03 billion required in FY 2028 alone.

The discussion around the submission focuses on various aspects of the US Air Force's plan to build AI-powered drones. Some users express concern about the use of AI in military operations, particularly the possibility of drones carrying weapons and the potential ethical implications. Others discuss the cost-effectiveness of the drones compared to crewed fighter jets and the potential for large-scale conflicts. There is also a mention of the parallel between the Air Force's drone project and Google's language models for robots. Additionally, the conversation touches on related topics such as robotic warfare, military surveillance, and the impact of AI on global politics. One user brings up the Skynet program from the Terminator franchise as a reference. The discussion ends with a comment about the budget for national defense and logistics spending.

---

## AI Submissions for Sun Aug 27 2023 {{ 'date': '2023-08-27T17:10:30.576Z' }}

### A study on robustness and reliability of large language model code generation

#### [Submission URL](https://arxiv.org/abs/2308.10335) | 168 points | by [floridsleeves](https://news.ycombinator.com/user?id=floridsleeves) | [207 comments](https://news.ycombinator.com/item?id=37287591)

A recent study conducted by Li Zhong and Zilong Wang examines the robustness and reliability of large language model (LLM) code generation. LLMs, known for their ability to understand natural language and generate programming code, are often consulted by software engineers for coding questions. However, the study highlights the potential problems that can arise from the misuse of APIs in the code generated by LLMs. The researchers collected coding questions from StackOverflow on 24 representative Java APIs and evaluated them on popular LLMs. The results show that even with GPT-4, 62% of generated code contained API misuses, which could lead to unexpected consequences when introduced into real-world software. The study calls for more attention to be given to the reliability and robustness of LLM-generated code, especially considering the vulnerability of novice developers who rely on these services.

The discussion on Hacker News regarding the study on reliability issues with large language model (LLM) code generation covers several different perspectives and opinions.
- Some users express sympathy for GPT-4 and point out that mistakes in code generation are to be expected. They argue that the researchers' conclusions are not well-supported and that more specific considerations should be taken into account when evaluating LLMs.
- Others argue that the problem lies with human developers and their lack of understanding when it comes to proper exception handling, concurrency, and other programming concepts. They suggest that proper education and training should be a priority.
- Some users recommend reading books like "Effective Java" or "Java Concurrency in Practice" for a more thorough treatment of these topics.
- There is a discussion about the difficulty of detecting semantic bugs in code and the challenges of checking the correctness of code generated by LLMs, especially in complex scenarios.
- One user suggests that the misuse of APIs and semantic alignment issues are a particular problem in software engineering and that LLMs can exacerbate these issues.
- A few users point out that the study's examples and reasoning may not be grammatically correct or clear, and that language models like LLMs could benefit from grammar checks.
- There is also some skepticism about the future of LLMs and concerns that their use may lead to a decline in proper coding practices.

Overall, the discussion highlights the need for better understanding and education in software development and the challenges associated with code generation by large language models.

### PMET: Precise Model Editing in a Transformer

#### [Submission URL](https://arxiv.org/abs/2308.08742) | 113 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [13 comments](https://news.ycombinator.com/item?id=37285396)

The paper titled "PMET: Precise Model Editing in a Transformer" by Xiaopeng Li and his co-authors proposes a new method for model editing in Large Language Models (LLMs). Model editing techniques modify a small portion of knowledge in LLMs at a low cost, and this paper aims to improve the precision of these edits.

Previous methods assumed that the hidden states of the Transformer Layer (TL) in LLMs are values of key-value memories of the Feed-Forward Network (FFN). These methods optimized the TL hidden states to remember target knowledge and used it to update the weights of the FFN. However, the TL hidden states contain information that is not specifically required for the FFN, and neglecting this fact reduces the performance of model editing.

To address this, the authors analyze the hidden states of the Multi-Head Self-Attention (MHSA) and FFN, and discover that MHSA encodes certain general knowledge extraction patterns. This finding suggests that the MHSA weights do not need to be updated when new knowledge is introduced. Based on this insight, the authors introduce PMET, which optimizes the hidden states of the Transformer Component (TC, namely MHSA and FFN), while only using the optimized TC hidden states of FFN to precisely update FFN weights.

The experiments conducted demonstrate that PMET achieves state-of-the-art performance on both the COUNTERFACT and zsRE datasets. Ablation experiments further validate the effectiveness of the enhancements introduced in PMET, emphasizing the finding that MHSA encodes certain general knowledge extraction patterns and stores a small amount of factual knowledge.

Overall, the proposed PMET algorithm improves the precision of model editing in LLMs, offering potential advancements in natural language processing and artificial intelligence.

The discussion on the submission includes various comments and related links. One user, "KhoomeiK," mentions a YouTube interview that discusses the paper. Another user, "dnprk," shares a link related to the topic. User "gmrc" comments on how the cost of implementing changes in language models would increase due to government-mandated regulations. User "ttl" brings up the issue of removing historical knowledge from LLMs in China and its potential implications. In response to this, user "PaulHoule" discusses the challenge of keeping LLMs updated and mentions the application of LLMs in summarizing soccer games. User "jpfd" acknowledges the promising work in external data structure retrieval-guided LLMs and shares related research papers. User "zptrm" corrects a mistake made in identifying the year of a Super Bowl game, prompting a response from "PaulHoule." User "DennisP" suggests using document vector similarity search. "PaulHoule" shares a link to an SBERT retrieval plugin and "nl" provides information on different types of document embeddings and similarity search tools. Lastly, "quantum_state" expresses curiosity about the reason behind publishing the paper.

### IBM analog AI chip could give the Nvidia H100 a run for its money

#### [Submission URL](https://www.techradar.com/pro/nvidia-beware-ibm-has-a-new-analog-ai-chip-that-could-give-the-h100-a-run-for-its-money) | 73 points | by [mikece](https://news.ycombinator.com/user?id=mikece) | [59 comments](https://news.ycombinator.com/item?id=37281851)

IBM has unveiled an analog AI chip that promises to be up to 14 times more energy efficient than current industry-leading components. The chip, which can encode 35 million phase-change memory devices per component, aims to reduce the power consumption of generative AI technology. Unlike digital chips that work with distinct binary signals, analog chips can manipulate analog signals and understand gradations between 0 and 1. IBM claims its prototype chip, which can model up to 17 million parameters, mimics the operation of the human brain by performing computations directly within memory.

The discussion surrounding the submission revolves around several themes. 

One commenter highlights the potential benefits of IBM's analog AI chip for low-power computing in machine learning and inference applications. Another commenter agrees and imagines the possibility of efficient inference engines for image generation and translation.

However, there is some skepticism expressed about IBM's claims and promotional headlines. One commenter notes that IBM has a long history of competent software development but may struggle to achieve success in hardware. Another commenter points out that while IBM has published research in relation to analog chips, it is unclear if their commercial products in modern chip design are cutting-edge.

The topic of IBM's business strategy is also discussed, with one commenter noting that IBM does not usually sell the kind of products that excite the Hacker News crowd. Another commenter shares their concern about IBM's future, suggesting that the company has been declining and may not survive in competitive markets.

The discussion also veers into the topic of neuromorphic hardware and the potential advantages of direct computation within memory cells. Some commenters point out that current hardware architectures struggle to support large-scale models with high parameter counts. Others question the efficiency of brain-like synaptic clusters and suggest that pattern recognition and multi-model perception are important features to consider.

One commenter brings up Foveon sensors as an example of implementing direct analog-to-digital conversion. However, there is some disagreement about the effectiveness of Foveon sensors, with some commenters pointing out limitations such as limited sharpness compared to modern camera lenses and misalignment issues.

Overall, the discussion includes a mix of positive outlooks, skepticism, and technical points related to analog AI chips, IBM's business strategy, and alternative analog implementations.

### Meta just released its answer to GitHub Copilot, and it’s free

#### [Submission URL](https://www.itpro.com/technology/artificial-intelligence/meta-just-released-its-answer-to-github-copilot-and-its-free) | 15 points | by [Beggers1960](https://news.ycombinator.com/user?id=Beggers1960) | [7 comments](https://news.ycombinator.com/item?id=37280783)

Meta, the parent company of Facebook, has released Code Llama, an open-source language model (LLM) that competes with OpenAI's ChatGPT. Code Llama is designed for code completion, generation, and testing in languages like Python, C++, Java, and Bash. It was trained on 500 billion tokens of code and programming data and is available in three parameter sizes: 7-billion, 13-billion, and 34-billion. The 34B model achieved 48.8% accuracy on the HumanEval benchmark, surpassing OpenAI's GPT-3.5 and Llama 2 models. Meta also released two fine-tuned versions for Python and natural language input. The 7B model can run on a single GPU.

The discussion about Meta's release of Code Llama on Hacker News includes a discussion about the commercial terms and licenses associated with the model. User "iFire" mentions that there are additional commercial terms for the Llama 2 version, and Meta grants certain rights at its discretion to licensees. User "acheong08" comments that it is reasonable for Meta to make a profit given the significant monthly active users (700 million) it serves. User "dmsk" adds a single-word comment of "dd" which is unclear in meaning.

Another aspect of the discussion revolves around the practicality of using the Code Llama language model. User "snttschl" mentions that they are waiting for a lightweight version of the model that can be run locally on a high-end GPU or even on a Raspberry Pi. User "jstnclft" raises the question of whether limitations would prevent the model from running on a Raspberry Pi, to which "klysm" replies that Pi's flip. User "snttschl" responds that they are attempting to be reasonably realistic in their expectations.

Lastly, user "snttschl" also comments separately about the benefits of using Code Llama, such as being able to generate good GPT4 code without a large codebase and at a lower cost compared to other options.

---

## AI Submissions for Sat Aug 26 2023 {{ 'date': '2023-08-26T17:09:52.665Z' }}

### When Kraftwerk Issued Their Own Pocket Calculator Synthesizer (2019)

#### [Submission URL](https://www.openculture.com/2019/06/when-kraftwerk-issued-their-own-pocket-calculator-synthesizer.html) | 30 points | by [layer8](https://news.ycombinator.com/user?id=layer8) | [9 comments](https://news.ycombinator.com/item?id=37271644)

German electronic band Kraftwerk released their eighth studio album, Computer World, in 1981, right at the cusp of the computer revolution. The album's first single, "Pocket Calculator," featured the Casio fx-501P programmable calculator as one of the instruments used in its recording. To promote the song and allow fans to play Kraftwerk hits on their own calculators, the band commissioned a special calculator from Casio that could play music. This calculator was a modified version of Casio's VL-80 model, which was also a musical synthesizer. Today, 40 years after the release of Computer World, Kraftwerk continues to perform their music around the world. With the anniversary approaching, it might be time for the calculators to make a comeback on stage.

The discussion around the submission includes several comments and links related to Kraftwerk and their music. One user mentions that Casio calculators from the 1970s had some musical capabilities and shares a number (951) that produces a random melody when taking the square root. Another user shares a direct link to Kraftwerk's song "Pocket Calculator" and a cover of their song "The Robots" by the Balanescu Quartet. Another comment highlights the privilege of attending Kraftwerk concerts and recommends experiencing their repetitive perfection. They mention a successful backstage meeting with the Balanescu Quartet. Links to regional live performances and performances in different languages are also shared, including Japanese and English versions. Additionally, a comment suggests a reference to a Teenage Engineering product called "Pocket Operator," which is a tiny synthesizer with musical capabilities. Another user makes a joke about being a "Pocket Calculator" themselves.

### Cody – The AI that knows your entire codebase

#### [Submission URL](https://about.sourcegraph.com/cody) | 162 points | by [adocomplete](https://news.ycombinator.com/user?id=adocomplete) | [59 comments](https://news.ycombinator.com/item?id=37277722)

Meet Cody BETA, the AI coding assistant that knows your entire codebase. Cody can answer code questions and even write code for you by reading your codebase and the code graph. To get started, you can sign up for free access on their website and install the Cody app BETA, a lightweight desktop version of Sourcegraph. Cody is compatible with various IDEs, such as VS Code, IntelliJ, Neovim, and Emacs. 

Cody offers a range of features to make your coding experience more efficient. It can provide code explanations, explaining what code is doing in conversational language. It can also analyze code blocks for code smells, potential bugs, and unhandled errors, pointing out issues and providing suggestions for improvement. Cody can summarize recent code changes, generate unit tests, suggest code completions while you code, and even translate code between programming languages. 

Additionally, Cody can help with code navigation, finding functions and components in your codebase, and tracking references to specific functions. It can also generate code based on your codebase's context and style, from boilerplate code to API resolvers. If you need help with debugging, Cody can assist with that too. It can even generate documentation and write code on your request. 

Developers who have tried Cody are impressed with its capabilities. Some have found it helpful in navigating code and finding solutions quickly, saving them hours of searching through documentation. Others have praised its ability to ease the process of code auditing. And for those who struggle with naming variables, Cody's feature to improve variable names is like a dream come true.

Cody is available for personal use as well as for enterprise teams with private codebases. You can sign up on their website to get access and explore the pricing and plans for Cody Enterprise. So if you're looking for an AI coding assistant that can enhance your coding productivity, give Cody BETA a try!

The discussion about Cody BETA on Hacker News is largely positive, with developers sharing their experiences and opinions on using the AI coding assistant. Some users have found Cody to be helpful in navigating code and finding solutions quickly, saving them time and effort. Others have praised its ability to ease the process of code auditing and improve variable naming. 

There is also a comparison with GitHub Copilot, with some users expressing that they prefer Cody over Copilot, citing specific features or examples of where Cody performs better. However, one user points out that they would like to see some examples of Copilot failing and how Cody handles those cases. 

There are also discussions about the user interface and user experience of Cody, with some users mentioning missing or inconsistent buttons. One user points out that they had trouble getting Cody to recognize their current code repository correctly. 

In terms of privacy, there are concerns about the third-party dependencies used by Cody and the transparency of data usage. One user mentions the need for transparency and confirmation of any downstream impacts related to partnerships with entities like Anthropic and OpenAI.

Some users also discuss their experiences with other coding tools, such as Sublime Text and Visual Studio Code, and their advantages or limitations compared to Cody.

Overall, the feedback on Cody BETA is generally positive, with developers appreciating its capabilities and potential to improve coding productivity.

### Show HN: TRS-GPT – ChatGPT client/server for the TRS-80

#### [Submission URL](https://druid77.github.io/trs-gpt/) | 94 points | by [druid77](https://news.ycombinator.com/user?id=druid77) | [19 comments](https://news.ycombinator.com/item?id=37276026)

The author of this submission shares their childhood dream of interacting with a computer in an intelligent way, particularly inspired by movies like War Games. Fast forward to 2023, and they acquire a TRS-80 Model III computer from 1981. After restoring the keyboard and adding a FreHD module for storage, they realize they need internet connectivity to achieve their goal. They discover the TRS-IO, a solution that allows for both program storage and internet access. After configuring it, they are able to connect to the internet and explore basic programs that interact with WHOIS servers. To pass queries to OpenAI, the author sets up an AWS Lambda function, but encounters issues with API Gateway only supporting HTTPS connections. They decide to implement a simple EC2 server running a Python program to listen on the same port as the WHOIS server. Finally, the author achieves their dream of interacting with an intelligent computer on their TRS-80 Model III.

The discussion on this submission covers various topics related to the TRS-80 Model III computer and the author's efforts to achieve internet connectivity and interact with it in an intelligent way.

- One commenter suggests using the TRS-IO, an interface that allows for program storage and internet access, which enables the author to send and receive network requests with WHOIS servers using BASIC programs.
- Another commenter shares their nostalgic appreciation for the TRS-80 Model III and their interest in reading articles and watching YouTube videos about the computer.
- A brief discussion about playing chess on the TRS-80 Model III occurs, referencing a line from the movie War Games.
- A commenter mentions running a C++ program on the TRS-80 Model III and discusses the computer's CPU, addressing its 48k of physical memory and the upgrade options available.
- Someone shares their own experience experimenting with a TRS-80 CoCo computer and attempting to write code to interface with modern digital devices. They also mention the challenge of translating code from a TRS-80 file format to a format that could be read by modern systems.
- Another commenter suggests using GPT, a language model, to write BASIC code and mentions the model's ability to crawl online sources for training materials.
- Positive feedback is given to the author for their project.
- Some commenters express their interest and appreciation for the TRS-80 Model III and the author's achievements.
- One commenter shares a link to an article about a modern speech synthesis model as a potential replacement for the TRS-80's speech synthesizer module.
- A conversation emerges about the TRS-IO module's compatibility with Linux and the possibility of using a serial terminal to achieve connectivity.
 
Overall, the discussion includes appreciation for the nostalgia-inducing TRS-80 Model III and provides suggestions, tips, and ideas related to internet connectivity and programming on the computer.

### Deep Neural Nets: 33 years ago and 33 years from now (2022)

#### [Submission URL](http://karpathy.github.io/2022/03/14/lecun1989/) | 275 points | by [gsky](https://news.ycombinator.com/user?id=gsky) | [90 comments](https://news.ycombinator.com/item?id=37268610)

A recent blog post by Andrej Karpathy discusses the historical significance of the Yann LeCun et al. (1989) paper on handwritten zip code recognition. This paper is believed to be the earliest real-world application of a neural network trained end-to-end with backpropagation. Despite its age, the paper reads remarkably modern, covering topics such as dataset creation, neural network architecture, loss function, optimization, and reporting classification error rates. To explore the progress made in deep learning, Karpathy decided to reproduce the paper's results using PyTorch. He implemented the original network, which was written in Lisp, and successfully replicated the reported error rates. However, due to the loss of the original dataset, a simulated dataset based on MNIST had to be used. Karpathy also notes some ambiguities in the paper, such as the weight initialization scheme and the connectivity structure between layers. He concludes the post by reflecting on how much progress has been made in deep learning over the past 33 years and the potential for further improvement in the future.

The discussion on the Hacker News submission revolves around several key points. 

1. Energy Efficiency: One user points out the difference in energy consumption between the original 1989 system and Karpathy's modern implementation. The user notes that the energy efficiency of neural networks is an important consideration in evaluating their performance, while another user adds that measuring energy consumption accurately can be challenging.

2. Inference vs. Training Costs: There is a discussion about the difference between the costs of training and inference in contemporary neural networks. The conversation suggests that while training costs may be high, inference costs can be relatively low.

3. Moore's Law: One user disputes the claim that the 30,000-fold improvement in performance over 33 years is not in line with Moore's Law, which predicts a doubling of performance every two years. They explain the concept of compound annual growth rate (CAGR) and argue that the improvement is reasonable within that framework.

4. Hardware Limitations: There is a discussion about the limitations of hardware in training neural networks. It is mentioned that GPUs have limited RAM, and expanding memory can be costly.

5. Critique of Future Predictions: Some users express skepticism about making predictions about the future of artificial intelligence based on historical trends. They argue that the current state of AI may not be indicative of future breakthroughs and that extrapolating from past performance may not be accurate.

6. Fundamental Changes: A user highlights the potential for fundamental changes in AI models and approaches in the future, mentioning synthetic data generation, filtering, and other advancements. They suggest that these changes may lead to revolutionary breakthroughs.

7. Technological Progress: The discussion also touches on the progress made in self-driving cars and AGI, with some users expressing their excitement about advancements in the field and others pointing out the challenges and limitations.

8. Practical Design Considerations: One user reflects on their own experience in machine learning projects and emphasizes the importance of practical design considerations. They note that while there have been significant advancements in machine learning, there are still areas for improvement and mastery.

Overall, the discussion covers a range of topics related to energy efficiency, technological progress, future predictions, and practical considerations in machine learning and AI.

### Never-Ending Learning of User Interfaces

#### [Submission URL](https://arxiv.org/abs/2308.08726) | 54 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [22 comments](https://news.ycombinator.com/item?id=37275331)

Researchers from various institutions have developed an app crawler called the Never-ending UI Learner to improve the training of machine learning models for user interfaces (UIs). These models are used to make apps more accessible, easier to test, and automate certain tasks. Currently, most models rely on datasets that are collected and labeled by human crowd-workers, which can be expensive and prone to errors. The Never-ending UI Learner automatically installs real apps from a mobile app store and crawls them to discover new and challenging training examples. This approach has been successful, with the app crawler performing over half a million actions on 6,000 apps to train three computer vision models: tappability prediction, draggability prediction, and screen similarity. This research offers a promising solution to enhance the training of UI models and improve the user experience of apps.

The discussion surrounding the submission on Hacker News includes various perspectives on user interface (UI) design and the challenges involved in improving it. Some commenters highlight the complexity of UI design and the difficulties in achieving consistency across different platforms. They mention the need for standardized accessibility and the slow and expensive process of user testing and iterating on UI designs.

Others express frustrations with specific aspects of UI, such as password requirements and the need to constantly relearn UIs due to design changes. There is also discussion about the pros and cons of different UI design approaches, including flat design, gradient textures, and the use of ribbons.

In addition, some commenters bring up the challenges of legacy systems and the resistance to change in certain industries. They argue that if something is working well, there may be little incentive to transition to new systems or redesign UIs.

Overall, the discussion highlights the complexities and ongoing debates surrounding UI design and the challenges faced by developers and designers in creating effective and accessible user experiences.

### Interpretable graph neural networks for tabular data

#### [Submission URL](https://arxiv.org/abs/2308.08945) | 75 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [5 comments](https://news.ycombinator.com/item?id=37269376)

Researchers have proposed a new approach called IGNNet (Interpretable Graph Neural Network) that aims to make graph neural networks (GNNs) more interpretable when applied to tabular data. GNNs have become popular for handling tabular data due to their ability to capture feature interactions through representation learning. However, the models produced by GNNs are often considered black boxes, making it challenging to understand how the predictions are computed. IGNNet addresses this issue by constraining the learning algorithm to produce an interpretable model that shows the exact computation process from the original input features. The researchers conducted a large-scale empirical investigation and found that IGNNet performed on par with state-of-the-art machine learning algorithms for tabular data, such as XGBoost, Random Forests, and TabNet. Furthermore, the explanations obtained from IGNNet were aligned with the true Shapley values of the features without incurring additional computational overhead. This approach holds promise for improving the interpretability of GNNs in real-world applications.

The discussion surrounding the submission on Hacker News includes various points of interest. One user, "PaulHoule," commented that significant regional articles related to the field of research don't handle tabular data and mentioned that there are other things that graph neural networks (GNNs) can't handle, similar to ChatGPT-like models. Another user, "wstrnr," added that TabPFN (Transformers for Tabular Data) had similar performance to models like XGBoost, Catboost, LightGBM, KNN, SAINT, Reg Cocktail, Autogluon, and Auto-sklearn. They also noted the requirement of only 5 minutes to reach 20% ROC (Receiver Operating Characteristic) compared to TabPFN1. Additionally, they shared links to related papers such as "TabPFN Transformer Solves Small Tabular Classification Problems Second 2022" and "Interpretable Graph Neural Networks for Tabular Data Aug 2023".

---

## AI Submissions for Fri Aug 25 2023 {{ 'date': '2023-08-25T17:10:40.251Z' }}

### How do domain-specific chatbots work? A retrieval augmented generation overview

#### [Submission URL](https://scriv.ai/guides/retrieval-augmented-generation-overview/) | 128 points | by [czue](https://news.ycombinator.com/user?id=czue) | [35 comments](https://news.ycombinator.com/item?id=37261198)

In a recent post on Hacker News, the concept of retrieval augmented generation (RAG) was explored in the context of building domain-specific chatbots. The post highlighted an open-source library called LangChain that can easily create chatbots for Q&A purposes on any website or document. With just three lines of code, developers can leverage LangChain to build powerful chatbots that provide specific answers to user queries.

The post explained that RAG, or retrieval augmented generation, is the process of supplementing a user's input to a large language model (LLM) with additional information retrieved from external sources. This additional information enriches the response generated by the language model. A diagram was provided to illustrate the workflow of RAG, starting with the user's question, followed by the retrieval of relevant content from a knowledge base, and finally, the generation of an answer by the language model.

The article emphasized the importance of the retrieval step, which involves searching for the most relevant information to answer the user's query. It highlighted the reasons for not sending the entire knowledge base to the language model, such as model limitations, cost, and the effectiveness of providing small amounts of relevant information.

To generate an answer, the post explained that language models like ChatGPT rely on prompts and messages. The system prompt, which provides overall guidance to the language model, can be customized to instruct the model to utilize the extracted knowledge base information for answering the question. The format of the knowledge base documents passed to the language model was also outlined in the post.

Overall, the article aimed to provide a high-level overview of RAG and its implementation in building domain-specific chatbots. It provided valuable insights for both developers interested in building such bots and non-developers looking to make the most of AI tools for their datasets.

The discussion on the Hacker News submission touched on various aspects related to retrieval augmented generation (RAG) and building domain-specific chatbots. Here are some key points from the discussion:

- Some users found the concept of RAG interesting and discussed practical implementation details. They mentioned the importance of testing frameworks and datasets to ensure the effectiveness of the chatbots.
- The LangChain library was praised for its ease of use and ability to quickly create chatbots. However, there were some suggestions to improve the documentation and code quality.
- Testing the performance of RAG systems was discussed, with suggestions to consider slow ranking-based metrics, offline precision recall, normalized discounted cumulative gain (nDCG), and mean reciprocal rank (MRR).
- The contrasting ideas of the capabilities of RAG and the difficulty organizations face in providing meaningful and cost-effective results were debated.
- The topic of vectorizing chunks of data and the use of semantic search were explored. Users shared resources on semantic search, index embeddings, and the benefits of using them in RAG systems.
- There were discussions about the advantages of using semantic search over keyword search and the complexity of implementing semantic search algorithms like Lucene.

Additionally, there were discussions around handling real-time streaming data and refreshing systems, the impact of document context on model performance, the use of embeddings and vectorizers, and the resources and research papers related to RAG.

### Finetuning of Falcon-7B LLM Using QLoRA on Mental Health Conversational Dataset

#### [Submission URL](https://github.com/iamarunbrahma/finetuned-qlora-falcon7b-medical) | 156 points | by [iamarunbrahma](https://news.ycombinator.com/user?id=iamarunbrahma) | [100 comments](https://news.ycombinator.com/item?id=37259753)

A developer named iamarunbrahma has created a project called "finetuned-qlora-falcon7b-medical" on GitHub. The project aims to improve the understanding and support for mental health by using a chatbot powered by the Falcon-7B LLM model and the QLoRA technique. The chatbot can provide immediate assistance and emotional support to users seeking help with mental health issues. It is important to note that while the chatbot can be helpful, it is not a replacement for professional mental health care. The dataset used for training the chatbot was curated from online FAQs, healthcare blogs, and wiki articles related to mental health. The pretrained Falcon-7B model was finetuned on this dataset using the QLoRA technique. The entire finetuning process took less than an hour using Nvidia A100. The project also includes a Gradio-based frontend for demo purposes, allowing users to interact with the chatbot interface. Users can try different hyperparameter configurations and evaluate the quality of the chatbot's responses. The inference model for the chatbot is also provided in a separate repository. Overall, this project aims to provide accessible and quality mental health support through the use of chatbot technology.

The discussion on this submission revolves around several key points. 

One point of discussion is about the effectiveness and limitations of using LLMs (large language models) for medical devices. Some commenters express concerns about the potential dangers of relying on LLMs for medical treatment, especially in the case of mental health, as it may lead to misdiagnosis or inadequate care. Others argue that LLMs can be a useful tool but should not be seen as a replacement for professional healthcare.

There is also a discussion about the affordability and accessibility of mental health care. Many commenters highlight the high costs of healthcare and the challenges in finding qualified professionals, especially for individuals without insurance coverage. The idea of universal healthcare is brought up as a potential solution to address these issues.

Some commenters express skepticism about the effectiveness of LLMs in providing mental health treatment. They argue that LLMs may not be able to fully understand and resolve complex mental health issues and that relying on them could be harmful. Others defend the potential of LLMs but emphasize the need for careful regulation, ethical considerations, and the involvement of qualified professionals.

There is also a discussion about the responsibilities of practitioners in mental health treatment and the importance of maintaining affordability and availability. Some commenters argue that the current healthcare system is unnecessarily complex and that greed and lack of ethics are major problems. Others discuss the need for better policies and regulations in the healthcare industry.

Overall, the discussion highlights the potential benefits and risks of using LLMs for mental health support and the broader issues of affordability and accessibility in healthcare. There are differing opinions on the effectiveness of LLMs and the responsibilities of practitioners, but there is a general agreement that more comprehensive and accessible mental health support is needed.

### Note-taking apps are designed for storage, not insight – can AI change that?

#### [Submission URL](https://www.theverge.com/2023/8/25/23845590/note-taking-apps-ai-chat-distractions-notion-roam-mem-obsidian) | 96 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [86 comments](https://news.ycombinator.com/item?id=37262265)

In a recent article on Platformer, Casey Newton discusses the limitations of note-taking apps and their inability to improve our thinking. Despite the abundance of information available to us, many people find themselves feeling overwhelmed and paralyzed by the vast amount of data they collect. Newton shares his own struggles with data paralysis as a journalist and how note-taking became a solution for him. He highlights the breakthrough tool Roam Research, which offers features like daily note creation and bidirectional linking to help users capture and organize their thoughts. However, Newton admits that these tools didn't live up to his expectations of improving his thinking. He suggests that note-taking apps may be up against the daily distractions of the internet, making it difficult for users to truly engage with their notes and extract valuable insights.

The discussion revolves around the different perspectives on note-taking apps and their effectiveness in improving thinking. Some argue that note-taking apps do not provide the benefits they claim, as they do not facilitate deeper understanding or help with organizing thoughts. Others suggest that the issue lies in the distractions of the internet, which hinder users from engaging with their notes effectively. 

Some users recommend alternative methods such as the Zettlekasten Method or TiddlyWiki for more structured and interconnected note-taking. Obsidian is also mentioned as a useful tool, although some users find its user experience lacking in comparison to other methods like Zettlekasten. Other suggestions include physical note-taking, taking handwritten notes during lectures or presentations for better comprehension, and using techniques like flashcards for studying.

### Show HN: PlotAI – Create Plots in Python and Matplotlib with LLM

#### [Submission URL](https://github.com/mljar/plotai) | 50 points | by [pplonski86](https://news.ycombinator.com/user?id=pplonski86) | [13 comments](https://news.ycombinator.com/item?id=37260913)

PlotAI is a new Python library that makes it incredibly easy to create plots in Python using Matplotlib. The library harnesses the power of the LLM (Language Models for Plots) to generate the necessary Python code for creating plots based on user input. Here's how it works: users provide a DataFrame and a prompt, and PlotAI constructs a prompt for the LLM that includes the first five rows of the DataFrame and the user's prompt. The LLM then generates Python code as output, which is executed and the resulting plot is displayed. The PlotAI API is incredibly simple, with just one method called `make()`. Users can use this method in Python scripts and notebooks (such as Jupyter, Colab, and VS Code) to create plots. To get started with PlotAI, users need to install the PlotAI package (`pip install plotai`) and provide their OpenAI API key in the `.env` file. Once that's done, they can import PlotAI and start making plots using just a single line of code. While PlotAI is currently in an experimental form, there are plans to extend its compatibility to other LLM models in the future. However, it's important to note that PlotAI sends the first five rows of the DataFrame to the OpenAI ChatGPT model, so users should remove or encode any sensitive data before using it. Additionally, since PlotAI executes the Python code returned by the LLM, caution should be exercised, and it would be beneficial to have the option to review the response code before execution. The developers of PlotAI provide it "as is," without any warranty, and users are responsible for any risks associated with its use. It's also important to note that the use of OpenAI language models can be costly due to token usage, so users should monitor and manage their own token usage to avoid unexpected charges. Overall, PlotAI aims to make plot generation in Python more accessible and intuitive for users. With its simplicity and integration with LLM technology, creating visualizations has never been easier.

The discussion around the PlotAI submission on Hacker News covers a few different points:

1. A user suggests exploring Vega and Vega-Lite for visualization grammar and mentions the use of Vegavoyager and CompassQL for chart recommendations.
2. Another user mentions the potential benefits of using OpenAI's language models to generate synthetic data for graphing but raises concerns about the formatting and potential misuse.
3. A user comments on the potential usefulness of LLMs like the ones used by PlotAI and suggests the Code Llama tool as an alternative with the ability to generate appropriate chart types based on natural language metadata.
4. One user appreciates the simplicity of PlotAI's API and suggests an example of how to use it in Python scripts and notebooks.
5. There is a discussion about the capabilities of the LLM model in understanding and generating prompt-specific Python code and surprise at its ability to generalize from the first five rows of a DataFrame.
6. Another conversation arises about a potential major acquisition and ML projects, with one user seeking advice on the topic.
7. Lastly, there is a short exchange regarding string arguments and comments in code.

Overall, the discussion includes appreciation for PlotAI's simplicity, suggestions for alternative tools, concerns about data formatting and usage, and unrelated conversations about ML and coding practices.

### AI isn’t good enough

#### [Submission URL](https://skventures.substack.com/p/ai-isnt-good-enough) | 169 points | by [MaysonL](https://news.ycombinator.com/user?id=MaysonL) | [354 comments](https://news.ycombinator.com/item?id=37256577)

In their latest post, Paul Kedrosky and Eric Norlin of SK Ventures discuss the current labor shortage in the U.S. and the role of AI in addressing this issue. They explain that the shortage is driven by factors such as demand growth, an aging society, retirements, lower immigration, and skill mismatches. This shortage has led to companies offering signing bonuses to attract workers. However, the authors argue that the solution lies in automation, specifically AI, which can help fill the gaps in the workforce. They highlight that the current wave of AI is uniquely suited to address tasks that require "tacit knowledge," where programmatic solutions are not feasible. However, they also note that current-generation AI has limitations, including tendencies towards hallucinations and inadequate training data. They predict that the first wave of large language model-based AI is nearing its end, with new technological and cost constraints on the horizon. Despite this, they believe that AI can play a significant role in addressing labor shortages if its limitations are overcome.

The discussion on Hacker News revolves around the limitations and potential of current-generation AI, specifically large language models (LLMs). Some users express skepticism regarding the progress of LLMs, pointing out the inflated confidence statements made by OpenAI and the lack of concrete breakthroughs. Others share their experiences with LLMs and note the impressive advancements they have witnessed. The conversation also delves into the intersection of AI and other technologies like blockchain, the demand for AI skills, and the potential impact of AI on different industries. Some users raise concerns about the legal and ethical implications of AI, while others discuss the hype surrounding AI and the need for rational assessment of its capabilities. Overall, the discussion reflects a mix of skepticism, excitement, and differing viewpoints on the future of AI.

### Imminent Death of ChatGPT [and Generative AI] Is Greatly Exaggerated

#### [Submission URL](https://synthedia.substack.com/p/the-imminent-death-of-chatgpt-and) | 42 points | by [larve](https://news.ycombinator.com/user?id=larve) | [36 comments](https://news.ycombinator.com/item?id=37263231)

In a recent article on synthedia.substack.com, Bret Kinsella argues that the recent skepticism surrounding generative AI, particularly ChatGPT, is largely unfounded. While figures like Elon Musk and Gary Marcus have expressed concerns about the technology, Kinsella points to user adoption and revenue generation as evidence of its value. He acknowledges that there are still challenges to overcome, such as data management and security, but argues that these are typical hurdles for any new technology. Kinsella believes that the current hype surrounding generative AI is largely productive and that the technology has the potential for long-term success.

The comments on Hacker News regarding the submission are varied and touch on different aspects of the discussion. Here is a summary of the key points:

- Some users express frustration with people's comments and skepticism towards ChatGPT, stating that it is useful in their daily lives.
- One user argues that AI is often overvalued and that Pre-Revenue startups with billion-dollar valuations are not necessarily worth discussing.
- Another user discusses the analogy of an electric drill, stating that just as an electric drill does not mean the end of carpentry, AI does not mean the end of human creativity.
- There is a discussion about the potential for plagiarism with ChatGPT and its usefulness in various applications.
- Some users argue that the current progress in AI is still in the early stages and that there is much more to come in terms of its applications and commercial world adoption.
- There is a debate about the rise and fall of AI bubbles and the pace of technological advancements.
- One user mentions the challenges of implementing AI in businesses, including the need for executive buy-in and managing projects effectively.
- Another user discusses the winners and losers in the AI market, mentioning the importance of differentiated products and the advantage of smaller companies in moving quickly and exploring niche markets.
- The comments also highlight the importance of AI moonshots and the potential for significant returns in the AI-powered future.

Overall, the discussion covers a range of perspectives on the current state and future potential of generative AI, acknowledging its value in some areas but also highlighting challenges and potential pitfalls.

---

## AI Submissions for Thu Aug 24 2023 {{ 'date': '2023-08-24T17:10:41.669Z' }}

### Code Llama, a state-of-the-art large language model for coding

#### [Submission URL](https://ai.meta.com/blog/code-llama-large-language-model-coding/) | 847 points | by [marcopicentini](https://news.ycombinator.com/user?id=marcopicentini) | [474 comments](https://news.ycombinator.com/item?id=37248494)

Today, a groundbreaking large language model called Code Llama has been released. This state-of-the-art model is capable of generating code and natural language about code from both code and natural language prompts. Code Llama is free for both research and commercial use.

Code Llama is built on top of Llama 2 and is available in three models: Code Llama, Codel Llama (Python specialized for Python), and Code Llama - Instruct (fine-tuned for understanding natural language instructions). In benchmark testing, Code Llama outperformed state-of-the-art publicly available large language models on code tasks.

The release of Code Llama is a significant advancement for generative AI in the coding field. It has the potential to improve workflows, boost productivity, and lower the barrier to entry for people learning to code. The model can be used as a productivity and educational tool to help programmers write more robust and well-documented software.

Code Llama works by further training Llama 2 on code-specific datasets, enhancing its coding capabilities. It supports popular programming languages such as Python, C++, Java, PHP, Typescript (Javascript), C#, and Bash. The model can generate code, provide natural language explanations about code, assist with code completion, and even aid in debugging.

Three sizes of Code Llama are available, with 7B, 13B, and 34B parameters respectively. Each model is trained with 500B tokens of code and code-related data. The 7B and 13B models feature fill-in-the-middle (FIM) capability for code completion. The larger 34B model provides the best results and coding assistance but may have higher latency. The models can handle input sequences up to 100,000 tokens.

Two additional variations of Code Llama have been fine-tuned: Code Llama - Python, specifically designed for Python code, and Code Llama - Instruct, which excels at understanding natural language instructions. The latter is recommended for code generation as it has been trained to generate safe and helpful answers in natural language.

Code Llama's performance was evaluated using popular coding benchmarks. In tests, it outperformed existing solutions on code completion and code writing tasks. For example, the Code Llama 34B model scored 53.7% on HumanEval and 56.2% on Mostly Basic Python Programming (MBPP), making it one of the top-performing models.

It's worth noting that while Code Llama brings many benefits, it also comes with risks. Responsible AI development is essential, and precautions have been taken to mitigate potential issues. Code Llama has undergone safety measures, including a quantitative evaluation of its risk of generating malicious code.

Overall, Code Llama is a significant step forward in the field of generative AI for coding. With its innovative capabilities, researchers and developers can expect improved productivity and efficiency, while aspiring programmers can find valuable educational support.

The discussion about the submission "Introducing Code Llama: A State-of-the-Art Large Language Model for Coding" on Hacker News covers a range of topics related to the use and understanding of code generators for programming.

Some comments discuss alternative code solutions for specific problems and provide code snippets or suggestions. Others raise concerns about the limitations and potential pitfalls of using code generators and the risks associated with relying solely on AI-generated code. The discussion also touches on the importance of fundamental programming skills and knowledge, suggesting that relying solely on AI-generated code may lead to a lack of understanding and limitations in problem-solving capabilities.

There are also comments discussing the performance and technical details of Code Llama, including the size of the models, their capabilities, and the resources required to run them. Some users express skepticism about the practicality and usefulness of such large language models, while others highlight the potential benefits for productivity and education.

Overall, the discussion highlights different perspectives on the use of AI for code generation, emphasizing the need for a balanced approach that combines the capabilities of AI with human programming skills and knowledge.

### Artificial intelligence gave a paralyzed woman her voice back

#### [Submission URL](https://www.ucsf.edu/news/2023/08/425986/how-artificial-intelligence-gave-paralyzed-woman-her-voice-back) | 204 points | by [gehwartzen](https://news.ycombinator.com/user?id=gehwartzen) | [68 comments](https://news.ycombinator.com/item?id=37252025)

Researchers at UC San Francisco and UC Berkeley have made a breakthrough in brain-computer technology that could revolutionize communication for people with severe paralysis. Using a brain-computer interface (BCI), the researchers were able to synthesize speech and facial expressions from brain signals for the first time. The system can also decode these signals into text at a much faster rate than current communication devices, offering hope for a more natural and efficient way for individuals like Ann, a participant in the study, to communicate. The researchers hope that this advancement will lead to an FDA-approved system in the near future.

The discussion on this submission covers various aspects of the research and its implications. Some commenters discuss the technical details of the system, such as the mapping of words to phonemes and the challenges of interpreting speech signals based on muscle movements. Others highlight the limitations of the technology, such as the inability to read thoughts and the need for physical movements to generate signals. 

There is also a discussion about related studies and technologies, including silent speech interfaces and mind-to-speech interfaces. Some commenters express concerns about privacy and the potential for forced disclosure of personal information. Others discuss the legal implications, such as the use of thoughts as evidence in court proceedings. 

A few commenters point out potential applications beyond communication for people with paralysis, including gaming and medical diagnostics. There is also a brief discussion about the difference between AI and machine learning. Lastly, there are some users who flagged comments for help or to draw attention to them.

### Maccarone: AI-managed code blocks in Python

#### [Submission URL](https://github.com/bsilverthorn/maccarone) | 169 points | by [silverthorn](https://news.ycombinator.com/user?id=silverthorn) | [70 comments](https://news.ycombinator.com/item?id=37254510)

Introducing Maccarone: AI-managed code blocks in Python! Developed by user bsilverthorn, Maccarone allows you to delegate sections of your Python program to AI ownership. Simply define the sections you want the AI to handle, and Maccarone will generate the code for you. It uses the power of GPT-4 to write code and makes OpenAI API calls using your API key. However, do note that API calls come with a cost, as you will be charged by OpenAI based on the size of the generated code. Maccarone also keeps the generated code up to date when you make changes to your program. You can try out Maccarone through the VS Code extension or install it directly from PyPI. Be sure to check out the detailed documentation and FAQs to learn more about this exciting tool.

The discussion on this submission covers various topics related to Maccarone, AI code generation, and related concepts. Here are the key points:

- One commenter points out that Maccarone sounds like a mix of languages, and another mentions the German term "gflschtr dtschr dsnt cptr," which refers to a similar concept.
- The strength of GPT-4 in generating code is discussed, with some noting that GPT models have become stronger over the years and others suggesting that GPT-4 would be even better.
- There is a mention of Copilot, another AI code generation tool, and its contextual understanding of code. It is noted that Cross-file support is coming soon for Copilot.
- The concept of using deterministic finite automata (DFA) in managing code is discussed, with an example of using DFAs for JSON validation. The benefits and limitations of this approach are highlighted.
- The discussion delves into the idea of using AI to write proofs and validate conditions in code. Some commenters express skepticism about self-verifying systems and discuss the potential role of AI and deep learning in assisting with proofs.
- A reference to a research paper on AI reflection and self-correction is shared.
- The advantages and disadvantages of complete code generation and the use of comments as placeholders are debated. Some argue that continuous manual review is necessary, while others suggest relying on automation.
- The idea of using AI in code decorators is discussed, with one commenter pointing out an existing framework that implements this concept.
- The potential for AI-generated comments and the flexibility of languages in supporting comments are debated, with some advocating for structured and limited use of comments.
- The importance of using version control properly and ensuring that comments match the code changes is mentioned.
- Suggestions are made for using AI to configure data flows and predefined code models.
- Some commenters express interest in trying out Maccarone or similar AI code generation tools.
- Various links and resources related to the discussed topics are shared.

Overall, the discussion covers a range of perspectives on AI code generation tools like Maccarone and delves into topics such as language flexibility, code verification, and the role of AI in programming.

### Graph of Thoughts: Solving Elaborate Problems with Large Language Models

#### [Submission URL](https://arxiv.org/abs/2308.09687) | 261 points | by [jonbaer](https://news.ycombinator.com/user?id=jonbaer) | [43 comments](https://news.ycombinator.com/item?id=37248694)

The paper titled "Graph of Thoughts: Solving Elaborate Problems with Large Language Models" introduces a framework called Graph of Thoughts (GoT) that enhances the prompting capabilities of large language models (LLMs). GoT allows the modeling of LLM-generated information as a graph, where LLM thoughts are represented as vertices and dependencies between thoughts as edges. This approach enables combining thoughts into synergistic outcomes, distilling the essence of thought networks, and enhancing thoughts using feedback loops. The authors demonstrate that GoT offers advantages over existing paradigms on different tasks, such as improving sorting quality by 62% while reducing costs by over 31%. The extensibility of GoT allows for the development of new thought transformations and prompting schemes. This work brings LLM reasoning closer to human thinking and brain mechanisms.

The discussion on Hacker News regarding the submission titled "Graph of Thoughts: Solving Elaborate Problems with Large Language Models" covers a range of topics related to the paper. One commenter, knxr, mentions a similar project they worked on and expresses excitement about exploring the direction of modeling complex LLM-aided processes using dependency graphs. They highlight the usefulness of features like time-rewinding for debugging and the potential of applying genetic algorithms to LLM implementation. Another user, brtsbrn, expresses interest in systems that can generate knowledge graphs from LLMs to make machine-generated information more readable. They suggest using prompt papers to suggest different ways of categorizing and grading the generated content. The topic of trustworthiness of LLMs is discussed by throwaway290 and brtsbrn. The latter expresses skepticism and emphasizes the importance of human checking and validating the generated graphs. Firewolf34 brings up the idea of a hierarchy and structure in graph-like thought processes, suggesting that they are advanced forms of information processing. Mcwfsh mentions that non-hierarchical graphs can perform complex transformations and suggests that there may be a trade-off between hierarchical optimization and performance in thought processes. Other topics briefly discussed include the use of graphs in finance, the challenges of LLM directionality, the potential applications of graph transformation in general computation, and the efficiency of LLMs in sorting numbers. Overall, the discussion covers a range of perspectives on the topic of using graphs to enhance large language models, including their potential applications, limitations, and the challenges associated with trustworthiness and efficiency.

### Show HN: Web App with GUI for AutoML on Tabular Data

#### [Submission URL](https://github.com/mljar/automl-app) | 38 points | by [pplonski86](https://news.ycombinator.com/user?id=pplonski86) | [3 comments](https://news.ycombinator.com/item?id=37247268)

Automated Machine Learning (AutoML) is taking the world by storm, and now there's a web app to make it even easier. Developed by mljar, the AutoML Web App allows users to train machine learning pipelines using MLJAR AutoML, specifically tailored for tabular data. The app automates several key tasks, including data preprocessing, features engineering, algorithm selection, tuning, model explanations, and automatic documentation. The best part? The app is created directly from Jupyter Notebooks with the Mercury framework. Whether you prefer the online demo or running the app locally, you'll have access to a user-friendly interface and powerful ML capabilities. Give it a try and see how it can revolutionize your ML training journey.

The discussion on this submission revolves around the challenges and concerns related to AutoML and the features of the mljar AutoML Web App. 

One commenter, cnvscrtc, points out that AutoML may not always generate reliable models that generalize well to real-world scenarios. They mention that support for data preprocessing and model explanations can be overlooked, and raise concerns about the robustness and reliability of the models generated. They also mention the risks of overfitting and the difficulties in debugging projects. However, they acknowledge the usefulness of AutoML in probing and refining approaches.

Another commenter, pplonski86, shares a benchmark for independent researchers to verify and validate AutoML techniques. They mention the technique of stopping the training time as a way to address issues related to overfitting.

pplonski86, who appears to be associated with mljar, mentions the mljar AutoML Web App that they have created. They explain that the app is built using Python packages, specifically the MLJAR AutoML package for tabular data and the Mercury framework for converting Jupyter Notebooks into web apps. They encourage users to try the online demo or use the app locally, highlighting features such as adjusting notebooks, validation strategies, evaluation metrics, longer training times, and as a starting point for advanced applications.

### Block the Bots That Feed “AI” Models by Scraping Your Website

#### [Submission URL](https://neil-clarke.com/block-the-bots-that-feed-ai-models-by-scraping-your-website/) | 22 points | by [sohkamyung](https://news.ycombinator.com/user?id=sohkamyung) | [24 comments](https://news.ycombinator.com/item?id=37248061)

A recent article on Hacker News discusses the issue of AI companies scraping websites without explicit consent and using the data to train their models. The author argues that opt-out options are not practical and that data scraping should strictly be an opt-in process. They believe that developers should not be entitled to use others' work without permission. While there are ongoing court cases and debates surrounding this issue, the author provides a solution to block some of the scraping bots by using the robots.txt file on your website. They also mention that some website-building platforms do not allow users to update or add their own robots.txt, so they recommend contacting support to address this issue.

The discussion on this submission covers various viewpoints on the topic of AI companies scraping websites. Here are the key points made by the commenters:

- "rgnstn" argues that respecting the robots.txt file alone is not enough, and companies should justify their actions and seek explicit consent.
- "brnjkng" mentions that OpenAI's GPT model does not include content from CommonCrawl or ThePile datasets.
- "JohnFen" expresses distrust in scrapers and emphasizes that honoring opt-out mechanisms like Do Not Track (DNT) is voluntary for companies that make money from scraping.
- "nuc1e0n" responds by highlighting the need for clearer communication between stakeholders and recognizes that website owners have the right to grant or deny permission for scraping.
- "JohnFen" suggests that the efficacy of the robots.txt system in court may not be reliable in determining clear consent.
- "brnjkng" shares their own experience in building a scraper and argues for the inclusion of potential training content from CommonCrawl and ThePile.
- "jstrsn" suggests using IP-level filtering to better control scraping.
- "gmbllnd" states that the perspective on AI grabbing data depends on drivers, clicks, and advertising revenue.
- "nbgh" fails to understand why people would object to allowing AI to gather data and claims that it protects livelihoods.
- "JohnFen" expresses concern that protecting livelihoods does not contribute to training AI models.
- "extraduder_ire" mentions that ByteDance's crawler is likely blocked based on a recent case involving a KC video.
- "strng" comments on the authors spending little time talking about AI and more time proposing solutions.
- "nuc1e0n" suggests granting additional access based on specific search agents, and "JackGreyhat" proposes allowing bots based on the robots.txt file for search engines like Google and Bing.

### Bun v0.8

#### [Submission URL](https://bun.sh/blog/bun-v0.8.0) | 356 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [154 comments](https://news.ycombinator.com/item?id=37244012)

Bun v0.8.0 has been released with some exciting new features and improvements. Debugger support has been added through WebKit's Inspector Protocol, allowing developers to inspect and control the running bun process. The --inspect flag starts an HTTP server and a WebSocket server for debugging. There's also a new Bun Inspector tool hosted at debug.bun.sh, where developers can inspect code, set breakpoints, and execute code in the console.

Another notable addition is the bun update command, which updates all project dependencies to the latest compatible versions specified in the package.json file. This feature is similar to npm's update command but is specific to Bun.

SvelteKit support has been improved, enabling better integration with environment variables in Worker. Developers can scaffold a SvelteKit project using the create-svelte command and start it with bun run dev. Nuxt development server now works with Bun, thanks to improved node:tty and node:fs support. Developers can use the bunx command-line tool with the --bun flag to run the Nuxt development server using the Bun runtime.

Bun now also supports fetch() response body streaming, allowing developers to stream data from API responses instead of waiting for the entire response to be downloaded. This is especially useful when working with APIs that have large responses.

Overall, Bun v0.8.0 introduces several exciting features and improvements, making it an even more powerful and versatile JavaScript runtime, bundler, transpiler, and package manager.

The discussion on the Hacker News thread about the release of Bun v0.8.0 had several different points of view. Some users expressed confusion about the changes and mentioned that they had difficulty getting the new features to work. Others shared their positive experiences and praised the improvements in Bun. There was a discussion about the security vulnerabilities in Zig and whether or not Zig takes security seriously. Some users argued that Andrew, the creator of Zig, stated publicly that the project is not production-ready due to security vulnerabilities. Others disagreed and emphasized the importance of addressing security issues promptly. There were also comments about Bun's stability and its target audience. Some users felt that Bun should prioritize stability and production-readiness, while others defended the project's focus on delivering new features. One user mentioned that the recent release of Deno discarded compatibility with Node and wondered about the details of this decision. Another user expressed interest in using Bun for their project, specifically mentioning its support for JavaScript and TypeScript runtimes. The conversation also touched on concerns about the reliability of JavaScript as a language and the constant changes and deprecations in the ecosystem. Overall, there were a variety of opinions on the topic, ranging from support and enthusiasm for Bun to skepticism and concerns about its stability and compatibility.