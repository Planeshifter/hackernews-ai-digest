import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Fri Dec 15 2023 {{ 'date': '2023-12-15T17:09:42.368Z' }}

### Do large language models need all those layers?

#### [Submission URL](https://www.amazon.science/blog/do-large-language-models-really-need-all-those-layers) | 173 points | by [belter](https://news.ycombinator.com/user?id=belter) | [80 comments](https://news.ycombinator.com/item?id=38656039)

Do large language models really need all those layers? That's the question posed in a paper presented at the Association for Computational Linguistics (ACL) conference. The researchers found that 70% of attention heads and 20% of feed-forward networks in large language models could be removed with minimal effect on in-context learning, suggesting that these models are undertrained. The study focused on the OPT-66B model, a 66-billion-parameter language model, and found that a significant portion of the model could be discarded without affecting performance. These findings could help in building more powerful language models by identifying architectural elements that need better training.

The discussion on this submission revolves around various aspects of large language models (LLMs). Some users highlight the wastefulness of training these models with large amounts of parameters, suggesting that certain architectural elements could be removed without significant impact on performance. Others discuss the trade-offs and techniques for improving the efficiency of LLMs, such as pruning, distillation, sparse transformers, mixture experts, and quantization. 

There is also a debate on the utility and generalizability of LLMs, with some users questioning their performance compared to smaller models and the need to chase state-of-the-art benchmarks. Concerns are raised about the excessive size and computational costs of these models, as well as issues related to convergence and training time. Users also bring up the idea of combining different techniques and specializations in LLMs to enhance performance.

Additionally, there are discussions on the appropriate methods for optimizing LLMs, such as quantization and pruning, and the challenges of compressing these models. The role of scale and context learning in LLMs is explored, and comparisons are made to the human brain's capacity for learning. There is also mention of a related paper about the interpretability of large-scale models and the need for rethinking their role.

Some users question the generalizability of LLMs and the interpretations they provide, highlighting the multiple possible interpretations of sentences and the limitations of syntactical understanding. The differences between training and inference in LLMs are also brought up.

Overall, the discussion delves into the efficiency, performance, and limitations of large language models, providing insights and alternative viewpoints on their architecture, training methods, and practical applications.

### ChatGPT created a text adventure for me

#### [Submission URL](https://andrewhuth.substack.com/p/chatgpt-created-a-text-adventure) | 33 points | by [ahuth](https://news.ycombinator.com/user?id=ahuth) | [16 comments](https://news.ycombinator.com/item?id=38657389)

Summary: In this intriguing account, Andrew Huth shares his experience playing a text adventure game created by ChatGPT. With commands like "walk north" and "use objects," Andrew found himself in a haunted house. Guided by eerie whispers, he explored the house, discovered a tattered journal and rusty key, and delved deeper into the mysteries. ChatGPT successfully engaged Andrew with its descriptions and even provided an inventory of acquired items. Although unable to generate images, the AI painted vivid descriptions of a painted family and a ghostly figure. As Andrew continued his adventure, the tension and supernatural atmosphere grew. 

Commentary: Andrew Huth takes the reader on a captivating journey through an interactive text adventure created by ChatGPT. This imaginative twist of using an AI to generate a game showcases the creative potential of AI language models. The story not only captures the reader's attention but also highlights the AI's ability to provide atmospheric descriptions, maintain consistency, and adapt to player choices. Whether you're a fan of text-based games or curious about the possibilities of AI-generated experiences, this account offers a thrilling glimpse into the future of interactive storytelling.

The discussion on this submission covers a range of topics related to text-based adventures and AI language models. 

- One user mentions that they have enjoyed procedurally generated text adventures with puzzle elements, where players have access to objects and can break through current puzzles by using specific items.
- Another user shares a tangentially relevant link to a Text Adventure GPT, expressing frustration with OpenAI's alleged anticompetitive behavior.
- One user points out a Python library called "chtp" that generates text adventures, complete with character creation, inventory tracking, and consistent status updates.
- A discussion ensues about Python variables, control prompts, and the workings of GPT models.
- Another user comments on the role of imagination in interaction and narrative levels in storytelling, sharing an example of a narrated interactive story where the reader's reactions influenced the direction of the narrative.
- A separate user mentions their experiments with complex interaction and narrative plans, highlighting the importance of listening and reacting to the player's choices in interactive storytelling.
- One user suggests that using the Inform7 programming language could lead to the creation of valid text adventures.
- There is also speculation about the possibility of using ChatGPT to create text adventures with illustrations.
Overall, the discussion demonstrates the interest and enthusiasm for text-based adventures and the potential applications of AI language models in interactive storytelling.

### Godot: A Collaboration with Google and the Forge

#### [Submission URL](https://godotengine.org/article/collaboration-with-google-forge-2023/) | 149 points | by [piebro](https://news.ycombinator.com/user?id=piebro) | [51 comments](https://news.ycombinator.com/item?id=38651818)

Godot, the open-source game engine, has announced a collaboration with tech giant Google and The Forge, a renowned developer specializing in game engines and rendering solutions. The partnership aims to enhance Godot's Vulkan mobile backend, primarily benefiting developers building games for Vulkan-capable mobile devices. Google's commitment to bolstering the Android gaming ecosystem and ensuring strong Vulkan support across games, game engines, and devices has prompted their assistance in optimizing Godot's Vulkan mobile renderer. Over the next few months, The Forge will lend their expertise to Godot, with support from Google experts and existing Godot contributors. This collaboration aims to foster an exceptional ecosystem for Android games, enabling developers to push the boundaries of creativity with Vulkan.

The discussion on the submission includes various comments discussing different aspects of the collaboration between Godot, Google, and The Forge to enhance Godot's Vulkan mobile backend. Some users express excitement about the positive impact on VR rendering, while others mention the potential benefits for game development on Linux platforms. There is also a discussion about the challenges of dealing with backward ABI compatibility and the implications for containerization. Some users express concerns about Google's involvement and the potential negative effects on the Godot community. The topic of .NET support and the possibility of Google and Microsoft improving it is also briefly mentioned.

### HuggingChat â€“ ChatGPT alternative with open source models

#### [Submission URL](http://huggingface.co/chat?model=mistralai/Mixtral-8x7B-Instruct-v0.1) | 56 points | by [victormustar](https://news.ycombinator.com/user?id=victormustar) | [6 comments](https://news.ycombinator.com/item?id=38655495)

HuggingChat is a platform that is making the best AI chat models in the community accessible to everyone. However, it's important to note that AI is an area that is still actively being researched and has known problems such as biased generation and misinformation. Therefore, the platform advises users not to rely on it for important decision making or seeking advice.

HuggingChat's latest version, v0.6.0, offers the meta-llama/Llama-2-70b-chat-hf model. This model is designed to have engaging conversations with users and can assist with various tasks. Some examples of what it can do include writing an email based on a bullet list, coding a snake game, assisting in a specific task, and even searching the web for information.

It's worth mentioning that when the web search feature is enabled, the model will attempt to provide additional information by querying the web. However, users should keep in mind that the generated content may not always be accurate or reliable.

Overall, HuggingChat aims to provide a user-friendly experience by leveraging the power of AI chat models.

The discussion on this submission revolves around the capabilities of the HuggingChat platform and the usage of AI chat models.

- One user, jshstrng, comments that they cannot wait for the MistralAI Mixtral-8x7B Instruct support and compares it to GPT-4. Another user, ZoomZoomZoom, responds that it has been pushed yesterday and works well.
- Another user, crknzk, shares their positive experience with MistralAI Mixtral-8x7B Instruct and mentions that it is a great service that is gaining popularity.
- User gscr discusses the web search capability of Language Models (LLMs) and mentions that LLM-based systems can access web search tools. They explain that the system can handle structured text, particularly in JSON format, and intercepts and detects structured responses from web search results. The user also mentions the retrieval augmented generation (RAG) technique, which combines web search with LLMs to retrieve and generate relevant information.
- PhilippGille adds to the previous comment, explaining that retrieval augmented generation (RAG) includes additional training data from web search results. They mention that if one searches for papers, tutorials, videos, etc., related to retrieval augmented generation, there are resources available.

Overall, the discussion focuses on the capabilities and potential of AI chat models, particularly in relation to web search and retrieval augmented generation techniques.

### ByteDance is using OpenAI's tech to build a competitor

#### [Submission URL](https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm) | 18 points | by [skagenpilot](https://news.ycombinator.com/user?id=skagenpilot) | [4 comments](https://news.ycombinator.com/item?id=38658870)

ByteDance, the parent company of popular app TikTok, is secretly using OpenAI's technology to develop its own large language model (LLM), according to leaked internal documents. This move is seen as a controversial shortcut in the AI industry, as it violates OpenAI's terms of service and Microsoft's policies, through which ByteDance accesses OpenAI. The project, codenamed Project Seed, heavily relies on OpenAI's API for training and evaluation, despite the prohibition on using the technology to develop competing AI models. Employees even discuss ways to "whitewash" the evidence of this misuse. The practice highlights the intense competition in the generative AI space.

The discussion on this submission revolves around the controversy surrounding ByteDance's use of OpenAI's technology to develop its own large language model (LLM). 
One commenter points out that the leaked documents suggest that ByteDance is using OpenAI's technology to improve its models despite violating OpenAI's terms of service (ToS) and Microsoft's policies. ByteDance apparently accesses OpenAI through Microsoft. The commenter also mentions that employees are discussing ways to hide evidence of this misuse, raising concerns about the intense competition in the generative AI space.
Another commenter adds that this is a significant story because ByteDance, the parent company of TikTok, is a big player in the industry. They speculate that there may be significant consequences for ByteDance, such as potentially being banned or facing additional scrutiny.
In response to this, another commenter points out that there is a leaked memo suggesting that OpenAI has already banned ByteDance's account.
One last comment in the discussion takes a different approach by jokingly remarking that plagiarizing machines will soon be posting their plagiarized works.
Overall, the discussion highlights the ethical and competitive issues surrounding ByteDance's alleged misuse of OpenAI's technology and the potential consequences it may face.

### Metasurface antenna to manipulate all fundamental characteristics of EM waves

#### [Submission URL](https://www.nature.com/articles/s41467-023-40717-9) | 17 points | by [ortusdux](https://news.ycombinator.com/user?id=ortusdux) | [5 comments](https://news.ycombinator.com/item?id=38658931)

Researchers have proposed and demonstrated a universal metasurface antenna (UMA) capable of manipulating all characteristics of electromagnetic waves simultaneously and independently. Metasurfaces have the potential to revolutionize various photonic and electronic devices, but controlling all wave properties has been a challenge. The UMA allows for dynamic, software-defined manipulation of properties such as amplitude, phase, frequency, polarization, and momentum. This opens up possibilities for more complex waveform generation, beamforming, and information manipulation, potentially simplifying the architecture of information transmitter systems. The UMA could have applications in next-generation wireless systems, cognitive sensing, imaging, quantum optics, and quantum information science.

The discussion on the proposed universal metasurface antenna (UMA) highlights the potential applications and implications of this technology. One user mentions previous research on photonic chips that transform light beams with multiple properties and another user shares two related articles on universal visible matter integration and coherent surface plasmon polariton amplification. Another user finds the concept of software-defined manipulation of electromagnetic wave properties interesting, particularly in terms of reducing interference and allowing for station streaming of beams. The discussion then veers into topics such as reversible debatable quantum properties and the Church-Turing-Deutsch complete quantum platform.

Lastly, a user suggests that software-defined lenses could have revolutionary potential in various fields.

---

## AI Submissions for Thu Dec 14 2023 {{ 'date': '2023-12-14T17:10:26.485Z' }}

### Embeddings, vectors, and arithmetic

#### [Submission URL](https://montyanderson.net/writing/embeddings) | 68 points | by [montyanderson](https://news.ycombinator.com/user?id=montyanderson) | [16 comments](https://news.ycombinator.com/item?id=38645411)

Monty Anderson, in his blog post titled "Embeddings, Vectors, and Arithmetic," explores the concept of embeddings as a representation of text and the computational operations that can be performed on them. He references Lilian Weng's project, which showcases a ranking of the closest emojis to a search query in the meaning-space. The emoji vectors are calculated using the OpenAI's Ada model, and the results are based on the euclidean distance or cosine similarity. Building on this idea, Anderson and Barney Hill developed an app that allows users to add two emojis and find the closest known emoji to that result. While the project worked well, it also revealed the stereotypes and flaws present in the training data. Anderson mentions their exploration of building safety systems at Prodia by checking if input prompts are within a distance threshold of known adult or illegal concepts. The post concludes by hinting at a fuzzy future where machines can reason about meaning in various types of data, not just text.

The discussions around Monty Anderson's blog post "Embeddings, Vectors, and Arithmetic" cover various aspects related to vector embeddings and their applications. 
User "YPCrumble" expresses their interest in vector embeddings, while user "wyncchrn" asks a question about embeddings in linear space and discusses how addition operations can make sense. User "bnrymx" comments that the blog post does not mention that the training data used GloVe, a popular model for word vector spaces. Other users add positive comments about embeddings, with one mentioning the usefulness of GloVe and another noting that linear models and PCA can be employed.
User "throwup238" shares their experience in building safety systems at Prodia, where they investigate distance thresholds for known adult or illegal concepts. They mention that these measures are necessary due to the limitations and uncertainties of embedding models.
The conversation continues with discussions about embedding categorization, fingerprints, and retrieval results for different sizes of text. User "mntyndrsn" comments on using embedding for safety filters and having different models for different purposes. User "batch12" mentions their struggle with semantic meaning in retrieval results. User "ptr" suggests expanding the process of using various tools for embedding-based search.
User "ttcr" raises concerns about embeddings and illegal concepts, noting that embeddings are not objective and that measuring similarity distances should not punish or censor certain concepts. User "rbrnd" argues that embeddings are not objective due to the complexity of training data, while expressing their love for AI finding traditional winter message boards. The discussion then diverges into debates about censorship, privacy, and the influence of AI technology on society.

The last comment, by user "jflkn", seems to be flagged and doesn't contribute to the discussion.

### Stable Zero123: Quality 3D Object Generation from Single Images

#### [Submission URL](https://stability.ai/news/stable-zero123-3d-generation) | 86 points | by [homarp](https://news.ycombinator.com/user?id=homarp) | [8 comments](https://news.ycombinator.com/item?id=38647562)

Stability AI has released Stable Zero123, their in-house trained model for view-conditioned image generation. This model generates 3D objects with improved quality compared to the previous state-of-the-art model, Zero123-XL. The improvements were achieved through an improved training dataset, elevation conditioning, and a pre-computed dataset. Stable Zero123 is now available for download on Hugging Face for researchers and non-commercial users to experiment with. Additionally, Stability AI has improved the open-source code of threestudio to support Zero123 and Stable Zero123, enabling open research in 3D object generation. However, it's important to note that this model is intended for non-commercial and research use only.

The discussion surrounding the submission is varied. Users are generally impressed with the improved results of Stable Zero123 compared to the previous model, Zero123-XL. Some users discuss the limitations of 3D object generation, particularly in the context of augmented reality (AR) where there is a lack of available 3D objects. One user mentions Amazon's proposed solution of digitizing physical objects using computer vision, while another user highlights the challenges of creating accurate 3D models due to factors like licensing, object complexity, and optimization. The discussion also touches on the limitations of AR experiences, particularly in terms of delivery and the availability of 3D models. Some users express interest in the application of augmented reality in the clothing industry, while another user promotes Matterport as a popular solution for creating 3D models. Lastly, there is a brief mention of the high costs and complexities involved in generating fully rigged 3D models through conventional means.

### Vision Pro will change photography

#### [Submission URL](https://om.co/2023/12/14/why-vision-pro-will-change-photography/) | 54 points | by [SLHamlet](https://news.ycombinator.com/user?id=SLHamlet) | [73 comments](https://news.ycombinator.com/item?id=38645283)

Apple's upcoming Vision Pro, a spatial computer worn on the face, is set to redefine our relationship with visual media. The device allows users to capture spatial videos, a mixed-reality format that records depth and spatial information, offering a more immersive 3D experience when played back on the Vision Pro's high-resolution display. While the videos are slightly lower quality due to the limitations of the ultra-wide lens, they have a dreamlike quality that resembles memories. Spatial videos have the potential to revolutionize storytelling and photography, offering a new way to capture and experience moments. In addition to spatial video, the Vision Pro also enhances the viewing experience of photos, allowing users to pinch and expand images for a more immersive experience. Overall, the Vision Pro is shaping up to be a game-changer in the world of mixed reality glasses.

The discussion surrounding the submission on Apple's upcoming Vision Pro focuses on various aspects of the device and its potential impact. Several comments discuss the limitations and practicality of the product. Some mention that the performance may not be worth the high price tag, while others express skepticism about the usefulness of virtual reality (VR) solutions in a productivity context. The discussion also touches on related topics such as the difference between virtual reality and augmented reality, the potential for VR in photography, and the comparison to previous technologies like Lytro and Google Cardboard. Some comments question the accuracy and reliability of the device's depth mapping capabilities, while others mention the integration of similar functionalities in existing smartphone cameras. There is also a comment criticizing the relevance of the discussion and the hype surrounding the product. Overall, the comments provide a range of perspectives on the potential impact and practicality of Apple's Vision Pro.

### The AI Trust Crisis

#### [Submission URL](https://simonwillison.net/2023/Dec/14/ai-trust-crisis/) | 308 points | by [simonw](https://news.ycombinator.com/user?id=simonw) | [272 comments](https://news.ycombinator.com/item?id=38643046)

Dropbox has faced a wave of criticism after introducing new AI features that some users fear jeopardize the privacy of their data. The concern arises from the belief that Dropbox is sharing user files with OpenAI for training its models, a claim vehemently denied by Dropbox. While Dropbox's AI features, such as "summarize on demand" and "chat with your data," seem sensible, the company's communication on data privacy and AI has been lacking, leading to a crisis of trust. The existence of a checkbox buried deep in the settings, which appeared to enable data usage for AI training, only added to the confusion. People's skepticism is reminiscent of the belief that Facebook spies on users through their phone's microphone, despite such claims being debunked. The issue at hand is that trust in AI companies is eroding, with their assurances overshadowed by the mysterious nature of AI models and the lack of transparency in their training data. Trust is crucial, and allegations of deceit regarding user privacy must be taken seriously by both companies and regulators.

The discussion on this submission revolves around concerns over Dropbox's new AI features and the company's approach to privacy. Some users criticize Dropbox for allegedly sharing user files with OpenAI, while others argue that the claims are baseless. The lack of clear communication from Dropbox regarding data privacy and AI training has led to a crisis of trust. Additionally, the comparison is made with the belief that Facebook spies on users through their phone's microphone. The overall sentiment is that trust in AI companies is eroding, and allegations of deceit regarding user privacy should be taken seriously by both companies and regulators. 

In the comments, there is a discussion about the legal implications of consent and contracts, with some users arguing that silent consent can be considered fraudulent. Others argue that digital contracts should not be binding, and that current laws are not always applicable to digital transactions. The conversation also touches on the role of government regulation, with some users expressing cynicism towards the power of regulations like GDPR in protecting user privacy.

There are also comments discussing the flawed nature of third-party apps accessing phone microphones and the importance of data privacy and trust in AI companies. The conflicting perspectives highlight the ongoing debate about privacy, consent, and the responsibility of technology companies in safeguarding user data.

### DeepMind AI outdoes human mathematicians on unsolved problem

#### [Submission URL](https://www.nature.com/articles/d41586-023-04043-w) | 102 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [18 comments](https://news.ycombinator.com/item?id=38646123)

An AI system called FunSearch, based on large language models (LLMs), has made progress in solving combinatorics problems inspired by the card game Set. Combinatorics is a field of mathematics that studies how to count the possible arrangements of sets with finite objects. FunSearch generates requests for an LLM to write computer programs that can generate solutions to a specific mathematical problem. The system then quickly checks whether the generated solutions are better than existing ones and provides feedback to improve in subsequent rounds. FunSearch has shown that LLM-based systems can go beyond what is already known by mathematicians and computer scientists, making it a valuable tool in mathematical discovery and problem-solving.

The discussion on Hacker News revolves around the submission discussing FunSearch, an AI system based on large language models (LLMs) that can solve combinatorics problems. Here are the key points from the discussion:

1. Some users express skepticism about the potential of LLMs in solving complex mathematical problems, stating that LLMs are not a replacement for human mathematicians and that computers alone have not solved fundamental math problems.
2. Others argue that LLMs are capable of generating computer programs that explore large solution spaces, which can be helpful in discovering novel solutions. They suggest that in the future, LLM-based systems might be able to make significant contributions in fields like materials science and protein folding.
3. There is a discussion about the hybrid nature of FunSearch, which combines LLMs with human effort. Users point out that LLMs are not a complete replacement for human-generated data and that the reported results of FunSearch are a combination of LLM-generated programs and insights refined through iterations of the workflow.
4. Some users challenge the notion that LLMs are a form of artificial general intelligence, stating that they are not truly intelligent but rather stochastic pattern-recognition systems.
5. The availability of code for the discovered solutions is mentioned, with users finding it disappointing that the details of the method and the implemented algorithm are missing.
6. The discussion also touches on the effectiveness of FunSearch in solving difficult problems and discovering new knowledge. FunSearch is commended for pushing the boundaries of existing LLM-based approaches and demonstrating its effectiveness in combinatorics.
7. Some users express excitement about the potential of LLMs in aiding mathematical discovery and problem-solving, citing the success of similar approaches in the past.
8. The relevance of FunSearch to mathematical benchmarks and the importance of human input in the process are also discussed.
9. A link to the GitHub implementation of FunSearch is shared, leading to further discussion about the distributed system and the details of the method.
10. Overall, the discussion encompasses a range of opinions about the capabilities and limitations of LLMs in solving combinatorics problems, and the potential impact of FunSearch in various domains.

### Windows AI Studio Preview

#### [Submission URL](https://github.com/microsoft/windows-ai-studio) | 195 points | by [Jayakumark](https://news.ycombinator.com/user?id=Jayakumark) | [68 comments](https://news.ycombinator.com/item?id=38637853)

Microsoft has released a preview of Windows AI Studio, a platform that simplifies generative AI app development. It brings together AI development tools and models from Azure AI Studio Catalog and other catalogs like Hugging Face. With Windows AI Studio, developers can browse AI models, download them locally, fine-tune them, and use them in their Windows applications. All computation happens locally, but in the future, Windows AI Studio plans to integrate ORT/DML to run AI models on any Windows Hardware. Currently, Windows AI Studio only runs on NVIDIA GPUs.

The discussion on this submission revolves around various topics related to Windows AI Studio and the use of AI models on different platforms.

- One user faced some issues while installing Windows AI Studio and mentioned that they had to disable Python scripts.
- Another user suggested trying the command "conda config --set auto_activate_base false" to solve the issue.
- Some users commented on the fact that Windows AI Studio only runs on NVIDIA GPUs currently.
- There was a discussion about the differences between running AI models on Linux and Windows, with some users pointing out that there may be better compatibility with NVIDIA drivers on Linux.
- Some users shared their experiences with running CUDA on WSL2, with some saying it provided a good experience and others facing difficulties.
- There was a mention of ROCM support for Windows and the support of CUDA on current-generation cards.
- One user raised the question of whether this is the year of the Linux desktop, and others shared their thoughts on the topic.
- The discussion also touched on the release of an official OCR model by Microsoft and the availability of AI models for text recognition.
- A user commented on Apple's hardware and its potential for AI development, mentioning the limitations of RAM and GPU options.
- There was a discussion comparing Apple's GPUs with NVIDIA's in terms of VRAM and memory capabilities for machine learning tasks.

Overall, the discussion covers various aspects of AI development, including platform compatibility, hardware limitations, and the release of AI models.

### The AI revolution is an opportunity for writers (the human kind)

#### [Submission URL](https://on.substack.com/p/the-ai-revolution-is-an-opportunity) | 14 points | by [cjbest](https://news.ycombinator.com/user?id=cjbest) | [3 comments](https://news.ycombinator.com/item?id=38636159)

A recent article on Substack posits that the AI revolution is actually an opportunity for human writers, despite the fears and concerns that many may have. The article points out that while AI can generate content, it cannot replace the human connection and creativity that comes from writers and other culture makers. The author argues that as AI takes over the mundane and repetitive tasks of content creation, it will actually increase the value of original human work. The article emphasizes that platforms like Substack, which prioritize human-to-human relationships and connections, will continue to thrive in the era of AI. The author concludes by stating that the true opportunity of the AI revolution lies in the unique perspectives and abilities of human writers and culture makers.

The discussion on the submission revolves around different perspectives on the role of AI in content creation and its impact on human writers. 
User "gentleman11" shares skepticism about the opportunity for human writers on platforms like Substack, suggesting that it might not be enough to navigate a brave new world. 
User "mdmsmrt" brings up the idea that AI is just a human-made part of the smartphon environment and the transition to an AI-dominated world may be hampered by human habits and preferences. They mention that humans still spend quality time on their smartphones and argue that AI-generated content might not be able to bridge the gap completely. 
User "tmrkzm" comments that making real content available is a hopeful and positive idea for creating job opportunities for human writers. 
User "Mobil1" simply confirms the accuracy of the summary by saying "dd," which likely stands for "done."

### Ted AI 2023

#### [Submission URL](https://www.ai-event.ted.com) | 14 points | by [gardenfelder](https://news.ycombinator.com/user?id=gardenfelder) | [4 comments](https://news.ycombinator.com/item?id=38647123)

TED AI: Exploring the Profound Implications of Artificial Intelligence

Get ready to dive into the world of artificial intelligence at TED AI, a full day conference that delves deep into the transformative power of AI. Hosted by Chris Anderson, Head of TED, and curated by Sam & Walter De Brouwer, this event brings together pioneers and trailblazers to discuss how AI is set to revolutionize our civilization, industries, institutions, communities, and cultures. In addition to the conference, there is also a 2-day hackathon focused on using AI for social causes. If you have a passion for creating AI solutions that make a positive impact, this is your chance to join the community and showcase your skills. The winning project will even be featured on the TED AI stage. The lineup of speakers is incredibly diverse and includes renowned individuals such as Shane Legg, Ilya Sutskever, Stephen Wolfram, Eric Topol, Liv Boeree, and many more. They will discuss topics ranging from the transformative potential of AGI to the dark side of competition in AI. Aside from the talks, there will be engaging panels and workshops where you can enhance your AI skills and engage in interactive discussions with the speakers. This event wouldn't be possible without the support of generous partners, who have helped shape the experience. Make sure to check them out and appreciate their invaluable contributions. Don't miss out on this exciting opportunity to explore the future of AI. Join the TED AI community and brace yourself for an impactful event that promises to reshape the way we think about artificial intelligence.

The discussion about the submission seems to have mixed responses. One user, mdrzn, suggests that they are excited about the upcoming event, while another user, hppnd, criticizes the quality and downplays the significance of recent TED talks.  In response to hppnd's comment, user lfszvntt agrees and believes that the quality of TED talks has gone downhill, specifically mentioning the lack of substantial speeches. However, user grdnfldr counters this argument by stating that the value of TED talks depends on the viewer, suggesting that some talks are truly worthwhile. Lastly, user grdnfldr comments on the original submission, stating that the TED AI event is focused on the power and impact of AI.

Overall, the discussion contains differing opinions about the quality and relevance of TED talks, as well as some anticipation for the TED AI event.

---

## AI Submissions for Wed Dec 13 2023 {{ 'date': '2023-12-13T17:14:34.570Z' }}

### SMERF: Streamable Memory Efficient Radiance Fields

#### [Submission URL](https://smerf-3d.github.io/) | 578 points | by [duckworthd](https://news.ycombinator.com/user?id=duckworthd) | [136 comments](https://news.ycombinator.com/item?id=38632492)

Researchers from Google DeepMind and Google Research have introduced a new view synthesis approach called SMERF (Streamable Memory Efficient Radiance Fields) that enables real-time rendering of near-photorealistic scenes on commodity smartphones and laptops. Unlike previous methods that use either explicit scene representations or neural fields for ray marching, SMERF combines both approaches to achieve high quality and real-time performance. The researchers developed a hierarchical model partitioning scheme to increase model capacity while constraining compute and memory consumption. They also used a distillation training strategy to improve image fidelity by leveraging a state-of-the-art offline radiance field as a teacher model. SMERF outperforms existing real-time methods on large scenes, achieves faster rendering speeds, and is compatible with a wide variety of devices, including smartphones. The technology allows for full six degrees of freedom (6DOF) navigation within a web browser. The researchers have provided video demonstrations of SMERF's capabilities on various scenes, such as Berlin, NYC, London, and more. The code and pre-trained models are open source and can be accessed on GitHub.

The discussion on this submission covers a wide range of topics related to the technology and its applications:

- Some users express their amazement at the capabilities of the SMERF technology, particularly in terms of rendering photorealistic scenes in real-time on smartphones.
- There is a discussion about the potential applications of this technology in the real estate market, allowing users to virtually navigate properties in a realistic manner.
- Users share their experiences and thoughts on the quality of the rendered scenes, with comments about specific locations like Berlin and NYC.
- There are comments about the spooky and ghostly effects seen in some of the rendered scenes, particularly reflections and blurriness.
- Discussions also touch on the technical aspects of the technology, such as the challenges of 3D reconstruction and rendering highly reflective surfaces.
- Some users express interest in the code and models used in SMERF, requesting access to them or asking about the licensing.
- There is also a mention of other related technologies, such as Gaussian Splatting and the use of DSLRs for photogrammetry.
- Finally, there are comments expressing excitement about the advancements in VR technology and the potential for future developments.

Overall, the discussion highlights both the impressive capabilities of the SMERF technology and the various technical and practical aspects related to its use.

### The limitations of deep learning (2017)

#### [Submission URL](https://blog.keras.io/the-limitations-of-deep-learning.html) | 43 points | by [andrelaszlo](https://news.ycombinator.com/user?id=andrelaszlo) | [13 comments](https://news.ycombinator.com/item?id=38635452)

In a post from the book "Deep Learning with Python," the author discusses the simplicity of deep learning and how it operates in a geometric space. Deep learning models use parametric models trained with gradient descent to transform input data into output data. This transformation is broken down into simple geometric transformations performed by different layers in the model. The key is that the transformation must be differentiable to allow for gradient descent. The author compares this process to uncrumpling a paper ball in 3D. However, there are limitations to what deep learning can accomplish. Tasks that require reasoning, algorithmic-like data manipulation, and long-term planning are out of reach for deep learning models. Additionally, most programs cannot be expressed as continuous geometric transformations, making them difficult to learn. Increasing the number of layers and training data can only partially alleviate these limitations. The author also warns against anthropomorphizing deep learning models, as they do not truly understand the content they are working with.

The discussion on this post revolves around several points. 
One commenter argues that anthropomorphizing AI and treating it as if it has human-like consciousness is incorrect and stems from a narrow perspective on intelligence. They believe that animals possess various forms of intelligence and consciousness that are different from human cognition, and it is incorrect to attribute human-like qualities to AI.
Another commenter disagrees and suggests that AI does not possess significant cognitive abilities or intelligence similar to humans. They argue that animals have different types of intelligence and consciousness, and AI does not possess those qualities.
In response to the discussion on anthropomorphizing AI, another commenter brings up the limitations of deep learning. They discuss that it is not feasible for deep learning models to generate papers, codebases, or complex systems just by reading product descriptions. They argue that the complexity threshold for generating functioning code is quite high, and deep learning models would require multiple rounds of correction and a significant amount of time to achieve any level of success.
Another commenter points out that the original post from the book "Deep Learning with Python" has limitations in terms of its perspective on AI progress. They believe that progress has been slower than predicted, and there are still many challenges to overcome in natural language processing and generalization.

Overall, the discussion touches on the limitations of deep learning, the anthropomorphizing of AI, and the challenges in AI progress.

### Google Imagen 2

#### [Submission URL](https://cloud.google.com/blog/products/ai-machine-learning/imagen-2-on-vertex-ai-is-now-generally-available) | 237 points | by [geox](https://news.ycombinator.com/user?id=geox) | [178 comments](https://news.ycombinator.com/item?id=38628417)

Google Cloud has announced the general availability of Imagen 2 on Vertex AI, their advanced text-to-image technology. Imagen 2 allows customers to generate high-quality, photorealistic, and aesthetically pleasing images from natural language prompts. It also supports text rendering in multiple languages, logo generation, visual question and answering, and more. Imagen 2 is integrated with safety features to ensure responsible AI usage, including digital watermarking and safety filters. Customers such as Snap, Shutterstock, and Canva have already started leveraging Imagen API to enhance their products and services.

The discussion on Hacker News about Google Cloud's announcement of Imagen 2 on Vertex AI revolves around various topics. 
One user mentions trying to use Imagen 2 but facing issues with changing JavaScript variables, while another user points out that the documentation is incomplete. There is also a comment expressing disappointment in Google's presentation of their AI products.
The discussion then diverges into a comparison between Android and iOS, with users discussing the advantages and disadvantages of each platform.
Some users express frustration with Google's marketing tactics and difficulty in accessing AI tools like Imagen. Others mention the importance of stability and reliability in AI models and caution against cherry-picking impressive examples.
There is a comment about the difficulty in understanding composition instructions when generating images using AI models like Imagen, and a suggestion to use text-to-music generation as an alternative.
The discussion also touches on the nature of AI advancements and the challenges designers and illustrators face in adapting their work to different platforms.

Overall, the discussion covers a range of topics including technical issues, marketing strategies, and the complexities of generating images using AI models.

### Artificial intelligence systems found to excel at imitation, but not innovation

#### [Submission URL](https://techxplore.com/news/2023-12-artificial-intelligence-excel-imitation.html) | 118 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [109 comments](https://news.ycombinator.com/item?id=38627816)

Artificial intelligence (AI) systems excel at imitation but struggle with innovation, according to researchers at the University of California, Berkeley. While humans, including young children, are able to find novel uses for everyday objects, AI systems lack this ability. The researchers conducted experiments comparing the performance of AI language models with that of children and adults. They found that while the AI models could imitate human responses, their ability to innovate and find non-obvious solutions was lacking. The researchers suggest that AI systems act more like "libraries" or search engines, summarizing existing knowledge rather than creating new ideas. However, they also note that there is still much to be learned about AI and its potential for innovation in the future.

The discussion on the submission revolves around the topic of AI's ability to innovate compared to humans. Some comments argue that AI's lack of innovation is due to its composition and reliance on existing knowledge, while others point out that innovation requires a combination of randomness and composition. There is also debate about whether innovation should be based on random generation or tested combinations. Some users argue that AI models have limited training in text messages, while others believe that machines with higher fidelity connections to the world can manipulate objects and generate higher-level concepts. The limitations and potential of AI in terms of creativity and innovation are also discussed, with some users emphasizing the role of observation and experience in human creativity. Additionally, there is discussion about the difference in quality and content between AI-generated and human-generated content.

### Partnership with Axel Springer to deepen beneficial use of AI in journalism

#### [Submission URL](https://openai.com/blog/axel-springer-partnership) | 26 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [10 comments](https://news.ycombinator.com/item?id=38627619)

OpenAI has partnered with publishing house Axel Springer to integrate journalism into AI technologies. This collaboration will enhance the user experience of OpenAI's ChatGPT by incorporating recent and authoritative content from Axel Springer's media brands, such as POLITICO, BUSINESS INSIDER, BILD, and WELT. Users will receive summaries of selected global news articles, even those behind paywalls, with attribution and links to the full articles for transparency. The partnership aims to support independent journalism, improve content experiences, and create new financial opportunities. Additionally, Axel Springer's quality content will contribute to the training of OpenAI's large language models.

The discussion on the submission revolves around various aspects of the partnership between OpenAI and Axel Springer.

- One user criticizes Axel Springer's Bild-Zeitung and accuses it of being a sensationalist newspaper with poor journalistic ethics.
- Another user expresses disappointment with Axel Springer's content on Samsung phones' Upday app, referring to it as trash and suggesting that OpenAI should be careful about partnering with such companies.
- One user comments on the irony of OpenAI, a company known for its focus on AI ethics, integrating journalism from a publication accused of sticking to its own facts.
- The CEO of Axel Springer, Mathias Dopfner, is mentioned by a user in a negative light for allegedly using derogatory terms to describe East Germans and being politically biased.
- The potential dangers of AI-generated news and the impact on people's trust in journalism are discussed.
- A user shares a tweet from OpenAI announcing the partnership with Axel Springer.
- One user expresses concern about the inclusion of news in ChatGPT, suggesting that it could lead to biased or worrisome news consumption.

Overall, the comments highlight skepticism and concerns about the collaboration between OpenAI and Axel Springer, particularly in terms of the journalistic ethics and content quality of Axel Springer's media brands.

### QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models

#### [Submission URL](https://arxiv.org/abs/2310.16795) | 41 points | by [titaniumtown](https://news.ycombinator.com/user?id=titaniumtown) | [11 comments](https://news.ycombinator.com/item?id=38632390)

Researchers Elias Frantar and Dan Alistarh have developed a new compression and execution framework called QMoE, which allows for the practical compression of trillion-parameter models to less than 1 bit per parameter. This addresses the memory problem associated with large language models (LLMs) using mixture-of-experts (MoE) architectures. In their paper, titled "QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models," the authors describe how QMoE can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB, enabling the execution of trillion-parameter models on affordable commodity hardware. The framework achieves this with only minor accuracy loss and runtime overheads, making it a significant step toward more accessible and efficient deployment of large language models.

The discussion on Hacker News revolves around different aspects of the QMoE compression framework for trillion-parameter models. 
One user, "iTokio," comments that the affordable commodity hardware needed to run large models would include a single server with four NVIDIA A6000 and eight NVIDIA 3090 GPUs. They express excitement about the potential for affordable hardware.
Another user, "jtrnk," mentions that the cost of running models is reasonable at $4/hour, suggesting that the affordability of deployment is a significant advantage.
In response, user "wthnbrdm" discusses the cost of living in different countries and states that even in low-cost regions, the expenses for running large models can be too high.
A user named "nine_k" compares the cost of running models to the price of a hamburger, stating that if someone cannot afford a hamburger, then there may be problems with compressing trillion-parameter models.
User "vmch" humorously adds to the previous comment, saying that they cannot afford a hamburger either.
The user "sms" contributes by stating that running models for research purposes is affordable, especially since the starting points are small self-bootstrapped startups. However, they acknowledge that the expenses may become significant for data scientists working with full-scale models.
User "rnsr" suggests that NVIDIA's prices distort people's perception of affordability.
Moving on to the technical aspects of QMoE, user "krmkz" explains that QMoE can compress the 16 trillion-parameter SwitchTransformer-c2048 model to 160GB, achieving a compression ratio of 20x with 0.8 bits per parameter and only minor accuracy loss. They go on to explain briefly how QMoE achieves this compression level.
User "chssgck" expresses interest in whether QMoE exploits the low entropy of model parameters to achieve compression below 1 bit per parameter. They speculate that larger models might have smaller redundancy and warrant closer attention.
User "cynydz" suggests that sparse models might have negligible entropy, leading to almost zero compression using standard compression algorithms.
Lastly, user "kslm" offers a simple comment, stating "Nice."

### 2nd Batch of the A16Z Open Source AI Grant

#### [Submission URL](https://a16z.com/announcing-our-latest-open-source-ai-grants/) | 37 points | by [rajko_rad](https://news.ycombinator.com/user?id=rajko_rad) | [9 comments](https://news.ycombinator.com/item?id=38632827)

The announcement of the second batch of a16z Open Source AI Grant recipients has been made. The program aims to support the open-source AI ecosystem by providing grant funding to developers and small teams. This cohort focuses on two areas: tools for training language models and models and communities built around visual AI. The recipients include Common Crawl, Axolotl, SkyPilot, LMSys, LLaVA, Deforum, and Lucidrains. These projects contribute to strengthening the open-source AI ecosystem and advancing the field.

The discussion around the submission includes various comments about the different projects mentioned. Here are the key points:
- One user mentions that the support from a16z is significant for advancing the field of self-teaching process learning using Transformers in language models. They note that there are many implementations of Transformer-related papers in PyTorch, making it one of the largest publicly available collections.
- Another user points out that the grant recipients are not disclosed in the article, which sparks a brief conversation.
- There is a discussion about GPU strain monitoring, with one user mentioning that a GPU tool they checked showed a GPU utilization of 43%. Another user shares their love for this kind of technology.
- One user makes a comment about a hanging mobile, which is unrelated to the main topic.
- The mention of "Axolotl" in the submission title leads one user to think of the fictional creature from the Dune franchise. Another user clarifies that "Axolotl" refers to a type of salamander, and provides links to the creature's information.
- One user expresses surprise at the financial cost of the Common Crawl project, noting that it seems quite high for crawling a massively bloated, modern web.

Overall, the discussion touches on topics such as self-teaching process learning, GPU strain monitoring, the Dune franchise, and the cost of web crawling.

### First Impressions with Google Gemini

#### [Submission URL](https://blog.roboflow.com/first-impressions-with-google-gemini/) | 80 points | by [zerojames](https://news.ycombinator.com/user?id=zerojames) | [25 comments](https://news.ycombinator.com/item?id=38630349)

Google recently announced Gemini, a new Large Multimodal Model (LMM) that can process text, images, and audio. The Roboflow team analyzed Gemini's performance across various computer vision tasks and found that it excelled in some areas but struggled in others. Gemini is capable of answering questions about text, images, and audio. It launched with demos that showcase its ability to write code, explain math problems, find similarities between images, and more. However, there were claims that one or more demos were edited, raising doubts about the extent of Gemini's capabilities. Gemini has three versions: Ultra, Pro, and Nano. The Ultra model, which is currently unavailable, reportedly outperforms other LMMs on academic benchmarks. The Pro model is designed to scale across different tasks, while the Nano model is intended for use on mobile devices.

To run Gemini, you can use the Google Cloud Vertex AI Multimodal playground or send requests to the Gemini API. The API documentation provides more information on how to integrate Gemini into your applications. The Roboflow team evaluated Gemini on four computer vision tasks: Visual Question Answering (VQA), Optical Character Recognition (OCR), Document OCR, and Object Detection. Gemini performed well in some tests, accurately counting coins in an image and identifying a movie from a screenshot. However, it struggled with OCR, providing incorrect responses when asked to read a serial number or extract text from an image. Gemini's performance varied compared to other LMMs. For example, LLaVA, BakLLaVA, and CogVLM performed well in some tests where Gemini struggled. Overall, while Gemini shows promise in its multimodal capabilities, there are areas where it can be further improved.

You can try Gemini yourself using the Google Cloud Vertex AI Multimodal playground or explore its capabilities on the Roboflow Gemini playground page.

The discussion on the submission about Gemini, Google's new Large Multimodal Model (LMM), touched on various points:

- One commenter shared their experience with the web interface, mentioning intermittent performance in object detection and regularly running tests.
- There was speculation about whether Gemini could solve captchas related to safety.
- Some users commented on the readability and SEO optimization of the article, expressing a desire for more optimized articles that are easier to read.
- The analysis of Gemini's performance was discussed, with one commenter pointing out that Gemini struggled with certain tasks such as OCR but performed well in others.
- The formatting of the article was criticized for condensing the content too much and not providing sufficient depth, resulting in a summary that didn't fully capture the details.
- There was feedback on the inconsistencies and lack of clarity in the linking within the article, as well as repetitive screenshots that didn't provide much value.
- One commenter mentioned that they didn't find the article interesting enough to read it in Safari's reader mode.
- A comment pointed out that the discussion wasn't filtered by an AI prompt, which caused the responses to not flow smoothly.
- Some users discussed the possibility of using Gemini for data generation and training purposes.
- There was a question about how to achieve empty responses from the model using the HTTP API.
- Comparison between Gemini and GPT4 was mentioned, with Gemini reportedly outperforming GPT4 in some tests.
- There was an exploration of using GPT4 Vision directly through the API and analyzing its responses to image-related prompts.
- The effectiveness of Gemini's response to a prompt about counting coins was debated, with some users expressing doubts about the intelligent reasoning behind the answer.
- Overall, there were comments appreciating the analysis and discussing Gemini's performance in comparison to other models.

### GM says it's dropping Apple CarPlay and Android Auto because they're unsafe

#### [Submission URL](https://jalopnik.com/gm-drops-apple-carplay-android-auto-unsafe-phone-1851093013) | 181 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [415 comments](https://news.ycombinator.com/item?id=38622476)

General Motors (GM) is facing criticism for its decision to drop Apple CarPlay and Android Auto in favor of its in-house system, Ultifi. To defend its decision, GM claims that the popular phone mirroring programs actually pose safety risks by encouraging drivers to use their phones while behind the wheel. GM's head of product for infotainment, Tim Babbit, cited stability issues with CarPlay and Android Auto, such as bad connections and slow responses, which lead drivers to pick up their phones and take their eyes off the road. GM believes that if their in-house system is robust enough, drivers will be less likely to rely on their phones for their infotainment needs. The Ultifi system, debuting in the 2024 Chevy Blazer EV, uses Google apps like Maps and Assistant for enhanced voice controls. Additionally, GM is hoping to profit from driver data and subscription services through the Ultifi system. The success of this gamble remains to be seen as more GM vehicles integrate with Ultifi from next year.

The discussion on Hacker News revolves around the decision by General Motors (GM) to drop Apple CarPlay and Android Auto in favor of its in-house system, Ultifi. Some users sympathize with GM's position, noting that phone mirroring programs like CarPlay and Android Auto can be unreliable and may encourage drivers to use their phones while driving. Others argue that GM's decision is driven by self-interest and a desire to profit from driver data and subscription services. The discussion also touches on the reliability of infotainment systems in general, with users sharing their experiences with different car brands. Some users express concerns about the increasing control that Apple and Google have over the automotive industry, while others believe that vehicle manufacturers should focus on building their own in-house systems. Overall, the discussion highlights the varying opinions on the role of phone mirroring programs and the future of infotainment systems in cars.