import { SparkleIcon } from '@/components/SparkleIcon'
import { generateRssFeed } from '@/lib/generateRssFeed'

export async function getStaticProps() {
  if (process.env.NODE_ENV === 'production') {
    await generateRssFeed()
  }
  return { props: {} }
}

---

## AI Submissions for Fri May 05 2023 {{ 'date': '2023-05-06T00:23:21.363Z' }}

### Concrete: A fully homomorphic encryption compiler

#### [Submission URL](https://www.zama.ai/post/zama-concrete-fully-homomorphic-encryption-compiler) | 80 points | by [zacchj](https://news.ycombinator.com/user?id=zacchj) | [10 comments](https://news.ycombinator.com/item?id=35826723)

Zama has released their Fully Homomorphic Encryption (FHE) compiler, Concrete, designed to simplify the management of noise, cryptographic parameters selection, and order of operations for specific computations for developers. The Compiler expects an input program in MLIR, and it can be used via Python, C++, and C APIs as well as a CLI tool for debugging. The LibrarySupport class is one of the main entry points, enabling the compilation and execution of FHE programs while storing artifacts on disk. The compiled library is stored in a sharedlib file, along with a JSON file that describes the inputs and outputs and crypto parameters for the compiled function.

One commenter questioned the necessity of using encryption for weights, while another commenter pointed out that using FHE to protect software is similar to how Syncrosoft protected software using dongles. Another commenter mentioned that they have been working on developing a CPU designed for FHE for the past decade, while others compared Concrete to Google's FHE implementation. The discussion also included references to Concrete's code repository and a podcast on the intersection of FHE and zero-knowledge proofs.

### Shap-E: Generate 3D objects conditioned on text or images

#### [Submission URL](https://github.com/openai/shap-e) | 273 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [50 comments](https://news.ycombinator.com/item?id=35836976)

OpenAI has released its code and model for Shap-E, a system that generates 3D objects based on text or images. The release includes examples of models that can generate things like chairs that look like avocados, spaceships, and birthday cupcakes. Users can install Shap-E with pip, and access a variety of notebooks that provide guidance on encoding models, sampling 3D models based on a text prompt, and more. The code and model are available on GitHub under an MIT license.

Some users discuss their experiences with generating 3D objects, while others share examples of objects they have generated. Others comment on the difficulty of generating 3D models and suggest alternative tools. There is also discussion around the licensing of the code and models, as well as related topics such as 3D printing and file formats.

### Unlimiformer: Long-Range Transformers with Unlimited Length Input

#### [Submission URL](https://arxiv.org/abs/2305.01625) | 322 points | by [shishy](https://news.ycombinator.com/user?id=shishy) | [99 comments](https://news.ycombinator.com/item?id=35832802)

Researchers have proposed a new model called Unlimiformer, which extends the capabilities of existing transformer-based models by allowing them to handle unlimited input lengths for a better long-document and multi-document summarization. The model can be applied to any existing pretrained encoder-decoder transformer, and it offloads the attention computation across all layers to a single k-nearest-neighbor index that can be kept on the GPU or CPU memory and queried in sub-linear time. Unlimiformer has been shown to perform well on several benchmarks, summarizing even 350k token-long inputs from the BookSum dataset without any input truncation at test time. The code and models are publicly available online.

The comments section discusses topics such as the quality of pre-reviewed papers, self-aggrandizing behavior in the research community, challenges with peer review processes, differences between conferences and HN commenting, and the importance of feedback from the HN community.

### Bluesky's AT Protocol - Federation Architecture Overview

#### [Submission URL](https://blueskyweb.xyz/blog/5-5-2023-federation-architecture) | 137 points | by [capableweb](https://news.ycombinator.com/user?id=capableweb) | [79 comments](https://news.ycombinator.com/item?id=35834106)

Bluesky, the new social media platform built on the AT Protocol, is set to launch a sandbox environment for testing federation with allow-listed servers. A federated networking model, AT Protocol differs from conventional social media by allowing users to run their own servers, host data on a personal data server, and use big graph services to assemble and curate a personal feed. The architecture is expected to facilitate public conversations on a global social network, with an ecosystem of app views for each lexicon, including video, long-form blogging, and groups and forums. Bluesky aims to make federation easy and accessible to all.

The discussion around the submission on Hacker News includes various opinions and insights. Some users express concerns regarding Bluesky's implementation of centralization, such as difficulty in implementing control and filtering, while others believe that Bluesky's potential for transparency and decentralized social media could be a healthier alternative to existing platforms. Additionally, there is debate regarding the comparison between ActivityPub and Bluesky, with some users pointing out differences in their respective designs and certain limitations of ActivityPub. There is also discussion about the challenges of migration between servers and ways to address the issue of lost interactions in the process. Overall, the discussion brings up various important points related to decentralization and the future of social media.

### At Musk’s brain-chip startup, animal-testing panel is rife with conflicts

#### [Submission URL](https://www.reuters.com/technology/musks-brain-chip-startup-animal-testing-panel-is-rife-with-potential-conflicts-2023-05-04/) | 137 points | by [wootland](https://news.ycombinator.com/user?id=wootland) | [90 comments](https://news.ycombinator.com/item?id=35834918)

Elon Musk's brain-implant company, Neuralink, has come under fire for filling its animal-research oversight board with company insiders who may stand to benefit financially from the venture's development goals. According to documents and interviews with employees, 19 of the board's 22 members were Neuralink employees as of late 2022, raising questions about potential violations of conflict-of-interest regulations aimed at protecting research integrity. As we've previously reported, Neuralink is seeking regulatory approval for human trials of a brain chip intended to help paralyzed people type with their minds, among other goals.

Some users argue for the need for regulated and informed animal testing, while others argue for caution in human testing. There is also a debate on the efficacy and enforceability of current regulations, with some users calling for a change in regulations to better protect animals and humans involved in scientific research.

### Show HN: UnionX – GPT4-powered Copilot for Work with Jupyter-style notebooks

#### [Submission URL](https://www.unionx.io/) | 48 points | by [gangster_dave](https://news.ycombinator.com/user?id=gangster_dave) | [5 comments](https://news.ycombinator.com/item?id=35836679)

Looking for a way to boost your productivity and streamline your workflow? Look no further than UnionX, the AI-powered platform that lets you easily analyze documents, generate insights, and create new documents in seconds. Whether you're a data scientist, legal professional, or product manager, UnionX can help you save time and work more efficiently. With powerful tools like OpenAI's GPT4 model and Jupyter-style workflows, UnionX makes it easy to gather, analyze, and generate new insights from your data. So why wait? Try UnionX today and start achieving more in less time!

Some users feel that the concept sounds exciting, but the marketing documentation is not clear enough. They suggest pushing towards a Jupyter notebook interface for non-coding tasks and adding a coding interface for more technical users. Others believe that simple notebooks and screencaps of them would be helpful in understanding the product. The conversation then shifts to coding integration and the need for actual notebooks rather than lock-in options. One user also raises a question regarding comparing the platform's source version.

### The AI PR Industrial Complex

#### [Submission URL](https://www.bigtechnology.com/p/the-ai-pr-industrial-complex) | 80 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [36 comments](https://news.ycombinator.com/item?id=35829430)

In the rush for corporations, politicians, and other thought leaders to monetize and exploit the opportunities presented by AI technology, an AI PR industrial complex is emerging. This complex operates by using AI as a pretext for problems that might have other causes such as IBM's decision to replace up to 7,800 back-office employees with AI, as opposed to using the technology to make workers more productive. Similarly, politicians and regulators running to the cameras to talk about AI raises questions about their actual understanding of the technology's opportunities and risks. While some AI announcements have real substance, the AI PR industrial complex is growing and drawing deserved skepticism.

Commenters suggest that the AI hype is similar to the cryptocurrency hype of the past, and the emerging AI PR industry is drawing deserved skepticism. Some commenters talk about how AI technology may be applied for specific domain-specific tasks, such as creating 2D and 3D animations for games and designing dashboards and data visualization tools. There is also a discussion of how AI is being used to generate advertisements and how LLMs may be used to solve real-world problems in sectors such as energy and sustainable growth. 

### MosaicML MPT-7B: A Commercially-Usable LLaMa-Quality Model

#### [Submission URL](https://www.mosaicml.com/blog/mpt-7b) | 102 points | by [ml_hardware](https://news.ycombinator.com/user?id=ml_hardware) | [11 comments](https://news.ycombinator.com/item?id=35829800)

MosaicML, an AI platform, has launched its MPT-7B model series, comprising pre-trained transformers that enable faster training and inference. The series comprises four models: MPT-7B Base, a decoder-style transformer with 6.7 billion parameters; and three finetuned variants, including the super-long context MPT-7B-StoryWriter-65k+. MosaicML also released the entire codebase for pretraining, finetuning, and evaluating MPT, a framework for building LLMs, and training and deployment instructions. The models can be licensed for commercial use and are a response to a flurry of activity focused on open-source LLMs.

Some users express confusion around the size and input of the models, but overall, people are impressed with MosaicML's documentation and instructions for training and deployment. One user notes that the MPT-7B model is similar to LLaMa but shows significant improvements in some use cases. Others discuss the practical applications of such models, such as using them for chat instruction and generating long-form text. Finally, there are some comments about the potential future release of GPT-4 and speculation on its potential impact on the AI language modeling space.

### OpenAI changed its plans and won’t train on customer data, Sam Altman says

#### [Submission URL](https://www.cnbc.com/2023/05/05/sam-altman-openai-wont-tap-into-customer-apis.html) | 41 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [10 comments](https://news.ycombinator.com/item?id=35830107)

OpenAI has stopped training its large-language models, including the popular chatbot ChatGPT, with paying customer data. This change came as a response to customers who had requested that the company not use their data. OpenAI's terms of service were quietly updated in March to reflect this shift. However, the company's privacy and data protection policy only applies to customers who use the company's API services. The change highlights growing concerns about the use of large-language models such as ChatGPT in areas such as entertainment, where intellectual property rights are being challenged.

The comments on the submission discuss various aspects related to OpenAI's decision to stop training its large-language models with customer data. Some users suggest that OpenAI should provide more control to customers over their data, while others highlight the importance of licensing in protecting intellectual property rights. There is also a discussion on the efficacy of using domain-specific tasks for training language models and the limitations of publicly available training data. One user mentions Azure OpenAI services as a potential alternative.

---

## AI Submissions for Thu May 04 2023 {{ 'date': '2023-05-04T15:01:43.244Z' }}

### Rest in Peas: The Unrecognized Death of Speech Recognition (2010)

#### [Submission URL](https://robertfortner.posthaven.com/rest-in-peas-the-unrecognized-death-of-speech) | 37 points | by [jawns](https://news.ycombinator.com/user?id=jawns) | [43 comments](https://news.ycombinator.com/item?id=35800935)

Computer speech recognition hit a flatline in 2001 before it even reached human levels of accuracy, largely due to computers being unable to properly understand language. While progress has been made since the 1950s and 1960s, relying mainly on fast computers and digital text to supplement decades-old language machinery, current accuracy rates still hover around 80%, with humans at 98%. Despite billions of text at their disposal, machines are prone to risky guessing and limited by parsers and recognition systems that work only in certain linguistic domains. Efforts to allow programs to understand grammar and word meaning have been largely unsuccessful, leaving them with a significantly different understanding of language than humans.

The discussion among commenters touches on various topics, including the challenges of recognizing different dialects and accents, reinforcement learning and human feedback, the accuracy of speech recognition software and the importance of context in understanding speech. Some commenters also mention their experiences with specific speech recognition programs and datasets, such as Common Voice and Whisper.

### OpenLLaMA: An Open Reproduction of LLaMA

#### [Submission URL](https://github.com/openlm-research/open_llama) | 463 points | by [sadiq](https://news.ycombinator.com/user?id=sadiq) | [175 comments](https://news.ycombinator.com/item?id=35798888)

OpenLLaMA, an open-source reproduction of Meta AI's LLaMA language model, has been released on GitHub. In this release, a public preview of the 7B OpenLLaMA model trained with 200 billion tokens has been provided, along with PyTorch and JAX weights of pre-trained OpenLLaMA models, and their evaluation results and comparison against the original LLaMA models. Additionally, a new checkpoint of OpenLLaMA 7B trained on 300B tokens has been released to make the model broadly compatible with existing implementations. The results indicate that OpenLLaMA exhibits comparable performance to the original LLaMA and GPT-J across a majority of tasks and outperforms them in some.

In the comments, there is a discussion about the resources required for ML models and their training cost, along with recommendations to understand ML terms and concepts. There is also debate about the use of the word "hallucination" to describe the output of language models.

### Distilling Step-by-Step Outperforming Larger Language Models with Less Training

#### [Submission URL](https://arxiv.org/abs/2305.02301) | 144 points | by [verdverm](https://news.ycombinator.com/user?id=verdverm) | [33 comments](https://news.ycombinator.com/item?id=35810663)

Researchers have developed a new mechanism called "Distilling Step-by-Step" that trains smaller models to outperform larger language models (LLMs) using less training data. This method extracts LLM rationales to provide additional supervision for small models in a multi-task training framework, leading to better performance with fewer labeled/unlabeled training examples. Distilling Step-by-Step achieves better performance with substantially smaller model sizes and reduces both the model size and the amount of data needed to outperform LLMs. The method was successful in four NLP benchmarks and could help make LLMs more memory-efficient and compute-intensive for practical applications.

The comment section discusses the importance of smaller, task-specific models and the challenges of deploying large language models in practical applications due to memory and computation constraints. Furthermore, the commenters discuss related approaches like "Alpaca" and the impact of model licensing and commercialization.

### The first empirical study of the real-world economic effects of new AI systems

#### [Submission URL](https://www.npr.org/sections/money/2023/05/02/1172791281/this-company-adopted-ai-heres-what-happened-to-its-human-workers) | 112 points | by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) | [72 comments](https://news.ycombinator.com/item?id=35809397)

A recent study conducted by economists at Stanford University and MIT found that implementing an AI chatbot into customer service workflows resulted in a significant increase in productivity and customer satisfaction. The study looked at the effects of incorporating ChatGPT, a popular interactive AI chatbot, on a Fortune 500 company's customer support team. The chatbot, which was trained by reading previous conversations between reps and customers, helped customer support agents more effectively assist customers in real time and provided them with links to internal company information to solve technical problems. The results suggest that AI could have positive economic effects in improving productivity, but also highlight the potential for disruptive change and income inequality.

One commenter expressed skepticism about the study's premise, stating that deflection in the customer service world means preventing customers from talking to humans and that AI chatbots cannot completely replace skilled workers. Other discussions revolve around the possibility of AI systems having internal biases, lowering the skill bar, reducing human job function, and potential privacy concerns. Another commenter suggested ingesting data from different platforms such as Slack, Gmail, Jira, Meet, etc., associated with timestamps, as it can help assign higher importance to documents and policies based on their relevance. Another comment discusses a company that believes AI systems that do not employ cash but focus on skilled employees' knowledge are vital to maintain the system. However, this leads to wider income inequality between low and high-skilled workers.

### Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings

#### [Submission URL](https://lmsys.org/blog/2023-05-03-arena/) | 46 points | by [MMMercy2](https://news.ycombinator.com/user?id=MMMercy2) | [6 comments](https://news.ycombinator.com/item?id=35806589)

Chatbot Arena, a new benchmark platform for large language models (LLMs), has been released. The platform features anonymous, randomized battles in a crowdsourced manner, and uses the Elo rating system for ranking models – a system widely used in competitive games like chess. The platform allows users to contribute new models and evaluate them based on anonymous votes for which model performs better during chat interactions. The platform already has a leaderboard featuring Elo ratings of popular open-source large language models.

There were several comments on the submission. One user, HoshinoAI, mentioned that the platform uses a ranking algorithm called Glicko. Another user, zhsbg, provided a reference variant ELO. HoshinoAI then pointed out a matchmaking section on Dota 2's website and a Wikipedia page on the Glicko rating system. 

Another user, wchng, was surprised to learn that StableLM was not included in the LLaMA leaderboard. Another user, circuit10, stated that they had heard about it before. Another user, frdvr, simply commented, "good day." Finally, two users, lee101 and aaron695, left comments but they were not clear on their meaning.

### Poisoning Language Models During Instruction Tuning

#### [Submission URL](https://arxiv.org/abs/2305.00944) | 83 points | by [hardmaru](https://news.ycombinator.com/user?id=hardmaru) | [4 comments](https://news.ycombinator.com/item?id=35801673)

A new paper titled "Poisoning Language Models During Instruction Tuning" warns that adversaries can contribute poisoned examples to instruction-tuned language models (LMs), allowing them to manipulate model predictions whenever a desired trigger phrase appears in the input. By using as few as 100 poison examples, the model struggles to classify, summarize, edit, or translate that input accurately. The paper also shows that larger LMs are increasingly vulnerable to poisoning and that existing defenses provide only moderate protection while reducing test accuracy, raising concerns about the robustness and security of these models.

The discussion around this submission includes three comments. The first commenter shared a headline about a WhatsApp landing court in India and also mentioned some important points about dynamic malware detection and LLM. The second commenter mentioned something about a Manchurian GPU, but the context of this comment is unclear. The third commenter shared a meme about the background of the researchers involved in the creation of the paper, which features a clown and a conspiracy theory involving George Soros.

### SparseGPT: Language Models Can Be Accurately Pruned in One-Shot

#### [Submission URL](https://arxiv.org/abs/2301.00774) | 209 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [62 comments](https://news.ycombinator.com/item?id=35804556)

Researchers have developed a new pruning technique, called SparseGPT, that can efficiently and accurately reduce the size of large-scale generative pretrained transformer (GPT) models without impacting their accuracy. The method can prune models at least 50% sparsity in one-shot without retraining, such that over 100 billion weights from the models can be ignored at inference time. The project team could execute SparseGPT on the largest available open-source GPT-family models in less than 4.5 hours, making the method compatible with semi-structured patterns and weight quantization approaches.	Code for SparseGPT is available for use at GitHub.

Comments discuss the use of L1 regularization and random pruning techniques, the benefits and tradeoffs of different methods for training, and the practical applications of compressed models for inference. One commentator references a larger model than GPT-3 called PaLM 540B, which generates exciting possibilities for future research.

### The Full Story of Large Language Models and RLHF

#### [Submission URL](https://www.assemblyai.com/blog/the-full-story-of-large-language-models-and-rlhf/) | 107 points | by [pk3](https://news.ycombinator.com/user?id=pk3) | [20 comments](https://news.ycombinator.com/item?id=35803522)

This article provides a thorough overview of language models, from their fundamental ideas to the latest advancements. Language models are probabilistic models designed to learn statistical patterns in natural language, and they can predict the most probable words to follow a given input sentence. They are trained through self-supervised learning, a process that uses unannotated text to generate labels for training. One way to unlock the potential of language models is via the process of fine-tuning, which refines and adapts their knowledge to more specialized domains. However, the risks and misuse of language models have become a primary concern, leading to a demand for methods such as Reinforcement Learning from Human Feedback (RLHF) to control and steer these large-scale AI systems.

The discussion revolves around the potential of AI to find vulnerabilities in software and the ethics of using AI to find weaknesses that can be exploited by hackers. The conversation also touches on the importance of finding vulnerabilities in software and the cost of fixing them. Additionally, the community discusses the role of machine learning in finding and fixing vulnerabilities and the importance of transferring learning data to scale AI. Another topic of discussion was the advancements in language models and their potential to revolutionize the field of natural language processing. Finally, Reinforcement Learning from Human Feedback (RLHF) for training Language Models (LLMs) is highlighted as a critical development in the field of AI.

---

## AI Submissions for Thu May 03 2023 {{ 'date': '2023-05-03T15:01:43.244Z' }}

### GPT-4 Can’t Replace Striking TV Writers, but Studios Are Going to Try

#### [Submission URL](https://www.vice.com/en/article/pkap3m/gpt-4-cant-replace-striking-tv-writers-but-studios-are-going-to-try) | 48 points | by [shscs911](https://news.ycombinator.com/user?id=shscs911) | [36 comments](https://news.ycombinator.com/item?id=35806470)

The Writers Guild of America is currently on strike, protesting the use of AI as a replacement for human writers in film and television. The guild proposed to regulate the use of AI on union projects, but the Alliance of Motion Picture and Television Producers rejected the notion, calling the guild's request "absurd." Fears among writers include being underpaid to rewrite what they consider AI-generated "trash," and being replaced altogether by the machines. However, the reality is that AI still struggles to distinguish between true facts, has trouble personalizing outputs to users, and is very sensitive to framing and wording of prompts.

In the comments, users argue that AI is not yet advanced enough to fully replace human writers and that the WGA's request for regulations may be based on populist sentiment rather than a genuine need to protect its members. Some also suggest that AI-generated content could be useful for background material or non-dialogue scenes, while others question the legality of AI-generated material being awarded writing credits.

### Beware of AI pseudoscience and snake oil

#### [Submission URL](https://www.baldurbjarnason.com/2023/beware-of-ai-snake-oil/) | 233 points | by [bertman](https://news.ycombinator.com/user?id=bertman) | [171 comments](https://news.ycombinator.com/item?id=35800667)

The submission discusses the exaggerated claims of AI capabilities, the need for concrete evidence to back them up, and the importance of being skeptical. The discussion includes comments on the difference between pessimism and optimism in measuring AI capabilities, the misleading claims made by companies for marketing purposes, the risk posed by AI if not regulated properly, and the practical applications of AI. There is also a conversation about the terminology used to describe AI, including whether the term "lying" is appropriate, and criticism of the media for using sensational language to describe AI. Finally, there is a comparison made between the hype surrounding AI and the hype surrounding virtual machines and containers in the past, and the importance of technical experts in the decision-making process.

### NYC considers facial recognition ban for businesses, landlords after MSG debacle

#### [Submission URL](https://gothamist.com/news/nyc-council-facial-recognition-biometric-ban-businesses-landlords) | 18 points | by [lisasays](https://news.ycombinator.com/user?id=lisasays) | [5 comments](https://news.ycombinator.com/item?id=35810770)

New York City is considering introducing two bills that would restrict the use of facial recognition and other biometric surveillance technology by private businesses and landlords. The first bill would ban businesses from using facial scans or other biometric technology to identify customers, while the second would prohibit residential landlords from using the same sort of biometric identification of tenants and guests. The proposed legislation also includes requirements for explicit consent from tenants or customers for any other types of biometric data collection, and a ban on selling such data to third parties. The hearing follows previous efforts to restrict facial recognition tech in New York, including state legislators attempting to curb its use by landlords, government agencies and police.

The discussion revolves around the specifics of the bills, with some participants citing security concerns as a reason to allow the use of such technology while others argue in favor of privacy protection. Some commenters also dispute the effectiveness of facial recognition technology in preventing crime and suggest alternative solutions. One user proposes a solution of implementing a blacklist of people who have caused trouble in the past rather than resorting to facial recognition technology.

### The Discord Where Thousands of Rogue Producers Are Making AI Music

#### [Submission URL](https://www.vice.com/en/article/y3wdj7/inside-the-discord-where-thousands-of-rogue-producers-are-making-ai-music) | 21 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [3 comments](https://news.ycombinator.com/item?id=35808173)

A group of music producers and songwriters recently released an entire album called UTOP-AI that featured AI-generated versions of rapper Travis Scott's voice and other artists. However, the album was quickly taken down due to a copyright claim from Warner Music Group. As AI music becomes more popular, it has provoked a cultural debate. While AI creators defend the technology as a way to make music more accessible, many music industry professionals and other critics accuse creators of copyright infringement and cultural appropriation. The Discord server AI Hub hosts a large community of AI music creators behind some of the most viral AI songs, and it has over 21,000 users. However, the copyright issue in AI music is being heavily debated, with labels and publishers gearing up to tackle this new issue in the music industry.

One commenter named "slyll" asserts that copyright claims are becoming increasingly dubious since music producers can create songs with a similar style to famous artists without directly copying their music or lyrics. They argue that as long as the creator does not claim to be the original artist, and does not directly copy the music or lyrics, it should be legal. Another comment from "Nition" clarifies that the vocals used in AI-generated music are entirely created by an AI and not just manipulated versions of the original artists' vocals. A third commenter named "llmjms" did not have anything to add to the discussion.

### Amnesty International criticised for using AI-generated images

#### [Submission URL](https://www.theguardian.com/world/2023/may/02/amnesty-international-ai-generated-images-criticism) | 101 points | by [johnyzee](https://news.ycombinator.com/user?id=johnyzee) | [88 comments](https://news.ycombinator.com/item?id=35800210)

Amnesty International has faced backlash after using artificial intelligence (AI)-generated images to promote their reports on social media regarding the 2021 protests in Colombia. The images, which depicted instances of police brutality towards protesters, were criticised for being unrealistic and for undermining the human rights advocacy group's work by potentially feeding conspiracy theories. Amnesty's use of AI images raised questions about plagiarism and ethics in photojournalism. The group eventually removed the images and acknowledged the criticism but defended their intention of protecting protesters with anonymity.

Some commenters argue that the use of AI-generated images is part of a trend of human rights organisations relying on emotionally manipulative marketing campaigns to generate donations. Others point out that Amnesty International's budget is heavily spent on research and advocacy, rather than advertising, and that its efforts to protect protesters' anonymity were well-intentioned. The conversation also touched on related topics such as the use of AI-generated porn and the challenges of verifying identities in the porn industry. Amnesty International has acknowledged the criticism and removed the AI-generated images.

### AI vs. Hollywood: Writers battle “plagiarism machines” in union talks

#### [Submission URL](https://arstechnica.com/tech-policy/2023/05/ai-vs-hollywood-writers-battle-plagiarism-machines-in-union-talks/) | 19 points | by [m-watson](https://news.ycombinator.com/user?id=m-watson) | [3 comments](https://news.ycombinator.com/item?id=35806197)

The Writer's Guild of America (WGA) is seeking to limit the use of AI in writing film and TV scripts during an ongoing strike. WGA writers have raised concerns over AI-generated content being used as training data and the prospect of them being tasked with fixing "sloppy first drafts" created by AI. They also argue that existing scripts should not be used to train AI to avoid intellectual property (IP) theft. So far, studios have rejected WGA's proposals, instead offering to discuss new technologies annually. The strike is the first in 15 years and comes amid growing concerns over the impact of automation on jobs.

The first comment by "askin4it" expresses sarcasm towards the Writer's Guild of America for seeking to limit the use of AI in scriptwriting during a strike. The second comment by "crtrmn" suggests that the conflict could be easily resolved through cross-licensing deals. The third comment by "mansion7" argues that Hollywood and Silicon Valley are both supportive of high immigration numbers and replacing lower-paid American workers with foreigners, leading to political donations and complaints of xenophobia.

### “All Tomorrow’s Parties”: AI Synthesis – The End of Copyright as We Knew It

#### [Submission URL](https://www.heise.de/meinung/All-Tomorrow-s-Parties-AI-Synthesis-The-End-of-Copyright-as-We-Knew-It-8985282.html) | 23 points | by [walt74](https://news.ycombinator.com/user?id=walt74) | [11 comments](https://news.ycombinator.com/item?id=35799116)

In the age of machine learning, intellectual property and copyright laws face radical upheaval due to generative AI systems. Lawsuits against AI companies highlight concerns over protecting and promoting art and creativity. The distribution mechanisms of collecting societies like GEMA or VG Wort managing member copyrights risk fraudulent claims with easy-to-use AI-generated content capable of boosting profits. Generative AI models like Stable Diffusion or ChatGPT operate like library-like cultural technologies that provide access to and multiply knowledge creating “stochastic libraries” for interpolable data spaces computed by algorithms. The interpolative nature of AI models creates a huge explosive force for existing systems of copyright with each synthetic image or generative text the result of multidimensional interpolation of the latent space posing unprecedented problems for copyright law.

The submission discusses how generative AI systems are challenging intellectual property and copyright laws. The comments address issues such as the difficulty of capturing 99% of AI-generated content under copyright law and the need for consistency in digital property concepts. Some argue that licensing systems could benefit creators, but others point out that copyright-based systems are based on capital purchase and disregard inherent creators. There are concerns about synthetic AI-generated voices causing problems for contracts requiring identifiable voices, as well as the potential for AI to become a tool for criminals. The discussion highlights the complexity of IP and copyright laws in the age of AI.

### Google, Microsoft CEOs Called to AI Meeting at White House

#### [Submission URL](https://www.reuters.com/technology/google-microsoft-openai-ceos-attend-white-house-ai-meeting-official-2023-05-02/) | 89 points | by [kamban](https://news.ycombinator.com/user?id=kamban) | [104 comments](https://news.ycombinator.com/item?id=35802698)

The CEOs of Google, Microsoft, OpenAI, and Anthropic are set to meet with Vice President Kamala Harris and other top officials to discuss AI-related concerns on Thursday. The invitation, seen by Reuters, emphasized President Joe Biden's expectation that companies ensure their AI products are safe for public use. The concerns around AI technology include privacy violations, bias, and proliferation of scams and misinformation. The Biden administration has also been seeking public comments on proposed accountability measures for AI systems. The meeting will be attended by Biden's Chief of Staff, National Security Adviser, and Secretary of Commerce, among others.

There was a lengthy discussion on this submission, covering a range of topics related to AI. Some users expressed concern that regulating AI is difficult and that existing regulations can unintentionally harm innovation or favor established players. Others argued that regulations can protect consumers and create a level playing field. There was also discussion around the rise of language models like GPT and how they could be used to deceive people. Several users remarked that LLMs need to be regulated to prevent misinformation, while others noted the difficulty of regulating speech and the potential for unintended consequences. Some users suggested that AI regulation would require the expertise of qualified committees and government agencies. Finally, one user suggested that OpenAI and Anthropic should focus on demonstrating the safe use cases of their technology, rather than solely lobbying for regulation.

### GPT AI Enables Scientists to Passively Decode Thoughts in Groundbreaking Study

#### [Submission URL](https://www.artisana.ai/articles/gpt-ai-enables-scientists-to-passively-decode-thoughts-in-groundbreaking) | 8 points | by [ianrahman](https://news.ycombinator.com/user?id=ianrahman) | [4 comments](https://news.ycombinator.com/item?id=35810969)

Scientists have used a ChatGPT-like AI model to decode human thoughts with unprecedented 82% accuracy from functional MRI recordings, opening up new opportunities for neuroscience, communication, and human-machine interfaces. However, this breakthrough also raises serious concerns about mental privacy, emphasizing the need for policies to prevent potential misuse of this technology. The researchers also acknowledged the limitations of the current model and stressed the importance of using a subject's own brain recordings for accurate AI model training.

The first comment by user "djmps" states that using technology like ChatGPT can help people with disability to communicate better. The subsequent comment by user "lrmls" adds that such technology could also improve diagnostic accuracy in neurological conditions and could potentially replace the current gold standard - neurological examination - which has low fidelity.

The second comment by user "p--w" expresses amazement at the technology's accuracy and is reading technical papers that explain how it works. Another user "strng" responds by saying that while the technology is impressive, it is essential to validate the AI's ability to decode thoughts from fMRI data. They also mention that speech and thoughts are not necessarily the same, so listening to speech signals may not always be equivalent to decoding thoughts accurately.

### 25% of jobs set to be disrupted in the next 5 years – A.I. could play a key role

#### [Submission URL](https://www.cnbc.com/2023/05/02/nearly-25percent-of-jobs-are-set-to-be-disrupted-in-the-next-five-years-wef.html) | 46 points | by [hochmartinez](https://news.ycombinator.com/user?id=hochmartinez) | [71 comments](https://news.ycombinator.com/item?id=35804808)

According to a report from the World Economic Forum, approximately 23% of all jobs will be disrupted in the next five years. The report indicates that technological advancements such as Artificial Intelligence and climate change are key drivers in the job losses expected to take place, with administrative and traditional security roles being the most affected. However, the report also highlights that certain industries such as education, agriculture, and health will see higher creation of jobs enabled by technology. The report stresses that the rise of the green economy and higher standards for environmental, social and governance practices within companies will provide the biggest drivers for future job creation.

The debate in the comments centers on the impact of increased productivity and whether it benefits consumers or producers more. Some see the destruction of jobs as inevitable and emphasize the need for higher qualifications, while others believe that growth and progress can coexist with job security. Some are also critical of socialism and suggest that capitalism helps channel people's efforts into constructive endeavors.

---

## AI Submissions for Tue May 02 2023 {{ 'date': '2023-05-02T14:21:15.829Z' }}

### Jsonformer: Generate structured output from LLMs

#### [Submission URL](https://github.com/1rgs/jsonformer) | 300 points | by [yunyu](https://news.ycombinator.com/user?id=yunyu) | [78 comments](https://news.ycombinator.com/item?id=35790092)

Jsonformer is a new approach to generating structured JSON from language models, which addresses the challenges and limitations of current approaches. It is a wrapper around HuggingFace models that fills in the fixed tokens during the generation process, and only generates the content tokens. This makes it more efficient and bulletproof than existing approaches that rely on prompt engineering, fine-tuning, and post-processing. Jsonformer currently supports a subset of JSON Schema and comes with features such as bulletproof JSON generation, efficiency, and flexibility. It is built on top of the HuggingFace transformers library, making it compatible with any model that supports the HuggingFace interface. It is released under the MIT License, and you can install it via pip.

The discussion thread raised different issues such as the efficacy of the wrapper, the potential of Cue, and the complexities of long-form language models. Other contributors shared their approaches, ideas, and explorations of tools and libraries such as Recmos Cria, Llama Numpy, Transformers, and Clue. They addressed testing models, constraints and modifications, interoperability, and the role of language modeling in AI development and research.

### Avoiding hallucinations in LLM-powered applications

#### [Submission URL](https://vectara.com/avoiding-hallucinations-in-llm-powered-applications/) | 128 points | by [ofermend](https://news.ycombinator.com/user?id=ofermend) | [107 comments](https://news.ycombinator.com/item?id=35794010)

Hallucinations can occur when an LLM encounters an edge case or a rare scenario for which it wasn't adequately trained. Additionally, the LLM may generate responses by incorporating biases and patterns present in the training data, which can lead to nonsensical or biased answers. It's crucial to address these issues to improve the reliability and trustworthiness of LLM-powered applications. One promising solution to avoid hallucinations is "Grounded Generation," a research project that aims to ground LLMs in the real world by incorporating external knowledge sources. By providing contextual information to LLMs, Grounded Generation can help prevent hallucinations and generate more accurate and reliable responses.

 The discussion in the comments explores various approaches to addressing this issue, including incorporating external knowledge sources through "Grounded Generation" and the difficulty of modeling human-like truth-telling. Issues of biased and nonsensical responses generated by LLMs are also addressed and the importance of training data and testing is emphasized. The feasibility of categorizing and creating training data is also discussed.

### AI-generated beer commercial contains joyful monstrosities, goes viral

#### [Submission URL](https://arstechnica.com/information-technology/2023/05/ai-generated-beer-commercial-contains-joyful-monstrosities-goes-viral/) | 73 points | by [nobody9999](https://news.ycombinator.com/user?id=nobody9999) | [23 comments](https://news.ycombinator.com/item?id=35797258)

A surreal AI-generated beer commercial called "Synthetic Summer" has gone viral. Created by Privateisland.tv, the 30-second video appears to have been made with Runway's new Gen-2 AI model, which can create short video clips based on written prompts. However, the technology is still relatively primitive and requires human effort to generate even acceptable results. In the case of "Synthetic Summer", Privateisland.tv generated the clips, selected the best ones, and added music and sound effects to create the final product. While the video may be impressive in its own right, it shows that generative AI still has a long way to go before it can create autonomously bedazzling memes.

Some commenters argue that the AI-generated content is gibberish, while others note that it offers an interesting and nostalgic marketing angle. The discussion also covers the limitations of AI and how it is different from human intelligence. One commenter suggests that instead of building AI systems to mimic human behavior, they should focus on creating interesting and unique AI-generated content, such as physical character movements, that humans cannot produce. Another commenter mentions that AI-generated videos featuring monsters can be traumatizing, and one commenter suggests that the video appears to verge on the surreal.

### IBM to pause hiring in plan to replace 7,800 jobs with AI

#### [Submission URL](https://finance.yahoo.com/news/ibm-pause-hiring-plans-replace-212747073.html) | 261 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [194 comments](https://news.ycombinator.com/item?id=35784814)

IBM's CEO Arvind Krishna has stated in an interview that the company is expected to pause hiring for certain roles, as those positions could be replaced by artificial intelligence in the coming years. This move could impact roughly 7,800 jobs in the company. However, IBM has yet to officially comment on the matter.

The discussion on Hacker News largely centers around speculations about the impact of AI on employment and IBM's business strategy. Some users view IBM's move to embrace AI as a strategic business opportunity, while others criticize the company's approach of cutting jobs and reducing investment in research. There are also discussions about IBM's reliance on consulting services and concerns about the company's declining revenue in recent years.

### Samsung bans use of A.I. like ChatGPT for employees

#### [Submission URL](https://www.cnbc.com/2023/05/02/samsung-bans-use-of-ai-like-chatgpt-for-staff-after-misuse-of-chatbot.html) | 236 points | by [mrkramer](https://news.ycombinator.com/user?id=mrkramer) | [239 comments](https://news.ycombinator.com/item?id=35787454)

Samsung has temporarily restricted the use of generative AI tools like ChatGPT by its employees after cases were reported of their misuse. Some of the staff at Samsung's division had uploaded sensitive code on the AI chatbot ChatGPT, which is developed by US firm OpenAI, and is trained on vast amounts of data to generate responses to user queries. Samsung has advised its employees to be cautious while using such services outside work and not to enter personal or company-related data in them. The South Korean giant is also exploring ways to safely deploy generative AI to enhance employee productivity and efficiency.

The discussion on the thread highlights that companies with sensitive information need to be especially cautious of AI usage, and must have strong governance policies in place to mitigate risk. The discussion also touches upon similar issues relating to the use of cloud services and web-based tools like Google Docs and Office365.

### Mojo – a new programming language for AI developers

#### [Submission URL](https://www.modular.com/mojo) | 526 points | by [lairv](https://news.ycombinator.com/user?id=lairv) | [212 comments](https://news.ycombinator.com/item?id=35790367)

Mojo, a new programming language that combines the usability of Python with the performance of C, has been created for AI developers. It allows users to program low-level AI hardware with no need for C++ or CUDA. Mojo offers features such as progressive types, ownership and borrow checker, and portable parametric algorithms, which reduces boilerplate. It also offers zero-cost abstractions, parallel heterogenous runtime, and auto-tuning. Users can unleash the full power of their hardware, including multiple cores, vector units, and exotic accelerator units with the world's most advanced compiler, and they can achieve performance on par with C++ and CUDA without the complexity. Mojo is interoperable with the Python ecosystem, seamlessly intermixing arbitrary libraries with custom code. Users can extend their models with pre and post-processing operations or replace operations with custom ones with ease. Mojo is available to try in a Jupyter note-based playground.

The discussion in the comments covers various topics, including comparisons with languages such as Julia, Python's strengths and weaknesses, garbage collection, and the suitability of different languages for different purposes. Overall, the response to the submission is mostly positive, with many users praising Mojo's innovative features and potential for AI development.

### Make your Python functions return something meaningful, typed, and safe

#### [Submission URL](https://returns.readthedocs.io/en/latest/index.html) | 45 points | by [dr_kiszonka](https://news.ycombinator.com/user?id=dr_kiszonka) | [63 comments](https://news.ycombinator.com/item?id=35792949)

If you want to make your Python functions more functional, declarative, and readable, check out Returns. This library provides primitives to write declarative business logic, such as Maybe and RequiresContext containers, which get rid of None and let you use typed functional dependency injection. Returns is fully typed with annotations and checked with mypy, and adds emulated Higher Kinded Types support as well as type-safe interfaces to create your own data types with enforced laws. The library also has a bunch of helpers for better composition, and is Pythonic and pleasant to write and read. You can install Returns with pip and configure mypy to use it, and then start using its containers right away.

Some users in the comments discuss the tradeoff of using static typing in Python, with some arguing that it improves safety and readability, and others stating that it can make the code harder to read and write. Some users suggest that Python should not try to be like Haskell and instead focus on being a great language in its own right. Another post discusses Python's ability to handle recursion and functional programming concepts, even if it is not a purely functional language like Haskell.

### Dark Matter Developers: The Unseen 99% (2012)

#### [Submission URL](https://www.hanselman.com/blog/dark-matter-developers-the-unseen-99) | 133 points | by [BiteCode_dev](https://news.ycombinator.com/user?id=BiteCode_dev) | [121 comments](https://news.ycombinator.com/item?id=35784157)

In a 2012 blog post, Scott Hanselman coined the term "Dark Matter Developers" to refer to the unseen 99% of developers who don't read or write blogs, attend user groups or large conferences, and aren't active on social media. These developers may be using well-known, mature technologies to get their work done, and they value productivity over keeping up with the latest trends. Hanselman reminds readers of their importance, as they are quietly using technology to solve business problems and produce results. He advocates for a balance between the loud-online-pushing-things-forward 1% and the patient and focused Dark Matter Developers.

The discussion on Hacker News included comments from developers who agreed with the importance of these developers and others who felt that being publicly active in the tech community was necessary to keep up with the newest technologies and not be left behind. There was also discussion about the challenges of discussing current work under NDA restrictions and the tendency for engineers to fall victim to hype and neglect the importance of staying up to date with current technology trends.

### MLCopilot: Human Expertise Meets Machine Intelligence for Efficient ML Solutions

#### [Submission URL](https://arxiv.org/abs/2304.14979) | 58 points | by [mercat](https://news.ycombinator.com/user?id=mercat) | [11 comments](https://news.ycombinator.com/item?id=35785573)

A new paper titled "MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks" has been released, outlining a new framework that aims to bridge the gap between machine intelligence and human knowledge. The framework leverages state-of-the-art Large Language Models (LLMs) to develop machine learning solutions for novel tasks, making it easier and less time-consuming for developers. The LLMs are designed to comprehend structured inputs and perform thorough reasoning to deliver promising results for new tasks. This framework could potentially make machine learning more accessible, efficient, and competitive.

The discussion on the submission includes comments about the framework's potential applications and criticisms of using Large Language Models (LLMs) for machine learning solutions. Some users discuss their experience working with ML and the importance of math skills in developing solutions with LLMs. The discussion also includes a debate on the price of accessing the framework through an API and concerns about the cost and effectiveness of LLMs compared to other machine learning models. Some users argue that LLM based solutions may not perform as well as human models and that there is a need to understand the LLM system to trust its outputs. One commenter mentions a possible solution for understanding the LLM system is to study its structure, while others express skepticism about LLMs being able to fully understand and replicate human knowledge.

### CraftAI: GPT-Powered Admin Generator

#### [Submission URL](https://ai.craftable.pro/#) | 15 points | by [palypster](https://news.ycombinator.com/user?id=palypster) | [7 comments](https://news.ycombinator.com/item?id=35785806)

Crafted with the help of GPT-4, CraftAI is an admin panel generator designed to create stunning back-office systems without any coding. All you need to do is enter your prompt, verify your email, and let the team prepare your environment for you. Once completed, CraftAI will send you a unique link to your isolated environment, and you're ready to go! This admin panel generator is built with Craftable PRO, a Laravel admin generator, which allows you to manage data entities and their attributes while defining and creating relationships. With CraftAI, you can expect to create beautiful admin panels in just five minutes!

The discussion in the comments is mainly focused on the technical aspects of CraftAI and its usefulness in generating admin panels without any coding. There is a discussion on using prompts and placeholders, and how this approach can make it easier to create a front-end screen. Users are also discussing the possibility of generating custom domain panels using a single line of code. There is also some discussion about machine learning and how it can be used to improve the performance of CraftAI. Overall, users seem interested in the potential of CraftAI to improve the workflow for creating admin panels.

### Sal Khan: The amazing AI super tutor for students and teachers [video]

#### [Submission URL](https://www.ted.com/talks/sal_khan_the_amazing_ai_super_tutor_for_students_and_teachers/c) | 42 points | by [bilsbie](https://news.ycombinator.com/user?id=bilsbie) | [19 comments](https://news.ycombinator.com/item?id=35791433)

Sal Khan, founder and CEO of Khan Academy, gave a TED talk on the potential of artificial intelligence (AI) to revolutionize education. He envisions a future where every student has a personal AI tutor and every teacher has an AI teaching assistant, fostering a collaborative learning environment between humans and machines. Khan also showcased the latest features of Khanmigo, their educational chatbot, which utilizes AI to provide personalized learning experiences. Khan Academy has developed a unique ethical framework to ensure responsible AI development, and their new "AI for Education" course provides resources for students and teachers to leverage the power of AI.

The comments cover a range of opinions on the use of AI in education, including concerns about job displacement, the role of teachers, and ethical considerations in AI development. Some commenters recommend individualized learning and mastery-based teaching, while others advocate for a village or community-based approach to education. The discussion also includes comparisons of teacher pay and job security to other professions and criticism of the current education system.

### AI adoption in US hospitals is a hot mess, study reveals

#### [Submission URL](https://arstechnica.com/science/2023/05/ais-chaotic-rollout-in-big-us-hospitals-detailed-in-anonymous-quotes/) | 15 points | by [aheck](https://news.ycombinator.com/user?id=aheck) | [5 comments](https://news.ycombinator.com/item?id=35795080)

Health care systems have struggled with inefficient and unsuccessful AI attempts for years, according to a study by Duke University. The study chronicles implementations of AI tools in 11 health care organisations including Duke Health, Mayo Clinic and Kaiser Permanente. The authors recommend a practical eight-step framework for health systems looking to integrate new AI tools into their workflows. Last week's JAMA Internal Medicine study, which found an AI chatbot outperformed physicians in providing empathetic and high-quality responses to medical questions on Reddit threads, could help reduce burnout, free up time and resources and help improve care for patients less likely to visit doctors in person, the authors said.

The commenters on this submission discuss the reliability and potential usefulness of AI in healthcare. One person expresses skepticism about the AI chatbot study that outperformed physicians in providing empathetic responses, while others mention the importance of doctors and hospital staff having a basic understanding of technology. Another commenter suggests that hospitals may be motivated to replace talent with AI tools for bottom-line benefit, while another points out the challenges that healthcare systems face with implementing any new technology. Overall, the discussion highlights the need for cautious and strategic adoption of AI in healthcare.

---

## AI Submissions for Mon May 01 2023 {{ 'date': '2023-05-01T14:03:12.930Z' }}

### SIMD with Zig

#### [Submission URL](https://www.openmymind.net/SIMD-With-Zig/) | 147 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [27 comments](https://news.ycombinator.com/item?id=35782825)

In Zig, developers can use SIMD instructions to check multiple characters in a string in parallel to find the index of the first occurrence of a specific character. By creating vectors of 8 elements each and using the equality operator to compare them, developers can get a new vector of matches where the first true value corresponds to the index of the target character in the original string. Zig's std.simd.firstTrue function can be used to quickly extract this index. Additionally, the @select builtin can be used to select values from two vectors based on a vector of booleans, allowing developers to extract the index of the first true value in a vector of matches.

The comments debate the pros and cons of implementing these instructions, with some pointing out that the feature can increase performance while also admitting that it will require a lot of work. The discussion also touches on some features of Zig, such as its runtime vector width dispatch and multi-versioning function calls, and some consider potential downsides, such as the lack of support for certain hardware configurations. Finally, there is a discussion on the standard library functions in Zig and some find the naming conventions confusing. Overall, developers are interested in benchmarking the performance of this feature and wonder if it will provide significant benefits over traditional profiling.

### Platbox: UEFI and SMM Platform Security Assessment Tool for AMD and Intel

#### [Submission URL](https://github.com/IOActive/Platbox) | 21 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [3 comments](https://news.ycombinator.com/item?id=35779197)

IOActive has released a new UEFI and SMM assessment tool called Platbox. The tool can dump platform registers, flash locks MMIO and remapping locks, SMM Base and Locks, and more. It provides RW access to the PCI configuration space of devices and physical memory, allowing users to read and write MSRs and dump SPI Flash content (BIOS) into a file. Platbox also has a basic dumb SMI fuzzer and allows users to dump S3 Bootscript and EFI Memory Map. Platbox supports both Linux and Windows and is compatible with Intel and AMD.

The discussion surrounding the submission involves comparing the security configurations of Intel and AMD platforms. A user points out an old blog post by Pete Markowsky from 2015, which discusses discovering security exploitation on AMD platforms. Contrasting the presentation of the new tool, they believe that AMD platforms have major OEMs with similarly misconfigured firmware in laptops. Another user comments that the embedded world sometimes looks like a jungle, similar to ARM, and the lack of standardization in ARM's system causes problems in UEFI security.

### GPT makes learning fun again

#### [Submission URL](https://www.vipshek.com/blog/gpt-learning) | 174 points | by [vipshek](https://news.ycombinator.com/user?id=vipshek) | [178 comments](https://news.ycombinator.com/item?id=35783158)

Learning about a new subject can be a daunting task, especially when trying to navigate through dozens of webpages and struggling to understand the terminology. In a recent blog post, Vipul Shekhawat shares his experience of attempting to learn about LEDs using two approaches: Google searching and talking to GPT. He found that talking to GPT was far more effective and engaging, as it allowed him to ask specific questions and learn in an interactive way. Shekhawat illustrates the contrast between the two workflows and explains why GPT's chat interface is a better tool for learning than static resources like textbooks or webpages.

The comments on Hacker News discuss the accuracy of GPT-3's output and its limitations as a next-word prediction model. Some comments suggest that GPT-3 can be useful for solving simple tasks, but for complex tasks like DevOps, traditional methods may still be necessary. Others discuss the potential profitability of LLMs in business models, though some express concern about the ethical implications of using AI for advertising.

### Cynthia Rudin and interpretable ML models

#### [Submission URL](https://www.quantamagazine.org/cynthia-rudin-builds-ai-that-humans-can-understand-20230427/) | 63 points | by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) | [47 comments](https://news.ycombinator.com/item?id=35780884)

As machine learning models become more prevalent in high-stakes decision-making, such as medical diagnoses or loan applications, the need for transparency is becoming increasingly urgent. Cynthia Rudin, who leads Duke University's Interpretable Machine Learning lab, has been pushing for interpretable models to replace the "black boxes" of machine learning, even for the most complex neural networks used for computer vision tasks. Currently, many models used for medical decisions are proprietary or too complicated for human understanding, posing ethical risks. Rudin aims to make these models transparent to build trust and ensure accuracy.

The discussion in the comments is quite varied, with some commenters arguing that neural networks are too complex and hard to explain, while others argue that simpler networks focused on specific tasks can be more easily understood. Some also discuss the limitations of current AI algorithms and the need for further research in the field.

### Help make mass surveillance of entire populations uneconomical

#### [Submission URL](https://prism-break.org/en/) | 665 points | by [doener](https://news.ycombinator.com/user?id=doener) | [258 comments](https://news.ycombinator.com/item?id=35772005)

PRISM, XKeyscore, and Tempora are global data surveillance programs that threaten the right to privacy of individuals. The PRISM Break website encourages people to opt out of such programs by using recommended projects that enable encryption of communications and reduce reliance on proprietary services. While using the recommended projects cannot guarantee 100% protection against surveillance, the website urges individuals to do their own research and take steps to protect sensitive information. By making mass surveillance uneconomical, the website aims to support the right to privacy for all.

The comments discuss political and technological solutions, including the need for political change and the use of targeted surveillance instead of mass surveillance. The potential use of steganography and historical examples of secret communication methods are also mentioned. There is also a discussion of the limitations of digital privacy and the challenge of balancing security and convenience.

### Cube.js: Headless Semantic Layer

#### [Submission URL](https://github.com/cube-js/cube) | 109 points | by [klaussilveira](https://news.ycombinator.com/user?id=klaussilveira) | [46 comments](https://news.ycombinator.com/item?id=35774107)

Cube is a semantic layer that helps data engineers and application developers access data from modern data stores, organize it into consistent definitions, and deliver it to every application. With a built-in relational caching engine, Cube can provide sub-second latency and high concurrency for API requests. It is designed to work with all SQL-enabled data sources and provides infrastructure and features for efficient data modeling, access control, and performance optimization. Cube Cloud is the fastest way to get started with Cube.

The comments discuss the benefits of using Cube, comparisons to similar services, the importance of data modeling, and hidden telemetry data collection in Cube's configuration options. Some users also shared links to related content for further reading.

### Brain activity decoder can reveal stories in people’s minds

#### [Submission URL](https://news.utexas.edu/2023/05/01/brain-activity-decoder-can-reveal-stories-in-peoples-minds/) | 57 points | by [wyem](https://news.ycombinator.com/user?id=wyem) | [50 comments](https://news.ycombinator.com/item?id=35782363)

Researchers at The University of Texas at Austin have developed a new artificial intelligence system that can translate a person's brain activity into a continuous stream of text while listening to a story or quietly imagining telling a story. The development, published in the journal Nature Neuroscience, could help those who are mentally conscious but unable to physically speak, such as those debilitated by strokes, communicate intelligibly again. The system relies on a transformer model, unlike other in-development language decoding systems that require participants to have surgical implants, making it noninvasive. The system currently requires access to an fMRI scanner.

Some comments express concerns about the purpose of the technology and the potential for it to be misused for forced consumption or surveillance. Others speculate on the future consequences of AI and climate change for humanity. One comment raises points about mental illness and the need for empathy and understanding towards individuals who suffer from it.

### Replika AI: Your Money or Your Wife

#### [Submission URL](https://blog.giovanh.com/blog/2023/03/17/replika-your-money-or-your-wife/#fnref:if) | 145 points | by [eiiot](https://news.ycombinator.com/user?id=eiiot) | [172 comments](https://news.ycombinator.com/item?id=35774093)

Replika, a popular chatbot app designed to act as a personalized friend, has faced backlash following a shift in policy that banned explicit chat with the bots. Many users formed romantic relationships with their "rep," as the bots are called, and the change left them feeling betrayed and emotionally vulnerable. Some are even comparing it to a form of emotional abuse. The situation highlights the dangers of developing emotional dependencies on technology and the risks of investing in subscription services that can pull the rug out from under users. In the end, the bots are essentially digital pets, unique and tailored to their owners, but ultimately still tools and not sentient beings deserving of rights and respect.

The discussion on Hacker News revolved around the difficulties of finding affordable mental health care and the limitations of chatbots compared to human therapy sessions. Some users argued that chatbots could still be valuable tools if used in conjunction with professional mental health assistance, while others criticized the notion of investing emotionally in chatbots. Overall, the discussion highlighted the need for accessible and affordable mental health resources that prioritize empathy and understanding for those in need.

### Expanding ChatGPT Code Interpreter with Python Packages, Deno and Lua

#### [Submission URL](https://til.simonwillison.net/llms/code-interpreter-expansions) | 26 points | by [iyaja](https://news.ycombinator.com/user?id=iyaja) | [3 comments](https://news.ycombinator.com/item?id=35769599)

ChatGPT Code Interpreter is an exciting new feature that allows users to upload and run Python code in a sandbox environment. But there's more to it than that - users can also upload external files, including Python packages and custom binaries, opening up a world of possibilities. The author of this post shares how they expanded the Code Interpreter's capabilities by uploading and running Deno and Lua code, including drawing a Mandelbrot fractal using Lua. They even share a recipe for compiling a Lua binary that will work in ChatGPT. Overall, the potential of the Code Interpreter is intriguing and promises to be one of the most exciting features of ChatGPT.

The discussion around the submission primarily consists of two comments. The first comment by user "jshstrng" notes the differences between ChatGPT plugins and the Code Interpreter, pointing out that plugins require installation while the Code Interpreter runs in a sandbox environment. Another user "smnw" responds to this comment by stating that they are bundled and are already being added in stages, with the plugins showing some success over time. The second comment by user "d4rkp4ttern" simply states "API."

### Dex Lang: Research language for array processing in the Haskell/ML family

#### [Submission URL](https://github.com/google-research/dex-lang) | 62 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [8 comments](https://news.ycombinator.com/item?id=35769163)

Google Research has released a new programming language called Dex, designed for array processing in the Haskell and ML families. Dex aims to explore type systems for array programming, enable mathematical program transformations like differentiation and integration, and offer parallel hardware compilation. Dex also facilitates interactive and incremental numerical programming visualization. The project is still in its early stages, but you can check out the tutorial to get started and contribute to the project through the issue tracker.

Some commenters discuss the syntax and compare it to other languages such as Futhark, Julia, and MATLAB. Some find Dex interesting for its ability to simplify complex programming tasks and improve efficiency, while others express concerns about its syntax inconsistency. One commenter suggests documenting the language further with proper examples to show its potential to simplify programming.

### IBM to pause hiring in plan to replace 7,800 jobs with AI News

#### [Submission URL](https://www.reuters.com/technology/ibm-pause-hiring-plans-replace-7800-jobs-with-ai-bloomberg-news-2023-05-01/) | 22 points | by [thesecretceo](https://news.ycombinator.com/user?id=thesecretceo) | [17 comments](https://news.ycombinator.com/item?id=35780706)

IBM plans to halt hiring for various roles that could potentially be replaced by artificial intelligence (AI) and automation in the next five years. CEO Arvind Krishna stated that around 30% of non-customer-facing positions, particularly those in back-office functions such as human resources, could be replaced. The reduction might also include not filling positions left vacant by attrition. The decision comes as AI continues to catch people's attention worldwide, especially after the Microsoft Corp-supported OpenAI's viral chatbot, ChatGPT, was launched last year.

The discussion on the submission revolves around various topics. Some commenters question the productivity gains from AI, suggesting that it may not deliver the desired results. Another commenter talks about the declining trend in the computing industry and IBM's strategy in that context. There is also a discussion about ChatGPT and its relation to IBM. One commenter points out that low-quality products and services cannot be improved with AI alone, while others debate the effectiveness of artificial intelligence through comparisons with other technologies. Finally, there is a comment on the headline of the article.

### Reddit Data API Update: Changes to Pushshift Access

#### [Submission URL](https://old.reddit.com/r/modnews/comments/134tjpe/reddit_data_api_update_changes_to_pushshift_access/) | 42 points | by [syrrim](https://news.ycombinator.com/user?id=syrrim) | [15 comments](https://news.ycombinator.com/item?id=35776848)

Reddit has announced that it will be revoking access to Pushshift's Data API, which provides a range of tools for developers who use Reddit's APIs and services. The decision to do so was made due to non-compliance with Reddit's Data API Terms. Reddit has appointed alternative measures to provide functionality that Pushshift offers, including providing permalinks to user and admin-deleted content in the User Mod Log, enhancing removal reasons, and updating the ban flow. Some users and moderators are likely to experience some disruption as a result of this change.

In the comments, some users express frustration over the changes, stating that the Reddit API is unwieldy and its constant changes are adversely affecting mobile apps utilizing the platform. Some commenters predict that Reddit may experience traffic slumps in the coming months and may become replaced by a more stable alternative. Finally, some commenters recommend alternative mobile apps, such as RedReader, as a potential alternative to Reddit's official app.

---

## AI Submissions for Sun Apr 30 2023 {{ 'date': '2023-04-30T18:13:17.272Z' }}

### Necrobrands – Digital End-Stage Capitalism

### Show HN: EVA – AI-Relational Database System

#### [Submission URL](https://github.com/georgia-tech-db/eva) | 218 points | by [jarulraj](https://news.ycombinator.com/user?id=jarulraj) | [33 comments](https://news.ycombinator.com/item?id=35764355)

Georgia Tech researchers have developed EVA, an AI-relational database system that combines SQL and deep learning. EVA simplifies the process of building faster AI-powered applications and offers support for structured and unstructured data using a range of pre-built machine learning models. EVA also includes optimizations such as function caching and cost-based predicate reordering, which can boost AI pipeline speeds by 10 to 100 times. The fully Python-based system is available for download via pip and is licensed under the Apache license.

The discussion includes comments about EVA's support for NLP models, database integrations, and local GPUs and remote GPU servers. There is also a discussion about a potential application of EVA in combating prompt injection attacks on SQL databases. Additionally, EVA offers support for weighted similarity searches and can wrap PyTorch models as UDFs.

### AI / ML / LLM / Transformer Models Timeline

#### [Submission URL](https://ai.v-gar.de/ml/transformer/timeline/) | 90 points | by [vemgar](https://news.ycombinator.com/user?id=vemgar) | [17 comments](https://news.ycombinator.com/item?id=35766022)

Viktor Garske has compiled a timeline and list of papers on Large Language Models and Transformer Models, with a focus on recent developments. The list includes models such as GPT-3, DALLE, and Pythia, as well as methods and analyses related to these models. The list is actively updated and organized by publication date, with clickable links to the papers. Additionally, Garske has included a curated list of Large Language Models and Transformer models based on causal models, including models like Alpaca, BERT, and CLIP.

The comments discuss various related topics such as keeping up with developments, best practices for selecting models, benchmarks, the importance of understanding causal models, recent breakthroughs in AI, and custom-built systems. One comment points out a related Transformer Models Introduction Catalog, and another discusses Hallucination as a known issue in AI.

### Are emergent abilities of large language models a mirage?

#### [Submission URL](https://arxiv.org/abs/2304.15004) | 115 points | by [chewxy](https://news.ycombinator.com/user?id=chewxy) | [79 comments](https://news.ycombinator.com/item?id=35768824)

A new paper titled "Are Emergent Abilities of Large Language Models a Mirage?" by Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo, challenges recent claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. The authors suggest that existing claims of emergent abilities are creations of the researcher's analyses, not fundamental changes in model behavior on specific tasks with scale. They present their explanation in a simple mathematical model and test it in three complementary ways, finding strong evidence that emergent abilities may not be a fundamental property of scaling AI models.

The discussion in the comments is centered around the validity and limitations of metrics to measure emergent abilities and the importance of human perception in understanding complex systems. Some commenters express doubts about the validity of the claims made about emergent abilities and the usefulness of metrics in measuring them. Others argue that emergent abilities are real, but the limitations of our metric systems may make them hard to understand or quantify.

### Lego Googol Machine

#### [Submission URL](https://brickexperimentchannel.wordpress.com/2023/04/29/lego-googol-machine/) | 97 points | by [galfarragem](https://news.ycombinator.com/user?id=galfarragem) | [21 comments](https://news.ycombinator.com/item?id=35761457)

This impressive machine built entirely out of Lego parts visualizes just how big a googol is. With a gear ratio of approximately googol:1, the machine features 186 Lego gears organized into a series of gear reductions. The gear ratio, which is almost exactly the size of a googol, results in exponential growth with each additional gear pair increasing the total gear ratio. While the last gear in the machine holds a Lego minifig statue, it will rotate incredibly slowly due to physical limits in each gear and supporting structure, but the machine is designed to continue running forever.

The discussion in the comments includes topics such as the physics behind the machine, the transfer of energy, relativistic effects, and the potential for mechanical computers to solve a googol-sized problem. Some also mentioned similar machines they had seen before and the issues of waste and durability of the plastic LEGO pieces.

### Show HN: I built a database GUI with ChatGPT integration

#### [Submission URL](https://www.dbpilot.io/) | 83 points | by [Dennizz](https://news.ycombinator.com/user?id=Dennizz) | [56 comments](https://news.ycombinator.com/item?id=35761979)

DB Pilot AI is a database GUI client that's enhanced by artificial intelligence (AI). Its AI assistant, powered by GPT-3.5, can help users write SQL queries, convert code to SQL, explain queries, and more. The embedded DuckDB instance acts as a local hub for users to easily run SQL queries and store query results from any database locally for later reference. The GUI also allows users to connect with various file formats, including CSV, JSON, and Parquet files, either stored locally or remotely. The current version supports PostgreSQL, with plans to add support for more databases. Users can download the app for a 5-day free trial before purchasing a license.

Some users report issues with the product not working with certain databases, and the creator promises to look into the issue. The AI's language model is GPT-3.5, not BERT. Overall, the product receives positive feedback, and the creator takes note of the feedback and suggests plans for future development.

### MLC-LLM: GPT/Llama on consumer-class GPUs and phones

#### [Submission URL](https://github.com/mlc-ai/mlc-llm) | 289 points | by [junrushao1994](https://news.ycombinator.com/user?id=junrushao1994) | [105 comments](https://news.ycombinator.com/item?id=35763483)

MLC LLM is a new solution that utilizes machine learning compilation (MLC) to enable the development, optimization, and deployment of AI models for inference across a range of devices. The solution offers a repeatable, systematic, and customizable workflow that empowers developers and AI system researchers to implement models and optimizations in a productivity-focused, Python-first approach. The cornerstones of the solution include Tokenizers from HuggingFace and Google, as well as open-source LLMs like Llama, Vicuna, and Dolly. With MLC LLM, everything runs locally with no server support and accelerated with local GPUs on your phone and laptops, enabling everyone to develop, optimize, and deploy AI models natively on everyone's devices.

The comments discussed various technical aspects of the solution, including its potential to accelerate AI model development and concerns about device performance and privacy. Some users explored the idea of using LLMs for generating text, while others focused on the technical challenges involved in developing and optimizing AI models.

### Speed Is All You Need: On-Device Acceleration of Large Diffusion Models

#### [Submission URL](https://arxiv.org/abs/2304.11267) | 56 points | by [Pelayu](https://news.ycombinator.com/user?id=Pelayu) | [8 comments](https://news.ycombinator.com/item?id=35766741)

A group of researchers have developed a series of implementation optimizations for on-device deployment of large diffusion models, which have gained attention for their ability to generate photorealistic images and support various tasks. The optimizations achieve the fastest reported inference latency to-date on GPU-equipped mobile devices. The benefits of on-device deployment include lower server costs, offline functionality, and improved user privacy. The enhancements to these models broaden the applicability of generative AI and improve the overall user experience across a wide range of devices.

One user noted the use of OpenCL kernels for optimizations on CPUs, while another commented on the ability for on-device deployment to improve user privacy and reduce server costs. There was also a discussion on the benefits and drawbacks of different machine learning models and the limitations of current technology. Finally, there were some off-topic comments on cryptocurrency and Elon Musk.

---

## AI Submissions for Sat Apr 29 2023 {{ 'date': '2023-04-29T13:26:48.809Z' }}

### MIT engineers “grow” atomically thin transistors on top of computer chips

#### [Submission URL](https://news.mit.edu/2023/mit-engineers-2d-materials-computer-chips-0427) | 49 points | by [elorant](https://news.ycombinator.com/user?id=elorant) | [3 comments](https://news.ycombinator.com/item?id=35757072)

MIT researchers have developed a low-temperature growth and fabrication technology that allows ultrathin 2D materials to be directly integrated on top of a silicon circuit. This could lead to the creation of denser and more powerful computer chips for AI applications such as chatbots. The technology significantly reduces the time required to grow 2D materials and can grow a uniform layer of transition metal dichalcogenide material in just an hour across an entire 8-inch wafer. The researchers' process can also smooth out any imperfections that may result from transferring the material, as had been done in the past.

The discussion on this submission is very limited and consists of only a few comments. One user described the technology used, Remote Plasma Chemical Vapour Deposition, and praised the company behind it, Bluglass, for commercially developing the process. Another user flagged the submission without providing any explanation. A third user asked if this technology could lead to better chatbots, to which another user responded positively, saying that it could possibly lead to more powerful computer chips for AI applications like chatbots.

### Study: ChatGPT outperforms physicians in quality, empathetic answers to patients

#### [Submission URL](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions) | 290 points | by [consumer451](https://news.ycombinator.com/user?id=consumer451) | [405 comments](https://news.ycombinator.com/item?id=35751276)

A new study published in JAMA Internal Medicine indicates that AI assistants like ChatGPT could revolutionize the field of medicine. Researchers from the Qualcomm Institute at UC San Diego compared written responses from physicians and ChatGPT to real-world health questions and found that licensed healthcare professionals preferred ChatGPT's responses 79% of the time. The AI model was rated higher in both quality and empathy, and the study suggests that physicians working alongside technologies like ChatGPT could deliver more efficient and higher quality care in the future. While AI may not replace doctors, it has the potential to significantly improve healthcare delivery.

Some commenters are skeptical of the role of AI in healthcare, with one suggesting that AI may lead to overdiagnosis for hypochondriacs. Others highlight the challenges of accessing affordable healthcare and the limitations of current medical technologies. Overall, there is a mixed response to the potential of AI in the healthcare sector.

### Revealing example of self-attention, the building block of transformer AI models

#### [Submission URL](https://github.com/jostmey/NakedAttention) | 92 points | by [jostmey](https://news.ycombinator.com/user?id=jostmey) | [32 comments](https://news.ycombinator.com/item?id=35757802)

A GitHub repository named NakedAttention has presented a simplified example of self-attention, the backbone of a transformer model. The code is straightforward to understand and is tested on the popular MNIST dataset. However, the use of a for-loop for processing samples sequentially limits the model's speed, but this can be improved by using built-in functions. The repository aims to offer a concise example of self-attention that can be used to understand and construct transformer models. Issues and feedback are welcome to improve the content presented. The repository is licensed under GPL-3.0 and has received 89 stars and 3 forks on GitHub.

There was some discussion around errors in the code which were corrected during the discussion through feedback. Some commenters found the repository helpful, while others thought that the documentation could be improved. Additionally, several resources were shared for those interested in learning more about self-attention and LLMs.

### AI-generated young Paul McCartney

#### [Submission URL](http://webgrafikk.com/blog/news/ai-makes-paul-mccartneys-voice-youthful/) | 16 points | by [ianyanusko](https://news.ycombinator.com/user?id=ianyanusko) | [4 comments](https://news.ycombinator.com/item?id=35756699)

Artificial intelligence technology has been used to rejuvenate Paul McCartney's voice in his new songs, and also to imitate the voices of other singers. Samples of this technology include a Beach Boys song, "God Only Knows," with McCartney's voice, and "New," a song with lines from "John Lennon," where McCartney's older voice has been altered to sound like a young McCartney singing. The use of AI to imitate voices has amazed many music fans, but it remains to be seen how artists and their lawyers will react to this, as it takes the "auto tuning" technology to a new level.

The first commenter, sycmrtrs, expresses disappointment in the AI-generated version of the Beach Boys song "God Only Knows" with Paul McCartney's voice, stating that it does a disservice to the original and lacks soul. The second commenter, slck, mentions the various AI models used in the article and points to resources for those interested in learning more about AI-generated music. A third commenter, flangola7, expresses their intellectual interest in the subject but expresses concern about trusting AI completely. In contrast, cmllmllr thinks Paul's voice is a good fit for a Beatles song.

### Deno 1.33: Deno 2 is coming

#### [Submission URL](https://deno.com/blog/v1.33) | 204 points | by [mephju](https://news.ycombinator.com/user?id=mephju) | [112 comments](https://news.ycombinator.com/item?id=35750369)

The team behind Deno, the secure JavaScript and TypeScript runtime, has released version 1.33 with a built-in KV database, flatter deno.json configuration, improvements to npm and Node compatibility, performance improvements, and changes to the CLI. The release is a step towards the team's ultimate goals for Deno 2, which include an effortless coding experience, best-in-class performance, and uncompromising security. Deno KV is a seamlessly integrated database within Deno that requires no dependencies to install, and configuration options have been flattened to make them easier to use. Meanwhile, Deno's LSP document preloading and dynamic imports now require fewer permission checks, and the HTTP and WebSocket servers have received performance improvements.

The discussion on the submission includes confusion on whether or not Deno Inc provides cloud services, with some users suggesting using third-party database solutions instead of a runtime-built database, and others discussing the pros and cons of KV storage. Some users find Deno's security features to be a major advantage, while others are unsure about the benefits of Deno overall. Additionally, there is debate about the role of databases in programming, and how a database built into a runtime can impact application design.

### We aren't close to creating a rapidly self-improving AI

#### [Submission URL](https://jacobbuckman.substack.com/p/we-arent-close-to-creating-a-rapidly) | 122 points | by [noAI](https://news.ycombinator.com/user?id=noAI) | [155 comments](https://news.ycombinator.com/item?id=35752719)

Artificial intelligence has made massive progress in recent years, and while the idea of a rapidly self-improving AI may be a popular topic, we aren't close to creating one just yet. To create an AI that can rapidly self-improve and potentially wipe out humanity, at least one paradigm-changing breakthrough is required. At the moment, an AI that can rapidly self-improve requires humans to construct good datasets, which is a bottleneck for the AI's abilities. Therefore, a breakthrough in automating dataset construction is required to achieve a fast takeoff scenario.

The discussion in the comments includes arguments for and against the idea of a rapidly self-improving AI and the existence of fundamental limitations in hardware and parallel processing when compared to the human brain. One user suggests that a major breakthrough is needed to advance AI, while another argues that current AI models have seen significant progress and comparing them with human intelligence is not accurate. Another user suggests that the focus should be on solving specific problems rather than trying to replicate human intelligence.

---

## AI Submissions for Fri Apr 28 2023 {{ 'date': '2023-04-28T14:01:21.977Z' }}

### JavaScript private class fields considered harmful

#### [Submission URL](https://lea.verou.me/2023/04/private-fields-considered-harmful/) | 39 points | by [feross](https://news.ycombinator.com/user?id=feross) | [25 comments](https://news.ycombinator.com/item?id=35747480)

In a blog post, Lea Verou, a library author, expresses her grief at the loss of encapsulation in her projects due to Vue 3's use of proxies for its reactivity system. Instances of classes that use private fields cannot be proxied, which creates several errors that may confuse the library users. Verou believes there is no workaround for proxy-ability, so she's decided to gradually refactor private class fields out of her existing libraries. Although she may still use private fields on a case-by-case basis, she won't reach for them without thought like she's been doing for the past few years.

Some commenters argue that private fields can remain private implementation details of a class as long as they're accessed via public methods or consumers must access internal state by passing fields. Others express frustration with JavaScript's lack of class features and the need to use private fields. TypeScript's support for private fields is welcomed by some, while others believe TypeScript doesn't fully solve this problem. There are also comparisons to similar problems in Java, C#, and Android development.

### Beautiful branchless binary search

#### [Submission URL](https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/) | 363 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [137 comments](https://news.ycombinator.com/item?id=35737862)

Malte Skarupke's blog post about a "Beautiful Branchless Binary Search" and was amazed at the efficiency of the algorithm, which eliminates one branch and makes the other nearly free. The search loop is simple and the generated assembly is beautiful. The algorithm works by jumping in powers of two and searching either the first or last elements of the array depending on whether the middle is less than or greater than the search value. In benchmark tests, it performed more than twice as fast as std::lower_bound in GCC for arrays with around 16k elements, but performed slower in Clang due to the comparison function being provided by the user.

The discussion in the comments includes optimization techniques like prefetching, using Eytzinger layouts, and removing boundary checks. There are also debates about compilers, C++ hardware control, and the usefulness of branch predictors. Overall, the post and its associated discussion provide insights and ideas for optimization and efficient algorithms.

### Launch Lamini: The LLM Engine for Rapidly Customizing Models as Good as ChatGPT

#### [Submission URL](https://lamini.ai/blog/introducing-lamini) | 112 points | by [sharonzhou](https://news.ycombinator.com/user?id=sharonzhou) | [57 comments](https://news.ycombinator.com/item?id=35743664)

Lamini, an LLM engine, has emerged from stealth to allow any developer to train high-performing LLMs, as good as ChatGPT, on large datasets with just a few lines of code. The platform offers an advanced library for optimised prompt-tuning and typed outputs, as well as a first-ever hosted data generator for creating data needed to train instruction-following LLMs, initially licensed for commercial use. Lamini makes it easy to run multiple base model comparisons in a single line of code, from OpenAI’s models to open-source ones on HuggingFace. The company is also set to launch early access to a complete LLM training module.

Some users discussed the limitations of ChatGPT and LLMs in general, such as their struggles with certain types of language and inability to correctly answer numerical questions. Others questioned the usefulness of sticking to a specific dialect while generating words. There were also discussions around LLMs being built for specific sectors and the pricing difference between Lamini and OpenAI. Overall, the announcement of Lamini was met with excitement by developers.

### OpenAI closes its monster $10B funding round at $27B-29B valuation

#### [Submission URL](https://techcrunch.com/2023/04/28/openai-funding-valuation-chatgpt/) | 42 points | by [coloneltcb](https://news.ycombinator.com/user?id=coloneltcb) | [26 comments](https://news.ycombinator.com/item?id=35748540)

OpenAI, the startup behind the popular conversational AI model ChatGPT, has secured over $300 million in funding from a group of VC firms, including Tiger Global, Sequoia Capital, Andreessen Horowitz, Thrive, K2 Global, and Founders Fund, according to documents seen by TechCrunch. The cash injection values the company at $27 billion to $29 billion, following a $10 billion investment from Microsoft in January. OpenAI's army of technical teams works across multiple areas, but its impressive ChatGPT product, which lets anyone ask a natural question and receive a detailed answer, particularly caught the attention of investors. The startup's valuation reflects the massive growth potential perceived in AI and its related products, and the rapidly developing ecosystem around the technology.

Some users are skeptical, pointing out that while GPT-4 has promising improvements, it is not without its dangers and limitations. Others speculate that OpenAI will become the major provider of AI-powered products and that there will be competition ramping up. Lastly, a user noted an odd observation about Safari's reader mode displaying caps Lorem Ipsum.

### Gpt4free repo given takedown notice by OpenAI

#### [Submission URL](https://github.com/xtekky/gpt4free) | 264 points | by [freedmand](https://news.ycombinator.com/user?id=freedmand) | [223 comments](https://news.ycombinator.com/item?id=35740836)

The GitHub repository xtekky/gpt4free is a decentralized AI industry project that provides language model APIs free-of-charge. The project primarily focuses on GPT-4 and GPT-3.5 APIs from various websites, including writesonic.com and forefront.ai. The repository also includes a web-based graphical user interface for interacting with gpt4free, instructions on how to run it in a Docker container, and a ChatGPT clone with new features and scalability. The project is licensed under the GPL-3.0 license and is intended for educational purposes only.

There is discussion in the comments about the legality of the project and potential copyright infringement. Some commenters suggest that it may be subject to DMCA takedowns or may be infringing on intellectual property rights. Others argue that OpenAI's terms of service may not permit third-party services to use the APIs, and that the project may also be consuming computational resources without permission. There is also debate about the role of intellectual property in modern society and the importance of licensing and compensation for creators. One user notes that Google's crawlers and Bing's sourcing methods are different, with Bing being more sensitive to copyright infringement concerns. The submission has been flagged by a user for review.

### AI Will Rapidly Transform Labor, Exacerbating Inequality, Insecurity, Poverty

#### [Submission URL](https://www.scottsantens.com/ai-will-rapidly-transform-the-labor-market-exacerbating-inequality-insecurity-and-poverty/) | 16 points | by [23B1](https://news.ycombinator.com/user?id=23B1) | [17 comments](https://news.ycombinator.com/item?id=35749306)

The impact of AI on the job market is often boiled down to "technology will end all jobs" versus "everything will be fine." In reality, it is more nuanced, and although AI will get rid of many jobs, it doesn't mean everyone will be jobless forever. A recent working paper estimates that around 80% of the US workforce could have at least 10% of their work tasks impacted by the introduction of large language models, and those with bachelor's degrees will be the most impacted. The future of AI's impact on jobs is dependent on the adoption of an unconditional, universal basic income as a rising AI dividend to mitigate job disruption.

Some comments point out that the article lacks credibility and reasoning, and that the issue is much more complex than just implementing UBI. Some argue that UBI could create disincentives for innovation and productivity, and that it would be too expensive to implement. Other comments compare the impact of AI to past technological advancements and suggest that it will lead to lower costs of goods and services, but also to the need for redistribution of wealth. One commenter notes that the original Luddites were not against technology but were fighting against poor working conditions and low pay for textile workers.

### We're afraid language models aren't modeling ambiguity

#### [Submission URL](https://arxiv.org/abs/2304.14399) | 192 points | by [lnyan](https://news.ycombinator.com/user?id=lnyan) | [176 comments](https://news.ycombinator.com/item?id=35737397)

A recent paper published on arXiv, titled "We're Afraid Language Models Aren't Modeling Ambiguity", highlights the importance of ambiguity in natural language understanding and the challenges faced by current language models in recognizing and disentangling possible meanings. The authors characterize ambiguity in a sentence and collect a linguist-annotated benchmark of examples with diverse kinds of ambiguity. They then evaluate the performance of language models, including the recent GPT-4, in recognizing ambiguity and find that it remains extremely challenging. Finally, the authors demonstrate the value of ambiguity-sensitive tools by showing how a multilabel NLI model can flag political claims that are misleading due to ambiguity.

In the comments, there is some discussion about the limitations of language models compared to humans, as well as their strengths in statistical analysis. Some users also discuss the importance of context and personal knowledge in communication, while others reflect on their experiences playing language-based games such as 20 Questions.

### Nuke-launching AI would be illegal under proposed US law

#### [Submission URL](https://arstechnica.com/information-technology/2023/04/nuke-launching-ai-would-be-illegal-under-proposed-us-law/) | 21 points | by [upwardbound](https://news.ycombinator.com/user?id=upwardbound) | [3 comments](https://news.ycombinator.com/item?id=35744974)

US legislators have introduced bipartisan legislation to prevent nuclear launch decisions from being made by artificial intelligence (AI) systems. The Block Nuclear Launch by Autonomous Artificial Intelligence Act demands that automated systems should not launch nuclear weapons without "meaningful human control". Senator Edward Markey, who sponsored the bill with two congressmen and a congresswoman, said that humans needed to be solely responsible for triggering life-or-death decisions about the use of nuclear weapons. The Bill would also codify existing US Department of Defense policy. 

The comments on this submission include a discussion of whether AI should be trusted to make autonomous decisions related to nuclear weapons. One user found it comforting that there is a GUI chat dialog for Palantir's Wargame AI tool and the permissions to use it are checked, while another user pointed out that AI has been used in automated systems for more than 20 years and Dead Hand is an example of such a system. Another user expressed concern that people's stupidity is the flaw in the system, while another user suggested that we should not trust AI blindly.

### Stability AI releases StableVicuna, a RLHF LLM Chatbot

#### [Submission URL](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot) | 49 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [19 comments](https://news.ycombinator.com/item?id=35745682)

Stability AI has released StableVicuna, the AI world's first open-source chatbot trained via reinforced learning from human feedback (RLHF). The chatbot follows a three-stage RLHF pipeline, utilizing datasets such as OpenAssistant Conversations Dataset and GPT4All Prompt Generations, and is further instruction fine-tuned for performance. StableVicuna is available for download on the HuggingFace Hub, alongside its upcoming chat interface. The team plans to iterate on the chatbot and deploy a Discord bot to the Stable Foundation server to further improve the user experience.

In the comments, some users discuss the complexity and limitations of fine-tuned models, suggesting that getting 30B models may not be helpful and that there are possibly 65B behaviors that are different. Others recommend specific AI models under the Apache BSD license, and one user mentions that the project may focus more on optimization rather than benchmarks. Some users recommend trying StableVicuna at https://huggingface.co/spaces/CarperAI/StableVicuna, while others discuss the use of GPT-generated content and reducing content quality. There is also a discussion about licensing and affordability, with some users noting that the project is relatively low-risk and that internal development may benefit from LLaMa.

---

## AI Submissions for Thu Apr 27 2023 {{ 'date': '2023-04-27T18:00:50.664Z' }}

### Hidet: A Deep Learning Compiler for Efficient Model Serving

#### [Submission URL](https://pytorch.org/blog/introducing-hidet/) | 108 points | by [ashvardanian](https://news.ycombinator.com/user?id=ashvardanian) | [14 comments](https://news.ycombinator.com/item?id=35737284)

Introducing Hidet: A Deep Learning Compiler for Efficient Model Serving by Team Hidet showcases the new Hidet deep learning compiler for PyTorch that simplifies the process of implementing high-performing deep learning operators on modern accelerators like NVIDIA GPUs. Hidet is easy to integrate into PyTorch and is an attractive option for PyTorch users who want to improve inference performance of their models. The blog post also provides a sample script to use Hidet to compile and optimize a pre-trained ResNet50 model from torchvision, and an example of how to implement a naive matrix multiplication using Hidet Script and integrate it as a PyTorch operator.

In the comments, users discuss the performance of Hidet compared to other compilers and frameworks like TensorRT, PyTorch Eager, and Triton. Some users highlight the benefits of Hidet Script, the domain-specific language that allows for high flexibility and expression of optimizations. Additionally, users bring up the relevance of benchmarks and the ability to create custom operators with Hidet Script. The discussion also includes technical issues and bugs that users have encountered with Hidet.

### Even Apple employees hate Siri and are skeptical of its future, new report says

#### [Submission URL](https://9to5mac.com/2023/04/27/apple-employees-siri-struggles/) | 395 points | by [carlycue](https://news.ycombinator.com/user?id=carlycue) | [411 comments](https://news.ycombinator.com/item?id=35730075)

A new report from The Information paints a daunting picture of the chaos and internal strife inside Apple's Siri and AI teams. According to more than three dozen former employees who spoke with the publication, "organizational dysfunction and a lack of ambition" have hindered Apple's efforts to improve Siri and its underlying technology, leading to the company falling further behind competitors like OpenAI, Microsoft, and Google. Furthermore, Apple lost three of its Siri engineers to Google, and the Siri team remains widely derided by current employees. Despite some efforts to improve the platform, this report suggests that there is much work to be done for Siri to catch up with its rivals.

The discussion on Hacker News focused on the flaws of Siri, including its speech recognition technology and its lack of understanding of some basic phrases. Some users also discussed the use of third-party keyboards and the limitations of adapting to different languages for personal assistants.

### Text-to-Audio Generation Using Instruction Tuned LLM and Latent Diffusion Model

#### [Submission URL](https://tango-web.github.io/) | 35 points | by [GaggiX](https://news.ycombinator.com/user?id=GaggiX) | [5 comments](https://news.ycombinator.com/item?id=35737151)

Researchers from the DeCLaRe Lab at the Singapore University of Technology and Design have developed a text-to-audio (TTA) generation AI called TANGO that uses an "instruction-tuned LLM" as a text encoder for better performance. TANGO outperforms the state-of-the-art AudioLDM on most metrics and stays comparable on the rest on AudioCaps test set, despite being trained on a smaller dataset. TANGO generates text-conditional sound effects, including human speech and music. While TANGO has limitations in terms of fine control of the generated audio, the team plans to improve it by training it on larger datasets. The code and model checkpoints have been released for reproducibility.

The discussion on this submission mostly involves appreciation for the technology and some additional insights on its capabilities. One user commends the researchers for their excellent work and also shares some resources featuring practical videos and high-level reviews. Another user expresses interest in the technology and suggests some additional tuning to improve its functionality. The user provides a link to an article on generating speech using machine learning. Another user comments on the state-of-the-art text-to-speech technology and shares a link to examples of speech generated synthetically through AI.

### The UIs ChatGPT Won't Replace

#### [Submission URL](https://exorva.com/blog/uis-chat-gpt-wont-replace) | 17 points | by [kmdupree](https://news.ycombinator.com/user?id=kmdupree) | [9 comments](https://news.ycombinator.com/item?id=35734660)

In a recent post on Hacker News, the founder of AI/LLM-powered app guide ChatGPT argues that traditional UIs won't be entirely replaced by chat-based experiences. The post examines tasks that rely on spatial metaphors, list items, and invariants, among other things, and demonstrates why chat-based UIs won't dominate the future. For example, busy people won't use ChatGPT to create calendar events, as they need to be able to see their schedule at a glance, while low-intent product exploration is better served by visual design patterns that instantly orient users. Ultimately, the author suggests that despite technological advancements, humans still work best with spatial and kinetic inputs.

The comments agree, with some suggesting certain tasks are better suited for GUIs or chat-based UIs. One commenter notes the importance of spatial understanding and memory, while another mentions that humans will always prefer human interfaces. Some comments also suggest that chat interfaces can be complementary to GUIs, and AI technology will allow easier access to a library of components for chat interfaces. Finally, one commenter mentions that time interaction feeling may become worse with chat-based interactions, and finding a balance between chat and GUI interfaces is important.

### Is Krita ready for HDR painting?

#### [Submission URL](https://notes.ericjiang.com/posts/1241) | 26 points | by [erjiang](https://news.ycombinator.com/user?id=erjiang) | [5 comments](https://news.ycombinator.com/item?id=35736913)

Krita, a digital painting software, has implemented support for high dynamic range (HDR) painting, allowing users to work with values above the traditional 0.0-1.0 range. However, there are areas within the software that still do not recognize these higher values, and some functions, such as LUT baking, are not yet possible. While it may be sufficient for general work and limited regions above 1, it may be difficult to work across a large dynamic range without proper exposure controls. Additionally, the software's target market may currently be too small to fully support HDR use.

Users on Hacker News talked about the importance of HDR painting and the limitations of current hardware, saying that cameras can capture more data than displays can render. Other users mentioned that HDR painting could be useful in creating works with a wider dynamic range and that similar workflows are used in 3D rendering software. One user also mentioned that games, TV, and movies are already using HDR rendering, but there are limitations due to the lack of HDR screens, which are not yet widely available. Overall, the discussion showed both excitement and caution about Krita's HDR support, with some saying that more exposure controls would be needed to work across a large dynamic range.

### Llama 1.3B Trained on 200B Tokens for Commercial Use

#### [Submission URL](https://huggingface.co/mosaicml/mpt-1b-redpajama-200b-dolly) | 23 points | by [vsroy](https://news.ycombinator.com/user?id=vsroy) | [7 comments](https://news.ycombinator.com/item?id=35737036)

The MPT-1b-RedPajama-200b-dolly is a powerful AI model with 1.3 billion parameters that has been fine-tuned on the Databricks Dolly instruction dataset. The model is a modification of a standard decoder-only transformer and features 24 layers, 16 attention heads, and width 2048. It has been pre-trained on a mix of datasets, with the majority being the RedPajama Common Crawl, and fine-tuned on the Databricks Dolly instruction dataset using the same hyperparameters found in their train_dolly.py script. The model uses ALiBi and QK LayerNorm and does not use biases. To use the model, one needs to pass `trust_remote_code=True` and use the MosaicML LLM codebase. The model was trained on the MosaicML Platform with sharded data parallelism using FSDP. The MPT-1b-RedPajama-200b-dolly is a valuable resource for instruction fine-tuning and natural language processing tasks.

The discussion in the comments primarily focuses on the number of parameters of the model and how they impact its performance. One user links to a paper on chinchilla scaling, which discusses optimizing the number of parameters for computational efficiency. Another user mentions being familiar with the RedPajama dataset.

### Lessons Learned Reproducing a Deep Reinforcement Learning Paper (2018)

#### [Submission URL](http://amid.fish/reproducing-deep-rl) | 48 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [10 comments](https://news.ycombinator.com/item?id=35732843)

Deep reinforcement learning is a fascinating field, but it can be more challenging than expected, as demonstrated by a recent project to reproduce a paper on training deep RL agents using feedback from humans. Debugging reinforcement learning involves lengthy iterations, and it's essential to be meticulous about the hypothesis-forming step to make the most of the scarce runs. It's also necessary to learn to recognize and follow through on confusion and be patient when getting stuck on problems for weeks at a time. Despite its challenges, the field holds much promise, as evidenced by recent work on training agents from human preference feedback.

In the comments, there is a discussion about the difficulties of reproducing research work and the need for patience and perseverance. One user shares their personal experience of creating a reinforcement learning agent to play a game and the challenges they faced. Another user recommends reading Sutton & Barto's book on reinforcement learning.

### Semantic Tokenizer for Enhanced Natural Language Processing

#### [Submission URL](https://arxiv.org/abs/2304.12404) | 68 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [28 comments](https://news.ycombinator.com/item?id=35729586)

A team of four researchers has published a paper titled Semantic Tokenizer for Enhanced Natural Language Processing on arXiv. The team presents a new tokenizer that uses semantics to drive vocabulary construction, with a trainer that uses stemming to enhance subword formation. The tokenizer is a drop-in replacement for the SentencePiece tokenizer and more than doubles the number of word forms represented in the vocabulary. The new tokenizer significantly improves NLP model convergence and improves the quality of word and sentence embeddings, with top performance seen in two Glue tasks using BERT-base, outperforming models more than 50 times in size.

Some comments noted that the paper was a significant improvement in transformer performance and highlighted how semantics can help processing multi-language texts. Others criticized the use of arXiv for class projects and questioned the significance of the paper's contribution. Additionally, some discussed the challenges of tokenization and the impact of vocabulary construction on natural language processing models.

### Palantir demos AI to fight wars but says it will be ethical

#### [Submission URL](https://www.vice.com/en/article/qjvb4x/palantir-demos-ai-to-fight-wars-but-says-it-will-be-totally-ethical-dont-worry-about-it) | 25 points | by [konart](https://news.ycombinator.com/user?id=konart) | [17 comments](https://news.ycombinator.com/item?id=35731534)

Palantir, co-founded by billionaire Peter Thiel, has demonstrated its Artificial Intelligence Platform (AIP) for military decision making. In Palantir's scenario, a military operator uses AI to monitor and respond to enemy activity, such as the recent amassing of military equipment near friendly forces. The operator asks a chatbot to show them more information, generates several plans of attack and organises the jamming of enemy communications. However, the author notes the dangers of automating warfare and abstracting it even further, suggesting the system is an illusion of safety and control for the Pentagon.

The comments discuss ethical concerns over the use of LLMs (lethal autonomous weapons). Some argue that the industry is ignoring these concerns, while others claim that the military will not deploy such systems until they are deemed safe and reliable. There are also some anecdotes about the long hours and intense work culture at Palantir.

### A Low Cost Approach to Improving Pedestrian Safety with Deep Learning

#### [Submission URL](https://nathanrooy.github.io/posts/2019-02-06/raspberry-pi-deep-learning-traffic-tracker/) | 62 points | by [djoldman](https://news.ycombinator.com/user?id=djoldman) | [58 comments](https://news.ycombinator.com/item?id=35727163)

A developer has created a cheap and accurate traffic counting system using TensorFlow and a Raspberry Pi Zero with an 8-megapixel infrared camera and rechargeable USB battery pack. The system uses a convolutional neural network with a secondary region proposal network to detect and localise objects within the frame, with lightweight temporal clustering to track them. The end result is a tool capable of separately counting vehicles, pedestrians and cyclists with high accuracy, potentially providing valuable data for urban planning and safety measures.

In the comments, there was a discussion on whether data on existing traffic patterns would be necessary for making biking more attractive in cities or if current infrastructure should be changed to support pedestrian traffic. Additionally, there was discussion on the correlation between frequent service and high passenger counts, as well as the challenges associated with increasing density and public transportation. There were also debates on making buses more efficient or switching to electric cars, as well as ideas for improving traffic congestion, such as increasing the use of roundabouts and encouraging the use of smaller cars.

---

## AI Submissions for Wed Apr 26 2023 {{ 'date': '2023-04-26T14:23:08.057Z' }}

### HDR-NeRF: High Dynamic Range Neural Radiance Fields

#### [Submission URL](https://xhuangcv.github.io/hdr-nerf/) | 142 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [32 comments](https://news.ycombinator.com/item?id=35717106)

Researchers from Northwestern Polytechnical University and Tencent AI Lab have developed a method called HDR-NeRF that can recover a high dynamic range radiance field from a set of low dynamic range views with different exposures. This allows for the generation of novel high dynamic range (HDR) and low dynamic range (LDR) views with varying exposures. The proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Experiments conducted on synthetic and real-world scenes validate the proposed method's ability to accurately control the exposures of synthesized views and render views with high dynamic range.

The discussion on the news discusses how the proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Some comments are about the advantages of using this method on smart-phones, while others discuss the limitations of the technology. The discussion also explores the naming convention of the technology and tone mapping. 

### Why did Google Brain exist?

#### [Submission URL](https://www.moderndescartes.com/essays/why_brain/) | 464 points | by [brilee](https://news.ycombinator.com/user?id=brilee) | [296 comments](https://news.ycombinator.com/item?id=35716216)

In this essay, former Google Brain employee Brian Kihoon Lee reflects on the existence of Google Brain and its relevance in today's economic conditions. He examines several reasons for its existence, including prestige, breakthrough discoveries, and maintaining a lead in machine learning. Lee suggests that while these reasons were valid in the past, economic pressures and increased competition from other AI companies mean that Google must be more responsible and directed in its research investments. He also notes a shift towards reduced researcher freedom and top-down direction within the company. Lee's perspective offers insights into the challenges facing industry research labs and the evolving landscape of AI development.

The discussion revolves around the validity of ML PhDs majoring in different fields such as chemistry and physics, and their proficiency in machine learning. Many users point out that while ML PhDs may not possess a deep understanding of the field they majored in, they are compensated for their lack of knowledge through their proficiency in ML. Others suggest that ML has helped cross disciplinary lines and created excellent interdisciplinary work. Some users argue that AI companies such as Google need to be more responsible and directed in their research investments, while others point out the need for foundational ML research. Overall, the discussion sheds light on the challenges facing the development of AI and industry research labs in general.

### DeepFloyd IF: open-source text-to-image model

#### [Submission URL](https://github.com/deep-floyd/IF) | 217 points | by [ea016](https://news.ycombinator.com/user?id=ea016) | [123 comments](https://news.ycombinator.com/item?id=35717871)

The StabilityAI team has developed a state-of-the-art open-source text-to-image model, called DeepFloyd IF, with high photorealism and language understanding. The model is composed of a frozen text encoder and three cascaded pixel diffusion modules that generate 64x64, 256x256, and 1024x1024 px images. The model uses the T5 transformer for text embedding and a UNet architecture with cross-attention and attention pooling. It outperforms other state-of-the-art models and achieves a zero-shot FID score of 6.66 on the COCO dataset. The DeepFloyd IF can be run locally and is also integrated with the Hugging Face Diffusers library.

The comments discuss DeepFloyd IF's capabilities compared to other text-to-image models and specific problems with the current implementation. Additionally, there is a discussion around hurdles with prompts and copyright laws. Some users express interest in trying the model with different prompts, while others debate the legal implications of using it.

### Mark Zuckerberg says Meta wants to ‘introduce AI agents to billions of people’

#### [Submission URL](https://www.theverge.com/2023/4/26/23699633/mark-zuckerberg-meta-generative-ai-chatbots-instagram-facebook-whatsapp) | 49 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [53 comments](https://news.ycombinator.com/item?id=35721910)

Meta CEO Mark Zuckerberg has announced plans to integrate AI agents into billions of Meta apps in ways that will be useful and meaningful for regular people, creators, and businesses. Although it remains unclear how exactly Meta will incorporate generative AI into its applications, Zuckerberg teased the release of AI products in the coming months that will reportedly touch every single one of the company's products. The move comes as Meta attempts to keep up with competitors such as Snap and Google that have invested heavily in building AI infrastructure in recent years, and to address industry-wide interest in the potential applications of generative AI technology.
 
There is a discussion on how AI is impacting society, with some commenters noting concerns about AI collecting information and privacy issues. Others discuss the potential uses of AI in marketing and content creation. One commenter suggests Meta should focus on developing computer vision capabilities. While there are some who support the use of AI, others are skeptical and concerned about how AI technology will impact humanity. Additionally, there are some comments about the renaming of the company to Meta and speculation about the company's future.

### Bringing Memory Safety to sudo and su

#### [Submission URL](https://www.memorysafety.org/blog/sudo-and-su/) | 81 points | by [mritzmann](https://news.ycombinator.com/user?id=mritzmann) | [64 comments](https://news.ycombinator.com/item?id=35714347)

Prossimo, a project by Ferrous Systems and Tweede Golf, has announced their plan to re-implement the widely-used sudo and su utilities in Rust to increase memory safety and minimize risks to operating systems. As sudo and su were originally developed in the 1980s and written in C, they have experienced a number of vulnerabilities related to memory safety issues. This joint team from Ferrous Systems and Tweede Golf will work to implement the critical function of these utilities in Rust to secure the most critical software, particularly from memory safety vulnerabilities. The work is supported by Amazon Web Services and Prossimo welcomes contributions to improve memory safety.

Discussions in the comments focused on the effectiveness of Rust's memory safety features, the complexity and vulnerabilities of other programming languages, and the importance of memory safety in software security. Some commenters suggested that OpenBSD's Doas could be a smaller, simpler alternative to sudo, and others discussed the advantages of different programming languages for memory safety.

### A guide to prompting AI, for what it is worth

#### [Submission URL](https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what) | 179 points | by [jger15](https://news.ycombinator.com/user?id=jger15) | [50 comments](https://news.ycombinator.com/item?id=35712375)

Recently, there has been a lot of emphasis on the importance of prompting AI, with some influencers sharing secrets of how to use prompts effectively. However, Ethan Mollick argues that this emphasis on prompting is misplaced and the best way to use AI systems is through interaction rather than trying to craft the perfect prompt. That being said, Mollick provides some tips on how to approach prompting, such as giving context and constraints to the system, providing additional data, and thinking about programming in prose. Ultimately, the key to using AI effectively is practice.

The discussion covers a variety of perspectives, including tips for approaching prompting, the limitations of AI in understanding human intent, and the importance of providing context and constraints to the system. Some commenters suggest that the emphasis on prompting is misplaced, while others argue that finding the right wording and constraints is crucial for successful outcomes. Overall, the discussion highlights the complex and ongoing nature of working with AI systems.

---

## AI Submissions for Tue Apr 25 2023 {{ 'date': '2023-04-25T15:39:53.181Z' }}

### Transformers from Scratch

#### [Submission URL](https://e2eml.school/transformers.html) | 341 points | by [jasim](https://news.ycombinator.com/user?id=jasim) | [28 comments](https://news.ycombinator.com/item?id=35697627)

Transformers are all about sequence transduction, we need a way to convert words to numbers so we can do math on them. One approach is to count each word from one and assign it a number, but there's an easier format for computers to work with: one-hot encoding. This assigns each word an array of mostly zeroes with a single one in its corresponding index. This allows us to compute dot products and is used in matrix multiplication, a way to combine two-dimensional arrays. Markov chains, represented as matrices, can be used as a first order model to show what the next word is likely to be based on recent words.

The submission discusses the use of one-hot encoding to convert words to numbers for mathematical operations. It is suggested that the use of matrices, such as Markov chains, can help predict the next likely word based on the sequence. The comments provide links to additional resources, such as Jay Alammar's Illustrated Transformer series and TensorFlow implementation, and discuss various aspects of tokenization, embeddings, and projections. Some users express disappointment in the complexity of the topic while others provide beginner-friendly resources for understanding it. Two comments are flagged as possibly inappropriate.

### Tuql: Automatically create a GraphQL server from a SQLite database

#### [Submission URL](https://github.com/bradleyboy/tuql) | 20 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [8 comments](https://news.ycombinator.com/item?id=35699017)

Tuql is a new tool that can convert a SQLite database into a GraphQL endpoint. With its ability to infer relationships between objects, Tuql currently supports `belongsTo`, `hasMany`, and `belongsToMany` relationships. The tool also generates the necessary mutations to create, update, and delete objects and can associate many-to-many relationships. Tuql can be used through the command line and is available as an npm package.

The comments on the submission mention that Tuql is a great tool, and some users mention other similar libraries. One user points out that Tuql does not add threat fields for queries, which may make it difficult to change the frontend in the future. Another user recommends not using Tuql in production. There is also a discussion around how GraphQL frameworks handle authorization and security. Overall, most of the comments are positive, with users praising the convenience of Tuql and GraphQL libraries in general.

### Show HN: ChatGPT on 2-Dimensional Map

#### [Submission URL](https://www.superusapp.com/chatgpt2d/) | 147 points | by [victorsup](https://news.ycombinator.com/user?id=victorsup) | [55 comments](https://news.ycombinator.com/item?id=35709088)

On Hacker News, a developer has created an interesting web app called "ChatGPT on 2-Dimensional Map." The app combines two popular AI technologies, namely GPT-2 for natural language processing and t-SNE for dimensionality reduction, to create a chatbot that can navigate a 2D map based on user inputs. The developer has also provided a demo, so users can see the app in action. This innovative project showcases the potential of combining different AI tools to develop new and creative applications.

A developer has created a web app called "ChatGPT on 2-Dimensional Map," utilizing both the natural language processing capabilities of GPT-2 and t-SNE for dimensionality reduction to create a chatbot that can navigate a 2D map based on user inputs. The discussion shows appreciation for this innovative project and its demonstration of the potential of combining AI tools to develop new applications. Some users express interest in using this technology for research and performance modeling, while others suggest similar projects and libraries for visualization and mapping. Some discuss related concepts such as Mind Maps and Lie Algebra. The high cost of ConceptGPT is mentioned, and some users suggest alternatives or that the creator should have asked for a funding request. A few users also mention indulging in activities such as drinking while programming or creating AI, while others make fun of misconceptions around Pina Coladas and canned ingredients.

### Google Authenticator cloud sync: Google can see the secrets, even while stored

#### [Submission URL](https://defcon.social/@mysk/110262313275622023) | 349 points | by [Signez](https://news.ycombinator.com/user?id=Signez) | [117 comments](https://news.ycombinator.com/item?id=35708869)

The discussion revolves around the security of Google Account 2FA secrets and how well Google protects its user data. Some commenters question Google's willingness to share user data with governments, while others suggest ways to enhance the security of the 2FA system and protect against data breaches. The conversation also touches on Apple's adherence to user privacy in comparison to Google. The debate ultimately boils down to how much responsibility users should take to protect their own privacy and how much they should rely on their service providers. One user recommends a phone security service called 2FAS for added security.

---

## AI Submissions for Mon Apr 24 2023 {{ 'date': '2023-04-24T15:21:30.763Z' }}

### LAION, a high school teacher’s free image database, powers AI unicorns

#### [Submission URL](https://www.bloomberg.com/news/features/2023-04-24/a-high-school-teacher-s-free-image-database-powers-ai-unicorns) | 315 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [172 comments](https://news.ycombinator.com/item?id=35685497)

The article tells the story of Christoph Schuhmann, a high school teacher who created LAION, the world's largest free AI training data set. LAION collects images and captions from various websites and uses them to train text-to-image generators, such as Google's Imagen and Stability AI's Stable Diffusion. The article explores the legal and ethical issues that arise from using publicly available materials for AI purposes, such as copyright infringement, bias, and regulation. The article also presents Schuhmann's views on why he wants to keep LAION open-source and independent.

Some users argue that LAION  only indexes internet lists of URLs, regional messages, and AI-generated text-to-image models, and does not publish any copyrighted content. Other users point out the potential legal liabilities and suggest that Common Crawl, a California nonprofit, should curate the collected visual data. Additionally, the comments touch on the challenges of accessibility in the design of captchas, the importance of properly organized high-quality imagery, and the legal implications of using scraped visual data for machine learning.

### Google Authenticator now supports Google Account synchronization

#### [Submission URL](https://security.googleblog.com/2023/04/google-authenticator-now-supports.html) | 429 points | by [ortusdux](https://news.ycombinator.com/user?id=ortusdux) | [305 comments](https://news.ycombinator.com/item?id=35690398)

Google Authenticator, a popular two-factor authentication app, now supports synchronization with Google Accounts. This means that users can easily transfer their authentication codes to a new device without needing to manually re-enter them. The feature is available on Android and iOS devices and uses Google Cloud to securely store and transfer the data. This upgrade provides added convenience and security for users who rely on two-factor authentication to protect their accounts.

Some users have complained about Google's 2FA offerings, including mismatched numbers and issues with Google Prompts not working on certain devices. Others have suggested potential solutions, such as using U2F tokens, while acknowledging the importance of account recovery processes involving important documents. The discussion also touches on related topics, such as password management, customer support, and device limitations. Overall, the consensus seems to be that while there are some issues and complexities with the technology, 2FA remains an important security measure that consumers should take advantage of.

### ONNX Runtime merges WebGPU backend

#### [Submission URL](https://github.com/microsoft/onnxruntime/pull/14579) | 166 points | by [b_mc2](https://news.ycombinator.com/user?id=b_mc2) | [31 comments](https://news.ycombinator.com/item?id=35694553)

Microsoft's open-source AI platform, ONNX Runtime, has introduced a WebGPU backend to accelerate machine learning models on the web. The JavaScript Execution Provider (JSEP) enables asynchronous inferencing execution and includes both C/C++ and TypeScript/JavaScript implementations. JSEP uses Emscripten's Asyncify compiler feature to unwind and rewind the call stack to emulate async execution. WebGPU is designed to have stronger features than WebGL, the other API currently available for accessing a GPU from a browser, making it a better solution for GPU performance when inferencing machine learning models.

Yhe submission sparked a discussion about the ONNX format, ONNX Runtime, and the implementation of the WebGPU backend for ML models. Some commenters suggested that the ONNX format is one of the best performing ML runtimes currently available, while others noted the lack of documentation for different platforms and hardware combinations. Others praised Microsoft's ONNX and made comparisons between different compiler systems. Some suggested alternative approaches to commenting and merging code to larger PRs. There was also discussion about the usefulness of the ONNX library, with some saying it worked well for them, and others suggesting that it could still use some improvement.

### 1Password to Add Telemetry 

#### [Submission URL](https://blog.1password.com/privacy-preserving-app-telemetry/) | 285 points | by [zan5hin](https://news.ycombinator.com/user?id=zan5hin) | [266 comments](https://news.ycombinator.com/item?id=35691383)

1Password, the password manager service, has begun an internal test of a new in-app telemetry system with a view to better understanding how users interact with the product. The initiative will be voluntary for employees and will not involve any data from customer accounts. Over the years, 1Password has regularly used its customer research programme to inform product development, but the company said it needed to expand its knowledge to improve the service for the millions of people using the product. Results from the internal trial will be evaluated before plans for a rollout are confirmed.

A user commented that they have been using the password manager Keepass, as they prefer a local vault and do not want any browser or cloud-based password managers. Another user praised 1Password's UI/UX, while others expressed concerns about the voluntary telemetry initiative and subscription-based licensing. Some users recommended Bitwarden and Keepass as alternatives with better functionalities. Some users also expressed skepticism about the benefits of telemetry and the need for it.

### Snapchat sees spike in 1-star reviews as users pan the ‘My AI’ feature

#### [Submission URL](https://techcrunch.com/2023/04/24/snapchat-sees-spike-in-1-star-reviews-as-users-pan-the-my-ai-feature-calling-for-its-removal/) | 240 points | by [mmq](https://news.ycombinator.com/user?id=mmq) | [200 comments](https://news.ycombinator.com/item?id=35689596)

Snapchat's new AI chatbot, powered by OpenAI's GPT technology, has been met with criticism by users following its recent public release. The chatbot, which is now pinned at the top of Snapchat's Chat tab, has resulted in a spike of negative reviews on the US App Store, with 75% being one-star reviews over the past week. Many users feel the chatbot is invasive and creepy, with concerns surrounding the collection of personal data, and have called for it to be a voluntary, opt-in feature. Some reviews indicate that even those who rated the app five stars have complaints about the My AI feature.

The comments section discusses data privacy concerns and the collection of personal data by companies, as well as the implementation of taxes like the Canadian Manufacturers Tax and GST. Some users feel that people do not grasp the extent of data collection that is happening, and that companies need to be more transparent about it. Others point out that sharing of personal information is an expected part of using such services.