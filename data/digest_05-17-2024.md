## AI Submissions for Fri May 17 2024 {{ 'date': '2024-05-17T17:10:25.226Z' }}

### OpenAI departures: Why canâ€™t former employees talk?

#### [Submission URL](https://www.vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release) | 993 points | by [fnbr](https://news.ycombinator.com/user?id=fnbr) | [787 comments](https://news.ycombinator.com/item?id=40393121)

In a shocking turn of events, OpenAI, the artificial intelligence company that brought us ChatGPT, is now making headlines for all the wrong reasons. While touting the release of ChatGPT 4o with its human-like conversational abilities, the company is also facing a major internal crisis. The resignations of key figures like co-founder and chief scientist Ilya Sutskever, along with his team leader Jan Leike, have sparked intense speculation and controversy.

The departure of these high-profile employees from OpenAI's superalignment team has raised concerns about the company's direction and culture. The lack of transparency surrounding their resignations has only fueled rumors and theories about what might be happening behind closed doors at OpenAI. One particularly troubling detail that has emerged is the strict off-boarding agreement that former employees are required to sign, which includes nondisclosure and non-disparagement clauses. This agreement effectively silences departing employees, preventing them from speaking out against the company or even acknowledging the existence of the NDA. Failure to comply with these terms can result in the loss of millions of dollars in vested equity, a severe consequence that acts as a powerful deterrent against speaking out. As OpenAI struggles to address the fallout from the resignations and the backlash over its restrictive policies, questions continue to swirl about the company's commitment to transparency and accountability. The once-celebrated tech giant now finds itself embroiled in controversy, raising doubts about its true priorities and values.

The discussion on the Hacker News submission revolves around OpenAI's internal crisis, particularly focusing on the resignations of key figures like co-founder Ilya Sutskever and the restrictive off-boarding agreements for departing employees. One user highlights the unethical nature of non-disclosure and non-disparagement agreements, emphasizing the severe consequences for former employees who do not comply.

Another commenter expresses concerns about OpenAI's pursuit of AGI (Artificial General Intelligence), suggesting that the company's direction may pose risks to humanity. They criticize OpenAI for prioritizing profit and venture capital over societal responsibility.
The conversation touches upon issues related to workers' rights, the impact of advancing AI technology on human labor, and the ethical considerations of AI development.
There are also mentions of Sam Altman, co-founder of OpenAI, with some users questioning his integrity and leadership, while others raise concerns about the company's culture and decision-making processes.

Overall, the discussion reflects a mixture of skepticism, ethical considerations, and speculation about the future of AI development at OpenAI.

### Multi AI agent systems using OpenAI's assistants API

#### [Submission URL](https://github.com/metaskills/experts) | 204 points | by [metaskills](https://news.ycombinator.com/user?id=metaskills) | [65 comments](https://news.ycombinator.com/item?id=40395107)

The new tool called metaskills / experts on GitHub is making waves by simplifying the creation and deployment of OpenAI's Assistants. Experts.js aims to revolutionize the way engineers interact with LLMs by enabling the creation of Multi AI Agent Systems with expanded memory and attention to detail. This tool leverages OpenAI's Assistants API, which represents a significant advancement beyond the Chat Completions API. Paired with the powerful GPT-4o model, Assistants can now reference attached files & images within a managed context window called a Thread. The Assistants can support instructions up to 256,000 characters, integrate with 128 tools, and efficiently search up to 10,000 files per assistant using the Vector Store API.

Experts.js simplifies the usage of the new API by allowing Assistants to be linked together as Tools, creating a Panel of Experts system. It introduces the concept of Multi AI Agent Systems, where each Tool can take on specialized roles or complex tasks, enabling orchestration workflows and task choreography.
With easy installation via npm and simple usage requiring just three objects to import - Assistant, Tool, and Thread - Experts.js provides a streamlined way to work with AI agents. The tool's async create() function handles finding or creating assistants by name and updating configurations to the latest version.

Users can interact with Assistants using the ask() function, providing a message and a thread identifier without having to manage Run objects directly. Experts.js also supports adding Assistants as Tools, allowing for seamless integration of different AI agents.
Furthermore, Experts.js leverages OpenAI's server-send events for streaming text, image, and tool outputs, giving developers control over events in their applications. By supporting various event names such as textDelta, toolCallDelta, and more, Experts.js paves the way for sophisticated applications using AI assistants.

In conclusion, Experts.js is a game-changer in the world of AI development, offering a user-friendly approach to creating Multi AI Agent Systems with advanced features and functionalities.

- Users in the discussion emphasized the potential of the Assistants API and the advancements it brings, although there were some concerns about the complexities and costs associated with OpenAI's platform. Some users shared their experiences with working on similar projects and their preferences for different frameworks.
- There was a debate about the effectiveness of specific models and APIs and the advantages of using different tools and methodologies for AI development.
- The discussion also delved into the challenges and benefits of utilizing Multi AI Agent Systems to solve complex problems and deliver real value in various industries.
- Some users shared their experimentation with custom RAG solutions and the importance of consistency and adaptability in AI development.
- The conversation touched on practical applications of AI-powered systems in enhancing productivity and individual worth within companies, as well as the potential for AI to revolutionize various industries.
- Various users shared insights and experiences related to using single-agent systems versus multi-agent platforms, discussing the limitations and benefits of each approach.

### LoRA Learns Less and Forgets Less

#### [Submission URL](https://arxiv.org/abs/2405.09673) | 167 points | by [wolecki](https://news.ycombinator.com/user?id=wolecki) | [58 comments](https://news.ycombinator.com/item?id=40389421)

The latest research paper titled "LoRA Learns Less and Forgets Less" delves into the realm of parameter-efficient fine-tuning methods for large language models. Authored by Dan Biderman and a team of 11 others, the study explores the efficacy of Low-Rank Adaptation (LoRA) compared to full fine-tuning in the domains of programming and mathematics. While LoRA may lag behind full fine-tuning in performance, it showcases superior regularization abilities, preserving the base model's proficiency in tasks beyond the target domain. By analyzing the perturbations learned, the researchers unearth insights into LoRA's mechanisms and suggest best practices for fine-tuning with LoRA. This paper, with its emphasis on memory optimization and regularization benefits, contributes valuable knowledge to the evolving landscape of machine learning and artificial intelligence.

The discussion on Hacker News surrounding the research paper titled "LoRA Learns Less and Forgets Less" includes various comments from users. Some users expressed confusion or humor about the similarity in names between LoRA and LoRa, a popular wireless protocol, over the past 10 years. Others delved into technical aspects, such as the small problem domain typical in machine learning and the importance of clear naming conventions. There were also discussions about the trademark registration of LoRa by Semtech Corporation and potential confusion with explosive material Semtex. 

Additionally, users touched on topics like the naming strategies of technology companies, the evolution of machine learning protocols, and the challenges faced by ML engineers in understanding wireless protocols. Some users critiqued the paper's findings, comparing LoRA to other methods like QLoRA and discussing the performance differences based on target models. The conversation dived into the comparison of LoRA's performance against other fine-tuning methods, the impact of low-rank adaptations on training parameters, and the potential benefits of LoRA in personal testing scenarios. 

Overall, the discussion highlighted a mix of technical analysis, industry insights, naming concerns, trademark issues, and personal anecdotes related to the research paper on LoRA and its implications in the machine learning field.

### Why neural networks struggle with the Game of Life (2020)

#### [Submission URL](https://bdtechtalks.com/2020/09/16/deep-learning-game-of-life/) | 120 points | by [DeathArrow](https://news.ycombinator.com/user?id=DeathArrow) | [77 comments](https://news.ycombinator.com/item?id=40388013)

Today on TechTalks, we delve into the challenges neural networks face when attempting to tackle the famous Game of Life automaton. Developed by British mathematician John Conway, the Game of Life is a grid-based system where cells transition between life and death based on simple rules. Despite its straightforward nature, neural networks struggle to learn the game effectively, as highlighted in a recent research paper by AI experts from Swarthmore College and the Los Alamos National Laboratory.

The experiment involved training a neural network to predict cell states in the Game of Life grid. While a hand-crafted model could achieve this with precision, training a neural network from scratch failed to consistently replicate these results, even with a million training examples. The study underscores the challenges deep learning models face in grasping the underlying rules of complex systems like the Game of Life, offering valuable insights for future AI research.

This in-depth analysis of neural networks' struggle with the Game of Life sheds light on the limitations of current AI technologies and hints at potential directions for further exploration within the field. Stay tuned for more captivating insights from the world of artificial intelligence on TechTalks.

The discussion about the submission about neural networks struggling with the Game of Life automaton was quite insightful on Hacker News. Here are some key points from the conversation:

1. There was a debate about the idea of using lottery hypothesis for neural networks, suggesting that optimizing larger networks can sometimes present challenges due to computational complexity and resource limitations compared to smaller networks.
2. The concept of global optimization and regularization of loss functions within neural networks was discussed in relation to tackling complex systems like the Game of Life.
3. The conversation extended to topics such as neuroplasticity, brain processes, and evolutionary perspectives on learning mechanisms, shedding light on how biological processes relate to artificial neural networks.
4. Some users highlighted the connection between genetic coding and training neural networks, drawing parallels between DNA and learning processes.
5. Other discussions included the role of sensory perception in brain function, the challenges of handling larger networks efficiently, and the comparison of neural network learning to biological evolution.
6. There was also an interesting comparison made between the struggle of neural networks with the Game of Life and the challenge faced by computer programs mimicking genetics and evolution, hinting at the complexities involved in both scenarios.
7. Additionally, references were made to various concepts like dropout technique, drawing connections between neural networks and real-world phenomena to understand their functioning better.

Overall, the discussion touched upon various aspects of neural network learning, optimization techniques, and their limitations when dealing with complex systems like the Game of Life.
