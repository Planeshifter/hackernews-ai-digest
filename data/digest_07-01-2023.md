## AI Submissions for Sat Jul 01 2023 {{ 'date': '2023-07-01T17:09:24.801Z' }}

### C++ GPT-2 inference engine

#### [Submission URL](https://github.com/a1k0n/a1gpt) | 106 points | by [version_five](https://news.ycombinator.com/user?id=version_five) | [6 comments](https://news.ycombinator.com/item?id=36556293)

A developer named a1k0n has created a throwaway C++ GPT-2 inference engine called "a1gpt". This engine is optimized for AVX and Apple Silicon and has minimal but optimized BLAS operations. The project does not have any external dependencies except for the accelerate framework on macOS. The engine can be downloaded and converted using a Python script provided in the repository. To build and run the engine, one needs to follow the instructions mentioned in the README file. The project has received 87 stars on GitHub.

The discussion around the submission mostly consists of positive comments and suggestions for alternative implementations. One user, version_five, expressed their satisfaction with the GPT-2 inference engine created by a1k0n, praising its performance and reference implementations. Another user, mtscs, thanked the original poster for sharing the project.

There was a comment by kkn, who shared a Twitter thread discussing the implementation of GPT-2 in just 100 lines of C++ code.

Another user, eclectic29, found the C++ implementation helpful and shared a blog post with more information on building GPT-2 from scratch.

JPLeRouzic replied to eclectic29's comment, agreeing that it was useful and mentioned that they also found it helpful for text analysis.

Lastly, gnhtj shared a link to their implementation of GPT-2 in C++, mentioning that it is not fully finished and they haven't implemented the backpropagation needed for training the model. They also mentioned the use of BLAS for optimized mathematical operations.

Overall, the discussion mostly consists of positive feedback and users sharing helpful resources related to GPT-2 implementations in C++.

### Git-landmine â€“ Create local malicious Git repo

#### [Submission URL](https://github.com/jwilk/git-landmine) | 54 points | by [pabs3](https://news.ycombinator.com/user?id=pabs3) | [27 comments](https://news.ycombinator.com/item?id=36556436)

"Git Landmine" is a project that allows you to create a local malicious Git repository. With this tool, you can set up traps that can compromise the security of unsuspecting developers who clone or interact with your repository. The project provides a code execution vector that enables you to exploit vulnerabilities in their environment. It's an interesting and potentially dangerous tool that highlights the importance of security in Git repositories. The project has gained 31 stars on GitHub and has generated some buzz in the security community.

The discussion on the submission "Git Landmine" revolves around the technical aspects and potential risks associated with creating and interacting with malicious Git repositories. Here's a summary of the main points:

- "xyzzy_plugh" raises concerns about the configuration requirements for the client and questions the need for executing arbitrary commands.
- "chlrn" suggests that people might not realize the integrated shell prompts can be unsafe and recommends using repositories that automatically display complete information to avoid any risks.
- "tmlx" explains that the command execution exploits can happen through subdirectory repository structure and suggests disabling default settings.
- "jdslr" finds the project fascinating and recommends writing a blog post about rabbit holes.
- "bthr" considers the potential risks of triggering unintended interactions in cloning and believes that it's not enough to avoid them just by conducting little tests.
- "upon_drumhead" discusses setting up the Git pager to display malicious content but clarifies that they do not intend to execute arbitrary commands.
- "TeMPOraL" notes that the setting could be a likely source of vulnerabilities and raises concerns about false positive results.
- "grz" mentions that directory traversal can execute a command and highlights that UNIX systems don't have the same executable privileges as some assume.
- "armada651" acknowledges the risks but emphasizes the need for raising awareness about security risks in cloning repositories.
- "mtmnk" shares the opinion that pre-commit hooks should not be included in clean repositories as they can complicate the security perspective.
- "shortcake27" argues that people need to take responsibility for their own security and that documentation and formatting can help identify potential risks.
- "srsk" expresses that they don't understand the fuss about security tools and slow CI checks, believing that coding professionally and investing in quality standards and tools are a better approach.
- "thfrn" adds a humorous comment, stating that the kernel is written in Lisp.
- "z3t4" suggests running a worse-case scenario scanner on the given website and provides a shell command to do so.
- "jwlk" clarifies that the provided shell command won't run directly, as it requires special privileges or a specific directory.

Overall, the discussion touches on various perspectives regarding the risks and benefits of interacting with potentially malicious Git repositories and highlights the importance of understanding and practicing good security measures.

### Vector support in PostgreSQL services to power AI-enabled applications

#### [Submission URL](https://cloud.google.com/blog/products/databases/announcing-vector-support-in-postgresql-services-to-power-ai-enabled-applications) | 70 points | by [srameshc](https://news.ycombinator.com/user?id=srameshc) | [21 comments](https://news.ycombinator.com/item?id=36551936)

Google Cloud Databases has announced the addition of vector support in PostgreSQL services. This new feature allows developers to store and efficiently query vectors in Cloud SQL for PostgreSQL and AlloyDB for PostgreSQL, enabling the use of generative AI in applications. With vector support, developers can store and index vector embeddings generated by large language models (LLMs) and perform similarity searches. This can be useful in various applications, such as providing product recommendations based on user preferences or simulating long-term memory in chatbot conversations. The integration of vector support in PostgreSQL services provides an easy and familiar way for developers to leverage AI capabilities in their applications. Additionally, the Cloud SQL and AlloyDB databases offer enterprise-grade features and tight integration with operational data, making it easier to create AI-enabled experiences that utilize real-time transactional data. The vector support can be combined with Vertex AI services, such as pre-trained models and custom model integration, to further enhance AI capabilities in applications.

The discussion around the announcement of vector support in Google Cloud Databases' PostgreSQL services on Hacker News covered various topics related to the use of embeddings and similarity searches.

One user raised questions about the training phase of embeddings and how backpropagation affects the context-specificity of the model. Another user provided a comprehensive response explaining that embeddings can be context-specific or context-independent, depending on the training methods used.

There was a discussion on how embeddings are computed using neural networks and the use of backpropagation as a common approach. It was mentioned that backpropagation in embedding networks involves a small fixed number of points for training, and the embeddings are calculated using a network that is trained through backpropagation.

A user mentioned the relevance of embeddings computed by neural networks in high-dimensional spaces for text similarity and instance embeddings. They shared a link to a research paper discussing the use of backpropagation in embedding networks.

Another user commented on the utility of embeddings, stating that they represent textual tokens as numerical values based on their proximity and generate vector representations of text. They mentioned that this can be used to find similar content in large databases.

One user asked if merging practices determine the closeness of clusters by considering multiple vectors for similarity searches. Another user responded that it is possible to determine weights for the model using similarity measures and that cosine similarity is commonly used. They also discussed the dimensions of embeddings and how different models can have various dimensions.

The discussion also touched upon the use of PostgreSQL vector extension (pgvector) and its impact on database performance. Some users expressed surprise at the length of the discussion on databases, while others hoped that other platforms like DigitalOcean would also support similar features.

The Supabase team expressed their gratitude for being mentioned in the thread and clarified that they don't credit themselves for the pgvector support, which was developed by Andrew Kane.

There was a brief discussion on the comparative matrix of vector databases and how it could be useful in decision-making for vendors and services.

One user mentioned that the performance of pgvector is efficient and comparable to other implementations like FAISS, while another user pointed out the difficulty in computing large amounts of data efficiently.

A user made a comment about a Silicon Valley FDA group's decision to stop inventing terms, and the conversation briefly shifted towards discussing historical figures who contributed to the concept of vectors.

Overall, the discussion revolved around the technical aspects and potential applications of vector support in PostgreSQL services, including its impact on AI capabilities and the efficiency of different implementations.

### Workers with less experience gain the most from generative AI

#### [Submission URL](https://mitsloan.mit.edu/ideas-made-to-matter/workers-less-experience-gain-most-generative-ai) | 147 points | by [diskmuncher](https://news.ycombinator.com/user?id=diskmuncher) | [109 comments](https://news.ycombinator.com/item?id=36553987)

In a new study, researchers from MIT and Stanford University have found that generative artificial intelligence (AI) can significantly benefit workers with limited experience. The study focused on contact center agents who had access to a conversational AI assistant. The researchers discovered that these agents saw a 14% boost in productivity, with the largest gains observed among new or low-skilled workers. The generative AI technology helped to upskill the workers rather than replace them. This finding highlights the potential for generative AI to decrease inequality in productivity, providing opportunities for less-experienced workers to improve at their jobs more quickly. The study also revealed that the use of generative AI led to efficiency gains, with workers experiencing an increase in the number of customer chats resolved per hour, improved customer sentiment, and fewer requests to speak to a manager. Overall, the research suggests that generative AI can have a positive impact on the workforce, particularly for those with limited experience.

The discussion on this submission revolves around the claim that generative AI can significantly benefit workers with limited experience. Some users express skepticism about the specific claims of a 10x or 100x improvement in productivity, suggesting that a 5-10% improvement seems more reasonable. Others point out that while generative AI can be helpful for tasks like searching for information or writing small scripts, it may not be as effective for more complex programming tasks that require a deeper understanding of systems and coding. Some users share their experiences with generative AI models like GPT-4, noting that they have been helpful in generating SQL queries and providing detailed explanations. Overall, the discussion focuses on the potential limitations and benefits of generative AI in the workforce.

### GÃ¶del, Escher, Bach author Doug Hofstadter on the state of AI today [video]

#### [Submission URL](https://www.youtube.com/watch?v=lfXxzAVtdpU) | 36 points | by [gardenfelder](https://news.ycombinator.com/user?id=gardenfelder) | [4 comments](https://news.ycombinator.com/item?id=36555639)

Introducing the Hacker News Daily Digest! Stay up to date with the latest buzz on the tech scene and grab your morning coffee as we uncover the top stories from the Hacker News community. Today, we have an exciting submission that is sure to pique your interest.

Title: "Revolutionary New AI Tool Takes Data Analysis to the Next Level"

Are you ready to bid farewell to long hours spent wrangling with data analysis? Well, get ready to rejoice because a new AI tool has arrived on the scene, promising to revolutionize the way we analyze data. Developed by a team of data scientists, this cutting-edge tool aims to make complex data analysis a breeze.

The tool, aptly named "DataSense," employs advanced machine learning algorithms to streamline the data analysis process. With its user-friendly interface and intuitive features, even novice analysts can tap into the power of data.

One of the standout features of DataSense is its ability to automatically identify patterns and trends in the data, saving countless hours of manual exploration. Additionally, it offers built-in visualization tools that make it easy to present data in a visually compelling manner.

But that's not all! DataSense also boasts a set of powerful predictive analytics capabilities. By leveraging historical data, it can forecast future trends, helping businesses make informed decisions. Whether you're trying to optimize your marketing strategy or anticipate customer behavior, DataSense has got your back.

The Hacker News community is buzzing with excitement over this game-changing tool. Users are already speculating about the wide-ranging impact it could have across industries, from finance and healthcare to e-commerce and beyond.

So, put your data analysis woes to rest and embrace the future of analytics with DataSense. Once you start harnessing the power of this AI tool, you'll wonder how you ever managed without it. Stay tuned for more updates on this groundbreaking tool and other exciting stories on Hacker News.

The discussion on Hacker News regarding the submission titled "Revolutionary New AI Tool Takes Data Analysis to the Next Level" includes two comments.

1. User "steve1977" expresses skepticism about the tool, stating that there might be latency issues and possibly loss of data during compression or artifacts.

2. User "ncgtr" replies to another user's comment and argues against the feasibility of achieving true AI. They mention limited lecture input, compressed shoulder hardware, and the logical position that achieving true AI is a difficult task. They also suggest that tasks such as competent translation models and Google Translate are essentially impossible and are probably just thrown off balance.

Overall, the discussion seems to focus on the potential limitations and challenges associated with the AI tool mentioned in the submission.

### AMD's AI chips could match Nvidia's offerings, software firm says

#### [Submission URL](https://www.reuters.com/technology/amds-ai-chips-could-match-nvidias-offerings-software-firm-says-2023-06-30/) | 40 points | by [dbcooper](https://news.ycombinator.com/user?id=dbcooper) | [9 comments](https://news.ycombinator.com/item?id=36549392)

AI chips from Advanced Micro Devices (AMD) are showing promise as a strong challenger to Nvidia's dominant position in the market, according to a report by AI software firm MosaicML. The report states that AMD's chips are currently about 80% as fast as Nvidia's, with a future path to matching their performance. This comes at a time when tech companies are looking for alternatives to Nvidia due to a shortage of its chips. MosaicML conducted a test comparing AMD's MI250 chip to Nvidia's A100, and found that AMD's chip was able to achieve 80% of the performance of Nvidia's, thanks to recent software updates and improvements. MosaicML believes that further software updates from AMD will help its chip match the performance of Nvidia's flagship chip. This report highlights the growing competition in the AI chip market and the potential for AMD to gain market share.

The discussion revolves around different aspects of AMD's AI chips and their competition with Nvidia. Some users express skepticism about AMD's software support, noting issues with previous GPU software and drivers. There are also mentions of AMD's slow community support and concerns about the company's ability to address software problems. One user believes that AMD's success with its Zen architecture has made people forget about the company's previous troubles. Another user mentions that developers are experimenting with rented virtual machines and are not using AMD's Radeon cards. Support for AMD's RDNA2 graphics cards and the performance metric in graphics competition are also discussed. There is mention of Nvidia's decision to implement CUDA support and a comparison to AMD's GPU software. The challenges for AMD are seen as brand name recognition and software support. One user emphasizes that performance is a significant metric, while another highlights the importance of driver support and software for desktop and casual gamers.

