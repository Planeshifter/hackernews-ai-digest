## AI Submissions for Thu Jun 29 2023 {{ 'date': '2023-06-29T17:11:45.160Z' }}

### Building Boba AI: Lessons learnt in building an LLM-powered application

#### [Submission URL](https://martinfowler.com/articles/building-boba.html) | 160 points | by [nalgeon](https://news.ycombinator.com/user?id=nalgeon) | [62 comments](https://news.ycombinator.com/item?id=36523480)

Today's top story on Hacker News is about the lessons learned and patterns discovered while building an experimental AI co-pilot called "Boba." Boba is designed to assist with product strategy and generative ideation by leveraging a Large-Language Model (LLM) to generate ideas and help users navigate complex conversational flows. The article outlines several patterns for building generative co-pilot applications, including Templated Prompt, Structured Response, Real-Time Progress, Select and Carry Context, Contextual Conversation, Out-Loud Thinking, Iterative Response, and Embedded External Knowledge. These patterns aim to enhance the user's interaction with the LLM, improve the quality of generated results, and integrate external knowledge that the LLM may not have.

Boba is described as an AI co-pilot that augments the early stages of strategy ideation and concept generation. It enables users to generate and evaluate ideas in partnership with AI, leveraging OpenAI's LLM to generate ideas and answer questions related to specific domains. The first prototype of Boba focuses on capabilities such as researching signals and trends, creative matrix concepting, scenario building, strategy ideation, concept generation, and storyboarding. The article also mentions that Boba is a web application that serves as an interface between the user and the LLM (currently GPT 3.5). The goal of Boba is to simplify the interaction with the LLM for users who may not be familiar with effectively engaging with AI systems. The discussion highlights a mix of enthusiasm for AI co-pilots and a critical examination of their limitations, practicality, and potential for real-world applications. There is also a focus on the importance of integrating AI with existing tools and incorporating structured data for improved interactions and results.

### Tesla Fleet Telemetry

#### [Submission URL](https://github.com/teslamotors/fleet-telemetry) | 205 points | by [shekhar101](https://news.ycombinator.com/user?id=shekhar101) | [120 comments](https://news.ycombinator.com/item?id=36525940)

Tesla has released a decentralized framework called Fleet Telemetry, which allows Tesla customers to create a secure and direct connection between their Tesla devices and authorized third-party providers. Fleet Telemetry is a simple, scalable, and secure data exchange service for vehicles and other devices. It handles device connectivity, data transmission, and storage. Customers can configure telemetry records and receive acknowledgments, error responses, or rate limit notifications. Fleet Telemetry can be installed on Kubernetes with a Helm Chart or as a standalone binary. It requires setting up a publicly available endpoint and mutual TLS (mTLS) WebSocket connections for device communication. The service can be configured for different data backends and dispatchers. Tesla emphasizes the importance of security and privacy in Fleet Telemetry, allowing customers to have control over their data sharing.

The discussion on this submission revolves around the topics of privacy, data sharing, and the implications of Tesla's Fleet Telemetry framework. Some users express concerns about the potential misuse of customer data by third-party apps and the need for stronger privacy laws to protect consumers. Others argue that the benefits of data sharing and telemetry outweigh the risks, and that Tesla owners have control over their data. There are also discussions about the level of privacy protection provided by current laws and the potential for manipulation through targeted advertising.

### Valve is not willing to publish games with AI generated content anymore?

#### [Submission URL](https://old.reddit.com/r/aigamedev/comments/142j3yt/valve_is_not_willing_to_publish_games_with_ai/) | 611 points | by [Wouter33](https://news.ycombinator.com/user?id=Wouter33) | [380 comments](https://news.ycombinator.com/item?id=36522665)

Valve, the company behind the Steam gaming platform, has recently made it clear that they are not willing to publish games with AI-generated content. A developer shared their experience of trying to release a game with assets that were obviously AI-generated, only to have their submission rejected by Valve. The rejection message stated that the game contained art assets generated by AI that appeared to be relying on copyrighted material owned by third parties. Valve cited the unclear legal ownership of such AI-generated art as the reason for their decision. The developer then improved the assets by hand, but their resubmitted app was still rejected. This incident highlights the uncertainty around AI-generated content and the challenges developers may face in getting their games published. While some games on Steam do mention the use of AI, Valve, at least for now, seems wary and not willing to publish AI-generated content. The developer plans to try uploading their game to itch.io to see if they face similar issues there.

The discussion on this submission revolves around Valve's decision to not publish games with AI-generated content. Some users argue that Valve's rejection of games with AI-generated assets is justified due to potential copyright infringement, while others express frustration with the lack of clear guidelines and transparency from Valve. There are also discussions about the ethical implications of AI-generated content and the role of journalists in verifying information. Some users bring up the possibility of Valve's stance being influenced by legal concerns or demands from the public. The inconsistency in Valve's decisions and the potential impact on blockchain games are also mentioned in the discussion. Overall, there are mixed reactions and discussions about the legal, ethical, and practical aspects of AI-generated content in games.

### XGen-7B, a new 7B foundational model trained on up to 8K length for 1.5T tokens

#### [Submission URL](https://blog.salesforceairesearch.com/xgen/) | 260 points | by [bratao](https://news.ycombinator.com/user?id=bratao) | [92 comments](https://news.ycombinator.com/item?id=36514936)

Salesforce's team of researchers have trained a series of 7B Long-Range Language Models (LLMs) called XGen-7B that can handle input sequence lengths of up to 8K tokens. The models achieve comparable or better results than state-of-the-art open-source LLMs on standard NLP benchmarks. They also outperform 2K- and 4K-seq models on long sequence modeling tasks. XGen-7B performs well on both text and code tasks and has a training cost of $150K on 1T tokens. The codebase and checkpoint for XGen-7B are available on GitHub and Hugging Face, respectively. The researchers explain that the need for LLMs to effectively model long sequences is crucial for tasks such as summarizing text, writing code, and predicting protein sequences. Most open-source LLMs are trained with a maximum of 2K token sequence length, which limits their ability to handle long sequences. The XGen models were fine-tuned on public-domain instructional data, resulting in instruction-tuned counterparts. The researchers used a two-stage training strategy and JaxFormer, their in-house library, to train the XGen-7B models. They also explored "loss spikes" during training and made improvements to ensure stable training at larger model sizes. Overall, XGen-7B with 8K sequence length offers advancements in long sequence modeling.


