## AI Submissions for Sun Sep 03 2023 {{ 'date': '2023-09-03T17:09:36.877Z' }}

### Vector Search with OpenAI Embeddings: Lucene Is All You Need

#### [Submission URL](https://arxiv.org/abs/2308.14963) | 86 points | by [kwindla](https://news.ycombinator.com/user?id=kwindla) | [61 comments](https://news.ycombinator.com/item?id=37373635)

Researchers Jimmy Lin, Ronak Pradeep, Tommaso Teofili, and Jasper Xian have released a paper titled "Vector Search with OpenAI Embeddings: Lucene Is All You Need," challenging the notion that a dedicated vector store is necessary for leveraging deep neural network advancements in search. The researchers demonstrate that Lucene, leveraging hierarchical navigable small-world network (HNSW) indexes, is sufficient for vector search in a standard bi-encoder architecture. Their findings suggest that there is no compelling reason to introduce a dedicated vector store into modern AI stacks for search, given the substantial investments made in existing infrastructure.

The discussion on the submission mainly focused on the use of Lucene and PostgreSQL with pgvector for vector search. Many comments expressed that using Lucene for vector search is simpler and more straightforward for development and production purposes. Some users mentioned that using managed databases like RDS on AWS or Azure is a good option, while others pointed out the importance of security backups regardless of the technology being used. 

There was also a discussion about the practicality and performance of Lucene compared to other vector search options like Elasticsearch or Solr. Some users mentioned that Elasticsearch and Solr are used for production systems that require higher performance and features, while others emphasized the simplicity and usability of Lucene. 

One user raised the issue of naming and the importance of respecting breakthrough papers that have fundamentally changed the machine learning landscape, while another expressed frustration with complaints about the paper and urged for more constructive discussions. 

There were also mentions of other tools and libraries for vector search, such as Faiss, Hnswlib, and Annoy, as well as discussions about the performance metrics and limitations of different approaches in handling large datasets and scaling. 

Overall, the discussion revolved around the effectiveness of using Lucene for vector search and the various options and considerations in implementing vector search in different scenarios.

### The Eleuther AI Mafia

#### [Submission URL](https://www.latent.space/p/rwkv#%C2%A7the-eleuther-mafia) | 89 points | by [swyx](https://news.ycombinator.com/user?id=swyx) | [60 comments](https://news.ycombinator.com/item?id=37368264)

In a recent episode of the Latent Space: The AI Engineer Podcast, host swyx discusses the reinvention of Recurrent Neural Networks (RNNs) for the Transformer era with Eugene Cheah, CTO of UIlicious. The conversation dives into the concept of Receptance Weighted Key Value (RWKV) models, which aim to scale better than traditional Transformers while remaining competitive on reasoning benchmarks. RWKV models have garnered attention for their ability to handle large context sizes and support multiple languages. The discussion also touches on the international, uncredentialed community behind the RWKV project and its similarities to the early days of Eleuther AI. Overall, this episode provides insights into the advancements and challenges of LLM (Language Model) research beyond Transformers.

The discussion around the submission focuses on different aspects of the Receptance Weighted Key Value (RWKV) models and their potential impact on language models (LLMs). 
Some commenters express interest in the RWKV models and how they compare to traditional Transformers and RNNs. They note that RWKV models have shown promising results in terms of speed and performance for large context sizes. There is also discussion about the importance of quantization and stability in supporting RWKV models.
Others comment on the need for independent verification of the claims made about RWKV models and whether they can truly outperform existing models. Some suggest that the current landscape of language models needs more evidence and standardized benchmarks to properly evaluate their performance.
There is also discussion about the similarities between the emergence of RWKV models and the early days of Eleuther AI, emphasizing the role of the open-source and uncredentialed community in driving innovation in the field of LLM research. Overall, the discussion highlights the ongoing advancements and challenges in LLM research beyond Transformers, while also acknowledging the need for further validation and benchmarking of new models like RWKV.

### Vigil, the eternal morally vigilant programming language

#### [Submission URL](https://github.com/munificent/vigil) | 117 points | by [alex_marchant](https://news.ycombinator.com/user?id=alex_marchant) | [25 comments](https://news.ycombinator.com/item?id=37366678)

Vigil, the Eternal Morally Vigilant Programming Language: Vigil is a programming language that takes testing, contracts, and safety to a whole new level. It ensures that code that fails to meet certain specifications is not allowed to run. Vigil is similar to Python in terms of syntax and semantics but adds a layer of supreme moral vigilance. It uses the implore statement to require certain properties for parameters and the swear statement to state what it promises to return. If a function fails to meet its obligations or throws unhandled exceptions, Vigil will delete it from the source code. The goal is to ensure that the program meets its requirements by forbidding code that fails to do so automatically. This unique approach to programming safety sets Vigil apart from other languages.

The discussion on Hacker News surrounding the submission about Vigil, the morally vigilant programming language, covers a variety of opinions. Some users express skepticism about the effectiveness of Vigil, arguing that deleting code that fails to meet requirements may be too extreme of a punishment. Others joke about the consequences of making programming mistakes in Vigil, with one user suggesting that the language may lead programmers to redeem themselves by deleting their own code. Another user points out that while Vigil may punish code for unhandled exceptions, Python's handling of exceptions can also be problematic. The discussion also includes some off-topic comments, such as references to competitive programming and Monty Python sketches. Overall, the opinions on Vigil seem divided, with some finding it interesting and others expressing doubts about its practicality.

### Call of Duty enlists AI to eavesdrop on voice chat and help ban toxic players

#### [Submission URL](https://www.pcgamer.com/call-of-duty-enlists-ai-to-eavesdrop-on-voice-chat-and-help-ban-toxic-players-starting-today/) | 20 points | by [herbertl](https://news.ycombinator.com/user?id=herbertl) | [22 comments](https://news.ycombinator.com/item?id=37370934)

Activision Blizzard has announced a partnership with AI company Modulate to integrate its voice moderation tool, ToxMod, into the Call of Duty games. ToxMod is designed to identify and enforce against toxic speech in real-time, including hate speech, discriminatory language, and harassment. The AI tool analyzes tone and intent in speech, going beyond just keywords to determine what is and isn't toxic. It can also detect terms and phrases related to white supremacist groups and violent radicalization. ToxMod will roll out in Call of Duty at the launch of Modern Warfare 3 on November 10.

The discussion on the announcement of Activision Blizzard's partnership with Modulate to integrate the ToxMod voice moderation tool into Call of Duty games sparked a range of opinions. Some comments expressed concerns over the potential slippery slope of censorship and surveillance, questioning the need for monitoring and moderation in games. Others argued that the AI moderation tool's proficiency in identifying and banning toxic players greatly outweighed privacy concerns. There was further debate about the effectiveness of moderation in games like Overwatch and the impact it had on creating a more enjoyable gaming environment. Some commenters also discussed the nature of video games and their depiction of violence, while others highlighted experiences of encountering racist and toxic comments while gaming. The conversation shifted to issues of racism and sexism in gaming communities, with differing views on whether games themselves perpetuate these behaviors or simply reflect society. One commenter humorously suggested that fun is impossible in a world without racism and sexism, leading to further exchanges about the role of moderation and player-driven servers. The discussion ultimately expanded into larger societal issues surrounding racism and prejudice.

