## AI Submissions for Tue Apr 02 2024 {{ 'date': '2024-04-02T17:10:49.199Z' }}

### CityGaussian: Real-time high-quality large-scale scene rendering with Gaussians

#### [Submission URL](https://dekuliutesla.github.io/citygs/) | 456 points | by [smusamashah](https://news.ycombinator.com/user?id=smusamashah) | [120 comments](https://news.ycombinator.com/item?id=39907876)

Today's top story on Hacker News is about a groundbreaking research paper titled "CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians." The paper introduces CityGaussian (CityGS), a novel approach that tackles the challenge of efficiently training and rendering large-scale 3D Gaussian Splatting (3DGS) in real-time. By utilizing a divide-and-conquer training method and a Level-of-Detail (LoD) strategy, CityGS enables seamless fusion and fast rendering of detailed scenes across different scales.

The research paper highlights how CityGS outperforms existing techniques by achieving state-of-the-art rendering quality and significantly improving the rendering speed. By incorporating the LoD technique, CityGS can render large-scale scenes in real-time under varying scales, achieving an impressive average speed of 36 FPS. The paper includes visual comparisons and references to related works in the field, showcasing the innovative contributions of CityGaussian to real-time scene rendering.

Overall, CityGaussian presents a promising advancement in the field of 3D scene reconstruction and rendering, demonstrating the potential for high-quality, real-time rendering of large-scale scenes. This research is likely to attract interest and discussion within the Hacker News community due to its technical innovation and practical applications.

The discussion on Hacker News around the groundbreaking research paper on CityGaussian, a real-time large-scale scene rendering technique, covered various aspects of the research paper and related topics. Here is a summary of the key points made by the community:

- The original post referenced a highly extracted Unreal Engine 5 Matrix demo that was released years ago and highlighted similarities to CityGaussian.
- A commenter shared insights on Epic Games acquiring Quixel, a photogrammetry company, and using scanned assets for building the Matrix city.
- There was skepticism expressed regarding claims about the data set and the need for expert verification.
- Discussions touched upon the technical challenges of photogrammetry in determining camera position accurately in 3D space and the complexities of Gaussian splatting in rendering scenes.
- Some users mentioned procedural generation of splats with randomized distribution for improved efficiency in rendering complex scenes.
- Parallel discussions arose around real-time speeds in graphics rendering, historical benchmarks, and advancements in real-time rendering capabilities over the years.
- Comments highlighted the advancements in GPU benchmarks, Next-Gen consumer GPUs, and the potential impact of research like CityGaussian on the field of Virtual Production and beyond.
- Users shared references to related projects like OpenSplat and discussed the evolution of Gaussian splatting techniques over the years.
- Lastly, there were mentions of Google Earth's relevance, potential future advancements in technologies like LOD streaming optimizations, and the pace of innovation in the AI research domain.

Overall, the conversation reflected a mix of technical insights, skepticism, and appreciation for the research presented in the CityGaussian paper, stimulating further exploration into the field of real-time scene rendering and its practical implications.

### ReALM: Reference Resolution as Language Modeling

#### [Submission URL](https://arxiv.org/abs/2403.20329) | 120 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [14 comments](https://news.ycombinator.com/item?id=39911961)

The paper titled "ReALM: Reference Resolution As Language Modeling" explores the use of Language Models (LLMs) for reference resolution, particularly for non-conversational entities like those on a user's screen or in the background. By converting reference resolution into a language modeling problem, the authors show significant improvements over existing systems, with their smallest model even outperforming GPT-4 in some aspects. This work sheds light on the potential of LLMs in solving complex contextual problems across various types of references. More details can be found in the paper authored by Joel Ruben Antony Moniz and his team.

1. **dvt** shared excitement about their work involving language models for reference resolution in non-conversational entities like those on a screen, noting significant performance with their models even outperforming GPT-4 in some aspects.
2. **smrvc** asked for an explanation of the plan for fine-tuning the dataset for training, while **rchrdkmchl** shared a reminder link.
3. **lwsmnlws** commented positively on the hard work and contents of the discussion.
4. **dvt** further elaborated on their recent work and challenges faced in context-dependent reference resolution, including cleaning up data, dealing with non-context-relevant information, and using multishot prompting.
5. **djhnstn** mentioned that they fixed an error in their post about making something enlisted.
6. **dnlvghn** asked for an explanation of reference resolution in simple terms, while **shrmntktp** and **lnkr** contributed by discussing linguistic references and specific corner cases.
7. **thrsd** pondered about the possibility of Apple's Siri replacement being context-based and inquired about the data processing differences for Points of Interest (POI) in Apple's data.
8. **CharlesW** discussed the criticism faced by Apple's POI data provider and their transition to using OpenStreetMap data for better traffic information, eliciting comments from **ynhn** about user dissatisfaction in certain regions due to map inaccuracies.
9. **ultra_nick** suggested adding a 2D text position feature to vectors.

### Show HN: Undermind ‚Äì Deep scientific paper search with adaptive LLMs

#### [Submission URL](https://www.undermind.ai/home/) | 31 points | by [tomhartke](https://news.ycombinator.com/user?id=tomhartke) | [13 comments](https://news.ycombinator.com/item?id=39906683)

Undermind is revolutionizing scientific search with its cutting-edge algorithms that deliver unparalleled accuracy and comprehensiveness. With a focus on quality, Undermind can tackle even the most complex research topics with stunning accuracy, filtering out irrelevant results to highlight the most relevant papers. By leveraging Semantic Scholar's database of over 200 million articles, Undermind offers researchers a deep search experience that promises to enhance the research process significantly. Researchers can now access a powerful tool that outperforms Google Scholar by 10-50 times. If you want to elevate your research capabilities, give Undermind a try today and witness the difference in your research outcomes.

The discussion on the submission about Undermind, a scientific search tool, includes various perspectives and comparisons with other platforms. One user mentions using an AI research assistant and finds it fundamentally interesting, citing the high relevance of results and the confusion about some sections. Another user shares their positive experience with the platform, impressed with the search results related to cancer treatment research. There are discussions about different tools and approaches, such as using GPT-4 for classification and the importance of low latency in search engines. Additionally, there are mentions of other platforms like Elicit, Lumina-cht, Consensus, and OpenEvidence. Overall, the comments provide insights into users' experiences, comparisons with existing tools, and suggestions for enhancing research capabilities.

### AI Coach designed to help you start your tasks

#### [Submission URL](https://www.planroadmap.com/) | 38 points | by [PlanRoadmap](https://news.ycombinator.com/user?id=PlanRoadmap) | [12 comments](https://news.ycombinator.com/item?id=39910493)

In today's top story on Hacker News, a new AI coach has been introduced to help users tackle boring or complicated tasks they've been avoiding. This tool aims to help individuals overcome task paralysis by providing personalized strategy recommendations. Users can engage with the AI coach through a frictionless chat experience, making it easier to get started on tasks. The coach is tailored to individual preferences and habits, offering a unique and personalized approach to task management. Interested users can join the Roadmap Community to stay updated on the latest features and subscribe for more information. Don't let procrastination hold you back - give this AI coach a try today and kickstart those tasks you've been putting off!

The discussion on the submission about the new AI coach on Hacker News includes several users expressing interest in trying out the tool to help with tasks they've been avoiding. Some users appreciate the low-effort solution that the AI provides for managing tasks more effectively. One user mentions giving it a try soon, while another user finds the idea of AI assisting in completing mundane tasks intriguing.

The conversation then shifts to a deeper discussion about the role of AI in simplifying and automating tasks, as well as the impact of advancing technology on the way we work. A user points out that the increasing prevalence of technology in our daily lives is leading to a rise in mindless tasks, highlighting the potential for AI to take over more intellectually demanding work. However, another user argues that relying too heavily on AI may lead society down a harmful path where people accept superficial interactions as the norm, rather than genuine human connections.

Further into the discussion, a user emphasizes the importance of technology serving a specific purpose rather than aimlessly progressing, suggesting that recorded history should guide the direction of technological development. This prompts a conversation about the significance of recording history to understand the purpose of humanity, focusing on the need to integrate technology with a human-centric approach to sustainable development.

Towards the end of the discussion, a user reflects on their experience with the AI chat interface, feeling that it lacked authenticity. The conversation touches on the potential of AI to transform relationships and communities through incremental steps towards greater mechanization in various industries.

### Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs

#### [Submission URL](https://allenai.github.io/lumos/) | 98 points | by [milliondreams](https://news.ycombinator.com/user?id=milliondreams) | [10 comments](https://news.ycombinator.com/item?id=39902130)

üöÄ The Allen Institute for AI and researchers from UCLA and the University of Washington have unveiled a groundbreaking project called Lumos, designed to revolutionize language agents. Lumos boasts a modular framework with planning, grounding, and execution modules that achieve impressive results even surpassing GPT-series agents on various tasks. With a focus on diverse training data and competitive performance, Lumos stands as a significant advancement for open-source LLM agents.

ü™Ñ The Lumos architecture comprises planning, grounding, and execution modules, enabling the agent to break down complex tasks, convert them into actionable steps, and interact effectively with external tools. Lumos offers two formulations, Lumos-Iterative and Lumos-Onetime, catering to different task requirements and environmental factors.

üí° Lumos leverages advanced training annotations converted from ground-truth reasoning steps, leading to superior performance on complex QA, web tasks, and mathematics challenges. The project's commitment to high-quality annotations and innovative training methodologies positions Lumos as a frontrunner in the development of sophisticated open-source agents.

üåü Through rigorous evaluation and comparison with baseline formulations, Lumos has demonstrated exceptional versatility and generalizability. Notably, Lumos shines when tasked with an unseen challenge like WebShop, showcasing its adaptability and outperforming larger agents with substantial margins.

üîç In-depth analysis of Lumos' annotation quality and format choices underscores the project's methodological soundness and the effectiveness of its high-level subgoals approach. The findings reaffirm the superiority of Lumos' training annotations and highlight the strategic advantage of adopting a modular, design-driven framework for training open-source language agents.

### Myscaledb: Open-source SQL vector database to build AI apps using SQL

#### [Submission URL](https://github.com/myscale/myscaledb) | 55 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [5 comments](https://news.ycombinator.com/item?id=39902271)

Today on Hacker News, a project called MyScaleDB caught the attention of many developers, boasting an open-source, high-performance SQL vector database built on ClickHouse. This database is designed to enable developers to create production-grade AI applications with familiar SQL, optimized for managing massive amounts of data efficiently. MyScaleDB offers benefits such as fully SQL compatibility, fast vector search capabilities, and production-ready features for AI applications.

What sets MyScaleDB apart is its unmatched performance and scalability, leveraging cutting-edge OLAP architecture and advanced vector algorithms. It allows for lightning-fast operations on large datasets and ensures high accuracy in search queries. Compared to other specialized vector databases, MyScaleDB is claimed to be more powerful, performant, and cost-effective while being simpler to use. The project is gaining popularity for its compatibility with ClickHouse, a renowned analytical database known for its speed in processing big data.

Developers can easily get started with MyScaleDB by using the MyScale Cloud service or running the Docker image provided. With detailed documentation and benchmarks available, MyScaleDB aims to offer a seamless experience for developers looking to build AI applications using SQL. This project is a promising addition to the tech community, providing a robust solution for managing and processing data effectively.

1. **mttsh** commented on MyScaleDB being a SQL vector database that returns correct results for SQL statements, especially those related to ORDER. They also recalled using 100% indices.
2. **bsl-rsh** replied with a breakdown of the various types of indices available, mentioning that the trade-offs between different types of indices are not explicitly stated. They also discussed the differences between single and index Per-Table Scan (PGVCTR), HNSW instance, and how some nuances may not matter much.
3. **nrjms** shared information on ClickHouse features and primary index types through informative links.
4. **lqhl** explained that MyScaleDB utilizes approximate nearest neighbors (ANN) algorithms like ScaNN and HNSW, achieving 100% recall rate depending on search parameters while considering embedding vectors representing less compressed original text messages. They also mentioned achieving 100% recall rate and wanting to understand the practical implications better
5. **J_Shelby_J** discussed a catalog of retrieval tools, mentioning the complexity involved with scaling databases and expressing interest in non-processed retrieval options. They brought up the idea of documenting databases regardless of retrieval methods.

Overall, the discussion delved into the technical aspects of MyScaleDB, focusing on its indexing capabilities, recall rates, and practical implications for AI applications. There were also discussions around database retrieval tools and the complexity of scaling databases.

### TestDriver

#### [Submission URL](https://testdriver.ai/) | 22 points | by [marksabanal1](https://news.ycombinator.com/user?id=marksabanal1) | [5 comments](https://news.ycombinator.com/item?id=39901709)

TestDriver AI QA Agent is revolutionizing testing on GitHub, promising swift and assured software deployment without the hassle of traditional testing methods. With TestDriver, developers can bid farewell to time-consuming automated tests and mundane manual testing, allowing them to focus more on coding. By tagging @testdriverai in pull requests or utilizing the GitHub action, TestDriver swiftly sets up a robust virtual machine, clones the code, and diligently follows instructions for testing. Debugging test runs is a breeze as developers observe their AI companion conduct end-to-end exploratory tests on their application, complete with screen views, logs, and decision-making processes, all powered by Dashcam.io. Through its user-friendly platform, TestDriver simplifies the testing process, offering developers the opportunity to boost productivity and code quality.

The discussion revolves around the TestDriver AI QA tool on GitHub. One user mentions that they are ready to test with TestDriver, while another points out that they haven't tried it yet and provides a link to the TestDriver repository on GitHub. A different user comments on their experience with testing, noting the different types of testing scenarios and the potential costs associated with using ephemeral VMs for testing. Another user simply expresses interest in the topic.
