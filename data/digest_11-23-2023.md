## AI Submissions for Thu Nov 23 2023 {{ 'date': '2023-11-23T17:10:59.410Z' }}

### Show HN: An AI-Generated Encyclopedia

#### [Submission URL](https://mycyclopedia.co/) | 20 points | by [mahouk](https://news.ycombinator.com/user?id=mahouk) | [16 comments](https://news.ycombinator.com/item?id=38392747)

Today, the top story on Hacker News is about an AI-generated encyclopedia. This fascinating project aims to create an encyclopedia that is completely generated by artificial intelligence. You might be curious about how advanced this encyclopedia is and what it means for the future of knowledge sharing. Well, let's dive into it!

For starters, the encyclopedia is generated using advanced AI models developed by IBM. These models are designed to mimic human language and knowledge, enabling them to generate coherent and informative articles on a wide range of topics. This means that the encyclopedia can cover everything from the World Wide Web to economies of scale.

But what's truly impressive is the AI's ability to generate articles that read like they were written by human experts. It can explain complex topics in a way that anyone, regardless of their expertise, can understand. So, whether you're a total newbie or an intermediate learner, this encyclopedia can provide valuable insights and explanations.

In terms of examples, imagine being able to search for a topic like "Satoshi Nakamoto," the mysterious creator of Bitcoin. The AI-generated encyclopedia would offer a comprehensive article that delves into Nakamoto's background, their contributions to the world of cryptocurrencies, and the ongoing speculation surrounding their true identity. It's like having an expert on hand to answer your questions!

Another example is searching for information on Aleppo. The encyclopedia would provide a detailed overview of the city's history, the humanitarian crisis that unfolded there, and the ongoing efforts to rebuild and heal the community. Again, this demonstrates the AI's ability to tackle complex and significant subjects.

Ultimately, this AI-generated encyclopedia represents a significant advancement in harnessing the power of AI for knowledge sharing. It has the potential to democratize access to information and provide valuable insights to people from all walks of life. So, get ready to explore the world's vast knowledge with the help of this impressive AI creation!

The discussion about the AI-generated encyclopedia on Hacker News covers a range of topics. Some users express sympathy for the initial commenters who apologize for not being able to respond because of a funeral service and a sudden surge in Netflix traffic. Others discuss the use of religious expressions and make suggestions for alternative phrases to express sympathy. One user points out the need to respect different religious beliefs and not to insult or judge someone's religion. Another user mentions trying out the encyclopedia website and finding interesting results, including strange descriptions and combinations of words. The OP thanks them and explains that the message retrieval and format matching still need improvement. They mention considering a conclusion-less format and express interest in finding AI-generated messages entertaining and informative. The discussion also briefly touches upon the comparison between the encyclopedia and Wikipedia, the user interface, and the use of synthetic data in AI models. Some users express concerns about the use of synthetic text and the lack of depth in the AI-generated encyclopedia, suggesting that a longer and more in-depth training set is needed to improve the quality of the articles.

### Experimental tree-based writing interface for GPT-3

#### [Submission URL](https://github.com/socketteer/loom) | 205 points | by [pyinstallwoes](https://news.ycombinator.com/user?id=pyinstallwoes) | [32 comments](https://news.ycombinator.com/item?id=38398563)

Socketteer/loom is an experimental tree-based writing interface for GPT-3 that aims to facilitate collaboration between humans and AI. This tool allows users to navigate and edit a tree structure of text, making it easier to organize and structure ideas. Users can also generate new text using GPT-3 and modify various generation settings. 

The interface includes features such as linear story view, tree navigation, expand and collapse nodes, bookmarks, chapters, and the ability to open/save trees as JSON files. It also offers a "block multiverse mode" that allows users to explore different branches of a text generation, facilitating a more interactive and iterative writing process.

To use in Loom, users can click on the Wavefunction button on the bottom bar, which opens the block multiverse interface in the right sidebar. From there, they can write an initial prompt in the main textbox, set the model and parameters, and propagate and plot the block multiverse. Users can zoom in on specific blocks, reset zoom levels, and clear the plot before generating a new block multiverse.

Loom also provides a range of hotkeys for easy navigation and toggling between different modes and displays. Users can open/save files, change chapters, modify generation settings, visualize the tree structure, and more, all with just a few keystrokes.

Overall, Loom offers a unique and powerful tool for writers and researchers looking to collaborate with AI models like GPT-3. Its tree-based structure and interactive features make it easier to organize and edit text, while the block multiverse mode allows for more dynamic and exploratory writing processes.

The discussion about the Loom submission on Hacker News covered a range of topics. 

- One user mentioned that Loom could be integrated with Obsidian, a note-taking app, to enhance its functionality. Others pointed out that using existing plugins instead of building from scratch would be more practical and improve the user experience.
- There was a discussion about the benefits of the block multiverse feature in Loom. Some users found it useful for exploring different branches of text generation, while others raised concerns about the complexity of managing multiple models and the trade-off between larger models and faster response times.
- A user questioned the practicality of using Loom in real-world contexts, stating that they struggled to understand the reading page and its practical use for creative writing or exploring the possibilities of generating text.
- The topic of limited context windows in text generation models like GPT-3 was raised. While some argued that limiting the context could result in forgetting events or starting new chapters, others pointed out that context windows could be as large as 16k tokens and that GPT-3 could handle longer-form text.
- The issue of privacy and sensitive data came up, with one user stating that they specify placeholder words to avoid sharing sensitive information. Another user mentioned that they don't have much programming experience and suggested creating a bookmarklet for easy access.
- Some users recommended similar tools like SimpleMind for organizing thoughts and Constrained Text Generation Studio for constraining language models' vocabulary.
- A user shared a link to a video that conceptually explains block multiverse interfaces.

Overall, the discussion provided insights into the practicality, limitations, and potential use cases of Loom and highlighted alternative tools and approaches for text generation and organization.

### After OpenAI's blowup, it seems pretty clear that 'AI safety' isn't a real thing

#### [Submission URL](https://gizmodo.com/ai-safety-openai-sam-altman-ouster-back-microsoft-1851038439) | 243 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [343 comments](https://news.ycombinator.com/item?id=38395655)

In a shocking turn of events, Sam Altman, the former CEO of OpenAI, was recently ousted by the company's board, only to be reinstated later with the backing of OpenAI's partner, Microsoft. The dramatic power struggle between Altman and the board is said to be rooted in a disagreement over the pace of technological development and the commercialization of AI. OpenAI's unique organizational structure, with a non-profit governing the for-profit company, seems to have contributed to the clash of interests between the pursuit of the public good and making money. Despite OpenAI's mission of responsible AI development and safety, it has become apparent that in the real world, ethics often take a backseat to financial considerations in Silicon Valley. This episode serves as a reminder that even organizations focused on AI safety may not have the necessary understanding or ability to effectively navigate the tech industry's power dynamics.

The discussion on this submission covers various topics related to AI safety and the development of AGI. Some users express concerns about the potential risks of AGI and the need for proper governance and ethical considerations. Others discuss the timeline for AGI development, pointing out the complexity and uncertainty involved. The conversation touches upon the role of corporations in AGI development, with some arguing for more oversight and regulation. Additionally, the discussion highlights the importance of addressing societal issues and ensuring the responsible and sustainable use of technology.

### About That OpenAI "Breakthrough"

#### [Submission URL](https://garymarcus.substack.com/p/about-that-openai-breakthrough) | 96 points | by [passwordoops](https://news.ycombinator.com/user?id=passwordoops) | [98 comments](https://news.ycombinator.com/item?id=38394816)

In a recent post on his newsletter, Gary Marcus shares his skepticism about OpenAI's recent "breakthrough" in AI technology. He refers to the development as Q*, a technique that OpenAI claims could change the world. Marcus acknowledges that breakthroughs in AI often fail to live up to initial expectations and highlights the example of driverless cars, where multiple breakthroughs are still needed to achieve reliable autonomous vehicles. He also recalls OpenAI's previous claim of solving a Rubik's Cube with a robot, which ultimately went nowhere. While Marcus admits that he doesn't know enough about the details of Q* to judge its potential, he remains focused on other pressing concerns in the AI field.

The discussion around the submission revolves around the skepticism expressed by Gary Marcus regarding OpenAI's recent AI breakthrough. Some users agree with Marcus and express their own doubts about the potential of OpenAI's technology, citing previous failed breakthroughs and the need for more incremental improvements. Others argue that Marcus tends to be overly negative and question his expertise in the field. The discussion touches on the capabilities of OpenAI's GPT models, the challenges of AI regulation, and the importance of understanding the arguments and evidence presented in the debate. Some users provide counterarguments to Marcus's skepticism and highlight the significant progress that OpenAI has made with their AI models. Overall, the discussion reflects the ongoing debate and varying opinions surrounding OpenAI's advancements in AI technology.

### A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks

#### [Submission URL](https://arxiv.org/abs/2102.04518) | 33 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [3 comments](https://news.ycombinator.com/item?id=38395959)

Researchers Forest Agostinelli, Alexander Shmakov, Stephen McAleer, Roy Fox, and Pierre Baldi have introduced a new search algorithm called Q* search, which uses deep Q-networks to efficiently solve problems with large action spaces. The algorithm takes advantage of the fact that the sum of the transition costs and heuristic values of a node's children can be computed with a single forward pass through a deep Q-network, eliminating the need to generate those children explicitly. This significantly reduces computation time and requires only one node to be generated per iteration. The researchers applied Q* search to solve the Rubik's Cube with a large action space and found that it incurred only a 4-fold increase in computation time and a 3-fold increase in the number of nodes generated compared to A* search. Additionally, Q* search was up to 129 times faster and generated up to 1288 times fewer nodes than A* search. The researchers also proved that Q* search is guaranteed to find a shortest path with an admissible heuristic function. The paper, titled "A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks," provides further details on their findings.

In the discussion, user "techbro92" expressed their opinion that they didn't find the paper interesting and didn't think it was relevant to the topic. User "lkd" responded with a somewhat sarcastic comment, implying that it might be related to an OpenAI paper. User "smspnc" speculated that the paper could be somewhat related to OpenAI, possibly concerning the algorithm and how people are trying to figure out how it works. User "techbro92" agreed with this speculation.

### Workers AI Update: Stable Diffusion, Code Llama and Workers AI in 100 Cities

#### [Submission URL](https://blog.cloudflare.com/workers-ai-update-stable-diffusion-code-llama-workers-ai-in-100-cities/) | 74 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [31 comments](https://news.ycombinator.com/item?id=38392824)

Cloudflare has announced that Stable Diffusion and Code Llama are now available as part of Workers AI in over 100 cities across its global network. Stable Diffusion is an image-generation model that can create images based on text input, while Code Llama is a language model optimized for generating programming code. Stable Diffusion XL 1.0 provides distinct images without imparting any particular feel, and it offers vibrant and accurate colors. Code Llama is built on top of Llama 2 and can generate code in popular languages like Python, Java, and JavaScript. Workers AI inference is now available in 100 cities, exceeding the company's target of supporting inference tasks near users. In addition, Cloudflare launched Mistral 7B, a powerful language model. Cloudflare will be offering developer workshops for those interested in getting started with AI.

The discussion on this submission covers various aspects of Cloudflare's new offerings, Stable Diffusion and Code Llama, as part of Workers AI. Some users express concerns about the pricing. One user mentions that it costs $0.01 per 1k neurons, but they are unsure about the measurements in terms of dollar costs per 1k tokens. Another user comments that the generation of images with Stable Diffusion is relatively slow, taking around 15 seconds, but it could potentially start to replicate faster. They also mention specific resolutions and sampling options. A user points out that the benefit of running the models is the additional latency it adds to the requests, which is negligible compared to the latency of large language models like LLMs. Another user adds that low latency is crucial for voice recognition tasks. 

Someone suggests that integrating Replicate SDXL into Cloudflare Workers directly would be beneficial. Another user notes that Cloudflare's Mistral 7B language model is powerful. They also mention that Cloudflare will offer developer workshops for those interested in getting started with AI. 

There is a discussion about how to get started with Workers AI and Stable Diffusion XL via API. One user shares a command-line code for getting started, but another user points out that there seems to be an issue with the Cloudflare dashboard and they have not received any results. Suggestions are made to check the Cloudflare dashboard or use specific URLs for registration.

The pricing of Cloudflare's offerings is a topic of discussion. One user mentions that OpenAI's pricing is cheaper, while another user finds Cloudflare's pricing difficult to calculate. Another user shares the pricing details they found on the Workers AI page. Someone also suggests using serverless functions instead.

Some users express genuine curiosity and interest in understanding the capabilities and use cases of AI-powered coding assistants. One user mentions using the LLM API to generate pre- and post-processed custom code runtimes. Another user mentions the possibility of injecting malicious code. Another user mentions that Cloudflare does not provide a comprehensive list of available models, but suggests checking Hugging Face for more options.

The discussion also briefly touches on inference times for generating images, with one user mentioning that it takes around 16-17 seconds.

### The first Spanish AI model earning up to €10k per month

#### [Submission URL](https://www.euronews.com/next/2023/11/22/meet-the-first-spanish-ai-model-earning-up-to-10000-per-month) | 68 points | by [belter](https://news.ycombinator.com/user?id=belter) | [30 comments](https://news.ycombinator.com/item?id=38397404)

A Spanish agency called The Clueless has created Aitana, the first Spanish model designed using artificial intelligence (AI). Aitana is an exuberant 25-year-old pink-haired woman from Barcelona whose physical appearance is close to perfection. She has gained over 121,000 followers on Instagram in just a few months and receives private messages from celebrities who are unaware that she is not a real person. Aitana can earn up to €10,000 per month, and her income comes from advertising campaigns and endorsing brands. The agency has also created a second virtual model called Maia. The agency believes that creating virtual models could help bring down market prices and give a boost to small companies that cannot afford big advertising campaigns, but the initiative is not without its critics who argue that the unrealistic perfection and sexualized image of the models could negatively influence young people.

The discussion on Hacker News regarding the creation of a virtual model named Aitana by The Clueless agency revolves around various topics. 

One user points out that AI models could potentially disrupt the influencer system on platforms like Instagram and shift consumer behavior towards trusting verified persons, institutions, and organizations. Another user argues that influencers are human, and their credibility and interest come from the human connection and the end-to-end experience that they provide.
There is also discussion about the potential negative impact of virtual models on young people, as their unrealistic perfection and sexualized image may have a detrimental effect. One user mentions that comparing oneself to AI-generated models can be harmful, similar to how comparing oneself to genetically gifted lottery winners or edited magazine models can be damaging.
The income potential of virtual models is also discussed, with one user sharing that Aitana can earn up to €10,000 per month through advertising campaigns and brand endorsements. However, some users express concerns about the pricing and affordability of such models.
The dominance of AI-generated content on platforms like Instagram is also a point of discussion. One user mentions that AI could eventually dominate the online space, but others raise concerns about the authenticity of AI-generated content and the potential problems it may cause.
The topic takes a turn towards the criticism of the idealized portrayal of AI models, with one user noting that it perpetuates unrealistic beauty standards. The discussion expands to include the portrayal of models in magazines, the use of airbrushing, and the negative impact it can have on self-image.
There are also comments about the liberating aspect of AI models, as it allows people to realize and accept the artificial nature of modern life and reject meaningless consumerism. Some users find it liberating, while others refer to it as a glitch in the matrix.

Overall, the discussion explores the potential implications of virtual models created using AI, including impacts on the influencer industry, the influence on young people, the income potential, the dominance of AI-generated content, and the criticism of idealized portrayals.
