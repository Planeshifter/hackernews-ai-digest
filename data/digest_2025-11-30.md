## AI Submissions for Sun Nov 30 2025 {{ 'date': '2025-11-30T17:11:30.121Z' }}

### Writing a good Claude.md

#### [Submission URL](https://www.humanlayer.dev/blog/writing-a-good-claude-md) | 656 points | by [objcts](https://news.ycombinator.com/user?id=objcts) | [252 comments](https://news.ycombinator.com/item?id=46098838)

HN: How to write a useful CLAUDE.md (and why your agent keeps ignoring it)

- Core idea: LLMs are (mostly) stateless—your agent knows nothing about your codebase unless you put it in the prompt. In Claude Code–style setups, CLAUDE.md (or AGENTS.md) is the one file that’s injected into every session, so it’s your default onboarding doc.

- What CLAUDE.md should do: onboard the agent each session.
  - WHAT: map the tech stack, project structure, and monorepo layout (apps, shared packages, where things live).
  - WHY: explain the project’s purpose and the roles of each part.
  - HOW: explain how to work in the repo—tooling choices (e.g., bun vs node), how to run tests/typechecks/builds, and how to validate changes.

- Why Claude often ignores CLAUDE.md: the harness injects a reminder telling the model to use it only if “highly relevant.” If your file is stuffed with broad or situational instructions, the model is more likely to discard it. You can verify this by proxying the API via ANTHROPIC_BASE_URL and inspecting the injected system reminder.

- Less is more: keep instructions short, universal, and essential.
  - Models can only juggle a limited number of instructions reliably (~150–200 for large “thinking” models; much fewer for smaller/non-thinking models).
  - As instruction count increases, adherence drops across the board; smaller models degrade much faster (often exponentially).
  - The harness system prompt already burns ~50 instructions, shrinking your reliable budget.

- Placement matters: LLMs bias toward the edges of the prompt (the very beginning—system + CLAUDE.md—and the very end—latest user messages). Put truly universal rules up front; put task-specific guidance at the end of your prompt.

- Practical implications:
  - Don’t cram every command, style guide, or “hotfix” into CLAUDE.md.
  - Use CLAUDE.md for stable, evergreen orientation; provide task-specific commands/examples inline with the current request.
  - Prefer concrete, relevant context (examples, related files, tool outputs) over sprawling instruction lists.
  - For multi-step or complex plans, use larger “thinking” models; smaller models will struggle.

- Why it likely works this way: many teams use CLAUDE.md to patch behavior with ad hoc rules. Telling the model to ignore low-relevance instructions generally improves outcomes.

Bottom line: Treat CLAUDE.md as a tight, universal onboarding sheet that maps the repo and workflow. Keep it lean to preserve the model’s instruction budget and to make room for focused, task-specific context in each session.

Here is a summary of the discussion:

**The "Brown M&Ms" Compliance Test**
A significant portion of the discussion focused on how to verify if the model is actually respecting the `CLAUDE.md` file. One user shared an anecdote about instructing Claude to address them as "Mr. Tinkleberry"; if the model stops using the name, the user knows the context has been dropped or the file is being ignored.
- Commenters immediately drew a parallel between this technique and Van Halen’s famous "Brown M&Ms" contract rider, noting it is an effective canary for checking if the AI is paying attention to technical constraints.
- Other variations suggested included requiring specific start/end emojis or sign-offs (e.g., "Purple fish") to verify instruction adherence.

**Granularity: Monolith vs. Distributed Context**
Users debated the structure of onboarding files. While the article suggests a single file, several commenters argued for placing multiple `CLAUDE.md` files in specific subdirectories (e.g., `src/persistence/CLAUDE.md` or `tests/CLAUDE.md`).
- Proponents argued this allows the model to pull in highly specific context only when working in those directories, preventing the "one big file" from being ignored due to length.
- Critics felt this approach creates "directory clutter" and forces developers to manage multiple non-portable configuration files, arguing that standard `README.md` files should suffice if the AI were smarter.

**Tooling Comparisons (Cursor, Aider, Skills)**
The discussion compared Claude's implementation to other tools.
- **Cursor:** Some users noted that Cursor handles file/subdirectory context more naturally without needing a "giant blob" of instructions.
- **Aider:** Mentions were made of Aider’s "chat map" approach to context.
- **Claude Skills:** There was confusion and debate regarding the new "Skills" feature versus `CLAUDE.md`. Some users found that while Skills are good for dynamic actions (like converting files), `CLAUDE.md` is better for persistent, "evergreen" project orientation.

**Engineering vs. "Magic"**
A philosophical sub-thread emerged regarding the effort required to make LLMs effective. Skeptics addressed the irony of needing extensive configuration files to make "intelligent" tools work, questioning the promised productivity gains. Counter-arguments stated that "magic" is a marketing term; real productivity enhancement is an engineering discipline (likened to learning Vim or Emacs) that requires setup, process planning, and learning how to prompt the tool effectively.

### AI just proved Erdos Problem #124

#### [Submission URL](https://www.erdosproblems.com/forum/thread/124#post-1892) | 224 points | by [nl](https://news.ycombinator.com/user?id=nl) | [78 comments](https://news.ycombinator.com/item?id=46094037)

AI-and-Lean settle an Erdős problem (the “with 1s allowed” version); stronger variant still open

What’s the problem?
- For bases d1 < d2 < … < dr (each ≥ 3), let P(d, k) be the set of sums of distinct powers d^i with i ≥ k. A classical question asks: if sum_i 1/(d_i − 1) ≥ 1, can every sufficiently large integer be written as a 0/1-sum of elements from the union of these P(d_i, k)?
- There are two variants:
  - k = 0 (allow the 1 = d^0 term). This is how Erdős phrased it in 1997 (no gcd condition).
  - k ≥ 1 (exclude the 1’s place). Burr–Erdős–Graham–Li (1996) studied this version; here a gcd(d1,…,dr) = 1 condition is clearly necessary.

What’s new?
- “Aristotle” (an automated prover from Harmonic) found a simple, elementary solution to the k = 0 version under the Pomerance/Tao necessity condition sum_i 1/(d_i − 1) ≥ 1. Boris Alexeev then formalized and type-checked it in Lean.
- Stronger than asked: the Lean theorem shows every integer n (not just “sufficiently large”) can be expressed as a sum of at most r numbers, one per base, where each summand has only digits 0/1 in its respective base (i.e., lies in P(d_i, 0)).
- Timing: Aristotle needed ~6 hours to find the proof; Lean verified it in about a minute.

Why the nuance matters
- Literature mismatch: BEGL96 disallowed the 1’s place (k ≥ 1) and thus requires a gcd condition; Erdős’s 1997 formulation allowed 1’s and stated no gcd condition. The new proof resolves the Erdős-1997 version. The BEGL96-style version (k ≥ 1, gcd = 1) remains open in general (known for {3,4,7}).
- Necessity of sum_i 1/(d_i − 1) ≥ 1: Observed by Pomerance; Tao sketched a justification in the comments (think Kraft-type/density obstructions).
- Related: Melfi constructed infinite families showing you can get “completeness” with ∑ 1/(d_i − 1) arbitrarily small in a different, infinite-base setting.

State of play
- First (with-1s) version: now has a short, formally verified proof.
- Second (no-1s, gcd = 1) version: still open, aside from specific base sets.

Link: https://www.erdosproblems.com/124

Here is the summary of the discussion.

**The "Moving Goalposts" Debate**
A significant portion of the discussion focused on whether dismissing the achievement as an "easy" problem constitutes moving the goalposts for AI.
*   **The Pro-AI View:** Users argued that ten years ago, an AI solving an open Erdős problem—and formally verifying it—would have been considered science fiction. Minimizing the result because the math turned out to be "Olympic level" rather than "deep research level" is seen by some as a defense mechanism to downplay AI progress.
*   **The Skeptical View:** Critics countered that the skepticism isn't about moving goalposts, but addressing specific, potentially misleading hype from the company (Harmonic). They argue that the problem was less a "grand mystery" and more a "forgotten loophole" or typo in Erdős's papers that humans simply hadn't prioritized.

**"Low-Hanging Fruit" and Systematic Solutions**
Technically minded commenters (referencing Terence Tao and Boris Alexeev) clarified the nature of the solution:
*   **The "Typo" Theory:** The consensus is that the specific variant solved (the "with 1s" version) was likely left open due to a clerical oversight or phrasing mismatch in historical literature, making it "low-hanging fruit" rather than a deep mathematical blockade.
*   **The Value of the Bucket:** Despite the problem being "easy" in hindsight, users noted the value in having an AI capable of iterating through a "large bucket" of neglected or clearly solvable open problems. This demonstrated a strength in checking overlooked corners of mathematics, even if it doesn't yet demonstrate deep "understanding."

**VC Hype vs. Technical Progress**
There proved to be a strong undercurrent of cynicism regarding the commercial framing of the announcement.
*   Several users compared the announcement to the crypto boom, suggesting that VC-backed startups are incentivized to produce "breathless claims" to attract investment.
*   This creates a "boy who cried wolf" effect, where legitimate technical advances are viewed with suspicion because the marketing ("Aristotle," "solving Erdős problems") feels designed for viral engagement rather than scientific precision.

**Miscellaneous**
*   **Confusion:** A few users expressed temporary confusion, thinking the post meant the ancient philosopher Aristotle had solved the problem thousands of years ago.
*   **Future Utility:** Speculation arose that this type of AI—able to verify combinatorial complexity—will be more useful in fields like materials science and biology (finding patterns) than in abstract mathematics, which prioritizes understanding over raw solutions.

### Program-of-Thought Prompting Outperforms Chain-of-Thought by 15% (2022)

#### [Submission URL](https://arxiv.org/abs/2211.12588) | 128 points | by [mkagenius](https://news.ycombinator.com/user?id=mkagenius) | [33 comments](https://news.ycombinator.com/item?id=46099108)

- The idea: Instead of having a language model both “think” and compute in natural language (Chain-of-Thought), Program-of-Thoughts (PoT) has the model express its reasoning as short programs (mainly Python). An external interpreter executes the code to get the final answer. This cleanly separates planning from calculation.

- How it works: Provide few-shot examples where each problem is paired with a small program that solves it. The model (Codex in the paper) generates a program for a new problem; a sandbox runs it to produce the answer. With self-consistency, they sample multiple programs and aggregate the outputs.

- Results: Across five math word-problem datasets (GSM8K, AQuA, SVAMP, TabMWP, MultiArith) and three financial QA sets (FinQA, ConvFinQA, TAT-QA), PoT beats Chain-of-Thought by about 12% on average in both zero- and few-shot settings. With self-consistency, it achieves state-of-the-art on all the math sets and near-SOTA on the financial ones.

- Why it matters: Precise computation reduces arithmetic hallucinations, the generated code is auditable and debuggable, and the approach plugs neatly into the broader “LLMs + tools” pattern that’s powering more reliable agents.

- Caveats: Requires a code-capable model and a secure execution sandbox; brittle if the generated program is logically wrong or depends on unavailable libraries; not every reasoning task is easily expressible as code.

- Status: Published at TMLR 2023. Code and data are available on GitHub (linked from the paper).

Here is a summary of the discussion:

The discussion around "Program of Thoughts" (PoT) expanded beyond simple Python execution into a debate about the best intermediate representations for AI reasoning.

*   **"Chain of Spec" vs. Code:** User `rbt-wrnglr` argued that jumping from fuzzy natural language directly to concrete code skips necessary logic layers, potentially wasting tokens on implementation bugs rather than intent. They (and others) proposed a "Chain-of-Spec" approach—using semi-formal representations like Markdown bullet lists, TLA+, or Alloy—to verify logic *before* generating executable code.
*   **Prior Art and Tooling:** Commenters noted that this concept isn't entirely new, citing similarities to **PAL** (Program-Aided Language Models) and **DSPy**, which has supported similar "program of thought" workflows for some time. Others pointed out that modern implementations (like Claude’s artifacts or ChatGPTs Code Interpreter) effectively internalize this behaviors already.
*   **Alternative Languages:** While the paper focuses on Python, several users discussed the benefits of using logic programming languages like **Prolog** or logical specifications (TLA+) as the intermediate step. These languages force stricter reasoning and are easier to verify than imperative Python scripts.
*   **Skepticism and Security:** There was some pushback on the "natural language programming" paradigm, with one user calling it delusional. Others raised concerns about the security infrastructure required to run arbitrary generated code ("self-destructive prompting" if the sandbox is unsafe).
*   **Neuro-Symbolic Future:** The thread ultimately converged on the value of hybrid systems (LLMs + Symbolic Logic), suggesting that the industry has a vested interest in keeping these intermediate "thinking" languages obscure to maintain a competitive moat.

### AI rendering of Roman war scenes from Trajan's Column

#### [Submission URL](https://trajancolumn.com) | 25 points | by [unix-junkie](https://news.ycombinator.com/user?id=unix-junkie) | [3 comments](https://news.ycombinator.com/item?id=46099838)

Scroll to Rotate, Click to Zoom (Swipe/Tap on mobile) proposes a simple, consistent interaction model for 3D/product viewers: use the scroll wheel or a swipe to rotate the object, and a click or tap to enter/exit zoom. The goal is to avoid the common pitfalls of scroll-to-zoom (accidental zoom, hijacking page scroll) and make zoom a deliberate mode switch.

Why it matters
- Reduces accidental zooming and “scroll-jacking” that fights the page’s natural scroll.
- Gives desktop and mobile the same mental model: rotate as the default, zoom as an explicit action.
- Improves clarity: zoom becomes a state the user opts into, rather than a fragile continuous gesture.

Key ideas
- Default interaction rotates the object: scroll on desktop, swipe on mobile.
- Zoom is a discrete toggle: click/tap to zoom in/out or enter/exit a zoom mode.
- Provide clear affordances: on-hover/tooltips or subtle UI hints that say “Scroll/Swipe to rotate, Click/Tap to zoom.”
- Respect the page: don’t capture scroll outside the viewer bounds; release scroll when the cursor leaves.
- Accessibility: add keyboard shortcuts (e.g., arrows to rotate, Enter/Space to zoom) and maintain focus states.

Trade-offs and discussion points
- Discoverability vs. convention: many users expect click-and-drag to rotate or scroll-to-zoom; hints and gentle onboarding help.
- Trackpads and pinch: consider supporting two-finger pinch for zoom as a secondary gesture without making it the default.
- Precision: scroll-to-rotate can feel “steppy” on mice; add easing/inertia and sensible sensitivity.
- Nested scrolling/iframed embeds: ensure the viewer doesn’t trap scroll when not intended.

If you build 3D/product viewers, this pattern is a strong default: make rotation effortless and zoom intentional, keep it consistent across devices, and gently teach the controls.

**Scroll to Rotate, Click to Zoom (Swipe/Tap on mobile)**
This submission proposes a consistent interaction model for 3D product viewers to solve "scroll-jacking." The pattern uses the scroll wheel (or swipe) to rotate objects and requires a deliberate click (or tap) to enter a zoom mode, aiming to tackle accidental zooming while respecting the page's natural scroll flow.

**Discussion Summary**
The discussion was brief and primarily focused on the visual assets used in the demo rather than the interaction pattern itself.

*   **Implementation vs. Assets:** While `cnstnts` acknowledged that the technical implementation of the viewer deserved praise, they pointed out that the visual assets appeared to be low-effort AI generations or slight modifications of existing images.
*   **Visual Quality:** `alexalx666` criticized the quality of the imagery, comparing it negatively to early iPhone photos.
*   **AI Usage:** There was a brief mention regarding the use of AI in bringing the content to life, though the sentiment appeared mixed regarding the quality of the output.

