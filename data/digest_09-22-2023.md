## AI Submissions for Fri Sep 22 2023 {{ 'date': '2023-09-22T17:09:23.061Z' }}

### I made a transformer to predict a simple sequence manually

#### [Submission URL](https://vgel.me/posts/handmade-transformer/) | 329 points | by [lukastyrychtr](https://news.ycombinator.com/user?id=lukastyrychtr) | [84 comments](https://news.ycombinator.com/item?id=37609393)

In a blog post on September 11, 2023, the author shares their experience of building a transformer from scratch without training it. They wanted to gain a deeper understanding of transformers and attention, so they decided to manually assign each weight for a decoder-only transformer inspired by GPT-2.

The author starts by picking a task that is not too easy but also not too challenging. They settle on predicting a sequence of "aabaabaabaab...," which requires querying the previous two tokens to determine the next token. To simplify the problem, they use a tokenization scheme where "a" is represented by 0 and "b" by 1.

Next, the author designs the model based on jaymody's picoGPT implementation of GPT-2. They define functions for softmax, linear transformations, and attention calculations. The attention function takes in query (q), key (k), and value (v) matrices, and a mask, and returns the attention weights. The causal_self_attention function applies causal masking to hide future inputs and performs the attention calculation. The transformer_block function is then used to add the output of the attention calculation to the input.

Finally, the author mentions that they have implemented the necessary functions up to this point and will continue explaining the remaining parts in the next blog post.

This hands-on approach to building a transformer without relying on pretrained weights or training provides the author with a better understanding of transformers and attention. It also serves as a valuable resource for readers interested in delving into the inner workings of transformers.

The discussion on the Hacker News submission revolves around various aspects of the blog post that describes building a transformer from scratch without training it. Here are some notable points from the discussion:

- One user shares a link to a blog post about Thinking Transformers, which explores using a primitive programming language called RASP to simulate the components of a transformer model.
- Others express interest in the hands-on approach and recommend following the work demonstrated by the author.
- One user notes that they initially struggled to understand transformers when they implemented them from scratch without pretraining. Their experience was different from the standard PyTorch transformer implementation, and they realized that training and backpropagation were not as straightforward as expected.
- Another user shares a link to a video by Andrej Karpathy discussing building a Neural Network from scratch, which they find relevant to the topic.
- The challenge of working with weights in models and the interpretability of specific clusters of neurons are discussed.
- The discussion delves into the idea of compressing machine learning models and the potential for more efficient and controllable interfaces.
- Some users highlight the difficulty of manually adjusting weights and the downstream effects of modifying weights in transformers.
- The attention mechanisms present in transformers are discussed, and it is noted that they do not necessarily represent semantics understandable to humans.
- The complexity and interpretability of weights in transformers are compared to the Traveling Salesman Problem, and the limitations of solving certain problems with transformers are mentioned.
- One user points out that neural networks are Turing machines and that the weights represent approximations of the computation process.

Overall, the discussion appreciates the hands-on approach of building a transformer from scratch and dives into various technical aspects and implications of the topic.

### Outperforming larger language models with less training data and smaller models

#### [Submission URL](https://blog.research.google/2023/09/distilling-step-by-step-outperforming.html) | 309 points | by [atg_abhishek](https://news.ycombinator.com/user?id=atg_abhishek) | [118 comments](https://news.ycombinator.com/item?id=37606352)

A team of researchers from Google's Cloud AI team has developed a new mechanism called "distilling step-by-step" that allows smaller task-specific models to outperform larger language models (LLMs) with less training data. LLMs, such as BERT and T5, have revolutionized the field of natural language processing but tend to be computationally expensive and require large amounts of data. The researchers found that by extracting informative natural language rationales from LLMs, they could train smaller models more efficiently. These rationales, which explain the connections between input questions and their corresponding outputs, provide additional supervision during training. The team demonstrated that a 770M parameter T5 model could outperform a 540B parameter PaLM model using only 80% of the examples in a benchmark dataset. This approach offers a potential solution for deploying high-performance natural language models in applications with limited computational resources.

The discussion on this submission revolves around the use of smaller task-specific models versus larger language models (LLMs) in natural language processing. Some users argue that using multiple smaller models instead of a single large model can be more effective in certain applications. Others point out the potential limitations of this approach and discuss different techniques for training smaller models. Some users also share related papers and resources on the subject. There is a debate about the effectiveness of curriculum training and the need for comprehensive training data for LLMs. The discussion also touches on the relevance of text generation and the importance of high-quality training data. Finally, there are conversations regarding the similarities and differences between LLMs and human intelligence, as well as the need for specialized resources like textbooks in natural language processing.

### GraalOS: Containerless instant-on cloud functions for Java

#### [Submission URL](https://www.graal.cloud/graalos/) | 97 points | by [mike_hearn](https://news.ycombinator.com/user?id=mike_hearn) | [27 comments](https://news.ycombinator.com/item?id=37610654)

Oracle has introduced GraalOS, a high-performance serverless application deployment platform that leverages GraalVM Native image technology. This innovative solution enables applications to run as native machine executables, harnessing the latest processor features of x64 and AArch64. GraalOS boasts impressive features such as fast startup times, low latency, reduced memory footprint, on-demand suspension and resumption of applications, and cloud-native support for both stateful and stateless services and functions. By taking advantage of hardware-enforced application isolation without relying on containerization, GraalOS pushes the boundaries of application deployment.

The discussion around Oracle's GraalOS on Hacker News primarily focused on understanding the technology and its implications. Some users expressed disappointment in the lack of information provided by Oracle, while others questioned the need for GraalOS when existing solutions like Docker and EKS already exist. There were also discussions about the benefits of GraalOS and its potential use cases, such as serverless computing, protecting shared libraries, and running legacy applications. Additionally, there were some comments about Oracle's Java-related technologies and copyright notice. Some users also mentioned similar concepts, such as V8 and Cloudflare Workers. Overall, the discussion was a mix of technical analyses and opinions on the usefulness of GraalOS.

### Provably safe systems: the only path to controllable AGI

#### [Submission URL](https://arxiv.org/abs/2309.01933) | 44 points | by [antonkar](https://news.ycombinator.com/user?id=antonkar) | [56 comments](https://news.ycombinator.com/item?id=37619285)

Researchers from MIT and Beneficial AI Research have published a paper titled "Provably safe systems: the only path to controllable AGI" in the arXiv preprint repository. The paper outlines a path to ensuring that powerful Artificial General Intelligences (AGIs) can be built to satisfy human-specified requirements and operate safely. The authors argue that this is the only way to guarantee safe and controlled AGI development. They propose using advanced AI techniques for formal verification and mechanistic interpretability to achieve this goal. The paper also puts forward a list of challenge problems that would contribute to the development of provably safe systems. Interested readers are invited to join in this work.

The discussion on the Hacker News thread revolves around the challenges and limitations of formal methods in ensuring the safety and control of AGI development.

One user points out that formal methods have historically been used for verifying critical systems, but applying them to AI poses additional difficulties due to the complexity and multi-valued nature of AI systems. Another user suggests that fixing the current limitations of formal methods, such as improving level stacking and encryption, could lead to better control of AGI development.

The conversation then shifts to the regulation of AI, with one user remarking that regulating AI is similar to regulating corporations and that it may be slower due to internal data transfer issues. Another user adds that regulating AI is also challenging because it involves managing unpredictable and potentially dangerous scenarios.

The discussion continues with users debating the differences between humans and AI, highlighting the lack of consciousness in AI and the potential for AGI to prevent psychopathy. Another user points out that formal methods have made significant progress in the past two decades, and their application to AI could lead to improvements in safety and security.

One user mentions that LLMs (large language models) are revolutionizing programming, but their impact on traditional software development remains uncertain. They express skepticism about the effectiveness of formal methods and suggest that AI programming may require a different approach.

In response, another user discusses the potential of using formal methods to improve safety and security in shipping products, citing examples in Java, C++, Ada, and other languages. They also mention the existence of projects like seL4, which demonstrate the ability of formal methods to improve safety and security in real-world applications.

The discussion concludes with a user expressing skepticism about the capabilities of formal methods, stating that they haven't seen much progress in the software industry in the past 20 years. They suggest that LLMs may replace traditional programming altogether but acknowledge the importance of continuous advancements in the field of formal methods.

Overall, the discussion highlights the complexity and challenges involved in ensuring the safety and control of AGI development and the potential of formal methods in addressing these concerns.

### Show HN: Movie Guess – A AI movie title guessing game

#### [Submission URL](https://www.movieguess.com) | 5 points | by [gustavomaestri](https://news.ycombinator.com/user?id=gustavomaestri) | [15 comments](https://news.ycombinator.com/item?id=37617961)

Title: "Scientists Discover New Method to Generate Renewable Energy from Plant Waste"

Summary: 
In a groundbreaking scientific breakthrough, researchers have unveiled a novel technique that efficiently transforms plant waste into renewable energy. This discovery promises a significant step towards sustainable energy production, offering a potential solution to the world's growing energy demands while reducing reliance on fossil fuels.

The method, developed by a team of scientists at a leading university, involves utilizing a combination of advanced chemistry and microbial processes. By breaking down plant waste materials such as agricultural leftovers or even discarded wood, this innovative process releases energy-rich substances that can be harnessed to generate electricity or produce biofuels.

What sets this approach apart is its ability to convert a wide range of plant waste varieties, making it highly versatile and adaptable. This could be a game-changer for areas that struggle with access to traditional energy sources, as it allows them to make use of locally available resources.

Moreover, the sustainability aspect of this breakthrough is truly commendable, as it lessens the environmental impact associated with waste disposal, while simultaneously promoting a greener energy landscape. By reducing dependence on conventional power generation methods, this new technique can significantly contribute to mitigating climate change and curbing greenhouse gas emissions.

The research team believes that their innovation holds enormous potential and envisions a future where plant waste can act as a reliable and clean energy source. While there is still work to be done before widespread implementation, this breakthrough marks a significant milestone in the pursuit of sustainable energy solutions.

Whether it's maximizing the energy potential from agricultural byproducts or finding new ways to utilize discarded wood, this remarkable breakthrough shows that nature's leftovers could hold the key to a more sustainable and eco-friendly future.

The discussion surrounding the submission seems to be unrelated to the topic. It involves some confusion and misunderstanding among the users. One user mentions that they find the original message confusing, and another user apologizes for the issue and states that it's fixed. There's also a conversation about guessing a movie, where some users congratulate each other, and one user mentions that they misunderstood the previous user's message from 1995. Another user suggests using a shared screen or board for guessing. Overall, the discussion does not provide any additional insights or information related to the submission's topic.

### AI-focused tech firms locked in ‘race to the bottom’, warns MIT professor

#### [Submission URL](https://www.theguardian.com/technology/2023/sep/21/ai-focused-tech-firms-locked-race-bottom-warns-mit-professor-max-tegmark) | 12 points | by [pg_1234](https://news.ycombinator.com/user?id=pg_1234) | [4 comments](https://news.ycombinator.com/item?id=37618807)

MIT physicist Max Tegmark has warned that AI-focused tech firms are engaged in a "race to the bottom" and are unwilling to pause development to consider the risks associated with artificial intelligence. Tegmark co-authored an open letter in March calling for a six-month pause in the development of advanced AI systems. The letter failed to secure a pause, but Tegmark believes it has had a significant impact in raising awareness about AI risks. He highlighted the growing interest from politicians and the convening of a global summit on AI safety by the UK government in November as evidence of the changes in attitude. Tegmark stressed the need for safety standards and government intervention in AI development.

The discussion on this submission revolves around the risks associated with the development of advanced AI systems. 

One commenter argues that if civilization had control over its own development, it wouldn't surrender that control to AI. The problem, they believe, lies in people's reliance on AI technology, which is gradually replacing human tasks on a large scale. This commenter suggests that AI is being managed by a single entity rather than being collectively controlled, which raises concerns about individual influence over society.

Another commenter argues that people are not trying to stop the development of AI; instead, they are attempting to regulate and ensure responsible advancements. However, a third commenter disagrees with this point, asserting that it is challenging to regulate AI since it has the potential to interfere with the ability to control civilization itself.

Ultimately, the discussion highlights differing opinions on the extent to which AI development should be controlled and regulated.

