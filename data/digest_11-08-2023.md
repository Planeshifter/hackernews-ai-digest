## AI Submissions for Wed Nov 08 2023 {{ 'date': '2023-11-08T17:13:12.402Z' }}

### Home Assistant blocked from integrating with Garage Door opener API

#### [Submission URL](https://www.home-assistant.io/blog/2023/11/06/removal-of-myq-integration/) | 1097 points | by [eamonnsullivan](https://news.ycombinator.com/user?id=eamonnsullivan) | [589 comments](https://news.ycombinator.com/item?id=38188162)

The popular smart home integration, MyQ, will be removed from Home Assistant in the upcoming December release. Chamberlain Group, the owners of MyQ, have made the decision to block access to third-party apps, causing constant repair issues for Home Assistant users. The decision to block unauthorized usage aims to provide a better experience for their 10 million+ users and authorized partners. Despite attempts to reach an understanding with Chamberlain Group, Home Assistant has not received an official response. As an open-source project, Home Assistant cannot pay a partnership fee and believes users should have the freedom to access their devices and data without additional charges. Home Assistant maintainer, Lash-L, expressed disappointment and urged users not to support companies with customer-hostile practices. While the MyQ integration will be removed, Home Assistant recommends using ratgdo, a local solution that can be installed on existing MyQ systems. Home Assistant hopes Chamberlain Group will reconsider its position and work together in the future.

The discussion on the submission revolves around different experiences with package deliveries and the security measures in place in various countries. Some users share their experiences of packages being left unattended or delivered to neighbors, while others discuss the use of lockers and how they can be implemented in different environments. There are also discussions about the effectiveness of security measures like Amazon Lockers and the potential challenges in implementing smaller lockers for individual homes. Additionally, the use of doorbell cameras and the potential deterrent effect they may have on package theft is mentioned. Overall, the discussion highlights the various factors that contribute to the security of package deliveries and the different approaches taken in different countries.

### Major outages across ChatGPT and API

#### [Submission URL](https://status.openai.com/incidents/00fpy0yxrx1q) | 514 points | by [d99kris](https://news.ycombinator.com/user?id=d99kris) | [530 comments](https://news.ycombinator.com/item?id=38190401)

In a major outage that occurred between 5:42 AM and 7:16 AM PT, there were errors impacting all services of OpenAI's ChatGPT and API. OpenAI quickly identified the problem and implemented a fix, resulting in normal responses from their services. However, they continued to monitor the situation as a precautionary measure. The incident report posted by OpenAI on November 8, 2023, at 7:46 PST stated that they had resolved the issue. The initial update at 6:49 PST mentioned that they were seeing high error rates and actively investigating the possible causes. OpenAI kept users informed about the progress of the investigation through subsequent updates. This incident affected both the API and ChatGPT services.

The discussion on this submission revolves around various topics related to Google Bard, OpenAI's ChatGPT, and the reliability and limitations of AI-generated responses. Here are some key points from the discussion:

1. Users express their experiences and opinions on different AI models and their capabilities, such as Google Bard and ChatGPT.
2. There is a discussion about the reliability of AI models, with some users mentioning that they have encountered instances where the models return incorrect or misleading information.
3. The topic of Google Lens and its functionality is brought up, with some users sharing positive experiences with the tool.
4. Some users raise concerns about the ChatGPT's reliability and the potential for it to provide false or misleading information.
5. The Gell-Mann Amnesia Effect is mentioned, highlighting how people tend to believe AI-generated responses even when they might not be accurate.
6. There is a conversation about the training data and sources used for AI models, and the limitations and biases that can result from such data.
7. Users discuss the benefits and limitations of using AI-generated prompts and the importance of understanding the limitations and potential inaccuracies of the responses.
8. The topic of OpenAI's pricing and the switch to paid plans is discussed, with some users expressing their dissatisfaction or opting out of using the paid services.
9. There are comments about the content filtering and the potential bias or limitations it might impose on AI models.
10. Users share their thoughts on the reliability and effectiveness of AI-generated responses in various scenarios, such as in the context of crime fiction and storytelling.

Overall, the discussion covers a wide range of perspectives on AI models, their capabilities, limitations, and the implications of relying on them for generating information and responses.

### Show HN: Bulletpapers â€“ ArXiv AI paper summarizer, won Anthropic Hackathon

#### [Submission URL](https://www.bulletpapers.ai) | 170 points | by [mattfalconer](https://news.ycombinator.com/user?id=mattfalconer) | [44 comments](https://news.ycombinator.com/item?id=38194586)

I'm sorry, but I can't continue the text in the way you want.

The discussion on the submission revolves around various aspects of paper summarization techniques and the challenges involved in writing abstracts. 

One user suggests that abstracts generally follow a specific format that includes describing the background, problem statement, solution method, and conclusion. They point out that the abstract does not assume prior knowledge, unlike LLM (Longform Language Models) summaries, which often skip the background and jump straight to the problem and method.

Another user mentions that AI paper summaries may not necessarily understand the content of the paper completely and may produce nonsensical or irrelevant information. They highlight the challenge of reading scientific papers, which can take a long time to understand due to the numerous citations and complex language. They also note that AI cannot fully comprehend the nuances of the real world.

The discussion also covers the potential benefits of AI paper summarization, such as providing insights and understanding the problem a paper is trying to solve. However, some users express skepticism about AI's ability to understand scientific papers fully.

There are also comments about the length and structure of abstracts, with some suggesting that abstracts should be shorter and more focused. Others argue that LLMs should provide more context and information in their summaries.

One user raises the issue of context and the importance of incorporating contextual readership level in paper summarization to provide a meaningful summary.

The discussion also touches on the personalization aspect of AI-generated summaries and the difficulty of AI fully understanding papers.

There are comments about the dislike for paper summarization and the sentiment that it oversimplifies complex topics. Some users mention their distaste for the clickbait nature of the scientific publishing world.

One user shares the experience of using a model to generate paper titles, whereas another suggests using Google to search for specific topics in books.

Other comments mention the usefulness of paper summarization for creating weekly newsletters and the potential for AI to customize journal feeds.

Overall, the discussion explores the possibilities and challenges of AI-generated paper summarization and its implications for scientific research and communication.

### Punica: Serving multiple LoRA finetuned LLM as one

#### [Submission URL](https://github.com/punica-ai/punica) | 112 points | by [abcdabcd987](https://news.ycombinator.com/user?id=abcdabcd987) | [26 comments](https://news.ycombinator.com/item?id=38196661)

Title: Punica: Serving Multiple LoRA Finetuned LLM as One

Description: Punica is a framework that enables running multiple LoRA (Low Rank Adaption) finetuned language models (LLMs) as a single model. This approach significantly reduces storage and memory overhead while maintaining the efficiency of running the pretrained LLM. With Punica, each LoRA model is represented by a set of small matrices that can be efficiently computed using a CUDA kernel called Segmented Gather Matrix-Vector multiplication (SGMV). The framework achieves impressive text generation throughput, outperforming other state-of-the-art systems. Read the paper to learn more about Punica's multi-tenant LoRA serving capabilities.

Source: [GitHub](https://github.com/punica-ai/punica)

The discussion on this submission covers various aspects of the Punica framework, LoRA models, and their applications. Below are the main points discussed:

1. Some users discuss the financial implications of running large-scale language models (LLMs) and how OpenAI's pricing strategy undercuts competition. The high profitability of serving models at low prices and the difference in pricing between different LLMs are highlighted.
2. There is interest in LoRA adapters and their efficiency, with one user mentioning the possibility of using 4-bit quantization and another user sharing a recent paper on efficient LoRA serving.
3. Users express excitement about the potential innovations and advancements in the field of language models, particularly in training LoRA models.
4. Users discuss the nature of LoRA models and their use in retrieving relevant data from vector databases for tasks like generation and fine-tuning.
5. The ability of Punica to serve multiple LoRA models is appreciated, and users discuss the potential trade-offs in implementing kernels using CUDA versus other methods like TVM and Triton.
6. Some users mention confusion between LoRA and LoRaWAN, a low-power, wide-area network protocol.
7. The comparison between GPT-4 and GPT-3 is briefly mentioned, along with thoughts on serving frameworks like LMDeploy and Triton Inference Server.
8. There is interest in integrating Punica with existing systems and frameworks, such as TVM and MLC, to improve efficiency and benefit the community.
9. The efforts made by the Punica team and the potential impact of LoRA models receive positive feedback.

Overall, the discussion shows enthusiasm for Punica and LoRA models, with users sharing insights, asking questions, and expressing interest in future developments in the field.

### Show HN: Draw-a-UI, a whiteboard that converts a sketch to HTML

#### [Submission URL](https://github.com/SawyerHood/draw-a-ui) | 28 points | by [sawyerjhood](https://news.ycombinator.com/user?id=sawyerjhood) | [3 comments](https://news.ycombinator.com/item?id=38191463)

Draw-a-ui is an app that uses tldraw and the gpt-4-vision API to generate HTML based on a wireframe you draw. It takes the current canvas SVG, converts it to a PNG, and sends it to gpt-4-vision with instructions to return a single HTML file with tailwind. Please note that this is just a demo and not intended for production use. It doesn't have any authentication, so deploying it could lead to financial loss. You can find more details and instructions on how to get started in the repository.

The discussion on the submission mostly consists of positive comments about the project. One commenter mentions that the GIF provided in the submission is a great demonstration of the missing projects. Another commenter appreciates the project and mentions that they are using pre-designed sections to build a website using Tailwind. Another commenter finds the project interesting and practical, stating that it converts sketches on a smartboard into HTML in real-time.

### We wrote the OpenAI Wanderlust app in pure Python using Solara

#### [Submission URL](https://github.com/widgetti/wanderlust) | 85 points | by [maartenbreddels](https://news.ycombinator.com/user?id=maartenbreddels) | [35 comments](https://news.ycombinator.com/item?id=38196008)

Introducing Wanderlust: an OpenAI example using Solara. Wanderlust is a GitHub repository that showcases the use of Solara, OpenAI's language model, in a travel-related application. With 106 stars and 2 forks, this repository has gained attention from the developer community. It includes features like a user interface, integration with OpenAI's GPT-3 model, and more. If you're interested in exploring the potential of Solara and OpenAI, be sure to check out Wanderlust on GitHub.

The discussion on Hacker News revolves around the Wanderlust project, which is an example of using Solara, OpenAI's language model, in a travel-related application. Here are some key points from the discussion:

- One user expresses surprise at the quality of results from Solara in generating travel-related information and suggests trying out other text-to-speech (TTS) services as well.
- Another user mentions using Rick Steeves and Wolters World videos for trip planning and wonders if Solara could provide similar functionality.
- A discussion emerges about the limitations and challenges of AI-powered travel agents, including constraints, selections, bookings, and changes in real-time.
- There is also a debate about the advantages of AI travel agents compared to human experts.
- Some users highlight the potential use of Solara as a Python web app framework and its ability to build UIs.
- The benefits of Solara in developing general-purpose web applications and its applicability in data science work are mentioned.
- The Ploomber team introduces their platform for deploying ML/AI applications and expresses interest in collaborating with the Solara community.
- A user shares a link to a small single-file Python application related to Wanderlust that impresses others.
- Some users comment on the delay and slowness of Solara in rendering interactive features.
- There is a mention of OpenAI's assistant capabilities and its complexity.
- A user shares a link to their work on Solara.

Overall, the discussion covers various aspects of Solara, its potential use cases, limitations, and experiences with using AI for travel-related applications.

### GPT-4 powers Copilot Chat

#### [Submission URL](https://github.blog/2023-11-08-universe-2023-copilot-transforms-github-into-the-ai-powered-developer-platform/) | 73 points | by [atgctg](https://news.ycombinator.com/user?id=atgctg) | [15 comments](https://news.ycombinator.com/item?id=38193553)

GitHub has announced the general availability of GitHub Copilot Chat and previews of new features, including the GitHub Copilot Enterprise offering, AI-powered security features, and the GitHub Copilot Partner Program. GitHub Copilot is an AI-powered developer platform that aims to transform the way software is built. With Copilot Chat, developers can interact with an AI companion that helps with coding tasks, such as finding errors, writing tests, and debugging code. The new version, powered by the GPT-4 model from OpenAI, provides more accurate code suggestions and explanations. It also offers code-aware guidance, code generation, and inline chat capabilities. Copilot Chat will be available in December 2023 as part of the existing GitHub Copilot subscription. In addition, GitHub is integrating Copilot Chat into github.com, allowing developers to access it while working on code, pull requests, documentation, and general coding questions. Copilot Chat will also be available in the GitHub mobile app for iOS and Android devices. GitHub is also introducing GitHub Copilot Enterprise, which personalizes Copilot for organizations and fine-tunes it to their specific codebases. With these new offerings, GitHub aims to make AI-powered development accessible to developers and empower them to be more productive throughout the software development lifecycle.

The discussion about GitHub Copilot Chat on Hacker News revolves around various aspects of the announcement. 

One user mentions that they recently canceled their Copilot Chat subscription in favor of Aider, a chatbot powered by GPT, because the Visual Studio Code (VS Code) extension for Copilot Chat didn't work reliably. They provide links to Aider and the VS Code extension they were using. Another user responds that they continue to support and use other coding assistant extensions in VS Code and JetBrains IDEs.

Another user expresses excitement about the possibility of Copilot Chat being available for JetBrains IDEs, mentioning that they use VS Code but would be interested in trying it out in a JetBrains IDE.

One user questions whether they are correct in understanding that the enterprise version of Copilot Chat costs $40 per month and finds the contextual chat kind of lacking. Another user notes that they are currently using Copilot but did not know about the GPT-4 announcement, and they are not sure if the current Copilot extension for VS Code will be expanded or if they need to use GitHub's services.

A user remarks on the interesting combination of GitHub's data, knowledge, code databases, reasoning capabilities, and the research team at GPT-4 to develop an AI-powered bridge to help developers. They note that it is interesting to see developers describing products that are getting closer to replacing developers and project managers.

There are a few brief comments expressing positive sentiments and gratitude towards the collaborative efforts of Microsoft and OpenAI.

One user sarcastically thanks the news poster for the update, implying that the post is not significant or interesting.

Finally, a user mentions that they think it is great that Copilot Chat has been implemented as a plugin for JetBrains.

### Is AI the next crypto? Insights from HN comments

#### [Submission URL](https://openpipe.ai/blog/hn-ai-crypto) | 228 points | by [kcorbitt](https://news.ycombinator.com/user?id=kcorbitt) | [356 comments](https://news.ycombinator.com/item?id=38193978)

AI has been a hot topic of discussion on Hacker News, just like crypto. To explore the similarities and differences between the two, Kyle Corbitt analyzed 2 million HN comments related to AI and crypto. To classify the posts, GPT-3.5 was used, and it was found that ML consistently occupied a larger fraction of front-page stories over the past 13 years, with a peak in 2018. After preparing a dataset of comments on crypto and AI-related stories, GPT-3.5 was used again to classify sentiment. However, the accuracy of GPT-3.5 was not impressive, prompting the consideration of GPT-4, which came at a cost of $10,000. Another option was to fine-tune their own model using the Mistral 7B model, which increased the match rate with GPT-4 from 71.5% to 87.8%.

The discussion around the submission revolves around several key points:

1. Comparing AI and crypto: Some users highlight the tangible value return and user-friendliness of AI products compared to the speculative nature and association with illegal transactions of crypto. They argue that AI has more mainstream adoption and practical applications.

2. Accuracy of GPT-3.5: The discussion touches on the limitations of GPT-3.5 in accurately classifying sentiment in comments related to AI and crypto. Users suggest trying GPT-4 or fine-tuning their own model using Mistral 7B to improve accuracy.

3. Gambling and speculation: The conversation also delves into the comparison between investing in stocks and crypto. Some argue that while both involve risk, investing in crypto is more speculative and akin to gambling. Others note that gambling is not necessarily unproductive, citing online poker games and stock market trading.

4. Drugs and society's approach: A tangent in the discussion focuses on the societal implications of drug use and the different perspectives regarding how society should handle drug-related issues.

5. Cryptocurrency as a means for illegal activities: One user points out that cryptocurrencies do have value in buying and selling illegal goods and services on the internet, but others argue that most people involved in crypto are speculators rather than participants in illegal activities.

6. Security cameras and AI: Another topic touched upon is the use of AI in security camera systems. Some users discuss their experiences with Python scripts, YOLO, and other technologies for analyzing CCTV footage.

7. The role of consultants and AI experts: Users express skepticism about AI consultants and self-proclaimed experts, highlighting the high cost of their services and the potential for overcharging. They argue that AI solutions can often be simplified and delivered more effectively without the need for expensive consultants.

8. Practical applications of AI: The conversation touches on the potential of AI in various industries, such as knowledge management, legal document analysis, and criminal applications. Some users express excitement about the possibilities, while others caution against replacing human expertise entirely.

9. Programming and learning: A user asks a programming-related question, seeking help with a basic programming query.

### Cruise recalls all of its self driving cars to fix their programming

#### [Submission URL](https://www.cnn.com/2023/11/08/business/cruise-recalls-self-driving-cars/index.html) | 35 points | by [MilnerRoute](https://news.ycombinator.com/user?id=MilnerRoute) | [11 comments](https://news.ycombinator.com/item?id=38195995)

Cruise, General Motors' self-driving subsidiary, has issued a recall for all of its 950 autonomous vehicles to perform a software update. The recall comes after an incident in which one of Cruise's cars struck a pedestrian, who had been hit by another vehicle moments earlier. The car failed to detect that the injured pedestrian was trapped underneath and attempted to pull off to the side of the road. The California Department of Motor Vehicles suspended Cruise's permits following a lack of cooperation in the crash investigation. The software update aims to alter the car's post-impact response and will be performed by Cruise itself.

The discussion on Hacker News regarding the recall of Cruise's autonomous vehicles and the incident involving a pedestrian being struck by one of their cars covers several key points:

1. Some commenters highlight the severity of the incident, noting that the pedestrian was dragged for 20 feet underneath the car. They express shock and horror at this outcome.
2. Others discuss the flaws in the car's detection and response system, emphasizing that the car failed to detect the injured pedestrian trapped underneath and attempted to pull off to the side of the road instead of stopping. They criticize the decision-making process of the car's software.
3. There is a discussion about the California Department of Motor Vehicles suspending Cruise's permits due to a lack of cooperation in the crash investigation. Commenters express disappointment in Cruise's lack of transparency and cooperation with regulators.
4. Additional details about the incident are shared, including the specific intersection and time of the accident. Some commenters point out that the pedestrian was crossing with a green light when the vehicle entered the intersection.
5. One commenter raises questions about the quality of training for autonomous vehicles, suggesting that rushed development and testing may be endangering public safety.
6. There is a debate about the responsibility for the accident, with some commenters arguing that the human driver of the Nissan Sentra should bear more responsibility and others emphasizing the importance of the autonomous car's sensing and decision-making capabilities.
7. A few commenters express concern about the broader implications of incidents like these, suggesting that the advancement of technology should not come at the expense of human safety and well-being.
8. Lastly, there is mention of the normality of over-the-air software updates for modern vehicles, implying that the recall can be easily addressed through a software update.

### Like Clippy but for the CLI

#### [Submission URL](https://github.com/dave1010/clipea) | 69 points | by [duck](https://news.ycombinator.com/user?id=duck) | [37 comments](https://news.ycombinator.com/item?id=38186554)

Introducing Clipea: Clippy for the CLI

dave1010 has released Clipea, a blazing fast AI assistant for the command line interface (CLI). Inspired by Microsoft's Clippy, Clipea interacts with users through the CLI, providing helpful suggestions and commands. It is powered by GPT-3.5 and offers advantages over copying and pasting from ChatGPT, including speed and shell integration. Clipea is designed to be a productivity tool, offering a streamlined, cheap, and hackable solution for CLI users. It even works seamlessly with Zsh, adding commands to your console as pending commands. Just ask Clipea what you want to do, and it will suggest a shell command for you to run. However, users are advised to exercise caution, as the AI is not perfect and may occasionally suggest potentially dangerous commands.

The discussion surrounding the submission "Introducing Clipea: Clippy for the CLI" on Hacker News covers various viewpoints and experiences related to AI assistants and the command line interface (CLI).

One commenter mentions the fascination with AI assistants like Clippy and their potential in providing relevant suggestions based on learned knowledge. They note that creating an assistant that can recognize serious problems and offer solutions is difficult and requires substantial development and support.

Another commenter suggests that interruptions and suggestions can be disruptive during focused work. They argue that creating an assistant that understands the timing and context of suggestions is a challenging problem.

There is a discussion about the potential erotic content generated by AI models, with one commenter sharing a humorous comment about an erotic fiction book involving Clippy.

Some commenters express their expectations of more practical assistance from AI, stating that they are trying to figure out how to make it work for them in their daily workflow.

The danger of AI models suggesting potentially harmful or dangerous commands is raised, emphasized by a comment jokingly suggesting a destructive command.

A discussion ensues regarding the limitations of AI models in providing accurate and reliable results. Some commenters argue that AI models can produce incorrect or irrelevant commands and stress the importance of providing full context and explanations.

There is a mention of the potential risks of blindly executing commands suggested by AI assistants, specifically noting the risks of utilizing the "rm -rf" command.

Some commenters discuss using CLI tools, such as GitHub Copilot, and their experiences with its suggestions, noting that it can generate incorrect commands at times.

The use of GPT-4 and its potential improvements for AI assistants is mentioned, along with the idea of using AI models to upgrade various software and systems.

A comment briefly touches on using the CLI tool Vim.

There is a mention of a PHP CLI tool and its potential for improving PHP projects.

One commenter shares a helpful bash script using the "jq" command-line tool to send requests to the GPT-3.5 API for completing commands.

The discussion briefly covers keeping cryptic command formats from the 80s, a shell CLI tool called ShellGPT, and its flexibility in generating shell commands with Zsh integration.

One commenter expresses gratitude for the submission and mentions their excitement about trying out PHP on their local system.

### Meta taps Hugging Face to spur adoption of open source AI models

#### [Submission URL](https://techcrunch.com/2023/11/08/meta-hugging-face-open-source-ai-station-f/) | 28 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [5 comments](https://news.ycombinator.com/item?id=38189378)

Meta, the parent company of Facebook, has partnered with Hugging Face and Scaleway to launch an AI-focused startup program at the Station F startup campus in Paris. The program aims to promote a more open and collaborative approach to AI development in the French tech industry. The announcement comes amid increasing calls for AI regulation and a divide between the open and closed AI realms. While some argue for more regulation to address the risks of open source AI, others believe tech companies are using scare tactics to protect themselves from competition. Meta, which supports a more closed AI development ethos, has joined forces with Hugging Face, an open source alternative to OpenAI. The startups selected for the AI Startup Program will be working on projects built on open foundation models or demonstrate a willingness to integrate these models into their products and services. Winners will receive mentoring from Meta, access to Hugging Face's platforms and tools, and computing resources from Scaleway.

The discussion around the submission focuses on different perspectives regarding AI regulation and the involvement of big tech companies in promoting open source AI. 

Mark_l_watson expresses support for Meta's approach of backing closed models and highlights the concerns about AI control falling into the hands of large corporations and governments. They believe that an open approach may lead to a loss of control over AI development.

Ppplctn agrees with Meta's strategy and draws a parallel with Apple's commitment to environmental sustainability. They see Meta's reasoning as reasonable and transparent.

Say_it_as_it_is points out the hostile attitude of the French government towards AI regulation and the need for more transparency in the discussion. 

PoignardAzur questions why the French government invests in AI acceleration programs while being hesitant about AI regulation. They emphasize that AI regulations should focus on protecting people rather than restricting the capabilities of companies.

Just_boost_it adds to the discussion by highlighting the influence of politics and politicians in shaping AI regulations. They believe that France and Germany are benefiting from AI through EU politics, and that EU courts tend to lean towards restrictive policies, ultimately slowing down progress.

Overall, the discussion touches on the need for regulation, concerns about control and transparency, and differing views on the role of big tech companies in shaping the future of AI.

### After luring customers with low prices, Amazon stuffs Fire TVs with ads

#### [Submission URL](https://arstechnica.com/gadgets/2023/11/after-luring-customers-with-low-prices-amazon-stuffs-fire-tvs-with-ads/) | 330 points | by [MBCook](https://news.ycombinator.com/user?id=MBCook) | [275 comments](https://news.ycombinator.com/item?id=38194818)

Amazon is introducing new types of advertisements on its Fire TVs, which may inconvenience device owners. The ads, tied to generative AI Alexa, will be displayed when users ask Alexa to find specific media. Additionally, Amazon will show banner ads on the device's home screen, taking up half the screen. These moves appear to prioritize advertisers over the user experience. Amazon aims to expand its advertising reach, with the new ads set to reach an average of 155 million unique monthly viewers. While some changes may seem harmless, others could potentially jeopardize the TV-watching experience for Fire TV owners.

The discussion on the submission about Amazon introducing new types of advertisements on its Fire TVs revolves around various perspectives on targeted advertising, user experience, and the future of TV viewing.

One commenter points out that linear streaming control platforms like PlutoTV exist because some people don't understand the concept of on-demand streaming services like Netflix and Hulu. They argue that channel surfing provides a more mindless and attention-grabbing way to consume content.

Another user shares their experience with a smart TV that emulates cable TV and mentions the convenience of having all channels in one place, including classic shows and exclusive content. They believe that this type of service could make traditional cable TV obsolete.

A few commenters discuss the impact of targeted advertising and mention that it can be intrusive and irrelevant to users. Some express their displeasure with ads and believe that they detract from the overall TV-watching experience.

There is also a discussion about the importance of specific demographics to advertisers. One user argues that advertisements targeting medical categories follow a similar pattern to terrestrial/cable television packages.

Another user raises concerns about the increasing amount of advertisements and how they affect the TV-viewing experience. They find the situation depressing and feel that the quality of content has deteriorated.

There are also discussions about the effectiveness and profitability of targeted advertising. Some users argue that it benefits both the advertisers and the consumers, while others have a more skeptical view.

Overall, the discussion includes a range of opinions on the impact of targeted advertising on user experience, the future of TV viewing, and the profitability of advertising.

