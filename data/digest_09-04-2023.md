## AI Submissions for Mon Sep 04 2023 {{ 'date': '2023-09-04T17:09:43.400Z' }}

### Show HN: finetune LLMs via the Finetuning Hub

#### [Submission URL](https://github.com/georgian-io/LLM-Finetuning-Hub) | 75 points | by [rsaha7](https://news.ycombinator.com/user?id=rsaha7) | [7 comments](https://news.ycombinator.com/item?id=37381296)

LLM-Finetuning-Hub is a repository that contains code and insights for fine-tuning various large language models (LLMs) for different use cases. The repository provides an Evaluation Framework that includes four pillars: performance, time to train, cost to train, and inferencing. It aims to assist users in leveraging LLMs for their business needs, deciding which LLM suits their requirements, and boosting reproducibility efforts. The repository offers ready-to-use scripts for fine-tuning LLMs and performing hyperparameter optimization. The setup process is straightforward, involving the creation of a conda environment, installation of relevant packages, and running the fine-tuning scripts for the desired LLM. The repository also provides instructions for zero-shot and few-shot learning using the fine-tuned LLMs. Currently, the experiments have been conducted on an AWS EC2 instance with one 24GB Nvidia GPU.

The discussion in the comments about the submission revolves around different aspects of fine-tuning large language models (LLMs). 

One user expresses confusion about the purpose of fine-tuning LLMs and mentions the difficulty they face in finding proper data and understanding the process. Another user responds, explaining that fine-tuning LLMs is often done without a specific dataset, and it can be helpful for tasks such as question-answering by converting text articles or tweets into questions. They suggest that the lack of proper documentation might be the reason for the confusion.

Another user argues that fine-tuning LLMs can lead to nonsensical results because most of the training data is from non-FAANG (Facebook, Apple, Amazon, Netflix, Google) sources, which may not accurately represent real-world scenarios. They suggest alternative approaches, such as using code to guide the model's responses or manually searching related documentation.

There is also a discussion about the process of fine-tuning LLMs and the different components involved. One user suggests an approach that involves manually searching related documentation using BM25F and BERT models, and then using the retrieved snippets to help answer questions. They also mention the importance of latency requirements in the process.

A user raises the distinction between fine-tuning LLMs and training templates, stating that they are working on projects using GPU-backed instances on Google Cloud. Finally, one user appreciates the project and mentions its similarities to another project they are working on.

### TinyLlama project aims to pretrain a 1.1B Llama model on 3T tokens

#### [Submission URL](https://github.com/jzhang38/TinyLlama) | 198 points | by [cmitsakis](https://news.ycombinator.com/user?id=cmitsakis) | [60 comments](https://news.ycombinator.com/item?id=37379984)

The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens within just 90 days using 16 A100-40G GPUs. It adopts the same architecture and tokenizer as Llama 2, making it compatible with many open-source projects built upon Llama. Despite its compactness with only 1.1B parameters, TinyLlama can cater to various applications with restricted computational and memory requirements.

The project has released a schedule for rolling out intermediate checkpoints, allowing developers to track its progress. TinyLlama has already made significant progress and continues to do so. The project also provides potential use cases for tiny, yet powerful language models, such as assisting speculative decoding of larger models and enabling real-time dialogue generation in video games.

The training details of TinyLlama are also shared, including the training setup and hardware used. The codebase supports features like multi-gpu and multi-node distributed training, flash attention, fused layernorm, and more. These optimizations enable a high throughput of 24k tokens per second per A100-40G GPU, allowing for efficient training and reduced memory footprint.

Overall, TinyLlama offers a powerful and compact language model solution for various applications, and its progress in pretraining the 1.1B model is worth keeping an eye on.

The discussion on Hacker News revolves around the pretraining of the 1.1B Llama model on 3 trillion tokens by the TinyLlama project. One user wonders if the metatraining process will have less curvature and convergence due to the scheduled checkpoints, to which another user responds that the gradual decrease in learning rate may not necessarily help. A discussion also arises about the scaling laws and the performance of different models. Some users express skepticism about the cost and resources required for training these models, while others discuss the relevance of Chinchilla scaling laws and the practicality of deploying large-scale language models. Another user highlights the potential bottlenecks and cost efficiency issues when it comes to inference latency and the availability of GPUs in production environments. The scalability and economic implications of running large models in various settings are also debated. Overall, the discussion touches upon various aspects of training and deploying large language models, including the technical and practical considerations involved.

### Is macOSâ€™s new XProtect behavioural security preparing to go live?

#### [Submission URL](https://eclecticlight.co/2023/09/04/is-macoss-new-xprotect-behavioural-security-preparing-to-go-live/) | 91 points | by [GavinAnderegg](https://news.ycombinator.com/user?id=GavinAnderegg) | [100 comments](https://news.ycombinator.com/item?id=37380104)

Apple's macOS security feature, XProtect, has received significant updates in recent months. XProtect consists of several components, including XProtect Remediator, which detects and removes known malware, and XProtect Behaviour Service (XBS), which observes potentially malicious behavior. The latest updates to XProtect Remediator have expanded its capabilities to detect 19 different types of malware on macOS 10.15 and later. Meanwhile, XBS has been recording potentially malicious behavior but has not yet taken any action to block it. The recent discovery of Bastion rules suggests that XBS may soon become more active in protecting macOS users. However, it remains unclear how updates to these rules are recognized by syspolicyd, the system policy daemon, and implemented without restarting macOS. These recent updates indicate Apple's dedication to improving macOS security, and it is anticipated that XBS will be ready to intervene in security threats in the near future.

The discussion around the submission mainly revolves around the effectiveness of Apple's security feature, XProtect, and the potential improvements it could bring to macOS security. Some users express skepticism about third-party security software and argue that Apple's built-in protection should be sufficient. Others raise concerns about Apple's documentation and control over third-party software that interacts with XProtect. There are also discussions about the challenges faced by developers when building applications for macOS and the limitations of the SwiftUI framework. Overall, the discussion highlights the importance of robust security measures and the need for continuous improvement in protecting macOS users.

### Robots pouring drinks in Vegas: As AI grows, the city's workers brace for change

#### [Submission URL](https://www.npr.org/2023/09/04/1197138244/vegas-ai-workers-brace-for-change) | 20 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [21 comments](https://news.ycombinator.com/item?id=37386280)

Las Vegas, a city known for its tourism and hospitality industry, is bracing for the impact of artificial intelligence (AI) and automation on its workforce. With robots already serving drinks and check-in kiosks replacing hotel front desk staff, the city's economy is at an inflection point as companies seek to reduce labor costs through technology. Studies show that between 38% to 65% of jobs in Las Vegas could be automated by 2035. To adapt to this change, the city will need to diversify its economy and focus on occupations that are less easily replaced by AI. The Culinary Union, which represents thousands of service and hospitality workers, is closely monitoring these developments and is prepared to strike over AI if necessary. While some workers believe that AI can never fully replace the human touch and experience, others are concerned about the potential loss of jobs. Overall, Las Vegas is undergoing a transformation as it prepares for the impact of AI on its service-heavy economy.

The discussion on this submission revolves around the use of AI and automation in Las Vegas, particularly in the hospitality industry. Some commenters highlight the potential benefits of AI, such as an AI bartender recognizing customers and handling return orders, as well as the potential for improved mental health by reducing pressure on human bartenders. Others express concerns about the loss of quality and consistency that may come with using robots instead of human bartenders. One commenter mentions that robotic bartenders could lead to wastage of individual drinks and potential theft, while another shares a story of an incident in a kitchen where a robot malfunctioned. Some commenters argue that the transition to AI and automation will result in a reduction in the number of workers supporting non-workers, while others suggest that this could be a positive shift. There are also discussions about the complexity of vending machine technology, the value of human touch in service, and the cost-effectiveness of using robots.

