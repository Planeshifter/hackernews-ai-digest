## AI Submissions for Mon Jan 15 2024 {{ 'date': '2024-01-15T17:09:56.582Z' }}

### (Unsuccessfully) Fine-tuning GPT to play "Connections"

#### [Submission URL](https://www.danielcorin.com/posts/2024/fine-tuning-connections/) | 94 points | by [danielcorin](https://news.ycombinator.com/user?id=danielcorin) | [45 comments](https://news.ycombinator.com/item?id=39003066)

In a recent blog post, Dan Corin shared his experience of fine-tuning the OpenAI language model, gpt-3.5-turbo, to play the word game "Connections." After struggling to make progress with prompt engineering alone, Corin decided to create a dataset by accessing the game's JSON API. He then used this dataset to fine-tune the model. The process involved estimating the price based on the number of tokens, creating a training file, and running the fine-tuning job. The cost of the job was $0.90, and it seemed to use 3 epochs for training. Corin tested the fine-tuned model in the OpenAI playground and eagerly awaited the results.

The discussion on this submission covers various aspects of the fine-tuning process and the performance of the OpenAI language model, gpt-3.5-turbo, in playing the word game "Connections." Some users express surprise at the model's ability to perform well in this task, while others point out limitations in its ability to handle certain types of combinations. The discussion also touches on the comparison between Alpha Zero and gpt-3.5-turbo in playing different games and the possibility of applying LLMs to solve the Connections problem. There are also suggestions for algorithmic approaches, such as using embeddings and vector representations, as well as the use of other games like Codenames to test the performance of language models. Some users mention the difficulty in training the model to generate correct groupings and provide insights into potential training strategies. Overall, the discussion highlights different perspectives on the fine-tuning process and the capabilities of language models in playing word games like Connections.

### Show HN: Spent 450hrs to bring my CV down to 1 page (ML, AI)

#### [Submission URL](https://be-distinguished.com) | 26 points | by [todyWasAGoodDy](https://news.ycombinator.com/user?id=todyWasAGoodDy) | [11 comments](https://news.ycombinator.com/item?id=39002675)

üì∞ Today's Top Stories on Hacker News üì∞

1Ô∏è‚É£ "Compare Job Descriptions: The Secrets of Getting a Top Tech Job" - Are you on the hunt for a new tech job? This post dives into the art of comparing job descriptions to find the perfect fit. Learn how to decode the hidden cues and requirements to increase your chances of landing your dream job. Don't settle for just any gig - aim high and get that top tech job you deserve! üíºüí™

2Ô∏è‚É£ "Update Your CV: Tips and Tricks to Stand Out in a Competitive Job Market" - Your CV is your first impression on potential employers, so make it count! This article offers valuable insights into refreshing your CV to attract attention in a crowded job market. Discover tips and tricks to highlight your skills, accomplishments, and unique qualities that will set you apart from the competition. Get ready to wow those recruiters and land your dream job! üéØüìù

3Ô∏è‚É£ "Be Distinguished: Unleash Your Inner Brilliance and Set Yourself Apart" - In a world filled with noise, it's important to be distinctive. This post delves into the powerful concept of being distinguished, both in your personal and professional life. Learn how to unleash your inner brilliance, cultivate unique ideas, and differentiate yourself from the crowd. One-size-fits-all approaches won't cut it - dare to be remarkable and leave your mark on the world! üåü‚ú®

Stay tuned for more trending stories tomorrow! Stay curious, stay informed! ü§ñüìö

Here is a summary of the discussion on this submission:

- User "pjm331" comments that keywords in job descriptions, like company names, are helpful in narrowing down the search. They provide examples of specific keywords to look for and mention the importance of certifications and company overviews.
- User "todyWasAGoodDy" thanks pjm331 for sharing their experience and suggests that a more summarized view of the job descriptions is helpful. They mention using page filters to quickly go through the results and find relevant requirements.
- User "dash2" didn't understand the mention of job description search and mentions searching for data scientist positions. They express their need for salary range information and that they are currently working on their CV.
- User "mym1990" comments on the amount of time spent learning and project undertaken, suggesting that it's important to focus on the average requirements and not the extreme cases. They mention that job descriptions should be tailored to individual CVs.
- User "jskhrmn" compliments the work and mentions a tool called Career Explorer on LinkedIn that helps in writing CVs.
- User "nprtm" finds the feedback strange and mentions that two pages are fine for a CV.
- User "Reubend" points out that some people may have extensive experience that cannot be summarized in just two pages.
- User "mplws" didn't understand the purpose of the post, mentioning that a CV cannot collapse into one page.

Please note that some comments are responses to others, and this summary may not capture the complete context of the discussion.

### ChatGPT does Advent of Code 2023

#### [Submission URL](https://www.themotte.org/post/797/chatgpt-vs-advent-of-code) | 182 points | by [luu](https://news.ycombinator.com/user?id=luu) | [171 comments](https://news.ycombinator.com/item?id=38998423)

In a recent experiment on Hacker News, user "aaa" tested the performance of ChatGPT-4 in solving problems from Advent of Code 2023. Advent of Code is an annual programming event that takes place during the first 25 days of December, where participants solve coding challenges for each day. 

ChatGPT, a language model, was pitted against Advent of Code, which has problems ranging from easy to moderately difficult. Previous iterations of ChatGPT had gained attention for their performance in the event, with users reaching the top of the global leaderboard. However, last year's results with GPT-3.5 were modest, struggling to solve problems past day 5.

The author chose Advent of Code as a benchmark because it provides a range of problems with increasing difficulty, making it a suitable test for AGI. All problems are solvable within a few hours, providing a benchmark for how well ChatGPT-4 performs.

Using the command line client, chatgpt-cli, the author manually ran ChatGPT's output programs based on the problem prompts. Prompting the model with a simplified version of the problem, the author fixed trivial syntax mistakes and gave up if a solution didn't terminate within 15 minutes. If the initial solution was incorrect, the author requested debug output from ChatGPT. The experiment was stopped after four consecutive days of ChatGPT's failure to solve part 1.

The results showed mixed performance from ChatGPT-4. It managed to solve some problems independently but struggled with others, requiring hints or assistance from ChatGPT Plus, a subscription-based version of the model. Additionally, the blog of another ChatGPT enthusiast provided insights into their efforts with ChatGPT Plus, but it often required baby-stepping the model to achieve results.

Comparing the performance of GPT-4 with the previous year's GPT-3.5, GPT-4 had a slightly worse performance. While GPT-3.5 could solve three days' problems independently, GPT-4 faced challenges as early as day 3.

The discussion on the Hacker News submission revolves around the performance of ChatGPT-4 in solving problems from Advent of Code. Some users argue that Advent of Code is not a perfect benchmark and suggest using alternative benchmarks like getting dependencies or benchmarking the ability to solve LeetCode challenges. Others express their personal experiences and opinions on the limitations and capabilities of language models like ChatGPT.

There is a debate on whether an average programmer can solve Advent of Code faster than GPT-4. Some users believe that the marginal utility of using GPT-4 may not necessarily improve performance significantly. Others argue that the performance depends on factors like syntax clarity, programming language choice, the quality of the code, and the hardware being used.

The discussion also touches upon the lack of debugging skills in ChatGPT and the need for human intervention in fixing bugs. Some users suggest that debugging capabilities should be added to language models. Others mention the importance of high-level languages and the limitations of current language models in understanding and improving code.

There are comments discussing the productivity of popular programming languages, the effectiveness of different debugging techniques, and the potential improvements that can be made in AI technology to complement developers' productivity.

One user shares a video where ChatGPT attempts to solve Advent of Code problems, generating multiple attempts and trying to correct them. The user points out that while the assistance is helpful, it may not be worthwhile in the context of programming challenges like Advent of Code.

Further discussions touch on issues related to ChatGPT providing incorrect answers, the limitations of its debugging skills, and the importance of clear and precise comments in code. Some users raise concerns about relying on ChatGPT and suggest verifying its approach through additional testing or experiments.

There is a mention of the limitations of current language models in understanding basic logic and common knowledge. Users also discuss the challenges of debugging AI algorithms and the difficulty of differentiating between bugs and incorrect solutions.

Other topics discussed include the need to specify comments in the code, the limitations of current language models in basic reasoning, and the comparison of ChatGPT with existing programming languages and tools.

Overall, the discussion highlights various perspectives on the performance and limitations of language models like ChatGPT in solving programming challenges and the potential improvements that can be made in debugging capabilities.

### How OpenAI is approaching 2024 worldwide elections

#### [Submission URL](https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections) | 49 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [32 comments](https://news.ycombinator.com/item?id=39005399)

OpenAI is taking steps to ensure the integrity of elections in 2024. The company is focused on preventing abuse of AI tools, improving transparency, and enhancing access to accurate voting information. OpenAI's cross-functional team is dedicated to election work and will address potential abuses such as deepfakes, influence operations, and chatbot impersonations. They have implemented safety measures to decline requests for image generation of real people, including candidates. OpenAI is refining its usage policies for ChatGPT and the API to prevent applications that misrepresent voting processes or discourage participation. The company is also working on transparency initiatives, including implementing digital credentials to detect image provenance and integrating ChatGPT with real-time news reporting. In collaboration with the National Association of Secretaries of State, OpenAI is directing users to authoritative voting information websites like CanIVote.org in the United States. OpenAI will continue to work with partners to prevent potential abuse of their tools leading up to global elections.

The discussion surrounding the submission on Hacker News covers a variety of topics related to OpenAI's efforts to ensure the integrity of elections. 

One commenter highlights related blog posts and a Reddit thread discussing OpenAI's initiatives. They mention that OpenAI should clarify their content policy and procedures, as well as address potential issues with the ChatGPT model.

Another commenter expresses concerns about the potential misuse of AI tools, particularly by individuals from foreign countries. They point out the need for platforms to detect and label AI-generated content, similar to the measures taken against deepfakes and misinformation.

A few discussions arise regarding the effectiveness of AI in personalized persuasion and generating propaganda. Some users suggest that there may be individuals attempting to manipulate information or create misleading content using ChatGPT. Others argue that the responsibility lies with political campaigns to protect the integrity of elections and not solely with OpenAI.

There are also comments discussing the potential implications of AI-generated content on political campaigns and the role of corporations in politics. Some express skepticism about the impact of AI-generated misinformation, while others raise concerns about the power and influence of corporations in the political landscape.

Overall, the discussion demonstrates a mix of concerns, suggestions, and opinions regarding OpenAI's efforts to ensure election integrity and the broader implications of AI in politics.

### Escaping from isolated networks using Broadcast DNS

#### [Submission URL](https://medium.com/sensorfu/escaping-isolated-networks-using-broadcast-dns-5aee866bcaff) | 38 points | by [jviide](https://news.ycombinator.com/user?id=jviide) | [3 comments](https://news.ycombinator.com/item?id=38997692)

Researchers at SensorFu have discovered a new method called "Broadcast DNS escape" that allows for the escape of isolated networks. By sending DNS queries via a broadcast ethernet packet, the researchers were able to redirect these queries to another network. This method has been proven effective in two real-world scenarios. In one instance, a Beacon deployed in a production network leaked because the isolated network containing the Beacon and the DNS resolvers were accidentally connected. In another case, a Beacon deployed in an isolated production network was connected to an IT network, allowing the broadcast DNS queries to escape. The researchers highlight that this method takes advantage of a weakness in TCP/IP network stacks, where the next layer of the stack may not recognize a broadcast packet and processes it anyway.

In the discussion about the broadcast DNS escape method, a user named "phyzm" expresses concern about the potential for DNS filtering capability and the possibility of a return channel. Another user named "hrrl" responds, thanking SensorFu for the discovery and explains that this technique takes advantage of the shortcomings in TCP/IP network stacks. They mention that the success of the method depends on the device's ability to process the broadcast packet and the specific configuration of DNS servers. 

Another user named "jstsmhngy" adds to the conversation, explaining that broadcast DNS packets are directed to the network's broadcast address in IPv4 networks, with the MAC address being the FFs. They mention that devices such as routers, switches, and load balancers in the network would process the DNS requests based on their configurations and requirements. They raise a question about whether individuals purposely configure devices in a way that allows these types of packets to pass through in production and industrial networks to facilitate troubleshooting or other purposes.

Overall, the discussion revolves around the technical aspects of the broadcast DNS escape method and the configurations of devices in different network settings.

