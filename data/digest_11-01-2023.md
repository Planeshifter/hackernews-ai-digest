## AI Submissions for Wed Nov 01 2023 {{ 'date': '2023-11-01T17:09:58.781Z' }}

### Dot by New Computer

#### [Submission URL](https://new.computer/) | 218 points | by [_kush](https://news.ycombinator.com/user?id=_kush) | [110 comments](https://news.ycombinator.com/item?id=38101966)

Dot by New Computer is an intelligent guide that will revolutionize the way you remember, organize, and navigate through life. Meet Mei, a first-semester college student who discovers the magic of Dot. Mei, on the eve of her first day of school, receives a treasured recipe from her grandmother, and she shares it with Dot, creating a digital connection between home and school. Dot becomes Mei's trusted companion, helping her stay on top of her class syllabi and even assisting with textbook purchases. Dot's context awareness shines when Mei heads to the library to prepare for her first test, where it quizzes her on her class notes. But Dot is not just about studying; it knows how to mix things up and keep things interesting. Mei's success at school has Dot considering her personal interests, like singing, and proactively sends her suggestions for music clubs to join. Mei's big audition day arrives, and with Dot's support, she feels prepared to conquer any challenge. Dot's automations and routines ensure that Mei's life runs smoothly, and it's always there to celebrate her achievements. Dot is currently in active development and will be available on iOS and web later this year. Join the waitlist to be part of this revolutionary experience that connects the dots in your life.

The discussion on this submission covers a range of topics related to Dot by New Computer. Some users express concern about the potential invasion of privacy that comes with using a service like Dot, while others discuss the practical applications and limitations of the technology. One user raises questions about the company's data processing practices and the trustworthiness of their service. Another user comments on the integration of Dot with Apple's ecosystem and compares it to existing Apple features. There is also a discussion about the potential benefits and drawbacks of Dot's capabilities, such as its ability to suggest music clubs to Mei based on her interests. Overall, the discussion covers a mix of opinions and analysis of the possibilities and implications of Dot.

### Distil-Whisper: distilled version of Whisper that is 6 times faster, 49% smaller

#### [Submission URL](https://github.com/huggingface/distil-whisper) | 258 points | by [omarfarooq](https://news.ycombinator.com/user?id=omarfarooq) | [74 comments](https://news.ycombinator.com/item?id=38093353)

Hugging Face has released Distil-Whisper, a distilled version of the Whisper speech-to-text model. Distil-Whisper is six times faster, 49% smaller, and performs within 1% word error rate (WER) on out-of-distribution evaluation sets. The Distil-Whisper model and processor are supported in Hugging Face Transformers from version 4.35 onwards. To use the model, you need to install the latest version of the Transformers library and optional Datasets library. Distil-Whisper offers both short-form and long-form transcription capabilities. For short-form transcription, you can load the model and processor using the AutoModelForSpeechSeq2Seq and AutoProcessor classes provided by the Transformers library. The example code provided demonstrates how to load the model, pass audio samples to the pipeline, and get the transcription results.

For long-form transcription, Distil-Whisper uses a chunked algorithm that is 9x faster than the sequential algorithm proposed by OpenAI in the Whisper paper. With chunking, you can transcribe long-form audio files efficiently. The code example shows how to enable chunking and batching for optimal performance. Distil-Whisper is a powerful and efficient speech-to-text model, making it an excellent choice for a variety of applications. Give it a try and see how it can enhance your projects!

The discussion on this submission revolves around various aspects of the Distil-Whisper speech-to-text model and its implications. One user points out the availability of other tools and libraries, such as CTranslate2 and Willow Inference Server, that could be useful in conjunction with Distil-Whisper. Another user questions the absence of a link to the original Whisper model in the README file, to which another user explains that it's not necessary as Whisper is a well-known model in the speech recognition field.

There is also a discussion about the trade-off between speed and accuracy in speech recognition models. Some users highlight the importance of fast model execution while others note that models like CTranslate2 and Whisper focus on efficient model execution rather than high accuracy. A user mentions the potential use of the Distil-Whisper model for wake word detection and raises questions about the availability of OpenWakeWord models and their compatibility with Distil-Whisper. Another user provides information on OpenWakeWord models and their usage.

The conversation also touches on the trade-off between model size and performance. Some users discuss the benefits of using distilled models like Distil-Whisper that offer reduced size while maintaining good performance. There is a separate discussion regarding the utilization of GPUs for model training and the challenges associated with GPU availability and capability. Some users mention successful experiences running the Whisper-Turbo model on GPUs. Overall, the discussion provides insights into the features and potential applications of the Distil-Whisper model while also touching on related tools, model optimization techniques, and considerations in the field of speech recognition.

### Attenuating Innovation (AI)

#### [Submission URL](https://stratechery.com/2023/attenuating-innovation-ai/) | 92 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [32 comments](https://news.ycombinator.com/item?id=38098513)

In a recent interview, Bill Gates claimed that Microsoft lost out on the mobile market due to the antitrust lawsuit it faced. He stated that if it hadn't been for the distraction caused by the case, Microsoft would have been more focused on creating a mobile operating system, and people would be using Windows Mobile today instead of Android. However, this claim is debunked by the fact that Windows Mobile actually predated Android by eight years. The real issue with Windows Mobile was that it failed to adapt to the mobile landscape and was too focused on replicating the Windows PC experience. In contrast, Apple's iPhone revolutionized the industry with its touch interface and new user experience paradigm. This failure to understand the future of mobile technology and consumer needs is the reason why Microsoft missed out on the smartphone revolution. The key to genuine innovation lies in embracing uncertainty, recognizing that people are constantly inventing new things, and exercising an editing function to refine ideas after they are created, rather than trying to predict the future.

The discussion on this submission dives into various aspects of the claims made by Bill Gates regarding Microsoft's loss in the mobile market. 

One commenter points out that Gates' claim that Microsoft would have developed a mobile operating system if it weren't for the distraction of the antitrust lawsuit is debunked by the fact that Windows Mobile actually predated Android. They argue that the real reason for Microsoft's failure in the mobile market was its inability to adapt its approach to the changing landscape and consumer needs.

Another commenter contrasts Gates' perspective with Steve Jobs' approach to innovation. They highlight Jobs' emphasis on embracing uncertainty and adapting to new developments, while Gates seemed to focus more on replicating existing PC experiences in the mobile space.

The discussion then veers toward the power and capabilities of current smartphones compared to computers, with some expressing their preference for using phones for various tasks. One commenter mentions that smartphones have become more powerful than a majority of computers and expresses their interest in seeing phone power combined with artificial intelligence capabilities.

There is also some discussion on the humility of Jobs' response compared to Gates' in the interview. One commenter shares a video of Jobs discussing Apple's work on tablets back in 1987, highlighting the company's visionary approach.

The conversation shifts to the limitations of current large language models (LLMs) and the challenges of achieving intelligent decision-making and planning. The importance of not relying solely on marketing tactics but instead focusing on building robust intelligent systems is emphasized.

Other topics raised include the need for stronger defense mechanisms against attacks, the impact of regulations on innovation, and the perception of Microsoft's efforts in the mobile market.

Overall, the discussion covers a range of perspectives on Microsoft's loss in the mobile market, innovation in the tech industry, the potential of smartphones and AI, and the role of regulation in shaping technological advancements.

### Scarlett Johansson takes legal action against use of image for AI

#### [Submission URL](https://www.theguardian.com/film/2023/nov/01/scarlett-johansson-artificial-intelligence-ad) | 64 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [34 comments](https://news.ycombinator.com/item?id=38105463)

Scarlett Johansson has taken legal action against an AI app called Lisa AI: 90's Yearbook & Avatar. The app used the actor's likeness in an AI-generated advertisement without her permission. The ad, posted on the platform formerly known as Twitter, used real footage of Johansson to create a fake image and dialogue for her. Johansson's representatives have confirmed that she is not associated with the company and appropriate legal actions have been taken. The ad has since been removed. This is not the first time Johansson has encountered her image being used without permission, as she has previously spoken out about the use of deepfakes.

The discussion on this submission revolves around various aspects of using AI to generate content and the legal implications of using celebrities' likenesses without permission.

Some users argue that using AI to create content is a form of artistic expression and does not necessarily change the fact that the celebrities involved may not have given their consent. They discuss the challenges of legally judging these situations and the potential concerns of trolling and manipulating content for malicious purposes.

Others express their belief that attacking deepfakes can be difficult, with one user mentioning that news organizations have used footage of Scarlett Johansson without her consent in the past. They argue that copyright laws protect these actions and that attacking deepfakes should not infringe on free speech or limit political discourse.

One user questions the existence of laws or regulations that can effectively tackle the issue of unauthorized use of celebrity likeness by AI. The discussion that follows explores the implications of AI-generated content and the potential need for technical and legislative safeguards.

Another user raises the concern of AI meeting humans in general, calling it a scary prospect. They wonder about the technical and legal safeguards in place, comparing the situation to the manipulation of mobile apps allowing serious manipulation of presidential candidates' appearances for politics-related purposes.

The discussion also touches on the topic of celebrity endorsements in advertising and the importance of obtaining proper consent and ensuring clarity in advertising campaigns. Users mention the Lanham Act, which grants celebrities powerful tools to correct misconceptions and enforce protection against false endorsements.

Other points in the discussion include the potential for blockchain and QR codes to provide verifiable certificates of consent, questions about the purpose of meeting celebrities, and debates about the need for special testing and legal procedures in these cases.

One user argues that there is no special testing needed, suggesting that existing legal procedures should be sufficient and referencing the Lanham Act as applicable. The discussion ends with some users sharing their thoughts on the impact of AI on creative industries and financial incentives, including the potential for creative death and the discussion of what constitutes creativity.

### Unveiling Ragna: An Open Source RAG-Based AI Orchestration Framework

#### [Submission URL](https://quansight.com/post/unveiling-ragna-an-open-source-rag-based-ai-orchestration-framework-designed-to-scale-from-research-to-production/) | 44 points | by [nkaretnikov](https://news.ycombinator.com/user?id=nkaretnikov) | [11 comments](https://news.ycombinator.com/item?id=38098046)

Quansight has released Ragna, an open-source project designed to explore the use of Retrieval-Augmented Generation (RAG) based AI tools. Ragna provides an API for experimentation with different components of a RAG model, a REST API for building RAG-based web applications, and a Panel-based GUI for configuring and interacting with Large Language Models (LLMs). Ragna comes with pre-built extensions for OpenAI, MosaicML, Anthropic, and local LLMs, as well as vector databases. The RAG approach combines a retrieval model and a generative model to improve the accuracy of AI assistants in answering queries. Ragna fills a gap in the ecosystem by providing a comprehensive framework for using RAG-based AI tools.

The discussion on the submission about Quansight releasing Ragna, an open-source project focused on Retrieval-Augmented Generation (RAG) based AI tools, covered several topics. 

- One user mentioned that Ragna seems cool and shared a link to a blog post where they found issues with page numbers in a PDF document. They also highlighted that Ragna currently provides pre-built extensions for OpenAI, MosaicML, Anthropic, local LLMs, Chroma, LanceDB, and vector databases.
- Another user responded by explaining their understanding of the architecture of Ragna. They shared a diagram that illustrates the steps involved, including querying, retrieving relevant parts, and submitting queries to language models.
- In a separate comment, it was mentioned that there will be a talk about Ragna at PyData NYC 2023.
- One user mentioned that Ragna's computers and partitions are similar.
- A link to Ragna's chat and GitHub repository was shared.
- A user expressed their interest in trying Ragna for a small-scale recommendation system.
- Another user encouraged starting a discussion about Ragna on GitHub.
- There was a brief mention of comparing Ragna with Zep.
- One user congratulated the launch of Ragna.
- Lastly, a user with the handle "jffchbr" made a comment, but its content is not mentioned in the summary.

### New AWS service lets customers rent Nvidia GPUs for quick AI projects

#### [Submission URL](https://techcrunch.com/2023/11/01/new-aws-service-lets-customers-rent-nvidia-gpus-for-quick-ai-projects/) | 21 points | by [webmaven](https://news.ycombinator.com/user?id=webmaven) | [3 comments](https://news.ycombinator.com/item?id=38102012)

AWS has introduced Amazon Elastic Compute Cloud (EC2) Capacity Blocks for ML to address the high cost and limited availability of Nvidia GPUs, which are essential for running large language models. This new feature allows customers to purchase access to GPUs for a specified period, typically for AI-related tasks like training machine learning models or running experiments. Users can reserve instances with Nvidia H100 Tensor Core GPUs in cluster sizes ranging from one to 64 instances, with 8 GPUs per instance. The reservation can be made up to 8 weeks in advance for a maximum period of 14 days. Once the time frame is over, the instances automatically shut down. This feature provides customers with upfront cost certainty, allowing them to know the duration of the job, the number of GPUs required, and the associated cost. AWS benefits from being able to utilise these valuable resources and generate revenue based on supply and demand. The price for accessing these resources is dynamic and may vary depending on demand and availability. The feature is available now in the AWS US East (Ohio) region.

The discussion on this submission primarily revolves around two points. 

Firstly, one user points out that the pricing for accessing GPUs in the AWS US East (Ohio) region is quite high, especially for local zone instances in Denver. They note that the lowest-cost local zone instances start at $300 per year. However, they mention that free tier-eligible instances and global instances are available in the Denver Local Zone. Another user adds that they wish AWS would offer instances with specially optimized speaker direction for transcription purposes, as opposed to the NVIDIA card kind.

Secondly, another user highlights the potential benefit of this new AWS feature for innovation in smaller teams. They explain that having access to high-performance Nvidia H100 GPUs on an hourly basis can greatly facilitate experimentation and innovation.
