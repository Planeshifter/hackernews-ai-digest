## AI Submissions for Tue Jun 06 2023 {{ 'date': '2023-06-06T17:14:27.704Z' }}

### Show HN: Arroyo – Write SQL on streaming data

#### [Submission URL](https://github.com/ArroyoSystems/arroyo) | 89 points | by [necubi](https://news.ycombinator.com/user?id=necubi) | [27 comments](https://news.ycombinator.com/item?id=36214393)

Arroyo is a distributed stream processing engine designed with Rust to efficiently execute stateful computations on data streams. The engine offers real-time streaming operations, including windows and joins, with state checkpointing for fault-tolerance and recovery of pipelines. Arroyo provides a web UI, API, and console for pipeline management. The engine is designed to run on modern cloud environments, supporting seamless scaling, recovery, and rescheduling and is built to enable non-experts to build real-time data pipelines. Arroyo is licensed under Apache-2.0 and MIT.

Arroyo is a distributed stream processing engine built from Rust, designed to execute stateful computations on data streams efficiently, with windows and joins, and state checkpointing. The engine was developed to enable non-experts to build real-time data pipelines, and comes with a web UI, API, and console for pipeline management. Discussions about Arroyo revolved around how it compares to Apache Flink and Kafka's KSQL. In particular, Arroyo was praised for its ability to scale and recover seamlessly on modern cloud environments, while Materialize was touted as a good alternative for view maintenance and ClickHouse for a backend. Discussions also touched on the documentation's mention of how events arriving after the watermark can be dropped, with comments pointing out that it is configural and soon will be altered to provide richer semantics of late arriving events. The engine's name which in Spanish means 'stream' was also brought up in discussions, and people shared the various meanings of Arroyo, ranging from seasonal desert streams to rivers. Additionally, there were brief discussions of other Rust-based developments such as TBlogs' tinybird and Arroyo's alternative to Apache KSQL, Confluent.

### Next-Generation CAMM, Mr-DIMM Memory Modules Show Up at Computex

#### [Submission URL](https://www.anandtech.com/show/18893/next-generation-camm-mr-dimm-modules-at-computex) | 22 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [6 comments](https://news.ycombinator.com/item?id=36213242)

ADATA demonstrated potential candidates for replacing traditional SO-DIMMs and RDIMMs/LRDIMMs, at the Computex 2023 trade show in Taipei. These new memory modules include Compression Attached Memory Modules (CAMMs) for ultra-thin notebooks and compact desktops; Multi-Ranked Buffered DIMMs (MR-DIMMs) for servers; and CXL memory expansion modules for machines that need extra system memory. The CAMM specification is slated to be finalized by JEDC later this year, and it promises benefits such as higher transfer rates, lower costs, higher DRAM density, reduced thickness, and dual-channel connectivity on a single module. MR DIMM technology promises to start at 8,800 MT/s with Gen1, then evolve to 12,800 MT/s with Gen2, and then to 17,600 MT/s in Gen3. Meanwhile, CXL memory modules feature a Compute Express Link and connect to host CPUs via a PCIe interface, expanding system memory for servers at a relatively low cost.

The discussion thread for the submission on ADATA's new memory modules includes several comments discussing the potential benefits and drawbacks of the technology. One user jokes about the naming convention for MR-DIMMs, while another suggests that CAMMs could be beneficial for Apple's expandable computers. A user proposes the idea of a "RAM Box" that could connect to a computer's system through Thunderbolt or USB4, while another user discusses the technical details of memory mapping and PCIe interfaces. Finally, one user disputes the claim that CAMMs offer significantly increased memory throughput, arguing that current CPUs do not support the high transfer rates that CAMMs are capable of.

### GGML – AI at the Edge

#### [Submission URL](http://ggml.ai) | 831 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [212 comments](https://news.ycombinator.com/item?id=36215651)

GGML is a tensor library for machine learning that enables large models and high performance on commodity hardware. Its features include automatic differentiation, built-in optimization algorithms, integer quantization support, and more. It is optimized for Apple Silicon, and can simultaneously run multiple instances of large models on a single chip. Whisper.cpp and llama.cpp are two projects that use GGML, and allow for high-performance speech-to-text and language model inference, respectively. GGML is open source and freely available under the MIT license, and the company behind it is seeking to hire full-time developers.

GGML is a tensor library designed for large models and high performance in machine learning. It comes with features like automatic differentiation, built-in optimization algorithms, integer quantization support, and is Apple Silicon optimized. Discussions revolve around related projects such as Llama and Whisper.cpp, which are focused on speech-to-text and natural language inference, respectively. Additionally, issues related to funding and backing are discussed, with some expressing hope for more support for open-source projects and concerns about the impact of closed-source competition. There are also discussions on practical applications of machine learning and the challenges of working with private data.

### Nvidia releases new AI chip with 480GB CPU RAM, 96GB GPU RAM

#### [Submission URL](https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/) | 370 points | by [logicchains](https://news.ycombinator.com/user?id=logicchains) | [277 comments](https://news.ycombinator.com/item?id=36209047)

NVIDIA has announced the Grace Hopper Superchip, a CPU designed specifically for giant-scale AI and high-performance computing applications. The superchip offers up to 10 times the performance of standard CPUs for heavy-duty tasks, such as running terabytes of data. Its features include a 900 GB/s coherent interface, 30 times the system memory bandwidth to GPUs compared to the NVIDIA DGX A100, and compatibility with all NVIDIA software stacks and platforms, from HPC to AI. The chip is already part of the NVIDIA HGX for AI and HPC, as well as the NVIDIA BlueField-3. It joins more than 400 configurations of NVIDIA architectures being produced to support the widespread demand for AI.

Nvidia has introduced a new CPU called the Grace Hopper Superchip, specifically designed for giant-scale AI and high-performance computing applications. The chip offers up to 10 times more performance than standard CPUs and has 30 times the system memory bandwidth to GPUs compared to the Nvidia DGX A100. Commenters discussed the history of supercomputers and computer memory and debated the significance of the Grace Hopper Superchip for the AI and high-performance computing industry. Some pointed out that the chip's compatibility with all Nvidia software stacks and platforms could be a game-changer. Others discussed the high-speed IO and the slow growth of available memory, indicating that building cards with 100GB RAM would be of little use to businesses. Overall, commenters were interested in the advancement of technology and the implications of this new CPU for the industry.

### Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields

#### [Submission URL](https://jonbarron.info/zipnerf/) | 142 points | by [netuffresche](https://news.ycombinator.com/user?id=netuffresche) | [41 comments](https://news.ycombinator.com/item?id=36208942)

Zip-NeRF is a recently proposed technique by a group of researchers at Google, aimed at improving the training and rendering of Neural Radiance Fields (NeRF), which is a method for generating photorealistic 3D models. The new approach combines grid-based representations and mip-NeRF 360, and uses multisampling to accurately approximate conical frustums and eliminate aliasing, resulting in error rates that are 8-77% lower than previous techniques. The approach also trains 24x faster than mip-NeRF 360. Overall, Zip-NeRF represents a significant advancement in the field of computer graphics and has the potential to provide improved realism and accuracy to 3D models.

A group of researchers at Google have proposed a new technique called Zip-NeRF which improves on the training and rendering of Neural Radiance Fields (NeRF) for photorealistic 3D models. The technique uses multisampling to approximate conical frustums and eliminate aliasing, leading to up to 77% lower error rates and 24x faster training times than previous methods. The discussion includes comments from people who have experience with NeRF and related techniques, with suggestions for optimizing and using the models. Some users also discuss issues related to motion blur and camera stability in the generation of 3D models. A few commenters add links to related papers or implementations.

### Preparing for the Incoming Computer Shopper Tsunami

#### [Submission URL](http://ascii.textfiles.com/archives/5543) | 552 points | by [kencausey](https://news.ycombinator.com/user?id=kencausey) | [132 comments](https://news.ycombinator.com/item?id=36206526)

If you're a tech aficionado, chances are you've heard of Computer Shopper, a magazine that served as the unofficial "bible" of computer hardware and software to the general public throughout the 1980s and 1990s. Despite its widespread popularity, the magazine is notoriously difficult to digitize due to its huge page count, cheap paper, and small gutters. However, one enthusiast decided to take on the challenge and purchased a collection of nearly 200 issues from an eBay auction for a few thousand dollars. While the prospect of digitizing the magazines seemed daunting, it was a small price to pay for preserving a fascinating piece of computer history.

A collection of almost 200 issues of popular computer magazine Computer Shopper has been purchased by a technology enthusiast in an eBay auction to preserve this important piece of computer history. However, digitizing the magazine is said to be a difficult task due to its sheer size, small gutters and cheap paper used. The comments section praises the work of those who are involved in preserving computer history, with some giving examples of the challenges of technology from the past, such as non-compatible components, IRQ conflicts, flappling plastic jumpers, and farmers almanacs. Others also reminisce the days of building their own computers and the nostalgia it brings.

### MeZO: Fine-Tuning Language Models with Just Forward Passes

#### [Submission URL](https://github.com/princeton-nlp/MeZO) | 138 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [21 comments](https://news.ycombinator.com/item?id=36216532)

Princeton University's Natural Language Processing group has developed a new memory-efficient optimizer that fine-tunes language models (LMs) using just forward passes. Dubbed MeZO, the method adapts the zeroth-order SGD method to operate in-place, thus improving memory efficiency for tasks such as LM fine-tuning. The team claims their solution can train a 30-billion parameter OPT model using just a single A100 80GB GPU, while fine-tuning with Adam can only train a 2.7-billion parameter LM. MeZO reportedly performs comparably to fine-tuning with backpropagation, with memory reduction of up to 12 times.

Princeton University's Natural Language Processing group has developed MeZO, a memory-efficient optimizer that allows for language model fine-tuning using just forward passes. MeZO is an adaptation of the zeroth-order SGD method to operate in-place, requiring less memory for fine-tuning tasks. The team claims that their solution can train a 30-billion parameter OPT model using just a single A100 80GB GPU, while fine-tuning with Adam can only train a 2.7-billion parameter LM. The discussion on Hacker News explores various aspects of the method, including its comparison with backpropagation, its potential for swarm optimization, and the significance of its memory-reducing capabilities. There are also discussions around other related topics such as forward-forward algorithms and inference vs. training speed.

### visionOS

#### [Submission URL](https://developer.apple.com/visionos/) | 96 points | by [soheilpro](https://news.ycombinator.com/user?id=soheilpro) | [87 comments](https://news.ycombinator.com/item?id=36208735)

Apple has announced visionOS, a new platform for designing and developing apps and games for its upcoming Apple Vision Pro. It offers an infinite spatial canvas for experimentation, exploration and play, and enables developers to create fully immersive environments or fluid experiences that can seamlessly transition between a 3D window and a fully immersive scene. The platform includes windows, volumes and spaces, and leverages familiar frameworks and tools such as SwiftUI, RealityKit, ARKit and Unity. The visionOS SDK will be released later this month, along with Xcode, the visionOS Simulator, Reality Composer Pro, documentation, sample code and design guidance.

Apple has released visionOS, a new platform for designing and developing apps and games for the Apple Vision Pro, which offers a fully immersive experience with familiar frameworks and tools such as SwiftUI, RealityKit, ARKit, and Unity. Commenters discussed various related topics, such as the use of 3D elements in standard HTML, the use of POSIX for full-stack development, and the possibility of using a global standard for 3D elements. Others talked about potential killer apps for watchOS, the health implications of screen time, the challenges of AR and VR technologies, and the need for better standards for augmented and virtual reality. Some commenters also discussed Furcadia, a 20-year-old game that uses 2D graphics.  Overall, the discussion covered a variety of topics related to the recent release of visionOS and the broader issues facing developers and users of augmented and virtual reality technologies.

### We reported a security issue in AWS CDK’s eks.Cluster component

#### [Submission URL](https://garden.io/blog/aws-security-issue) | 59 points | by [Orzelius](https://news.ycombinator.com/user?id=Orzelius) | [9 comments](https://news.ycombinator.com/item?id=36213332)

A security issue in AWS CDK's eks.Cluster component, dating back to 2020, was recently discovered and reported by engineers who were using AWS CDK to deploy infrastructure as code. The issue allowed any identity with "sts:assumeRole" permission in an AWS account to assume the "creationRole," undermining access management facilities. The AWS CDK team quickly addressed the issue and released fixed versions, v2.80.0 and v1.202.0, on May 20th. The engineers who reported the issue work at Garden, which just raised a Series A funding round and has been working on a solution to simplify the process of setting up a remote development cluster.

A security issue was discovered and reported by engineers using AWS CDK to deploy infrastructure as code. The issue allowed any identity with "sts:assumeRole" permission in an AWS account to assume the "creationRole," undermining access management facilities. The AWS CDK team quickly addressed the issue and released fixed versions. Some users discussed the need for AWS to have CVEs for tracking security vulnerabilities in real-time and practicing restricted identity access. Others discussed the importance of following trust policies and role definitions to prevent security vulnerabilities unless default implied trust policies are modified explicitly. Additionally, some users stressed that it is necessary to have a depth of knowledge about good trust policies and ground-level permissions of security vulnerabilities.

### Redditor creates working anime QR codes using Stable Diffusion

#### [Submission URL](https://arstechnica.com/information-technology/2023/06/redditor-creates-working-anime-qr-codes-using-stable-diffusion/) | 568 points | by [samizdis](https://news.ycombinator.com/user?id=samizdis) | [94 comments](https://news.ycombinator.com/item?id=36218281)

A Reddit user named "nhciao" has created functional QR codes using the Stable Diffusion AI image-synthesis model that reflect artistic styles in anime and Asian art. Despite the presence of intricate AI-generated designs and patterns, smartphone camera apps on both iPhone and Android are still able to read them as functional QR codes. Stable Diffusion is an AI-powered image-synthesis model released last year that can generate images based on text descriptions. Ordinary black-and-white QR codes could be turned into unique pieces of art with this technique, enhancing their aesthetic appeal.

Summary:

A Reddit user has used Stable Diffusion AI image-synthesis model to create QR codes with artistic styles in anime and Asian art without compromising functionality. Stable Diffusion AI is an image-synthesis model that can generate images based on text descriptions. By using this technique, an artist can create unique QR codes, enhancing their aesthetic appeal. The comments section discussed other topics like different kinds of QR codes, their historical development, and their correct labeling. Furthermore, others discussed the limitations and reliability of Machine Learning (ML) algorithms and its effects on QR code implementations. One user pointed out that generating images through Stable Diffusion AI is impressive and can be used on products other than QR codes. Another user mentioned that the aesthetics of anime and Asian art is distinct and might create different interpretations.

### Vector Database in a Jupyter Notebook

#### [Submission URL](https://zilliz.com/blog/exploring-magic-vector-databases-jupyter-notebooks) | 69 points | by [fzliu](https://news.ycombinator.com/user?id=fzliu) | [6 comments](https://news.ycombinator.com/item?id=36207009)

In this article, the author explains the concept of vector databases and their usefulness in powering similarity search applications. They particularly highlight the need for vector databases in solving one of the main challenges that large language models (LLMs) face, which is a lack of domain knowledge and up-to-date data. The article then goes on to explain how to use Milvus (Lite) in your Jupyter Notebook, a vector database with a distributed system native backend that is purpose-built to handle indexing, storing, and querying vector data at a billion scales. The author provides step-by-step instructions on how to get started with Milvus (Lite) and shares resources for those who want to use a standalone vector database instance.

The comments on the submission include some discussions about related topics. One commenter shared a YouTube link that could be helpful for those interested in vector databases. Another commenter mentioned the importance of vector databases in natural language processing (NLP) applications and machine learning model integration. They provided examples of vector databases beyond semantic text search, including spatial data and structured data vectorization for machine learning. The conversation then shifted to personal introductions and networking, with one commenter expressing interest in learning more about the Semantic Kernel.

### AI will save the world?

#### [Submission URL](https://pmarca.substack.com/p/why-ai-will-save-the-world) | 178 points | by [kjhughes](https://news.ycombinator.com/user?id=kjhughes) | [348 comments](https://news.ycombinator.com/item?id=36214781)

are high, but the potential benefits of AI are monumental. With AI augmentation of human intelligence, every person could have an AI assistant/coach/mentor/advisor/therapist that is infinitely knowledgeable and helpful, and every leader of people could make better decisions with the help of AI advisors. This could lead to faster scientific breakthroughs, new technologies and medicines, and even a golden age for the creative arts. Additionally, AI could improve warfare by reducing wartime death rates dramatically. Far from destroying the world, AI may be the key to saving and improving it in countless ways.

The submission argues that despite the fear surrounding AI taking over jobs, the potential benefits of AI are monumental. The comments, however, discuss the difficulty of finding candidates who are two, three, or even five times more efficient due to AI's increasing role in the workforce. Many argue that while AI may lead to job displacement, it is not an infallible replacement for human workers. AI may also create new job opportunities, such as AI advisor or coach, and improve certain industries, such as the creative arts. There are also comments that point out the historical tendency for technological advancements to increase efficiency and reduce the need for manual labor. Some argue that the fear of AI as a job destroyer is short-sighted, and that it is important for individuals to continue to develop their skills to adapt to the changing job market. Ultimately, while AI may lead to job displacement, it has the potential to create new job opportunities and bring significant economic benefits.

### Apple releasing segmentation/pose for humans and animals, embedding for 27 lang

#### [Submission URL](https://developer.apple.com/wwdc23/topics/ml-vision/) | 216 points | by [sumodm](https://news.ycombinator.com/user?id=sumodm) | [70 comments](https://news.ycombinator.com/item?id=36209014)

Apple's WWDC23 sessions offered in-depth explorations of machine learning and computer vision, with a focus on Apple's Core ML, Create ML, and Vision frameworks. Sessions delved into topics such as animal pose detection, 3D body pose and person segmentation, lifting subjects and developing live camera-tracking experiences. Create ML's updates in image understanding, text-based tasks with multilingual BERT embeddings, and multi-label classification were also discussed. Labs offered one-on-one appointments with Apple engineers to discuss machine learning in app development, and Q&A sessions let attendees ask questions on topics including image understanding and machine learning more broadly.

Apple's WWDC23 sessions focused on machine learning and computer vision, with an emphasis on Apple's Core ML, Create ML, and Vision frameworks. One Hacker News user was skeptical of the usefulness of pose detection exercises for personal fitness, while others noted that many fitness apps already use similar technology. Some users discussed the benefits and drawbacks of building apps specifically for Apple's platform vs. creating platform-agnostic software. One user suggested that Apple's subscription-based business model is geared towards retaining existing customers. Other users shared their experiences with various fitness apps and platforms.

### GitHub Copilot and the Methods of Rationality (2022)

#### [Submission URL](https://www.freshpaint.io/blog/github-copilot-and-the-methods-of-rationality) | 57 points | by [luu](https://news.ycombinator.com/user?id=luu) | [32 comments](https://news.ycombinator.com/item?id=36209574)

art observing some buggy behavior of Copilot? Or does it simply need more training data to understand certain types of prompts? Perhaps it's a combination of both.

In any case, one thing is clear from these experiments: being as specific as possible when writing prompts for Copilot can go a long way in getting it to generate the code you need. Additionally, it seems like giving Copilot a function signature can help it understand what you're trying to accomplish.

But as for the open questions mentioned at the beginning of the post, it seems like there's still a lot to explore when it comes to using Copilot effectively.

The article discusses the use of OpenAI's Copilot and reports on some buggy behavior observed while using it. Specificity in writing prompts and providing function signatures were reported to aid in generating the required code; however, there is still a lot to explore when it comes to using Copilot effectively. The comments discuss the importance of context when using Copilot and suggest that it may not work well for complex tasks or specific programming languages. While some users have found Copilot to be a time-saver, others have had varying experiences with its performance and suggest that it needs more training data. Concerns about its licensing and the use of GPT models were also discussed.

### Phishing Darknet Users for Bitcoins

#### [Submission URL](https://shufflingbytes.com/posts/ripping-off-professional-criminals-by-fermenting-onions-phishing-darknet-users-for-bitcoins/) | 100 points | by [campuscodi](https://news.ycombinator.com/user?id=campuscodi) | [58 comments](https://news.ycombinator.com/item?id=36212480)

A hacker has developed a Proof of Concept of a method for stealing from fraudsters operating on the darknet. The Onion Fermenter (OF) uses traffic modifying reverse proxy to create fake darknet sites and redirect transactions to the hacker's wallet, ensuring there are no breadcrumbs for investigators to follow. Darknet sites have no central trusted source for checking legitimacy and descriptions cannot differentiate between fake and real, making it easy to plant sites for the unwary. Other phishing attempts have previously been reported, but OF can be deployed quickly and easily across Kubernets making it potentially far more lucrative.

A hacker has created a Proof of Concept for a method of stealing from fraudsters on the darknet. The method, called Onion Fermenter (OF), uses traffic modifying reverse proxy to create fake darknet sites and redirect transactions to the hacker's wallet. The discussion includes arguments about the moral and legal justification for stealing from criminals, with some people calling for consistent moral codes to be applied across all situations. One commenter pointed out that high-trust societies respect themselves and play by their own moral codes, while others argued against vigilantism. The discussion also included technical details about the effectiveness of the OF method and the perception of different games and crimes. Finally, the discussion touched on the topic of phishing schemes and how they exploit the unwary on the darknet.

### AI: Nvidia Is Taking All the Money

#### [Submission URL](https://seekingalpha.com/article/4609485-ai-nvidia-is-taking-all-the-money) | 71 points | by [TradingPlaces](https://news.ycombinator.com/user?id=TradingPlaces) | [29 comments](https://news.ycombinator.com/item?id=36214749)

Nvidia Corporation has dominated the AI hardware and software market with their GPUs and software since 2012, making them a major target for competitors. Their GPUs have enabled exponential growth in AI model size, allowing them to charge high prices for their data center GPUs with a 75% gross margin. Microsoft's cloud operating margin has been impacted by the cost of Nvidia GPUs, and the cost to run large models in production has drastically increased due to Nvidia's monopoly. While competitors are working on non-GPU hardware, smaller models, and new software, it will be difficult for them to knock Nvidia off its perch as the default for AI research.

Nvidia's dominance in the AI hardware and software market is causing frustration among investors and impacting Microsoft's cloud operating margin. Competitors are working on non-GPU hardware, smaller models, and new software, but it will be difficult to knock Nvidia off its perch as the default for AI research. The discussion covers the finite demand for AI and how the high cost of Nvidia GPUs is impacting the industry. AMD is viewed as a potential competitor to Nvidia, but CUDA remains the industry standard. There is hope for a standardized software that does not require special customization and incentives for using non-Nvidia devices in AI training and inference.

### Hyperparameter Optimization for LLMs via Scaling Laws

#### [Submission URL](https://arxiv.org/abs/2302.00441) | 81 points | by [Lindizz](https://news.ycombinator.com/user?id=Lindizz) | [12 comments](https://news.ycombinator.com/item?id=36210727)

Researchers from the field of computer science and machine learning have proposed a new method called Deep Power Laws (DPL) to optimize hyperparameters of machine learning algorithms. The method utilizes an ensemble of neural network models conditioned to provide predictions that follow a power-law scaling pattern. The DPL method dynamically selects which configurations to pause and train incrementally, making use of grey-box evaluations. The researchers compared their method with 7 state-of-the-art competitors on 59 diverse tasks related to tabular, image, and NLP datasets. They achieved the best any-time results, obtaining the best results compared to all competitors.

The submission discusses a new method called Deep Power Laws (DPL) proposed by researchers for optimizing hyperparameters of machine learning algorithms. The discussion in the comments includes various strategies for hyperparameter optimization, including starting with a default configuration and using Hyperband, DL1, and Bayesian search methods. Additionally, some users commented on the use of smaller models with dynamic budgets and configurations, while others discussed the specific application of DPL for NLP and computer vision datasets. Some users also expressed issues with hyperparameter optimization and the need for more research in this area.

### Tips for better coding with ChatGPT

#### [Submission URL](https://www.nature.com/articles/d41586-023-01833-0) | 150 points | by [isingle](https://news.ycombinator.com/user?id=isingle) | [104 comments](https://news.ycombinator.com/item?id=36211250)

OpenAI's chatbot, ChatGPT, is a powerful AI tool that researchers can use to debug code, translate software from one programming language to another, and perform rote operations. However, users must remember that chatbots are not intelligent; they are stochastic parrots that randomly echo what they have seen before. Therefore, it is critical to use caution when working with ChatGPT and related tools based on large language models. Here are six tips to maximize the utility of chatbots in coding: choose your applications wisely, trust but verify their responses, read responses carefully, test them thoroughly, keep up with software engineering, and use them as a conversational interface to Stack Overflow.

OpenAI's ChatGPT, a powerful AI tool, could be used by researchers to debug code, translate software from one programming language to another, and perform rote operations; however, users must remember that chatbots are not intelligent but instead are stochastic parrots that randomly echo what they have seen before. The discussion among Hacker News users provided mixed opinions on the utility of ChatGPT in coding, with some calling it productive and helpful, and others describing it as useless or requiring context and business requirements. Some commentators noted that large language models (LLMs) have difficulty answering complex questions or tasks that require specific domain knowledge. There were also discussions on the potential risks of using AI tools like ChatGPT and the importance of context in interpreting its responses.

### First impressions: Yes, Apple Vision Pro works and yes, it’s good

#### [Submission URL](https://techcrunch.com/2023/06/05/first-impressions-yes-apple-vision-pro-works-and-yes-its-good/) | 276 points | by [thatsso1999](https://news.ycombinator.com/user?id=thatsso1999) | [530 comments](https://news.ycombinator.com/item?id=36207705)

Apple has previewed its new mixed reality headset, the Apple Vision Pro, and after a 30-minute demo, industry insiders are impressed with its capabilities. With an eye-tracking and gesture control feature recognised as perfect, and the ability to pass-through a real-time 4K view of the world around the user, the headset is being applauded for eliminating issues of long-session VR or AR wear by passing through an image and including a "breakthrough" mechanism to warn of intruders. Though priced at the high end at $3,500, insiders see it as a power users' device and believe it has the potential to be a new computing mode.

The submission discusses Apple's new mixed reality headset, the Apple Vision Pro, and its impressive capabilities. The comments include discussions about Apple's past successes and the potential success of the headset, as well as comparisons to previous technologies such as the iPhone and iPod. Some commenters are skeptical about the high price of the headset and whether it will appeal to a broad audience, while others believe it has the potential to be a new computing mode and replace laptops or even TV. Overall, there are mixed opinions about the potential success of the Apple Vision Pro and its place in the current market.

### A confession exposes India’s hacking industry

#### [Submission URL](https://www.newyorker.com/news/annals-of-crime/a-confession-exposes-indias-secret-hacking-industry) | 102 points | by [fortran77](https://news.ycombinator.com/user?id=fortran77) | [66 comments](https://news.ycombinator.com/item?id=36206746)

Geneva-based private investigator Jonas Rey has found evidence of a vast and thriving Indian cyberattack industry, according to The New Yorker. Rey was hired by British law firm Burlingtons to investigate the possibility of Aziman-born American entrepreneur Farhad Azima having had his email account hacked. Citizen Lab had identified BellTroX, based in New Delhi, as a large hacking-for-hire operation, a finding which Rey's own probe confirmed. This and more has now established “beyond dispute” the presence of a wide Indian hacking-for-hire operation.

The submission to Hacker News discusses the confirmation of a large hacking-for-hire operation called BellTroX, located in New Delhi, India. The article highlights the findings of private investigator Jonas Rey who was investigating whether a businessman's email account had been hacked. The conversation in the comments section covers various topics, including the reputation of India's IT support departments, the prevalence of black hat attacks, the language proficiency of Indians, the historical use of the term "pagan," and the underrepresentation of Indian hackers on GitHub. Some users also discuss the differences between Hinduism and Abrahamic religions.

### Sextortionists are making AI nudes from your social media images

#### [Submission URL](https://www.bleepingcomputer.com/news/security/sextortionists-are-making-ai-nudes-from-your-social-media-images/) | 38 points | by [nazgulsenpai](https://news.ycombinator.com/user?id=nazgulsenpai) | [27 comments](https://news.ycombinator.com/item?id=36219621)

The FBI has alerted the public to a disturbing new trend in sextortion attacks. Scammers are taking publicly available images of their targets from social media and using them to create AI-generated sexually explicit content. While these images and videos are not real, they look very convincing and can be used to blackmail victims into paying money or sending real sexually explicit content. This trend has also impacted minors. To protect oneself, the FBI advises that parents monitor their children's online activity, adults restrict viewing access to a small private circle of friends, and anyone who discovers deepfake content of themselves on pornographic sites should report it to the authorities and contact the hosting platform for removal.

The article is about the FBI warning people about a new trend in sextortion where scammers are using publicly available images of their targets from social media to create AI-generated sexually explicit content. The discussion on the article includes various opinions. Some people believe that AI-generated content completely eliminates the risk of revenge porn as it offers an alternative perspective and provides plausible alternatives. Others think the problem is with social norms and standards that objectify and degrade women. Moreover, scammers and people willing to pay for such content should be held accountable. However, some think that people need to take personal responsibility for their online activity, and they shouldn't be sharing private information publicly. Additionally, there was a mention of deepnude, a now-defunct AI service that used to generate nude images of women. Some people also talk about their personal experiences or the wider cultural landscape where nudity is either sensationalized or prohibited. Finally, some commenters suggested that AI-generated content could create new forms of art and entertainment while others expressed concern about ethical implications.

### Healthcare org with over 100 clinics uses GPT-4 to write medical records

#### [Submission URL](https://www.theregister.com/2023/06/06/carbon_health_deploys_gpt4powered_tools/) | 29 points | by [beardyw](https://news.ycombinator.com/user?id=beardyw) | [9 comments](https://news.ycombinator.com/item?id=36215907)

Carbon Health, a US healthcare chain, has introduced an AI tool for generating medical records automatically. Dubbed Carby, the tool is powered by OpenAI's latest language model, GPT-4. If a patient consents to having their meeting recorded and transcribed, the audio recording is passed to Amazon's AWS Transcribe Medical cloud service, which converts the speech to text. The transcript is then passed to an ML model that produces notes summarising important information gathered in the consultation. Carbon Health claims the tool produces consultation summaries in four minutes, compared to the 16 minutes it takes a single doctor to do it; clinics can therefore see more patients.

There were a few discussions about Carbon Health's AI tool for generating medical records. Some users were surprised that the healthcare providers allowed patient data to be sent to OpenAI given HIPAA regulations. However, it was noted that OpenAI's security page claims to have experience with helping customers meet regulatory industry requirements such as HIPAA. There was also a discussion about how the tool uses AI to produce consultation summaries in four minutes, which is much faster than a single doctor taking 16 minutes to do it. While some were skeptical about the accuracy of generative AI models, Carbon Health claimed that physicians verified 88% of the AI-generated text and made edits for the remaining 12% of the time. Finally, there was a discussion on the legal and privacy implications of using AI in healthcare, with some mentioning that Eric Schmidt, former CEO of Google, predicted in 2018 that AI will be widely used in healthcare in the future.

### Show HN: Free Ngrok Alternative

#### [Submission URL](https://hello.ports.live) | 8 points | by [fghxz](https://news.ycombinator.com/user?id=fghxz) | [4 comments](https://news.ycombinator.com/item?id=36217565)

Liveports: Get Your Localhost App Online Instantly with Custom Domain Name Support

Liveports is a free http tunnel that allows you to get your localhost app online in an instant, with no API keys or login required. With persistent cloud tunnel setup and custom domain name support, it also lets you view your request/responses with its built-in debug viewer. Additionally, you can request for higher throughput and set up multiple tunnels on a single host. To get started, simply install liveports with `pip3 install liveports` and follow the instructions for custom domain setup with a CNAME entry. Feedback is appreciated, and you can get the source code and support with a small contribution.

The article discusses a tool called Liveports, which is a free http tunnel that allows you to get your localhost app online instantly. Users can simply install Liveports with "pip3 install liveports" and follow the instructions for custom domain setup with a CNAME entry. The tool offers a persistent cloud tunnel setup and custom domain name support, and you can also request for higher throughput and set up multiple tunnels on a single host. Users in the comments suggest alternative tools, such as Zrok, a Python SDK, or using SSH tunneling with tools like PingGYIO. Some users praised the advantage of SSH tunneling for not requiring subscriptions or registrations and offering persistent tunnels that start when the user boots up their computer.

### Apple Vision

#### [Submission URL](https://stratechery.com/2023/apple-vision/) | 379 points | by [simonpure](https://news.ycombinator.com/user?id=simonpure) | [542 comments](https://news.ycombinator.com/item?id=36211788)

Yesterday at WWDC, Apple announced their new mixed reality headset called the "Vision" with a planned ship date of early 2024 and a price tag of $3,499. Tech analyst Ben Thompson had the opportunity to demo the device and found the hardware and experience better than expected, exceeding his high expectations. The Vision is technically a VR device that experientially is an AR device, which utilizes 12 cameras to capture the outside world and displaying them to the eyes in a way that feels like wearing safety goggles. The device boasts a speed of displaying images to the eyes in 12 milliseconds or less thanks to the Apple-designed R1 processor and the integration with Apple's software.

Yesterday at WWDC, Apple announced their new mixed reality headset called the "Vision" with a planned ship date of early 2024 and a price tag of $3,499. The device is technically a VR device that gives the experience of an AR device, with 12 cameras to capture the outside world and display it back to the wearer in a safety-goggle-like manner. The AI-generated summary also includes commentary from Hacker News users discussing the announcement, with varied opinions on the device's potential, concerns about the impact of technology on real-world interactions and relationships, and comparisons to other VR/AR headsets. Some users expressed excitement about the technology's potential, while others voiced concerns about the impact on society and human connections.

