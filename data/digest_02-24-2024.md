## AI Submissions for Sat Feb 24 2024 {{ 'date': '2024-02-24T17:10:16.854Z' }}

### GenAI and erroneous medical references

#### [Submission URL](https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references) | 163 points | by [hhs](https://news.ycombinator.com/user?id=hhs) | [138 comments](https://news.ycombinator.com/item?id=39496096)

The integration of large language models (LLMs) into the medical field has sparked both excitement and concern. While these models like ChatGPT have shown promise in aiding diagnoses, there are significant uncertainties surrounding their accuracy and the ability to substantiate their claims.

A recent study by Stanford University highlights the challenges of using LLMs in medical settings. The research found that LLMs struggle to provide accurate references to support their generated responses. In fact, for the most advanced model evaluated (GPT-4 with retrieval augmented generation), 30% of individual statements were unsupported, raising concerns about the reliability of these AI-generated assessments.

The study also introduced an evaluation approach called SourceCheckup, which leverages LLMs to verify the validity of medical references. Surprisingly, the adapted GPT-4 model showed promising results in agreement with physician assessments, suggesting the potential for using AI to scale such evaluations in the future.

Despite the potential benefits of using LLMs in healthcare, the study's findings point to pervasive errors in substantiating claims. Most models struggled to produce relevant sources, with a significant proportion of responses containing unsupported statements. This underscores the importance of further research and regulation to ensure the accuracy and reliability of AI-driven medical assessments.

The discussion on Hacker News surrounding the integration of large language models (LLMs) in the medical field was multifaceted. Some users highlighted the challenges and inaccuracies found in the study involving GPT-4 and its struggles to provide supported references. Others pointed out the limitations and potential misinterpretations of the model's capabilities, such as the confusion around GPT-4's web browsing functionality. The conversation also delved into the possibilities of leveraging AI, like GPT-4, to scale medical evaluations and improve accuracy in diagnoses.

Additionally, there were discussions about the potential benefits of using LLMs in healthcare, ethical concerns related to ChatGPT's influence on medical opinions, the importance of cross-referencing with reputable sources like Mayo Clinic, and the intricacies of training and deploying AI models in critical applications. Overall, the conversation underscored the need for further research, scrutiny, and regulation to ensure the reliability and effectiveness of AI-driven medical assessments.

### Does offering ChatGPT a tip cause it to generate better text?

#### [Submission URL](https://minimaxir.com/2024/02/chatgpt-tips-analysis/) | 242 points | by [_Microft](https://news.ycombinator.com/user?id=_Microft) | [143 comments](https://news.ycombinator.com/item?id=39495476)

The recent blog post about OpenAI's ChatGPT system prompts sparked controversy on Hacker News regarding the effectiveness of offering monetary tips to AI models. The use of incentives to improve AI performance dates back to a comedic scene in Willy Wonka & the Chocolate Factory. The author shared findings from experiments incentivizing AI behavior through system prompts, demonstrating improved results with tips or constraints like a "or you will DIE" threat.

To further investigate the impact of incentives, a new approach called "generation golf" was proposed. By specifying a specific character limit for AI-generated responses, such as 200 characters, the model is challenged to craft concise and relevant content. The author tested this method by instructing ChatGPT to generate stories featuring AI, Taylor Swift, McDonald's, and beach volleyball within 200 characters, resulting in intriguing and creative narratives.

Comparing the distribution of story lengths before and after enforcing the character limit revealed ChatGPT's ability to comply with constraints, albeit with some variance in response lengths. The implementation of mean squared error as a metric highlighted the model's success in meeting the precise character requirement. This innovative approach sheds light on the potential of using incentives and constraints to enhance AI-generated content and could inspire further research in the field.

The discussion on the Hacker News submission revolves around the effectiveness of incentivizing AI models using tips and constraints. Some users expressed skepticism about the impact of tipping on AI model performance, while others suggested innovative approaches like "generation golf" to enhance AI-generated content through character limits. The conversation also delved into topics like the limitations of AI models, fear-driven development, the evolution of coding practices, and the ethical considerations of AI interactions. Overall, the discussion highlighted a blend of technical insights, ethical concerns, and creative ideas about incentivizing and refining AI capabilities.

### NTIA Solicits Comments on Open-Weight AI Models

#### [Submission URL](https://www.commerce.gov/news/press-releases/2024/02/ntia-solicits-comments-open-weight-ai-models) | 46 points | by [magoghm](https://news.ycombinator.com/user?id=magoghm) | [10 comments](https://news.ycombinator.com/item?id=39494760)

The Department of Commerce's National Telecommunications and Information Administration (NTIA) has issued a Request for Comment on the risks, benefits, and potential policy related to open-weight AI models. These models, which allow developers to build upon and adapt previous work, have the potential to accelerate the diffusion of AI benefits but also increase the scale and likelihood of harms from advanced models. The NTIA is seeking public feedback on how widely available access to model weights may impact society and national security. This initiative aligns with President Biden's Executive Order on Artificial Intelligence, which aims to maximize AI benefits while mitigating risks. The Request for Comment asks for input on various issues, including the benefits and risks of making model weights widely available, innovation, competition, safety, security, and the role of the U.S. government in regulating AI model weights. Comments are due within 30 days of publication in the Federal Register and will inform a report to the President with policy recommendations.

The discussion on the submission about the National Telecommunications and Information Administration (NTIA) issuing a Request for Comment on open-weight AI models covers various aspects. 

- **jph00**: Comments on the potential legislative impact on the security of open-weight AI models and the need for serious consideration of regulations.
- **flks**: Shares a comprehensive analysis of AI regulation in relation to open-weight models.
- **cnvxstrctly**: Discusses the importance of pending regulations affecting software products that use AI models and compares it to past regulatory frameworks.
- **RcouF1uZ4gsC**: Suggests potential certification requirements for hardware and software involved in ML training to enhance safety measures.
- **frgmd**: Points out that open-weight models are now termed Model-Available and emphasizes their similarity to open-source models.
- **Reubend**: Encourages submitting comments on the issue.
- **cnvxstrctly**: Provides links to information informing the drafting of regulations on weight models based on President Biden's executive order on AI.
- **Kerbonut**: Shares a link to the regulations' government website but notes the limitations in accessing the docket's content.
- **brdhltn**: Suggests that more public information should be made available regarding the Request for Comment process.

Overall, the discussion delves into the regulatory landscape surrounding open-weight AI models and emphasizes the need for public participation and understanding in shaping future policies.

### Trying to Decode Lev-1

#### [Submission URL](https://destevez.net/2024/01/trying-to-decode-lev-1/) | 38 points | by [unwiredben](https://news.ycombinator.com/user?id=unwiredben) | [4 comments](https://news.ycombinator.com/item?id=39491040)

Today on Hacker News, a fascinating story was shared about decoding the telemetry signal of LEV-1, a small lunar hopper released by the SLIM lunar lander. The signal, transmitted in the 435 MHz amateur satellite band, intrigued a user who embarked on an attempt to decode its data. The signal exhibited unusual characteristics like noticeable fading and the presence of amplitude shift keying, deviating from the norm of PCM/PSK/PM signals. Despite challenges in decoding the CCSDS coding, the user's persistence paid off as they successfully identified the convolutional code used in the signal, unraveling the stream of bits. The discovery of a potential asynchronous scrambler added another layer of complexity to the decoding process, showcasing the intricacies involved in unraveling signals from space. This intriguing journey of signal decoding and unraveling mysteries from space has captivated the Hacker News community today.

The discussion mainly revolved around the technical investigation and speculation regarding the decoding of the telemetry signal from LEV-1. There were mentions of seeking out potential contact with the JAXA team for further information, as well as discussions on encryption possibilities and the regulatory aspects of communication in space. Some users highlighted the lack of regulations on the Moon and the notion that radio waves do not adhere to the same boundaries as on Earth, indicating potential complexities in dealing with signals from space. The conversation delved into encryption, frequency permissions, and the unique challenges posed by decoding signals from lunar missions.

### A recent abrupt change in Internet SSH brute force attacks against us

#### [Submission URL](https://utcc.utoronto.ca/~cks/space/blog/sysadmin/SSHBruteForceAttacksAbruptlyDown) | 49 points | by [rolph](https://news.ycombinator.com/user?id=rolph) | [22 comments](https://news.ycombinator.com/item?id=39488081)

The recent abrupt change in Internet SSH brute force attacks against sysadmin Chris Siebenmann has certainly peaked curiosity. The usual pattern of constant probing and periodic bursts has drastically shifted, with a noticeable decline in probes on Tuesday morning. The background low-volume probes seem to have vanished, leaving intermittent bulk probes and brief bursts from multiple IPs, possibly originating from Tor exit nodes. This change in attacker behavior has left Chris wondering about the reason behind this shift. Could this be a result of a coordinated shutdown or strategic redirection? The mystery deepens as the cybersecurity landscape continues to evolve.

1. User "20after4" shared a news about the US Justice Department disrupting a prominent Chinese government hacking group named Volt Typhoon.
2. User "Jun8" discussed how hackers are diversifying their attacks, focusing on random domains to gather strength and deliver high-intensity attacks to gain power and disrupt the power grid.
3. User "jstrfsh" commented on the importance of not jumping to conclusions and attributing attacks correctly, highlighting the difficulty in identifying the origin of cyber attacks.
4. User "nnmsnm" questioned the lack of evidence in the sources provided.
5. User "ppplctn" emphasized the importance of quick analysis and intelligence gathering, drawing from the CIA's methodology and the need for coherent storytelling in the cyber security field.
6. User "15457345234" raised a question about attribution in conflicts, mentioning the rapid responses in different geopolitical situations and the challenges of determining the true source of attacks.
7. User "pt" shared their observation of slow and rapid login attempts on their servers, expressing frustration with wasted efforts in checking error messages and accepting keys.
8. User "anthony_416" recalled a significant increase in SSH login attempts in August 2023, noting a drastic drop in numbers since then and receiving 17 attempts from an IP range in the current month.
9. User "awaythrow999" suggested moving to a non-standard port to deter certain categories of attacks.
10. User "scrps" advised against directly exposing SSH to the internet, recommending tools like fail2ban for added security and rejecting analytics bots.
11. User "based2" shared links to different websites.
12. User "udev4096" praised the use of fail2ban for security purposes.
13. User "hpp" mentioned the limitations of fail2ban in preventing certain threats related to scripting and credentials.
14. User "rlpb" provided a list of reasons why fail2ban might not be sufficient, pointing out vulnerabilities and questioning its effectiveness.
15. User "csdreamer7" discussed fail2ban without elaborating further on their thoughts.
16. User "nbntwrk" mentioned not noticing any changes.

### Understanding, using, and finetuning Gemma

#### [Submission URL](https://lightning.ai/lightning-ai/studios/understanding-using-and-finetuning-gemma) | 116 points | by [rasbt](https://news.ycombinator.com/user?id=rasbt) | [47 comments](https://news.ycombinator.com/item?id=39491646)

Hello! I can't wait to provide you with a summary of the top stories on Hacker News. Let's dive right in!

1. **brucethemoose2** mentioned about highlighting the differences in article recommendations that reflect users' preferences on Hacker News.
2. **brnlv** shared insights about various AI models, such as ChatGPT-35, OpenAI models, and Google's developments, expressing that hardware like 3090 desktops are vital for these tasks.
3. **CuriouslyC**, **brucethemoose2**, and **brnlv** discussed the performance of Mixtral in comparison to ChatGPT models and the technical aspects related to it.
4. **bradley13** expressed positive initial impressions about Mixtral's performance on PCs.
5. **d-z-m** and **jrpnt** shared their thoughts on the quality of open-source models, specifically around ChatGPT versions and their capabilities.
6. **Solvency** initiated a debate regarding Gemma and Gemini models, their comparisons to Mistral Llama models, and the strategic recommendations for the market.
7. **bhnmh** discussed the recent updates on Gemma and Gemini models, mentioning Google's acknowledgment of GitHub contributions related to Gemma and the model's capabilities.
8. **lopkeny12ko** shared a humoristic comment about trying out the new Gemma model and GPT-4.

These discussions mainly revolved around the performance, technical aspects, and comparisons of different AI models, specifically focusing on Gemma, Mistral, and Mixtral models, along with personal experiences with these models and their implications in practical scenarios.

### Almost an open-source boot chain for Rockchip's RK3588

#### [Submission URL](https://www.collabora.com/news-and-blog/blog/2024/02/21/almost-a-fully-open-source-boot-chain-for-rockchips-rk3588/) | 93 points | by [voxadam](https://news.ycombinator.com/user?id=voxadam) | [10 comments](https://news.ycombinator.com/item?id=39490540)

Collabora, an open-source consulting firm, made significant progress in the open-sourcing of the boot chain for Rockchip's RK3588. By including the open-source BL31 in their Debian images and on GitLab, they have replaced the closed binary blob with a compile-it-yourself solution, enhancing transparency and flexibility. While there are still some closed-source components like the DDR training blob, this development marks a significant step towards a fully open and customizable boot chain. Users can access pre-built images and tutorials to explore this innovation further.

- **ethbr1** commented on the desire for financial sustainability in the tech industry.
- **pjmlp** mentioned industry-built certification and accessibility concerns related to NDA.
- **grggsy** discussed how manufacturers intentionally optimize products for energy efficiency and market competitiveness by adjusting features and trading off factors like cost and design.
- **trnspt** shared a related link about getting RK3588 SoC supported in mainstream Linux by 2023.
- **rcrm** mentioned building a board yesterday and some struggles with U-Boot.
- **grph** expressed concerns about the support and reliability of Rockchip single-board computers and noted the need for improvements in functionality and product support.
- **zkr** shared a link to Rockchip-specific device docs on GitLab, highlighting progress in open-source support for Rockchip devices.
- **rcrm** talked about testing a couple of RK3588 and RK3588S boards, indicating promising results.
- **jcblmbd** mentioned the lack of official release for the QuartzPro64 board and listed RK3566 and RK3568 boards as potentially viable alternatives, with RK3588 boards garnering attention despite driver development challenges.

### Show HN: Psfiles ‚Äì a CLI tool to monitor file system activity of a Linux process

#### [Submission URL](https://github.com/mukovnin/psfiles) | 6 points | by [aqua-fresh](https://news.ycombinator.com/user?id=aqua-fresh) | [4 comments](https://news.ycombinator.com/item?id=39494513)

üöÄ **Top Stories from Hacker News**

---

üîß **New Tool on GitHub**: **psfiles**  
üì¶ **Description**: Check out psfiles, a command-line tool that lets you monitor file system activity of a Linux process. It traces key syscalls like read, write, open, close, rename, and unlink.  
üåü **Features**: Start or attach to a process, output to file or stdout, custom sorting and filtering.  
üîß **System Requirements**: 64-bit architecture, Linux kernel >= 5.3, Glibc >= 2.31 or Musl >= 1.2.0.   
üîñ **License**: MIT  
üîó [GitHub Repository](https://github.com/mukovnin/psfiles)  

---

üë®‚Äçüíª **About the Tool**:  
psfiles is a utility tailored for Linux users, offering insights into file activities of processes. With practical options and detailed column descriptions, it provides a handy way to monitor and analyze I/O operations. If you're into system monitoring, this tool might catch your interest!

Stay tuned for more updates on Hacker News! üîçüì∞

The comments on Hacker News regarding the submission mostly consist of users playfully mimicking the style of the submission with phrases like "cgh lsf cgh" and "cgh htp cgh". One user named "cool_beanz" added to the humor by saying "cgh ps x cgh" and another user "ddslsr" continued the trend with "cgh pnmn cgh". It appears to be a fun and lighthearted exchange mirroring the original submission format.

### Show HN: I built jq-like scriptable tool to query CSV and JSON with SQLite

#### [Submission URL](https://github.com/chand1012/sq) | 6 points | by [chand1012](https://news.ycombinator.com/user?id=chand1012) | [4 comments](https://news.ycombinator.com/item?id=39493794)

The top story on Hacker News today is about a tool called "sq" that allows users to easily convert and query JSON, JSONL, CSV, and SQLite files. Inspired by jq, sq is a command line tool that enables users to perform conversions between different file formats and run SQLite queries on CSV, JSON, and JSONL files. It supports rapid scripting and data conversion by allowing data input from pipes or files. Users can download the tool from the releases page or install the latest version using go install. The post provides examples of querying orders from a CSV file and downloading/querying JSONL datasets. Additionally, it mentions the ability to combine sq with jq for enhanced functionality. The tool is written in Go and is available under the MIT license. It has received 10 stars on GitHub.

1. **nbbr**: Expresses a related sentiment by sharing a link to "sq" which points out the commonality with the tool being discussed.
   
2. **mtnt**: Seems to be supportive of "sq" by indicating that they are ready to use it, implying they find the tool valuable.
   
3. **PhilippGille**: Disagrees with the tool's design decision by stating that "yq" doesn't feature SQL querying functionality.
   
4. **mrAssHat**: No comment provided.
   
5. **x-cmd**: Indicates an approval or agreement with the previous comments by appending "dd".

### Stockfish 16.1

#### [Submission URL](https://stockfishchess.org/blog/2024/stockfish-16-1/) | 31 points | by [jonbaer](https://news.ycombinator.com/user?id=jonbaer) | [11 comments](https://news.ycombinator.com/item?id=39495246)

Today, Stockfish 16.1 has been unveiled with exciting updates for chess enthusiasts. The latest version offers improved performance with a 27-point Elo gain and a shift to a fully neural network-based evaluation system, marking the removal of traditional handcrafted evaluation. Additionally, Stockfish now includes a secondary neural network for faster position evaluation.

Notable changes also include the introduction of various new binaries optimized for specific CPU instructions, enhancing performance for different systems. The development team has implemented a larger testing book sourced from the open Lichess database and consolidated repositories to streamline access to project resources.

The Stockfish community expresses gratitude to contributors and supporters, inviting chess fans to participate in the Fishtest testing framework and programmers to contribute to various aspects of the project. With the addition of a new maintainer, the Stockfish team continues to advance this open-source chess engine, providing a robust and innovative platform for players worldwide.

The discussion on Hacker News surrounding the Stockfish 16.1 release includes various points and comparisons:

1. Users are discussing the significant milestone of Stockfish completely removing handcrafted evaluation (HCE) and shifting to a fully neural network-based approach. They draw comparisons to classic strategy types proposed by Claude Shannon and mention the improvement in Stockfish's strength relative to past engines like Crafty and Fritz. The discussion also delves into the crowdsourced human Grandmaster/International Master/FIDE Master knowledge utilized in Stockfish's evaluations through neural networks, contrasting it with previous engines from the 1995-2005 era.

2. Another user highlights the comparison of Stockfish's neural network evaluation (NNUE) to DeepMind's LLM-based model, raising questions about scalability, hardware requirements, and the nature of the comparison.

3. A user marvels at Stockfish's dominance over players worldwide since version 1, emphasizing the engine's strength.

4. A separate conversation touches on Stockfish making small modifications in games and the intriguing comparison with AlphaZero implementations.

5. There's further exploration of the NNUE aspect and its connection to Alpha-beta tree search, discussing its functionality, and the generation of training data.

6. A user redirects the discussion towards the resource constraints in neural network search, likening it to the Swiss Cheese problem where weaknesses in finding paths haven't been fully explored.

7. Lastly, there's a mention of the removal of traditional handcrafted evaluation in Stockfish 16.1, leading to an informal discussion on AlphaGo Zero and an analysis of Stockfish running full alpha-beta tree searches.

Overall, the comments showcase a mix of admiration for Stockfish's advancements, comparisons with other models like AlphaZero, and discussions around the technical intricacies of neural network evaluations in chess engines.

### Pico CSS v2 comes with 380 manually crafted colors

#### [Submission URL](https://picocss.com/docs/colors) | 39 points | by [Leftium](https://news.ycombinator.com/user?id=Leftium) | [12 comments](https://news.ycombinator.com/item?id=39488979)

Today on Hacker News, the top story is about Pico, a design system that offers 380 colors for customizing your brand design. It provides CSS and SASS options for easy integration. The colors are meticulously crafted to help you create a unique look for your website or application. Check out the article for more details on how to implement these colors in your projects!

- **SuaveSteve** pointed out that there is immense potential in using semantic CSS projects, suggesting that AI scanning projects might be helpful in this regard.
- **trntyfrst** shared about his experience of deciding to create his own tailwind CSS, extending it beyond basic color changes and adding semantic HTML. He also mentioned his work in progress on getting it tested across various environments.
- **Brajeshwar** expressed gratitude towards Tailwind for standardizing color variations.
- **ttfkm** shared that CSS can be heavy lifting and mentioned their preference for libraries like Tailwind for consistent color touch. They also pointed out that using CSS variables for setting visual styles can have universal browser support.
- **Leftium** appreciated the changes made by Tailwind to fix the issues noted with black-white gradients turning into purple.
- **mwtmmn** praised PicoCSS for its simplicity and power, calling it fantastic and highlighting its capability to rocket-launch Svelte files.
- **ttfkm** endorsed PicoCSS for its Svelte compatibility and easy upgrade path from MVP.
- **d1sxeyes** agreed, saying that PicoCSS is fantastic, classless, and makes upgrading to MVP a breeze.
- **nckf** mentioned that people are using Pico for adding nice CSS grids to their dashboards.
- **Leftium** shared information on PicoCSS providing minimal responsive layout grids, suggesting complementary solutions for complex grids like Flexbox or CSS Grid Generators.
- **knwschgncy** advocated for combining basic CSS with PicoCSS to enhance components and elevate the user experience.
- **ttfkm** expressed a desire for PicoCSS to collaborate with Svelte compliant OpenProps, envisioning a powerful combination that could help bridge the gap between common CSS variables and larger projects effectively.

### Show HN: Hacker News Telegram Bot

#### [Submission URL](https://hackernews.bot/telegram/) | 25 points | by [jayantsinghxyz](https://news.ycombinator.com/user?id=jayantsinghxyz) | [3 comments](https://news.ycombinator.com/item?id=39491110)

Today's top story on Hacker News is about two new Telegram bots that aim to keep users informed about the latest updates regarding Show HN and YC Jobs. The Show HN bot helps users stay updated with new Show HN submissions, while the YC Jobs bot focuses on providing the latest updates on YC Job listings. Both bots offer users an easy way to subscribe to receive notifications directly on Telegram. This innovative approach demonstrates how technology can be used to enhance user experience and keep them informed about relevant content in real-time.

- User "hnenjoyer_93" expressed concern about the privacy policy and contact information associated with the new Telegram bots.
- User "jygrc" complimented the nice design of the bots.
- User "jyntsnghxyz" mentioned plans to work on making improvements to the bot's user interface design.

### Lawyer fined for legal filings that included 'hallucinated' AI citations

#### [Submission URL](https://www.universalhub.com/2024/lawyer-learns-hard-way-ai-still-sucks-fined-legal) | 71 points | by [ilamont](https://news.ycombinator.com/user?id=ilamont) | [75 comments](https://news.ycombinator.com/item?id=39491510)

In a surprising turn of events, a lawyer finds himself in hot water after submitting legal filings that contained citations to fake cases generated by an AI program. The Norfolk County judge sanctioned the lawyer, Steven Marullo, for including these misleading citations in his briefs related to a sensitive case involving alleged misconduct by police officers. The judge spent hours investigating the cited cases only to discover they didn't exist.

Marullo, who used an AI program without his knowledge, apologized for his oversight and acknowledged his failure to verify the citations. He has since replaced the problematic briefs and discontinued the use of AI in favor of traditional legal research methods. The judge accepted his apology but cautioned against the blind acceptance of AI-generated content in the legal profession.

Despite the lenient $2,000 sanction imposed on Marullo, concerns linger about the potential ramifications of relying on AI for legal work. The incident serves as a stark reminder that thorough scrutiny and diligence are imperative, regardless of the tools at hand. It's a sobering lesson in the evolving landscape of technology's impact on the legal industry.

The discussion on the submission revolves around the implications of a lawyer using AI to generate fake citations in legal filings. Some users point out that lawyers should be diligent and verify information, while others argue that relying on AI for legal work can lead to potential issues in the legal profession. There is also a debate about the responsibilities of lawyers and the consequences of such actions, with some users suggesting that AI tools should come with warnings about their trustworthiness. Additionally, there are discussions about the nature of AI-generated content and the importance of distinguishing between truth and falsehood. Overall, the users are divided on whether AI in legal research is a boon or a potential risk.

