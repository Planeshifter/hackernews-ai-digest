## AI Submissions for Fri Nov 29 2024 {{ 'date': '2024-11-29T17:11:51.975Z' }}

### Breaking the 4Chan CAPTCHA

#### [Submission URL](https://www.nullpt.rs/breaking-the-4chan-captcha) | 432 points | by [hazebooth](https://news.ycombinator.com/user?id=hazebooth) | [222 comments](https://news.ycombinator.com/item?id=42276865)

In an intriguing dive into machine learning, a developer shares their journey to create a model capable of deciphering the notoriously tricky 4Chan CAPTCHA with over 80% accuracy, reaching the code's realm on GitHub. The project aimed not just at enhancing TensorFlow expertise but also at testing the limits of AI in solving CAPTCHAs—those digital puzzles meant to separate humans from bots.

The creator details the challenges of scraping CAPTCHAs from 4Chan, including clever strategies to bypass Cloudflare's barriers and requests that tweak how data is gathered over time. The CAPTCHAs from 4Chan come in two varieties: standard alphanumeric images and the more complex slider style, both of which are frustrating even for human users. Notably, this exploration revealed that while computers could align the slider CAPTCHAs with ease, human solvers from a commercial service struggled, often returning incorrect answers—revealing just how difficult these challenges can be for people.

Through a meticulous process of data collection and model training, the developer not only sought accuracy but also learned about the nuances of CAPTCHA design and the limitations of human input in this context. This engaging case study encapsulates not only a technical feat but also reflects on the broader implications of CAPTCHA technology in the realm of internet security and user experience.

The discussion surrounding the submission on Hacker News delves into the complexities of CAPTCHA technology and AI's role in solving these digital puzzles. Users express opinions on the implications of breaking CAPTCHAs, not just from a technical perspective, but also considering the ethical and economic ramifications. 

Several commenters shared their experiences with CAPTCHA systems and highlighted how certain CAPTCHAs can be more challenging for humans than AI. There's a notable debate about the efficiency of various methods to bypass CAPTCHAs, with some claiming that they could generate substantial revenue through CAPTCHA-breaking services. 

Others reflected on the job market implications, stressing the need for AI and machine learning skills in developing solutions to internet security issues while noting the competitive landscape in these fields. Many acknowledged the resource-intensive nature of sophisticated CAPTCHA systems that are increasingly designed to thwart automation.

Furthermore, some discussions included criticisms and thoughts on CAPTCHA's effectiveness and usefulness, especially in terms of distinguishing between human users and bots. The exchange reflects a mix of technical insights, personal anecdotes, and broader discussions on the future of CAPTCHA technology and its relationship to AI.

### Core copyright violation moves ahead in The Intercept's lawsuit against OpenAI

#### [Submission URL](https://www.niemanlab.org/2024/11/copyright-claim-moves-ahead-in-the-intercepts-lawsuit-against-openai/) | 269 points | by [giuliomagnifico](https://news.ycombinator.com/user?id=giuliomagnifico) | [293 comments](https://news.ycombinator.com/item?id=42273817)

In a significant legal development, The Intercept's copyright infringement lawsuit against OpenAI has taken a step forward as a New York federal judge has ruled that a critical claim involving a potential violation of the Digital Millennium Copyright Act (DMCA) will proceed. This decision follows the dismissal of similar claims from other digital news organizations, indicating a complex legal landscape surrounding AI and copyright.

Judge Jed Rakoff has agreed to hear The Intercept's accusation that OpenAI improperly removed authorship details while incorporating its articles into the training data for ChatGPT. This practice may contravene the DMCA, which protects authorship information and digital rights. Although the judge dismissed claims regarding OpenAI's alleged distribution of these articles and ruled out claims against Microsoft, the core DMCA claim against OpenAI remains viable.

The broader implications of this case resonate within a context where many digital publishers struggle to register their works with U.S. Copyright Office due to the burdensome process. Just recently, regulatory changes aimed at allowing bulk registrations have come too late for many. Meanwhile, The Intercept represents a distinctive legal strategy that might encourage other publishers to follow suit, especially as they grapple with similar challenges posed by powerful AI systems utilizing their content without compensation.

As legal debates sharpen over the use of journalistic articles in AI training, publications like Raw Story and AlterNet are also seeking to adapt their claims in light of recent rulings to ensure their rights are safeguarded. The outcome of these cases could redefine copyright protections in the era of AI, raising pivotal questions about the future of digital journalism and its intersection with technology.

In the comments on Hacker News regarding The Intercept's copyright infringement lawsuit against OpenAI, users discussed the implications of copyright laws in relation to AI technologies, particularly generative models. Many expressed concerns about how large corporations, like Disney or Microsoft, might monopolize intellectual property rights, making it increasingly difficult for smaller companies and independent creators to navigate the complex landscape of copyright law.

Some commenters suggested that existing copyright laws favor large entities, providing them with significant advantages in enforcing their rights, while stifling innovation and fair use for smaller creators. There was a consensus that the current system may be unsustainable, as it disproportionately benefits bigger companies, leading to disproportionate lengths of copyright terms that may not reflect the public interest or the contributions of individual creators.

The discussion also touched upon the balance needed between protecting creators' rights and allowing for public access to creative works, especially in an age where generative AI is capable of creating content based on existing works. Several participants argued for copyright reform to foster innovation while also ensuring fair compensation and recognition for creators.

Overall, the comments reflected a strong concern regarding how the evolving relationship between AI and copyright could reshape the future of digital content creation and ownership rights.

### Llama.cpp guide – Running LLMs locally on any hardware, from scratch

#### [Submission URL](https://steelph0enix.github.io/posts/llama-cpp-guide/) | 347 points | by [zarekr](https://news.ycombinator.com/user?id=zarekr) | [80 comments](https://news.ycombinator.com/item?id=42274489)

In a newly updated guide on Hacker News, SteelPh0enix dives into the exciting world of running large language models (LLMs) locally, offering a comprehensive look at using llama.cpp from the ground up. Initially skeptical of the AI hype, the author shares their journey from experimenting with models like ChatGPT to ultimately transitioning to open-source alternatives. With a new RX 7900 XT GPU in hand, they discovered the capabilities of LM Studio and the crucial role of quantization in making LLMs accessible even on less powerful hardware.

The guide is filled with practical advice for those interested in self-hosting LLMs, clarifying misconceptions about hardware requirements. Contrary to popular belief, the author points out that you don't necessarily need a high-end GPU—modern CPUs can suffice, and even devices like Raspberry Pis can run LLMs, albeit with limited performance. 

Prospective users will find answers to common questions about performance expectations and the feasibility of replacing commercial LLM offerings with self-hosted alternatives. For those looking to explore the open-source side of AI while maintaining control over their work, this guide serves as an invaluable resource. Whether you're running on high-end GPUs or just your laptop, the potential to delve into the world of AI is more accessible than ever.

In a vibrant discussion on Hacker News surrounding SteelPh0enix's guide to running large language models (LLMs) with llama.cpp, users exchanged experiences and practical insights on setting up and optimizing their local LLMs. Here are the key takeaways from the conversation:

1. **Building and Configuration**: Several users shared tips on how to build and configure llama.cpp, particularly for different operating systems like macOS, Windows, and Ubuntu. Instructions typically included cloning the repository, running the make command, and configuring hardware settings to support specific models.

2. **Performance and Hardware Requirements**: A common theme was the feasibility of running LLMs on less powerful hardware. Some participants mentioned successfully operating LLMs on older machines with modest specs, which sparked discussions on performance expectations and configuration tweaks.

3. **Ease of Use and Accessibility**: Users emphasized how the guide and related tools are making AI experiments more accessible, even for those without extensive GPU resources. Tools like Ollama and Open Web UI were mentioned as user-friendly interfaces that facilitate working with LLMs locally.

4. **Practical Experiences**: Participants shared their own experiences with LLM performance, including successful interactions with smaller models and the results of their tests. Some noted that while running LLMs could be slow on older setups, the outputs were often impressively coherent.

5. **Community Resources**: The discussion highlighted the importance of community-driven resources, such as links to GitHub repositories and additional guides for troubleshooting and benchmarking models. Users encouraged each other to explore different LLMs and configurations to find the best setups for their needs.

Overall, the conversation was a mix of technical troubleshooting, sharing success stories with various setups, and reinforcing the community's collective knowledge about self-hosting AI models.

### Prometheus 3.0

#### [Submission URL](https://prometheus.io/blog/2024/11/14/prometheus-3-0/) | 197 points | by [dmazin](https://news.ycombinator.com/user?id=dmazin) | [36 comments](https://news.ycombinator.com/item?id=42274660)

The Prometheus Team has officially launched Prometheus 3.0, a significant upgrade after a seven-year gap since the last major release. First unveiled during PromCon in Berlin, this version enhances the cloud-native monitoring tool with a refreshed user interface (UI), improved interoperability with OpenTelemetry, and new features aimed at enriching user experiences.

Key highlights include:

- **Revamped UI**: The newly designed UI offers a cleaner look, advanced navigation options, and improved functionality, all while maintaining stabilization for legacy setups. Users can still revert to the old interface if needed, though it may not be as polished.
  
- **Remote Write 2.0**: This upgrade introduces new elements like metadata support, better handling of partial writes, and reduced payload sizes, making data ingestion more efficient.
  
- **UTF-8 and OTLP Support**: Prometheus now fully supports UTF-8 metric and label names, alongside enhancements for compatibility with OpenTelemetry's metrics protocol, making the integration seamless and user-friendly.

- **Native Histograms**: A new experimental metric type is designed for efficiency, simplifying the handling of data without the need to manually set bucket boundaries.

While Prometheus 3.0 aims to preserve stability, there are some breaking changes, particularly in configuration and PromQL syntax, so users are advised to consult the migration guide to align their systems.

Notably, performance statistics indicate that version 3.0 boasts notable improvements in CPU and memory usage over its predecessors. The Prometheus community encourages contributions toward future enhancements, implying an exciting road ahead for this essential monitoring tool.

The discussion surrounding the launch of Prometheus 3.0 on Hacker News features a mix of experiences and insights from users with different setups. Here are the key points:

- **User Experiences with Alternatives**: Several commenters mention using alternatives like Victoria Metrics, Mimir, and Thanos, highlighting varying experiences with resource usage and performance. For instance, one user reports a successful setup with Thanos and a manageable resource footprint.

- **General Optimism for Prometheus 3.0**: Users express excitement about upgrading to Prometheus 3.0, particularly due to the expected improvements in resource consumption (memory and CPU). Some believe the new version will better handle large cluster environments.

- **Technical Considerations**: There are discussions about the technical aspects of shifting to Prometheus 3.0, including the risks of breaking changes in configurations and PromQL syntax. Users are encouraged to consult the migration guide.

- **Feature Interest**: The experimental native histograms feature has sparked interest, though some users express disappointment that it isn’t included as a default feature in this major version.

- **Documentation and Communication**: Some users emphasize the need for clearer documentation to help with the transition to version 3.0, indicating that better guidance could alleviate concerns and improve user experience.

Overall, there is a positive sentiment towards the new release, tempered by practical concerns regarding migration and functionality. The community appears eager to explore the enhancements while also sharing insights from their experiences with other monitoring solutions.

### Jank is now running on LLVM IR

#### [Submission URL](https://jank-lang.org/blog/2024-11-29-llvm-ir/) | 82 points | by [Jeaye](https://news.ycombinator.com/user?id=Jeaye) | [13 comments](https://news.ycombinator.com/item?id=42276672)

In an exciting update for the jank programming language, developer Jeaye Wilkerson has announced that jank is now operating on LLVM IR. This significant change came after months of hard work focused on enhancing jank's LLVM IR generation capabilities, refining semantic analysis, and improving the module loading system. As of January 2025, Wilkerson will be dedicating full-time efforts to jank, with support from GitHub sponsors and collaborators at Clojurists Together.

The transition to LLVM IR marked a crucial milestone for jank, allowing for improved performance during startup. Compiling the core library of jank now takes just 2 seconds compared to a staggering 12 seconds with the previous C++ generation method. This optimization not only lowers the initial load times—ultimately bringing it down to as quick as 150 milliseconds—but also permits pre-compilation into object files for even swifter execution.

However, this transition isn’t without challenges. Jank's move to LLVM means addressing potential runtime performance drawbacks, as the library no longer benefits from C++ compiler optimizations. Despite these hurdles, Wilkerson is optimistic that further enhancements can be tailored to maximize jank’s performance over time.

In addition to LLVM IR work, Wilkerson has streamlined jank’s build system, removing dependencies like vcpkg to simplify project management. Overall, this update reflects a promising evolution for jank, indicating that it's on a path toward greater efficiency and robustness as a language.

The discussion on Hacker News revolves around the recent advancements in the jank programming language announced by developer Jeaye Wilkerson. Users expressed excitement and congratulations regarding Jank's transition to LLVM IR, highlighting its potential to enhance performance and improve startup times. Some participants mentioned their experiences with similar functional programming languages, like Clojure, noting challenges in traditional programming paradigms and praising jank for addressing these issues.

Jeaye Wilkerson engaged with the community, discussing his plans to work on jank full-time, aided by financial support and contributions from collaborators. He also outlined the removal of certain dependencies to streamline the build system, which many users found promising for project management. Discussions also touched on the comparative benefits of using jank versus languages like C++ for game development and the simplification of creating native applications. Other comments reflected a blend of optimism and caution regarding jank’s challenges and the broader implications for developers transitioning to functional programming. The discussion concluded with users encouraging the project and praising the innovative directions Wilkerson is pursuing with jank.

### Physics in Next-Token Prediction

#### [Submission URL](https://arxiv.org/abs/2411.00660) | 27 points | by [Anon84](https://news.ycombinator.com/user?id=Anon84) | [4 comments](https://news.ycombinator.com/item?id=42270468)

In a groundbreaking paper titled "Physics in Next-token Prediction," researchers Hongjun An, Yiliang Song, and Xuelong Li explore the intricate connections between machine learning models and fundamental principles of physics. They reveal the concept of information conservation within the mechanism of Next-token Prediction (NTP) and introduce the First Law of Information Capacity (IC-1), illustrating how the rise of intelligence in auto-regressive models is fundamentally a process of information transfer.

Additionally, the authors leverage Landauer's Principle to present the Second Law of Information Capacity (IC-2), which links the training of these models to energy consumption, highlighting the physical costs associated with data processing. Their findings also include practical implications for production practices and show a strong correlation between these new laws and established scaling laws for neural language models. This research not only deepens our understanding of machine learning but also sets the stage for future innovations in the field.

The discussion surrounding the paper "Physics in Next-token Prediction" on Hacker News includes various perspectives on the interplay between physics and machine learning principles.

- One user, **nlkl**, references another paper that connects physics with language modeling, suggesting that there is an ongoing exploration in this domain.
- **AIorNot** comments on the necessity for a solid background in physics and machine learning when analyzing the insights presented in the research. They highlight the complexities of modern model architectures and training methods, noting that these foundational assumptions play a crucial role in the model's capability to absorb and process information efficiently. They also mention a connection to Modified Newtonian Dynamics (MOND), hinting at past physics research predicting phenomena based on similar principles.
- Another commenter, **rob_c**, expresses skepticism about the implications of the research, suggesting that the physics of larger systems might not be necessary for understanding models that operate at different scales, bringing in the notion of qualitative versus quantitative analysis.

Overall, the conversation reflects a blend of appreciation for the theoretical advancements in understanding machine learning through the lens of physics, while also prompting skepticism and debate about the broader applicability and implications of these findings.

### The Deterioration of Google

#### [Submission URL](https://www.baldurbjarnason.com/2024/the-deterioration-of-google/) | 204 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [135 comments](https://news.ycombinator.com/item?id=42277673)

In a thought-provoking blog post, Baldur Bjarnason delves into the troubling decline of independent publishing, particularly spotlighting Google’s algorithm changes and their repercussions on smaller content creators. The recent shutdown of the site Giant Freakin Robot symbolizes a broader trend, with numerous independent publishers facing closure and struggling to survive in a landscape increasingly dominated by algorithm-driven traffic that favors larger, established entities.

Despite attempts to engage directly with Google about this crisis, Bjarnason outlines a concerning disconnect: the tech giant appears indifferent to the plight of smaller publishers. With changes rooted in machine learning designed to enhance search results, many independent sites have effectively been sidelined or “delisted,” leading to dramatic drops in traffic. In an unsettling facet of the situation, even Google’s own engineers seem perplexed about the workings of the algorithm, highlighting a loss of control over their own systems.

This scenario paints a bleak picture for independent creators, many of whom, despite producing high-quality and engaging content, find themselves trapped in a system they cannot navigate or influence. With Google’s monopoly position unchallenged and the broader tech landscape leaning towards greater consolidation, the continuing decline of smaller publishers is a stark warning sign for the future of diverse online content. The struggle of content creators remains a pressing issue in the conversation surrounding the ethical implications of algorithm-driven media distribution.

The discussion surrounding Baldur Bjarnason's blog post on the decline of independent publishing highlights several key points and critiques about Google and its current direction. Here are the main takeaways:

1. **Power Struggles and Algorithm Issues**: Users express concern over Google's shift towards prioritizing algorithm-driven results, which they argue has led to diminishing returns for independent content creators. Many participants mention that Google's leadership lacks a clear vision for navigating this complex landscape.

2. **Perceptions of Google’s Innovations**: Several commenters reflect on Google's past innovations, particularly those from 15 years ago, and contrast these with what they perceive as a decline in product quality and usefulness. There are nostalgic references to how Google's tools, like Docs and Maps, were once groundbreaking but have since stagnated or become less user-friendly.

3. **Rise of Alternative Platforms**: Some users point to emerging platforms, like Kagi, as promising alternatives that aim to bypass the limitations imposed by major search engines. They argue that such platforms may offer more relevant search results by prioritizing different algorithms than Google.

4. **Ad Revenue and Content Creation**: There are discussions surrounding ad tech and revenue generation for content creators, with a sense of urgency about how advertisers' strategies are adapting to the changing landscape. Concerns are raised about content fraud and its impact on independent creators.

5. **Broader Industry Trends**: Commenters also talk about the larger trend of consolidation in the tech industry, further hinting that the struggle for independent publishers is a microcosm of a wider tendency towards monopolization in the online content ecosystem.

Overall, the discussion reflects a deep concern over the future of independent publishing and its ability to survive in a landscape dominated by large tech companies like Google, with many participants advocating for more accountability and a re-evaluation of the systems in place.

