## AI Submissions for Tue Jun 20 2023 {{ 'date': '2023-06-20T17:12:58.204Z' }}

### RoboCat – A Self-Improving Robotic Agent

#### [Submission URL](https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent) | 168 points | by [l1n](https://news.ycombinator.com/user?id=l1n) | [65 comments](https://news.ycombinator.com/item?id=36406139)

DeepMind has created an AI agent called RoboCat, that learns to operate different robotic arms and perform a variety of tasks across different robots and self-generates new training data to improve its technique. The agent uses a multimodal model called Gato, which can process language, images, and actions in both simulated and physical environments. RoboCat learns much faster than other state-of-the-art models, as it can pick up a new task with as few as 100 demonstrations, reducing the need for human-supervised training. This is an important step towards creating a general-purpose robot. Commenters discussed the high costs of building robotic platforms and the difficulties of controlling motors using torque. There was also a debate about the limitations of UI automation tools and the hostility towards the automation sector.

### Building a Slack/Discord alternative with Tauri/Rust

#### [Submission URL](https://www.linen.dev/s/linen/t/12647025/building-a-slack-discord-alternative-with-tauri-rust) | 308 points | by [cheeseblubber](https://news.ycombinator.com/user?id=cheeseblubber) | [221 comments](https://news.ycombinator.com/item?id=36408633)

Linen, a search engine friendly alternative to Slack, has launched its Mac and Windows desktop clients using Tauri, a Rust-based Electron alternative. Tauri promises to yield smaller, more performant, and more secure desktop clients compared to Electron. While Tauri uses a Webview instead of chromium, Linen ran into compatibility challenges with NextJS and had to refactor all their code out of NextJS to a separate package to enable reuse between the NextJS app and the single page app Tauri built. Nonetheless, Linen was able to get a smooth developer experience on Tauri for the desktop, though it faced various challenges such as customizing the header and notification callbacks, among others. The Linux client suffered issues with fonts and emoji not building properly.

The discussion in the comments is centered around the comparison between Electron and Tauri, with some users defending Electron and stating that it works perfectly for them while others agree that Tauri is a more performant and secure alternative. The discussion also touches on the performance and resource usage of Electron versus other alternatives, as well as the issue of the increasing memory usage of modern software. Some users argue that the majority of people care about productivity and fast, snappy programs rather than high school dropouts, and that today's software runs worse on modern hardware while others disagree and say that today's engineers focus on UX features rather than actual performance.

### Predicting hit songs with 97% accuracy

#### [Submission URL](https://www.frontiersin.org/articles/10.3389/frai.2023.1154663/full) | 96 points | by [geox](https://news.ycombinator.com/user?id=geox) | [57 comments](https://news.ycombinator.com/item?id=36403334)

A team of researchers from Claremont Graduate University and Immersion Neuroscience has developed a machine learning model that can predict hit songs based on neurophysiological responses. Traditional methods of identifying hit songs involve measuring song elements from large databases, but the team took a different approach by measuring responses to a set of songs provided by a streaming music service. They found that a linear statistical model using two neural measures identified hits with 69% accuracy, while a machine learning model classified hit songs with 97% accuracy. The results demonstrate that applying machine learning to neural data can substantially increase classification accuracy for difficult-to-predict market outcomes. Some commenters pointed out problems with the small sample size and lack of diversity in songs used for the study, making the results less reliable. Others discussed the importance of properly validating synthetic datasets and the limitations of evaluation metrics like accuracy in imbalanced datasets. Finally, there was a discussion on the music industry and how difficult it is for independent artists and music genres outside of the mainstream to be represented on Billboard's charts.

### vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention

#### [Submission URL](https://vllm.ai/) | 275 points | by [wskwon](https://news.ycombinator.com/user?id=wskwon) | [40 comments](https://news.ycombinator.com/item?id=36409082)

Today, the UC Berkeley team introduced vLLM, an open-source library for fast LLM inference and serving. This library promises to serve LLM models fast, cheaply, and efficiently, even for small research teams with limited compute resources. The team achieved up to 24x higher throughput than HuggingFace Transformers, the most popular LLM library, and up to 3.5x higher throughput than the previous state of the art, HuggingFace Text Generation Inference (TGI), in their experiments. This breakthrough was due to the library's cutting-edge attention algorithm, PagedAttention, which allows for efficient management of the large and dynamic key-value cache necessary for autoregressive decoding. PagedAttention also enabled efficient memory sharing, making complex sampling algorithms practical for LLM services. The library is already deployed at Chatbot Arena and Vicuna Demo and is available on GitHub.

The discussion in the comments includes technical details about the library's attention algorithm, PagedAttention, and its memory optimization techniques. Some users express interest in applying the library to their own projects, while others speculate about its practical use cases and potential limitations. Overall, the community is impressed with the vLLM library's capabilities and looks forward to further developments in the field.

### Show HN: Autolabel, a Python library to label and enrich text data with LLMs

#### [Submission URL](https://github.com/refuel-ai/autolabel) | 143 points | by [nihit-desai](https://news.ycombinator.com/user?id=nihit-desai) | [17 comments](https://news.ycombinator.com/item?id=36409201)

Refuel AI has released a new open-source library called AutoLabel that allows the user to label and clean text datasets with large language models (LLMs). The library supports all GPT-3.5 and GPT-4 models, and users can easily specify labeling guidelines and model parameters in a JSON config. AutoLabel promises to save time and money compared to manual labeling efforts and provides a simple three-step process for labeling data. The library is MIT-licensed and available on GitHub. The main concerns are around privacy when using LLMs and potential inaccuracies in labeling. Some commenters recommend using self-hosted open-source LLMs or the openAI API, while others suggest that AutoLabel could be integrated with function calling to improve the labeling quality. Additionally, a commenter points out that Refuel provides confidence scores for LLMs but does not provide token-level probabilities. The original post on Hacker News linked to a benchmarking report and a GitHub repository. Some commenters note that the post may be self-promotion and not intended to share LLM labeling feedback with the community.

### Petaflops to the People: From Personal Compute Cluster to Person of Compute

#### [Submission URL](https://www.latent.space/p/geohot) | 66 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [10 comments](https://news.ycombinator.com/item?id=36407269)

In the latest episode of Latent Space: The AI Engineer Podcast, host Jade Le and George Hotz of the tiny corp discuss the company's efforts to take on major players like Nvidia, Google, and PyTorch, as well as its recent announcement of the tinybox, a luxury AI computer aimed at local model training and inference. They delve into the technical details of the deep learning framework tinygrad and the importance of optimizing instruction execution for GPU. Additionally, they touch on the potential role of personal compute clusters in the future of home intelligence.

The discussion includes technical details of the deep learning framework, tinygrad and the importance of optimizing instruction execution for GPU. They also touch on the potential role of personal compute clusters in the future of home intelligence. In the comments, there is a detailed discussion about quantization research benchmarks, perplexity testing, Fabrice Bellard's methods, and the challenges with FPGA systems. Additionally, some users express surprise at Hotz's knowledge and fluency in discussing technical details, while others criticize the half-baked implementation of some of his ideas.

### Google warns its own employees: Do not use code generated by Bard

#### [Submission URL](https://www.theregister.com/2023/06/19/even_google_warns_its_own/) | 299 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [152 comments](https://news.ycombinator.com/item?id=36399021)

Google has warned its employees to avoid using code generated by its AI chatbot, Bard, due to privacy and security risks. The move has raised concerns about the suitability and reliability of privately developed AI tools. Developers may not be able to trust AI tools if even the creators themselves don't use them. The search and ads company advised its staff not to disclose confidential information or use code generated by Bard due to potential buggy programs or difficult-to-fix software. Meanwhile, voice recognition software developer Nuance, backed by Microsoft, has been sued by three people for allegedly recording and using people's voices without permission in violation of the California Invasion of Privacy Act.

The comments on Hacker News discussed the risks and implications of monorepos, proprietary data privacy, legal liabilities, the legality of LLMs, and the potential impact on productivity. There were also concerns about copyright infringement and the need for companies to address and mitigate systemic risks. Overall, there were mixed views on the topic, with some emphasizing the need for caution and others stressing the importance of innovation and productivity.

### Stackoverflow is investing into baking GenAI

#### [Submission URL](https://stackoverflow.co/labs/) | 86 points | by [rounakdatta](https://news.ycombinator.com/user?id=rounakdatta) | [101 comments](https://news.ycombinator.com/item?id=36404743)

Stack Overflow Labs, the experimental arm of the popular Q&A website for developers, has been busy exploring the use of AI to improve the platform and developer experience. Some of the projects include: Experiment Question Formatting Assistant, which uses AI to improve the quality and format of questions to make reviewing easier; Title Suggestions, which utilizes AI to generate more descriptive and accurate question titles; and Chat Decipher, which can extract question topics from chat transcripts and group similar ones together. Additionally, the results of Stack Overflow's 2023 Developer Survey shed light on how developers and technologists feel about AI/ML. The website's Senior Data Scientist also delves into the creation of their course recommendation engine powered by AI. Meanwhile, their CEO will be making exciting announcements at the upcoming WeAreDevelopers event. With their mission to give technologists more time to create amazing things and make the coding field accessible to all, Stack Overflow Labs is always looking for new ways to merge emerging technologies with their platforms and services. There has been a discussion in the comments about the hype around blockchain and AI, and how they may be misunderstood and overhyped. There was also a discussion about the effectiveness of Stack Overflow's AI experiments, with some commenters offering criticism and others defending the platform's efforts to utilize AI.

### GPS alternative taps cosmic rays for underground or underwater navigation

#### [Submission URL](https://newatlas.com/technology/gps-alternative-muon-cosmic-rays-underground-underwater-navigation/) | 49 points | by [wjSgoWPm5bWAhXB](https://news.ycombinator.com/user?id=wjSgoWPm5bWAhXB) | [10 comments](https://news.ycombinator.com/item?id=36402086)

Researchers at the University of Tokyo have developed a proof-of-concept navigation system called the muometric wireless navigation system (MuWNS) that uses cosmic rays to track movement underground and underwater with precision of a few metres. Unlike GPS, which bounces signals off rocks, walls, and water, MuWNS tracks particles called muons that pass through solid materials. The particles are generated when cosmic rays enter the Earth’s atmosphere and produce a cascade of secondary particles. By tracking the paths of muons picked up by reference stations and a handheld detector, the scientists were able to trace the scientist's position with a high degree of precision deep inside a multi-story building.

One user points out that the technology is currently expensive and difficult to implement in real-time applications. Another user questions the need for real-time tracking in underground or underwater scenarios and suggests that a stable recording receiver may be more practical. The potential of using the technology in microchip and commercial manufacturing is also discussed, as well as the limitations of the technology in areas without consistent connection. Finally, a user comments on a related underwater experiment in Newfoundland.

