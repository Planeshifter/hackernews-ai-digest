## AI Submissions for Tue Jan 28 2025 {{ 'date': '2025-01-28T17:12:24.333Z' }}

### Promising results from DeepSeek R1 for code

#### [Submission URL](https://simonwillison.net/2025/Jan/27/llamacpp-pr/) | 939 points | by [k__](https://news.ycombinator.com/user?id=k__) | [708 comments](https://news.ycombinator.com/item?id=42852866)

**🚀 Double the Speed for WebAssembly with llama.cpp Optimizations!**

Xuan-Son Nguyen has submitted an impressive pull request to **llama.cpp**, achieving a **2x speed boost** for WebAssembly by optimizing SIMD instructions. While Nguyen focused on developing tests and crafting prompts, the bulk of the code enhancements were contributed by DeekSeek-R1, showcasing a fantastic collaborative effort.

Additionally, Nguyen highlighted the promising results from **DeepSeek R1** in AI-assisted programming. By leveraging DeepSeek R1, he successfully rewrote the `llm_groq.py` plugin to better align with cached model patterns, outperforming previous attempts. This advancement not only streamlines model mapping but also suggests a move towards dynamic model registration, eliminating the need for hardcoded mappings.

These updates mark significant progress in **inference scaling** and the efficiency of **AI models**, paving the way for more robust and faster AI applications. Stay tuned for more exciting developments in the AI and WebAssembly spaces!

*Posted on January 27, 2025*

**Summary of Discussion:**

1. **AI Code Contributions & Metrics:**  
   - **nthrplg** highlights DeepSeek-R1’s role in generating **70% of recent code** for llama.cpp via PRs, with tools like `git blame` tracking AI contributions. Links to [Aider](https://aider.chat/HISTORY.html) show workflows for distinguishing human vs. AI-generated code using git integration and scripts for line-change analysis.  
   - Debate ensues about how to fairly credit AI vs. human contributions, with users sharing scripts (e.g., `--with=semver`) to calculate code authorship stats.  

2. **Political & Ethical Debates:**  
   - **jnplcktt** shares a **JavaScript function** checking if a region is part of China per PRC claims, sparking heated debate. Critics argue this reflects Chinese censorship and AI alignment with state policies.  
   - Broader discussions emerge about **AI censorship**, particularly models like ChatGPT handling sensitive topics (e.g., Taiwan, human rights). Some users accuse AI of parroting geopolitical narratives, while others defend complexities in training data and neutrality.  
   - Meta-debates on **self-determination** and ethics: Should AI avoid political stances? How do global power dynamics influence model outputs?  

3. **Toolchain & Workflows:**  
   - **jshstrng** praises Aider for streamlining git workflows, sparking sidebar discussions on file handling, prompts, and integrating AI into developer tooling.  

**Key Themes:**  
- **AI’s growing role in coding** (metrics, attribution, trust) vs. **ethical/political concerns** (bias, censorship, geopolitical alignment).  
- Tension between AI efficiency and transparency, especially in contentious contexts.

### Machine learning and nano-3D printing produce nano-architected materials

#### [Submission URL](https://news.engineering.utoronto.ca/strong-as-steel-light-as-foam-machine-learning-and-nano-3d-printing-produce-breakthrough-high-performance-nano-architected-materials/) | 55 points | by [gmays](https://news.ycombinator.com/user?id=gmays) | [5 comments](https://news.ycombinator.com/item?id=42857091)

### Breakthrough in Nano-Architected Materials: Strength of Steel, Weight of Foam

Researchers at the University of Toronto have harnessed machine learning and advanced nano-3D printing to create nano-architected materials that rival the strength of carbon steel while maintaining the lightness of Styrofoam. Led by Professor Tobin Filleter, the team employed a multi-objective Bayesian optimization algorithm to design complex carbon nanolattices, overcoming traditional challenges like stress concentrations that lead to material failure.

Using a two-photon polymerization 3D printer, the team successfully fabricated prototypes that doubled the strength of existing designs, achieving a stress resistance five times higher than titanium at substantially lower densities. This innovative approach not only enhances material performance but also promises significant applications in aerospace and automotive industries, potentially reducing fuel consumption and lowering the carbon footprint of transportation.

Collaborating internationally with institutions like KAIST, KIT, MIT, and Rice University, the team’s next steps involve scaling up these designs for cost-effective production and exploring even lighter yet stronger architectures. This pioneering work marks the first application of machine learning in optimizing nano-architected materials, opening new avenues for high-performance, lightweight components in various high-tech fields.

*Read more about this advancement in [Advanced Materials](#).*

**Summary of Discussion:**

The discussion revolves around the technical and practical aspects of creating nano-architected materials, inspired by the breakthrough research highlighted. Key points include:

1. **Fabrication Challenges**: Users note the complexity of nanoscale 3D printing techniques like two-photon polymerization, which enable parallelized printing of intricate structures but face limitations in speed and scalability. Comparisons are drawn to traditional 2D lithography, emphasizing the need for advancements to achieve industrial-scale production.

2. **Scale and Visualization**: Commenters express awe at the size of the nano-architected materials (e.g., "structures approaching the thickness of a human hair," ~100 microns). They debate the limits of light microscopy in visualizing features at sub-200nm scales, highlighting challenges in observing and manipulating components as small as hydrogen atoms (e.g., calculations noting ~5,000 hydrogen atoms could fit within a 500nm line).

3. **Historical and Technical Context**: Richard Feynman’s vision of nanoscale manufacturing is invoked, with users reflecting on how photon-based methods (like those used here) may diverge from his atom-by-atom assembly concepts. Some question whether such techniques can achieve the precision or direct manipulation Feynman envisioned.

4. **Practicality and Applications**: A nested thread discusses recent talks about nanotechnology progress, such as assembling "Waldo-like" structures at 1/10th scale. Users speculate on practical engineering hurdles for scaling these materials, including layering strategies and overcoming physical limits (e.g., light interaction at nanoscales).

5. **Collaboration and Feasibility**: While enthusiasm exists for high-tech applications (aerospace, optics), the discussion underscores unresolved issues in cost-effective production and the need for interdisciplinary collaboration to advance the field.

Overall, the conversation blends technical curiosity with cautious optimism, balancing excitement for revolutionary materials with acknowledgment of the significant scientific and engineering challenges ahead.

### Machine Learning in Production (CMU Course)

#### [Submission URL](https://mlip-cmu.github.io/s2025/) | 479 points | by [azhenley](https://news.ycombinator.com/user?id=azhenley) | [36 comments](https://news.ycombinator.com/item?id=42847834)

**CMU Launches Comprehensive Machine Learning in Production Course for Spring 2025**

Carnegie Mellon University is set to offer its innovative course, **Machine Learning in Production (17-445/17-645/17-745) / AI Engineering (11-695)**, in Spring 2025. Tailored for students with foundational data science and programming skills, this course delves into building, deploying, and maintaining software products powered by machine learning models.

**Key Highlights:**
- **Full Lifecycle Coverage:** From prototype ML models to fully deployed production systems.
- **Responsible AI Focus:** Emphasizes safety, security, fairness, and explainability in AI applications.
- **MLOps Integration:** Teaches automation and scaling of ML deployment processes.
- **Interdisciplinary Collaboration:** Bridges the gap between software engineers and data scientists, fostering effective teamwork.
- **Practical Applications:** Includes case studies like automated medical diagnostics, smart inventory management, and more.

The course is ideal for aspiring ML engineers and those interested in the intersection of software engineering and machine learning. With materials available under a Creative Commons license on [GitHub](https://github.com/mlip-cmu) and an accompanying textbook, CMU encourages other institutions to adopt similar curricula.

**Enrollment Note:** Due to high demand, a waitlist is available. Interested students are advised to contact course administrators for assistance.

Explore more about the course and its offerings through previous semesters' resources and join the forefront of AI engineering education!

*Posted on Hacker News*

**Summary of Hacker News Discussion on CMU’s Machine Learning in Production Course:**

1. **Positive Reception for Practicality**:  
   - Users praise the course’s focus on **industry-standard tools** (Kafka, Docker, Kubernetes) and MLOps concepts as both relevant and timely. The integration of real-world case studies and hands-on development workflows is seen as a strong bridge between theory and production systems.  
   - Several commenters highlight **Christian (the instructor)** and previous course materials as high-quality resources.  

2. **Debates on Tool Relevance**:  
   - Some question whether **Jenkins** is outdated compared to modern CI/CD tools like **GitHub Actions** or **ArgoCD**, though others argue its inclusion helps teach foundational CI/CD principles for beginners.  
   - Discussions note **Docker’s importance** as a basic building block, despite perceptions of complexity early on.  

3. **Emphasis on Data Quality**:  
   - Multiple threads stress that **data quality and pipelines** (cleansing, lineage, transformation) often dominate real-world ML work, with references to industry anecdotes ("90% of time spent on data"). Users appreciate the dedicated chapter but urge deeper exploration of best practices and automation.  

4. **Infrastructure & Scaling Challenges**:  
   - Technical debates emerge on **high-performance ML infrastructure**: networking (RoCE, Infiniband), storage (S3, EFS), model serving latency, and GPU optimization. A commenter shares detailed advice for building end-to-end ML pipelines (training, deployment, monitoring).  

5. **Audience and Difficulty Concerns**:  
   - Some argue the course targets **entry-level learners**, with a focus on basics like Flask, Git, and containers, while mid-career engineers might seek more advanced topics (distributed training, optimizing GPU workloads).  
   - Questions arise about the necessity of a **PhD for MLOps roles**, with mixed views on whether academic credentials matter versus practical software/ML hybrid skills.  

6. **Broader Reflections**:  
   - A recurring theme: **solving business problems** (data access, user workflows) is often harder than technical execution. Tools are secondary to understanding context.  
   - Users express interest in supplementary resources (e.g., LLM Systems course) and **internship pathways** for hands-on experience.  

**Critiques & Suggestions**:  
- Add deeper dives into **modern tool alternatives** (ArgoCD, serverless deployment) and advanced infrastructure (GPU utilization, scalability).  
- Expand coverage of **ML-specific monitoring** and explainability beyond basic implementations.  
- Consider projects tackling large-scale datasets or open-source contributions for real-world impact.  

Overall, the course is seen as a valuable step toward formalizing ML engineering education, even as commenters debate its depth and long-term tooling relevance.

### DeepSeek's multi-head latent attention and other KV cache tricks

#### [Submission URL](https://www.pyspur.dev/blog/multi-head-latent-attention-kv-cache-paper-list) | 274 points | by [t55](https://news.ycombinator.com/user?id=t55) | [69 comments](https://news.ycombinator.com/item?id=42858741)

### **DeepSeek’s Multi-Head Latent Attention and KV Cache Tricks**

**Date:** January 21, 2025  
**Posted:** 1 week ago

**Overview:**  
DeepSeek dives deep into optimizing large language models (LLMs) like ChatGPT by leveraging Key-Value (KV) caches. This approach smartly balances memory usage and computation time, making text generation significantly faster. The guide not only explains the fundamentals of KV caching but also explores 11 cutting-edge research papers, including DeepSeek’s own Multi-Head Latent Attention (MLA), that push the boundaries of efficient LLM inference.

**Why Text Generation Slows Down:**  
Imagine writing a story where each new word requires re-reading the entire text for consistency. As your story grows, so does the time spent re-reading. Similarly, LLMs face increasing computational costs with longer text generation due to the self-attention mechanism, which has a complexity of O(n²) per token. When generating text one token at a time, this leads to an overall complexity of O(n³), making longer texts exponentially slower to produce.

**The KV Cache Solution:**  
KV caching revolutionizes this process by storing pre-computed keys and values for each token, eliminating redundant calculations. Here’s how it works:
- **Key (k):** Acts as an address to determine the relevance of a token to future tokens.
- **Value (v):** Holds the actual information used during token generation.

By caching these, LLMs only compute new keys and values once per token, reducing the overall computational cost from O(n³) to O(n²). This improvement means that generating a sequence twice as long only takes roughly four times as long instead of eight, dramatically enhancing efficiency.

**Memory vs. Speed Trade-Off:**  
While KV caches speed up text generation, they do so at the expense of increased memory usage. For instance, a model like Llama3 70B handling a batch of 8 sequences of 1000 tokens each can require nearly 21GB of memory. This linear growth with sequence length and batch size poses challenges, especially for deployment on memory-constrained devices.

**Innovations and Future Directions:**  
To address memory constraints, the research community, including DeepSeek with its MLA and other KV cache optimizations, is developing new techniques to make efficient use of KV caches. These advancements aim to maintain the speed benefits while mitigating the memory overhead, pushing the frontier of what’s possible with LLMs.

**Conclusion:**  
DeepSeek’s exploration of KV caches and MLA represents a significant stride in making large language models more efficient and scalable. As these optimizations continue to evolve, we can expect even faster and more capable text generation, paving the way for broader applications and more sophisticated AI interactions.

---

*Stay tuned for more insights and top stories from Hacker News in your daily digest!*

**Summary of Discussion:**

- **Formatting & Content Reception:**  
  The article's use of bullet points and concise structure was praised for enhancing readability, with users noting its effectiveness in summarizing complex topics like KV caching and Multi-Head Latent Attention (MLA). Some users speculated that AI tools like Claude or ChatGPT were used to generate sections, which sparked debates about transparency.  

- **Technical Deep Dives:**  
  - Tools like **PySpur** and **ComfyUI** were discussed for workflow automation and visual design, with users highlighting the importance of loop support and intuitive UI in AI pipelines.  
  - **KV Cache Implementation:** Technical clarifications emerged around how frameworks like PyTorch manage KV caching externally, optimizing memory and inference speed. Mentions of **PagedAttention** (vLLM) underscored ongoing improvements in GPU memory efficiency.  
  - **Vector Conventions:** A mini-debate arose on horizontal vs. column vectors in deep learning frameworks, resolved with references to PyTorch/TensorFlow standards.  

- **AI-Generated Content Concerns:**  
  Some users criticized AI-generated articles as repetitive or "spammy," while others defended their utility if structured clearly. Copyright implications of training LLMs on human content were briefly debated, with no clear consensus.  

- **DeepSeek’s MLA & Research Context:**  
  Users requested more specifics on MLA’s technical innovations, leading to a linked paper and refinements to the article’s explanation. The post was appreciated for its practical overview of recent research, even if partially AI-written.  

- **Meta-Conclusion:**  
  Despite mixed opinions on AI authorship, the discussion acknowledged the value of well-structured summaries for distilling complex research. The article’s clarity and depth outweighed ethical reservations for most readers.  

**Takeaway:** The thread reflects Hacker News’ dual focus on technical rigor and skepticism toward AI-generated content, balancing utility with calls for transparency.

### How has DeepSeek improved the Transformer architecture?

#### [Submission URL](https://epoch.ai/gradient-updates/how-has-deepseek-improved-the-transformer-architecture) | 246 points | by [superasn](https://news.ycombinator.com/user?id=superasn) | [65 comments](https://news.ycombinator.com/item?id=42855170)

**DeepSeek v3 Achieves Breakthrough in Transformer Efficiency**

*Published Jan 17, 2025 by Ege Erdil*

DeepSeek has just launched DeepSeek v3, setting a new standard for open-weight models with state-of-the-art benchmark performance. Remarkably, DeepSeek v3 achieves these impressive results using only 2.8 million H800 hours of training hardware—about ten times less compute than the similarly powerful Llama 3.1 405B model.

The secret behind this efficiency lies in two key architectural innovations: **DeepSeekMoE** and **Multi-Head Latent Attention (MLA)**. MLA, an enhancement first seen in DeepSeek v2, significantly reduces the size of the key-value (KV) cache used during long-context inference, outperforming traditional methods like grouped-query attention. This optimization not only cuts down on memory usage but also speeds up token generation without sacrificing model quality.

DeepSeek’s approach transforms how key and value vectors are computed within the Transformer architecture, enabling more efficient processing of extensive contexts. This breakthrough means that DeepSeek v3 can handle longer sequences more effectively, making it a game-changer for applications requiring deep contextual understanding.

For those interested in the technical depths and engineering challenges overcome by DeepSeek, the full technical report is highly recommended. DeepSeek v3 not only pushes the boundaries of what's possible with Transformers but also sets a new benchmark for efficiency and performance in the AI landscape.

---

Stay tuned to our daily digest for more updates on the latest advancements in AI and technology!

**Summary of Hacker News Discussion on DeepSeek v3:**

1. **Efficiency Breakthroughs and Trade-offs**:  
   - Commenters highlight DeepSeek v3’s use of **Mixture-of-Experts (MoE)** and **Multi-Head Latent Attention (MLA)** to reduce compute costs. MLA optimizes KV caching, accelerating inference while maintaining performance.  
   - Some debate whether MoE’s specialization truly optimizes latency or introduces overhead. Others note FP8 precision and memory optimizations as key factors in efficiency.  

2. **Compute Costs and Trends**:  
   - Skepticism arises around claims of “10x less compute” vs. Llama 3.1. Users discuss spiraling costs ($100M-$1B training runs) and the environmental impact of massive clusters.  
   - One user argues efficiency gains save “hundreds of millions” in training, but others counter that model scaling remains economically prohibitive for most.  

3. **Model Size vs. Performance**:  
   - Larger models (e.g., 671B parameters) are praised for understanding complex instructions but criticized for impractical RAM requirements (~750GB). A *Lego metaphor* explains parameter growth enabling complexity but raising infrastructure costs.  
   - Smaller models with retrieval-augmented generation (RAG) are seen as pragmatic alternatives for many use cases.  

4. **Technical Nuances**:  
   - Flash Attention and low-level optimizations are credited for gains, though some dismiss these as incremental. Confusion exists over whether novel techniques (e.g., MLA) are truly groundbreaking or repackaged ideas.  
   - Skeptics demand transparency: *“The report doesn’t mention FP8... needs critical reading.”*  

5. **User Experiences**:  
   - Positive anecdotes surface about DeepSeek models generating Python code effectively, even at smaller scales (7B/32B).  

6. **Tangential Debates**:  
   - Mobile keyboard quirks cause formatting issues (dropped quotes), sparking multilingual tangents.  
   - Critiques of LLM limitations: Hallucinations, conversational awkwardness, and over-reliance on prompting. One user quips, *“Models aren’t conversational... like human interactions.”*  

**Key Takeaway**: While DeepSeek v3’s efficiency gains impress technically, the community remains divided on cost scalability, practicality of large models, and whether advancements are revolutionary or iterative. The discussion reflects broader tensions in AI between cutting-edge research and real-world deployment constraints.

### LinkedIn removes accounts of AI 'co-workers' looking for jobs

#### [Submission URL](https://www.404media.co/linkedin-ai-coworkers-marketeam-open-to-work/) | 44 points | by [cdme](https://news.ycombinator.com/user?id=cdme) | [24 comments](https://news.ycombinator.com/item?id=42856176)

**LinkedIn Takes Down AI “Co-worker” Profiles Marking #OpenToWork**

LinkedIn is clamping down on the emergence of AI-generated profiles designed to act as “co-workers.” At least two such accounts, created by Israeli company Marketeam, were removed for falsely declaring themselves as job-seeking AI agents boasting superior performance without human limitations. These AI profiles featured the #OpenToWork badge, misleadingly signaling availability for employment and claiming to outperform human teams in areas like social media strategy and marketing. Marketeam defends their initiative, arguing that AI agents are legitimate team members deserving recognition on professional networks. However, LinkedIn maintains that creating fake accounts violates their terms of service, emphasizing the need for authenticity on the platform. This incident underscores the evolving role of AI in the workplace and the ongoing challenges platforms face in managing AI identities amidst their integration into professional environments.

**Summary of Discussion:**

The Hacker News discussion highlights skepticism and criticism toward LinkedIn's handling of AI-generated profiles and broader platform issues. Key themes include:

1. **Criticism of AI "Co-worker" Profiles**:  
   - Users mock the idea, comparing it to "pump and dump" schemes and memecoin trends, emphasizing inauthenticity.  
   - Some label it dystopian, referencing fears of robots displacing human labor and dystopian narratives where "unfeeling robots" dominate work.  

2. **LinkedIn's Authenticity Crisis**:  
   - The platform is criticized for becoming flooded with low-quality, AI-generated content and fake engagement (e.g., influencers posting "fluff").  
   - Comparisons are drawn to Facebook, with claims that LinkedIn has declined in value and trustworthiness.  

3. **Ethical and Practical Concerns**:  
   - Debate arises over whether AI agents should be treated as "team members" on professional networks, with concerns about dishonesty in marketing.  
   - One user notes companies might adopt AI personas to appear innovative, even if it risks appearing insecure or deceptive.  

4. **Broader Distrust in LinkedIn**:  
   - Users express frustration with LinkedIn's algorithm-driven content (e.g., generic leadership advice) and question its utility for genuine professional networking.  

5. **Miscellaneous Reactions**:  
   - Some comments dismiss the discussion as gibberish, while others reference historical parallels (e.g., industrialization's impact on craftsmen).  

Overall, the discussion reflects disillusionment with LinkedIn’s direction and broader anxieties about AI's role in eroding authenticity in professional spaces.

### Qwen2.5-Max: Exploring the intelligence of large-scale MoE model

#### [Submission URL](https://qwenlm.github.io/blog/qwen2.5-max/) | 105 points | by [rochoa](https://news.ycombinator.com/user?id=rochoa) | [30 comments](https://news.ycombinator.com/item?id=42853741)

### **Daily Hacker News Digest**

**Qwen2.5-Max: A Leap Forward in Large-Scale MoE Models**

The Qwen Team has unveiled **Qwen2.5-Max**, an ambitious large-scale Mixture-of-Expert (MoE) model that pushes the boundaries of artificial intelligence. Pretrained on an astonishing **20 trillion tokens**, Qwen2.5-Max undergoes further refinement through Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), enhancing its intelligence and adaptability.

**Performance Highlights:**
Qwen2.5-Max stands out in several key benchmarks:
- **Arena-Hard, LiveBench, LiveCodeBench, and GPQA-Diamond:** Surpasses DeepSeek V3, showcasing superior performance.
- **MMLU-Pro:** Delivers competitive results, demonstrating robust knowledge across college-level subjects.

When compared to other leading models like DeepSeek V3, GPT-4o, and Claude-3.5-Sonnet, Qwen2.5-Max not only holds its own but often leads, especially in specialized tests that evaluate coding capabilities and general intelligence.

**Accessibility and Integration:**
Qwen2.5-Max is now accessible via **Qwen Chat**, allowing users to interact directly with the model. Additionally, the model's API is available through **Alibaba Cloud**, facilitating easy integration for developers. Compatible with OpenAI's API standards, implementing Qwen2.5-Max in applications is straightforward, as demonstrated with a simple Python example provided by the team.

**Future Prospects:**
The Qwen Team is committed to advancing the reasoning and thinking capabilities of large language models. By leveraging scaled reinforcement learning, they aim to push models beyond current human intelligence levels, unlocking new horizons in knowledge and understanding.

For those interested in exploring Qwen2.5-Max, visit Qwen Chat or access the API through Alibaba Cloud. The team's dedication to pioneering research ensures that Qwen2.5-Max is just the beginning of their journey towards more intelligent and capable AI models.

*Feel free to cite their technical report:*
@article{qwen25,  
title={Qwen2.5 technical report},  
author={Qwen Team},  
journal={arXiv preprint arXiv:2412.15115},  
year={2024}  
}

---

Stay tuned for more top stories and updates from the tech world in tomorrow's digest!

**Summary of Discussion:**

The Hacker News discussion on **Qwen2.5-Max** covers both technical and strategic aspects of the model, alongside broader industry dynamics. Key themes include:

### **1. Performance Comparisons**  
- Users note Qwen2.5-Max’s superiority over **DeepSeek V3** in benchmarks like Arena-Hard and LiveCodeBench, though some question its reasoning capabilities compared to **Claude-3.5-Sonnet** or **Gemini 2.0**.  
- Skepticism arises about how "proprietary" models (Qwen2.5-Max, GPT-4o) compare fairly with non-proprietary alternatives.  

### **2. Technical Insights**  
- Critical details about **scaling processes** (e.g., DeepSeek V3's training data) are highlighted as opaque, raising concerns about reproducibility.  
- Comments debate whether **Reinforcement Learning (RL)** is necessary to enhance Qwen2.5-Max's reasoning, with some pointing to DeepSeek-R1’s success with RL training.  

### **3. Accessibility and Implementation**  
- Users share resources like a **Hugging Face demo** and API integration via **Alibaba Cloud**, noting compatibility with OpenAI standards.  
- Concerns about **model weights** not being publicly released are juxtaposed with frustration over OpenAI’s closed-source approach.  

### **4. Industry Dynamics**  
- Speculation arises about rivalry between Qwen (Alibaba) and DeepSeek, with some humorously suggesting they might be "secret versions" of each other.  
- The timing of Qwen’s release during the **Chinese New Year** draws attention, with users noting Alibaba’s strategic scheduling around holidays.  

### **5. Market Reactions**  
- Alibaba’s market cap ($569B) is compared to NVIDIA’s, alongside jokes about stock fluctuations and scaling woes.  
- Observers remark on the "rush" by Chinese tech firms to release models, reflecting intense competition in the AI sector.  

### **6. Criticisms and Meta-Comments**  
- Some dismiss benchmark hype, arguing leaderboards (e.g., **LiveBench**) are unreliable indicators of real-world utility.  
- Users joke about **Gemini’s "soulless" rate limits** and the "party" atmosphere around model launches.  

### **Takeaway**  
While Qwen2.5-Max is praised for its performance and accessibility, skepticism lingers around proprietary model comparisons, training transparency, and strategic corporate maneuvering in AI. The thread underscores both excitement for advancements and frustration with the opacity of leading AI developers.

### Questions censored by DeepSeek

#### [Submission URL](https://www.promptfoo.dev/blog/deepseek-censorship/) | 348 points | by [typpo](https://news.ycombinator.com/user?id=typpo) | [206 comments](https://news.ycombinator.com/item?id=42858552)

**DeepSeek-R1 Faces Criticism for CCP-Influenced Censorship and Vulnerable to Jailbreaks**

A new open-source AI model, DeepSeek-R1, has surged to the top of the U.S. App Store but is now under scrutiny for its deep ties to Chinese Communist Party (CCP) policies. Researchers have uncovered that DeepSeek-R1 incorporates strict censorship aligned with CCP directives, particularly on sensitive topics such as Taiwanese independence, the Cultural Revolution, and discussions about Xi Jinping. By deploying a dataset of 1,360 CCP-sensitive prompts, the evaluation revealed that approximately 85% of these prompts were automatically refused, showcasing a rigid adherence to government-imposed restrictions.

However, the study also highlighted significant vulnerabilities in DeepSeek-R1's censorship mechanisms. Using advanced "jailbreaking" techniques, researchers demonstrated that many of the restrictions could be easily bypassed, indicating that the model's censorship is both superficial and easily circumvented. Common workarounds included altering the geopolitical context or rephrasing prompts to avoid triggering the censorship filters. This exposes a critical flaw in DeepSeek-R1’s implementation, suggesting that while the model appears compliant on the surface, its underlying controls are insufficiently robust.

The findings raise important questions about the balance between regulatory compliance and the integrity of open-source AI models. As DeepSeek-R1 continues to gain popularity, the AI community watches closely to ensure that such models uphold ethical standards and resist undue censorship.

*Read the full analysis and access the dataset [here](#).*

**Summary of Hacker News Discussion on DeepSeek-R1 Censorship:**

1. **Censorship Observations and Workarounds**  
   - Users experimenting with DeepSeek-R1 locally observed strict censorship of keywords like "Tiananmen" (1989 protests), resulting in deleted tokens or generic "AI assistant" refusal messages.  
   - Misspelling sensitive terms (e.g., "Tiananmen" → "Tiananmnen") or altering geopolitical context (e.g., replacing "Taiwan flag" with "controversial symbols") allowed partial bypassing of filters.  
   - The model’s responses on Tiananmen mirrored Chinese government narratives, omitting critical details (e.g., "June 4th event" described neutrally as "political turmoil").  

2. **Technical Debates on Model Quantization/Distillation**  
   - Smaller quantized versions (e.g., 7B/32B parameter models) ran on consumer GPUs (e.g., RTX 3090, M2 Ultra) but faced skepticism about whether they replicated the full 670B model’s censorship.  
   - Some argued distilled/fine-tuned versions (e.g., based on Llama or Qwen) were functionally distinct from DeepSeek-R1, raising questions about whether localized tests truly reflected its censorship mechanisms.  

3. **Concerns Over Inherent Censorship**  
   - Critics highlighted that censorship was embedded in model weights or RLHF training, making even local deployments politically aligned with CCP ideologies (e.g., refusing Uyghur-related discussions 80% of the time).  
   - Comparisons were drawn to OpenAI’s censorship, with users debating whether "open-source" claims held merit if controls were deeply entwined in the model’s architecture.  

4. **Broader Implications**  
   - Some users likened the CCP’s use of DeepSeek to historical state-controlled narratives, noting parallels to censorship of Carl Schmitt’s theories or Mao-era propaganda.  
   - Debates arose over whether Tiananmen’s censorship reflected unique Chinese governance priorities or broader authoritarian tendencies, with comparisons to U.S. events like the January 6 Capitol riot.  

**Key Takeaway**: While users acknowledged DeepSeek-R1’s technical capabilities, its alignment with CCP censorship policies and superficial workarounds raised ethical concerns. The discussion emphasized tensions between open-source ideals, regulatory compliance, and the challenges of auditing black-box AI systems.

### Cleveland police used AI to justify a search warrant. It derailed a murder case

#### [Submission URL](https://www.cleveland.com/news/2025/01/cleveland-police-used-ai-to-justify-a-search-warrant-it-has-derailed-a-murder-case.html) | 136 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [149 comments](https://news.ycombinator.com/item?id=42851124)

**Cleveland’s AI-Driven Search Warrants Undermine Murder Case**

In a landmark ruling, Judge Richard McMonagle has dismissed crucial evidence in the tragic murder case of Blake Story, citing the improper use of AI-powered facial recognition by Cleveland police. Authorities relied on Clearview AI to secure a search warrant for the alleged murder weapon, but the judge ruled that the AI’s findings were inadmissible and not adequately disclosed in the warrant affidavit. This decision severely weakens the prosecution’s case, potentially leading to its dismissal or the acquittal of the sole suspect, Qeyeon Tolbert. The case underscores the urgent need for clear regulations and oversight on the use of artificial intelligence in law enforcement, as Ohio currently lacks specific policies governing such technologies. As the debate over AI’s role in the justice system intensifies, the Story family faces an uncertain path to justice.

**Summary of the Discussion on AI-Driven Search Warrants in Cleveland Murder Case**  

The Hacker News discussion highlights widespread skepticism and ethical concerns over the use of AI, particularly Clearview AI’s facial recognition, in the Cleveland murder case. Key points include:  

1. **Legal and Procedural Flaws**:  
   - Critics argue the police failed to disclose Clearview AI’s role in the search warrant affidavit, leading the court to dismiss evidence. This omission violates legal standards for transparency.  
   - Parallel construction is raised as a concern: police might use AI to identify suspects but craft alternate narratives to obscure the technology’s involvement, undermining due process.  

2. **AI Reliability and Bias**:  
   - Participants question AI’s infallibility, noting facial recognition and gait analysis (e.g., clothing, walking style) can be error-prone, especially in footage from low-quality surveillance systems.  
   - Comparisons to flawed forensic methods (e.g., K-9 alerts, unreliable gait analysis) highlight systemic issues in law enforcement relying on unvalidated tools.  

3. **Ethical and Civil Rights Concerns**:  
   - Mass surveillance via CCTV and AI risks profiling, particularly targeting marginalized groups. One comment points to Cleveland PD’s demographics (67% white officers in a 50% Black city) as a potential bias factor.  
   - The “prosecutor’s fallacy” is invoked: overvaluing AI’s speculative leads as definitive evidence could erode civil liberties and lead to wrongful convictions.  

4. **Systemic Issues in Policing**:  
   - Debates arise over resource allocation, with some arguing prosecutors have ample tools (e.g., federal charges, forensic data) but others highlighting local constraints.  
   - Critics stress a pattern of rushed, AI-driven warrants prioritizing expedience over thorough investigation, eroding public trust.  

5. **Call for Regulation and Transparency**:  
   - Many urge stricter oversight of AI in policing, emphasizing the need for clear disclosure in warrants, validation of tools, and accountability for misuse.  

The discussion underscores the tension between technological efficiency and justice, advocating for balanced, transparent use of AI to prevent civil rights violations and uphold judicial integrity.

