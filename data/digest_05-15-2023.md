## AI Submissions for Mon May 15 2023 {{ 'date': '2023-05-15T17:12:19.292Z' }}

### StarCoder and StarCoderBase: 15.5B parameter models with 8K context length

#### [Submission URL](https://arxiv.org/abs/2305.06161) | 295 points | by [belter](https://news.ycombinator.com/user?id=belter) | [149 comments](https://news.ycombinator.com/item?id=35954481)

A group of researchers from the BigCode community has introduced two new large language models for code (Code LLMs) called StarCoder and StarCoderBase. The models have 15.5 billion parameters with 8K context length, infilling capabilities, and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories, while StarCoder was fine-tuned on 35 billion Python tokens. The researchers claim that StarCoderBase outperforms every open Code LLM and matches or outperforms the OpenAI code-cushman-001 model, and StarCoder outperforms every model fine-tuned on Python and can achieve 40% pass@1 on HumanEval. The models are now publicly available with an improved PII redaction pipeline and a novel attribution tracing tool under a more commercially viable version of the Open Responsible AI Model license.

A group of researchers from the BigCode community has introduced two new large language models for code (Code LLMs) called StarCoder and StarCoderBase, which outperform every open Code LLM. The models have 15.5 billion parameters with 8K context length, infilling capabilities, and fast large-batch inference enabled by multi-query attention. The discussion on Hacker News includes comments on the comparison between these models and human intelligence, the importance of training data in developing models, and the limitations of LLMs in comparison to human brains. The conversation also touches on the potential applications for these models in the field of coding and artificial intelligence.

### Show HN: Willow – Open-source privacy-focused voice assistant hardware

#### [Submission URL](https://github.com/toverainc/willow) | 540 points | by [kkielhofner](https://news.ycombinator.com/user?id=kkielhofner) | [128 comments](https://news.ycombinator.com/item?id=35948462)

Willow is an open-source, self-hosted voice assistant alternative to Amazon Echo and Google Home. The project is based on ESP IDF and primarily targets the ESP BOX hardware. Willow promises competitive performance, accuracy, cost, and functionality with Home Assistant and other platforms. It is 100% open-source and completely self-hosted by the user with low-cost commercially available hardware. Willow claims faster response times than Alexa/Echo or Google Home, high-wake word accuracy, low false activation, and reliability with a less than 1% failure rate. This practical, open-source, and privacy-focused platform checks all the boxes for a voice-activated system.

The submission discussed Willow, an open-source, self-hosted voice assistant alternative to Amazon Echo and Google Home, based on ESP IDF and primarily targeting the ESP BOX hardware. It promises faster response times and high-wake word accuracy with low false activation and a less than 1% failure rate, with low-cost commercially available hardware. The discussion involved experiences with setting up Willow and some users found difficulties with ESP IDF. Some users also suggested alternatives such as Home Assistant and Raspberry Pi. Overall, the project was praised for its practicality, open-sourcing, and privacy-focused platform. There was also excitement about the customization and potential of a voice-activated system that is completely self-hosted.

### Translating Akkadian clay tablets with ChatGPT?

#### [Submission URL](http://www.janromme.com/2023/05/ChaptGPT-transaltion-of-Akkadian-texts.html) | 162 points | by [janandonly](https://news.ycombinator.com/user?id=janandonly) | [100 comments](https://news.ycombinator.com/item?id=35954259)

It looks like Jan is attempting to translate an old Akkadian clay tablet related to the Biblical account of King Manasseh of Judah. However, he's having difficulty locating the tablet again and finding a digital translation. He's turned to OpenAI's chatGPT for help, asking if it can speculate on how the name of King Manasseh would be written in Babylonian Cuneiform. After receiving a couple of variant spellings from chatGPT, he's had some success in finding hits on CDLI. It'll be interesting to see if he's successful in translating the tablet with the help of chatGPT.

Jan is trying to translate an old Akkadian clay tablet related to the Biblical account of King Manasseh of Judah but is having difficulty locating the tablet again. He turned to OpenAI's chatGPT for help to speculate on how the name of King Manasseh would be written in Babylonian Cuneiform. After receiving a couple of variant spellings from chatGPT, he has had some success in finding hits on CDLI. The discussion covers various topics, including the limitations of natural language processing and AI alignment. There is also a debate about the reliability of machine translation versus human translation. Additionally, there are discussions about the works of Philip K. Dick, the development of GPT, and the problems with training models.

### LTESniffer – An Open-Source LTE Downlink/Uplink Eavesdropper

#### [Submission URL](https://github.com/SysSec-KAIST/LTESniffer) | 236 points | by [conductor](https://news.ycombinator.com/user?id=conductor) | [43 comments](https://news.ycombinator.com/item?id=35952206)

SysSec-KAIST/LTESniffer is an open-source LTE downlink/uplink eavesdropper designed to decode the Physical Downlink Control Channel (PDCCH) to obtain Downlink Control Information and Radio Network Temporary Identifiers of users. This tool can capture messages sent between a cell tower and connected smartphones and decode unencrypted parts of the communication for security and analysis research. LTESniffer can automatically detect physical layer configuration per UE and supports a security API for RNTI-TMSI mapping, IMSI collecting, and UECapability Profiling. However, it does not support decrypting encrypted messages and must follow local regulations on sniffing LTE traffic. It requires Ubuntu 18.04/20.04 and a high-performance CPU with at least 8 physical cores.

The submission discusses an open-source tool called LTESniffer, designed for decoding and analyzing unencrypted parts of communication between smartphones and cell towers using the LTE (Long-Term Evolution) network. The tool can capture messages sent between a cell tower and connected smartphones and decode the Physical Downlink Control Channel (PDCCH) to obtain Downlink Control Information and Radio Network Temporary Identifiers of users. The discussion mentions the high-performance CPU and Ubuntu 18.04/20.04 requirement for running the tool and indicates that it does not support decrypting encrypted messages. The discussion also touches upon related topics, such as the cost and functionality of alternative software and hardware, the legal concerns around eavesdropping on LTE traffic, and potential vulnerabilities in LTE encryption. The commenters also emphasize the importance of responsible use of such tools and suggest caution against illegal activities.

### Basic Pitch: Spotify’s Open Source Audio-to-MIDI Converter (2022)

#### [Submission URL](https://engineering.atspotify.com/2022/06/meet-basic-pitch/) | 31 points | by [andrewmcwatters](https://news.ycombinator.com/user?id=andrewmcwatters) | [3 comments](https://news.ycombinator.com/item?id=35955934)

Spotify has released an open source tool for converting audio recordings into MIDI notes using machine learning. Called Basic Pitch, the tool can transcribe the musical notes in a recording from almost any instrument, including the voice. Basic Pitch uses a neural network to predict MIDI note events given audio input, and is both versatile and accurate, as well as computationally lightweight, meaning it is faster to run. In contrast to other MIDI converter tools, Basic Pitch is polyphonic and instrument-agnostic, can detect pitch bends, and can track multiple notes at once.

The discussion includes various opinions and experiences with audio-to-MIDI conversion tools. Some users have expressed interest in trying out Basic Pitch as it seems accurate and versatile. One user mentions that they will try it out, as their current digital audio workstation (DAW) does not have a voice recorder after transcription to MIDI, which Basic Pitch could potentially solve. However, some users have shared cautionary experiences with other conversion tools, such as one service that unexpectedly started charging for usage, which led them to wish for more open source hardware. Another user mentions using Ableton's Audio-to-MIDI converter, which they found to be fast but not always accurate in detecting chords, notes, velocity, and timing. Lastly, there is a comment providing a Github repository for an earlier version of the Basic Pitch code that is recommended to be used with Python, although it is noted that the installation may have some unresolved issues.

### Show HN: Openlayer – Test, fix, and improve your ML models

#### [Submission URL](https://www.openlayer.com/?ref=hn) | 47 points | by [vikasnair](https://news.ycombinator.com/user?id=vikasnair) | [11 comments](https://news.ycombinator.com/item?id=35951703)

Sure, I can help you with that. To get started, I'll need access to Hacker News, either through an API or web scraping. Do you have any preference on how we retrieve the top stories?

The discussion consists of several users commenting and discussing various topics related to data-centric platforms, technologies, and solutions. One user shared a confusing experience with a website they visited, while another user expressed interest in OpenLayers. Additionally, there was a conversation about the usefulness of comparison tables in various industries such as machine learning. Another user shared a witty typo they found while browsing a website. The conversation also touched on the potential of data-centric platforms to help improve business processes, with one user sharing examples of real-world applications. Lastly, one user talked about building AI-driven chatbots for experiment tracking and improving NLP content classification models.

### Basic SAT model of x86 instructions using Z3, autogenerated from Intel docs

#### [Submission URL](https://github.com/zwegner/x86-sat) | 148 points | by [djoldman](https://news.ycombinator.com/user?id=djoldman) | [22 comments](https://news.ycombinator.com/item?id=35946078)

x86-sat is a basic SAT model of x86 instructions using Z3 that's autogenerated from Intel docs. It interprets Intel's instruction pseudocode and transforms it into a model for Z3. This technique generates models that are limited since the instructions only cover a subset of x86 instructions. However, it can do some interesting and non-trivial things like derive lookup tables or find index vectors. You can use it by downloading the latest XML from Intel's Intrinsics Guide, which is required for this project. The project also requires Z3 and the sprdpl parsing library.

The submission on Hacker News is about a basic SAT model of x86 instructions called x86-sat, generated from Intel documentation that uses Z3 to interpret Intel's pseudocode. Some of the comments discuss its applications, vulnerabilities of the x86 architecture, unexpected behaviour of some instructions, and how this model can help with formal verification of code. There is also a discussion about formalization, theorem proving, code optimization, and the use of model checking to verify computer systems, with Coq as one of the tools mentioned. Some users also mention the limitations of this system and the need for further development.

### Self-Replace: A Utility For Self Replacing Executables

#### [Submission URL](https://github.com/mitsuhiko/self-replace) | 55 points | by [asicsp](https://news.ycombinator.com/user?id=asicsp) | [25 comments](https://news.ycombinator.com/item?id=35944015)

Self-replace is a utility library that allows binaries to replace themselves with newer versions or to uninstall themselves. It is particularly useful for implementing self-updating and self-uninstallation features in single-executable utilities. While it's an easy task on Unix systems, a few hacks are needed for Windows, and this is where self-replace comes into play. Refer to the documentation for more information about the implementation and how to use it.

Self-replace is a utility library that allows binaries to replace themselves with newer versions or to uninstall themselves, useful for self-updating and self-uninstallation features in single-executable utilities, especially on Windows. The discussion covered various topics such as package management on Linux compared to Windows, the security implications of software privileges, and the technical aspects of self-updating/replacing. One user mentioned KSplice and its implementation in Oracle, while another discussed the complexity of Windows implementation compared to Unix. Some users also talked about self-modifying code, interface implementations on Unix and Windows, and executable replacement tricks.

### Show HN: Use ChatGPT, Bing, Bard and Claude in One App

#### [Submission URL](https://github.com/chathub-dev/chathub/blob/main/README.md) | 135 points | by [wonderfuly](https://news.ycombinator.com/user?id=wonderfuly) | [52 comments](https://news.ycombinator.com/item?id=35946955)

Sorry, but this is not a story on Hacker News. It appears to be the README file of a GitHub repository for a chatbot client called ChatHub.

A submission on Hacker News sparked a discussion about the current state of chatbots. One user mentioned that the chatbot experience on ChatGPT seemed slow and sluggish, while others suggested that a streamlining of prompts and typing indicators could speed up the experience. Others drew parallels between current chatbot technology and search engines from the 90s, and debated the business viability of AI for consumer products. Some users also shared their own chatbots and extensions, with suggestions for how to improve them. Overall, the discussion touched on the potential and current limitations of chatbot technology.

### Case study: fake hardware cryptowallet

#### [Submission URL](https://www.kaspersky.com/blog/fake-trezor-hardware-crypto-wallet/48155/) | 202 points | by [freerk](https://news.ycombinator.com/user?id=freerk) | [149 comments](https://news.ycombinator.com/item?id=35954422)

A recent incident has revealed that even having a hardware cryptocurrency wallet can't guarantee the safety of your funds. The victim had purchased a Trezor Model T hardware wallet, but hackers orchestrated a supply-chain attack by creating a fake version of the wallet. The fake model was designed to look identical to the real product, with even the holographic stickers on the packaging and the wallet itself remaining undamaged. Attackers had removed the bootloader-check for protection mechanisms and digital signatures, replaced randomly generated seed phrases with pre-generated ones saved in the hacked firmware from a pool of just 20, and reduced the protection password to just a single symbol. Ultimately, the attackers managed to steal the victim's cryptocurrency by knowing the private key in advance.

A recent supply-chain attack targeted a Trezor Model T hardware wallet. The attackers created a fake version of the wallet that looked identical to the real product, and they removed various protection mechanisms to steal the victim's cryptocurrency. Commenters discussed the predictability of wallet seed phrases and noted that deterministic wallets can expose private keys to network attacks. Other commentators pointed out that hardware hacking is increasingly sophisticated, and that vendors should prioritize proper planning and security measures to prevent potential attacks. Additionally, users should strive to verify that they have authentic hardware and firmware. Some commenters shared their own experiences with hacked wallets and suggested that more complex security measures, such as Hardware Security Modules (HSMs), may be necessary to keep private keys secure.

### Google I/O and the Coming AI Battles

#### [Submission URL](https://stratechery.com/2023/google-i-o-and-the-coming-ai-battles/) | 196 points | by [Amorymeltzer](https://news.ycombinator.com/user?id=Amorymeltzer) | [176 comments](https://news.ycombinator.com/item?id=35945988)

Google's recent keynote in Paris was shockingly poor, with little new content and out-of-sync speakers. This surprising lack of quality in an AI-related presentation may be due to Google feeling threatened by Microsoft's GPT-powered Bing announcement, highlighting Google's apparent reliance on AI. However, Google has been talking about AI for years and has a clear focus on organizing the world's information. The company's evolving AI capabilities are evident in products like Gmail and Google Photos, which feature Smart Reply, Smart Compose, and Magic Erase capabilities. Google has 15 products with over 500 million users and is taking a hybrid approach with generated text and ads in search results. This bold and responsible approach highlights Google's determination to win at AI and search.

Google’s recent keynote in Paris is being criticized as poor quality with outdated speakers and little new content. The submission suggests that this could be due to Google feeling threatened by Microsoft’s Bing announcement, which is powered by the GPT language model AI. However, Google has been talking about AI for years and is progressing significantly with its Smart Reply and Smart Compose features found in products like Gmail and Google Photos. There is a discussion in the comments suggesting that Google has a clear focus on organizing the world’s information, and that its AI capabilities are evident in its 15 products with over 500 million users. A few comments discuss how Google’s AI strategy is largely directionless, and others suggest that the company may be paying for sponsored Tweets to promote its AI products. There is also a debate about how Google's competitors are fairing in the AI space. Overall, the comments discuss Google's AI capabilities and direction, as well as the similarities and differences between Google and its competitors.

### StarFive VisionFive 2 SBC Now Supports TianoCore EDK II (UEFI)

#### [Submission URL](https://forum.rvspace.org/t/unlocking-new-possibilities-starfive-visionfive-2-sbc-now-supports-tianocore-edk-ii-uefi/2779) | 41 points | by [snvzz](https://news.ycombinator.com/user?id=snvzz) | [29 comments](https://news.ycombinator.com/item?id=35951867)

StarFive VisionFive 2 SBC now supports TianoCore EDK II (UEFI), creating more sophisticated interfaces for system initialization, firmware updates, and system management. The EDK II firmware is available on the StarFive GitHub repository and comes with detailed instructions and pre-built binaries, facilitating faster boot times, larger storage device support, and more advanced security features. Developers can now choose the most suitable storage device for their specific application from SD Card, eMMC, and QSPI flash. Despite not having support for framebuffer utilization or direct reading of NVMe/USB devices yet, the SBC's powerful JH7110 quad-core RISC-V processor and now EDK II support make it a versatile and powerful solution for a wide range of applications.

The StarFive VisionFive 2 SBC now has support for TianoCore EDK II (UEFI), allowing for more advanced interfaces for system initialization, firmware updates, and system management. The EDK II firmware is available on the StarFive GitHub repository and facilitates faster boot times, larger storage device support, and advanced security features. Developers can now choose their preferred storage device from SD Card, eMMC, and QSPI flash. Despite not having support for framebuffer utilization or direct reading of NVMe/USB devices yet, the SBC’s powerful JH7110 quad-core RISC-V processor and now EDK II support make it a versatile and powerful solution. Commenters discussed the challenges of implementing firmware in RISC-V hardware, with divergent platforms and competing standards. Some expressed optimism for RISC-V’s future, but others expressed frustration with the prevalence of closed-source firmware in many RISC-V products. One commenter noted that the VisionFive 2 does not require firmware for GPU boot, but does require HDMI controller support and hardware block for video decoding acceleration.

### Which kinds of GPT startups will thrive?

#### [Submission URL](https://assistedeverything.substack.com/p/the-three-hills-model-for-evaluating) | 108 points | by [gimili](https://news.ycombinator.com/user?id=gimili) | [81 comments](https://news.ycombinator.com/item?id=35948145)

A new article on the "Assisted Everything" newsletter proposes a model to evaluate the success potential of startups based on GPT, a technology that is revolutionising the white-collar industry; the "Three-Hills" model considers "Productivity Enhancements", "Non zero-sum-game Value" and "Moat = Value from Context" as the three main axes to assess a GPT application. The article provides examples of Level I GPT applications, which are those where users could perform tasks themselves but can do so faster and more efficiently assisted by GPT, and Level II GPT applications, which surpass the Tug-of-War Valley and provide value outside of existing zero-sum games.

The article proposes a model called the "Three-Hills" to evaluate the success potential of GPT-powered startups based on "Productivity Enhancements," "Non zero-sum-game Value," and "Moat = Value from Context." The discussion touched on various aspects including how Microsoft and Google companies may not be well suited to run startups because they primarily build generic software targeted for business development, SaaS and mobile apps. The comments also addressed the differences between closed and open-source models in machine learning and how GPT technology may not be suitable for every vertical. They discussed the potential of GPT-powered tools to help fine-tune business models, offer legal and medical support, and revolutionize traditional markets like customer support and finance. Lastly, the conversation touched on how GPT startups may have to focus on building products that people love, reaching people to eventually scale, monetizing users, and building a kind of network effect.

### Together’s $20M seed funding to build open-source AI and cloud platform

#### [Submission URL](https://www.together.xyz/blog/seed-funding) | 73 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [22 comments](https://news.ycombinator.com/item?id=35951023)

Together, an AI platform that provides open-source generative AI models, has raised $20 million in seed funding led by Lux Capital. The platform aims to empower innovation and creativity by making AI accessible to anyone, anywhere, and establishes open-source as the default way to incorporate AI. Together's mission is to outrival closed models by creating open models and to give developers and organizations greater ability to understand, inspect, and utilize AI without vendor lock-in and with strong privacy protections.

Together, an AI platform that provides open-source generative AI models, has raised $20 million in seed funding, and it aims to make AI accessible to anyone, anywhere, and establishes open-source as the default way to incorporate AI. The discussion on Hacker News mainly revolves around the trend of commercial entities claiming to be open source, but charging licensing fees, and Together's approach to using open models. Other topics of discussion include the company RedPajama's release of commercial-only licensed LLM models, the importance of open source in AI models, Stability AI platforms, and the benefits of Together's platform. Some users also discussed the funding and alignment of the company's strategy.

### HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion

#### [Submission URL](https://synthesiaresearch.github.io/humanrf/) | 60 points | by [Keats](https://news.ycombinator.com/user?id=Keats) | [15 comments](https://news.ycombinator.com/item?id=35946893)

Researchers have introduced HumanRF, a high-fidelity neural radiance field (RF) that captures human performance in motion from multi-view video input and enables playback from novel, previously unseen viewpoints. The researchers trained the model on ActorsHQ, their multi-view dataset of footage from 160 cameras providing 12MP footage of 16 sequences. While most research focuses on synthesizing at resolutions of 4MP or lower, this work operates at 12MP, making a significant step towards production-level quality novel view synthesis. Applications of high-fidelity human representation and motion capture include film production, gaming and video conferencing.

Researchers have created a high-fidelity neural radiance field (RF) called HumanRF that captures human performance in motion and enables playback from novel, unseen viewpoints. They trained the model on ActorsHQ, a multi-view dataset comprising footage from 160 cameras that provided 12MP footage of 16 sequences. The model could find applications in film production, gaming, and video conferencing. Commenters discussed the movie The Matrix's interpolation techniques, as well as the potential for gaming applications and the similarities with Nintendo Miis. Additionally, someone talking about a classic 1981 film called Looker with an ocular-oriented kinetic emotive response device called "Light Ocular-Oriented Kinetic Emotive Responses (LOOKER) dvc technology."

### Bark: A transformer based text to audio system

#### [Submission URL](https://github.com/suno-ai/bark/blob/main/README.md) | 169 points | by [antman](https://news.ycombinator.com/user?id=antman) | [54 comments](https://news.ycombinator.com/item?id=35943108)

I'm sorry, but the provided text is a documentation file for a model called "Bark". It does not contain actual news stories from Hacker News. Would you like me to look up and summarize today's top stories on Hacker News for you?

The discussion revolves around a model called "Bark", which generates voices. The creator, JonathanFly, posts a link to the Github documentation file for the model and mentions its features, as well as its limitations. Other users discuss the potential for sponsorship, using Bark for micro SaaS, generating different languages, fixing the quality of the voices, trying to match text to voice for David Attenborough's voice, testing and customizing the model, and using GPUs to increase efficiency. They also discuss the quality of the voices, their expressiveness and control, and the limitations and challenges of generating synthetic voices.

### Vicuna: An Open-Source Chatbot Impressing GPT-4

#### [Submission URL](https://lmsys.org/blog/2023-03-30-vicuna/) | 42 points | by [kordlessagain](https://news.ycombinator.com/user?id=kordlessagain) | [6 comments](https://news.ycombinator.com/item?id=35942654)

The Vicuna Team has introduced Vicuna-13B, an open-source chatbot that achieves more than 90% ChatGPT quality and outperforms other models such as LLaMA and Stanford Alpaca in more than 90% of cases. Vicuna-13B was trained by fine-tuning LLaMA on user-shared conversations from ShareGPT and the open-source code and weights, along with an online demo, are publicly available for non-commercial use. The preliminary evaluation of the model quality was done using GPT-4 to judge the model outputs. Vicuna-13B builds on top of Stanford’s Alpaca with improvements in memory optimization, multi-round conversations, and cost reduction through spot instances and achieved competitive performance compared to other open-source models.

The discussion involves several users providing their opinions and thoughts on the Vicuna-13B chatbot and its open-source release. One user, Animats, raises concerns about the comparison of small and large models while pointing out the importance of underlying data and verifying results. Another user, jsnll, links to an earlier discussion on the same topic. A third user, rngn, is impressed with the article and the hosting of the models. Meanwhile, brnjkng is optimistic about the commercial potential of Vicuna-13B, but stvncr expresses concerns about the terms and conditions of using open-source resources such as ShareGPT. Finally, brnjkng mentions that multiple models can be run locally for commercial purposes using CPU inference.

### Benchtop DNA printers are coming soon–and biosecurity experts are worried

#### [Submission URL](https://www.science.org/content/article/benchtop-dna-printers-are-coming-soon-and-biosecurity-experts-are-worried) | 18 points | by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) | [4 comments](https://news.ycombinator.com/item?id=35946161)

Benchtop DNA printers will soon be available as a more convenient option for biologists to obtain DNA sequences for their research, but this new technology also poses risks if misused by bioterrorists. A report by a Washington-based think tank urges better safeguards to prevent these risks by revamping existing screening. The current screening system that's voluntary for synthetic biology companies "could be upended by benchtop DNA synthesis," explained report co-author Jaime Yassif. The technology to synthesize DNA sequences has been around since the early 1980s and is widely used for genetic research to develop new pharmaceuticals, agricultural products, and biofuels. The report recommends that the manufacturers of benchtop synthesis devices must vet their customers and adopt build-in protections, and that governments should update their voluntary guidelines for customer and sequence screening and adopt mandatory requirements that apply to devices operating within their borders. The report notes that the length of stretches of DNA that can be synthesized with these machines will likely increase from about 200 base pairs to as many as 7,000 base pairs with the longer lengths of DNA allowing labs to more easily splice together large pathogen genomes.   

The discussion around the submission highlights concerns about the potential misuse of benchtop DNA printers for bioterrorism. Some commenters suggest that current security measures are not sufficient and that manufacturers of these devices must do more to vet their customers and build-in protections. Others speculate about the increasing lengths of DNA that can be synthesized with these machines and the potential risks of uncontrolled access to custom DNA sequences. Some point out that while conventional DNA synthesis requires significant skill, benchtop DNA printers could democratize access to the technology, creating new opportunities but also new risks.

### EU AI Act to Target US Open Source Software

#### [Submission URL](https://technomancers.ai/eu-ai-act-to-target-us-open-source-software/#more-561) | 18 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [4 comments](https://news.ycombinator.com/item?id=35946388)

The EU's amended AI Act is causing controversy by targeting US open source software. The act would prohibit American companies like OpenAI, Amazon, Google, and IBM from providing API access to generative AI models, as well as sanctioning American open-source developers and software distributors if unlicensed generative models become available in Europe. While the act includes open source exceptions for traditional machine learning models, it expressly forbids safe-harbor provisions for open source generative systems. If enacted, the AI Act would subject companies to massive fines of up to €20,000,000 or 4% of worldwide revenue.

The discussion about the submission seems to be divided. One user points out that the headline doesn't fit the reality of the situation, and the EU's amended AI Act is not necessarily targeting US open source software. Another user argues that the legislation could lead to unnecessary protectionism and disrupt the current employment markets. A third user is suggesting that this regulation is driving towards a worldwide trend of government regulation of AI.

### Real Multithreading Is Coming to Python

#### [Submission URL](https://martinheinz.dev/blog/97) | 38 points | by [nalgeon](https://news.ycombinator.com/user?id=nalgeon) | [3 comments](https://news.ycombinator.com/item?id=35950618)

Python, an age-old programming language, has finally come up with a solution to its lack of proper parallelism and concurrency. With the introduction of the "Per-Interpreter GIL," set to arrive in Python 3.12, individual interpreters no longer have to share the same GIL, which means they can run concurrently. But there's a catch. For now, as sub-interpreters are intended for a narrow set of users of the C-API, only the C-API allows access to the feature, and there is no direct interface for Python developers. However, we can use the _xxsubinterpreters module or CPython's test module, and with some helper functions, we can pass code to sub-interpreters.

The discussion begins with the original submission explaining Python 3.12's solution to its lack of proper parallelism and concurrency, which involves the introduction of "Per-Interpreter GIL" allowing multiple sub-interpreters to run concurrently, albeit with some limitations. A user named mtdt finds this interesting and looks forward to learning about IPC compared to Python's multiprocessing, Golang's goroutines, C++, and Java threads. Another user named smnw shares a GitHub link to a similar project and mentions that the Global Interpreter Lock (GIL) has been a major problem for Python, with many existing libraries depending on its existence.

