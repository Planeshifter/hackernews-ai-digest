## AI Submissions for Sat Jun 10 2023 {{ 'date': '2023-06-10T17:11:06.827Z' }}

### Mercedes beats Tesla to autonomous driving in California

#### [Submission URL](https://www.theregister.com/2023/06/09/mercedes_california_tesla/) | 424 points | by [belter](https://news.ycombinator.com/user?id=belter) | [652 comments](https://news.ycombinator.com/item?id=36270413)

Mercedes-Benz has become the first automaker to receive permission from the state of California to sell or lease vehicles with an automated driving system to the public. The permit was granted for Mercedes-Benz's DRIVE PILOT system, which is a Society of Automotive Engineers level 3 automated system. The Californian Department of Motor Vehicles has placed serious restrictions on the DRIVE PILOT system. For instance, it can only operate during the day on certain limited roads and at speeds of up to 40mph. Meanwhile, Mercedes-Benz's DRIVE PILOT can automatically control speed and follow distance while staying in its lane and taking "the route profile, events occurring on the route and traffic signs" into consideration.

Mercedes-Benz has become the first automaker to gain permission from the California Department of Motor Vehicles to sell or lease vehicles with an automated driving system (ADS). The permit covers Mercedes-Benz's DRIVE PILOT system, which is a Society of Automotive Engineers’ level three automated system. The ADS can only be used in daytime on certain roads with speeds of up to 40mph. It can control speed and follow distance, stay in its lane, and respond to traffic signs, among other things. Commenters showed mixed opinions; some are optimistic, while others believe self-driving cars aren’t practical and autonomous driving will add more cars to the road.

### MusicGen: Simple and controllable music generation

#### [Submission URL](https://ai.honu.io/papers/musicgen/) | 423 points | by [og_kalu](https://news.ycombinator.com/user?id=og_kalu) | [305 comments](https://news.ycombinator.com/item?id=36271926)

Facebook AI researchers have proposed MusicGen, a single language model that generates high-quality samples conditioned on textual descriptions or melodic features. Unlike prior works, MusicGen eliminates the need for cascading several models by using an efficient token interleaving pattern. The model was tested with famous melodies from classical music and new text descriptions to provide interpretations in any genre or style. MusicGen was found to be superior to evaluated baselines on a text-to-music benchmark, and the researchers have provided code and models to replicate their work.

Facebook AI researchers proposed MusicGen, a single language model that generates high-quality samples conditioned on textual descriptions or melodic features. The model eliminates the need for cascading models by using an efficient token interleaving pattern and was found to be superior to evaluated baselines on a text-to-music benchmark. The discussion in the comments section primarily centered around the quality of AI-generated music compared to music produced by humans and the challenges of creating original music. Some users mentioned the importance of collaborating with human musicians and creating clear contracts when doing so, while others emphasized the potential for AI to enhance digital synthesis.

### Show HN: RISC-V core written in 600 lines of C89

#### [Submission URL](https://github.com/mnurzia/rv) | 186 points | by [mnurzia](https://news.ycombinator.com/user?id=mnurzia) | [76 comments](https://news.ycombinator.com/item?id=36270150)

Mnurzia has created an RV32IMC CPU core in 600 lines of ANSI C that features an easy-to-use API with two memory callback functions. The code doesn't use any integer types larger than 32 bits for multiplication and passes all supported tests in riscv-tests. The CPU core is written in C89 and is meant to be used with the riscv-gnu-toolchain, with suggested GCC command-line arguments. The creator also addresses some assumptions that are not completely compliant with C89/99 due to the width of integer types.

Mnurzia created an RV32IMC CPU core in 600 lines of ANSI C that uses two memory callback functions and doesn't use integer types larger than 32 bits for multiplication. The creator also addresses some assumptions that are not compliant with C89/99 due to the width of integer types. In discussions, users compared different programming languages and libraries, including C89 vs. C99, C++ vs. C99, and how modern compilers can handle C99. Some users noted how RISC-V instructions can be implemented in a straightforward manner, and other users questioned the completeness of the implementation of the ISA. Users also discussed the complexity of hardware and how the distribution of workload affects software development. They also talked about RISC-V and its reference implementation.

### A performance analysis of Intel x86-SIMD-sort (AVX-512)

#### [Submission URL](https://github.com/Voultapher/sort-research-rs/blob/main/writeup/intel_avx512/text.md) | 127 points | by [Twirrim](https://news.ycombinator.com/user?id=Twirrim) | [40 comments](https://news.ycombinator.com/item?id=36273544)

The performance of Intel's x86-simd-sort (AVX-512) implementation is analyzed in comparison to various generic sort libraries including std::sort and vqsort. The analysis shows that while manual vectorization with wide AVX-512 SIMD is one way to write efficient software, the hardware-specific approach is not the only way to achieve high performance. Additionally, the author proposes using vqsort with Clang for better overall performance and to avoid catastrophic scaling for certain input patterns. Finally, ipnsort, a generic implementation optimized for more than just peak performance and only using up to SSE2 instructions, is shown to have comparable performance to x86-simd-sort.

The discussion for the article covers a wide range of topics on sorting algorithms, including existing implementations, optimization techniques, and hardware limitations. Some users recommended Rust as an alternative language for sorting algorithms. Others proposed different optimization approaches for sorting, such as using smaller integer keys that can be sorted more efficiently or sorting small sequences before merging them. Some users also discussed the effectiveness of sorting algorithms in handling pre-sorted data or large datasets and compared the performance of different sorting libraries. Additionally, there was some discussion about the impact of CPU frequency and throttling on sorting performance. Finally, one user shared a dataset for sorting algorithms based on different machine learning models and data sizes.

### Licensing is neither feasible nor effective for addressing AI risks

#### [Submission URL](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor) | 186 points | by [headalgorithm](https://news.ycombinator.com/user?id=headalgorithm) | [147 comments](https://news.ycombinator.com/item?id=36270303)

Amidst concerns over the potential risks posed by the spread of advanced AI models, suggestions have been made that licensing could be used as a non-proliferation measure. However, Sayash Kapoor and Arvind Narayanan argue that such an approach would be difficult, if not impossible, to enforce. They suggest that allowing only a small number of companies to develop state-of-the-art AI models would likely lead to increased concentration and not solve AI risk issues. Additionally, it could worsen concerns over monoculture, outcome homogenization, defining acceptable speech and regulatory capture.

The submission discusses the suggestion that licensing could be used as a non-proliferation measure in advanced AI models. However, commenters argue that such an approach would be difficult to enforce and may lead to increased concentration and concerns over monoculture, outcome homogenization, defining acceptable speech, and regulatory capture. Additionally, there is debate over the likelihood of achieving human-level intelligence with AI and the required resources. Commenters also discuss the potential risks of concentrating power in the hands of a small number of companies or individuals and the need for government resources to improve shared knowledge and reduce harm caused by the development of AI. Finally, there is debate over the possibility of slow vs. rapid progress in the development of intelligent AI models.

### OBS merges WebRTC support

#### [Submission URL](https://github.com/obsproject/obs-studio/commit/851a8c216e14617fb523951839f3bdb240e85141) | 411 points | by [Sean-Der](https://news.ycombinator.com/user?id=Sean-Der) | [132 comments](https://news.ycombinator.com/item?id=36273075)

This commit is from obsproject, the developers behind OBS Studio, an open-source and cross-platform software for video recording and live streaming. The commit adds a Whip output and associated service to OBS-WebRTC, which is used for WebRTC output support. The code is inspired by DDRBoxman and implemented by Sean DuBois, tt2468, and pkv.

A commit from the developers behind OBS Studio, an open-source video recording and streaming software, adds a Whip output and associated service to OBS-WebRTC, used for WebRTC output support. Users on Hacker News discuss the benefits of WebRTC, including serverless streaming, sub-second latency, multitrack input, and mobility. Some users express frustration with streaming on self-hosted platforms, citing issues with freezing, interrupted audio, and P2P networking. Others discuss the technical details of WebRTC and P2P networking, and suggest solutions for issues with NAT and self-signed certificates. Overall, the discussion is constructive and informative.

### How much memory is needed to run 1M Erlang processes?

#### [Submission URL](https://hauleth.dev/post/beam-process-memory-usage/) | 24 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [5 comments](https://news.ycombinator.com/item?id=36273902)

In a recent benchmark for concurrency implementation in different languages, a poor example of Erlang's process memory usage was used. The code reported 3.94 GiB of memory used by the process, but with some work, it was reduced to around 0.93 GiB of RAM usage. This article explains the changes made, why the original code was consuming so much memory, and why using ChatGPT to write benchmarking code is not ideal. Erlang processes' isolation and location transparency are discussed, along with process dictionaries and "well-behaved" OTP processes. The article also covers the use of erlang:spawn/1 over Task.async/1, and the use of linked lists in Erlang.

The discussion on this submission primarily consists of comments expressing skepticism about using synthetic benchmarks to evaluate real-world performance, praise for Erlang's concurrency features, and some technical discussion about the memory usage of different programming languages. One comment points out that an earlier article wrongly implemented a concurrency benchmark, resulting in significantly higher memory usage. The author responds to clarify the changes they made to fix this issue. There is also some discussion about Java's memory usage and the use of linked lists in Erlang. One commenter makes a joking comment about Python. Overall, the discussion focuses on technical aspects of programming languages and their performance characteristics.

### Zig language server and cancellation

#### [Submission URL](https://matklad.github.io/2023/05/06/zig-language-server-and-cancellation.html) | 193 points | by [goranmoomin](https://news.ycombinator.com/user?id=goranmoomin) | [62 comments](https://news.ycombinator.com/item?id=36268247)

In a recent article on Zig language servers, cancellation was identified as a potential problem when a user makes edits while the server is in the middle of computation. The article explores three solutions: strong consistency, immutability, and cancellation. While strong consistency is an easy model for implementers to reason about, immutability ensures parallelism and prioritizes writes over reads, and cancellation actively cancels all background work pertaining to the old state and applies the modification in-place. The article also proposes the idea of semi-space garbage collection for dealing with memory that's needed now but not in the future. The article concludes by discussing the concept of relaxed consistency and how it may work with Zig's compilation model.

The article discusses potential problems with Zig language servers and explores solutions such as strong consistency, immutability, and cancellation. Some comments discuss the relationship between completion models and AST parsing, while others argue that cancellation is useful for dealing with memory and issues with parallelism. There is also a discussion on language servers and the extent to which they handle tasks such as type checking and building abstract syntax trees. Additionally, there is debate around the benefits of using multi-threading and parallelism, as well as the use of cancellation with blocking I/O calls. Overall, the comments provide various perspectives and insights related to the article's topics.

### Generative AI support on Vertex AI is now generally available

#### [Submission URL](https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-support-on-vertexai) | 79 points | by [blitz](https://news.ycombinator.com/user?id=blitz) | [28 comments](https://news.ycombinator.com/item?id=36274789)

Google Cloud has announced the general availability of Generative AI support on Vertex AI, helping developers and data scientists build and deploy custom generative AI applications with ease. The platform boasts over 60 foundation models from Google and its partners in Model Garden, as well as user-friendly tools in Generative AI Studio for model tuning and deployment. Along with enterprise-grade data governance and security features, the platform offers a full ecosystem of tools to help builders tune, deploy, and govern models in production. The platform has already seen innovative results from early adopters, such as GA Telesis and GitLab.

Google Cloud has launched Generative AI support on Vertex AI which is helping developers create and deploy custom generative AI apps. The platform offers over 60 foundation models, as well as user-friendly tools for model tuning and deployment. Early adopters have produced innovative results, such as GA Telesis and GitLab. The discussion mainly consisted of technical details and questions regarding functionality and pricing, with a few comments related to the current state of AI. Some commenters expressed concerns about Google's dominance in AI, while others mentioned issues related to data privacy and censorship.

### GitHub accused of varying Copilot output to avoid copyright allegations

#### [Submission URL](https://www.theregister.com/2023/06/09/github_copilot_lawsuit/) | 119 points | by [belter](https://news.ycombinator.com/user?id=belter) | [101 comments](https://news.ycombinator.com/item?id=36270427)

GitHub is facing accusations that it has used slight variations of ingested training code in its Copilot programming assistant to avoid it being flagged as a copy of licensed software. The claim was made in an amended complaint filed against Microsoft, GitHub, and OpenAI, in which plaintiffs said the tool presented other people's code as its own, violating copyright law and software licensing requirements. GitHub introduced a user-adjustable filter in response to criticism of Copilot, but the amended complaint alleges the filter is essentially worthless as it only checks for exact matches and does not detect output that has been slightly modified.

The top story on Hacker News is about GitHub, which is facing accusations that it used slight variations of ingested training code in its Copilot programming assistant to avoid it being flagged as a copy of licensed software. The tool allegedly presented other people's code as its own, violating copyright law and software licensing requirements. GitHub introduced a user-adjustable filter in response to criticism, but the amended complaint alleges the filter is essentially worthless. In the comments, there are discussions about a range of topics, including 4chan, the Nix community, AI expertise, copyright law, and the benefits of freely available knowledge.

### French tax officials use AI to spot 20k undeclared pools (2022)

#### [Submission URL](https://www.theguardian.com/world/2022/aug/29/french-tax-officials-use-ai-to-spot-20000-undeclared-pools) | 108 points | by [amelius](https://news.ycombinator.com/user?id=amelius) | [159 comments](https://news.ycombinator.com/item?id=36268907)

French tax authorities have used AI software to identify 20,000 undeclared private swimming pools resulting in €10m in tax receipts. Developed by Google and Capgemini, the system can identify pools via aerial images and cross-check them against land registry databases. The scheme was launched as an experiment in nine French departments and will now be extended nationwide. The authorities are also considering using the software to identify undeclared annexes, extensions and verandas. France is believed to have around 3.2 million private pools.

The French tax authorities have identified 20,000 undeclared swimming pools using an AI-powered system developed by Google and Capgemini. The system uses aerial images to identify swimming pools and cross-checks them against land registry databases. The scheme has resulted in €10m in tax receipts and may be extended to include the identification of other undeclared annexes and extensions. Discussions on the post touched on the potential implications of AI on infrastructure and regulation. Some pointed out concerns about subjective and discriminatory systems, while others felt that government intervention in physical inspections could have unintended consequences. Others emphasized the importance of manual verification when using AI and discussions on selective enforcement and illegal employment practices were also raised.

### Fatalities, 736 crashes: The shocking toll of Tesla’s Autopilot

#### [Submission URL](https://www.washingtonpost.com/technology/2023/06/10/tesla-autopilot-crashes-elon-musk/) | 54 points | by [0xedb](https://news.ycombinator.com/user?id=0xedb) | [21 comments](https://news.ycombinator.com/item?id=36269805)

A recent analysis by The Washington Post has revealed that Tesla's Autopilot driver-assistance system has been involved in many more crashes than initially reported, with 736 incidents since 2019. Furthermore, the number of deaths and serious injuries associated with Autopilot has increased to at least 17 fatalities and five serious injuries in the past year alone. Despite this, Tesla CEO Elon Musk maintains that Autopilot cars are safer than those piloted solely by humans; however, experts claim that the increase in incidents is due to Musk's decision to expand the technology's availability and remove radar sensors. Concerns have been raised over the number of fatalities compared to overall crashes, and the fact that the technology is being tested on the nation's roadways in real-time.

A recent analysis by The Washington Post has revealed that Tesla's Autopilot driver-assistance system has been involved in many more crashes than initially reported, with 736 incidents since 2019. However, experts claim that the increase in incidents is due to Musk's decision to expand the technology's availability and remove radar sensors. Concerns have been raised over the number of fatalities compared to overall crashes, and the fact that the technology is being tested on the nation's roadways in real-time. The comments on the post discuss the regulatory framework, the true safety statistics, the importance of attentive driving, and Tesla's responsibility in marketing Autopilot as a fully autonomous driving system. Some argue that regulator should step up and demand clear information sharing about the accidents, while others believe that people should accept the reality that a hands-on driver-assistance system has limitations and drivers should always be vigilant.

