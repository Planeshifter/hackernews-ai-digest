## AI Submissions for Mon Jun 03 2024 {{ 'date': '2024-06-03T17:12:23.610Z' }}

### Hacking millions of modems and investigating who hacked my modem

#### [Submission URL](https://samcurry.net/hacking-millions-of-modems) | 112 points | by [albinowax_](https://news.ycombinator.com/user?id=albinowax_) | [168 comments](https://news.ycombinator.com/item?id=40560010)

Today's top story on Hacker News unravels a cybersecurity mystery involving a user who discovered that their modem had been hacked. The user noticed unusual activity in their network logs, revealing that someone was intercepting and replaying their HTTP traffic across all their devices. Further investigation led them to an unknown IP address linked to DigitalOcean, which had a history of hosting phishing websites targeting a cybersecurity company. The user disconnected the compromised device, a Cox Panoramic Wifi gateway, and attempted to hand it over to their ISP for further analysis. The story highlights the intricate world of cyber threats and the complexities of securing personal networks against sophisticated attackers.

The discussion on Hacker News regarding the cybersecurity mystery of a hacked modem involves a deep dive into the technical aspects of network security and potential solutions to mitigate the risks associated with compromised devices. Users share experiences and advice related to dealing with security threats, examining the response of ISPs such as Cox and discussing the implications of responsible disclosure programs. There are also debates on the ethics of vulnerability disclosure and the motivations behind security research, touching on issues such as financial incentives and professional integrity. Additionally, the conversation delves into broader societal concerns around cybersecurity, poverty, and the prioritization of resources. Overall, the discussion reflects a mix of technical expertise, ethical considerations, and social awareness in addressing cybersecurity challenges.

### Grokfast: Accelerated Grokking by Amplifying Slow Gradients

#### [Submission URL](https://arxiv.org/abs/2405.20233) | 106 points | by [johnsutor](https://news.ycombinator.com/user?id=johnsutor) | [32 comments](https://news.ycombinator.com/item?id=40567165)

The latest submission on Hacker News is a paper titled "Grokfast: Accelerated Grokking by Amplifying Slow Gradients" by Jaerin Lee and three other authors. The paper delves into the phenomenon of grokking in machine learning, where delayed generalization occurs after near-perfect overfitting to training data. The authors aim to accelerate the generalization process of models experiencing grokking by analyzing and amplifying the slow-varying components of gradients. Their algorithm claims to accelerate grokking by more than 50 times with just a few lines of code. The experiments showcased the effectiveness of the approach across various tasks involving images, languages, and graphs. For those interested, the code is available for practical use.

The discussion on the submission regarding the paper "Grokfast: Accelerated Grokking by Amplifying Slow Gradients" covers various aspects of grokking in machine learning and its practical implications. 

- **utensil4778**: Makes a comment about AI creating new vocabulary and not requiring disambiguation pages.
- **svr**: Recalls seeing grokking demonstrated in MNIST and synthetic datasets and expresses interest in its practical applications.
- **fwlr**: Discusses the distinct aspects of grokking and its significance in resource allocation.
- **Legend2440**: Points out that practical applications should not necessarily expect cutting-edge research.
- **whmsclsm**: Highlights the role of grokking in modern ML and the importance of regularization.
- **sfk**: Reflects on the beginnings of the grokking phenomena and its implications in learning and research.
- **curious_cat_163**: Mentions signal processing in relation to the discussion.
- **bldbt**: Talks about MNIST Graph CNN and scaling models with OpenWebText dataset.
- **Imnimo**: Discusses grokking in critical zones of training data and its implications.
- **gssh**: Comments on the competitive effort to reproduce results on complex datasets.
- **QuadmasterXLII**: Mentions optical phenomena in the context of the discussion.
- **HarHarVeryFunny**: Refers to a recent paper on a deep model related to grokking.

These comments show a diverse range of perspectives on grokking, its applications, implications, and challenges in the field of machine learning.

### Mamba-2 â€“ State Space Duality

#### [Submission URL](https://tridao.me/blog/2024/mamba2-part1-model/) | 143 points | by [bratao](https://news.ycombinator.com/user?id=bratao) | [28 comments](https://news.ycombinator.com/item?id=40564067)

The release of Mamba-2 brings a new structured state space model (SSM) variant, addressing key questions regarding the conceptual connections between state space models and attention, as well as the efficiency in training. The SSD model, part of Mamba-2, introduces structured state space duality, which includes a layer that can be integrated into neural networks efficiently. The SSD algorithm ensures more efficient computation of SSD layers compared to previous SSMs.

The SSD model, at its core, involves a structured state space model with a scalar times identity structure for improved performance. Additionally, multihead SSMs can handle multiple channels of data independently, enhancing the model's versatility. Stay tuned for more insights in the upcoming parts of the blog post series!

The discussion on the submission about Mamba-2 and its structured state space model (SSM) variant includes various insights and debates. Users discuss the efficiency and improvements in training of the SSD model introduced in Mamba-2, highlighting its benefits such as efficient computation of SSD layers compared to previous SSMs. 

There is a comparison made between Transformers and humans in recalling tasks, noting that humans underperform Transformers in certain recall tasks. Additionally, the discussion delves into the capabilities and limitations of different models in tasks like translation and memory recall. 

Some users talk about Quadratic Transformers outperforming other models in attention recall tasks, while others emphasize the importance of linear SSMs and the advancements made in Mamba-2. Debate arises over the practical benefits of different models like RNN and Mamba in terms of layers, transformations, and efficiency in training.

Furthermore, there are discussions on the scalability of attention mechanisms, the differences between Transformers and traditional models like LSTMs, and the training processes of Mamba-2. An explanation of Mamba-2's improvements over Mamba-1 from both a training and inference perspective is also given. The conversation includes technical insights, comparisons between models, and practical implications for various tasks in the field of natural language processing.

### The simdjson library

#### [Submission URL](https://simdjson.org/) | 57 points | by [fanf2](https://news.ycombinator.com/user?id=fanf2) | [23 comments](https://news.ycombinator.com/item?id=40560233)

A new library called simdjson is revolutionizing the way servers parse JSON, making the process faster and more efficient than ever before. This library utilizes SIMD instructions and microparallel algorithms to achieve remarkable speeds, outperforming other popular JSON parsers by a significant margin.

Some key highlights of the simdjson library include its incredible speed - over 4x faster than RapidJSON and 25x faster than JSON for Modern C++, its user-friendly APIs, strict JSON and UTF-8 validation, automatic CPU-tailored parser selection, and robust design focused on reliability and performance.

Widely used by industry giants like Microsoft, Google, and Intel, simdjson is also integrated into various technologies such as ClickHouse, Shopify, and Node.js runtime. Additionally, the library offers support for multiple languages and platforms, making it accessible and versatile for developers across different ecosystems.

With features like On Demand API for blazing speeds, minification capabilities, standalone UTF8 validation, multithreaded processing for massive JSON files, support for JSON Pointer, and runtime dispatch for optimized performance, simdjson stands out as a game-changer in the world of JSON parsing. Whether you're working on a Python, Rust, Go, or C# project, simdjson has got you covered with its wide range of ports and bindings.

The discussion around the simdjson library on Hacker News delves into various aspects of JSON parsing, binary formats, and hardware optimizations. Some users express their opinions on using binary formats like Protocol Buffers for improved performance, while others highlight the importance of human-readable properties in JSON compared to binary formats. The conversation touches on topics like file formats such as Amiga's IFF and different perspectives on binary format vs. human-readable format discussions. Additionally, comments discuss the use of SIMD instructions like AVX-256 for faster JSON parsing and how hardware acceleration can optimize parsing performance. There is also a conversation about ARM instructions like FJCVTZS and their application in JavaScript for floating-point conversions.

### Scientists should use AI as a tool, not an oracle

#### [Submission URL](https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool) | 113 points | by [randomwalker](https://news.ycombinator.com/user?id=randomwalker) | [103 comments](https://news.ycombinator.com/item?id=40568026)

The latest article on Hacker News delves into the importance of viewing AI as a tool rather than an oracle in scientific research. The piece discusses how the hype surrounding AI can lead to flawed research, perpetuating a cycle of misinformation and misguided expectations. The authors emphasize the significance of maintaining a skeptical mindset in the face of AI's capabilities, highlighting the need for thorough validation and reproducibility in ML-based science. By acknowledging the potential pitfalls of overreliance on AI and promoting a culture of critical inquiry, researchers can work towards improving the quality and integrity of scientific discoveries in the field.

1. **nklnkl**: The commenter expresses concern about the susceptibility of scientific fields to fall for AI hype, resulting in flawed research and inaccurate predictions. They mention the danger of self-fulfilling prophecies and the importance of distinguishing between experts and machines in evaluating predictions.

2. **gdlsk**: Responding to nklnkl's comment, gdlsk points out the issue with blindly trusting machines, citing the example of AI safety proponents critiquing the credentials of AI Safety proponents.

3. **starship006**: starship006 engages in a discussion about the flaws in the argument structure broadly criticizing the credentials of AI safety proponents.

4. **lcksr**: lcksr contributes by cautioning against trusting machines and emphasizes the importance of human judgment over blindly relying on AI technologies, criticizing the arguments based on Harry Potter fandom.

5. **SrslyJosh**: SrslyJosh mentions the necessity for AI safety proponents to understand the technology objectively, warning against creating potential dangers inadvertently.

6. **mmbs**: mmbs introduces the idea of corporations being responsible for creating significant threats to humanity, mentioning Skynet, capitalism, and the Internet of Things.

7. **thrwnm**: Discussing the potential misuse of GPT and the implications of people following devices without critical thinking, thrwnm emphasizes the importance of distinguishing between genuine information and manipulated content.

8. **grdsj**: grdsj critiques the accuracy and specificity of the submitted article, calling it "Garbage" and pointing out various errors.

9. **cptnkrtk**: cptnkrtk discusses the challenges in professional work related to language models like GPT and cautions against blindly trusting AI-generated content due to potential mistakes and biases.

10. **tmbrt & ntnvs**: These two users engage in a detailed discussion about the complexities of AI models, the implications of wrong responses, and the challenges of ensuring correct outputs based on the input provided.

Overall, the discussion highlights the importance of maintaining a critical mindset towards AI technologies, questioning their reliability, and considering the ethics and consequences of their applications in various fields.

### AMD Unveils Ryzen 9000 CPUs for Desktop, Zen 5

#### [Submission URL](https://www.anandtech.com/show/21415/amd-unveils-ryzen-9000-cpus-for-desktop-zen-5-takes-center-stage-at-computex-2024) | 327 points | by [rx_tx](https://news.ycombinator.com/user?id=rx_tx) | [278 comments](https://news.ycombinator.com/item?id=40559368)

AMD made waves at Computex 2024 with the unveiling of its highly anticipated Ryzen 9000 CPUs, powered by the cutting-edge Zen 5 microarchitecture. These processors promise a significant performance boost over their predecessors, Zen 4 and the Ryzen 7000 series. The Ryzen 9000 lineup includes impressive SKUs like the Ryzen 9 9950X, featuring 16 cores and a maximum boost frequency of 5.7 GHz.

One of the key highlights of the Ryzen 9000 series is the use of the AM5 socket, offering longevity and compatibility with future platforms. Accompanying these CPUs are the X870E and X870 chipsets, boasting features like USB 4.0, PCIe 5.0, and enhanced memory profile support.

Zen 5 introduces notable architectural improvements, such as an enhanced branch predictor, wider pipelines, and a deeper out-of-order instruction window size. These enhancements aim to deliver a 16% increase in IPC over Zen 4, promising improved performance in desktop workloads.

Overall, AMD's Ryzen 9000 series is set to redefine desktop computing with its Zen 5 microarchitecture, pushing the boundaries of speed and efficiency for tech enthusiasts and professionals alike.

The discussion on Hacker News regarding the unveiling of AMD's Ryzen 9000 CPUs and the use of Zen 5 microarchitecture at Computex 2024 delved into a comparison with Intel's CPUs, specifically focusing on AVX-512 instructions. Some users highlighted the differences between Intel and AMD CPUs regarding AVX-512 support and throughput, predicting how future developments might impact different market segments.

The conversation also covered the implications of AVX-512 on system costs, strategy, and segmentation by Intel, contrasting it with AMD's approach. There was a debate on the implementation and impact of AVX-512 on performance and efficiency, with insights shared on the technical aspects of clock speed management and execution efficiency between AMD and Intel CPUs.

Additionally, discussions touched on the execution units and throughput optimizations, FP16 support, and FP math latency in Zen 5 compared to Zen 4. There were detailed explanations on instruction units, dispatchers, and throughput enhancements in Zen 5, emphasizing the architectural improvements and advancements in AMD's latest offerings. Moreover, the conversation highlighted differences in instruction execution latency, SIMD support, and memory throughput between AMD and Intel architectures, showcasing the technical depth of the discussion.

### Google can keep your phone if you send it in for repair with non-OEM parts

#### [Submission URL](https://www.androidauthority.com/google-keeps-phones-with-non-oem-parts-3448350/) | 22 points | by [josephcsible](https://news.ycombinator.com/user?id=josephcsible) | [5 comments](https://news.ycombinator.com/item?id=40566186)

Google's stringent repair policy has come under fire recently, with the revelation that the tech giant will keep your device if non-OEM parts are detected. This controversial practice, implemented since July 2023, has stirred up frustration among consumers who feel that companies like Google are restricting their ownership rights. The issue is not isolated to Google, as other tech giants like Samsung and Apple have also been criticized for similar anti-consumer behaviors. The right to repair movement continues to gain traction amidst concerns that self-repair programs are more for show than actual consumer empowerment.

- **r-jhnv**: Suggests that legal protections for company property are inserted in the terms and conditions, and by extending the possession or ownership rights of the device, one can change the parts in page 7 of the terms and conditions, stating when one can change legal protections.
  
- **JohnFen**: Expresses dissatisfaction with Google's business model, mentioning that just like Apple and Samsung, they also want to replace smartphones once they die. Criticizes the hostile treatment of customers by these companies.
  
- **lhamil64**: Agrees with the sentiment, stating that smartphones inevitably become dumbphones.
  
- **JohnFen**: Confirms the transition of smartphones into dumbphones and expresses skepticism towards dumbphones, citing the limited capabilities of smartphones. 
  
- **jstnclft**: Suggests an alternative option, recommending a practical solution and shares a link to a potential phone model that might work well.

Overall, the discussion revolves around frustrations with tech giants like Google, Apple, and Samsung for their anti-consumer behaviors regarding device repairs and replacements. The conversation also touches upon the dwindling capabilities of smartphones and proposes alternative options for users.

