## AI Submissions for Mon Apr 08 2024 {{ 'date': '2024-04-08T17:10:28.706Z' }}

### Hello OLMo: A truly open LLM

#### [Submission URL](https://blog.allenai.org/hello-olmo-a-truly-open-llm-43f7e7359222?gi=760105621962) | 337 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [62 comments](https://news.ycombinator.com/item?id=39974374)

The Allen Institute for AI (AI2) has unveiled OLMo 7B, a groundbreaking open large language model that comes with pre-training data and training code, revolutionizing the AI landscape. The release of OLMo aims to enhance understanding and transparency in AI model development, empowering researchers and developers to collectively advance the science of language models. The OLMo framework features a suite of open AI development tools, including full pretraining data, model weights for four variants at the 7B scale, training code, evaluation suite, and more. By providing access to the training data and evaluation ecosystem, OLMo enables researchers to work faster, reduce carbon footprints, and build on previous models for lasting results. AI2's commitment to openness and transparency with OLMo sets a new standard in the AI community, fostering collaboration, scientific understanding, and responsible AI technology development. The collaboration with industry partners like AMD, CSC, and academia further enhances the reach and impact of this initiative. With OLMo, AI researchers and developers now have the opportunity to delve deep into model creation, evaluation methods, and data, paving the way for a more inclusive and scientifically-driven approach to language model research.

The discussion on Hacker News about the unveiling of the Allen Institute for AI's OLMo 7B covers various aspects. One thread discusses the licensing of the model, with participants pointing out the complexities and potential implications of different licenses being used. Another thread delves into the legal implications and restrictions related to the MR Agreement, while also touching on issues around intellectual property rights and licensing of datasets like Pile. There is a discussion on the implications of the model's training on AMD GPUs and potential collaboration with Databricks, as well as a conversation about the licensing and risk classification of datasets. A user raises concerns and ethical considerations surrounding governance, legal implications, and potential revisions of laws related to language models. Additionally, there are comments on the licensing, restrictions, and legal complexities of using certain datasets, along with discussions on the technical aspects and training processes of language models like OLMo 7B. Some users express surprise at the fast performance of smaller-sized models and share insights into running inference models effectively. There are also discussions related to story generation, AI-generated text, and the comparison of different language models.

Furthermore, there is a thread critiquing blogging platforms like Medium for their user experience and subscription model, along with discussions on the transparency and clarity in licensing decisions and the potential future developments and advancements in language model research.

### Show HN: Shorebird 1.0, Flutter Code Push

#### [Submission URL](https://github.com/shorebirdtech/shorebird) | 140 points | by [eseidel](https://news.ycombinator.com/user?id=eseidel) | [54 comments](https://news.ycombinator.com/item?id=39973150)

Today on Hacker News, the top story is about Shorebird, a project focused on Flutter and tools for Flutter businesses. The Shorebird repository has just reached version 1.0, marking a significant milestone. This release includes packages like shorebird_cli for command-line interactions, shorebird_code_push_client for Dart applications to interact with the ShoreBird CodePush API, and more. The project is actively maintained with contributions from a community of developers. If you're interested in getting involved, you can check out their Discord channel for contributing. Shorebird is licensed under both Apache License, Version 2.0, and MIT license, giving users flexibility in how they can use the project. If you're working with Flutter and interested in code push solutions, Shorebird might have the tools you need. Visit shorebird.dev for more details.

The top discussion on Hacker News regarding the Shorebird project includes various viewpoints on different aspects of Flutter and Google's involvement. 

1. One user expressed concerns about Google's past history of abandoning products and the potential risk of Flutter being a victim of this trend. They highlighted the importance of long-term commitment and community support for the sustainability of projects like Flutter.
2. Another user emphasized that Google needs to address the challenge of balancing priorities and trade-offs in its projects, especially in terms of long-term commitment and downstream impacts on developers.
3. A contributor from Shorebird team shared excitement about the project's progress and the community involvement in pushing Flutter forward, aiming to create a conducive environment for Flutter's advancement.
4. A detailed discussion compared the technical aspects of Flutter with other frameworks like React Native, highlighting strengths and weaknesses in terms of UI rendering and performance considerations.
5. Some users shared their experiences with Flutter development and related projects, discussing performance issues and features they found beneficial or lacking in the platform.
6. Lastly, there was a conversation about building applications seamlessly across platforms, discussing the accessibility support and improved performance provided by Flutter compared to other frameworks like React Native.

Overall, the discussion revolved around the technical capabilities, community support, and long-term sustainability considerations of Flutter in the context of the Shorebird project and Google's involvement in the ecosystem.

### Show HN: Beyond text splitting â€“ improved file parsing for LLMs

#### [Submission URL](https://github.com/Filimoa/open-parse) | 198 points | by [serjester](https://news.ycombinator.com/user?id=serjester) | [40 comments](https://news.ycombinator.com/item?id=39966534)

The latest project making waves on Hacker News is Filimoa's "Open Parse." This innovative library aims to revolutionize file parsing for Large Language Models (LLM) beyond just text splitting. Open Parse offers a flexible and user-friendly solution for chunking complex documents in a visually discerning manner, allowing for more accurate results in AI applications. Unlike other layout parsers, Open Parse stands out with its visually-driven approach, Markdown support, and high-precision table extraction capabilities. The project showcases examples, such as semantic processing and serialization of results, demonstrating its ease of use and extensibility. Developers can dive into Open Parse's core library by installing it via pip and explore additional features like ML table detection for enhanced document parsing. With its aim to simplify and enhance document parsing for AI applications, Open Parse is gaining attention for its potential to streamline processing tasks effectively.

The discussion around Filimoa's "Open Parse" project on Hacker News delved into the concept of chunking documents for more accurate results in AI applications. Users discussed strategies for document chunking, the quality of chunking pieces in context, and the potential performance improvements in searching by running multiple variations of search phrases. Other topics included comparison to existing technologies, suggestions for extending benchmarks, and considerations about licenses. Additionally, there was a mention of the need for correct table detection and parsing in PDFs, alongside insights into handling complex tables and extracting data from documents. Users shared experiences with different technologies, such as OCR, and explored various aspects of document analysis and processing.

### After AI beat them, professional Go players got better and more creative

#### [Submission URL](https://www.henrikkarlsson.xyz/p/go) | 398 points | by [iNic](https://news.ycombinator.com/user?id=iNic) | [200 comments](https://news.ycombinator.com/item?id=39972990)

In a surprising turn of events, professional Go players experienced a remarkable surge in performance and creativity following the introduction of AlphaGo, an AI that defeated the best human players. Contrary to suspicions of cheating, these players genuinely improved their game, showcasing a blend of AI-influenced and novel strategies. This transformation in the Go community highlights a common pattern in history where once-"impossible" feats become common standards after initial breakthroughs. Similarly, as seen in chess after DeepBlue's victory, the rise of AI can inspire human players to reach new heights rather than displace them. The shift towards creativity and enhanced skills in Go occurred post-AlphaGo's appearance and was further amplified by the open-source engine Leela Zero, enabling players to deeply understand and leverage AI reasoning. This phenomenon hints at the untapped potential across various competitive domains, suggesting that AI could propel individuals to surpass existing limitations and excel further.

Ultimately, the partnership between AI and human ingenuity could lead to a resurgence of innovation and excellence, pushing the boundaries of what was once deemed unattainable.

The discussion on Hacker News centered around the impact of AI on professional Go and chess players, drawing parallels between the introduction of AI like AlphaGo and DeepBlue to the subsequent improvements in human players' performance. The comments touched on various topics such as the evolving strategies in chess due to computer analysis, the challenges faced by younger players in competitive events, the scoring systems in different sports, the potential changes to tournament formats, and even debated the idea of removing draws from chess games. Some users discussed the complexity of endgames in chess and the implications of different rule modifications. Additionally, there was a conversation about the popularity of Chess960 compared to traditional chess. The discussions also included recommendations for online platforms for playing Go and chess, and shared insights on ongoing tournaments.

### Direct Nash Optimization: Teaching language models to self-improve

#### [Submission URL](https://arxiv.org/abs/2404.03715) | 50 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [11 comments](https://news.ycombinator.com/item?id=39972800)

The paper titled "Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences" introduces an algorithm called DNO that leverages preference feedback to help large language models enhance themselves. Unlike traditional approaches that rely on reward maximization, DNO directly optimizes general preferences, resulting in improved model performance. In experiments, the Orca-2.5 model aligned by DNO outperformed GPT-4-Turbo and other models, showcasing a significant win-rate increase on AlpacaEval 2.0. This advancement in optimizing language models could lead to notable progress in the field of artificial intelligence.

The discussion on the submission "Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences" encompasses various viewpoints on the efficacy and implications of the DNO algorithm and its application in improving large language models. 

- Users like "firejake308" expressed their impressiveness with the 7B parameter Orca-2.5 model's ability to outperform the GPT-4-Turbo by 33% on the AlpacaEval 2.0 dataset, highlighting the student surpassing the teacher scenario. 
- Contrasting views were brought up by "crbyrsst," who suggested that the teacher-student analogy might not be appropriate, indicating that the modeling should focus on learning rather than surpassing teachers.
- Another user, "kjs," provided insights on the high costs associated with deploying advanced language models like GPT-4, emphasizing the resource-intensive nature of training and inference processes which could cost up to $6000 depending on varying factors like model size and training duration.
- "vsrg" mentioned the importance of cost considerations in preparing training data to help models learn from mistakes effectively.
- Additionally, "Grimblewald" and "dr_dshiv" touched upon the challenges related to the dissemination and verification of research papers and the significance of human preferences in model development.

Overall, the discussion delved into the technical advancements, ethical considerations, and practical implications of leveraging the DNO algorithm to enhance language models with general preferences.

### Anthropic's Haiku Beats GPT-4 Turbo in Tool Use

#### [Submission URL](https://docs.parea.ai/blog/benchmarking-anthropic-beta-tool-use) | 48 points | by [Joschkabraun](https://news.ycombinator.com/user?id=Joschkabraun) | [14 comments](https://news.ycombinator.com/item?id=39971839)

Today on Hacker News, one of the top stories is about Anthropic's Haiku beating GPT-4 Turbo in tool use - sometimes. The post discusses the comparison between the two models and highlights the unique capabilities of Anthropic's Haiku in certain scenarios. It delves into the nuances of building and evaluating retrieval systems, shedding light on the importance of evaluation metrics for labeled data in LLM applications. Additionally, the evolution of the ChatGPT model from March to June is analyzed, showcasing the advancements made during this period. This insightful post provides a comprehensive overview of the developments in AI technology and the progress in natural language processing models.

The discussion on the submission revolves around different approaches and comparisons in using local LLMs for JSON data. Some users are sharing their experiences with local LLMs responding to JSON calls and the challenges faced in getting them to work effectively. There is a mention of Anthropic's function calls returning proper JSON files but being somewhat fragile, with hopes for continuous improvement. Other users discuss experimenting with APIs and parsing function call responses similarly to GPT-3. The conversation also touches upon the comparison of model capabilities based on prompt-based training and the importance of functionality calls in API design. Lastly, there is a reference to Claude JSON model towards the end of the discussion.

