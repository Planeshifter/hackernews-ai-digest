## AI Submissions for Sun May 12 2024 {{ 'date': '2024-05-12T17:11:11.257Z' }}

### Did GitHub Copilot increase my productivity?

#### [Submission URL](https://trace.yshui.dev/2024-05-copilot.html#did-github-copilot-really-increase-my-productivity) | 206 points | by [fzliu](https://news.ycombinator.com/user?id=fzliu) | [277 comments](https://news.ycombinator.com/item?id=40338241)

The author reflects on their experience with GitHub Copilot, discussing both the benefits and drawbacks of using the AI tool. After a year of free access, they found Copilot helpful for generating boilerplate code but ultimately concluded that they are more productive without it. The author highlights two key issues with Copilot: its unpredictability in providing accurate code suggestions and its speed compared to traditional language servers like clangd. Despite the initial novelty, the author ultimately decides that Copilot does not significantly enhance their productivity and would not pay for it in the future.

The discussion on the Hacker News submission titled "Did GitHub Copilot Really Increase My Productivity?" delved into various aspects related to Entity Framework, ORM, and query optimization.

- **marcus_holmes**: Shared their experience with Microsoft's Entity Framework, highlighting issues with Lazy Loading and code suggestions.
- **rspl**: Pointed out misconceptions about Lazy Loading in Entity Framework and its impact on performance.
- **LandR**: Expressed frustration with Entity Framework, especially in handling lazy loading and performance issues.  
- **nnsnst**: Discussed inconsistencies in Entity Framework Core 8 and recommended checking the latest version for expected behavior.
- **moron4hire**: Shared their 5-year experience with Entity Framework, mentioning difficulties in managing schema changes and querying references.
- **nrcry**: Shared insights on ORM, emphasizing the importance of proper database design and query optimization outside of ORM usage.
- **rrwsmth**: Discussed their experience with ActiveRecord, Ecto in Elixir/Phoenix, and the challenges of debugging and performance optimization.
- **ndrm**: Highlighted the benefits of writing custom queries and tweaking execution plans over relying solely on ORM frameworks.

The conversation covered a wide range of experiences and opinions related to Entity Framework, ORM usage, and database query optimization in software development.

### Automatically Detecting Under-Trained Tokens in Large Language Models

#### [Submission URL](https://arxiv.org/abs/2405.05417) | 176 points | by [veryluckyxyz](https://news.ycombinator.com/user?id=veryluckyxyz) | [25 comments](https://news.ycombinator.com/item?id=40332651)

In the latest submission on Hacker News, a paper titled "Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models" discusses the issue of glitch tokens in language models that can lead to unexpected behavior. The authors, Sander Land and Max Bartolo, propose methods for identifying these under-trained tokens by analyzing tokenizers, model weights, and prompts. Their research sheds light on improving the efficiency and safety of language models. With 16 pages and 4 figures, this paper delves deep into the realm of Large Language Models. For those interested, the PDF of the paper is available for viewing.

1. User "hlsnkndrw" shared a Computerphile video about glitch tokens and found the article interesting. User "3abiton" highlighted that the video describes the problem but hasn't fully read the pre-print article.
2. User "65a" was surprised to hear that Canadian companies' models contained under-trained tokens related to hockey, while a German user appreciated the understanding of tokenization impacts on models. They noted significant findings on error correction returns.
3. User "londons_explore" discussed the importance of looking for under-trained tokens effectively in the network to balance training data and weights. User "mycll" expressed uncertainty regarding deleting weights not following them, and User "dssd" suggested compressing under-merged homomorphic models.
4. User "sfk" shared on random matrix theory for diagnostic training rules, spectral density correlation matrix weights, and implications on truncated power law exponential alpha.  
5. User "anewhnaccount3" suggested a solution to training tokens for Large Language Models, prompting a discussion on tokenizers and training issues. User "sebzim4500" explained the challenge with tokenizers and under-trained tokens, and User "btlr" shared a blog post supporting pre-train models which they found convenient and essential.
6. User "bjrnsng" raised the concern that abstract filing techniques could be monetized for downloading weights secretively. User "krpthy" discussed the reasons behind using BPE in Unigram LLMs, while User "dTal" pointed out the secrecy and importance of source weights.
7. User "yrwb" mentioned people wanting source code and expressed support for efforts against piracy and illicit behavior. User "SolidGoldMagikarps" was praised for their work in countering such practices.
8. User "sp332" commented on the feasibility of large-scale corpus processing. User "swhn" discussed the scalability of tokenizer training compared to model training, with insights on training statistics and data frequency calculations.

Overall, the discussion focused on the technical nuances and implications of under-trained tokens in large language models and efforts to improve training and tokenization processes for better model efficiency and safety.

### Show HN: "data-to-paper" â€“ autonomous stepwise LLM-driven research

#### [Submission URL](https://github.com/Technion-Kishony-lab/data-to-paper) | 133 points | by [roykishony](https://news.ycombinator.com/user?id=roykishony) | [49 comments](https://news.ycombinator.com/item?id=40331850)

I found an interesting project on Hacker News called "data-to-paper" by Technion-Kishony-lab, focusing on AI-driven research from data to human-verifiable research papers. This framework aims to guide LLM and rule-based agents through all the steps of scientific research, from data annotation to writing a complete research paper while maintaining scientific values like transparency and verifiability. Key features of data-to-paper include being field-agnostic, supporting open or fixed-goal research, creating transparent manuscripts with linked data, providing coding guardrails, involving humans in the research process, and enabling record & replay for transparency.

The project's goal is to understand the capabilities and limitations of LLM-driven research and find ways to accelerate research while upholding key scientific values. Researchers can try out data-to-paper with their own data and contribute feedback and suggestions to enhance the framework.

In the discussion on the submission about the "data-to-paper" project, several users shared their thoughts. 

- QuadmasterXLII mentioned that the paper reviewing session was challenging due to the AI-generated content lacking substance and confidentiality, emphasizing the importance of human involvement in the reviewing process.
- 8organicbits appreciated the framework's rigorous quality control, highlighting the collaboration between humans and AI in creating error-proof manuscripts.
- Others, like srss, raised concerns about potential biases in LLMs and the limitations they might impose on scientific research.
- Users like rbwwllms discussed the potential of structured data and genetic loci mapping in advancing research.
- nqd expressed the significance of AI in propelling scientific research forward but also touched on the need for a balance between AI and human involvement in the research process.
- escape_goat emphasized the importance of meaningful review processes to ensure the credibility and integrity of research outcomes.
- jffrygst referenced Stanislaw Lem's work in predicting AI's role in transforming research processes.

Overall, the discussion touched on various aspects of leveraging AI in scientific research, highlighting the need for transparency, quality control, human oversight, and meaningful review processes to uphold the values of scientific research.

### Robot dogs armed with AI-aimed rifles undergo US Marines Special Ops evaluation

#### [Submission URL](https://arstechnica.com/gadgets/2024/05/robot-dogs-armed-with-ai-targeting-rifles-undergo-us-marines-special-ops-evaluation/) | 34 points | by [hiatus](https://news.ycombinator.com/user?id=hiatus) | [8 comments](https://news.ycombinator.com/item?id=40336606)

The United States Marine Forces Special Operations Command (MARSOC) is exploring the potential of arming new robotic "dogs" developed by Ghost Robotics with gun systems from Onyx Industries. These quadrupedal unmanned ground vehicles may be used for reconnaissance and surveillance, with the capability of being armed for remote engagement. The robots are armed with Onyx's SENTRY remote weapon system, featuring AI-enabled digital imaging and human-in-the-loop control for fire decisions. The rise of armed robotic dogs reflects a broader trend in military experimentation with small unmanned ground vehicles. While the technology offers benefits in terms of reconnaissance and reducing risks to human personnel, it also raises significant ethical concerns about the future of autonomous weapons systems and the potential for broader domestic uses. As these technologies evolve, it will be critical to address these ethical considerations and ensure compliance with existing policies and international regulations.

The discussion on the submission includes various viewpoints and themes. 

- "jmslk" references a TED talk by Daniel Suarez on the topic of being able to make life or death decisions similar to the scenario described in the article, highlighting the role of human input in such critical choices.
- "gmrc" connects the use of AI in decision-making to a broader context about accepting AI decisions, drawing from an example involving Israel.
- "thebruce87m" humorously mentions the scenario where hospitals might schedule Cesarean sections during holidays leading to doctors being at home, pondering what happens in emergency situations during such times.
- "4gotunameagain" delves into the moral and ethical implications of removing human decision-makers from critical choices, emphasizing the importance of imperfect friend or foe detection preventing such scenarios.
- "bltzr" simply comments with "Baddies."
- "wldrhythms" and "Wool2662" make positive comments about the idea of robots bringing democracy and freedom.
- "pntl" adds a light-hearted comment about sharks being armed with frickin laser beams.

The discussion touches on themes of ethics, human involvement in decision-making, democratic values, and humor, providing a diverse range of perspectives on the potential implications of armed robotic dogs in military settings.

