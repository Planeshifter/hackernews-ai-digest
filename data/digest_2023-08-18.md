## AI Submissions for Fri Aug 18 2023 {{ 'date': '2023-08-18T17:09:21.362Z' }}

### You probably donâ€™t need to fine-tune an LLM

#### [Submission URL](https://www.tidepool.so/2023/08/17/why-you-probably-dont-need-to-fine-tune-an-llm/) | 168 points | by [gk1](https://news.ycombinator.com/user?id=gk1) | [72 comments](https://news.ycombinator.com/item?id=37174850)

Today's post is for all the builders out there focused on developing LLM (large language models) applications. As a builder, it's crucial to know what tools are available in your toolbox and when to use them. With the booming experimentation in the LLM field, there's a wide range of techniques and acronyms to navigate, like fine-tuning, RLHF, RAG, and chain-of-thought.

However, it's easy to get stuck in decision paralysis when determining the best technical approach for your app, even if your ultimate goal is simply to build an app for a specific purpose. Many people encounter issues when using base model LLMs, such as models not returning desired results, providing nonsensical answers, or lacking knowledge on certain topics they weren't trained on. This is when many consider fine-tuning as a solution.

In this post, we'll explore why fine-tuning might not be necessary for your app. People often turn to fine-tuning when they need additional structure or style from the LLM beyond open-ended question answering, or when they want the LLM to answer questions using knowledge that it wasn't trained on. However, a combination of two techniques, few-shot prompting and retrieval-augmented generation (RAG), can often suffice for most use cases.

So, why do people think fine-tuning is helpful in the first place? Fine-tuning involves taking a pre-trained LLM and training it further on a smaller, domain-specific dataset to make it more specialized for a specific task or data. However, it's worth noting that as of August 2023, OpenAI only supports fine-tuning for its GPT-3 models, not the newer GPT-3.5 and GPT-4 models that power ChatGPT.

While the base LLMs have a range of abilities like question answering and summarization, some may find them too generic or unaware of their particular use case. The desire to fine-tune often stems from the belief that more training will improve accuracy in the target task. However, there are several reasons why the existing base LLM and the aforementioned techniques may be sufficient:

1. It's cheaper and leverages the existing training of the base LLM.
2. Techniques like RAG allow access to private knowledge bases by storing embeddings in vector databases and querying them semantically.
3. Desired style or format can be achieved using a more specific prompt and improved with few-shot prompting by providing examples within the context window.
4. Providing additional context in each prompt is not a token usage concern, as token usage isn't expensive.
5. Fine-tuning doesn't guarantee accurate answers and doesn't prevent LLM from hallucinating, whereas using clear questions with a source provided to the base model may result in more reliable answers.

In conclusion, the combination of few-shot prompting and retrieval-augmented generation techniques can often meet the needs of LLM applications without resorting to the complexity and cost of fine-tuning.

The discussion on the submission primarily revolves around the effectiveness and necessity of fine-tuning large language models (LLMs). 

One commenter suggests that using retrieval-augmented generation (RAG) and few-shot prompting can often be sufficient for most use cases, eliminating the need for fine-tuning. They highlight the benefits of these techniques, such as leveraging existing training, accessing private knowledge bases, and achieving desired style or format. Additionally, they point out that fine-tuning doesn't guarantee accurate answers and can result in the model hallucinating.

Another commenter shares their positive experience using a large context window and examples for challenging tasks. They note that breaking down complex questions into multiple steps within the context window can be effective.

Some commenters discuss the limitations and challenges of fine-tuning, including the need for a large amount of high-quality training data and the effort involved. They argue that for most developers relying on pre-trained models, using context-specific prompts is sufficient.

The discussion also touches on other topics related to LLMs, such as the potential dangers of hallucination, the benefits of retrieval-augmented generation, the challenges of working with large models, and the significance of model size and training data in the effectiveness of LLMs.

### Expanding Transformer size without losing function or starting from scratch

#### [Submission URL](https://arxiv.org/abs/2308.06103) | 49 points | by [og_kalu](https://news.ycombinator.com/user?id=og_kalu) | [25 comments](https://news.ycombinator.com/item?id=37178842)

Researchers Andrea Gesmundo and Kaitlin Maile have proposed six composable transformations to incrementally increase the size of transformer-based neural networks while preserving functionality. This approach allows for the expansion of the model's capacity without having to restart from scratch and randomly initialize all parameters. The authors provide proof of exact function preservation under minimal initialization constraints for each transformation. These methods could enable more efficient training pipelines for larger and more powerful models by progressively expanding the architecture throughout training. The paper, titled "Composable Function-preserving Expansions for Transformer Architectures," explores these methods and their potential impact on training state-of-the-art neural networks.

The discussion on this submission covered various aspects of the proposed method for expanding transformer-based neural networks. One user mentioned that they were curious about whether this approach could work for small models as well. Another user shared a link to a paper discussing the application of similar techniques to small language models. There was a discussion around the practicality and effectiveness of the proposed method, with some users expressing skepticism and others acknowledging the need for more experimental evidence. There was also a mention of general concepts like transfer learning and the potential impact of expanding and contracting Transformers on model size and behavior. Additionally, there were humorous comments and references to science fiction. One user highlighted the similarities between the proposed method and the concept of lifecycle software objects. Another user speculated about the future capabilities of AI and the potential for AI to invent things on its own. Overall, the discussion showcased a mix of curiosity, skepticism, and enthusiasm for the proposed method and its potential implications.

### Show HN: ChatGPT: craft the right question, unlock the best answer

#### [Submission URL](https://maestro-chatgpt.vercel.app/) | 24 points | by [gtestault](https://news.ycombinator.com/user?id=gtestault) | [5 comments](https://news.ycombinator.com/item?id=37174246)

Today's top story on Hacker News is about Maestro, a new browser extension for ChatGPT. Maestro aims to enhance the chat experience by providing users with the ability to craft better prompts, in turn unlocking more accurate and helpful answers. With Maestro, users can manage prompts, apply parameters, and even use a built-in PowerPoint maker. The extension is integrated into chat.openai.com, making it easily accessible. One notable feature of Maestro is its advanced prompting, which allows users to create parametrized prompts for even more specific responses. Additionally, Maestro ensures privacy and security as it runs entirely on the client-side without making any external web calls. The extension is also open-source, encouraging community contribution. If you're looking to supercharge your prompts and maximize the potential of ChatGPT, Maestro might be worth checking out!

The discussion around the Maestro browser extension for ChatGPT on Hacker News includes the following points:

- A user named "gtstlt" mentions that they are not currently using the extension due to a recent change in the ChatGPT UI. They suggest trying out the extension on the latest release on GitHub.
- Another user, "CapstanRoller," finds the scrolling behavior of the extension to be jarring. They explain that when scrolling downward, there is a flicker or jump to the bottom of the page.
- "somedude895" highlights an interesting use case for ChatGPT with the Maestro extension - creating Powerpoint presentations.
- "nthnldnsr" points out that Maestro does not meet the requirements of a "Show HN" (Show Hacker News) post, which is a type of submission where users showcase their projects. The user does not specify the exact requirements.
- In response to "nthnldnsr," another user named "nml" shares a link discussing the specific requirements for a "Show HN" post.

Overall, the discussion touches on issues with the extension's user interface, potential use cases for creating Powerpoint presentations, and a debate over whether the submission meets the criteria for a "Show HN" post.

