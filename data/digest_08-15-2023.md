## AI Submissions for Tue Aug 15 2023 {{ 'date': '2023-08-15T17:10:02.422Z' }}

### Bayesian Flow Networks

#### [Submission URL](https://arxiv.org/abs/2308.07037) | 81 points | by [albertzeyer](https://news.ycombinator.com/user?id=albertzeyer) | [14 comments](https://news.ycombinator.com/item?id=37134315)

A new paper titled "Bayesian Flow Networks" introduces a new class of generative models called Bayesian Flow Networks (BFNs). BFNs modify the parameters of independent distributions using Bayesian inference based on noisy data samples. These modified parameters are then passed as input to a neural network that outputs a second, interdependent distribution. This generative procedure is similar to the reverse process of diffusion models but simpler since no forward process is required. The paper derives discrete and continuous-time loss functions for different types of data and proposes sample generation procedures. BFNs achieve competitive log-likelihoods for image modeling and outperform existing discrete diffusion models on a character-level language modeling task. The network inputs for discrete data are on the probability simplex, making it possible to use gradient-based sample guidance and few-step generation in discrete domains like language modeling. The paper provides a significant contribution to the field of machine learning and artificial intelligence.

The discussion around the submission includes a variety of topics. One user provides links to threads on Twitter and Reddit that discuss the paper's findings, with another user mentioning that Schmidhuber has mentioned the paper as well. Another user shares a visualization from the paper, specifically Figure 20. Some users discuss the idea of compressing and extracting systematic and non-systematic parameters in learning. One user emphasizes that the paper shows good results on larger benchmarks. Another user expresses surprise that the paper has been downvoted, mentioning their excitement about generative modeling work but being disappointed with results on MNIST and CIFAR-10. Another user expresses their understanding that the paper focuses on generating MNIST and CIFAR-10 data for classification. A discussion ensues about the seemingly endless papers on generating machine learning datasets, with one user mentioning that they are becoming meaningless. Another user argues that showing results on MNIST and CIFAR-10 is still valuable as a demonstration of innovation. Another user provides a historical perspective, mentioning that the field has progressed from focusing on basic tasks to more advanced ones. The discussion ends with some users flagging the submission.

### New way to read data in antiferromagnets unlocks their use as computer memory

#### [Submission URL](https://phys.org/news/2023-08-antiferromagnets-memory.html) | 38 points | by [lnyan](https://news.ycombinator.com/user?id=lnyan) | [26 comments](https://news.ycombinator.com/item?id=37130331)

Researchers from Nanyang Technological University in Singapore have made a breakthrough in the development of alternative materials for high-speed computer memory chips. They have discovered a way to read data stored in antiferromagnets, which are potentially more energy-efficient than traditional silicon-based chips. Previously, it was challenging to determine which number the antiferromagnets were coded as, but through their experiments, the researchers found that passing a current through the materials at ultra-low temperatures resulted in a unique voltage that allowed them to distinguish between the two states. This discovery paves the way for using antiferromagnets in future computer memory applications, as these chips can change data 100 times faster than traditional magnetic materials. The research was published in the journal Nature and involved collaborations with institutes in Israel, Japan, and China.

The discussion on this submission covers various topics related to the research breakthrough and its implications.

- One commenter suggests that this discovery may have potential applications in harnessing wireless energy from Wi-Fi and mobile signals to power portable electronic devices.
- Another commenter mentions that rectennas can passively harvest RFID energy from ambient surroundings and can be useful in low-power applications.
- There is a discussion about the physical properties and behavior of antiferromagnets at ultra-low temperatures, with some commenters diving into the physics and mechanics of materials at extremely cold temperatures.
- Some comments discuss the challenges of memory functioning at low temperatures, while others mention specific temperature ranges at which memory can operate.
- A discussion about quantum metrics and measurements is initiated, with commenters discussing the principles of quantum systems, measuring voltage in relation to antiferromagnetic data storage, and the use of quantum metrics to describe certain physical properties.
- One commenter expresses gratitude for the explanation of quantum metrics provided by another commenter.
- There is a debate about the accuracy of predictions and futuristic technologies, with some commenters suggesting that things mentioned today may become reality in 3-5 years, while others believe such predictions are often exaggerated.
- Some commenters bring up unrelated topics, such as flying cars and nuclear fusion power.
- The potential advantages of the research breakthrough in terms of its impact on future technologies are discussed, including the potential for faster and more efficient memory storage.
- A few comments mention the significance of 3D Xpoint technology developed by Intel and its potential application in the memory market, as well as the challenges in replacing existing technologies.
- One commenter shares a link to an xkcd comic related to the topic.

Overall, the discussion covers a broad range of topics, including the applications of the research breakthrough, the physics involved, the feasibility of future technologies, and related advancements in memory technology.

### My deep learning rig (2022)

#### [Submission URL](https://nonint.com/2022/05/30/my-deep-learning-rig/) | 156 points | by [jacquesm](https://news.ycombinator.com/user?id=jacquesm) | [76 comments](https://news.ycombinator.com/item?id=37138672)

Today, we have a special treat for all the tech enthusiasts out there! A talented developer and AI enthusiast decided to give us a glimpse into the machines that power his projects. In a recent blog post, he shared photos and specifications of his deep learning servers, which he has painstakingly built over the past few years.

The developer started this journey by acquiring six NVIDIA RTX 3090 GPUs when they were first released. From there, he gradually expanded his inventory to a total of 16 GPUs, all purchased at their original market price. Impressive, right?

To support his business, he rents out one of his servers on vast.ai, while the other is solely dedicated to his deep learning projects. Both servers are identical, except for the storage and GPU count. The rented server has seven GPUs, while his personal machine boasts eight GPUs and a massive SSD bank for dataset storage.

When it comes to building these rigs, the developer does everything himself, from assembling the components to maintenance. He aimed for maximum GPU density per server to optimize training large models without the need for costly networking hardware. The result is an impressive setup that he's proud to showcase.

In terms of specifications, his deep learning server is powered by an AMD EPYC 7502 CPU and features eight RTX 3090 GPUs. The motherboard is an Asrock ROMED8-2T, and he has a whopping 256GB of Cisco PC4-2400T DDR4 RAM. Storage-wise, he uses a combination of Samsung and ADATA NVMe SSDs, totaling over 20TB. To power this beast of a machine, he has three EVGA 1600W G+ power supplies.

Each component was chosen with careful consideration, prioritizing GPU density and affordability. For example, the AMD EPYC CPU was selected for its high number of PCIe lanes, ensuring optimal GPU performance. The developer also added custom memory heat sinks and replaced thermal pads on the GPUs to address thermal issues.

While the setup may not be flashy or boast high-price enterprise-grade hardware, it's a testament to the DIY spirit and resourcefulness of the developer. He has managed to create a powerful and efficient system for his deep learning endeavors.

If you're interested in checking out the detailed photos and component descriptions, be sure to visit his blog post (link included). It's a fascinating journey into the world of deep learning server building and a great source of inspiration for tech enthusiasts.

The discussion on this submission covers a range of topics related to deep learning servers and hardware choices:

1. Some users express interest in the specific hardware specifications and performance of the deep learning server. One commenter shares that they are renting an NVIDIA RTX 3080 machine and asks about the performance compared to the 3090s mentioned in the article.

2. The cost and return on investment of building and funding deep learning servers are discussed. One commenter shares that they are making a profit renting out their GPUs, while another mentions the potential for investment returns in the crypto market.

3. The suitability of consumer-grade electronics for high humidity environments is debated. Some users share that consumer-grade electronics are not designed for high humidity conditions, while others mention their experience using them in such environments without issues.

4. Questions arise regarding the meaning of "QS" in the context of the mentioned CPU, AMD EPYC, and speculation is made about its legality and the potential risks involved in purchasing non-production grade CPUs.

5. The limitations of network bandwidth in training large models and the impact of using NVLink for improved performance are discussed. It is mentioned that high-speed networking equipment can become a bottleneck in training large models, and one user shares their experience with NVLink improving performance in their PyTorch training with RTX 3090 GPUs.

6. The support for high-speed networking technologies, such as Thunderbolt AICs and 100GbE Mellanox connect cards, is mentioned. Some users share their experiences with these technologies and discuss their affordability and usefulness for enthusiast-level or small business-level networking needs.

7. The availability and pricing of GPUs, as well as the current trend of GPU shortages, are brought up. A user asks about the availability of GPUs and the long-term shift in demand from cryptocurrencies to AI, and others share their insights on the temporary nature of the shortage and the role of manufacturers in maintaining market competitiveness.

8. The discussion also touches on the absence of AMD ML Edition GPUs with larger memory capacities and their pricing compared to NVIDIA GPUs. Users express frustration at the limitations of available options and the perception of higher prices for professional-grade ML GPUs.

9. The potential benefits of using multiple GPUs and the limitations of memory and ALU in machine learning tasks are mentioned. Users discuss the benefits of connecting GPUs through NVLink and the potential for improvements in memory support and floating-point performance in future AMD GPUs.

10. Lastly, the potential for using a network of NVLink-connected GPUs in training models is briefly mentioned, with users speculating about the possibility of AMD supporting a similar network with multiple MI60 GPUs linked by Infinity Fabric. The limitations of PCIe bandwidth in this scenario are also mentioned.

### Carl Linnaeus Set Out to Label All of Life

#### [Submission URL](https://www.newyorker.com/magazine/2023/08/21/the-man-who-organized-nature-the-life-of-linnaeus-gunnar-broberg-book-review) | 45 points | by [Petiver](https://news.ycombinator.com/user?id=Petiver) | [15 comments](https://news.ycombinator.com/item?id=37129417)

The Tyrannosaurus rex, despite being extinct for millions of years, continues to captivate people's imaginations. Thanks to the likes of Michael Crichton and Steven Spielberg, as well as the fascination of elementary-school children, the T. rex remains a widely recognized dinosaur. In scientific circles, the T. rex is known by its proper scientific name, Tyrannosaurus rex, or T. rex for short. This name follows the binomial nomenclature system, which assigns a two-part name (genus and species) to every species on Earth. While binomial names are important to scientists, they are rarely used in everyday conversation. However, they still play a vital role in fields like molecular biology and evolutionary ecology. The system of binomial nomenclature was developed by Carl Linnaeus in the 18th century, and though widely known, his life and scientific contributions remain controversial. A new biography seeks to provide a comprehensive account of Linnaeus's life but grapples with the question of how he should be classified. Linnaeus, often considered the father of modern taxonomy, was born into a family of botanists and showed a keen interest in plants from a young age. Despite facing challenges in his education, Linnaeus went on to study medicine and became a pioneer in the field of botany.

The discussion surrounding this submission on Hacker News covers various topics related to taxonomy and the life of Carl Linnaeus, the father of modern taxonomy. Some users appreciate the scientific contributions of Linnaeus and discuss the importance of binomial nomenclature in fields like molecular biology and evolutionary ecology. Others share their personal experiences and perspectives on Linnaeus's work, including the influence of Michael Crichton and Steven Spielberg's portrayal of dinosaurs, the relevance of Linnaeus's system in classifying species today, and the controversy surrounding his life and categorization. One user mentions a biography about Linnaeus that attempts to provide a comprehensive account of his life but has issues in capturing the full essence of his work. Links to related resources and discussions are also shared, including a primary source article discussing different kinds of natural classification and a small book about Linnaeus.

### Bots can complete CAPTCHAs quicker than humans

#### [Submission URL](https://www.theregister.com/2023/08/15/so_much_for_captcha_then/) | 62 points | by [magoghm](https://news.ycombinator.com/user?id=magoghm) | [91 comments](https://news.ycombinator.com/item?id=37133485)

According to researchers from the University of California, Irvine, computers are now better at completing CAPTCHA tests than humans. CAPTCHA, which stands for Completely Automated Public Turing test to tell Computers and Humans Apart, is a common bot defense measure used by websites to identify low-risk human users. However, the study found that bots were able to complete the tests in less than a second with 99.8% accuracy, while humans took 9-15 seconds with an accuracy of just 50-84%. The researchers suggest that organizations should use "intelligent algorithms" to distinguish between bot and human interactions instead of relying solely on CAPTCHA.

The discussion surrounding the submission revolves around various aspects of CAPTCHA, spam, and bot behavior. 

One user suggests that relying solely on CAPTCHA is not sufficient because bots can easily mimic human behavior. They propose using behavioral analysis and intelligent algorithms to distinguish between bots and humans. Another user adds that intelligent bots can generate convincing reviews and engage in misleading behavior, which can pose a challenge for platforms that rely on user-generated content.

There is a debate about the effectiveness of microtransactions as a solution. Some argue that if people have to pay small amounts for access to services, it can help manage spam. However, others point out that people don't want to pay for such services, and implementing microtransactions may not be practical.

The discussion also touches upon the idea of using phone numbers for verification. Some users express concerns about privacy and the potential misuse of personal information. Others mention that relying on phone numbers may not be effective as they can be easily obtained and used for spamming.

There is also discussion about the limitations of CAPTCHAs and the need for better solutions. Some users suggest that trusting behavior-driven AI and using web integrity APIs can help tackle the challenges posed by bots.

The conversation extends to topics like online privacy, trust, and the impact of AI on the internet. There are varying opinions on the importance of privacy and the implications of AI and behavioral analysis. One user mentions the importance of trust and consent in internet interactions.

Overall, the discussion highlights the complex nature of combating spam and determining bot behavior, and it explores different approaches and their implications.

### What coal and Jevons’ paradox tell us about AI and data

#### [Submission URL](https://hex.tech/blog/jevons-paradox-demand-for-insight/) | 70 points | by [erehweb](https://news.ycombinator.com/user?id=erehweb) | [67 comments](https://news.ycombinator.com/item?id=37129853)

The rise of artificial intelligence (AI) and machine learning models (LLMs) has raised concerns about the future of data jobs. Will computers replace human data practitioners? According to a blog post by Barry McCardel, the job of a data practitioner is more than just writing code or making charts. It involves formulating the right questions, anticipating the needs of stakeholders, and providing valuable insights. While AI can automate certain rote tasks, it is unlikely to replace the human element of data work.

McCardel draws a parallel to Jevons' Paradox, which observed that as coal-powered engines became more efficient, overall coal consumption increased. The same rebound effect could apply to AI and data. As the cost of generating insights decreases, the demand for data work and the number of questions that can be answered with data will likely increase. Organizations are supply-constrained when it comes to utilizing data, and AI can help unlock the untapped potential of data teams.

While AI will undoubtedly change how data practitioners work, McCardel argues that it will likely lead to an increased need for human hours rather than a decrease. The impact of data on organizations is far from reaching its theoretical limit, and AI can help data teams be more impactful. McCardel concludes by discussing Hex, a platform that enables the creation and sharing of interactive data products, and invites readers to explore opportunities with the company.

Overall, the blog post highlights the potential of AI to augment rather than replace human data practitioners, and the exciting possibilities that lie ahead in the field of data analysis.

The discussion on Hacker News revolves around the blog post's main points about AI and the future of data jobs. One commenter agrees with the post, saying that AI may take over low-value tasks but will not replace the higher-level strategic work that humans can do. They argue that as technology progresses, there is a shift in the types of jobs available. Another commenter brings up the concern that AI may replace non-essential service vendors and result in organizational changes. 

There is also a discussion about the impact of automation on different types of jobs. Some argue that AI will lead to an increase in the need for human hours rather than a decrease. Others point out that certain jobs, like manual labor, may be more easily replaced by automation, while others believe that higher-skilled jobs will still be in demand. The potential impact on the middle class is also mentioned.

Another comment highlights the importance of natural language communication, social and emotional intelligence, and decision-making in certain professions, suggesting that AI may not fully replace these roles. However, another commenter challenges this notion, stating that AI has the potential to approximate decision-makers and replace jobs traditionally done by lower-skilled workers. They argue that humans are not horses and will adapt to new roles.

There is also a discussion about the current and future job market and the creation of new roles. Some argue that the current job market is not representative of the future, and there is uncertainty about the impact of AI on employment. Others discuss the changing dynamics in households and the increase in multiple jobs held by individuals.

Overall, the comments touch on various aspects of the impact of AI on jobs, the potential changes in the job market, and the role of humans in the age of automation.

### Google Chrome will summarize entire articles for you with built-in generative AI

#### [Submission URL](https://www.theverge.com/2023/8/15/23833045/google-artificial-intelligence-summary-chrome-sge) | 17 points | by [exz](https://news.ycombinator.com/user?id=exz) | [3 comments](https://news.ycombinator.com/item?id=37138586)

Google Chrome is introducing a new feature that will allow users to summarize entire articles using built-in generative AI. The AI-powered Search Generative Experience (SGE) can already provide summaries of search results, and now it will also offer article summaries once users click on a link. The feature, known as "SGE while browsing," is being rolled out as an early experiment in Google's opt-in Search Labs program. Initially, it will be available on the Google app for Android and iOS, with plans to bring it to the Chrome browser on desktop soon after. The feature will only work on freely available articles and won't support paywalled content. Google is also making other enhancements to SGE, such as providing definitions and diagrams for certain words and improving summaries of coding information. The company has received positive user feedback on SGE so far and believes it will become a standard function of Search over time.

The discussion primarily revolves around a comparison between the new Chrome search feature and an existing tool called Kagi. One user points out that Kagi works with most browsers by using JavaScript, while Chrome's search feature seems to have limitations. Another user provides a bookmarklet code that allows users to use Kagi on Chrome by redirecting the page to the Kagi website.

### Elon Musk’s X is throttling traffic to news and websites he dislikes

#### [Submission URL](https://www.washingtonpost.com/technology/2023/08/15/twitter-x-links-delayed/) | 190 points | by [c5karl](https://news.ycombinator.com/user?id=c5karl) | [79 comments](https://news.ycombinator.com/item?id=37136858)

The company formerly known as Twitter, now called X, has been slowing down the speed at which users can access links to news organizations and online competitors like the New York Times and Facebook. This move appears to be targeted at companies that have drawn the ire of owner Elon Musk. Users who clicked a link on Musk's website were made to wait about five seconds before seeing the page. However, X began reversing the throttling on some sites hours after the story was first published. The delay affected the t.co domain, a link-shortening service that X uses to process every link posted to the website. Traffic is routed through the domain, allowing X to track and potentially throttle activity to targeted websites, potentially affecting traffic and ad revenue. Some of the targeted businesses have expressed concerns about the delays and the potential for targeted pressure on news organizations. Online companies invest heavily to ensure their websites open quickly, as even tiny delays can lead to users abandoning the site.

The discussion on Hacker News revolves around the topic of the company formerly known as Twitter, now called X, slowing down the speed at which users can access links to news organizations and online competitors, particularly those that have drawn the ire of owner Elon Musk. Some users discuss how the throttling of traffic to specific websites was observed and comment on the technical aspects of how this could be implemented. There are also debates about the ethics of such actions and whether X should be allowed to engage in practices that potentially stifle competition. Some users argue that as a private company, X has the right to regulate its platform as it sees fit, while others express concerns about the implications for free speech and fair competition. Additionally, there are discussions about Elon Musk's motivations and behavior, as well as comparisons to other platforms like Facebook and Twitter in terms of content moderation and censorship.

