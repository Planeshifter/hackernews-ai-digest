## AI Submissions for Tue Apr 29 2025 {{ 'date': '2025-04-29T17:16:44.788Z' }}

### Chain of Recursive Thoughts: Make AI think harder by making it argue with itself

#### [Submission URL](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) | 514 points | by [miles](https://news.ycombinator.com/user?id=miles) | [225 comments](https://news.ycombinator.com/item?id=43835445)

In today's Hacker News roundup, we delve into an intriguing project called "Chain of Recursive Thoughts" (CoRT), where an innovative approach has been applied to enhance AI decision-making. Created by the user PhialsBasement, this open-source venture explores the potential of making AI models ‘argue with themselves’ to improve their problem-solving skills. The methodology harnesses the power of self-evaluation and recursive thinking, pushing AI to generate multiple alternatives, rigorously assess them, and select the most optimal response.

The project has shown particularly impressive results when paired with the smaller-sized Mistral 3.1 24B model, dramatically boosting its performance, especially in programming tasks. Key to this success is the "AI battle royale" approach, where various potential solutions are pitted against each other, with only the top choice surviving to become the final answer. 

For those keen on experimenting, PhialsBasement provides clear instructions on setting up and running the code via a Web UI, though it's still in early development. Users interested in enhancing this innovative setup are encouraged to contribute, with the project licensed under MIT, giving plenty of freedom for creative adaptations and improvements.

This project underscores the power of iterative refinement and dynamic thinking in AI, making it a fascinating area for developers and AI enthusiasts eager to push the boundaries of machine intelligence.

**Summary of Discussion:**  
The Hacker News discussion around the "Chain of Recursive Thoughts" (CoRT) project explores both enthusiasm and critical considerations for recursive AI verification methods. Key points include:

1. **Verification Challenges & Solutions**:  
   - While CoRT’s "AI battle royale" approach (generating multiple solutions and filtering via verifiers) shows promise, users note **task-dependent efficacy**. For example, mathematical proofs are easier to verify programmatically, but LLMs like GPT-4 often produce flawed reasoning that requires external checkers.  
   - In software engineering, LLM-generated code may include vulnerabilities, but verification tools (compilers, linters, test suites) can improve reliability. Automatic test reruns help but **require well-defined cases** to avoid false confidence.  
   - Some argue verification is harder than generation, though projects like CoRT demonstrate significant accuracy gains when combining LLMs with external validators.

2. **Practical Implementation**:  
   - Users share experiences with **temperature settings** affecting output quality, with lower temperatures yielding more focused—though less creative—results.  
   - Ideas like **Monte Carlo Tree Search** (MCTS) for LLMs are suggested as complementary methods to refine reasoning, albeit with higher computational costs.  
   - Iterative self-critique workflows (e.g., AI generating a report, critiquing it, then revising) are praised for improving results, though some call it "clunky."

3. **Human vs. AI Judgment**:  
   - Debate arises over **replacing human evaluation**. While tools like LLM-as-judge frameworks (LangChain, LlamaIndex) aid scalability, they’re seen as supplementary rather than substitutes for human oversight.  
   - Concerns about **sycophancy** (LLMs echoing user biases) highlight the need for diverse, context-aware verification steps.

4. **Anecdotes & Alternatives**:  
   - Users mention tools like Gemini’s large context window for maintaining project-specific knowledge and Sillytavern’s group-chat approach for multi-agent debates.  
   - Training data overlap and entropy reduction techniques (e.g., k-fold cross-validation) are noted as inspirations for improving model robustness.  

**Conclusion**:  
The community views CoRT’s recursive verification as a promising step toward enhanced AI reasoning but emphasizes the need for hybrid approaches (human + automated checks), task-specific adaptations, and cost-effective scalability. Practical experimentation, iterative workflows, and leveraging external validators are highlighted as effective strategies.

### An illustrated guide to automatic sparse differentiation

#### [Submission URL](https://iclr-blogposts.github.io/2025/blog/sparse-autodiff/) | 121 points | by [mariuz](https://news.ycombinator.com/user?id=mariuz) | [20 comments](https://news.ycombinator.com/item?id=43828423)

In the bustling world of machine learning, we're all familiar with automatic differentiation, a method that swiftly calculates gradients essential for model optimization. But dive deeper, and you'll discover the lesser-known sibling: automatic sparse differentiation (ASD). This specialized process capitalizes on the sparseness of Hessians and Jacobians—those large, unwieldy matrices where most elements are zero—common in scientific and engineering applications. By focusing only on the non-zero elements, ASD can dramatically speed up computations and cut down on memory usage.

Our illustrated guide starts with the basics: understanding traditional automatic differentiation (AD) and its role in computing Jacobians using both forward and reverse modes. From there, we explore the heart of ASD, which hinges on two core techniques: detecting sparsity patterns and employing matrix coloring. These strategies enable the efficient calculation of sparse Jacobians, and subsequently, sparse Hessians.

For those entrenched in machine learning, the benefits are clear. While first-order optimization via gradients is standard, utilizing sparse structures can significantly enhance the performance of second-order methods, which deal with these large matrices. However, ASD remains underutilized, partly because its theoretical foundations were developed outside the mainstream machine learning discourse. This post aims to bridge that gap, showcasing how ASD can revolutionize computational efficiency in real-world applications.

Through a practical demonstration within the post, readers can see firsthand how ASD shines when handling high-dimensional data, providing benchmarks and scenarios where it surpasses traditional methods. By demystifying ASD’s approach to leveraging sparsity, this guide opens the door to faster, more memory-conscious machine learning optimizations, paving the way for broader adoption in cutting-edge applications.

The Hacker News discussion on the blog post about **automatic sparse differentiation (ASD)** highlights technical insights, resource sharing, and debates on its mathematical foundations. Here's a concise summary:

### Key Discussion Points:
1. **Technical Insights**:
   - ASD’s efficiency in handling sparse Jacobians/Hessians was praised, with users noting its underuse in machine learning despite benefits for second-order optimization.
   - Methods like **sparsity pattern detection** and **matrix coloring** were discussed as critical for optimizing computations.

2. **References & Tools**:
   - Users cited foundational papers (e.g., Schmidhuber’s 1999 NIPS work) and textbooks (Trefethen’s *Numerical Linear Algebra*, Strang’s *Linear Algebra*).
   - Julia libraries like [`SpAutoDiff.jl`](https://github.com/rdyro/SpAutoDiff.jl) and tools like **Enzyme** were shared as practical implementations.
   - A prior [benchmark blog post](https://clr-blogposts.github.io/2024/blog/bench-hvp) inspired the submission, focusing on Hessian-vector products.

3. **Mathematical Debates**:
   - Participants debated whether ASD’s foundations lie in **calculus/numerics** or **computer science**, with some emphasizing its roots in traditional AD and FORTRAN-era optimizations.
   - Questions arose about prerequisites for understanding ASD, with recommendations for calculus, linear algebra, and graph theory basics.

4. **Educational Resources**:
   - Users highlighted the need for accessible explanations, linking to arXiv preprints and suggesting simplified programming projects to grasp concepts like matrix coloring.

5. **Miscellaneous**:
   - The blog’s clean design (based on MIT’s **Al-Folio** theme) and use of Markdown/LaTeX were briefly noted.
   - Some users humorously admitted struggling to grasp the dense material, reflecting the technical complexity of the topic.

### Community Sentiment:
- Enthusiastic engagement with ASD’s potential, though some found the concepts challenging without foundational math knowledge.
- Appreciation for practical code examples and efforts to bridge theory with real-world ML applications.

### Duolingo will replace contract workers with AI

#### [Submission URL](https://www.theverge.com/news/657594/duolingo-ai-first-replace-contract-workers) | 153 points | by [donohoe](https://news.ycombinator.com/user?id=donohoe) | [106 comments](https://news.ycombinator.com/item?id=43827978)

In a bold move towards embracing the future, Duolingo is set to transform into an "AI-first" company, as announced by cofounder and CEO Luis von Ahn. Revealed in an all-hands email shared on LinkedIn, this strategic pivot means AI will progressively take over tasks currently handled by contractors, allowing employees to focus on more creative and critical challenges. Drawing from Duolingo’s successful bet on mobile-first innovation in the past, von Ahn believes this shift to AI will enable the language-learning platform to rapidly scale its content and enhance features, outpacing traditional methods.

Von Ahn clarified that this isn't about substituting their human-like mascot, Duo, with artificial intelligence, but rather removing repetitive bottlenecks to empower the existing workforce with more meaningful work. The initiative includes integrating AI in hiring processes and performance assessments, and justifying new hires only if automation isn't feasible. This change mirrors a similar directive recently highlighted by Shopify's CEO, who urged teams to leverage AI solutions before requesting additional resources.

Despite the shift, Duolingo remains committed to its employees, promising more support in AI training and tools, aiming to turn the upcoming transitions into a positive progression towards achieving its educational mission. With this leap, Duolingo is poised to redefine content creation and feature development, anchoring itself as a leader in integrating AI into its foundational operations.

The Hacker News discussion on Duolingo's AI-first pivot reveals a mix of skepticism, critique of its educational model, and broader concerns about AI's role in the workplace. Key points include:

1. **Skepticism Toward Corporate Motivations**:  
   Users question whether Duolingo’s shift is driven by genuine innovation or cost-cutting, with parallels drawn to Shopify’s recent AI-driven layoffs. Some argue the move mirrors typical corporate trends where "AI-first" rhetoric masks efforts to reduce labor costs, prioritizing shareholder returns over employee welfare. Others worry AI-driven productivity gains might inflate expectations without fair compensation for workers.

2. **Criticism of Duolingo’s Educational Value**:  
   Many criticize Duolingo’s gamified approach as ineffective for serious language learning, calling it a "lazy game" that prioritizes engagement over foundational skills (e.g., grammar, verb conjugation). Comparisons to tools like Anki, HelloChinese, or LingoDeer highlight frustration with Duolingo’s superficial content and rigid learning paths. Some users canceled subscriptions, arguing the platform feels more like a monetized game than a robust educational tool.

3. **AI’s Impact on Developers and Jobs**:  
   Developers express concern that AI-generated code could devalue their roles, likening the trend to past hype cycles (e.g., crypto). Critics warn that companies might use AI to justify layoffs or suppress wages, especially if automation handles tasks traditionally done by contractors. Others caution against overestimating AI’s current capabilities, noting that non-developers pushing AI tools often lack technical understanding.

4. **Defense of AI in Learning Tools**:  
   A minority defend AI’s potential, citing platforms like Anki for spaced repetition and vocabulary retention. However, even proponents acknowledge Duolingo’s limitations, arguing its AI integration needs to enhance, not replace, structured learning methods.

5. **Broader Distrust of Corporate AI**:  
   Users highlight a pattern of companies using AI buzzwords to mask profit-driven decisions, often at the expense of user experience and product quality. Privacy concerns and fears of "AI-generated mediocrity" emerge, with skepticism about whether automation will improve content or merely streamline costs.

**In Summary**: The discussion reflects apprehension about Duolingo’s AI pivot, blending doubts about its educational efficacy, ethical implications for workers, and broader cynicism toward corporate AI narratives. While some see potential in AI-augmented tools, many fear the changes prioritize business metrics over meaningful learning outcomes and fair labor practices.

### Generative AI is not replacing jobs or hurting wages at all, say economists

#### [Submission URL](https://www.theregister.com/2025/04/29/generative_ai_no_effect_jobs_wages/) | 331 points | by [pseudolus](https://news.ycombinator.com/user?id=pseudolus) | [478 comments](https://news.ycombinator.com/item?id=43830613)

In a fascinating twist on the tech narrative, a recent paper by economists Anders Humlum and Emilie Vestergaard suggests that generative AI, despite being the tech industry's darling with billions in investment, hasn't quite delivered the economic revolution some predicted. Their study examined the impact of AI chatbots, like ChatGPT, across 11 job categories in Denmark, from educators to software developers, and found no significant wage or labor effects. 

This revelation complicates the tech industry's hype about AI's economic potential and raises questions about the massive capital poured into AI infrastructure. The economists' research indicated that while chatbot adoption is high, the economic benefits are minimal, with time savings clocking in at a mere 2.8% of work hours, tantamount to just over an hour per typical workweek. 

Interestingly, the speedy adoption of AI chatbots has not translated into drastic changes or benefits. Instead, it's reshaping jobs by creating new tasks, including those monitoring whether AI tools, like ChatGPT, are used for cheating—tasks that ironically eat into potential time savings. Humlum points out that while these new activities could, in a best-case scenario, lead to higher-value tasks and possibly wages, the overall productivity gains remain limited. 

Moreover, only a sliver of any productivity boost reaches workers' pockets, with just 3-7% seen in higher earnings. While AI might save time on activities like emailing, it doesn't necessarily mean employees can take on more work to increase earnings. This insight frames a backdrop where firms might reap more benefits than workers, casting a nuanced light on the AI advancement narrative and hinting at a future where the real economic game-changer status of AI is still on the horizon.

The discussion surrounding the study on generative AI's economic impact reflects widespread skepticism and nuanced debates. Key points include:

1. **Minimal Measurable Impact**: Users highlight the study’s finding of only **2.8% time savings** (≈1 hour/week) from AI tools, questioning whether such marginal gains justify the hype or investment. Critics argue these savings often fail to translate into wage increases, as companies absorb efficiency gains without redistributing benefits to workers.  

2. **Productivity vs. Wages**: A recurring theme is the disconnect between AI-driven productivity and wage growth. While AI might streamline tasks (e.g., drafting emails), participants note that saved time often leads to **new administrative burdens** (e.g., monitoring AI use) or increased workload demands rather than higher pay. Some argue companies prioritize revenue growth over employee compensation.

3. **Historical Analogues**: Commenters draw parallels to past technological shifts, like textile automation, which reshaped jobs without reducing employment long-term. Others cite **Jevons Paradox**—efficiency gains (e.g., cheaper software) may spur demand for new services, creating unforeseen roles while rendering others obsolete.

4. **Technical Realities**: Developers debate AI’s practical utility in technical fields (e.g., coding, UI design). While some praise tools like ChatGPT for accelerating tasks (e.g., generating code drafts), others note limitations, emphasizing that **baseline expertise** remains critical. Efficiency gains here are often incremental (e.g., saving 5% of time) rather than transformative.

5. **Economic Structures**: Discussions critique systemic factors, such as corporate greed, regulatory capture in education, and rising student debt, which may distort AI’s potential benefits. Critics argue markets increasingly favor price-fixing over competition, dampening consumer gains from AI-driven cost reductions.

6. **Skepticism of Hype**: Many dismiss the AI “revolution” narrative as market-driven speculation, stressing that real-world adoption often falls short of transformative claims. The study’s focus on Denmark is seen as a caution against overgeneralizing AI’s global impact.

In essence, the consensus leans toward **cautious doubt**: while AI introduces incremental efficiencies, structural economic forces and historical precedents suggest its revolutionary potential remains unrealized, with benefits disproportionately favoring firms over workers.

### Waymo and Toyota outline partnership to advance autonomous driving deployment

#### [Submission URL](https://waymo.com/blog/2025/04/waymo-and-toyota-outline-strategic-partnership) | 378 points | by [ra7](https://news.ycombinator.com/user?id=ra7) | [351 comments](https://news.ycombinator.com/item?id=43839123)

Toyota and Waymo are teaming up in an exciting new venture to boost the development of autonomous driving technologies. This dynamic duo, along with Woven by Toyota, aims to blend their strengths to build a cutting-edge autonomous vehicle platform. The partnership is rooted in a shared vision for improving road safety and expanding mobility options for everyone.

Toyota, known for its commitment to reducing traffic accidents, brings its expertise in vehicle development and advanced safety technologies to the table. The partnership will explore integrating Waymo's top-notch autonomous technology with Toyota's next-generation personally owned vehicles (POVs). Waymo, a frontrunner in autonomous driving, already logs numerous safe trips weekly in cities like San Francisco and Phoenix, boasting impressive safety records.

Hiroki Nakajima from Toyota underscores the goal of achieving zero traffic accidents and emphasizes the collaboration's potential to elevate safety solutions worldwide. Meanwhile, Tekedra Mawakana of Waymo highlights the partnership's role in expanding accessible transportation and integrating their tech into Toyota's lineup.

This promising collaboration not only envisions a safer driving future but also aspires to make autonomous technologies widespread, offering peace of mind to drivers globally. Keep an eye on this space as the partnership unfolds!

The Hacker News discussion on Toyota and Waymo’s autonomous driving partnership quickly pivoted to debates about Tesla’s **Full Self-Driving (FSD)** system and broader industry challenges:  

1. **FSD Criticism vs. Progress**:  
   - Users criticized Tesla’s FSD for overpromising, with some likening it to a “Kickstarter project” still unrealized after 12 years. Skeptics argued Tesla’s marketing (e.g., “Full Self-Driving” branding) implies autonomy beyond its **Level 2** capabilities (driver-assist requiring constant supervision), fueling perceptions of misleading claims.  
   - Others acknowledged incremental FSD improvements but highlighted regressions and edge-case failures.  

2. **Competitor Comparisons**:  
   - **Waymo** (L4, fully driverless in geofenced areas) was contrasted with Tesla’s approach. Users noted Waymo’s liability for accidents, while Tesla shifts responsibility to drivers.  
   - **Mercedes’ Drive Pilot** (L3, limited autonomy with manufacturer liability) sparked debate about its practicality versus Tesla’s scalability. Critics dismissed it as a “gimmick” due to strict operational constraints (e.g., 40 mph max speed, mapped highways).  

3. **Legal and Safety Concerns**:  
   - Discussions emphasized how branding impacts liability. Tesla’s “FSD” label was seen as risky, contrasting with Mercedes’ cautious L3 marketing and legal acceptance of responsibility. References to Ford’s Pinto lawsuit highlighted potential reputational and financial risks if autonomy claims prove deceptive.  
   - Users questioned whether Tesla’s strategy prioritizes scalability over safety, noting Waymo’s slower, safer geofenced deployments.  

4. **User Experiences**:  
   - Some Tesla drivers praised FSD for highway assist but stressed it’s far from “full” autonomy. Others mocked the requirement to “pay 100% attention” to a system marketed as self-driving.  

**Takeaway**: The conversation reflects skepticism toward Tesla’s FSD timeline and marketing, admiration for Waymo’s cautious but functional autonomy, and broader concerns about ethical branding and legal accountability in the AV industry.

### Meta AI App built with Llama 4

#### [Submission URL](https://about.fb.com/news/2025/04/introducing-meta-ai-app-new-way-access-ai-assistant/) | 96 points | by [friggeri](https://news.ycombinator.com/user?id=friggeri) | [106 comments](https://news.ycombinator.com/item?id=43833783)

Meta has unveiled the first version of its highly anticipated Meta AI app, your new digital sidekick, designed to learn about your preferences and provide personalized assistance. Built on the Llama 4 model, this app aims to revolutionize the way you interact with technology by ensuring that your AI experience is personal, social, and seamless. Whether you're chatting on WhatsApp, Instagram, Facebook, or Messenger, Meta AI is primed to respond in a conversational tone, making interactions feel natural and intuitive.

Meta AI doesn't just chat — it listens, remembers, and evolves. With voice conversation capabilities now enhanced, you can multitask efficiently, using voice commands to manage your queries and daily tasks. While it doesn’t access the web in real time yet, Meta AI can still help navigate questions, offer recommendations, and enhance day-to-day interactions based on the information you’ve shared across Meta platforms. For those wanting to see the bigger AI picture, the app comes with a Discover feed to glimpse and share how people are creatively engaging with AI.

The introduction of voice features with full-duplex speech technology in select regions, including the U.S. and Canada, means users can now test a more conversational interface, where Meta AI generates speech directly, aiming to make it sound as though you're chatting with a friend rather than programming a bot. Want an even tighter integration? Connect your Facebook and Instagram for an enriched experience that’s as personalized as it gets.

Meta AI is the companion app for the AI-enhanced Ray-Ban glasses, intertwining advanced AI-powered interactions with cutting-edge hardware, underscoring Meta’s vision of the future of personalized tech. This innovation seamlessly allows you to shift from a conversation on the glasses to the app, ensuring continuity and a rich user experience. 

In essence, Meta is redefining AI's role in your life, making it more than just a tool but a personal assistant that knows you like a friend. As this first iteration rolls out and feedback is gathered, expect Meta AI to become an indispensable part of your digital routine.

The Hacker News discussion about Meta's new AI app highlights several key themes:

### **Privacy Concerns**
- Users warn about the app's broad permissions on iOS, including access to browsing history, purchase history, phone numbers, physical addresses, location, photos, and videos. Skepticism persists around Meta’s data-handling track record, with references to Facebook’s past privacy issues. Even without real-time web access, fears remain that data from Meta’s other platforms (WhatsApp, Instagram) could be exploited.

### **Technical Debates on iOS WebViews**
- Discussions delve into how Meta’s app might use WebViews (in-app browsers) instead of Safari, potentially bypassing Safari’s privacy features like content blockers. Some argue Apple’s WebView system is a privacy weak spot, while others note limitations in user control over third-party link handling. AdGuard’s effectiveness in blocking WebView tracking is questioned.

### **Rebranding and Integration Strategy**
- The app’s rebranding from "Meta View" (linked to Ray-Ban glasses) is seen as a move to boost App Store visibility and credibility. Critics call it "spammy," comparing it to past Meta products that failed to innovate. Integration with WhatsApp, Instagram, and Messenger is viewed as an attempt to lock users into Meta’s ecosystem, though some see potential in leveraging Meta’s vast user base for mainstream adoption.

### **Skepticism vs. Potential Adoption**
- Tech-savvy users dismiss the app as unoriginal, citing overlap with existing AI tools like ChatGPT. However, others argue non-technical users may embrace it due to seamless integration with familiar Meta platforms. Meta’s ability to leverage personalized data for AI customization is noted, but concerns about monopolistic control over hardware (Ray-Ban glasses) and AI models (LLaMA 4) arise.

### **User Experience Critiques**
- Voice features and glasses integration are praised as innovative, but the use of WebViews over native browser tabs is criticized for clunky UX. Some users question if Meta AI’s conversational tone and "friend-like" interactions will resonate long-term or feel intrusive.

### **Open-Source and Power Dynamics**
- LLaMA 4’s open-source aspects are debated, with concerns about Meta’s influence over AI development and potential misuse. The tension between corporate control and community-driven AI models is highlighted.

In summary, the discussion reflects a mix of skepticism about Meta’s privacy practices and strategic rebranding, technical debates over iOS security, and cautious acknowledgment of the app’s potential to reach mainstream audiences through Meta’s ecosystem.

