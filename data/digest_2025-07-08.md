## AI Submissions for Tue Jul 08 2025 {{ 'date': '2025-07-08T17:14:18.977Z' }}

### Smollm3: Smol, multilingual, long-context reasoner LLM

#### [Submission URL](https://huggingface.co/blog/smollm3) | 350 points | by [kashifr](https://news.ycombinator.com/user?id=kashifr) | [70 comments](https://news.ycombinator.com/item?id=44501413)

Exciting news from the world of language models! Meet SmolLM3, a cutting-edge multilingual, small-scale language model with big ambitions. Developed collaboratively by a team of experts, SmolLM3 is designed with efficiency and long-context reasoning in mind, aiming to outperform its peers like Llama-3.2-3B and Qwen2.5-3B, while being a worthy competitor to the larger 4B models such as Qwen3 & Gemma3.

Boasting a 3 billion parameter design, SmolLM3 is built to support six major languages, including English, French, and Spanish, making it an attractive option for global applications. Capable of handling long contexts up to 128,000 tokens, SmolLM3 promises breakthrough performance with its novel attention mechanisms like Grouped Query Attention (GQA) and the innovative NoPE hybrid attention strategy.

The creators are not just sharing a final product; they're offering an open-source blueprint of how they constructed this marvel from the ground up. This transparency allows enthusiasts and developers to understand the intricacies behind achieving such performance at a smaller scale. The model is trained on a whopping 11 trillion tokens with a three-stage approach focusing on datasets from diverse domains such as web, math, and code.

SmolLM3 uses advanced techniques like intra-document masking and improved stability strategies akin to its predecessor, SmolLM2, while introducing tweaks for superior stability and performance during training. The model's robustness was ensured through numerous validations using massive computing power—an awe-inspiring setup involving 384 H100 GPUs over 24 days.

For those curious about the finer points of SmolLM3, the project offers a goldmine of engineering insights and methodologies, making it a remarkable reference for anyone looking to elevate their understanding or build upon this foundation. Whether you're interested in language models' architecture or aiming to push the boundaries of machine learning capabilities, SmolLM3 paints an inspiring picture of what skilled and thoughtful engineering can achieve in the AI landscape.

**Hacker News Discussion Summary: SmolLM3 Release**

**Cost & Training Resources:**  
The discussion highlights the significant computational cost of training SmolLM3, initially cited as using 384 H100 GPUs over 24 days. Users debated the exact cost, with estimates ranging from $28k to over $500k, depending on GPU rental pricing (e.g., $2–$3/hour on cloud platforms like Runpod). Corrections clarified the math, emphasizing the high barrier to entry for reproducing such training without corporate-scale resources.

**Open-Source Debate:**  
Participants questioned whether SmolLM3 is "truly open-source," comparing it to models like OLMo, which provide full training code, datasets, and weights. Some users expressed skepticism, noting that many "open" models omit critical details like training data or infrastructure. The SmolLM3 team clarified they are releasing a full engineering blueprint, including architecture and dataset mixes, to aid reproducibility.

**Technical Challenges & Local Deployment:**  
Users shared mixed success running SmolLM3 on local hardware (e.g., Macs). Issues with inference engines like `llama.cpp` and Ollama were noted, though workarounds using MLX-LM or Transformers libraries were suggested. Quantization (e.g., 4-bit GGUF) was discussed to reduce VRAM usage, with some achieving 128k-token contexts on 24GB GPUs like the RTX 4090. The Mac community faced hurdles but found partial success with PyTorch and Metal GPU acceleration.

**Use Cases & Small Model Potential:**  
The conversation pivoted to practical applications for 3B-scale models, such as edge devices (Jetson, mobile) and RAG systems. Participants debated whether small models can compete with larger ones in reasoning tasks, emphasizing domain-specific fine-tuning and hybrid approaches (e.g., combining vector search and keyword retrieval). Some shared success stories with Mistral 7B for specialized tasks, while others stressed the need for rigorous benchmarking.

**Community Reception:**  
The release of SmolLM3’s detailed methodology was praised as a valuable resource for engineers and researchers. However, skepticism lingered about its benchmark claims and真正的 "state-of-the-art" status, with calls for independent validation. Developers expressed enthusiasm for testing the model, particularly its multilingual and long-context capabilities, despite deployment challenges.

**Key Takeaways:**  
- SmolLM3’s engineering transparency is a standout feature, though its open-source credentials face scrutiny.  
- Costs and infrastructure requirements limit reproducibility for individuals.  
- Local deployment remains tricky but feasible with community-driven tools.  
- Small models like SmolLM3 show promise for niche applications but require careful optimization and benchmarking.

### The Tradeoffs of SSMs and Transformers

#### [Submission URL](https://goombalab.github.io/blog/2025/tradeoffs/) | 64 points | by [jxmorris12](https://news.ycombinator.com/user?id=jxmorris12) | [8 comments](https://news.ycombinator.com/item?id=44503056)

In the world of machine learning, a fascinating discussion is taking place between enthusiasts and experts alike about State Space Models (SSMs) and Transformers. A blog post has been adapted from a popular talk, aimed at making this complex subject accessible to everyone, from casual readers to dedicated researchers. The crux of the conversation lies in understanding how SSMs are evolving as a strong contender in sequence modeling, traditionally dominated by Transformers, particularly in language processing.

State Space Models have come a long way, derived from a lineage of work that culminated in the development of models like Mamba. At their core, SSMs can be conceptualized as modern successors to recurrent neural networks (RNNs), with distinct advantages that help them rival the performance of Transformers.

Three essential ingredients characterize the success of SSMs:

1. **State Size**: SSMs feature a hidden state with a larger size than the inputs and outputs, enabling the model to store more context-rich information—a crucial trait for handling complex modalities like language.

2. **State Expressivity**: The recursive update functions in SSMs are expressive enough to store and selectively access needed information, akin to the gating mechanisms in classic RNNs like LSTMs and GRUs. This flexibility allows the model to handle sequences with varying information rates, a key requirement for language modeling.

3. **Training Efficiency**: While having a larger recurrent state boosts performance, it also increases computational complexity. Innovations like parallel scan algorithms have been employed to enhance the feasibility of training SSMs on modern hardware, balancing memory usage and computational workload.

The blog highlights that these strategies, though not entirely new, when combined effectively, bring SSMs to the forefront, demonstrating near-equivalence to Transformers in language modeling tasks.

The landscape of modern machine learning is rapidly shifting as researchers continuously seek to improve recurrent models. SSMs and other models like RWKV and Griffin are explored further, depicting diverse approaches in state expressivity and parallel training efficiency. The post delves into the nuances of linearity, selectivity, and the theoretical underpinnings of these models, underscoring a vibrant research area ripe with potential.

In sum, while Transformers have been the rockstars of sequence modeling, the advancements in SSMs suggest that the spotlight may start to share its focus, prompting an exciting era of innovation and rediscovery in the field.

The discussion around State Space Models (SSMs) versus Transformers reflects a mix of skepticism, optimism, and technical debate:  

### Key Themes:
1. **Tokenization Debate**:  
   - Some users argue that replacing tokenization schemes like BPE with raw bytes could simplify representations and better align with linguistic fundamentals. For example, one user claims raw bytes (as in Chinese characters or English letters) might offer a more basic, language-agnostic alternative to BPE.  
   - Counterarguments suggest Transformers *require* preprocessing to compress dense information efficiently, particularly for video/audio tasks. Current architectures still depend heavily on tokenization despite its limitations.  

2. **SSMs vs. Transformers**:  
   - Skeptics (**mbowcut2**) question whether SSMs justify significant R&D investment compared to optimized Transformer-based LLMs. They argue that established methods (like Transformers) dominate benchmarks, making SSMs a risky bet without clear evidence of outperformance.  
   - Proponents (**vsrg**, **nxts**) highlight SSMs’ potential differentiation (e.g., efficiency gains, novel architectures like xLSTM) and niche applications (time-series forecasting). Some cite models like xLSTM as proof that alternative architectures can rival Transformers in specific domains.  

3. **Practical Challenges**:  
   - Training costs and scalability remain barriers. While SSMs might theoretically reduce bottlenecks like "information density," users note current SSMs lack competitive benchmarks and struggle to match Transformer-scale datasets.  
   - Hybrid approaches (**Herring**) and incremental innovations (e.g., DeepSeek’s models) are seen as safer bets than full SSM overhauls.  

4. **Broader Research Landscape**:  
   - Comments hint at parallel efforts (LiquidAI, Griffin) exploring lightweight architectures or alternatives that blend SSM concepts with Transformers. However, the dominance of Transformers in industry R&D (e.g., Llama, Gemma) makes radical shifts unlikely in the short term.  

### Conclusion:  
The discussion underscores cautious interest in SSMs as a complement or niche alternative to Transformers, but few see them as an imminent replacement. Technical challenges, entrenched infrastructure for Transformers, and high costs of experimentation temper enthusiasm, even as theoretical advantages (efficiency, differentiation) keep SSMs on the radar.

### Google can now read your WhatsApp messages

#### [Submission URL](https://www.neowin.net/guides/google-can-now-read-your-whatsapp-messages-heres-how-to-stop-it/) | 448 points | by [bundie](https://news.ycombinator.com/user?id=bundie) | [309 comments](https://news.ycombinator.com/item?id=44501379)

This week, Google stirred the pot in the Android community with an unexpected announcement regarding its AI-powered Gemini service. Starting July 7, Gemini is now integrated with popular apps like Phone, Messages, and WhatsApp, allowing users to command tasks like sending messages without needing to toggle Gemini Apps Activity. However, this convenience comes with a catch. While Google reassures users that Gemini won’t read or summarize WhatsApp messages under normal circumstances, integration with Google Assistant or Utility apps could enable access to your messages and notifications. 

Naturally, privacy-concerned users were quick to act, with many opting to disable Gemini’s connected apps to safeguard their data. Despite turning off Gemini Apps Activity, Google maintains data for a brief 72 hours to "ensure safety and security.” Those hoping to completely extricate Gemini from their devices face a more complex endeavor, as Google representatives artfully dodged direct inquiries about permanent removal. However, an arduous path exists via ADB (Android Debug Bridge) to uninstall Gemini, albeit with mixed results due to its ties with the main Google app. 

Tech enthusiasts looking to eliminate Gemini altogether are advised to roll back all updates and disable the Google app entirely, a move that effectively removes the AI agent but also disables Google’s broader functionalities.

This development has led to broader discussions about privacy, with questions circling the necessity and implications of AI’s growing integration into daily tech interactions. Amidst these concerns, users are reminded of the broader trade-offs involved when weighing functionality against privacy. Meanwhile, platforms like Neowin encourage community engagement and support through various means, including Amazon shopping links and virtual coffee contributions. Stay tuned to the ever-evolving landscape of tech privacy and AI integration—your voice, and vigilance, matter.

The discussion revolves around Google's integration of Gemini as an OS-level feature on Android, raising significant privacy and antitrust concerns. Key points include:

1. **Privacy Concerns**: Users worry Gemini could access sensitive data (e.g., WhatsApp messages) via integrations like Google Assistant, despite Google’s assurances. Disabling Gemini is complicated, requiring ADB or disabling the Google app entirely, which breaks core functionalities.

2. **Antitrust Parallels**: Comparisons are drawn to Microsoft’s Internet Explorer case and Apple’s ecosystem control. Critics argue Google’s OS-level integration stifles competition, echoing historical antitrust issues. The EU’s Digital Markets Act (DMA) is cited as a regulatory counterforce.

3. **OS Alternatives**: Some advocate for alternatives like GrapheneOS or LineageOS to escape Google’s control, though practical hurdles (e.g., banking app compatibility) persist. Others mention decentralized projects like ApostrophyOS or Purism’s Librem 5.

4. **Apple Comparisons**: Debates arise over Apple’s Siri and privacy reputation, with skepticism about both companies’ motives. While Apple is seen as more privacy-focused, critics note its ecosystem’s closed nature mirrors Google’s control.

5. **Broader Skepticism**: Users express distrust in tech giants, emphasizing data monetization and AI overreach. Concerns about centralized control of personal information and AI’s role in daily tech interactions dominate.

The discussion highlights tensions between innovation/convenience and privacy/control, reflecting broader debates about corporate power and regulatory adequacy in the AI era.

