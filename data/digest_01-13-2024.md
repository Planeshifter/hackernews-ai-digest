## AI Submissions for Sat Jan 13 2024 {{ 'date': '2024-01-13T17:09:44.716Z' }}

### Building a fully local LLM voice assistant to control my smart home

#### [Submission URL](https://johnthenerd.com/blog/local-llm-assistant/) | 567 points | by [JohnTheNerd](https://news.ycombinator.com/user?id=JohnTheNerd) | [149 comments](https://news.ycombinator.com/item?id=38985152)

A developer has built their own personal assistant that is sassy and sarcastic, with the ability to control devices locally. The assistant runs on a combination of hardware including a firewall, managed switch, and multiple graphics cards. The developer also used an inference engine and a customized voice model to achieve the desired functionality. However, they encountered challenges with integrating the assistant with HomeAssistant and had to make modifications to the templates and code to address the issues. Despite the challenges, the developer was able to create a working solution for controlling devices with their personalized assistant.

The discussion on this submission revolves around various aspects of the developer's personal assistant and HomeAssistant integration.
One comment points out that Home Assistant already has similar functionality and suggests using standardized APIs instead of reinventing the wheel.
Another user praises the capabilities of local language models (LLMs) in Home Assistant but notes that the integration can be complex due to the various installations and integrations required. They also mention some use cases like creating a dashboard or controlling lights based on specific conditions.
There is a discussion about controlling lights based on various factors like temperature, light level, and sensor signals. Machine learning and natural language processing are mentioned as potential solutions.
Some comments discuss the challenges of integrating AI language models, suggesting the use of specific libraries or existing frameworks like Blueprints, Pyscript, Node-RED, and ESPHome for better control and automation.
One user raises concerns about AI safety in terms of preventing the assistant from performing harmful actions like setting the thermostat to extreme temperatures or power-cycling devices excessively.
Another comment suggests leveraging OpenAI's API for better compatibility and discusses the limitations of local language models in terms of online access and response time.
There is interest expressed in streaming responses and faster performance for integrating language models like Whisper for a more responsive experience.
In general, the comments reflect a mix of admiration for the developer's work, discussions on existing solutions within Home Assistant, and suggestions for further improvements and integrations.

### The Global Project to Make a General Robotic Brain

#### [Submission URL](https://spectrum.ieee.org/global-robotic-brain) | 66 points | by [T-A](https://news.ycombinator.com/user?id=T-A) | [18 comments](https://news.ycombinator.com/item?id=38979713)

A global project called the RT-X project is aiming to create a general-purpose robotic brain by pooling together the experiences of 34 different labs around the world. The goal is to enable a single deep neural network to control various types of robots, a capability called cross-embodiment. The challenge lies in the fact that robots require specific robot data to learn from, which is often created slowly and tediously in lab environments. By combining data, resources, and code from multiple labs, the project hopes to accelerate progress in robot learning and enable robots to perform real-world tasks outside of the lab.

The discussion on this submission covers a range of topics related to AI and robotics. Here are the key points:

- One commenter mentions a 1974 report by Professor Sir James Lighthill that criticized the objective and effectiveness of AI research in the UK. There is some debate about the impact of this report on AI research in the UK.
- Another commenter highlights the complexity of training robots and the limitations of current research. They suggest that simulations and virtual reality systems could help in training robots more efficiently.
- A discussion ensues about the computational power required for AI research and the challenges of handling large matrix multiplications.
- Some commenters express skepticism about the abilities of general-purpose robots and believe that specialized robots for specific tasks would be more effective.
- Others believe that general-purpose robots with a wide range of skills, comparable to average human abilities, are feasible and will be developed in the future through advancements in AI research.
- The potential market for cleaning robots is mentioned, with a commenter noting that effective cleaning robots can potentially capture a significant portion of the multi-billion dollar market.
- The discussion also touches on the challenges of integrating sensory perception and hand control in robots, as well as the limitations of current robot capabilities compared to human abilities.
- The need for specialized robotics research and the difficulty in achieving general-purpose robots are debated. Some argue that the complexity of tasks and behaviors require specialized robots, while others believe that general-purpose robots can be trained to handle a variety of tasks.
- One commenter mentions the challenges of identifying and manipulating objects in real-world environments, highlighting the difficulties that arise when robots encounter unexpected situations.

Overall, the discussion covers various perspectives on the potential and challenges of AI and robotics, including the feasibility of creating a general-purpose robotic brain.

### Open-Source AI Is Uniquely Dangerous

#### [Submission URL](https://spectrum.ieee.org/open-source-ai-2666932122) | 29 points | by [redbell](https://news.ycombinator.com/user?id=redbell) | [56 comments](https://news.ycombinator.com/item?id=38977366)

The dangers of open-source AI systems are highlighted in a guest post on IEEE Spectrum. While closed-source AI applications like OpenAI's ChatGPT have secure software held by the maker, powerful unsecured AI systems are being rapidly released without regulations. Companies like Meta, Stability AI, Hugging Face, Mistral, EleutherAI, and the Technology Innovation Institute are releasing unsecured AI systems, which could generate misleading or toxic content. While the open-source movement is important for democratizing access to AI, there is currently a lack of control over the risks posed by unsecured AI. Regulation is needed to address these concerns.

The comments on this submission cover various aspects of the dangers and implications of open-source AI systems. Some users express concerns about closed-source AI applications, stating that they may also pose risks and that public safety requires regulation. Others argue that researchers working behind closed doors can create dangerous things, and the risks are not limited to open-source AI. 
Some comments discuss the potential for misuse of open-source AI models, such as using them to generate misleading or toxic content. There is a debate about whether open-source AI systems should be called "unsecured" or "unsecured AI models." Some users argue that replacing the term "AI" with "computer" in the discussion provides better insights into how the human mind works and the potential dangers.
There are also discussions about the role of regulation and the need for transparency in open-source AI. Some users argue that the risks associated with AI can be mitigated by commercial service providers offering well-secured systems. Others express skepticism about the article and the motives behind it, suggesting that it may be misleading or propaganda.
Overall, the comments reflect a range of opinions on the dangers and regulation of open-source AI systems, with some users emphasizing the importance of responsible development and others questioning the level of risk and potential for misuse.

### Your pacemaker should be running open source software

#### [Submission URL](https://www.theregister.com/2024/01/12/column/) | 18 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [18 comments](https://news.ycombinator.com/item?id=38984030)

In a recent article by Steven J. Vaughan-Nichols, the author highlights the issue of proprietary software in medical devices, specifically implantable medical devices like pacemakers, defibrillators, and insulin pumps. Vaughan-Nichols tells the story of Karen Sandler, the Executive Director of the Software Freedom Conservancy, who faced a life-or-death situation when she couldn't access data from her pacemaker because it ran on proprietary software. This incident raises concerns about the lack of transparency and security in medical devices, as proprietary software is a black box that only the manufacturer has control over. Vaughan-Nichols emphasizes that all software has bugs and vulnerabilities, and open-source software tends to be safer and more reliable over time. He also references previous cases where medical devices were found to have security vulnerabilities and were subject to recall. The author's main point is that relying on proprietary software in medical devices puts patients at risk and highlights the need for greater transparency and security in the industry.

The discussion on this submission primarily focuses on the need for third-party verification and the importance of open-source software in ensuring the safety and reliability of medical devices. Some users argue that running certified and audited software by competent third-party experts is essential for identifying and mitigating safety defects. They also highlight that open-source software tends to have a higher quality level and allows for additional quality assurance measures. 
Others discuss the challenges of relying on closed-source software in medical devices, citing cases where certified software was replaced with uncertified versions, potentially compromising patient safety. They argue that only certified source code is constantly validated in production and that open-source software is a sufficient alternative for safety-critical deployments. 
There is also a discussion on the liability of component providers and the importance of transparency in the medical field. Some users emphasize the need for full chemical makeup and formulation information in medical products, while others highlight the importance of third-party validation in ensuring the efficacy and safety of medications. 
The topic of regulation and testing by centralized authorities like the FDA is also mentioned, with suggestions that decentralization of verification processes could improve safety and efficiency.
Overall, the discussion revolves around the significance of open-source software, the need for third-party verification, and the challenges related to closed-source and proprietary software in the medical device industry.

