## AI Submissions for Mon Dec 11 2023 {{ 'date': '2023-12-11T17:10:21.576Z' }}

### TSA introducing self-service screening technology in Las Vegas

#### [Submission URL](https://upgradedpoints.com/news/tsa-self-service-screening/) | 107 points | by [mji](https://news.ycombinator.com/user?id=mji) | [200 comments](https://news.ycombinator.com/item?id=38603440)

The Transportation Security Administration (TSA) is introducing new self-service screening technology for TSA PreCheck travelers. The new process will allow eligible travelers to proceed through screening lanes with little to no intervention by TSA officers, hopefully providing a more seamless screening experience. The new self-service screening machines will debut at Las Vegas' Harry Reid International Airport (LAS) in January 2024 and will only be available to TSA PreCheck members. The technology will be tested and rolled out slowly, depending on its success. In addition to the self-service screening process, passengers will still have to follow the 3-1-1 liquids rule, cannot be in possession of a sharp object or weapon, and cannot carry any prohibited items. Another company, Micro-X, is developing individual self-screening pods that are scheduled to be tested in 2025, with the goal of accommodating multiple travelers at once. The successful rollout of self-screening options to other airports will depend on the success of these pilot tests. Overall, this new technology aims to speed up the screening process and reduce interaction between TSA staff and travelers.

The discussion in the comments section of this submission on Hacker News covers a wide range of topics related to biometrics, privacy, and the effectiveness of TSA screening procedures. Here's a summary of the main points discussed:

- Some users express skepticism about the reliability and security of biometric systems, such as fingerprint recognition. They point out past instances where biometric data has been hacked or misused.
- Others discuss the limitations of using biometrics as a form of identification, noting that fingerprints and DNA can be easily changed or manipulated.
- Some users argue for the importance of individual privacy and express concerns about the potential misuse of biometric data.
- The discussion also includes anecdotes from users who have experienced difficulties with biometric identification due to various reasons, such as missing fingers or medical conditions.
- There are debates about the effectiveness of TSA screening procedures and whether biometric identification is necessary for security purposes.
- A few users mention alternative methods of identification, such as using Social Security numbers or unique personal identifiers.
- The potential risks of identity theft and phishing attacks are also raised, with users discussing the vulnerability of biometric data compared to other forms of credentials.

Overall, the discussion highlights the complex nature of biometrics and the varying opinions on its use in security screening processes. Users emphasize the need for careful consideration of privacy and security implications when implementing biometric systems.

### Photorealistic Video Generation with Diffusion Models

#### [Submission URL](https://walt-video-diffusion.github.io/) | 152 points | by [smusamashah](https://news.ycombinator.com/user?id=smusamashah) | [47 comments](https://news.ycombinator.com/item?id=38603014)

Researchers from Stanford and Google Research have introduced W.A.L.T, a transformer-based approach for generating photorealistic videos. This method leverages diffusion modeling and incorporates two crucial design decisions. Firstly, it utilizes a causal encoder to compress images and videos in a unified latent space, enabling cross-modal training and generation. Secondly, it adopts a window attention architecture tailored for joint spatial and spatiotemporal generative modeling to improve memory and training efficiency. Notably, W.A.L.T achieves state-of-the-art performance on video and image generation benchmarks without relying on classifier-free guidance. Additionally, the researchers trained a cascade of three models for text-to-video generation, resulting in the creation of high-resolution videos at a rate of 8 frames per second.

The discussion on this submission covers various topics related to AI-generated videos and the film-making process. Here are the key points raised:

- Some users express skepticism about the capabilities of generative AI, comparing it to low-quality stock footage and criticizing the lack of creative control and originality.
- Others argue that while the current state of AI-generated videos may not be perfect, they show potential for sophisticated and complex productions in the future.
- The discussion shifts to the challenges of the film-making process, including the difficulties faced by directors in gaining access to resources and the limitations imposed by conventional production methods.
- There is a debate about the democratization of content creation and the potential impact of AI on the industry, with some arguing that AI tools will provide more opportunities for aspiring filmmakers and others expressing concerns about the quality and originality of content.
- Some users suggest alternative AI models and technologies for video generation and enhancement, such as Real-ESRGAN for upscaling images and the potential of machine learning in improving video stability.
- There are also tangential discussions about the commodification of AI-generated content, the requirements for becoming a filmmaker, and the limitations of current AI technology.

Overall, the discussion reflects a mix of opinions on the potential and challenges of AI-generated videos, as well as the broader implications for the film-making industry.

### Mistral: Our first AI endpoints are available in early access

#### [Submission URL](https://mistral.ai/news/la-plateforme/) | 481 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [136 comments](https://news.ycombinator.com/item?id=38598568)

Mistral AI, the company behind the strongest open generative models, is now offering early access to their AI endpoints. The platform provides developers with efficient ways to deploy and customize these models for production. In this initial beta release, Mistral AI is offering three chat endpoints for generating text based on textual instructions, as well as an embedding endpoint. The generative endpoints, called mistral-tiny, mistral-small, and mistral-medium, vary in performance and price. The first two endpoints use open models, while the third uses a prototype model with higher performance. Mistral AI has employed effective alignment techniques to create easy-to-control and pleasant-to-use models. The models are pre-trained on data from the open web and fine-tuned with instructions. Mistral AI also offers an embedding endpoint called mistral-embed with a 1024 embedding dimension, designed for retrieval capabilities. The API follows the specifications of a popular chat interface, and clients can use Python and Javascript libraries to query the endpoints. Mistral AI is gradually ramping up capacity and anyone can register to use their API.

The discussion on this submission includes various points of interest and perspectives. Some users discuss their surprise at the rapid growth and valuation of Mistral AI, comparing it to other AI companies like OpenAI and Google. Others emphasize the impressive performance and benchmarks of Mistral AI's models. The topic of regulations and compliance is also discussed, with some users pointing out the importance of adhering to EU rules and the potential impact on the AI market. There is also a mention of the French engineering company focusing on mathematics and the advantages it brings to AI. The conversation then shifts to a discussion about Google's dominance in the AI space and the challenges faced by smaller companies. The debate touches on how Google's AI algorithms impact search results and the trade-off between AI-powered summarization and traditional search results.

### GigaGPT: GPT-3 sized models in 565 lines of code

#### [Submission URL](https://www.cerebras.net/blog/introducing-gigagpt-gpt-3-sized-models-in-565-lines-of-code) | 220 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [65 comments](https://news.ycombinator.com/item?id=38603207)

Cerebras has developed gigaGPT, an implementation of Andrei Karpathy's nanoGPT, that enables training and fine-tuning of GPT models with over 100 billion parameters. Unlike other frameworks, gigaGPT achieves this without introducing additional code or relying on third-party frameworks. The entire codebase is just 565 lines, making it compact and highly accessible. The models were validated by training them on the OpenWebText dataset, and gigaGPT demonstrated the ability to scale from millions to hundreds of billions of parameters without specialized parallelization techniques. It even showed promise in handling models with over 1 trillion parameters, without running out of memory on Cerebras hardware. With gigaGPT, ML practitioners can have a hackable and efficient codebase for training large GPT models with long context lengths.

The submission introduces gigaGPT, an implementation of Andrei Karpathy's nanoGPT that enables training and fine-tuning of GPT models with over 100 billion parameters. The discussion covers various topics related to the implementation and its implications:

1. Comparison with distributed training: Some users believe that distributed training is necessary for handling large models and question the need for gigaGPT. Others point out that while distributed training is useful for certain tasks, it is not always necessary and can add complexity.
2. Hardware constraints: There is discussion about the limitations of scaling vertically and the challenges in designing hardware that can handle larger models. Cerebras, the company behind gigaGPT, is mentioned for developing Cerebras Wafer-Scale Engine (WSE), which is capable of supporting models with over 1 trillion parameters.
3. Complexity and performance considerations: Users discuss the trade-offs between different model architectures, such as Transformers and RNNs, and their hardware requirements. The scalability and efficiency of gigaGPT compared to other implementations are also discussed.
4. Pricing and availability: Some users mention the cost of Cerebras chips and note that it may not be accessible to all consumers.
5. Performance of gigaGPT: Several users point out the importance of performance metrics in the article and express curiosity about the comparative performance of gigaGPT with other models.
6. Codebase and optimization: The compactness of gigaGPT's codebase is appreciated, and users discuss the challenges of optimizing models for training and inference.

Overall, the discussion highlights the advancements and challenges in scaling GPT models and the implications of gigaGPT's approach in training large models with long context lengths.
