## AI Submissions for Wed Oct 16 2024 {{ 'date': '2024-10-16T17:12:11.148Z' }}

### AI PCs Aren't Good at AI: The CPU Beats the NPU

#### [Submission URL](https://github.com/usefulsensors/qc_npu_benchmark) | 449 points | by [dbreunig](https://news.ycombinator.com/user?id=dbreunig) | [256 comments](https://news.ycombinator.com/item?id=41863061)

In a recent development, the usefulsensors GitHub repository has unveiled a public benchmarking project to assess the performance capabilities of Qualcomm's Neural Processing Unit (NPU) on Windows-based devices, specifically targeting Surface tablets powered by Qualcomm's Arm-based system-on-chip (SoC). Dubbed "qc_npu_benchmark," this initiative aims to provide developers with a clearer understanding of the NPU's processing power for machine learning models, spotlighting the challenges many face when trying to optimize performance in this relatively uncharted territory.

Despite high promises from Qualcomm, the benchmarks revealed only 1.3% of the claimed 45 Teraops/sec under practical testing conditions. The project includes detailed instructions on installation and running benchmarks using Python, CMake, and Visual Studio, noting gaps in existing documentation for external developers. The results highlight a significant disparity between CPU performance and NPU performance, with the CPU achieving around 821 Gigaops, while the NPU's performance reached between 225 to 573 Gigaops depending on the configuration.

As interest in AI PCs grows, contributors to the repository are hopeful that optimizations at the application, framework, or driver levels will enhance performance in the future. The benchmarking results and methodologies laid out in this project are poised to foster discussion and further investigation into maximizing the potential of Qualcomm's hardware in Windows environments.

The discussion on the Hacker News submission about the qc_npu_benchmark project from usefulsensors delves into various aspects of the performance of Qualcomm's Neural Processing Unit (NPU) on Windows devices. Key points include:

1. **Performance Comparisons**: Commenters noted that the benchmark results revealed a significant performance gap between the CPU (821 Gigaops) and the NPU (ranging from 225 to 573 Gigaops). One user expressed disappointment that the NPU did not meet expectations compared to CPU and GPU alternatives.

2. **Understanding NPU Speed**: Several comments clarified misconceptions about NPU speed. It was emphasized that the NPU is designed for lower power consumption rather than maximum processing speed, with a focus on optimizing efficiency.

3. **Hardware Discussions**: The conversation shifted to broader discussions about hardware capabilities, including comparisons with Apple Silicon, which many users found to be notably effective in their performance. Users debated the future direction of AI hardware and questioned how various NPUs could compete in the market.

4. **Industry Context**: The need for Qualcomm and others to improve their driver and software support to unlock the full potential of their hardware was highlighted. Users discussed how companies like Apple and NVIDIA have established themselves in the AI space, which might set benchmarks for others.

5. **AI and Market Dynamics**: Several users pointed to the increasing demand for AI technology in consumer products and the associated market implications. The discussions pointed towards an evolving landscape where companies need to adapt to meet consumer expectations for performance and efficiency.

Overall, the conversation blended technical assessments of the benchmark findings with strategic insights into the competitive landscape of AI hardware, underscoring the complexities and challenges in achieving optimal NPU performance.

### We outsmarted CSGO cheaters with IdentityLogger

#### [Submission URL](https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/) | 340 points | by [mobeigi](https://news.ycombinator.com/user?id=mobeigi) | [316 comments](https://news.ycombinator.com/item?id=41862028)

In the competitive world of Counter-Strike: Global Offensive (CSGO), running a community server is no small feat. An insightful post from a former operator of Invex Gaming, a thriving CSGO community in Australia and New Zealand from 2014 to 2019, explores the multifaceted responsibilities involved in maintaining such a server.

**Building a Community**  
Invex Gaming gained recognition thanks to an engaging community, custom plugins, and exciting competitions. However, the operator outlines that success comes with a substantial workload: from maintaining server infrastructure and handling player donations, to implementing new features and addressing security threats like DDOS attacks.

**The Exasperating Cat-and-Mouse Game with Cheaters**  
One of the most frustrating aspects of server operation is battling cheaters. While there are various anti-cheat measures available, including server-side detection and Valve's VAC system, the game between cheat developers and anti-cheat measures often feels like an endless, unpredictable duel. When blatant cheats are identified, manual reviews of recorded gameplay (demos) are necessary for final decisions.

**The Art of Ban Evasion**  
Cheaters aren’t easily deterred, often employing tactics to evade bans. When banned, a player typically shifts their Steam ID or IP address to sneak back onto the server. However, operators can still trace these changes, creating a 'fingerprint' for repeat offenders. Despite these measures, highly determined cheaters can ultimately escape detection by changing both identifiers simultaneously, making it nearly impossible to connect them with their history of misconduct.

**The Never-Ending Battle**  
The operator emphasizes the reality that cheaters continually devise new strategies, leading to an ongoing arms race within the gaming community. While there are ideas for maintaining lists of known VPNs or employing other preventive measures, these plans require extensive upkeep that volunteer admin teams may be reluctant to pursue.

This post not only sheds light on the dedication behind community management but also raises awareness about the complex and relentless battle against cheating in online gaming. As community servers continue to grow, the strategies for safeguarding competitive integrity remain crucial but daunting.

In the discussion regarding the challenges of running a CSGO community server, various commenters shared insights and suggestions based on their experiences with server management and player behavior.

1. **Cheating and Bans**: Several users highlighted the persistent issue of players using VPNs and dynamic IP addresses to evade bans. One commenter mentioned the necessity of implementing robust blocking measures against VPNs and suggested advanced techniques such as creating a 'fingerprinting' system to track persistent offenders. They stressed that even when IP bans are enforced, dedicated cheaters often find ways around them.

2. **Game Integrity**: The conversation delved into the struggle for maintaining game integrity amidst continuous attempts at cheating. A user noted how tricky it can be to enforce rules effectively, especially as VPNs and other tools evolve, complicating the process of ensuring fair play.

3. **Community Building**: Many participants remarked on how vital community engagement is for the success of servers. Building a strong player base can help counteract issues like cheating, as invested players may be more likely to report misconduct.

4. **Technical Challenges**: Some participants shared technical recommendations for monitoring player behavior and enforcing rules, such as using specific server commands and plugins to mitigate unfair advantages.

5. **Latency Concerns**: The issue of latency for players utilizing mobile or VPN connections was also brought up. Commenters discussed how high latency can impact gameplay quality for users, particularly for competitive shooters like CSGO, making it essential for server operators to consider regional connection quality.

6. **Player Retention**: One user expressed concern about the challenges in retaining players due to ongoing issues with cheating and server-related problems. They shared experiences about player drop-off rates when server performance diminishes or when players feel unfairly treated.

Overall, the discussion emphasized the complexity of managing a CSGO community server, focusing on both the technical and community aspects that contribute to a successful gaming environment.

### Efficient high-resolution image synthesis with linear diffusion transformer

#### [Submission URL](https://nvlabs.github.io/Sana/) | 206 points | by [Vt71fcAqt7](https://news.ycombinator.com/user?id=Vt71fcAqt7) | [41 comments](https://news.ycombinator.com/item?id=41859805)

In a groundbreaking advancement in image synthesis, a team from NVIDIA, MIT, and Tsinghua University has introduced **Sana**, an innovative text-to-image framework capable of generating high-resolution images (up to 4096 × 4096 pixels) at unprecedented speeds without sacrificing quality. What sets Sana apart is its efficiency; it employs a deep compression autoencoder that reduces latent tokens by an impressive 32 times, allowing it to produce stunning images while remaining light enough to run on a typical laptop GPU.

Key features of Sana include the **Linear Diffusion Transformer** (DiT), which replaces traditional quadratic attention with a linear approach, enhancing processing speed and resolution capability. A new text encoder, utilizing a decoder-only small language model, significantly improves text comprehension and alignment, enhancing the synergy between textual prompts and visual output. Additionally, a novel **Flow-DPM-Solver** streamlines the sampling process, cutting down inference steps and boosting overall performance.

Sana has shown remarkable results, outperforming existing models in both speed and image quality. For instance, Sana-0.6B is 20 times smaller and 100 times faster than competing models and can generate a 1024 × 1024 resolution image in under one second. By offering substantial advancements in generative model efficiency and performance, Sana is poised to revolutionize content creation, making it accessible and cost-effective for creators everywhere.>

The discussion surrounding the submission of the **Sana** text-to-image framework showcases a mix of excitement, skepticism, and technical evaluation among commenters. Here's a summary of the key points raised:

1. **Performance Claims**: Many users expressed enthusiasm about Sana's reported performance improvements compared to existing generative models. It was mentioned that Sana can generate high-quality images at significantly faster rates and with fewer resource requirements (e.g., just 16GB VRAM for specific resolutions). However, some raised concerns about the reliability of benchmarks, suggesting the need to compare results against established models like **FLUX**.

2. **Technical Underpinnings**: Commenters highlighted the innovative aspects of Sana's architecture, such as the Linear Diffusion Transformer and deep compression autoencoder, which allows the model to maintain high quality while reducing the computational burden. Some comments discussed the technical merits of these components but called for a clearer explanation of the methodologies used in comparisons.

3. **Comparison to Other Models**: The discussion included comparisons to models such as **Stable Diffusion** and **Midjourney**. Some participants noted that while Sana claims rapid generation, other models like Stable Diffusion have yielded convincing results on personal hardware setups.

4. **Benchmarking and Quality**: There were concerns regarding the benchmarking processes and the reproducibility of results. Some users pointed out that various models produce different quality outputs, leading to ongoing debate about the absolute measurement of quality across various generative tasks.

5. **Generative Ethics and Copyright**: A sub-discussion emerged around the ethical implications of using AI for image synthesis, especially in relation to copyright issues for artists and creators. This reflection echoed broader concerns about how generative models utilize data, particularly regarding intellectual property rights.

6. **Future Expectations**: Overall, many in the discussion remained cautiously optimistic about Sana's potential in revolutionizing content creation, but emphasized the need for transparency in performance claims and rigorous testing against peer models.

In summary, the conversation captured a blend of optimism about the advancements offered by the **Sana** framework alongside valid concerns over performance benchmarking, technical clarity, and ethical considerations in AI-generated content.

### Traveling with Apple Vision Pro

#### [Submission URL](https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/) | 437 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [544 comments](https://news.ycombinator.com/item?id=41859012)

As the Apple Vision Pro becomes a staple for frequent flyers, an insightful blog post reveals how this innovative device enhances travel experiences. Whether on a plane or a train, the Vision Pro offers users an immersive way to tune out the surroundings and engage with movies, work, or apps.

The author shares practical tips for seamless travel, emphasizing a minimalist packing strategy. Instead of the bulky official case, they recommend simply using the device's protective cover and a lens protector to conserve space in your backpack. This setup has proven effective across multiple flights, ensuring the Vision Pro remains scratch-free.

Airport security checks prove manageable, with the Vision Pro blending in without raising eyebrows. When it comes to gauging performance mid-flight, the headset's "Travel Mode" stands out as a game-changer, adjusting for movement-related tracking issues to provide a stable experience.

However, users should be mindful of battery life – lasting only 2.5 to 3 hours, the Vision Pro is suitable for short flights but could present challenges on longer journeys. The author suggests relying on in-seat power outlets or a high-capacity battery bank to extend entertainment options.

In conclusion, while the Vision Pro enhances the journey with engaging media, travelers are encouraged to plan accordingly for battery life and weight considerations to fully enjoy the benefits this cutting-edge device brings to their travel adventures.

The discussion stemming from the submission on traveling with the Apple Vision Pro touches on various experiences and tips regarding long-duration flights and the use of technology for entertainment and sleep. Here's a summary of the key points highlighted by users:

1. **Device Comparisons**: One user mentions using Xreal Air glasses with an iPhone, indicating they find this setup works well for streaming Netflix. They note the Apple Vision Pro is limited by its battery life of 2-3 hours.

2. **Flight Experience**: Many comments revolve around the challenges of getting adequate sleep on long flights. Several participants share personal anecdotes about their difficulty sleeping on planes, suggesting various methods to improve comfort, such as using melatonin or sleeping masks.

3. **Travel Comfort**: The conversation highlights how some users have adapted to long flights, developing routines to maximize rest and minimize discomfort. Specific mention is made of the importance of having in-flight entertainment and the struggle with cabin pressure and noise.

4. **Medical Conditions**: A segment of the discussion addresses the necessity for CPAP or BiPAP machines for users with sleep apnea and the challenges encountered while trying to travel with them. Detailed descriptions of what makes these devices effective and applicable for travel emerge, along with concerns about power supply compatibility during flights.

5. **Cultural Insights**: Participants also reflect on cultural aspects of traveling, sharing regional expressions and phrases that resonate with their travel experiences.

6. **Balance of Travel and Sleep**: Overall, the comments underline a common theme of travelers trying to find a balance between maximizing their time during long trips while still ensuring they can rest adequately, particularly concerning the constraints of available technology and personal health.

These discussions reveal a shared interest in leveraging technology for enhanced travel experiences, while also addressing the broader issues of comfort and well-being during long-duration journeys.

### Show HN: Automated smooth Nth order derivatives of noisy data

#### [Submission URL](https://github.com/hugohadfield/kalmangrad) | 134 points | by [hugohadfield](https://news.ycombinator.com/user?id=hugohadfield) | [37 comments](https://news.ycombinator.com/item?id=41863398)

Today's highlight from Hacker News features an intriguing Python package called **Kalmangrad**, designed for calculating derivatives from noisy time series data with enhanced accuracy. Developed by hugohadfield, Kalmangrad utilizes Bayesian filtering techniques to deliver smooth estimates of derivatives, even when dealing with non-uniformly sampled data—an issue traditional numerical methods struggle with due to noise amplification.

This package allows users to compute derivatives of any specified order, making it especially useful in fields like signal processing and control systems. It stands out for its easy integration into existing projects and minimal dependencies—only requiring NumPy and the BayesFilter package. 

Kalmangrad's interface is user-friendly, with the primary function `grad` tasked with estimating derivatives based on the given data. The package provides an illustrative example of estimating first and second derivatives from a noisy sine wave, showcasing its practical application alongside visualization of results.

For anyone wrestling with the complexities of derivative estimation in noisy environments, Kalmangrad offers a robust, Bayesian-based solution that promises not just accuracy but also ease of use. Check it out on GitHub to explore its features and enhance your data processing capabilities!

The discussion surrounding the Kalmangrad submission on Hacker News has revealed a variety of perspectives and experiences regarding derivative estimation techniques, particularly in relation to the use of the Kalman filter and Savitzky-Golay filters.

1. **Technical Comparisons**: Users have engaged in comparing Kalmangrad's Bayesian approach with traditional methods like Savitzky-Golay filters, with some noting the limitations of traditional techniques, especially in handling noise within non-uniformly sampled data.

2. **Practical Applications**: Several commenters shared their own experiences with similar issues in fields such as signal processing, control systems, and data analytics. They discussed the difficult challenges they faced with noise and repeated measurements, and indicated that Kalmangrad could potentially address these issues effectively due to its unique approach.

3. **User Feedback and Questions**: There were questions regarding the functionality and depth of Kalmangrad. The package developer, hugohadfield, responded by clarifying capabilities and discussing scenarios where noise could significantly inhibit performance and how Kalmangrad offers solutions.

4. **Further Exploration**: Commenters expressed enthusiasm and curiosity about the package, with several indicating plans to explore Kalmangrad for their own projects. Some pointed out that better understanding of mathematical concepts behind Kalman filters could aid in utilizing Kalmangrad to its full potential.

5. **General Sentiments**: The overall tone of the discussion was positive, with many users expressing appreciation for the development of such a tool and its ease of integration into existing workflows. Insights were shared on how to extend its application, particularly in more complex scenarios involving noisy data.

In summary, the discussion highlighted a strong interest in Kalmangrad, appreciated its approach to derivative estimation in noisy data, and fostered a dialogue on its potential practical applications and challenges relative to other techniques.

### I Self-Hosted Llama 3.2 with Coolify on My Home Server

#### [Submission URL](https://geek.sg/blog/how-i-self-hosted-llama-32-with-coolify-on-my-home-server-a-step-by-step-guide) | 217 points | by [whitefables](https://news.ycombinator.com/user?id=whitefables) | [88 comments](https://news.ycombinator.com/item?id=41855886)

In his recent blog post, a tech enthusiast shares his adventurous journey of self-hosting Llama 3.2 on a home server using Coolify. Motivated by cost concerns over existing platforms and a desire to enhance his technical skills, he transformed an unused server—which had previously been a workhorse for high-frequency trading—into a hub for AI applications for his business, Wisp.

The post details a step-by-step guide that not only highlights the technical challenges he faced, such as GPU acceleration with CUDA toolkit and API exposure, but also celebrates the triumphs along the way, including deploying a Next.js website secured through Cloudflare Tunnel. The author walks readers through installing Ubuntu, configuring Coolify, and optimizing the use of his server's GeForce RTX 2060 GPU, which drastically improved inference speeds.

His detailed account includes useful tips for others attempting similar projects, from essential commands for managing system resources to troubleshooting installation hiccups. With several encouraging successes, like hosting his personal blog, this narrative serves as both a roadmap for aspiring self-hosters and a testament to the rewarding nature of tackling complex tech challenges.

In a lively discussion on Hacker News regarding a blog post about self-hosting Llama 3.2, various users shared insights and experiences related to running self-hosted applications. Key points included:

1. **Self-Hosting Benefits**: Participants emphasized the advantages of self-hosting for personal projects, particularly with tools like Cloudflare for securing websites and managing content delivery. Many found self-hosting to be a practical solution to avoid costs associated with commercial platforms.

2. **Technical Insights**: Users discussed technical hurdles faced while setting up servers, such as configuration of SSL certificates and managing resources effectively. Specific experiences ranged from using OpenVPN to connect remote servers to deploying personal websites efficiently using tools like Tailscale and Coolify.

3. **Content Delivery and TOS Issues**: Concerns were raised about the service agreements of platforms like Cloudflare and how these might affect content delivery, especially for image-heavy sites. Some users pointed out changes in Cloudflare’s terms over time that made self-hosting more viable.

4. **Community Knowledge Sharing**: Many participants appreciated the shared tips on handling software installations and performance issues, such as optimizing GPU usage for faster inference speeds. The community provided a platform for troubleshooting and exchanging strategies for enhancing various setups.

5. **Exploration of LLMs**: Some comments focused on the recent trend of self-hosting language models (LLMs) at home and the potential for freeing those models from the content restrictions often applied by commercial offerings, allowing for more diverse applications.

The conversation highlighted both the challenges and excitement of managing personal server projects, underscoring the importance of community support in overcoming technical difficulties while also celebrating successes in expanding their projects.

### Show HN: Arch – an intelligent prompt gateway built on Envoy

#### [Submission URL](https://github.com/katanemo/arch) | 20 points | by [adilhafeez](https://news.ycombinator.com/user?id=adilhafeez) | [19 comments](https://news.ycombinator.com/item?id=41864014)

The recently launched Arch is making waves in the world of generative AI by providing an intelligent Layer 7 gateway designed to enhance the security and observability of Large Language Model (LLM) applications. Built by the core contributors of Envoy Proxy, Arch aims to streamline the management of prompts—ensuring they are processed swiftly and safely through robust integrations with backend APIs.

Key features of Arch include advanced prompt handling that safeguards against vulnerabilities, intelligent routing for API calls, and centralized observability for monitoring performance metrics like latency and token usage. These capabilities position Arch as a valuable tool for developers looking to improve the operational efficiency of their AI applications.

With its user-friendly CLI and comprehensive setup documentation, Arch allows developers to easily configure LLM providers and set guardrails without having to write extensive code. Its emphasis on secure and personalized AI interactions aligns closely with the current trends in AI development, making it a notable addition to the tech landscape.

Developers are encouraged to check out Arch’s documentation and join its active Discord community for support, demos, and further insights on enhancing generative AI applications.

The discussion surrounding the submission on Arch, the intelligent Layer 7 gateway for AI prompt handling, provides a range of insights from contributors on Hacker News. Here are the main points:

1. **Prompt Security and Handling**: There are mentions of how Arch is designed to prevent jailbreak attempts and ensure safe interactions within AI applications. Some commenters highlight the need for robust measures to control traffic and guarantee secure operations when handling prompts.

2. **Integration with Existing Gateways and Tools**: Several users discuss the integration of Arch with existing API gateways, such as Envoy and Portkey, indicating its compatibility with traditional architectures and its potential to enhance them with AI-specific features.

3. **Feedback and Improvement Suggestions**: Some participants provide constructive feedback on Arch, suggesting areas for further development and emphasizing the importance of community input. The prospect for Arch’s evolution sparked interest, particularly regarding features that align with developer needs and current trends in AI.

4. **Technical Capabilities and Design**: Commenters expressed fascination with Arch's technical design and underlying architecture. The discussion touched on its ability to efficiently route prompts, monitor metrics, and provide a solid framework for developers.

5. **Community Engagement**: The opportunity for collaboration and discussions in Arch’s Discord community was highlighted, encouraging developers to seek help and share insights, which contributes to building a more robust tool.

Overall, the conversation reflects a strong interest in Arch’s potential to impact generative AI applications positively, with users eager to explore its functionalities while providing valuable feedback for ongoing improvements.

### Parents take school to court after student punished for using AI

#### [Submission URL](https://www.theregister.com/2024/10/16/parents_sue_student_ai/) | 24 points | by [belter](https://news.ycombinator.com/user?id=belter) | [23 comments](https://news.ycombinator.com/item?id=41861818)

In a notable legal battle, the parents of a Massachusetts student, referred to as RNH, are suing his school after he faced punishment for using AI in a Social Studies project. The contention stems from the student's acknowledgement that he used AI as a research tool, rather than to generate the entire paper. Despite his explanation, RNH received detention and a lower grade, which his parents argue is causing "irreparable harm" to his academic future, especially with college applications looming. 

They are seeking to have the punitive marks removed from his record, reinstatement in the National Honor Society, and a grade adjustment to a B, asserting that without intervention, their child's chances for college acceptance are jeopardized. 

The school, however, maintains its stance, citing established guidelines against AI usage in student work, which RNH allegedly breached by not properly citing the AI's contributions. As discussions continue, all eyes are on the court's decision, which could set a precedent for the handling of AI in education.

The discussion surrounding the case of RNH, the Massachusetts student penalized for using AI in a school project, emphasizes varying opinions on the implications of academic policies regarding AI usage. 

Some commenters highlighted the prevalence of Saturday detentions in schools, suggesting it’s a common disciplinary method, similar to that portrayed in films like "The Breakfast Club." Others expressed concerns about rigid school policies that can unfairly penalize students, especially when it comes to the use of modern resources like AI. There is a concern for the impact of such policies on students’ academic standing and future endeavors, like college applications.

Comments also reflected worries about academic dishonesty, where students could misuse AI tools without adequately disclosing them, yet some argued that AI could be used responsibly to assist in research rather than outright cheating. The distinction between assistance and cheating was widely debated, with some framing the conversation around whether students can leverage AI as part of their academic work without breaching integrity policies.

Furthermore, there were discussions about the clarity of school handbooks and whether rules regarding AI use were sufficiently communicated, particularly as technology continues to evolve. The overarching sentiment in the thread underscores the need for schools to adapt their policies to account for technological advancements while ensuring academic integrity.

### National Archives Pushes Google Gemini AI on Employees

#### [Submission URL](https://www.404media.co/ai-mazing-tech-venture-national-archives-pushes-google-gemini-ai-on-employees/) | 44 points | by [m463](https://news.ycombinator.com/user?id=m463) | [14 comments](https://news.ycombinator.com/item?id=41855366)

In a bold move to modernize operations, the U.S. National Archives and Records Administration (NARA) is introducing an AI chatbot named "Archie," set to launch in December. Announced during an employee presentation dubbed “AI-mazing Tech-venture,” the tool is intended to enhance productivity for staff by leveraging Google's Gemini AI. However, the rollout faces skepticism from employees concerned about the implications of AI in the critical task of preserving history accurately. One employee voiced frustration, describing the effort as “AI bullshit,” reflecting a wider trepidation among staff about integrating AI into such pivotal work. With ambitions to reshape how citizens access historical records, NARA's initiative is stirring both excitement and unease.

The discussion surrounding the introduction of the AI chatbot "Archie" by the U.S. National Archives and Records Administration (NARA) reveals a deep skepticism among archival professionals about AI's role in preserving historical records. Many participants expressed concerns that generative AI might compromise the accuracy and reliability of historical data. 

Key points raised in the discussion include:

1. **Concerns Over Accuracy**: Participants debated the reported accuracy levels of AI-generated transcripts, with some noting that while AI might achieve around 90% accuracy, this is insufficient for critical archival work where 100% accuracy is essential.

2. **Skepticism About Implementation**: Several comments echoed the sentiment that the integration of AI seemed poorly planned or "shoddy," potentially undermining meaningful historical preservation.

3. **Need for Human Expertise**: The importance of skilled human archivists in the process was emphasized, with critics arguing that replacing or undermining their roles with AI could erode the quality and depth of archival work.

4. **Resistance to Change**: The term "AI bullshit" was notably mentioned by a participant illustrating frustration towards a perceived trend of replacing human expertise with technology that may not be fully adequate or trustworthy.

5. **Dangers of Simplification**: Participants cautioned against oversimplifying complex archival tasks, arguing that generative AI cannot fully replace the nuanced understanding and expertise that trained archivists possess.

Overall, the comments reflect a strong desire to retain rigorous standards in historical preservation while expressing caution regarding the promises of AI technology. There is a call for thoughtful integration rather than a rushed implementation that could jeopardize the integrity of historical records.

