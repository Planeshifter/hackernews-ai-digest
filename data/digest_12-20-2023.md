## AI Submissions for Wed Dec 20 2023 {{ 'date': '2023-12-20T17:11:44.136Z' }}

### Implementation of Mamba in one file of PyTorch

#### [Submission URL](https://github.com/johnma2006/mamba-minimal) | 391 points | by [johnma2006](https://news.ycombinator.com/user?id=johnma2006) | [107 comments](https://news.ycombinator.com/item?id=38708730)

ðŸ“° Today's Top Story: "mamba-minimal: Simple, minimal implementation of Mamba in one file of PyTorch" 

A developer named johnma2006 has created a simplified and minimalist implementation of Mamba in PyTorch. Mamba is a linear-time sequence modeling architecture introduced by Albert Gu and Tri Dao. This implementation aims to provide equivalent numerical output as the official implementation for both forward and backward pass. Although it does not prioritize speed optimizations like the official implementation, it emphasizes readability and simplicity. The implementation does not include proper parameter initialization, but this can be added without sacrificing readability. You can check out the demo.ipynb file to see examples of prompt completions. So if you're interested in exploring Mamba in a more straightforward way, this implementation might be worth checking out.

The discussion on the submission starts with a user praising the library mentioned in the submission and mentions other libraries like EgBERT and MPT which offer support for TorchScript JIT and PyTorch. Another user appreciates the concept of the library and mentions that they have tried a similar implementation by Hugging Face and finds the API level abstraction beautiful. 

A user points out that Mamba does not prioritize speed optimizations but focuses on simplicity and readability. Another user mentions that they are interested in Mamba's implementations and that Fortran can be used as a low-level compiled language for scientific code wrapped in libraries like PyTorch and Numpy. The discussion then goes into debating the benefits of using Fortran and its growing adoption. 

One user talks about the potential of Mamba for sequence modeling beyond transformers and mentions other related models like S4, H3, and Monarch. They also discuss the potential applications of Mamba, including reduced computational effort and faster inference times. Another user adds that Mamba can be competitive in training smaller-sized models.

The conversation then shifts to discussing the difficulties of implementing Mamba and the advantages it offers in compressing context and non-dependent state variables. The topic of attention quadratics and their applications in Mamba and related models is also brought up. 

Users discuss the relevance of Mamba in relation to other models like RNNs and transformers, as well as the challenges of dealing with long-context length. The discussion also touches upon the potential of Mamba for model compression and efficient training. 

One user brings up a video that explains the paper in more detail, while another user mentions the importance of considering the computation parameters and the potential memory constraints in training and inference. They also discuss the use of minimal testing and the requirements for efficient data handling. 

Finally, users share resources such as videos and papers for further understanding and mention their excitement about the development of Mamba.

### High-Speed Large Language Model Serving on PCs with Consumer-Grade GPUs

#### [Submission URL](https://github.com/SJTU-IPADS/PowerInfer) | 380 points | by [dataminer](https://news.ycombinator.com/user?id=dataminer) | [79 comments](https://news.ycombinator.com/item?id=38708585)

Introducing PowerInfer: High-speed Large Language Model Serving on PCs with Consumer-grade GPUs

SJTU-IPADS has developed PowerInfer, a powerful tool that enables high-speed serving of large language models on PCs equipped with consumer-grade GPUs. With 3k stars and 120 forks on GitHub, PowerInfer is gaining popularity in the developer community. The tool is licensed under the MIT license, making it accessible for commercial and open-source projects alike. PowerInfer leverages the computational capabilities of consumer-grade GPUs to deliver fast and efficient language model serving, opening up new possibilities for natural language processing tasks.

The team behind PowerInfer has put in significant effort to optimize the codebase and provide detailed documentation. They have also included several examples to help developers get started quickly. Additionally, frequent updates and bug fixes ensure that PowerInfer stays up to date with the latest advancements in language model serving. The tool is compatible with popular programming languages and frameworks, making it versatile and easy to integrate into existing projects.

PowerInfer has garnered positive feedback from the developer community, with users praising its performance and ease of use. It offers a cost-effective solution for serving large language models, eliminating the need for expensive hardware infrastructure. Whether you're building chatbots, recommendation systems, or language translation services, PowerInfer is a tool worth exploring. To learn more and get started with PowerInfer, visit their GitHub repository.

The discussion on the submission about PowerInfer: High-speed Large Language Model Serving on PCs with Consumer-grade GPUs touches on various topics.

- One user mentions that ReLU activation functions can cause problems in language models and suggests using alternative activation functions like SwiGLU.
- Another user raises the potential legal implications in the USA and EU when it comes to regulating language models and their computational requirements.
- A discussion emerges about the potential harmful effects of mobile games and advertising, with some users expressing concerns about addiction and privacy.
- There is a debate about the benefits and drawbacks of regulations in the technology industry, with some arguing that regulation stifles competition while others emphasize the need for consumer protection.
- Users discuss the performance and compatibility of PowerInfer, with some sharing their experiences with running language models on different GPUs and processors.

Some users also engage in discussions around specific technical details and benchmarks, as well as sharing links to related resources and YouTube videos.

### Six Degrees of Wikipedia

#### [Submission URL](https://www.sixdegreesofwikipedia.com/) | 267 points | by [EndXA](https://news.ycombinator.com/user?id=EndXA) | [66 comments](https://news.ycombinator.com/item?id=38713167)

Introducing the Hacker News Daily Digest: Your one-stop-shop for all the latest and greatest tech news! Our AI will tirelessly scour the depths of Hacker News to bring you the most intriguing and exciting stories, served up in bite-sized summaries that will leave you wanting more. From cutting-edge startups to mind-bending AI breakthroughs, we've got you covered. So sit back, relax, and let us do the heavy lifting while you stay informed and inspired. Get ready to have your mind blown by the world of tech!

In the discussion, the creator of the Hacker News Daily Digest, jwngr, mentioned that they are currently building an AI ml app called Shortwave. They provided links to the GitHub repository and the app's website. Another user, rbtrndmsr, mentioned that they are also building a similar app called Shortwave V2. Some users expressed interest in trying out the app, while others mentioned their frustration with Gmail's inability to properly categorize and label emails. There were also comments discussing the relationship between the Hacker News Daily Digest and similar projects like Six Degrees of Wikipedia. Some users shared links to interesting Wikipedia pages and discussed the concept of linked articles. There were also comments about other websites that allow users to traverse Wikipedia pages in interesting ways. The discussion touched on topics like AI, user experience, and the structure of Wikipedia.

### An AI that learns about chemical reactions and designs a procedure to make them

#### [Submission URL](https://new.nsf.gov/science-matters/meet-coscientist-your-ai-lab-partner) | 131 points | by [geox](https://news.ycombinator.com/user?id=geox) | [45 comments](https://news.ycombinator.com/item?id=38711174)

An artificial intelligence-driven system called "Coscientist" has successfully planned, designed, and executed complex chemical reactions in a matter of minutes. Created by a research team from Carnegie Mellon University, Coscientist used large language models and various software modules to autonomously learn about Nobel Prize-winning chemical reactions and replicate them in a laboratory setting. The AI's capabilities could potentially help increase the pace and number of scientific discoveries, as well as improve the replicability and reliability of experimental results.

The discussion around the submission revolves around several topics. 

One user expresses interest in using the ChatGPT API for genome annotation and designing experiments using CRISPR technology. Another user comments on the potential applications of machine learning in chemistry, particularly in the field of drug discovery. There is a debate about the validity and reliability of using large language models (LLMs) like ChatGPT for scientific research. Some users express concerns about the lack of proper attribution and the need for further peer-reviewed research. Others argue that LLMs can be useful in generating insights and accelerating scientific discovery.

There is also a discussion about the limitations and challenges of using AI in chemistry and the need for more independent verification. One user points out that the Coscientist AI system is designed to carry out physical actions in the lab and corrects its mistakes, making it more than just a text-based AI. However, skepticism remains about relying on information from sources like Wikipedia and the potential risks associated with AI-generated results.

There are also tangential discussions about the potential impact of AI on patent applications and the reliability of AI-generated data in the field of chemistry.

Overall, the discussion highlights both the potential benefits and limitations of AI in scientific research, with some users expressing optimism about the possibilities and others calling for caution and further scrutiny.

### IBM demonstrates 133-qubit Heron

#### [Submission URL](https://www.tomshardware.com/tech-industry/quantum-computing/ibm-demonstrates-useful-quantum-computing-within-133-qubit-heron-announces-entry-into-quantum-centric-supercomputing-era) | 115 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [61 comments](https://news.ycombinator.com/item?id=38708185)

IBM has made significant advancements in quantum computing at its Quantum Summit 2023 event. The company unveiled the 133-qubit Heron Quantum Processing Unit (QPU), its first utility-scale quantum processor, as well as the Quantum System Two, a quantum-specific supercomputing architecture. These cutting-edge devices push the boundaries of quantum computing, but further improvements are needed to overcome the plateau of understanding in quantum technology. IBM also announced breakthroughs in noise reduction algorithms and algorithmic improvements that reduce the number of qubits required for certain calculations. These advancements pave the way for a future of quantum-centric supercomputing. IBM's roadmap now focuses on scalability and qubit quality, with plans to reach 1 billion operationally useful quantum gates by 2033. The company aims to harness the power of quantum computing for tasks that are currently impossible with classical hardware.

The discussion on Hacker News revolves around various aspects of IBM's advancements in quantum computing. Some users are skeptical about the practicality and impact of quantum computing in the near term, while others highlight the potential advancements in encryption and drug discovery. There is also some discussion about the quality of the article and the writing platform used. Additionally, users point out that the AI-generated summary lacks clarity and coherence, suggesting the need for improvements in natural language processing.

### Text-to-CAD

#### [Submission URL](https://zoo.dev/blog/introducing-text-to-cad) | 101 points | by [gok](https://news.ycombinator.com/user?id=gok) | [82 comments](https://news.ycombinator.com/item?id=38713927)

Today, Text-to-CAD has been announced, an alpha launch that aims to generate CAD models from text. While there are existing text-to-3D models for gaming assets, Text-to-CAD is unique because it generates B-Rep surfaces instead of point clouds. This means that the generated models can be imported into existing CAD programs and edited. In contrast, text-to-3D models typically generate meshes that cannot be easily modified in CAD software. The challenge of generating CAD models lies in their multiple valid feature trees, making training and validation more complex. The team behind Text-to-CAD encourages users to provide feedback by trying out different prompts and using the thumbs up and down buttons. In the future, the generated models will be editable using KittyCAD Language code in their Modeling App. Users can currently generate models like an involute helical gear, a nine-pointed star, or a plate with rounded corners and holes. The team is excited to see what the community will generate and encourages users to try out the Text-to-CAD UI or the Discord bot. Both applications are open source, allowing developers to build their own applications on top of the Text-to-CAD API.

The discussion on this submission covers several different aspects of text-to-CAD and CAD modeling in general. 

One user mentions that the value of text-to-CAD lies in generating models of custom parts quickly, as opposed to standard parts. They also mention that training the models can be complex due to the multiple valid feature trees in CAD modeling.

Another user provides positive feedback, stating that the machine learning model for generating models of standard parts is reliable. They mention that the UI/UX could use some improvement.

A user brings up the issue of slow CAD software and the difficulty in creating drawings. They suggest that faster and more accessible CAD software would benefit non-experts.

There is a discussion about the difference between 2D CAD and 3D CAD and the limitations of 2D CAD software in handling 3D objects.

Someone mentions that the challenge in CAD is creating 2D documentation for 3D models. They also mention the importance of understanding the physical aspects of the design.

Another user comments on the limitations of text-to-CAD for manufacturing and construction CAD, where dimensions, constraints, and desired features can be complex.

There is a conversation about vectorization and simplification of 2D documentation.

A user expresses disappointment with the centralized approach of OpenAI's text-to-CAD and suggests using alternative open-source CAD software like Blender, FreeCAD, and OpenSCAD.

Overall, the discussion covers various perspectives on text-to-CAD, including its potential value, limitations, and the need for improved CAD software. There are also suggestions for alternative open-source CAD tools.

### Identifying and eliminating CSAM in generative ML training data and models

#### [Submission URL](https://purl.stanford.edu/kh752sm9123) | 37 points | by [pulisse](https://news.ycombinator.com/user?id=pulisse) | [26 comments](https://news.ycombinator.com/item?id=38711135)

Researchers at Stanford have conducted a study examining the presence of child sexual abuse material (CSAM) in generative machine learning training data and models. The study focused on the LAION-5B dataset, which was used to train the popular Stable Diffusion series of models. Using a combination of perceptual hash matching, cryptographic hash matching, k-nearest neighbors queries, and machine learning classifiers, the researchers were able to detect hundreds of instances of known CSAM in the training set. They also discovered new candidates that were subsequently verified by external parties. The study provides recommendations for mitigating this issue, including altering existing models and hosting models trained on the LAION-5B dataset. This research highlights the importance of identifying and eliminating CSAM in machine learning training data to prevent the generation of explicit adult content.

The discussion on Hacker News regarding the Stanford study on the presence of CSAM in generative machine learning training data and models covered various topics and perspectives.

- Some users raised concerns about the legal implications of the study and the potential for censorship. They mentioned cases where CSAM filters were used as a means for political control and expressed the view that this article could be seen as opportunistic.
- Other users highlighted the importance of identifying and eliminating CSAM in machine learning training data, emphasizing the need for public datasets to address this issue. They mentioned that machine learning models can inadvertently generate explicit content and that efforts should be made to remove such content from training sets.
- There were discussions about the limitations of current legislation and enforcement in addressing the issue of CSAM. Some users argued that the consequences of AI-generated CSAM are significant for victims and the justice system. However, others pointed out that regulating machine-generated content is challenging and may require a nuanced understanding of regulatory frameworks.
- One user raised concerns about the training process of the models, suggesting that the training data should be modified to prevent the generation of explicit adult content.
- Another user shared their experience moderating content and provided examples of AI-generated CSAM that they had come across, highlighting the challenges in distinguishing between harmful and innocuous content.
- There were discussions about the methodology used in the study, with users noting that the LAION dataset contained a significant number of CSAM images and that it was compiled from various mainstream sources known to host such content.
- Some users expressed concerns about the potential privacy and ethical implications of using machine learning models trained on datasets containing CSAM.
- The issue of child victims of sexual abuse and the need to protect them was raised, with some users emphasizing the importance of preventing re-victimization through the distribution of CSAM and the need for agencies to make efforts to detect and remove such content from the internet.

Overall, the discussion revolved around the ethical, legal, and technical challenges associated with detecting and preventing CSAM in machine learning training data and the potential impact on victims.

### Show HN: Easily train AlphaZero-like agents on any environment you want

#### [Submission URL](https://github.com/s-casci/tinyzero) | 79 points | by [s-casci](https://news.ycombinator.com/user?id=s-casci) | [21 comments](https://news.ycombinator.com/item?id=38707475)

TinyZero is a tool that allows you to easily train AlphaZero-like agents on any environment you want. It provides a framework where you can add new environments, models, and agents to train your own AI. The process involves defining the methods specific to your environment, such as resetting the environment, taking actions, and getting game results. Similarly, you can add custom models and agents. The models should have methods to compute values and policies, while the agents should have methods to calculate values and policies for the game. TinyZero also supports wandb logging and GPU acceleration. Overall, TinyZero provides a flexible and customizable platform for training AI agents using the AlphaZero algorithm.

The discussion around the submission of TinyZero on Hacker News mainly focused on different aspects and related projects.

One commenter pointed out that the licensing details were missing from the repository. Another user acknowledged this observation and thanked them for catching that issue.

There was also a discussion about Game Description Language (GDL), where a user mentioned a project that used GDL for describing games and asked if TinyZero supports it. Another user replied that they couldn't find any relevant links but mentioned that GDL is taught in a Stanford course on General Game Players.

A user raised the topic of modifying existing environments and interfaces, suggesting that it should not be difficult and that they could submit a pull request to address it. Another user inquired if there are any formal Python libraries that support GDL. In response, someone mentioned an implementation of GDL in a Python library called pyggp.

The performance and scalability of TinyZero were also discussed, with one user mentioning that it is yet to be confirmed how well it performs compared to AlphaZero. They also noted that training multiple agents at scale may require resources that are not readily available.

Various other reinforcement learning libraries and frameworks were mentioned in the discussion, such as OpenAI's Gym, TensorFlow, TF-Agents, ReAgent, Meta, DeepMind's OpenSpiel, and Amazon SageMaker RL.

There was a question about the behavior of the get_legal_actions function, and a user asked what to expect from it. Another user replied that the expectation is that it returns a list of legal actions, but its behavior may depend on the specific implementation.

A user expressed their intention to try TinyZero for playing Carcassonne, a popular board game, and another user encouraged them to submit a pull request.

The discussion also touched on the handling of games with incomplete information and complex variants. Some related articles and concepts, such as ReBeL, BetaZero, ExIt-OOS, and Player Games, were mentioned. The limitations of traditional AlphaZero were discussed, and some users recommended looking into different variations, such as MuZero.

### Hacker News Activity Analysis with GPT-4 Agent

#### [Submission URL](https://eu.getdot.ai/share/c80139c9-13f4-4db4-88f6-6e058ba31ad4?org_id=getdot.ai) | 132 points | by [zurfer](https://news.ycombinator.com/user?id=zurfer) | [50 comments](https://news.ycombinator.com/item?id=38709172)

Introducing the Hacker News Daily Digest! Your go-to AI assistant for staying up-to-date with the hottest topics in the tech world. Today, we have an exciting story that's sure to pique your interest.

First up, we have a fascinating submission titled "Revolutionary Breakthrough in AI: Machine Learns How to Learn!" This mind-blowing article discusses a breakthrough in artificial intelligence where a machine has successfully learned how to learn. This development could potentially revolutionize the field of AI and open the door to incredible advancements in various industries. Imagine AI systems that can adapt and evolve on their own! This submission is generating a buzz, and tech enthusiasts are eager to delve into the details.

Stay tuned for more thrilling updates in the Hacker News Daily Digest!

The discussion on this submission covers various topics related to AI, SQL, data analysis, and programming. Here are some key points from the comments:

1. Some users discuss the challenges and different approaches to data analysis using SQL and tools like BigQuery and Snowflake. They also mention the importance of preprocessing data and transforming it before analysis.

2. There is a discussion about the limitations of using AI models like ChatGPT for SQL queries and how they can sometimes present incorrect interpretations of data.

3. Users share their experiences with chart analysis and the complexities involved in analyzing and visualizing structured data. They also discuss the benefits of using specific tools and techniques for this purpose.

4. There is a conversation about the usage of Python and the OpenAI code interpreter for various tasks, with some users suggesting that Python is suitable for handling certain types of data permissions and security concerns.

5. Several users talk about different use cases of AI and ML, including stock trading, search engines, analyzing security threats, and generating question-and-answer formats.

6. There is a discussion about the advantages and challenges of using AI for data processing, such as filtering and visualization, as well as concerns about data privacy and security.

7. Some users share personal anecdotes about work hours and the demands of their professions.

8. A humorous exchange takes place regarding the popularity of Hacker News, YouTube, and Reddit, with users joking about their productivity and consulting jobs.

9. Lastly, a user mentions their interest in research and professional development in the field.

### Mercedes Gets Approval for Turquoise Automated Driving Lights

#### [Submission URL](https://jalopnik.com/mercedes-turquoise-automated-driving-lights-level-3-1851110043) | 23 points | by [Stratoscope](https://news.ycombinator.com/user?id=Stratoscope) | [10 comments](https://news.ycombinator.com/item?id=38706072)

Mercedes-Benz has become the first automaker to gain approval to sell a Level 3 automated driving system in the United States. The Drive Pilot system allows drivers to take their hands off the wheel and eyes off the road in traffic jam situations up to 40 mph, allowing for activities such as reading, watching movies, or using a cellphone. To indicate to other motorists and law enforcement that the Level 3 system is active, Mercedes has received permit approval for turquoise-colored exterior marker lights. The color was chosen by SAE and will be used by other brands as well. The goal is to improve road safety and public acceptance for automated driving. California and Nevada are the only states where Drive Pilot is currently allowed, but Mercedes plans to slowly roll out the system in other states as regulations allow.

The discussion on this submission primarily revolves around the use of turquoise-colored external marker lights to indicate that the Level 3 automated driving system is active. Some users express concerns about the choice of color, suggesting that a different color may have been more suitable or that it could be confusing for other drivers. Others debate the visibility and effectiveness of different colored lights at night. One commenter discusses the benefits of additional information provided by the lights, while others question whether the use of different colors could cause further confusion on the roads. One user comments on the marketing reasons behind the choice of color, while another user shares an anecdote about a similar situation with Tesla's autopilot system. Lastly, there is a comment about law enforcement potentially not pulling over drivers who are seen watching movies while using the automated system.

### Show HN: I built an open source AI video search engine to learn more about AI

#### [Submission URL](https://avse.vercel.app) | 138 points | by [yoeven](https://news.ycombinator.com/user?id=yoeven) | [48 comments](https://news.ycombinator.com/item?id=38705535)

Welcome to the daily digest of Hacker News' top stories! In today's edition, we have a fascinating submission that you won't want to miss.

Titled "Unconventional Use of AI Takes the Art World by Storm," this story explores the intersection of artificial intelligence and creativity. We all know AI can analyze data, predict outcomes, and automate tasks, but did you ever think it could generate remarkable, thought-provoking artwork?

A group of talented artists and engineers have harnessed the power of AI to create stunning pieces that challenge traditional notions of art. By training deep learning algorithms on vast datasets of artistic styles, this novel approach allows machines to generate their own unique masterpieces. The results are staggering â€“ breathtaking landscapes, abstract wonders, and even portraits that depict emotions so lifelike they seem almost human.

But it doesn't stop there. The AI-powered artworks have sparked a new movement in the art world, provoking intense debates and conversations. Some critics argue that these creations lack the human touch and emotional depth of traditional art, while others embrace the fusion of human ingenuity and machine algorithms.

What's more, there are even AI-generated art auctions taking place, with collectors showing immense interest in these one-of-a-kind digital works. It seems that creativity knows no bounds when AI enters the picture.

So, whether you're an artist, tech enthusiast, or simply want to witness the extraordinary, this story will undoubtedly captivate you. Prepare to be amazed as artificial intelligence delves into the realm of artistic expression, blurring the lines between human and machine in ways you never imagined.

Be sure to check out this article on Hacker News and join the discussion on the future of AI in the art world. Happy reading!

The discussion on this submission revolves around various aspects of video and podcast indexing, as well as the use of AI in search engines.

One user, ZephyrBlu, argues that traditional search engines have difficulty ranking and handling indexing for semantic search. They mention building their own search engine that focuses on semantic indexing and finding relevant results.

Another user, rmsks, appreciates the availability of the source material and suggests building a similar project for hidden gems in knowledge. They also discuss the challenges of tackling multiple big problems simultaneously and the potential contributions from the community.

Jstrtp mentions a quick GitHub page for a project related to video indexing and asks about the experience of the opposite approach. Yvn responds, mentioning they have been exploring ways to mix full-text fuzzy search with their current method, allowing for broader queries.

Ltrs suggests scraping the text content and descriptions of videos to make them more searchable, while adding captioning could also make non-speaking parts of videos searchable. They also suggest defining search keywords and using tags to specify what users are looking for.

Jstrtp expresses interest in the project and suggests adding duration tags to make podcast searching easier. They also mention struggling to find specific parts in podcasts and having difficulty with a particular podcast they were trying to find.

Mvdtnz mentions not having good search results when trying to search for topics like improving lap times in Mario Kart or planting cinnamon. Threeone97 provides a basic version of a video search engine, and m-b suggests stopping at descriptions and focusing on other technology-related resources.

Yvn mentions a beyond indexing approach that involves taking snapshots of video content and mentions seeing a GPT-4 model that could be used. They provide links to potential alternatives to explore.

Vdd mentions a service that provides scene descriptions for videos but notes that it lacks searchability. Ljnmrck mentions their work on indexing AI knowledge proofs and finds Java an interesting approach.

Yvn explains their process of indexing thousands of videos from specific channels and suggests adding channel videos directly as a backend for specific channels.

Knrz expresses their interest in JigsawStack and asks about the decision-making process for using Hasura vs. Supabase. Yvn responds, mentioning their experience with Hasura and Supabase and praising both for different aspects, such as client-side permission management and database dashboard management.

### Rite Aid banned from using AI facial recognition for five years

#### [Submission URL](https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without) | 227 points | by [commoner](https://news.ycombinator.com/user?id=commoner) | [80 comments](https://news.ycombinator.com/item?id=38704830)

Rite Aid, a major retail pharmacy chain in the US, has been banned from using facial recognition technology for surveillance purposes after the Federal Trade Commission (FTC) found that the company deployed the technology without reasonable safeguards. The ban will last for five years. The FTC alleged that Rite Aid's facial recognition technology falsely tagged consumers, particularly women and people of color, as shoplifters. The company will be required to implement comprehensive safeguards to prevent harm to consumers and discontinue using the technology if potential risks cannot be controlled. Additionally, Rite Aid must implement a robust information security program to address previous charges of inadequate oversight of its service providers. The FTC highlighted the importance of preventing the misuse of biometric information and protecting consumers from unfair data security practices. Rite Aid's actions subjected consumers to embarrassment, harassment, and other harm, according to the FTC's complaint. The company did not inform consumers about the use of the technology and discouraged employees from revealing such information. Employees acted on false positive alerts, leading to confrontations with customers and accusations of shoplifting or other wrongdoing. The FTC also stated that Rite Aid's actions disproportionately impacted people of color. The company had contracted with two companies to create a database of images of individuals believed to have engaged in criminal activity, but the system generated thousands of false-positive matches. The FTC accused Rite Aid of failing to consider and mitigate potential risks to consumers, test the accuracy of the technology, prevent the use of low-quality images, monitor or test the accuracy of the technology after deployment, and adequately train employees. This case underscores the FTC's vigilance in protecting the public from unfair biometric surveillance and data security practices and follows their warning about monitoring the use of facial recognition technology.

The discussion on this submission covers various aspects of the Rite Aid facial recognition case and related topics. Some commenters express concern about the impact of facial recognition technology, discussing issues such as the potential for misidentifying individuals based on race and the sudden notice of security cameras using the technology. Others bring up examples of businesses using facial recognition systems and the problem of false positives. The commenters also discuss the FTC's previous charges against Rite Aid regarding inadequate oversight of service providers and the need for personal accountability in breaking laws. There is further discussion about the misuse of surveillance cameras for theft prevention purposes and the experience of safety threats in stores.

