## AI Submissions for Wed Sep 27 2023 {{ 'date': '2023-09-27T17:10:34.705Z' }}

### Show HN: Carton – Run any ML model from any programming language

#### [Submission URL](https://carton.run) | 174 points | by [vpanyam](https://news.ycombinator.com/user?id=vpanyam) | [47 comments](https://news.ycombinator.com/item?id=37682286)

Carton is an open-source API that allows you to run any machine learning (ML) model from any programming language. It provides a single API for all frameworks, making it easy to work with models regardless of the language you're using.

The process starts by packing your model with Carton. This involves wrapping your model with some metadata and putting it in a zip file. Importantly, Carton doesn't modify the original model, avoiding error-prone conversion steps. You just need to specify the framework and the required version, and Carton takes care of the rest.

Once your model is packed, you can load it using Carton. The API reads the metadata included in the packed model to determine the appropriate "runner" to use. If needed, Carton automatically fetches the right runner. A runner is a component of Carton that knows how to run a model with a specific version of an ML framework.

With your model loaded, you can then run inference using Carton's framework-agnostic API. Your application calls into Carton, which in turn calls the underlying framework to execute the model. Carton is implemented in Rust with bindings to several languages, all using the same optimized core.

Carton has been designed with performance in mind. Most of its code is implemented in optimized async Rust, resulting in low overhead. Preliminary benchmarks show that the overhead per inference call is less than 100 microseconds. Furthermore, the Carton team is actively working on further optimizing the system with improved use of Shared Memory, which will bring overhead levels even lower for models with large inputs.

In terms of platform support, Carton currently works on x86_64 Linux and macOS, aarch64 Linux (e.g., Linux on AWS Graviton), aarch64 macOS (e.g., M1 and M2 Apple Silicon chips), and WebAssembly (though for now, only metadata access is supported, with WebGPU runners coming soon).

So why should you use Carton instead of directly using frameworks like Torch or TensorFlow? Carton decouples your inference code from specific frameworks, treating them as implementation details. This allows you to easily keep up with the cutting-edge developments in the ML field. Additionally, while ONNX converts models, Carton wraps them, using the underlying framework to execute the model. This makes it easy to use custom operations, TensorRT, and other framework-specific features without making changes. Carton aims to support ONNX models in the future, enabling even more use cases, such as running models in the browser with WebAssembly (WASM).

In summary, Carton provides a convenient and efficient way to run ML models from any programming language. Its framework-agnostic API, optimized performance, and support for multiple platforms make it a powerful tool for ML deployment and experimentation.

The discussion surrounding the submission on Hacker News covers various aspects of the Carton API. Here are some key points from the comments:

- Some users mentioned other tools and frameworks that can be used for running machine learning (ML) models, such as Docker, Nvidias Triton, TensorFlow Java support, and ONNX.
- There was a discussion about the benefits of using Carton over directly using frameworks like PyTorch or TensorFlow. Carton provides a framework-agnostic API, making it easier to keep up with developments in the ML field. It also allows the use of custom operations and framework-specific features without modification. It was noted that Carton aims to support ONNX models in the future.
- Users asked about platform support, with some expressing interest in Windows support. The current platforms supported by Carton include x86_64 Linux and macOS, aarch64 Linux, aarch64 macOS, and WebAssembly.
- The performance of Carton was discussed, with preliminary benchmarks showing low overhead per inference call. The Carton team is actively working on further optimizing the system.
- Some users raised questions about the use of zip files for packaging models, noting that other container formats like Docker or compressed files could be more suitable.
- There were discussions about the challenges of running ML models and the benefits of using containerization technologies.
- There was interest in the potential use of Carton for running ML models on GPUs, and the Carton team acknowledged the importance of GPU support.
- The idea of implementing Carton in different programming languages was mentioned, with Python and Rust being the most commonly discussed options.
- Some users expressed skepticism or questioned the novelty of the Carton API.

Overall, the discussion revolved around the capabilities, performance, platform support, and potential use cases of the Carton API, with users sharing their thoughts and asking questions about its features and advantages.

### ZipPy: Detect AI-generated text quickly via compression ratios

#### [Submission URL](https://github.com/thinkst/zippy) | 24 points | by [makeworld](https://news.ycombinator.com/user?id=makeworld) | [3 comments](https://news.ycombinator.com/item?id=37682872)

The ZipPy project by thinkst aims to detect AI-generated text using compression ratios. The idea is to measure the perplexity of a text by calculating the compression ratios using LZMA or zlib compression algorithms. The project explores the use of compression as an approximate method for detecting low-perplexity text, which could indicate AI-generated content. By comparing the compression ratios of a seed corpus of AI-generated text to that of the sample text, the project can determine if the sample text closely resembles AI-generated content.

1. One commenter, "bstwhz," believes that detecting single blob text generated by AI is practically impossible. They suggest that a practical approach would be to determine multiple blobs of text and compare them to AI-generated content. They give the example of AI-generated student training reports that may have similar topics or prompts, making it possible to detect statistical similarities. However, they point out that an AI detection system might not be effective in detecting cheating, as it may mistake multiple students rephrasing report content for cheating.
2. Another commenter, "kj," states that this is a clever solution but warns about Goodhart's Law. They argue that if this becomes a widely used measure, AI text generators will optimize their output to pass this specific test, making it less reliable.
3. "bArray" suggests that AI-generated student reports have the potential to completely fool human markers. They mention the example of copying paragraphs from different sources, resulting in an extensive and diverse report that can be generated in a short amount of time, making it challenging to investigate for plagiarism.

### First Impressions with GPT-4V(ision)

#### [Submission URL](https://blog.roboflow.com/gpt-4-vision/) | 361 points | by [zerojames](https://news.ycombinator.com/user?id=zerojames) | [316 comments](https://news.ycombinator.com/item?id=37673409)

OpenAI has announced the rollout of two new features for its GPT-4 model: the ability to ask questions about images and to use speech as an input to a query. This marks GPT-4's move into being a multimodal model, similar to Bing Chat and Google's Bard model. In a guide, two individuals share their first impressions with GPT-4V's image input feature and run a series of experiments to test its functionality. They test visual question answering, optical character recognition (OCR), and math OCR. Overall, GPT-4V performs well in understanding context and relationships in images, but it does make some mistakes. It also excels at OCR tasks, accurately identifying text in images. These experiments highlight the capabilities and limitations of GPT-4V.

The discussion on the submission revolves around the topic of AI interfaces and their potential to replace traditional user interfaces (UIs). Some users argue that AI interfaces have the potential to improve productivity and efficiency, especially for repetitive tasks. Others point out that AI interfaces may not always be the best option and that current UIs have their own benefits and advantages. There is also a discussion about the limitations of AI in controlling physical systems and the challenges of designing AI interfaces for complex tasks. Additionally, there are discussions about the importance of human skill in complementing AI and the need to specify goals rather than just specifying tasks for machines. Some users express concerns about the limitations and potential risks of AI interfaces.

### ChatGPT can now search the web in real time

#### [Submission URL](https://www.theverge.com/2023/9/27/23892781/openai-chatgpt-live-web-results-browse-with-bing) | 104 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [43 comments](https://news.ycombinator.com/item?id=37681047)

OpenAI's ChatGPT can now search the web in real-time using a feature called "Browse with Bing." This allows ChatGPT to provide up-to-date information from current and authoritative sources, with direct links to those sources. Initially available only to Plus and Enterprise subscribers, OpenAI plans to roll out the feature to all users soon. While other AI chatbots like Microsoft's Bing Chat and Google's Bard can already fetch live information from the web, this update improves ChatGPT's credibility and enables users to fact-check the provided answers. OpenAI had briefly introduced web browsing capabilities to its ChatGPT iOS app in June but had to withdraw it after users figured out how to bypass paywalls.

The discussion on Hacker News about OpenAI's ChatGPT being able to search the web in real-time using "Browse with Bing" had a mix of opinions and observations. 

One user pointed out that the feature was confusing because their subscription plan didn't show that they had access to it, and they assumed it might be related to the app version. Another user mentioned that Bing search results don't offer customization options or search constraints, leading to technical browsing errors and room for improvement.

Some users discussed the limitations of relying on web browsing for answers, as it may generate insecure or biased responses, but others argued that it could be beneficial for fact-checking. The idea of blocking certain sites or search results was also brought up, with suggestions for using tools like Chrome extensions to improve the search experience. 

There was a discussion about the impact of paywalls being bypassed and OpenAI disabling web browsing in its iOS app. One user mentioned the WebPilot plugin as an alternative for browsing the web within the ChatGPT browser. 

The conversation touched on the challenges of determining accurate and up-to-date information, the possibility of misleading search results, and the need for properly documenting cutoff dates. Some users also questioned OpenAI's marketing strategy and how they handle the launch of new features. 

Issues related to security were also raised, such as the potential vulnerabilities of web browsing, bypassing paywalls, and the interpretation of commands by ChatGPT. There were concerns about poisoning the model and the lack of security measures currently implemented by OpenAI.

Discussion also emerged around the limitations of web crawling and the challenges of integrating it into an AI model. Users debated the usefulness and reliability of the browsing feature, with some suggesting that it could fundamentally change the worldview of GPT models by exposing them to potentially inaccurate or biased information.

Overall, the discussion on Hacker News covered a range of opinions and concerns about OpenAI's web browsing feature in ChatGPT, with users discussing its benefits, limitations, and potential security implications.

### Workers AI: Serverless GPU-powered inference

#### [Submission URL](https://blog.cloudflare.com/workers-ai/) | 248 points | by [jgrahamc](https://news.ycombinator.com/user?id=jgrahamc) | [90 comments](https://news.ycombinator.com/item?id=37674097)

Cloudflare has launched Workers AI, an AI inference as a service platform that allows developers to run AI models with just a few lines of code. The platform runs on Cloudflare's global network of GPUs, providing developers with off-the-shelf models that can be easily deployed. Workers AI is designed to be accessible to all developers, working seamlessly with Cloudflare's existing offerings as well as being platform-agnostic. The initial release includes a curated set of popular, open-source models for tasks such as text generation, automatic speech recognition, translation, text classification, image classification, and embeddings. Cloudflare plans to expand the platform based on community feedback and has also announced a partnership with Hugging Face to offer a subset of their catalog directly within Workers AI. With Workers AI, developers can easily integrate AI capabilities into their applications, regardless of their preferred stack or framework. The platform aims to provide a seamless and frictionless developer experience, allowing developers to go from zero to production quickly and easily.

The discussion on Hacker News revolves around several key points regarding Cloudflare's Workers AI platform. 

One commenter highlights the potential benefits of serverless solutions for AI inference, noting that it could lead to faster turnaround times and reduced costs compared to persistent GPU instances. However, there are concerns raised about potential delays and compatibility issues with serverless solutions.

Another commenter brings up the compatibility of WebGPU, stating that it is not widely supported yet but has the potential to improve the user experience and reduce deployment costs.

There is also discussion about the practical implications of Cloudflare's pricing based on neuron context, with one commenter not fully understanding how pricing is determined based on character count and neuron quantities.

The conversation then shifts to the limitations of serverless functions and the potential challenges in using them for speech-to-text applications.

The topic of pre-loaded models and the ability to use one's own models is brought up, with one user suggesting that the ability to load custom models would make the platform more versatile.

There is also discussion about the pricing and potential cost savings of serverless AI inference, as well as the integration of Cloudflare's Workers AI platform with Hugging Face's models.

Other topics touched upon include the usage of GPUs for AI models, the relationship between neural time units and computational time units, and the importance of documentation in the development process.

Overall, the discussion highlights both the excitement and the questions surrounding Cloudflare's Workers AI platform, with users discussing various technical aspects and potential use cases.

### Show HN: Use ChatGPT with Apple Shortcuts

#### [Submission URL](https://meetcopilot.app/) | 54 points | by [zdaniel16](https://news.ycombinator.com/user?id=zdaniel16) | [45 comments](https://news.ycombinator.com/item?id=37671821)

Introducing COPILOT: Your Personal AI Assistant

COPILOT is here to revolutionize the way you use your Apple devices. With seamless integration into the Apple ecosystem, intelligent web browsing, and context-aware assistance, COPILOT ensures your device experience is smoother than ever.

Deep Ecosystem Integration

Activate COPILOT instantly from anywhere on your device, including Siri. With its smart context-aware processing, COPILOT understands exactly what you need and responds accordingly. Say goodbye to manual searching and let COPILOT take care of it for you.

Advanced Web Capabilities

Delegate your web searches to COPILOT and save time. It swiftly navigates through webpages and brings back accurate results, taking the hassle out of your online research. Let COPILOT do the heavy lifting while you focus on what matters most to you.

Optimize Your Interaction with AI

Upgrade your interactive journey with COPILOT and enjoy a host of additional features. Benefit from detailed progress updates, maintain smooth follow-up conversations, experience dynamic personas tailored to your needs, and effortlessly solve math calculations in natural language. COPILOT truly enhances your productivity.

Detailed Progress

Stay updated on every action that COPILOT performs and their associated costs. Transparency is key, and COPILOT ensures you have all the information you need at your fingertips.

Follow-Up Magic

Maintaining conversations with COPILOT is a breeze. Ask follow-up questions and enjoy smooth, uninterrupted dialogues. COPILOT provides a seamless experience by understanding the context and delivering accurate responses.

Dynamic Personalities

Need content written? Looking for expert developer advice? COPILOT understands. It can adopt specific roles tailored to your needs, fine-tuning its responses for each specific task. Enjoy a personalized experience that caters to your requirements.

Natural Language Math Calculations

Say goodbye to complex calculations. COPILOT understands and solves any math equations you throw at it, thanks to the integrated power of Wolfram Alpha. Just express your equations in natural language, and COPILOT will take care of the rest.

Update Reminders

COPILOT ensures you stay updated with the newest features regularly. Never miss out on the latest enhancements and improvements that make your device experience even better.

Ready to Unlock the Full Power of COPILOT?

COPILOT offers accessible plans to suit your preferences. Choose Basic Access for a cost-free start, or supercharge your workflow with the Ultimate Experience. The Ultimate Experience unlocks the full potential of COPILOT with a one-time purchase.

Basic Access - Engage with AI-led productivity for free.

Ultimate Experience - Unlock full AI capabilities with a lifetime purchase.

Premium Support, Constant Upgrades, and Support Development

Opting for the Ultimate Experience comes with added benefits. Enjoy real-time web search, swift webpage navigation, dynamic personalities, natural language calculations, premium support, constant upgrades, and non-recurring fees. Additionally, your purchase helps support the development of COPILOT, ensuring its continuous improvement.

Guidelines for API Integration

To use COPILOT, you'll need your OpenAI API key. You have control and privacy, as COPILOT operates on a Bring Your Own Key (BYOK) basis. Premium features require separate API keys from SerpAPI, ScraperAPI, and Wolfram Alpha LLM API. Free usage tiers from each should suffice for normal use.

COPILOT is set to redefine your device experience. Get ready to unlock its full power and make the most out of your Apple devices. Stay tuned for more updates and watch as COPILOT transforms your productivity.

The discussion on Hacker News revolves around the introduction of COPILOT, a personal AI assistant for Apple devices. One user mentions the convenience of using Apple Shortcuts exclusively to simplify the process and improve user experience. Another user highlights the integration of OpenAI ChatGPT in the COPILOT iOS app, emphasizing its usefulness and real-time web search capabilities.

The discussion also touches on the inclusion of Google search, web scraping, and additional features like iMessage integration and Siri support. Some users express concerns about the installation process and complexity of creating shortcuts. Others suggest possible improvements, such as integrating COPILOT with Apple Notes and addressing limitations in the software.

The conversation diversifies, with users discussing topics such as the name "Copilot," trademark issues, and the potential for legal controversy. Some users provide suggestions or links to related resources for further exploration, while others inquire about privacy and security measures implemented in COPILOT.

Overall, the discussion showcases a mix of excitement, curiosity, and constructive feedback regarding COPILOT and its potential applications within the Apple ecosystem.

### Be My Eyes’ AI assistant starts rolling out

#### [Submission URL](https://www.bemyeyes.com/blog/announcing-be-my-ai) | 261 points | by [hubraumhugo](https://news.ycombinator.com/user?id=hubraumhugo) | [150 comments](https://news.ycombinator.com/item?id=37673300)

Be My Eyes, the platform that connects volunteers with blind and low-vision users to assist with everyday tasks, is introducing its AI assistant, Be My AI. The AI assistant, powered by GPT-4, is now entering an open beta phase for iOS users and will be rolled out to hundreds of thousands of Be My Eyes users worldwide in the coming weeks. Users can access and use Be My AI by opening the Be My Eyes app and clicking on the 'Be My AI' tab to take a picture and receive a detailed description from the AI. Be My AI can also answer questions and provide additional information. However, if the AI can't answer a question, users can still connect with human volunteers. Be My AI is designed to provide quick visual assistance 24/7, making it useful for situations where users need a quick solution or prefer not to talk to another person. The AI can provide information in 29 languages and offers a new way for deaf-blind users to access information using a braille display. While Be My AI has various applications, it does not replace mobility aids like white canes or guide dogs for safe travel. The platform aims to make the world more accessible for people who are blind or have low vision, and the introduction of Be My AI is a significant step towards achieving that goal.

The discussion on this submission revolves around the introduction of Be My Eyes' AI assistant, Be My AI. Some commenters point out that while AI assistance can be helpful in certain situations, it should not replace human volunteers entirely. They argue that calling human volunteers multiple times a day can be bothersome and time-consuming. However, others express frustration with the idea of AI replacing human interaction and believe that calling human volunteers is a more satisfying experience. There is also a discussion about the potential limitations and risks of relying solely on AI for visual assistance, such as the inability to understand complex situations or perceive physical dangers. Some commenters mention the importance of responsible AI use, particularly in areas like scanning medications or reading instructions where safety issues could arise. Overall, the debate revolves around finding the right balance between AI assistance and human volunteers, taking into consideration the limitations and potential risks associated with AI.

### New AI experiences across our family of apps and devices

#### [Submission URL](https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/) | 41 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [17 comments](https://news.ycombinator.com/item?id=37678431)

Meta, formerly known as Facebook, has announced new AI features and tools across its platforms. Users will soon be able to generate customized AI stickers for their chats and stories, with the technology turning text prompts into unique stickers. Image editing features called Restyle and Backdrop will also be introduced on Instagram, allowing users to transform their images using AI-generated visual styles or change the background. In addition, Meta AI, an advanced conversational assistant, will be available on WhatsApp, Messenger, and Instagram, as well as on Ray-Ban Meta smart glasses and Quest 3. It can provide real-time information and generate images based on text prompts. Meta is also introducing 28 more AIs with unique personalities that users can interact with on its platforms. These AI features aim to enhance connections and enable new forms of creativity and expression. Safeguards have been implemented to address the challenges posed by these AI experiences.

The discussion surrounding Meta's new AI features and tools on Hacker News has covered various perspectives and concerns.

- One user commented that the customizable AI stickers and AI-generated image editing features seem like fun additions, but they suspect that the generated stickers will largely be indistinguishable from manually created ones, and there may be a risk of AI-generated stickers flooding conversations.

- Another user expressed skepticism about the idea of creating AI personalities for user interaction, noting that licensed personalities like Kendall Jenner and Tom Brady wouldn't consent to their AI representations.

- A discussion arose about the uncertain nature of AI development and its potential risks. One user mentioned an image model that generates false images, while another user brought up the possibility of creating AI characters resembling Paris Hilton for detective play, suggesting potential misuse.

- The conversation shifted towards the need for proper regulation and ethical considerations in AI development. One user mentioned the importance of addressing short-term AI developments and the success of controlling hyper-scale AI agents. They believed that startups and competitors could have a say in shaping regulations.

- Some users discussed Meta's AI efforts in comparison to other companies like Google and the potential for interesting collaborations and models.

- There were concerns raised about the risks of AI-generated messages being inaccurate or inappropriate. One user sarcastically expressed their fear of AI leading to the start of SkyNet and AI-generated stickers dominating search results. They also mentioned concerns about AI accounts on Facebook and the need for better protection against inappropriate content.

- The discussion touched on the responsibility of platforms like Facebook in handling AI and ensuring safeguards to protect users, particularly children. One user suggested that Facebook's moderation efforts could be seen as wasteful and called for better measures to address the issue.

Overall, the discussion covered a range of perspectives, from excitement about new creative tools to concerns about AI misuse and the need for responsible development and regulation.

### We try out the first legal level 3 automated driving system in the US

#### [Submission URL](https://arstechnica.com/cars/2023/09/mercedes-benzs-level-3-autonomous-driving-system-takes-over-in-heavy-traffic/) | 81 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [66 comments](https://news.ycombinator.com/item?id=37674640)

Mercedes-Benz is set to release its Drive Pilot system, which will be available on the 2024 S-Class and EQS sedans. It is the first level 3 automated driving system approved for use in the US, but initially it will only be available and active in California and Nevada. Drive Pilot allows for hands-free highway driving and also allows the driver to take their eyes off the road. There are, however, several conditions that need to be met before the system can be activated, including a speed limit of 40 mph, a vehicle in front to follow, detectable lane markings, and a pre-mapped route. The system is designed for heavy stop-and-go traffic but not for free-flowing highways. Mercedes-Benz plans to increase the speed limit in the future.

The discussion on this submission revolves around the liability and insurance implications of Mercedes-Benz's Drive Pilot system. Some users express concern about who would be responsible in the event of an accident and whether insurance companies would cover the damages. There are also discussions about the regular insurance coverage for self-driving vehicles and the potential for lower insurance costs. Some users mention Volvo's responsibility claims in relation to their autonomous driving systems. Another topic of discussion is the limitations of Drive Pilot, such as its inability to handle sharp corners and low-quality lane markings. There are also mentions of the target market for this system, with some users suggesting that wealthy individuals who enjoy driving would be more interested in purchasing luxury vehicles like the S-Class. The impact on traffic congestion is also brought up, mentioning that users who frequently encounter highway congestion may not be the target market for this system. The discussion touches on various factors such as climate and local congestion conditions that may affect the effectiveness of Drive Pilot.

### My Books Were Used to Train Meta’s Generative AI. Good

#### [Submission URL](https://www.theatlantic.com/technology/archive/2023/09/books3-database-meta-training-ai/675461/) | 28 points | by [sherilm](https://news.ycombinator.com/user?id=sherilm) | [10 comments](https://news.ycombinator.com/item?id=37679514)

The Atlantic recently released a searchable database of tens of thousands of books that were used without permission to train Meta's AI language model. This revelation has sparked outrage among well-known authors who were unaware that their work was being used. However, author Ian Bogost found himself surprisingly unaffected when he discovered that three of his books appeared in the database. He questions whether the outrage is justified and argues that authors should embrace the unpredictable ways in which their work can be used. While Meta's behavior may be legally questionable, the concept of permission in the realm of art is complex. Bogost suggests that internet culture's emphasis on permission may limit the potential interpretations and uses of creative works. Furthermore, the release of the Books3 database was intended to empower grassroots AI projects, giving ordinary people more control over the future of technology. The situation raises larger questions about the nature of theft, innovation, and liberation in the internet age.

The discussions surrounding the submission revolve around various perspectives on the use of books without permission to train Meta's AI language model.

- User "sklld" highlights that the Atlantic missed some recent stories focusing on specific cases and generalizations, indicating that the database had a limited scope.
- User "DistractionRect" adds that the archived version of the website contains some funky stuff, but DNS changes would need to be made to respond to requests.
- User "jstnclft" points out that the provided link is not working for them and mentions their location in Australia as a potential reason for the difference.
- User "frjzz" argues that books should be licensed for what they are, suggesting that authors should be compensated for their work.
- User "wffltwr" believes that AI creators should respect the concept of Commons, emphasizing the exchange of ideas and knowledge. They mention examples like billboards, handballs, and novels in public libraries as knowledge shared without individual permission.
- User "JambalayaJim" argues that models are not treated legally the same way humans are and that licensing is necessary for derived model outputs. They dismiss the idea of theft and emphasize the importance of paying for content when necessary.
- User "frjzz" responds by pointing out that stop signs are not copyrightable and that not all music requires payment to listen to it. They also challenge the assumptions made about inherent rights of AI models.
- User "rxpp" agrees with the previous comment and suggests that paying for content is a way to invest more in communities that create it.

Overall, the discussion encompasses various viewpoints on the use of book content for AI training and the complexities surrounding permission, compensation, and the nature of AI models in relation to human creativity.

