## AI Submissions for Thu Mar 07 2024 {{ 'date': '2024-03-07T17:10:30.669Z' }}

### Fine tune a 70B language model at home

#### [Submission URL](https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html) | 557 points | by [jph00](https://news.ycombinator.com/user?id=jph00) | [136 comments](https://news.ycombinator.com/item?id=39635483)

Today, Answer.AI has launched an innovative open-source system that enables training a 70 billion parameter language model using standard gaming GPUs on a regular desktop computer. Collaborating with experts like Tim Dettmers and Hugging Face, this system combines FSDP and QLoRA technologies, making it easier for the community to develop better models. This breakthrough will empower smaller labs to access and create massive AI models, supporting Answer.AI's mission to democratize AI development. The project aims to leverage cost-effective gaming GPUs, which offer comparable performance to expensive data center GPUs, but with limited memory capacity. By addressing this challenge, Answer.AI seeks to revolutionize large model training and expand AI accessibility for all.

The discussion on the submission revolves around technical aspects related to the new open-source system introduced by Answer.AI for training a 70 billion parameter language model. Some users discuss the batch sizes, training methods, and memory constraints, highlighting the efficiency and cost-effectiveness of using gaming GPUs for large model training. Additionally, there are mentions of benchmarking results, scalability issues, and the implications of democratizing access to AI models. There is also a debate regarding the potential biases and discrimination in AI research, as well as comparisons between different GPUs and their memory capabilities for training large models. Other users bring up the NeurIPS Efficiency Challenge and the technical specifications of GPUs like M1 and RTX 4090 for machine learning tasks. Overall, the conversation delves into a mix of technical details, performance comparisons, ethical considerations, and implications of the new system on AI research and accessibility.

### New breakthrough brings matrix multiplication closer to ideal

#### [Submission URL](https://www.quantamagazine.org/new-breakthrough-brings-matrix-multiplication-closer-to-ideal-20240307/) | 147 points | by [bertman](https://news.ycombinator.com/user?id=bertman) | [26 comments](https://news.ycombinator.com/item?id=39630759)

In a recent breakthrough, computer scientists have devised a new method to speed up matrix multiplication, a fundamental computational operation used in various algorithms. This advancement, presented at the Foundations of Computer Science conference, is the result of innovative techniques by researchers Ran Duan, Renfei Zhou, and Hongxun Wu. Despite the relatively small improvement, it is considered conceptually significant in the field. With potential untapped for further enhancements, a second paper published in January extends the initial progress, marking a substantial leap forward in matrix multiplication efficiency, lauded as the most significant improvement in over a decade by experts like William Kuszmaul from Harvard University. This breakthrough holds promise for enhancing computational speeds in a range of applications and could lead to substantial time and cost savings.

The discussion on Hacker News regarding the submission about the new method to speed up matrix multiplication involves various technical details and insights from commenters. Some points mentioned include analysis of time complexity, theoretical lower bounds, and the importance of finding practical algorithms for matrix multiplication. There is also a comparison between specific algorithms and the implications of advancements in matrix multiplication efficiency for computational tasks. Commenters also discuss the potential impact of these advancements on hardware such as GPUs and TPUs, as well as the broader implications for machine learning and other applications. Additionally, one commenter brings up the significance of Moore's Law in relation to the advancements in matrix multiplication.

### How do computers calculate sine?

#### [Submission URL](https://androidcalculator.com/how-do-calculators-compute-sine/) | 191 points | by [vegesm](https://news.ycombinator.com/user?id=vegesm) | [154 comments](https://news.ycombinator.com/item?id=39633172)

The blog post delves into how calculators compute the sine function, a fundamental trigonometric function used across different disciplines. Initially, a simple Taylor series approximation is discussed, highlighting its limitations near $\pi/2$. The post then moves on to a more sophisticated method used by Intel processors, involving steps like reduction, approximation, and reconstruction to calculate sine efficiently. The Intel method includes precomputing values and using minimax approximation to minimize errors, resulting in a much more accurate calculation compared to basic approximations like the Taylor series. By exploring these techniques, the post showcases the complex yet precise methods employed by calculators to compute sine accurately and efficiently.

The discussion on this submission covers a wide range of topics related to trigonometry, lookup tables, precalculated values, and historical implementations of sine functions. One theme in the discussion focuses on the use of precalculated trigonometric lookup tables in the context of older hardware and video game consoles like the SNES and DOOM. Comments mention how games targeting pre-Pentium PCs used these tables for faster trigonometric calculations, while others reflect on the optimization techniques used in old gaming hardware. 

Regarding precalculated tables, there are mentions of engineers in the 1950s and the computational challenges they faced, the implementation of functions in BASIC for generating values, and a link to Abramowitz Stegun's Handbook of Mathematical Functions. The conversation also delves into the significance of trigonometric functions in CPU architectures, programming languages, and floating-point precision considerations. Further discussions touch on the complexities of rounding transcendental functions correctly, implementations in modern hardware, and the historical evolution of floating-point instructions like x87 and AVX.

Overall, the discussion sheds light on the historical, technical, and practical aspects of calculating trigonometric functions and the different approaches taken across various platforms and time periods.

### Social learning: Collaborative learning with large language models

#### [Submission URL](https://blog.research.google/2024/03/social-learning-collaborative-learning.html?m=1) | 74 points | by [t3nary](https://news.ycombinator.com/user?id=t3nary) | [12 comments](https://news.ycombinator.com/item?id=39633580)

The research on "Social learning: Collaborative learning with large language models" explores the idea of large language models (LLMs) learning from each other in a manner similar to how people learn in social settings. By sharing knowledge through natural language in a privacy-aware manner, these models can collaborate and improve each otherâ€™s performance. The study outlines a framework for social learning where LLMs act as both teachers and students, exchanging information without sharing private data. 

The paper evaluates the effectiveness of this framework on tasks like spam detection, math problem-solving, and question-answering. It introduces the concept of using synthetic examples to teach students, addressing privacy concerns while maintaining performance. By generating new examples that mimic the original data, the models can learn effectively without compromising privacy. The experiments demonstrate that sharing synthetic examples through social learning can yield comparable results to using real data, with only minor discrepancies in certain tasks like spam detection.

Overall, the research offers insights into leveraging social learning mechanisms among language models to enhance their performance and expand their capabilities in a collaborative learning environment.

- **dr_kiszonka** shared a link to a Wikipedia page related to the phrase "The blind leading the blind."
- **mz** discussed the use of synthetic examples, mentioning that they can help to teach students without containing personally identifiable information (PII) or data like social security numbers. They emphasized the importance of privacy in these models, highlighting that the paper might overlook smaller students or bigger privacy issues.
- **vsrg** delved into the complexity of social learning with large language models, focusing on the capabilities and challenges of these models in tasks like task-solving and providing feedback. They preferred a method they specified as "Machine Study Social Learning" to legitimate processes involving copyrighted content to aid in development, ensuring that models access original content safely.
- **falcor84** found the work interesting, particularly appreciating the goal-focused approach to storytelling in the research.
  - **xnx** expressed frustration with a Google extension and its ads, echoing a dislike for the tool's user interface.
  - **wordpad25** discussed readability issues and the struggle of trying to engage with a certain topic despite minimal context.
  - **gs17** shared that a video they watched played a role in enhancing their reading experience, mentioning a middle animation in a GIF.
- **llmzr** made a comment about following the scenario of writing conclusions on a particular book that involves modifying definitions slightly to help students understand the material. They described the process of copying as akin to singing a song back.
- **ctn** discussed the concept of social learning as extending beyond basic model distillation, touching on how it transcends limited processing power, training data exposure, and individual models by allowing multidimensional transfer.
- **v4dok** wondered about the practical implications of a teacher model in this context.
  - **btvd** related the discussion to generative adversarial networks (GANs) nested within teacher-learner structures, highlighting the importance of realistic training data and vulnerabilities in current models when exploring the ultimate goal of creating synthetic content.
- **mdmsmrt** shared their thoughts on large-scale collaborative efforts in Google's machine learning sphere, noting a decline in the quality of collaborative check-ins.

### Jetbrains unbundles AI Assistant and is now available as a separate plugin

#### [Submission URL](https://blog.jetbrains.com/idea/2024/03/intellij-idea-2024-1-beta/) | 57 points | by [adl](https://news.ycombinator.com/user?id=adl) | [22 comments](https://news.ycombinator.com/item?id=39636060)

In the latest news from the IntelliJ IDEA Blog, the much-anticipated release of IntelliJ IDEA 2024.1 Beta by JetBrains has arrived, packed with a host of new features to level up your development workflows. From enhanced support for Java 22 functionalities to a revamped Terminal tool window, IntelliJ IDEA continues to innovate. The update also includes features like full line code completion, conditional statements coverage, in-editor code reviews, and improved support for GitHub Actions.

Furthermore, the team has introduced improvements in various areas such as the Java Revamped Detected Conflicts dialog, renaming refactoring inlay hint, and the propagation of the official Kotlin code style to all projects. Additionally, static imports are now preserved on copy-pasting, making code management more efficient for developers. 

In the realm of frameworks and technologies, IntelliJ IDEA now offers enhanced support for Terraform, catering to developers, site reliability engineers (SREs), and DevOps professionals. With features like suggestion to run `terraform init`, support for third-party providers from the Terraform Registry, and Terraform template language (tftpl) support, IntelliJ IDEA simplifies infrastructure as code development for its users.

And lastly, with the release of IntelliJ IDEA 2024.1, developers can benefit from support for Maven Shade Plugin renaming workflow and project Maven repositories in the Maven tool window, making Maven project management a smoother experience. These enhancements, along with many others, make IntelliJ IDEA a leading choice for Java and Kotlin developers looking to boost their productivity.

- **dnmcrnld & drts**: The discussion revolves around JetBrains' restrictions on AI companies using their tools. While one user expresses trust in JetBrains' expertise and innovation, another doubts the value of the limitations imposed on AI companies.
- **dl, thegrim000 & flmpcks**: The conversation starts with an inquiry about the availability of the AI Assistant in the IntelliJ IDEA 2024.1 Beta, leading to discussions on complaints about licensing systems, with one user explaining how licensing works and another comparing it to other software companies like Apple and Blackmagic.
- **PeterStuer & dl**: A user appreciates a direct link to pertinent information related to the IntelliJ IDEA 2024.1 Beta release, while another expresses gratitude for the submission and suggests it might have been removed by the moderators.
- **sparrowInHand & hppytgr**: Users comment on customer visits to tech companies and the hype surrounding new product releases, indicating a potential gap between expectations and reality.
- **0xy & throwaway5959**: A user shares frustrations with trying the AI Assistant feature in the Beta version, encountering issues with server requests and slow processing, while another expresses cancellation of their JetBrains subscription and dissatisfaction with the handling of feedback on AI suggestions.
- **mistrial9 & MrDresden**: Discussion shifts to Ubuntu Linux and canonical snap packages, with users noting issues with removing snap components and expressing gratitude for insights on Jetbrains software downloads.
- **lnxln & Skhala**: Users discuss removing snap packages on Ubuntu and the success of installing Jetbrains Toolbox, with one user sharing a GitHub page for further information on packaging and mention of no problems with Toolbox on a Debian system.

### Neural Chess

#### [Submission URL](https://pvdz.ee/weblog/450) | 36 points | by [fagnerbrack](https://news.ycombinator.com/user?id=fagnerbrack) | [11 comments](https://news.ycombinator.com/item?id=39632332)

On January 21, 2024, an AI enthusiast shared their journey of delving into neural networks to train a chess-playing AI. Inspired by a video on how AI played Pokemon through reinforcement learning, they embarked on the challenge of codifying chess rules, realizing its complexity, especially in checking for threats like being in check. Despite contemplating brute-forcing with Math.random(), they opted for the neural network approach for the thrill.

They developed a chess engine called Yacge and began training the neural network part. Explaining neural networks as interconnected nodes with activation values and weights, they emphasized the challenging nature of training, including adjusting weights based on expected outcomes. The complexity involves factors like bias, training speed, hidden layer sizes, and learning strategies, requiring meticulous optimization.

Modeling was crucial in converting problems into normalized floating point values for neural network inputs and interpreting outputs. They experimented with different models for the chess network, leveraging Yacge's bitboard representation to feed the network with game status inputs. With bitboards representing black and white pieces, along with piece types, bitwise operations unveiled the game state.

In their pursuit of teaching AI to play chess, this enthusiast navigated the intricacies of neural networks, striving to create an efficient model for the network to learn and make strategic moves in the game.

The discussion on the submission delves into various aspects of the AI enthusiast's journey into training a chess-playing AI using neural networks. 

- **xnsh** expressed disappointment in the attempt to create a correct chess network architecture through reinforcement learning, highlighting the complexity of chess programming and machine learning. They suggested exploring established references like Leela Maia or Alpha Zero for better results.
- **Imnimo** shared their experience with a neural network using a single hidden layer of 50 neurons for a project, emphasizing the benefits of investing time in finding a reasonable network architecture.
- **gwrn** discussed their skepticism about the feasibility of utilizing neural networks for creating a strong chess-playing AI, pointing out previous discussions and references including GPT-2 and discussions on chess-playing algorithms beyond hobbyist or research levels.
- **snsw** introduced the concept of introducing randomization to prevent repeated moves in the chess-playing AI.
- **rnx** critiqued a broken video link and discussed the concept of Novelty Search, a genetic algorithm approach that focuses on exploring the search space to discover new behaviors instead of just maximizing rewards. They also touched upon experimenting with AI in the context of graphics cards and AMD vs. Nvidia comparisons.

Overall, the comments provided a mix of feedback, skepticism, suggestions, and additional insights into the complexity and challenges of training AI for chess playing using neural networks.

### Can AI Solve Science?

#### [Submission URL](https://writings.stephenwolfram.com/2024/03/can-ai-solve-science/) | 20 points | by [headalgorithm](https://news.ycombinator.com/user?id=headalgorithm) | [6 comments](https://news.ycombinator.com/item?id=39626427)

In a recent article on Hacker News, the topic discussed was whether AI will eventually be able to do everything, especially in the realm of science. There is a growing belief that AI could potentially solve all scientific questions, but the reality is more complex. While AI can greatly aid scientific progress, there are inherent limitations to what it can achieve.

The article delves into the transformative impact of AI on science, considering AI as a tool for accessing existing methods or potentially offering something fundamentally new. The discussion focuses on the role of machine learning, particularly neural networks trained on vast datasets, in enhancing scientific research. One key challenge highlighted is the concept of computational irreducibility, where even with a complete set of rules governing a system, predicting its behavior can be extremely complex. This notion underscores the limitations of AI in fully comprehending and predicting the outcomes of complex systems, as it would require a level of computational power beyond current capabilities.

The article explores different scientific workflows, from prediction to explanation and creation, and examines how AI can contribute to these processes. It also touches on the theoretical and philosophical aspects of AI's potential in advancing science, emphasizing the need to balance expectations with the inherent constraints of computational systems. Overall, while AI holds immense promise in augmenting scientific endeavors, the article emphasizes that it is not a one-size-fits-all solution to unlocking the mysteries of the universe. By exploring the boundaries of AI's capabilities within the scientific realm, we gain a deeper understanding of its potential contributions and limitations.

- **jbrkr** pointed out that the article likely featured self-generated writing using GPT-3 and discussed the abstract nature of thinking in applying Large Language Models and Neural Networks to problems. They highlighted the lack of a name for a type of thinking invented by GPT-3 and made comparisons to computational irreducibility and chaos theory in mathematical spaces. They referenced Terence Tao discussing the limitations of Large Language Models in mathematics and how they relate to computational irreducibility.
- **llmzr** commented that the article focused on a common aspect of machine learning and AI techniques, emphasizing that they often provide approximately 80% of the answer but struggle with precision and correctness.
- **kylbnzl** humorously noted the length of the article at 16,000 words and requested a summary generated by AI.
- **nmr** mentioned solving natural language processing challenges.
- **qrl** found the paragraph structure impressive in predicting the next word.
- **quantum_state** commented simply with "answer bias."
- **JohnClark1337** indicated approval with a simple "dd."

### US govt announces arrest of ex Google engineer for alleged AI trade secret theft

#### [Submission URL](https://arstechnica.com/tech-policy/2024/03/former-google-engineer-arrested-for-alleged-theft-of-ai-trade-secrets-for-chinese-firms/) | 37 points | by [notamy](https://news.ycombinator.com/user?id=notamy) | [10 comments](https://news.ycombinator.com/item?id=39631582)

Former Google software engineer Linwei Ding was arrested on Wednesday in Newark, California, accused of stealing AI trade secrets from the company. Ding, a Chinese national, allegedly uploaded confidential information about Google's data centers to a personal Google Cloud account. He was offered a high-ranking position at a Chinese tech company using AI technology and founded his own startup without disclosing these affiliations to Google. The FBI seized over 500 stolen files from Ding's devices, leading to four counts of federal trade secret theft. Google commended the FBI for their help in protecting their information. Ding faces up to 10 years in prison for each count of theft.

- PeterCorless points out that Ding failed to disclose his travels or participation in investor meetings in China to Google, and alleges that Ding meticulously scanned internal documents and pretended to be working for Google from an office in China, benefiting a potential competitor.  
- JumpCrisscross suggests that Ding might have been involved in foreign espionage.  
- ChrisArchitect mentions that this story has been discussed before with links to previous discussions on Hacker News.  
- bdjsqcwk brings up the stereotype of Chinese individuals being linked to espionage and references a chemist who forgot her name after working for a company where she noticed suspicious activities involving trade secrets in China.
- bqnn discusses China's involvement in state-sponsored programs dedicated to stealing intellectual property and shares information about Chinese talents planning to work on IP theft projects.  
- spry-bsws references Shannon You11, a renowned chemist who uncovered similar suspicious activities, providing a link to an article about her sentencing.  
- ntmy mentions the original title of the article about the arrest of the former Google engineer for allegedly stealing AI trade secrets.  
- nm shares a link to another discussion thread on Hacker News related to the topic.  
- PeterCorless shares a link to a Bleeping Computer article about the arrest of the former Google engineer.  
- mdmsmrt expresses gratitude towards Ars Technica for their coverage of the privacy concerns related to the case.

### The Pile is a 825 GiB diverse, open-source language modelling data set (2020)

#### [Submission URL](https://pile.eleuther.ai/) | 321 points | by [bilsbie](https://news.ycombinator.com/user?id=bilsbie) | [231 comments](https://news.ycombinator.com/item?id=39631516)

Today on Hacker News, the hot topic is "The Pile: An 825 GiB Diverse Language Modelling Dataset" that has the tech community buzzing with excitement. This open-source gem combines 22 top-notch datasets and is being hailed as a fantastic training set for large models, enhancing cross-domain knowledge and generalization capabilities. The Pile is not just any dataset; it's a game-changer, proving its mettle by showing significant improvements on Pile BPB, a benchmark that tests a model's understanding across various domains like books, GitHub repositories, chat logs, and more. It's not just a training set; it's a benchmark that measures a model's world knowledge and reasoning skills. So, if you're developing a model or evaluating one, utilizing The Pile could be a game-changing move. With its jsonlines format and zstandard compression, it's a comprehensive resource waiting to be tapped. And remember, if you dive into The Pile, give credit where it's due!

The discussion about "The Pile: An 825 GiB Diverse Language Modelling Dataset" on Hacker News covers a range of topics related to copyright, fair use, and processing linguistic models. Here are the key points:
1. **Copyright Infringement:** Users address concerns about copyright issues related to The Pile dataset, discussing whether it contains copyrighted works and the implications of using it without permission from the copyright holder.
2. **Fair Use Doctrine:** The conversation touches upon the Fair Use doctrine and its application in the context of processing linguistic models, pointing out factors such as purpose, nature of the copyrighted work, amount used, and effect on the market value of the work.
3. **AI and Copyright:** There is a debate about whether AI models can reproduce original works without infringing on copyright laws, with discussions on the ethical implications of reproducing content and the distinction between human and AI creativity.
4. **Ethics of Style Transfer:** The conversation delves into the ethics of style transfer in AI models, particularly in the context of reproducing artistic styles and potential copyright violations.
5. **Data Compression:** Users discuss the practical aspects of data compression in linguistic modeling, debating the feasibility and limitations of compressing text data effectively.
6. **Legal Considerations:** The legal implications of distributing copyrighted content and the importance of obtaining proper permissions are highlighted, emphasizing the responsibility of dataset providers to respect copyright laws.

Overall, the discussion highlights the complex intersection of AI, copyright laws, ethics, and data processing techniques in the context of datasets like The Pile.

### Inflection-2.5: meet the best personal AI

#### [Submission URL](https://inflection.ai/inflection-2-5) | 68 points | by [swyx](https://news.ycombinator.com/user?id=swyx) | [75 comments](https://news.ycombinator.com/item?id=39635950)

Inflection unveils Inflection-2.5, the world's best personal AI, with enhanced IQ capabilities alongside its signature EQ traits. This upgrade competes with leading LLMs like GPT-4 and Gemini while being more efficient in training. Users are already enjoying Pi's new features, engaging in diverse topics, and experiencing improved performance, especially in STEM areas. With over a million daily users and four billion exchanged messages, Pi's popularity is soaring. Through technical benchmarks and industry comparisons, Inflection-2.5 demonstrates remarkable advancements, particularly in math and coding tasks. The personal AI continues to offer a unique, empathetic experience while pushing the boundaries of technological innovation.

The discussion on Hacker News regarding the submission about Inflection-2.5 unveiling the world's best personal AI with enhanced IQ capabilities includes various topics. 

1. LeoPanthera mentions concerns about prohibited sexually explicit content, inquiring about the design of LLMs and expressing interest in AI designed for conversations without explicit content. 
2. Discussions on open-source models and restrictions are shared by users like lphbttsy and numpad0, with mentions of Dolphin and intrinsic ethics restrictions.
3. Der_Einzige introduces Mistral 7B model, prompting discussions on local models and their alignment, with users sharing insights and cautioning about inappropriate content. 
4. A flagged user expresses skepticism about Gab AI and its validity, to which there are responses discussing the nature of Gab Media and differing perspectives on the platform. 
5. Various users engage in a conversation about AI ethics, personal information research, and development interests, including opinions on AI competitive technologies and reverse engineering attempts. 
6. A user shares a poetic piece about AI, sparking diverse comments on Gemini, GPT-4, and Claude-3 capabilities in creative writing tests. 
7. Discussions range from AI performance testing, personal AI interfaces, to the nature of AI conversations over particular interests and engagement levels. 

Overall, the discussion covers a wide array of topics related to AI technologies, ethical considerations, and user experiences with different AI models and platforms.

