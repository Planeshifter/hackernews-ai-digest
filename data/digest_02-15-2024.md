## AI Submissions for Thu Feb 15 2024 {{ 'date': '2024-02-15T17:11:27.177Z' }}

### Sora: Creating video from text

#### [Submission URL](https://openai.com/sora) | 3363 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [1996 comments](https://news.ycombinator.com/item?id=39386156)

Sora, an AI model developed by researchers, has the ability to create realistic and imaginative video scenes based on text instructions. The model can generate videos up to a minute long, while maintaining visual quality and adhering to the user's prompt. The examples provided showcase Sora's capabilities, including scenes of a stylish woman walking down a Tokyo street, giant wooly mammoths in a snowy meadow, a movie trailer featuring a space man, waves crashing against cliffs in Big Sur, a monster kneeling beside a melting candle, a papercraft world of a coral reef, a close-up shot of a Victoria crowned pigeon, and a photorealistic closeup video of pirate ships battling in a cup of coffee. Sora's technology aims to teach AI to understand and simulate real-world interactions, with the goal of helping people solve problems that require physical interaction.

The discussion surrounding the submission "Sora: An AI Model for Video Scene Generation" on Hacker News covers a range of topics. 
One commenter points out that the AI model's ability to generate creative scenes raises concerns about the loss of creativity in humans who are forced to perform mundane tasks. Another commenter argues that creative humans should be given credit for their work, just like famous artists throughout history were not required to acknowledge their inspirations. However, the original commenter disagrees, stating that acknowledging influences and inspirations is essential, as it prevents theft and respects the original creators.
The discussion then delves into the topic of whether AI can truly generate original work without being influenced by humans. Some commenters argue that AI models like Sora are capable of creativity and can generate personalized content, while others are skeptical and question whether AI can truly understand and create meaningful work.
There is also a debate on whether AI causing displacement and job loss is a significant concern. Some argue that AI has caused displacement in other industries before, while others believe that the impact of AI on industries will not be as transformative as anticipated.
Finally, there is a discussion about the issue of compensation for the work AI generates. Commenters mention that historical figures like Leonardo da Vinci and Shakespeare were not compensated for their work, and raise questions about how compensation should be handled in the context of AI-generated content.

Overall, the discussion on Hacker News covers a range of perspectives on the capabilities and implications of AI-generated video scenes.

### Our next-generation model: Gemini 1.5

#### [Submission URL](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/) | 1183 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [550 comments](https://news.ycombinator.com/item?id=39383446)

Google and Alphabet have announced their next-generation AI model, Gemini 1.5, which boasts enhanced performance and a breakthrough in long-context understanding. The model, built upon the MoE architecture, offers a context window of up to 1 million tokens, allowing it to process vast amounts of information in one go. It can analyze and summarize large amounts of content and perform understanding and reasoning tasks across different modalities such as video, audio, and code. Gemini 1.5 Pro, the mid-size multimodal model, is optimized for scaling across various tasks and offers comparable performance to Gemini 1.0 Ultra while using less compute. Developers and enterprise customers can now try Gemini 1.5 Pro in a private preview.

The discussion on the submission revolves around various aspects of the Gemini 1.5 AI model announced by Google and Alphabet. Here are some key points from the comments:

- Some skepticism is expressed about the claimed ability of the model to handle up to 10 million tokens of context, with users questioning the practicality and potential trade-offs.
- A debate arises regarding the significance of benchmarks and whether they accurately reflect the quality of intelligence in AI models. Some users express doubts about Google's track record in delivering on their claims.
- The potential limitations of using vectors in high-dimensional spaces and its impact on model performance are discussed.
- There are concerns about the pricing of the model and whether it would be cost-effective for certain use cases.
- The comparison between Gemini Pro and the previous Gemini Ultra model is examined, with users speculating about the capabilities of GPT-4 and whether Gemini Ultra would still be preferred.
- Some users share their experiences and observations about working with different models and their ability to handle complex tasks and provide realistic answers.
- Discussions also touch on issues related to model requirements, dependencies, and technical aspects of implementation.

Overall, the comments reflect a mix of curiosity, skepticism, and deliberation about the capabilities and practical implications of the Gemini 1.5 AI model.

### Safe and reliable production changes, and how Rivian recently got this wrong

#### [Submission URL](https://blog.substrate.tools/safe-and-reliable-production-changes-for-fast-moving-teams-and-how-rivian-recently-got-this-wrong/) | 58 points | by [kelp](https://news.ycombinator.com/user?id=kelp) | [45 comments](https://news.ycombinator.com/item?id=39386611)

A recent over-the-air (OTA) software update to Rivian vehicles went wrong, causing the infotainment screens to go into a reboot loop. While the vehicles were still drivable, many controls were unavailable for several days while Rivian worked on a fix. This incident raises questions about the process and design flaws at Rivian. One suggestion is to have a canary fleet of vehicles that receive updates first to catch any issues before they reach customer vehicles. Another recommendation is to have a pre-flight check that validates the update before installation, which could have prevented the faulty update from being installed. Additionally, implementing an automatic rollback mechanism for failed updates could minimize downtime. It's important to note that there is rarely a single root cause for such incidents, but rather a combination of mistakes, bugs, or design flaws.

The discussion on Hacker News revolves around the recent software update issue faced by Rivian vehicles. Some users suggest that Rivian should implement pre-flight testing and canary fleet testing to catch any issues before they reach customer vehicles. Others draw comparisons to Volvo's recent software problems and highlight the risks of over-the-air updates. The importance of thorough testing and the potential benefits of automatic rollback mechanisms are also mentioned. The discussion diverges into debates about the reliability of software in vehicles, the weighing of heavy trucks versus passenger cars, and the importance of public transportation infrastructure.

### New bill would let defendants inspect algorithms used against them in court

#### [Submission URL](https://www.theverge.com/2024/2/15/24074214/justice-in-forensic-algorithms-act-democrats-mark-takano-dwight-evans) | 73 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [10 comments](https://news.ycombinator.com/item?id=39390456)

Democratic lawmakers Reps. Mark Takano and Dwight Evans have reintroduced the Justice in Forensic Algorithms Act, a bill that would allow defendants to access the source code of software used to analyze evidence in their criminal proceedings. The proposed legislation also requires the National Institute of Standards and Technology (NIST) to establish testing standards for forensic algorithms used by federal enforcers. The bill aims to address concerns about the potential bias and limitations of algorithms used in the criminal justice system. While the bill does not currently have Republican co-sponsorship, Takano is optimistic that it can gain bipartisan support.

The discussion on this submission revolves around the reliability and transparency of forensic algorithms used in criminal proceedings.
One commenter discusses the need for comprehensive testing and documentation of these algorithms, stating that testing should include detailed information about test cases, test results, and version-specific configurations. Another user argues that expert witnesses should be involved in reviewing the conclusions derived from algorithmic analysis, as they can provide valuable insight.
However, some commenters believe that algorithms often rely too heavily on statistical analysis and can be expensive to challenge or disprove. They suggest that it can be difficult to prove bias or negligence in algorithmic decisions.
The discussion also touches on the importance of victim advocacy and debugging of algorithmic systems. One user poses a question about the victim's perspective, and another commenter points out the need for fairness and specificity in algorithmic determinations, emphasizing the importance of including jurors in the decision-making process.

Overall, the discussion highlights the need for proper testing, expert review, transparency, and fairness in the use of forensic algorithms in the criminal justice system.

### McDonald's Making Job Applicants Take Weird AI Personality Tests

#### [Submission URL](https://futurism.com/mandatory-ai-hiring-tests) | 58 points | by [hjek](https://news.ycombinator.com/user?id=hjek) | [36 comments](https://news.ycombinator.com/item?id=39388518)

McDonald's, Olive Garden, and FedEx are among the companies requiring job applicants to take personality evaluations sorted by an AI system. Paradox.ai, a conversational recruiting software company, uses strange personality assessments including images of blue-skinned humanoid aliens for applicants to identify with. The assessments are part of Paradox's "Traitify" product, which categorizes applicants into personality groups like the "Big Five" or "OCEAN" categories. The efficacy of such widely-used personality tests has been disputed, but companies continue to invest in these HR testing methods.

The discussion surrounding the submission revolves around the use of personality evaluations by companies during the hiring process. One user points out that these tests often have strange and seemingly irrelevant questions that may not accurately reflect a candidate's abilities. Another user counters by saying that sometimes violence-solving questions can be useful in certain job roles. Some users express their skepticism towards the effectiveness of these tests, while others argue that they help filter out potential problem candidates. The discussion also touches on the subject of credit checks during the hiring process and the legality of such practices. There are mentions of the Futurism article being referenced incorrectly, as well as discussions about the value of personality tests and the impact they can have on employee turnover. The thread ends with a lighthearted comment about Weird Al potentially writing interview questions.

### Asahi Linux project's OpenGL support on Apple Silicon officially surpasses Apple

#### [Submission URL](https://arstechnica.com/gadgets/2024/02/asahi-linux-projects-opengl-support-on-apple-silicon-officially-surpasses-apples/) | 378 points | by [throwaway2037](https://news.ycombinator.com/user?id=throwaway2037) | [146 comments](https://news.ycombinator.com/item?id=39383798)

The Asahi Linux project, a team of independent developers working to support Linux on Apple Silicon Macs, has reached an important milestone with their graphics driver. The Asahi driver now fully supports OpenGL version 4.6 and OpenGL ES version 3.2, surpassing what Apple offers in macOS, which tops out at OpenGL 4.1. The team achieved this despite the fact that Apple's GPUs don't support certain features required by newer graphics standards. The next challenge for the team is to support the low-overhead Vulkan API on Apple's hardware. This progress opens up possibilities for running native Linux apps and taking better advantage of software like Valve's Proton on Arm-based Apple hardware.

The discussion on the submission revolves around the impressive progress made by the Asahi Linux project in supporting Linux on Apple Silicon Macs. Some users discuss the technical details, highlighting the challenges of Apple's deprecation of OpenGL and the missing features required by newer graphics standards. There is also a discussion around the significance of supporting Vulkan API on Apple's hardware and the potential benefits for running native Linux apps and leveraging software like Valve's Proton.

Other users appreciate the efforts of the Asahi team, especially their work in achieving OpenGL and OpenGL ES support. They mention the significance of this milestone and express their admiration for the team's accomplishments. There is also a discussion about the use of Python in the Asahi project and the efficiency of their development workflow.
Some users discuss the challenges faced by the Asahi team in implementing GPU drivers and mention the complexities involved in supporting different GPU APIs. The discussion also touches on the importance of DRM support and USB 3 functionality in Linux.
There is a brief mention of Rosenzweig's blog post that didn't provide specific details about Vulkan support, and the potential impact of Asahi's progress on gaming on macOS and using Valves Proton on Arm-based Apple hardware. Some users also bring up Apple's approach as a hardware company and compare it to other vendors in terms of supporting different versions of hardware.

Overall, the discussion is a mix of technical analysis, appreciation for the Asahi team's efforts, and speculation about the potential implications of their progress.

### Show HN: NeuralFlow – Visualize the intermediate output of Mistral 7B

#### [Submission URL](https://github.com/valine/NeuralFlow) | 131 points | by [valine](https://news.ycombinator.com/user?id=valine) | [20 comments](https://news.ycombinator.com/item?id=39378773)

NeuralFlow, a Python script developed by valine, allows you to visualize the intermediate output layers of Mistral 7B. By running this script, you can generate a heatmap image that represents the output at each layer of the model. This visualization can be particularly useful for inspecting model outputs during the fine-tuning process. By comparing the outputs before and after training, you can identify patterns and anomalies within the model. The script segments the image into chunks of 512 and arranges them vertically for better display on landscape screens. You can find the code for NeuralFlow on valine's GitHub repository, along with some models trained using this visualization technique. These models have generalized exceptionally well and can be accessed through the provided links.

The discussion on this submission includes various comments discussing the benefits and applications of the NeuralFlow Python script developed by valine. Some comments highlight the usefulness of visualizing intermediate output layers in understanding model outputs during the fine-tuning process. Others discuss the potential for identifying patterns and anomalies within the model by comparing outputs before and after training. One user mentions that they have found individual snapshots of models to be helpful in observing structural changes over time. Another user expresses interest in how this visualization technique can improve model performance. The discussion also includes comments about gradient products leading to an indicator and determining the starting rules of the model. One user shares their investigations into the repetition problem and another user explains the concept of folding layer distributions to observe discontinuity. Another user mentions the powerful effect of perception visualization. Finally, there is a comment comparing the visualization to encrypted thoughts in The Matrix.

### Sam Altman owns OpenAI's venture capital fund

#### [Submission URL](https://www.axios.com/2024/02/15/sam-altman-openai-startup-fund) | 246 points | by [choppaface](https://news.ycombinator.com/user?id=choppaface) | [80 comments](https://news.ycombinator.com/item?id=39387578)

In a surprising twist, it has been revealed that Sam Altman, the CEO of OpenAI, also owns the OpenAI Startup Fund, a venture capital fund associated with the company. The fund was launched in late 2021 to invest in AI startups and projects, and has reported $175 million in total commitments. However, what sets it apart is that it is not owned by OpenAI or its affiliated nonprofit foundation, but by Altman himself. The decision to put the fund in Altman's name was made for expediency, but it has now been over a year and there are questions about the potential risks and governance structure. OpenAI has acknowledged the need to re-examine their governance structure and establish a new board before making any changes to the fund. This revelation highlights the structural peculiarities of OpenAI as a company.

The discussion on this submission revolves around various aspects of the news and raises questions about Sam Altman's involvement in OpenAI's venture capital fund and the potential risks and governance structure associated with it.
One comment highlights the need to understand Altman's intentions and suggests that it might be interesting to examine the history and intentions of the founders and funders involved. In response, another user shares a link to an article by Matt Levine discussing the situation.
There is also a comment discussing Andrej Karpathy's perspective on the matter, stating that he believes Altman's involvement was for convenience and that the fund will be re-evaluated.
Another user mentions Gary Marcus trying to bring attention to the situation and provides a link to a tweet by Marcus.
One commenter expresses skepticism and states that Altman's previous business dealings should be taken into consideration. The discussion then shifts to Worldcoin and Altman's involvement in cryptocurrency.
There are comments discussing the difficulties in parsing some sentences and suggesting breaking them into smaller sentences. Another user tries to correct and interpret a previous comment.
Some users bring up the WeWork scandal, with one mentioning the similarities between Altman and WeWork's Adam Neumann.
A comment raises suspicions about Altman, comparing him to a scam and suggesting that the community should be cautious. Another user responds, highlighting the need for substantive comments and avoiding mindless celebrity or billionaire worship.
One comment finds it interesting that small investments can turn into large funding rounds, using Andy Bechtolsheim's small investment in Google as an example.
The discussion also touches on the nature of non-profit organizations and their ability to make money. There are comments discussing tax implications and the distinction between for-profit and non-profit entities.
One user brings up the concept of corporate responsibility and suggests parallelism with Twitter's CEO, Elon Musk, and controversy surrounding the two figures.
Someone jokes about Altman's involvement in OpenAI leading to fictional scenarios like the replacement of workers with robots based on Disney's Black Hole movie from the 1980s.
There are comments about Altman's role as a CEO and comparisons to Reddit's CEO, as well as discussions about Y Combinator and its application process.
One user raises concerns about Altman's involvement based on recent reports, while another comment defends Altman and argues that judging CEOs should consider the context and the qualities they bring to their positions.

The discussion ends with a comment jokingly suggesting that the next revelation will involve Altman sending employees to work on Disney's Black Hole movie set.

