## AI Submissions for Mon Oct 02 2023 {{ 'date': '2023-10-02T17:09:43.527Z' }}

### Efficient streaming language models with attention sinks

#### [Submission URL](https://github.com/mit-han-lab/streaming-llm) | 404 points | by [guywithabowtie](https://news.ycombinator.com/user?id=guywithabowtie) | [65 comments](https://news.ycombinator.com/item?id=37740932)

The MIT-HAN lab has released a new project called "Efficient Streaming Language Models with Attention Sinks." The project aims to deploy large language models (LLMs) in streaming applications without sacrificing efficiency and performance. It addresses two major challenges: the extensive memory consumption of caching previous tokens' Key and Value states (KV) during decoding, and the inability of popular LLMs to handle longer texts than the training sequence length. The project introduces StreamingLLM, an efficient framework that enables LLMs trained with a finite-length attention window to generalize to infinite sequence length without the need for fine-tuning. The researchers also discovered the concept of attention sinks, where keeping the KV of initial tokens can largely recover the performance of window attention. They found that adding a placeholder token as a dedicated attention sink during pre-training further improves streaming deployment. In streaming settings, StreamingLLM outperforms the sliding window recomputation baseline by up to 22.2x speedup. To use StreamingLLM, the environment needs to be set up, and the project provides instructions and code examples for running a streaming chatbot.

In the discussion, there are various points raised about the MIT-HAN lab's project on efficient streaming language models with attention sinks. Some of the key highlights include:

1. Some users point out that the infinite-length inputs mentioned in the summary are misleading and clarify that the project focuses on efficient usage of attention windows.
2. The use of sliding context windows and shifting relevant information forward through the layers is seen as a straightforward technique.
3. The concept of attention sinks, where initial tokens' key and value states are kept to recover performance, is found interesting. The limitations of using softmax and potential solutions are also discussed.
4. The idea of adding attention cache memory as a solution is considered intriguing, with references made to similar approaches used in vision transformers.
5. The discussion also touches on the challenges faced by large language models and how they compare to recurrent neural networks (RNNs) in terms of training and performance.
6. There are mentions of related projects, such as RWKV1 and INKBOT-13B-8k-02, and discussions about the limitations and integrity of public leaderboards.
7. Some comments highlight the need for more diverse evaluation and verification methods and the potential advantages of transformers over RNNs.
8. The use of llama2, a library for non-binary conversational summarization, is mentioned as a relevant tool.
9. The FAQ section of the project is referenced for further clarifications and explanations.

Overall, the discussion explores the techniques and challenges involved in deploying large language models efficiently, providing insights and additional perspectives on the project.

### Weird A.I. Yankovic: a cursed deep dive into the world of voice cloning

#### [Submission URL](https://waxy.org/2023/10/weird-ai-yankovic-voice-cloning/) | 305 points | by [waxpancake](https://news.ycombinator.com/user?id=waxpancake) | [177 comments](https://news.ycombinator.com/item?id=37739233)

In a parallel universe, Weird Al is the original artist and other musicians cover his songs. One person decided to bring this alternate reality to life using AI voice cloning. They started with Michael Jackson covering Weird Al's "Eat It," but the results were a bizarre blend of the two artists' styles. They then explored a community on Discord called A.I. Hub, where members trade tips, tools, and techniques for creating A.I.-generated cover songs. The Discord community uses the hosting service Hugging Face to store their models. The RIAA has taken notice of this community but has not taken action against the A.I. models themselves. The creator also experimented with Madonna covering "Like A Surgeon" and A.I. Kurt Cobain singing "Smells Like Nirvana." Google Colab is another platform that many A.I. hobbyists use for generating audio with these models. Overall, the results of these experiments were strange and sometimes comical, highlighting the difficulty of replacing Weird Al's unique voice with A.I.-generated vocals.

The discussion on Hacker News about the submission revolves around various topics related to AI voice cloning and the technical aspects of hosting AI models. Some users discuss the challenges of downloading models and utilizing AI tools on platforms like Google Colab. Others delve into the strategic partnerships of AI hosting services and the cost implications of bandwidth usage. There are also discussions about alternative methods for storing models and configuring cache drives. Additionally, some users share their thoughts on the implications of AI-generated voices, ranging from concerns about job displacement to the potential for manipulation and propaganda. The discussion also touches on the legality and copyright aspects of AI-generated voices.

### Show HN: Anything World â€“ AI for 3D auto-rigging and animation

#### [Submission URL](https://anything.world/) | 120 points | by [mov](https://news.ycombinator.com/user?id=mov) | [48 comments](https://news.ycombinator.com/item?id=37741575)

Introducing "Animate Anything": a web app that automates the tedious tasks of rigging and 3D animations. Say goodbye to the complexities of rigging and bring your own 3D models to life effortlessly. In addition to the web app, "Anything World SDKs" allows you to build directly in Unity and Unreal, unleashing the full power of Anything World within your favorite game engine. Tap into a mammoth library of AI animated 3D models, ranging from common to curious, and create assets ready to be used in your commercial projects. With the Unity SDK, you can even create and control 3D worlds with your voice or text prompts. Download the plug-ins now and give your game-level design a boost. Supercharge your game development by harnessing the power of AI, voice computing, 3D rendering, and behavioral intelligence. The proprietary Machine Learning algorithms can understand and add animations to almost any 3D model, saving you both time and money. Book a demo with the team to see these game-changing tools in action. Join the Discord community and immerse yourself in the world of Animate Anything!

The discussion on the submission revolved around various topics related to the web app "Animate Anything." 

One user mentioned that the web app's visual style reminded them of websites from the late 90s and early 2000s. Another user pointed out that Dropbox Design is a good example of a similar visual style. 

The AI team behind "Animate Anything" joined the discussion and thanked everyone for their positive feedback. They mentioned that they utilized machine learning algorithms to add animations to 3D models, but didn't provide technical details. They also acknowledged that their tools are not meant to replace skilled artists but to assist in the animation process. 

Some users suggested that the website could benefit from optimizing the loading speed for slower networks by using CSS loading indicators and lazy loading. 

Others asked specific questions about the capabilities of "Animate Anything," such as whether it supports non-human skeletons or if it works in the game engine Godot. The team responded by providing information and inviting users to join their Discord community for further details. 

There were also discussions about pricing models for AI services and the difficulty of rigging 3D models. Some users expressed interest in a more affordable option, while others mentioned the challenges they faced in rigging models themselves. 

Overall, the discussion touched on various aspects of the web app and its potential applications in game development and animation.

### Art or Artifice? Large Language Models and the False Promise of Creativity

#### [Submission URL](https://arxiv.org/abs/2309.14556) | 59 points | by [p4bl0](https://news.ycombinator.com/user?id=p4bl0) | [28 comments](https://news.ycombinator.com/item?id=37743567)

Title: "Art or Artifice? Large Language Models and the False Promise of Creativity"

Authors: Tuhin Chakrabarty, Philippe Laban, Divyansh Agarwal, Smaranda Muresan, Chien-Sheng Wu

Summary: In a recent paper titled "Art or Artifice? Large Language Models and the False Promise of Creativity," a group of researchers examined the creative capabilities of large language models (LLMs). They proposed a new evaluation method called the Torrance Test of Creative Writing (TTCW) to assess the creativity of written pieces. The study involved comparing stories written by LLMs with those written by professional authors. The results showed that LLM-generated stories passed significantly fewer TTCW tests than stories written by professionals. Additionally, the researchers investigated the use of LLMs as automated assessors using the TTCW evaluation method and found that none of the LLMs correlated positively with expert assessments. This study raises important questions about the true creative abilities of LLMs and suggests that their capabilities may not be as advanced as previously believed.

Tags: #ArtificialIntelligence #LanguageModels #Creativity #EvaluationMethods #Research

The discussion on the submission titled "Art or Artifice? Large Language Models and the False Promise of Creativity" covers a range of topics and viewpoints. Here are the key points:

1. Prompt Testing Approach: Some users discuss the testing approach proposed in the paper, suggesting that testing the system using multiple prompts could be more effective in benchmarking and improving the system.

2. Multiple Passes: The discussion touches on the use of multiple passes in the code and the benefits it brings to the workflow of AI models. Examples include generating product descriptions and improving the readability and maintainability of code.

3. Human Composition and LLMs: The debate revolves around the comparison between the creative abilities of LLMs and professional writers. Some argue that LLMs cannot truly replicate human creativity, while others highlight the impressive advancements in LLMs and their potential in creative writing tasks.

4. Objective Evaluation and Existing Tools: Users highlight the challenges of objectively evaluating the creativity of LLMs and emphasize the need for leveraging existing tools and techniques to improve evaluations.

5. Performance of LLMs: There is a discussion about the performance of LLMs, with some users expressing surprise at the lack of professional-level creative output from the models. Others suggest that the current LLMs may still have severe misunderstandings and limitations in creative writing tasks.

6. Upscaling and Comparison: The topic of upscaling creative processes using LLMs is touched upon, and users discuss the relevance and comparability of LLM-generated stories with regards to creative outputs.

7. AI as a Tool: Some users argue that LLMs should be seen as powerful tools rather than replacements for human creators. They point out the difference between the capability of AI models to generate content and the true creativity of human artists and writers.

8. Divergent Opinions on AI-generated Content: The conversation diverges to discussing AI-generated messages on social media and the perception of art and creativity. Some users argue that AI-generated content lacks the true creativity found in human creations, while others believe that AI can produce valuable and artistic outputs.

Overall, the discussion showcases a wide range of perspectives on the creative capabilities of LLMs and the evaluation methods used to assess them. The potential and limitations of LLMs in creative writing remain topics of debate among the users.

