## AI Submissions for Sun Jan 28 2024 {{ 'date': '2024-01-28T17:09:32.664Z' }}

### Open-source PixArt-δ image generator spits out high-res AI images in 0.5 seconds

#### [Submission URL](https://the-decoder.com/open-source-pixart-%CE%B4-image-generator-spits-out-high-resolution-ai-images-in-0-5-seconds/) | 78 points | by [danboarder](https://news.ycombinator.com/user?id=danboarder) | [10 comments](https://news.ycombinator.com/item?id=39168474)

Open-source PixArt-δ image generator has been developed by researchers from Huawei Noah's Ark Lab, Dalian University of Technology, Tsinghua University, and Hugging Face. This advanced text-to-image synthesis framework shows great potential to compete with the popular Stable Diffusion family. PixArt-δ integrates the Latent Consistency Model (LCM) and ControlNet to significantly increase the speed of image generation. It can now generate high-resolution images with a resolution of 1,024 x 1,024 pixels in just 0.5 seconds, which is seven times faster than its predecessor, PixArt-α. The researchers have also introduced a ControlNet module to provide finer control over the diffusion models, allowing for more precise text-to-image generation. This open-source image generator presents a promising alternative to existing models and could have a wide range of applications.

The discussion on this submission revolves around the technical aspects and comparisons of the PixArt-δ image generator with other existing models. 
One user, "smsmshh," expresses confusion about the article's presentation of the model and asks for clarification. "wut42" responds, affirming that the training technique used in PixArt is impressive, reaching 108% of the performance of Stable Diffusion v1.5 with faster training time. They provide a link for more details.
Another user, "stvrs," expresses interest in projects like SDXL-LCM and wonders if PixArt supports it. "Zetobal" suggests checking the checkpoint loader and not the model architecture to see if SDXL models are supported.
"artninja1988" reminisces about the existing models and understands the concept of PixArt when compared to stable diffusion models. "ltrt" clarifies that PixArt uses the Latent Consistency Model (LCM) and ControlNet, and also provides a link with more information about PixArt-α.
"jstnclft" wonders when 3D scene generators and working models for image generators will be available. "jncfhnb" expresses disappointment in their attempt to make game assets using SDXL ControlNet models, stating that they did not live up to expectations.
"Aeolun" suggests that one step of comparison can help save ten steps of shuffling between SD and SDXL (referring to Stable Diffusion). "GaggiX" responds, stating that the choice depends on the individual's model and their distilled inference requirements, mentioning the LCM and LCM-LoRA model.

Overall, the discussion focuses on technical details and comparisons between PixArt-δ and other models, as well as users sharing their experiences and interests in related projects.

### New GitHub Copilot Research Finds 'Downward Pressure on Code Quality'

#### [Submission URL](https://visualstudiomagazine.com/articles/2024/01/25/copilot-research.aspx) | 13 points | by [alex-moon](https://news.ycombinator.com/user?id=alex-moon) | [5 comments](https://news.ycombinator.com/item?id=39164079)

New research conducted by GitClear found some concerning trends in the quality and maintainability of code generated by the AI-powered GitHub Copilot. The study compared AI-assisted code to what would have been written by a human developer and found that code churn, the percentage of lines that are reverted or updated within two weeks of being authored, is projected to double in 2024 compared to pre-AI levels. The study also observed an increase in the percentage of "added code" and "copy/pasted code," indicating a lack of code reuse and poor maintainability. These findings challenge previous studies that reported faster completion of tasks and positive developer satisfaction when using GitHub Copilot. GitClear's research raises questions about the impact of AI on code quality and emphasizes the need for evaluating the long-term consequences of relying on AI for code generation.

The discussion on this submission seems to be brief and fragmented. Here are some of the main points raised by the commenters:
1. "nopeYouAreWrong" and "srprsd" seem to disagree on the issue of speed versus quality in AI-generated code.
2. "gnbgb" mentions that there were previous discussions on this topic with varying points and comments.
3. "llc" suggests that they would have written a shorter method and mentions the time it took them to do so.
4. "Havoc" expresses surprise at the results of the study.
5. "cynydz" agrees that there might be concerns with relying on AI for coding.
Overall, it appears that the discussion on this submission is limited and doesn't delve into a comprehensive analysis of the study's findings.

### Judge your Resume with AI: What's the worst that can happen?

#### [Submission URL](https://medium.com/neuml/judge-your-resume-with-ai-4223a2803509) | 17 points | by [dmezzetti](https://news.ycombinator.com/user?id=dmezzetti) | [7 comments](https://news.ycombinator.com/item?id=39161263)

In this article, the author explores the use of Large Language Models (LLMs) and Generative AI in the context of resume evaluation. They use their own resume as an example and demonstrate how LLMs can generate responses to various questions about the resume. The author showcases the capabilities of LLMs by asking questions such as "Tell me about David" and "Is David more of a front-end or back-end developer?" and providing the AI-generated responses. They also experiment with changing the persona of the AI from friendly to brutally honest to see how it affects the responses.

The discussion thread mainly revolves around the concerns and limitations of using Large Language Models (LLMs) and AI in the hiring process. 
One user criticizes LLMs, suggesting that they can lead to systemic discrimination in the hiring pipeline. They mention that the Federal Trade Commission (FTC) has penalized a retailer for using facial recognition software that allegedly created a discriminatory environment. They argue that the claims made by AI software suppliers about their performance should be validated, to ensure that it doesn't perpetuate discrimination. 
Another user responds optimistically, stating that AI can help improve the hiring process. They believe that AI can assist in identifying good candidates and filling gaps in HR systems. However, they acknowledge that larger companies already have established hiring processes and suggest that there is potential for improvement.
A user counters that relying on AI for hiring is wishful thinking and that the current AI technology may not be able to make the process better. They emphasize that technology doesn't solve problems but rather replaces them, suggesting that AI-powered hiring processes might create their own set of problems.
The conversation then shifts to discussing the benefits of LLMs in resume extraction and natural language queries for candidate databases. The usage of existing Applicant Tracking Systems (ATS) and the potential for AI-powered marketing to enhance these systems are also mentioned.
One user dismisses the discussion with a brief negative comment, while another user points out that the article only covers prompts and their resulting outputs, without addressing the broader problems associated with using AI in resume evaluation.
Overall, the discussion highlights concerns about potential discrimination, skepticism about the capabilities of AI in improving the hiring process, and the need to address the limitations and broader issues associated with these technologies.

