## AI Submissions for Mon Aug 21 2023 {{ 'date': '2023-08-21T17:10:14.899Z' }}

### Pixel Binary Transparency: verifiable security for Pixel devices

#### [Submission URL](https://security.googleblog.com/2023/08/pixel-binary-transparency-verifiable.html) | 199 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [112 comments](https://news.ycombinator.com/item?id=37214733)

Google has released a blog post highlighting its latest security feature for Pixel devices called "Pixel Binary Transparency." This feature aims to provide verifiable security for Pixel devices by allowing users to examine and verify the software running on their devices. With this transparency, users can ensure that their devices are running genuine and untampered software. Google's commitment to security and safety on the internet is evident in this new development.

The discussion on the submission revolves around several key points. 

One user points out that Google's commitment to security and safety on the internet is evident in this new feature. However, another user raises concerns about the presence of analytics spyware in the firmware stack and questions whether Google can block such activities. The discussion then shifts to the topic of radio firmware and the control it has over the phone.

Another user who has experience working on Android Security for Pixel phones explains how Pixel phones use verified boot and other security measures to ensure the integrity of the software running on the devices. They also mention the use of the KeyStore API to further enhance security.

A user highlights the importance of binary transparency and how it can address certain threat models. They provide examples of potential attacks where a malicious actor modifies the firmware image and discusses the effectiveness of Google's approach.

The discussion also touches on issues like anti-rollback technology, backdoors in firmware, and the lessons learned from the SolarWinds hack. Some users express skepticism and raise concerns about trusting Google and the potential misuse of the transparency system.

One user points out that GrapheneOS, an alternative Android operating system, provides additional protections against attacks that the official Google Pixel firmware does not have. The discussion also touches on the possibility of custom firmware installation and the long-term support for devices.

There is also a mention of Trillian, a distributed ledger system, and its potential applications in computer security. The discussion concludes with concerns about installing custom firmware and the risks associated with companies disappearing and leaving unsupported devices.

Overall, the discussion covers a wide range of topics related to the security and transparency of firmware on Pixel devices, with varying opinions and concerns expressed by users.

### FreeBSD Experimenting with a Port of Nvidia's Linux Open DRM Kernel Driver

#### [Submission URL](https://www.phoronix.com/news/FreeBSD-Port-Linux-DRM-KO) | 123 points | by [mikece](https://news.ycombinator.com/user?id=mikece) | [36 comments](https://news.ycombinator.com/item?id=37210103)

FreeBSD developers are experimenting with a port of NVIDIA's Linux Open DRM Kernel Driver. This port, called nvidia-drm-kmod, allows FreeBSD users to use the open-source NVIDIA kernel driver for better integration with the kernel. While NVIDIA graphics on FreeBSD have been excellent thanks to the quality Linux driver stack, this new port could further enhance the experience, particularly in terms of Wayland support. The port is still in its early stages, but it has the potential to improve graphics support on FreeBSD systems.

The discussion about the submission started with a comment sharing a link to further information about the new port of NVIDIA's Linux Open DRM Kernel Driver for FreeBSD. Another user responded with a sarcastic comment about the DRM acronym, bringing up its association with Digital Rights Management and its negative perception. This led to a discussion about the different meanings of DRM, with users providing examples and clarifications.

Another user pointed out that the integration of NVIDIA graphics on FreeBSD has been good so far, but they have had trouble with AMD graphics. They praised the documentation and integration of NVIDIA graphics on FreeBSD and highlighted the stability of the system.

Some users mentioned specific technical problems with the FreeBSD NVIDIA driver, including issues with the Kernel Mode Setting (KMS) and visible screen tearing during video playback. One user mentioned that NVIDIA provides a native FreeBSD driver, but it lacks certain features.

There was a brief discussion about CUDA support on FreeBSD, with one user stating that they have used CUDA on FreeBSD in the past and another user asking about the compatibility of RTX cards on FreeBSD.

Overall, the discussion revolved around the new port of NVIDIA's Linux Open DRM Kernel Driver for FreeBSD and the current state of graphics support on the operating system. Users shared their experiences, highlighted the strengths and weaknesses of the existing drivers, and discussed the potential impact of the new port.

### I Made Stable Diffusion XL Smarter by Finetuning It on Bad AI-Generated Images

#### [Submission URL](https://minimaxir.com/2023/08/stable-diffusion-xl-wrong/) | 316 points | by [minimaxir](https://news.ycombinator.com/user?id=minimaxir) | [63 comments](https://news.ycombinator.com/item?id=37211519)

Today's top story on Hacker News is about Stability AI's release of Stable Diffusion XL 1.0 (SDXL), an open-source model capable of generating high-resolution images without any special permissions. Despite flying under the radar due to the current focus on text-generating AI like ChatGPT, SDXL is a noteworthy addition to the generative image AI space. SDXL consists of two models, a base model and an optional refiner model, which significantly improves the level of detail in the generated images. With full support in the diffusers Python library by Hugging Face, developers now have the tools to experiment and create their own projects using SDXL. The article provides code snippets and examples to get started. Additionally, it introduces two new features supported by diffusers: prompt weighting and Dreambooth LoRA training and inference. Prompt weighting allows users to mathematically influence the significance of certain terms in the generated text embeddings, while Dreambooth LoRA enables the finetuning of Stable Diffusion on a small set of source images using a trigger keyword. With Dreambooth, developers can incorporate specific concepts from source images into different contexts. The article concludes with examples of the LoRA model's capabilities, including generating images of Ugly Sonic and heavily distorted, garbage images conditioned on the prompt "wrong."

The discussion on this submission revolves around different aspects of Stability AI's release of Stable Diffusion XL 1.0 (SDXL) and its capabilities. 

One user mentions the potential for personalized RLHF (Reinforcement Learning Human Feedback) interactions with generative AI systems. They discuss the idea of implementing thumbs-down feedback buttons and potential ways to make the UI more transparent and user-friendly. They also mention the possibility of using prompt refinement and Dreambooth LoRA for fine-tuning and incorporating specific concepts from source images into different contexts.

Another user points out the difference between the concepts of explicit and implicit RLHF. They mention that explicit RLHF systems are trained based on feedback ratings given by humans, while implicit RLHF systems use other signals to determine the quality of generated content.

There is also a discussion about the quality and potential improvements of Stable Diffusion XL compared to its predecessor, Stable Diffusion 15 (SD15). Users share their experiences with the models, showcase generated images, and discuss their impressions. Some users express their interest in trying out SDXL and its capabilities.

Further discussions touch on topics such as generating Pokemon images, training models with LoRA, and the technical details of implementation and training. Users share their experiences and recommendations for parameter settings, training methods, and hardware requirements.

Overall, the discussion highlights the excitement and curiosity around SDXL and its potential applications in generating high-resolution images. Users share their experiences, ask questions, and provide insights into the capabilities of the model.

### Associated Press clarifies standards around generative AI

#### [Submission URL](https://www.niemanlab.org/2023/08/not-a-replacement-of-journalists-in-any-way-ap-clarifies-standards-around-generative-ai/) | 81 points | by [jyunwai](https://news.ycombinator.com/user?id=jyunwai) | [32 comments](https://news.ycombinator.com/item?id=37215829)

The Associated Press (AP) has released new guidelines to caution journalists about the use of AI in news coverage. While the AP has used AI technology to automate certain tasks since 2014, the guidelines emphasize that AI should not replace journalists and that AI-generated content should be treated as unvetted source material. The guidelines also state that generative AI should not be used to alter any elements of photos, video, or audio, and that journalists should exercise caution when using AI-generated content to avoid the spread of mis- and disinformation. The AP Stylebook also includes updates that warn journalists about far-fetched claims made by AI developers and advise against attributing human characteristics to AI systems.

The discussion on this submission covers a range of topics related to the use of AI in news coverage and the guidelines set by the Associated Press (AP). 

One commenter, RheingoldRiver, expresses interest in the guidelines' point about avoiding gendered pronouns for LLMs (large language models) and suggests that it's important to question decision-making processes and avoid biases. In response, mchlt points out that journalists often prioritize the preferences of companies and governments, which can lead to biased reporting.

Another commenter, LispSporks22, raises the question of why OpenAI needs permission to train its models on AP news stories dating back to 1985. Nl responds by suggesting that the AP News Archive is not publicly available and that there are reasonable arguments for crawling public pages for learning purposes.

The discussion also delves into the topic of AI-generated images and the legal implications. Some commenters, like fshbbdssbbgdd, discuss the potential copyright issues with training models using copyrighted Shutterstock images, while others, like mdfplk, argue that it's not a problem as long as there are no trademarks.

Other topics brought up include the potential biases and limitations of AI, the need to acknowledge the problems with the current copyright system and compensate content creators, the impact of AI on public perception, and the distinction between artificial intelligence and tools like ChatGPT.

Overall, the discussion covers a wide range of perspectives on the use of AI in news coverage, copyright law, biases, and the challenges faced by content creators and AI developers.

### Early Days of AI

#### [Submission URL](https://blog.eladgil.com/p/early-days-of-ai) | 142 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [50 comments](https://news.ycombinator.com/item?id=37213107)

Elad Gil, a former Google and Twitter engineer, has written a blog post discussing the early days of AI and its potential as a new era of technology. Gil highlights that prior to the rise of new AI architectures like transformers and diffusion models, most machine learning startups failed because the capabilities were not advanced enough. However, with the launch of GPT-3 in June 2020, there was a significant step up in AI capabilities. This was followed by the launch of image-gen products and ChatGPT, which captured the public's imagination and marked the AI startup big bang moment. Despite this progress, true enterprise adoption of AI is still several quarters or years away, as large companies are still trying to understand what AI means for them. Gil predicts that there will be at least four waves of AI adoption, with the first wave consisting of companies like ChatGPT and Character.AI, and the fourth wave being the adoption of AI by large enterprises. Overall, Gil believes that the future of AI is bright and that there is enormous potential for this new era of technology.

The discussion on this submission revolved around various aspects of AI and its potential. Some users expressed skepticism about the performance and significance of certain AI models, such as MedPaLM2, highlighting the cherry-picked nature of the claims made in the blog post. Others discussed the historical context of AI, with a mention of expert systems from the 1980s and the potential limitations of current AI models. There was also a mention of the "AI effect" and the challenges in defining AI. Additionally, the accessibility of machine learning and the availability of APIs were mentioned as factors that make ML solutions more feasible for businesses.

### Stablevideo: Text-driven consistency-aware diffusion video editing

#### [Submission URL](https://rese1f.github.io/StableVideo/) | 209 points | by [satvikpendem](https://news.ycombinator.com/user?id=satvikpendem) | [42 comments](https://news.ycombinator.com/item?id=37204950)

Researchers from Zhejiang University and Microsoft Research Asia have made advancements in the field of video editing with their new method called StableVideo. While diffusion-based methods have been successful in generating realistic images and videos, editing existing objects in a video while maintaining consistency has remained challenging. StableVideo introduces temporal dependency to existing text-driven diffusion models, enabling them to generate consistent appearances for edited objects. The method utilizes a novel inter-frame propagation mechanism that propagates the appearance information from one frame to the next using layered representations. The researchers conducted extensive experiments to test the editing capability of StableVideo and found that it outperformed state-of-the-art video editing methods in terms of both qualitative and quantitative results.

In the discussion on Hacker News, there were several different perspectives and thoughts shared about the StableVideo method for video editing:

- Some users appreciated the advancements in video editing and found the results impressive. They mentioned that it's interesting to watch the edited videos, even though there are still some issues, such as weird lighting and low-quality textures.
- Others pointed out that the stability of the video models is important, and progress in this area is necessary for further advancements.
- Some comments discussed the progression of AI technology and how it has developed over the years. It was noted that while progress is being made, there are still limitations and challenges to overcome.
- A few comments highlighted the potential impact of AI development on hardware and software expression, emphasizing the importance of maintaining fundamental constraints.
- There was some discussion about the connections between artificial neural networks and the human brain, with some users suggesting that silicon-based neural networks could eventually achieve similar capabilities.
- One user mentioned that the discussion was unrelated to the original paper and criticized the lack of a proper GitHub page with a template for academic papers.
- There were also comments about video compression and the potential integration of AI models into video encoding processes, both in terms of training data and improving compression efficiency.
- Some users expressed their excitement about the new method and were looking forward to future advancements in the field.
- Others expressed skepticism and labeled the news as "fake" or "weird."
- There were also discussions about the availability of example videos and the functionality of the StableVideo method in different browsers.
- A user shared their experience with similar video stabilization solutions and mentioned other commercial applications that have been developed.

Overall, the discussion covered various aspects of video editing, AI technology, hardware constraints, and skepticism about the new method.

### Show HN: VisionScript, abstract programming language for computer vision

#### [Submission URL](https://github.com/capjamesg/visionscript) | 89 points | by [zerojames](https://news.ycombinator.com/user?id=zerojames) | [21 comments](https://news.ycombinator.com/item?id=37213729)

Visionscript: A High-Level Programming Language for Computer Vision

Capjamesg, a developer, has created a high-level programming language called Visionscript for computer vision tasks. Visionscript is built in Python and offers a simple syntax for running object detection, classification, and segmentation models. With Visionscript, users can easily perform common computer vision tasks in a fast and efficient manner. The language provides features like object detection, image classification, and image replacement. It also offers an interactive web notebook for running Visionscript code. The inspiration behind Visionscript was to create a simple way of performing one-off computer vision tasks. The language is ideal for beginners who want to explore computer vision concepts in a user-friendly manner. Visionscript is available on GitHub under the MIT license.

There are several comments discussing the functionality and potential of Visionscript:

- ulrikhansen54 expresses interest in the language as a modern alternative to OpenCV, specifically highlighting the need for replacements for good object tracking functions.
- symisc_devel shamelessly plugs a lightweight OpenCV alternative called SOD, targeting embedded devices and implementing modern image processing algorithms.
- rcc mentions a popular library, SPRVSN, for converting notations and validating models for object tracking and supervision.
- zrjms responds to rcc's comment, mentioning that VisionScript can handle scenes versus things, such as counting objects within a zone.
- tgv notes that VisionScript reminds them of Hypercard's scripting language and suggests a similar approach for dealing with multiple objects and labels.
- zrjms thanks tgv for their comment and mentions that they have been working on iterating on the language, giving an example script for detecting people in grayscale images.
- kn appreciates zrjms' contribution and suggests learning Progressions language for interpreting VisionScript, as it provides a graphical environment for dragging and dropping components.
- CyberDildonics comments that VisionScript goes beyond simple OpenCV terms and provides models for classification, object detection, and segmentation.
- chptrck suggests replacing global state with objects in VisionScript to improve compatibility with machine learning and computer vision ecosystems.
- jnlsncm wonders if there are extensions similar to Scratch that add functionality to VisionScript.
- rcc expresses excitement about the ability to create custom detection blocks with VisionScript.
- ano88888 tries out VisionScript and expresses appreciation for its work.

Overall, the discussion seems to be positive, with users expressing interest in the capabilities and potential of Visionscript. Some users suggest alternative libraries and extension possibilities for the language.

### Lidar on a Chip Puts Self-Driving Cars in the Fast Lane

#### [Submission URL](https://spectrum.ieee.org/lidar-on-a-chip) | 34 points | by [jnord](https://news.ycombinator.com/user?id=jnord) | [21 comments](https://news.ycombinator.com/item?id=37204724)

Self-driving cars have long been considered the future of transportation, with the potential to save lives and revolutionize the way we travel. However, one of the key challenges to widespread adoption has been the high cost and complexity of lidar sensors, which are crucial for creating detailed 3D maps of a vehicle's environment. Elon Musk, CEO of Tesla, has controversially advocated for a cameras-only approach to autonomous driving, arguing that cameras and neural networks are sufficient. However, many traffic-safety specialists have questioned this approach and believe that lidar is necessary for safe operation. In an effort to address the cost and integration challenges, Analog Photonics, a company spun out of MIT, is developing a chip-scale phased-array lidar sensor that promises to be tiny, reliable, and affordable. The company hopes that this breakthrough technology will pave the way for the widespread adoption of self-driving cars.

- Commenter "NoZebra120vClip" mentions that a company called Bubba Gumps is selling LIDAR stock in New York City.
- Commenter "whnvk" discusses the application of self-driving cars technology in body scanning and building 3D maps, suggesting that companies like Amazon, Meta, and Google might be interested in using it for body inspections.
- Commenter "tsyb" responds to "whnvk" suggesting that data collected from VR headsets could be used for detailed measurements, but the level of anonymity and granularity might be a concern.
- Commenter "_boffin_" mentions an article they haven't read but believes that self-exploring drones can be built without using LIDAR.
- Commenter "gnmd" mentions that there are low-cost integrated packages for ToF sensors available from talkitng ST.
- Commenter "scrtstn" mentions that Apple iPhones have a LiDAR chip.
- Commenter "ttr" believes that cheap, effective, and reliable LiDAR sensors for self-driving cars are a good thing, but questions whether self-stopping self-driving cars are a step in the right direction.
- Commenter "gnsh" mentions that they work with a million chips and are an EE, pointing out the issues of interference in the travel of LiDAR signals.
- Commenter "mkhlfrnc" is interested in the capability and price point of low-cost LiDAR sensors and believes they could affect industries beyond self-driving cars.
- Commenter "Havoc" suggests that Tesla might switch to using LiDAR due to advancements in the technology.
- Commenter "whmsclsm" mentions that they are working on a prototype LiDAR chip.
- Commenter "gtrfltr" reaches the end of the summary and comments, "dd" which is unclear in meaning.

### Wi-Fi sniffers strapped to drones: odd plan to stop election fraud

#### [Submission URL](https://arstechnica.com/tech-policy/2023/08/wi-fi-sniffers-strapped-to-drones-mike-lindells-odd-plan-to-stop-election-fraud/) | 35 points | by [sunbum](https://news.ycombinator.com/user?id=sunbum) | [122 comments](https://news.ycombinator.com/item?id=37208751)

Mike Lindell, the CEO of My Pillow and a vocal supporter of former President Donald Trump, is claiming he has developed a technology that can detect if voting machines are connected to the internet. Lindell demonstrated the technology at an event in Missouri using a wireless sniffing device mounted on a drone. However, experts have pointed out that there doesn't appear to be any major advance in network monitoring technology here. Lindell's plan to fly drones near polling places may also violate state laws on criminal trespassing and the use of unmanned aircraft for surveillance. Despite the skepticism surrounding his claims, Lindell said he has already used the device in Florida and plans to cover every parish in Louisiana for the upcoming fall election.

The discussion on the submission about Mike Lindell's voting machine technology revolves around skepticism and criticism of his claims. One user points out that there is already network access point control in place at polling locations to prevent any unauthorized access. Others mention that the main issue with voting machines is not their connectivity to the internet but rather the use of proprietary and unreliable systems. There is also discussion about the potential violation of state laws regarding using drones near polling places. Another topic that arises is voter ID laws and the need for ID verification. Some users argue for voter ID laws while others express concerns about disenfranchising certain groups of voters. The conversation also touches on tax refunds and the requirement of non-citizens voting. Overall, there is skepticism towards Lindell's claims and discussions on various related topics.

### US judge: Art created solely by artificial intelligence cannot be copyrighted

#### [Submission URL](https://arstechnica.com/tech-policy/2023/08/us-judge-art-created-solely-by-artificial-intelligence-cannot-be-copyrighted/) | 53 points | by [carride](https://news.ycombinator.com/user?id=carride) | [31 comments](https://news.ycombinator.com/item?id=37213492)

Art generated entirely by artificial intelligence (AI) cannot be copyrighted, according to a ruling by a federal judge in the US. The judge stated that human authorship is an essential part of a valid copyright claim, and therefore, AI-generated work does not meet the criteria. The case was brought by plaintiff Stephen Thaler, who sought copyright for an image produced by a computer program he developed. Thaler argued that the software, named the Creativity Machine, should be considered the author of the work. However, the judge's ruling reiterated that copyright law protects only works of human creation. This ruling follows a similar decision last year, where Thaler lost a case arguing that AI software could be registered as a patent inventor.

The discussion revolves around the ruling that AI-generated art cannot be copyrighted and the implications of this decision. Some commenters argue that AI should not be considered the creator and, therefore, should not have copyright protection. However, others point out that if AI-generated works are not protected, there could be legal issues around licensing and commercialization. The debate expands to discuss the copyrightability of AI-generated characters and the potential conflicts between AI creations and existing copyrighted materials. Additionally, there is a discussion about the distinction between copying and transformation in copyright law and whether AI-produced works fall under copyrightable material.

### Nvidia BIOS Signature Lock Broken – What Caused Open-Source Pains for Years

#### [Submission URL](https://www.phoronix.com/news/NVIDIA-Lock-Broken) | 23 points | by [segfaultbuserr](https://news.ycombinator.com/user?id=segfaultbuserr) | [5 comments](https://news.ycombinator.com/item?id=37216269)

In a major breakthrough for open-source enthusiasts, a Windows utility has been released that breaks the NVIDIA BIOS Signature Lock, a security feature implemented by NVIDIA since the GeForce GTX 900 days. This signature check has been a headache for the open-source Nouveau driver community, as it has limited the functionality of the GTX 900 series and newer GPUs. With the lock now broken, users will have more control over their graphics card's settings, including power limits, voltages, and fan curves. While the impact on the Nouveau developers is yet to be seen, this development certainly highlights the vulnerability of artificial software locks.

The discussion around the submission consists of several comments discussing different aspects of the NVIDIA BIOS Signature Lock and its implications for the open-source community. 

One user, SenAnder, points out that NVIDIA implemented the lock to prevent fraudulent individuals from flashing higher-end graphics card firmware onto lower-end products and selling them at a higher price. They question whether there are other ways to verify product authenticity without restricting user control.

RetroTechie responds to SenAnder's comment by explaining that there are hardware registers that can be used to identify supported features and non-modifiable firmware. They mention that if these hardware registers do not exist, it raises questions about firmware claiming support for hardware that is not actually present. RetroTechie suggests that this could be a problem created by shady sellers.

PlutoIsAPlanet adds to the discussion by highlighting that while NVIDIA locks their graphics cards, phones use bootloader messages to warn users of potential risks. They suggest that there may be other reasons for NVIDIA to lock their cards and express doubt about the prevention of fraud being the sole reason.

SenAnder replies to PlutoIsAPlanet's comment by noting that graphics cards do not have sufficient access to display warning screens like phones do.

In a separate comment, hdjfkfbfbr finds the discussion interesting and mentions that the NVIDIA BIOS Lock affects certain models of the 30-series graphics cards.

### Brave Browser has an AI assistant chat now

#### [Submission URL](https://brave.com/leo-release/) | 37 points | by [rejectfinite](https://news.ycombinator.com/user?id=rejectfinite) | [20 comments](https://news.ycombinator.com/item?id=37214735)

Brave browser has introduced Leo, its browser-native AI assistant, for testing and feedback in the Nightly desktop channel. Leo, built on the success of Brave Search AI Summarizer, is designed to allow users to interact with web pages without leaving the page itself. It can answer questions, suggest follow-up queries, augment content, and even help with reading comprehension. Leo is hosted by Brave without the use of third-party AI services, ensuring user privacy. Feedback from Nightly users will help improve Leo's accuracy and user experience, with plans to release it to all Brave browser users in the coming months.

The discussion on the submission revolves around Brave's new browser-native AI assistant, Leo. Some users express skepticism about trusting Brave considering its strong focus on privacy. Others point out that Brave is different from other companies jumping on the AI and NFT bandwagon. Some users mention that Brave has implemented an AI system to maintain user privacy, and they appreciate Brave's commitment to privacy-first browsing. There is a discussion about whether the AI prompts served by Leo are useful or a result of hype. Additionally, there is a brief mention of a previous issue with Brave's bookmark tabs button on Android and a comparison between Brave and Firefox. Some users express doubts about trusting Brave, while others argue that Brave is a privacy-focused company. The discussion also touches on the use of reverse-proxy access servers and logging individual IP addresses, with some users expressing concerns about privacy guarantees and others dismissing those concerns. Overall, opinions on Brave and Leo vary, with some users expressing trust and others expressing doubt.

