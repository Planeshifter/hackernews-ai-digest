## AI Submissions for Mon Oct 07 2024 {{ 'date': '2024-10-07T17:12:18.456Z' }}

### Homemade AI Drone Software Finds People When Search and Rescue Teams Can't

#### [Submission URL](https://www.wired.com/story/this-homemade-ai-drone-software-finds-bodies-when-search-and-rescue-teams-cant/) | 241 points | by [sohkamyung](https://news.ycombinator.com/user?id=sohkamyung) | [129 comments](https://news.ycombinator.com/item?id=41764486)

In a poignant tale that blends adventure with tragedy, Charlie Kelly, an experienced hillwalker, went missing during a solo hike in the Scottish Highlands on September 6, 2023. Leaving his home in Tillicoultry with plans to conquer the peak of Creise, Kelly assured his partner, Emer Kennedy, that he was prepared for the journey. His messages throughout the day were upbeat, detailing his progress until they abruptly stopped after he indicated he could see the lights of the ski center near his parked car. 

As darkness descended, Kennedy's concern grew, leading to a massive search operation by Glencoe Mountain Rescue, involving helicopters, drones, and dozens of volunteers. Despite extensive efforts, no trace was found of Kelly until more than six weeks later. In a remarkable turn, two mountain rescue volunteers, Dan Roach and David Binks, harnessed their newly developed drone technology to assist in the search. Their involvement led to a breakthrough; the drones quickly located Kelly's body within an hour of deployment. 

The story highlights not only the risks associated with solo hiking but also showcases the extraordinary dedication of mountain rescue teams—comprised entirely of volunteers—who work tirelessly under challenging conditions. As they navigate both the emotional weight of such searches and the evolving technological landscape, the marriage of human skill and innovation proves essential in these life-or-death situations.

The discussion surrounding the tragic case of Charlie Kelly, the missing hillwalker, delves into multiple facets of search and rescue (SAR) operations, particularly the role of technology and the complexities of maritime rescue laws in Europe. Several commenters share insights on how advancements in drone technology have the potential to improve SAR operations, emphasizing the importance of volunteer rescue teams that often operate under challenging conditions.

One commenter reflects on the difficulties faced by SAR teams, noting that legal stipulations sometimes hinder their ability to conduct rescues, especially across borders. There are also discussions about the practical challenges and ethical dilemmas tied to drone use in SAR operations, including the risks posed by military and surveillance applications.

Others highlight the potential for drone-assisted SAR solutions, advocating for more innovative designs and technologies that can enhance search efforts and reduce response times. Some participants also touch upon the necessity for clear and legal frameworks governing rescue operations to ensure that help can be provided without restrictions.

Overall, the comments underscore the blending of human dedication with technological advancements in SAR, while also debating the intricacies of legal, moral, and technical issues that impact such rescue scenarios.

### Longwriter – Increase llama3.1 output to 10k words

#### [Submission URL](https://github.com/THUDM/LongWriter) | 148 points | by [taikon](https://news.ycombinator.com/user?id=taikon) | [29 comments](https://news.ycombinator.com/item?id=41766144)

This week, the open-source community welcomed the launch of **LongWriter**, a cutting-edge AI model capable of generating over **10,000 words** from expansive contexts. Developed by the THUDM team, LongWriter is built on two notable architectures—**GLM-4-9B** and **Llama-3.1-8B**—promising enhanced text generation capabilities suitable for a variety of applications.

**Key Features**:
- **Speedy Output**: Thanks to its optimized deployment via **vllm**, users can produce lengthy text pieces in under a minute, making it a game-changer for content creators.
- **User-Friendly Setup**: The project provides straightforward code examples for deployment, along with detailed requirements and setup instructions, ensuring accessibility for all developers.
- **Evaluation Tools**: Two new benchmarks—**LongBench-Write** and **LongWrite-Ruler**—are introduced to assess the quality and length of the outputs, allowing for comprehensive performance testing.

**Practical Applications**: Users can employ LongWriter for storytelling, detailed guides, and creative writing, as demonstrated by its ability to craft narratives on-demand; for instance, composing a tragic love story spanning thousands of words.

For those interested in pushing the boundaries of AI-assisted writing, LongWriter stands out as an innovative tool in the ever-evolving landscape of machine learning and natural language processing. Check out the project on GitHub to explore its features and try it out for yourself!

The discussion following the launch of LongWriter on Hacker News highlights various perspectives on AI-generated writing and the capabilities of the model. Here are the key points raised by users:

1. **Capabilities and Quality of Outputs**: Many commenters noted that while LongWriter can produce lengthy texts quickly, there are concerns about the coherence and narrative structure of the generated content. Some users pointed out that AI-generated writings may lack the depth that human authors typically provide.

2. **Copyright and Ethical Considerations**: The discussion touched on potential copyright issues related to AI writing. Some users expressed concerns that generating texts in the style of specific writers could infringe on copyright laws, raising ethical questions about the originality of AI outputs.

3. **Complexity of Prompting**: Several users noted that effectively utilizing models like LongWriter requires careful prompting to achieve desired results. They highlighted the complexities of maintaining narrative consistency and the challenges of crafting prompts that generate meaningful sections of text.

4. **Comparison with Previous Models**: Users referenced their experiences with earlier AI models, noting how advancements like LongWriter continue to evolve the landscape of text generation. Some praised the user-friendly setup and evaluation tools introduced alongside LongWriter.

5. **Future of AI in Creative Writing**: The discourse included speculation about the future role of AI in creative endeavors. Users debated whether AI could effectively complement human creativity, especially in long-form writing, and how it might change the landscape of content creation.

Overall, the conversation reflected excitement about LongWriter's potential while also emphasizing the importance of addressing ethical and practical challenges in AI-generated writing.

### The computer built to last 50 years

#### [Submission URL](https://ploum.net/the-computer-built-to-last-50-years/index.html) | 35 points | by [andai](https://news.ycombinator.com/user?id=andai) | [16 comments](https://news.ycombinator.com/item?id=41765098)

In a thought-provoking blog post, Ploum explores the concept of creating a computer designed to last fifty years, aiming to emphasize longevity over obsolescence. Drawing parallels with typewriters, which have proven their durability and functionality over decades, Ploum critiques our throwaway culture of electronic devices that require replacement every few years. The proposed "ForeverComputer" would prioritize timeless tasks, such as reading and writing, minimizing the need for constant upgrades driven by trends or software updates.

Ploum advocates for a sturdy and resilient design over ultra-portability and power, arguing that a well-built device fosters a deeper connection with its user. By limiting its use cases to essential functions, the ForeverComputer could fill the gap left by modern gadgets that often serve more as distractions. Ultimately, this essay calls for a shift in how we approach technology, arguing that a focus on sustainability could reshape our relationship with our devices—encouraging us to cherish them rather than discard them.

The discussion surrounding Ploum's "ForeverComputer" blog post reflects a mix of skepticism and nostalgia regarding the concept of building computers designed to last fifty years. Some users highlighted the historical durability of technology, referencing devices like typewriters and the Zenith Z-120s, which have withstood the test of time. Others pointed out the challenges faced by modern computers, particularly rapid software obsolescence and the increasing complexity of hardware, which can hinder long-term usability. There was a recognition that while older systems could potentially last longer, the demands of contemporary software and security needs complicate the longevity of devices today.

Many participants also compared the reliability of retro computing models, like the PDP-11 and VAX, asserting that designs from earlier eras prioritized durability over the rapidly declining lifecycle of current technology. Despite supporting the idea of sustainable tech, some commenters expressed doubt about whether modern computing could genuinely support a fifty-year lifespan due to inherent obsolescence in software and hardware. Overall, the conversation centered on balancing nostalgia for past devices with the challenges of longevity in today's tech landscape.

### Sorbet: A neuromorphic hardware-compatible transformer-based spiking model

#### [Submission URL](https://arxiv.org/abs/2409.15298) | 56 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [52 comments](https://news.ycombinator.com/item?id=41761699)

In the quest for energy-efficient language models suitable for edge devices, researchers have unveiled "Sorbet," a cutting-edge transformer-based spiking language model designed with neuromorphic hardware compatibility in mind. Crafted by Kaiwen Tang and colleagues, Sorbet tackles the challenging integration of energy-intensive operations like softmax and layer normalization, essential for traditional models but difficult to implement on neuromorphic systems.

To address these hurdles, the authors introduced innovative alternatives: PTsoftmax for softmax operations and bit-shifting power normalization (BSPN), both of which significantly reduce the energy footprint while maintaining strong performance. By employing knowledge distillation and model quantization, Sorbet achieves a highly compressed binary weight model without sacrificing efficacy.

Extensive testing on the GLUE benchmark highlights Sorbet's promise, positioning it as a viable solution for resource-constrained environments where privacy and energy efficiency are paramount. This work represents a significant milestone in making advanced language capabilities accessible even in low-power devices.

In a recent Hacker News discussion, users engaged in a wide-ranging conversation sparked by the article about "Sorbet," a spiking language model for neuromorphic hardware. Comments varied significantly, with some users promoting suspiciously commercial messages regarding cryptocurrency trading. Others expressed appreciation for the academic insights provided in the original article, discussing related neural network concepts and referencing pertinent research about spiking neural networks.

Several participants questioned the definition of intelligence, debating whether artificial intelligence (AI) should be considered truly intelligent compared to human cognition. Some voiced skepticism about attributing intelligence to models that operate statistically, underlining a belief that many human qualities aren't replicated by AI. Conversations also touched on the philosophical implications of AI developments, addressing how human intelligence could be misunderstood or undervalued in discussions about machine capabilities.

A few users highlighted the difference between traditional and emerging models in the AI landscape, like Sorbet, while others contributed technical inquiries and references to external resources. Overall, the dialogue reflected a mix of curiosity, skepticism, and differing interpretations of intelligence in the face of advancing AI technologies.

### ByteDance’s Bytespider is scraping at much higher rates than other platforms

#### [Submission URL](https://fortune.com/2024/10/03/bytedance-tiktok-bytespider-scraper-bot/) | 138 points | by [wmstack](https://news.ycombinator.com/user?id=wmstack) | [93 comments](https://news.ycombinator.com/item?id=41764670)

ByteDance, the parent company of TikTok, has introduced an aggressive web scraper known as Bytespider, significantly ramping up its data collection efforts. According to research from Kasada, Bytespider is scraping online content at an astonishing rate—25 times faster than OpenAI's GPTbot and a staggering 3,000 times faster than Anthropic's ClaudeBot. This surge in activity comes as ByteDance seeks to catch up in the competitive generative AI landscape, having previously relied on partnerships with OpenAI for its own language models.

Despite potential challenges, including a looming U.S. ban on TikTok due to national security concerns, ByteDance is pushing ahead with its web scraping initiatives. The company aims to enhance its AI capabilities, particularly to improve TikTok’s search functionalities and advertising features. Bytespider bypasses conventional scraping restrictions, raising ethical concerns about copyright infringement and the implications of using vast amounts of online data for commercial gain. As TikTok refines its search tools to capitalize on trending content, the implications of this aggressive data strategy could reshape ad targeting and user engagement on the platform.

The discussion surrounding ByteDance's introduction of its aggressive web scraper, Bytespider, has generated mixed responses among Hacker News users. Key points from the conversation include:

1. **Performance Comparison**: Users noted that Bytespider operates at a substantially faster rate than competitors like OpenAI's GPTbot, which raises questions about the efficiency of such extensive scraping.
2. **Ethical Concerns**: There was a significant focus on the ethics of indiscriminate scraping practices. Many commentators expressed discomfort with the potential violations of copyright and the lack of consent from content creators regarding how their data is harvested for commercial gain.
3. **Market Impact and Competition**: Some users discussed the implications of ByteDance’s aggressive data collection strategy on the competitive landscape of generative AI. The mention of TikTok's refinement of search functionalities to leverage trending content was perceived as a strategy to enhance user engagement and ad targeting.
4. **Technical Critique**: There were critiques of the broader AI landscape, suggesting that many contemporary AI products, possibly including those from ByteDance, often lack fundamental design features, and rely heavily on vast amounts of data without considering the source or consent.
5. **Concerns About Centralization and Control**: Several commenters voiced concerns about the centralization of data among large tech companies and how this might impact smaller entities and the ethical landscape of content creation online.

Overall, the discourse reflects a blend of technical analysis, ethical considerations, and broader implications for the competitive dynamics in AI and content management, highlighting a community grappling with the rapid evolution of technology and its societal impacts.

