## AI Submissions for Mon Apr 29 2024 {{ 'date': '2024-04-29T17:11:09.243Z' }}

### Show HN: 3D framework for the web, built on Svelte and Three.js

#### [Submission URL](https://threlte.xyz/) | 347 points | by [spxneo](https://news.ycombinator.com/user?id=spxneo) | [53 comments](https://news.ycombinator.com/item?id=40205509)

Threlte is a cutting-edge 3D web framework that merges the power of Svelte and Three.js, offering declarative components that scale effortlessly. With Threlte, you can harness the full capabilities of Three.js in a more intuitive manner by composing your scene with render components. This community-driven framework includes integrations for physics engines, animation libraries, GLTF file transformations, and a host of extras to kickstart your projects. Additionally, custom props and events can be added to components with Plugins, providing even more flexibility. 

Several users and developers have expressed their excitement and satisfaction with Threlte, praising its intuitive API, robust documentation, and seamless integration with Svelte. From web developers to designers and creators, Threlte is receiving high praise for its ease of use and powerful features. Whether you're building webGL apps, experimenting with data visualization, or delving into shader writing, Threlte simplifies the process, making even challenging tasks more manageable. 

As you embark on your 3D web development journey, consider joining the vibrant Threlte Community on Discord, where enthusiasts and creators come together to share knowledge and insights. Dive into the world of Threlte and explore the endless possibilities it offers for your projects.

The discussion on the Threlte submission revolves around the capabilities and comparisons of the Threlte framework with other technologies like React-Three-Fiber, A-Frame, and X3D. 

- **lgrsch** mentions ongoing efforts to make Threlte Svelte 5 ready and emphasizes its intuitive API and the integration of significant features like physics engines and animation libraries. They invite users to join the Threlte Community on Discord.
  
- **mrdoob** expresses admiration for the framework's capabilities.
  
- **chmpychp** inquires about Threlte's comparison with React-Three-Fiber in terms of third-party performance.
  
- **Sateeshm** shares their experience with Threlte projects, citing gradual progress and challenges faced.
  
- **tlkngtb** compares React-Three-Fiber, React-Three-DR, and React versions of projects, highlighting examples and impressive sandbox demos.

- **lstdng** praises the tools available and sees potential for creative applications.
  
- **jnhx** shares how using Three.js transformed their web development experience.
  
- **k1zmt** draws analogies between web development tools and the variety of options available.
  
- **prlnr** considers the potential of declarative 3D components in various frameworks and the evolution of 3D standards across different technologies.
  
- **Sateeshm** expresses excitement about the discussions on Discord related to Threlte.
  
- **ndnd** expresses appreciation for a 3D chessboard project in Svelte with integrated Lichess environment.

### GPT-4.5 or GPT-5 being tested on LMSYS?

#### [Submission URL](https://rentry.co/GPT2) | 479 points | by [atemerev](https://news.ycombinator.com/user?id=atemerev) | [309 comments](https://news.ycombinator.com/item?id=40199715)

The news of gpt2-chatbot has stirred up a storm of speculation and discussion within the tech community. This mysterious model, seemingly associated with OpenAI, has piqued the interest of many due to its remarkable capabilities. With outputs rivaling high-end models like GPT-4 and Claude Opus, gpt2-chatbot stands out for its informative and rational responses across different domains.

The model's use of OpenAI's tiktoken tokenizer and its claim to be based on the GPT-4 architecture with "Personality: v2" further fuel the belief that it is linked to OpenAI. Despite exhibiting unique characteristics and vulnerabilities specific to OpenAI models, gpt2-chatbot continues to intrigue researchers and enthusiasts alike.

Speculations about the model being an early version of GPT-4.5, part of OpenAI's incremental updates, add another layer of mystery to the story. Some suggest the possibility of gpt2-chatbot being a strategic move by OpenAI to stealthily benchmark their latest model, while others ponder over alternative explanations such as a misconfigured service within LMSYS.

As the tech community delves deeper into unraveling the enigma surrounding gpt2-chatbot, one thing remains certain - the allure of cutting-edge AI technology and its potential implications continue to captivate minds and spark lively debates.

The discussion on the Hacker News thread regarding the gpt2-chatbot submission delves into various speculations and insights. Some users express confusion and skepticism about the nature of the model, with references to Reddit's involvement in AI training data and queries about OpenAI's potential motives. Others speculate on the model's connection to GPT-4.5 or whether it could be a strategic move by OpenAI for benchmarking purposes.

There is a separate conversation about different AI models, such as RAG, GPT-4, and GPT-5, discussing their capabilities and potential advancements in reasoning tasks. Users also share thoughts on specific AI training programs, like LLMs, and the implications of their data sources and methodologies.

Additionally, the discussion touches on GitHub projects, user interactions, and the impact of content deletion on knowledge-sharing platforms. Some users mention specific individuals like CTScott and their contributions to online communities, highlighting the significance of DIY guides, technical advice, and community engagement in fostering knowledge exchange.

Lastly, users share insights into AI performance metrics, such as perplexity, and engage in discussions about the current state and future developments of AI models like GPT-5. There are mentions of challenges faced by existing models in reasoning tasks and the potential for advancements in handling complexity and inference capabilities.

### Memary: Open-Source Longterm Memory for Autonomous Agents

#### [Submission URL](https://github.com/kingjulio8238/memary) | 205 points | by [james_chu](https://news.ycombinator.com/user?id=james_chu) | [61 comments](https://news.ycombinator.com/item?id=40196879)

Today's Top Story on Hacker News:
Title: memary: Longterm Memory for Autonomous Agents
Description: memary is an open-source project that aims to provide long-term memory for autonomous agents, enabling them to store a large corpus of information in knowledge graphs, infer user knowledge, and retrieve relevant information for meaningful responses. The project includes features like a routing agent, knowledge graph creation and retrieval, memory stream tracking, and entity knowledge storage. It also offers a detailed component breakdown, installation instructions, and a demo using Streamlit app. Additionally, it discusses the use of knowledge graphs, LLMs (Large Language Models), and future contributions to expand the project's capabilities. The project is hosted on GitHub with 666 stars and 38 forks.
Link: [memary on GitHub](https://github.com/kingjulio8238/memary)

The discussion on the submission about memary covers various aspects related to knowledge graphs, AI assistants, large language models (LLMs), and building knowledge using Neo4j and Semantic Knowledge Graphs. Users discuss the importance of knowledge graphs for AI assistants and the challenges of building and utilizing them effectively. They explore topics such as the role of ontologies in defining entity types and relationships, the potential of LLMs in building knowledge, and the practicalities of utilizing graphs for data retrieval and semantic understanding. Additionally, there are mentions of specific tools like Neo4j for building knowledge databases and the challenges of integrating AI technologies to enhance knowledge retrieval and memory functions. The conversation delves into technical details and considerations for effectively leveraging knowledge graphs in AI systems.

### Show HN: Kaytu â€“ Optimizing cloud costs using actual usage data

#### [Submission URL](https://github.com/kaytu-io/kaytu) | 91 points | by [acx1729](https://news.ycombinator.com/user?id=acx1729) | [15 comments](https://news.ycombinator.com/item?id=40199972)

The Kaytu CLI is making waves on Hacker News, offering a solution to save on cloud costs by optimizing server sizes based on historical usage data. This tool analyzes your past week's CloudWatch data and provides tailored recommendations, ensuring you only pay for the resources you need. With features like ease of use with a one-line command, customization options, and a secure, open-core philosophy, Kaytu is a promising tool for engineering, DevOps, and SRE teams looking to cut down on cloud spending. Stay tuned for upcoming features like Non-Interactive mode, Azure support, GPU optimization, and more. If cloud cost optimization is on your mind, Kaytu might just be the tool you've been looking for.

The discussion on the Kaytu CLI submission involves various perspectives and feedback from Hacker News users. Some users like Saleh express interest in the efficiency of the tool in recommending server components and instance types based on different combinations, highlighting the importance of making informed decisions. Others like nsl emphasize the significance of trusting business resources in decision-making processes, while acx1729 discusses the skepticism and cautious approach towards open-sourcing server-side components. Nathan_jr appreciates the information and insight provided by the Kaytu CLI, emphasizing the value of sizing data sent. Furthermore, acx1729 shares their experience with GCP integration and cost management, showcasing the benefits of tools like Kaytu in tackling high monthly spending. Finally, users like kywrkrng and swzy show interest in exploring cost-saving options for cloud spending and appreciate the functionality offered by the Kaytu CLI. Overall, the discussion reflects a mix of curiosity, skepticism, practical insights, and encouragement regarding the Kaytu CLI and cloud cost optimization in general.

### Answering Legal Questions with LLMs

#### [Submission URL](https://hugodutka.com/posts/answering-legal-questions-with-llms/) | 165 points | by [hugodutka](https://news.ycombinator.com/user?id=hugodutka) | [125 comments](https://news.ycombinator.com/item?id=40198458)

Hotseat, a legal tech startup, has tackled the challenge of using AI, specifically GPT-4, to answer legal questions comprehensively. By breaking down the process into subtasks and leveraging a system of artificial intelligence agents, they were able to make GPT-4 analyze complex legal documents, such as the EU's AI Act, and provide detailed responses to specific questions about regulations. The approach involved structuring the document with Markdown, roleplaying scenarios to prompt the AI, and utilizing functions to delegate subquestions to different "junior lawyers" within the AI system. This innovative method showed promising results in testing with lawyers, offering accurate and detailed answers to legal inquiries. While the process takes around 5 to 10 minutes and costs approximately $2, the system proved effective in analyzing legal texts and providing insightful responses.

The discussion surrounding the submission of Hotseat, a legal tech startup utilizing AI (specifically GPT-4) to answer legal questions comprehensively, delved into various aspects. Participants debated the role of AI in replacing knowledge workers such as doctors, lawyers, and court clerks, with opinions split on whether AI tools like GPT-4 could effectively replace human expertise. Some argued for the potential of AI to streamline processes and enhance accuracy in legal tasks, citing examples of AI's successful implementation in various professions. 

Additionally, there were discussions on the reliability of AI-generated responses and concerns about AI potentially replacing professionals like doctors and lawyers. The debate also touched on the implications of AI tools like GPT-4 in the legal field, discussing the need for human judgment, subjectivity, and proper research in handling complex legal matters. Participants highlighted the importance of AI complementing human professionals rather than fully replacing them, emphasizing the unique capabilities that human expertise brings to the table.

### GitHub Copilot Workspace: Technical Preview

#### [Submission URL](https://github.blog/2024-04-29-github-copilot-workspace/) | 284 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [303 comments](https://news.ycombinator.com/item?id=40200081)

GitHub has announced the launch of GitHub Copilot Workspace, a groundbreaking developer environment that allows developers to seamlessly transition from idea to code using natural language. The new Copilot-native developer environment aims to revolutionize the software development process by leveraging generative AI tools to boost productivity and collaboration. With Copilot Workspace, developers can brainstorm, plan, build, test, and run code in a task-centric approach, providing a streamlined workflow from start to finish. This innovative tool empowers developers to harness the power of natural language to create software efficiently and creatively, without sacrificing autonomy. GitHub's ultimate goal with Copilot Workspace is to democratize software development, enabling a future where over 1 billion individuals can easily build and control software. By reducing mundane tasks and cognitive overload, Copilot Workspace aims to enhance the productivity and creativity of both professional and hobbyist developers. The technical preview for GitHub Copilot Workspace is now available, inviting developers to sign up and explore the exciting possibilities it offers for the future of coding.

The discussion on Hacker News revolves around GitHub's announcement of the launch of GitHub Copilot Workspace, a developer environment that leverages generative AI tools to streamline the software development process. Some users express skepticism about the effectiveness of using AI in coding, noting that completing large tasks solely with AI-generated code may not be efficient and could lead to repetitive or incorrect results. Others mention the challenges of debugging LLM models, the potential benefits of alternative workflows, and the limitations of current AI models in handling complex programming tasks. There is also a discussion about the roles of AI and human brains in coding, with some users highlighting the importance of context-specific testing to improve AI models. Additionally, there are comments about the security implications of using AI in cryptographic implementations and comparisons between GPT-4 and other AI models. Overall, the comments reflect a mix of excitement, caution, and curiosity about the implications of GitHub Copilot Workspace and the future of AI in software development.

### I Witnessed the Future of AI, and It's a Broken Toy

#### [Submission URL](https://www.theatlantic.com/technology/archive/2024/04/rabbit-r1-impressions/678226/) | 33 points | by [mikestew](https://news.ycombinator.com/user?id=mikestew) | [17 comments](https://news.ycombinator.com/item?id=40205666)

In the world of artificial intelligence, the Rabbit R1 was set to revolutionize the way we interact with AI gadgets. With its cute bouncing rabbit screen and promise of seamless tasks like ordering an Uber or identifying objects, it seemed like the future we've been waiting for. However, reality hit hard when connectivity issues and functionality glitches left users stranded and underwhelmed.

The Rabbit R1 and its competitors like Humane's AI Pin are part of a new wave of AI devices aiming to bring generative-AI technology into our daily lives. While these gadgets hold promise, they are struggling to deliver on their lofty ambitions. Reviewers have criticized the devices for being slow, overheating, and failing to perform basic tasks effectively.

Despite its setbacks, the Rabbit R1 stands out for its retro-chic design, relatively affordable price, and some intriguing features like interpreting handwritten text. It aims to utilize a large action model (LAM) to complete tasks across various apps, similar to how a Tesla on autopilot can recognize stop signs. However, the reality falls short of the hype, with the device currently only able to function with a limited number of apps.

As Rabbit's founder, Jesse Lyu, faced scrutiny over the device's capabilities, questions arose about the actual existence of AI technology behind the scenes. Despite assurances from the company, doubts remain about the device's true potential. The journey towards integrating AI seamlessly into our daily lives continues, with the Rabbit R1 serving as a cautionary tale of the challenges in turning futuristic visions into reality.

- **jnlsncm** criticized Tesla's software features, mentioning the specific functions and interactions he believed were missing from the current software.
  - **Kirby64** responded with examples of Tesla's current software features that were relevant to the discussion.
- **rsynntt** commented on the overvaluation of AI companies by venture capitalists, suggesting that they might not truly understand the technology they are investing in.
- **RevEng** reassured readers that issues with gadgets like the Rabbit R1 at early stages of development are normal and fixable.
- **SushiHippie** shared a related review of the Rabbit R1 for further reading.
- **vbrsl** delved into the potential of AI technology in connecting humans and emphasized the importance of AI helping humanity rather than replacing human connections.
  - **blmstrss** and **vbrsl** further discussed the impact and implications of AI on human connections.
- **mkstw** shared a link related to the discussion.
- **throwaway5959** expressed skepticism about the success of AI gadgets, highlighting the issues with touchscreen interfaces and corporate motivations.
  - **pn-** agreed with the sentiment, pointing out the dysfunctional nature of current technology.
- **dhb** mentioned an article about the implications of pushing the boundaries of device development and extrapolating the future of AI, with **fnnds** noting a sense of disillusionment.

### Show HN: React Bricks, The only headless CMS with true Visual Editing

#### [Submission URL](https://www.reactbricks.com/) | 10 points | by [dsalinasgardon](https://news.ycombinator.com/user?id=dsalinasgardon) | [5 comments](https://news.ycombinator.com/item?id=40196760)

On May 7th, mark your calendars for a FREE workshop introducing a Visual Editing CMS specifically designed for React. This headless CMS is unique in its ability to transform React components into visually editable blocks, empowering marketers while maintaining brand consistency. 

For developers, the CODE VisualReact platform offers the flexibility of creating content blocks using React and TypeScript, ensuring that the brand image remains intact. Meanwhile, content editors can easily compose pages visually, much like using a word processor, making the process seamless and efficient.

The platform boasts advantages for both developers and marketing teams, with a user-friendly interface that bridges the gap between technical and non-technical users. By starting with just a few simple commands, developers can enhance their React components with visual editing capabilities, while marketers can take advantage of features like Digital Asset Management (DAM), Advanced SEO, and Scheduled publishing to streamline their workflow.

For those interested in a practical application, the platform offers a compelling e-commerce case study detailing how Beara Beara leveraged React Bricks to create a visually stunning and business-oriented website that is easy to maintain.

With features tailored to enterprises, startups, digital agencies, and e-commerce businesses, React Bricks provides a comprehensive solution for content creation and management. So, whether you're ready to revolutionize your website or just curious to learn more, React Bricks offers a seamless solution for all your visual editing needs.

In the discussion on the submission about the headless CMS for Visual Editing, there are a few key points brought up by the users:

1. **rnbrln** mentioned the website of the Visual Editing platform.
2. **ydn** raised a point about not being able to tell much difference between different platforms in terms of basic social pricing.
3. **rctbrcks** responded to **ydn** and explained that the pricing table is complex but highlights some key differences such as the number of pages supported, series, locales, and features like real-time collaboration and scheduled publishing.
4. **rctbrcks** also introduced themselves as the co-founder of React Bricks to **mdmsmrt** who commented that the website is slow but looks awesome.

### The Financial Times and OpenAI strike content licensing deal

#### [Submission URL](https://www.ft.com/content/33328743-ba3b-470f-a2e3-f41c3a366613) | 35 points | by [kmdupree](https://news.ycombinator.com/user?id=kmdupree) | [51 comments](https://news.ycombinator.com/item?id=40201397)

The Financial Times and OpenAI have announced a content licensing deal that will provide readers with access to quality journalism and expert analysis. This collaboration offers various subscription options, ranging from essential digital access to complete digital access with expert insights. With a focus on global news, expert opinion, and special features, readers can now enjoy the benefits of both the Financial Times' reputable journalism and OpenAI's cutting-edge content.

The discussion on the announcement of the content licensing deal between the Financial Times and OpenAI covers various angles and opinions. Some users express concerns about the control of content rights and the impact on small players in the industry, while others discuss the implications of AI models on journalism and the publishing industry as a whole. There is a debate on the sustainability of business models, the ethics of profiting from licensed content, and the role of AI in generating and distributing content. Discussions also touch on issues of intellectual property rights, commercial pricing models, and the future of content creation and consumption in the digital age.

### OpenAI GDPR Complaint

#### [Submission URL](https://www.theregister.com/2024/04/29/openai_hit_by_gdpr_complaint/) | 19 points | by [vorticalbox](https://news.ycombinator.com/user?id=vorticalbox) | [8 comments](https://news.ycombinator.com/item?id=40199121)

1. **Headline:** OpenAI faces GDPR complaint for inaccurate data handling
2. **Summary:** Privacy activist group noyb has lodged a complaint against OpenAI, alleging that its ChatGPT service breaches GDPR regulations by failing to correct inaccurate data. The complaint arose when ChatGPT inferred and returned a wrong birth date for a public figure. Despite requests, there was no apparent method to correct the error, leading to concerns about compliance with GDPR's accuracy requirements for personal data. This clash between cutting-edge AI and stringent data protection laws underscores the challenges faced by companies like OpenAI in aligning their technology with legal frameworks.
3. **Key Points:** 
   - The complaint alleges that ChatGPT generated false information about a public figure, highlighting the risks associated with AI models inaccurately processing personal data.
   - GDPR mandates that individuals have the right to correct inaccurate personal data, a requirement that poses challenges for AI systems like ChatGPT in ensuring compliance.
   - This incident reflects a broader trend of AI models struggling to adhere to privacy laws, as demonstrated by a previous Italian restriction on ChatGPT over privacy concerns.
   - Potential consequences for OpenAI may include fines based on GDPR's penalty framework, with penalties potentially amounting to a percentage of the organization's global turnover.
4. **Implications:** The clash between advanced AI technologies and stringent data protection regulations exemplified by the OpenAI-GDPR complaint underscores the need for AI developers to navigate complex legal landscapes. As AI continues to evolve, ensuring alignment with data protection laws will be essential to maintaining trust and compliance in the handling of personal information.

The discussion on the Hacker News post about OpenAI facing a GDPR complaint for inaccurate data handling includes various perspectives:

1. **Ukv** expressed concern about the specific data subject's incorrect birthdate and the challenges in training algorithms with accurate data while avoiding erroneous inferences.
2. **snpcstr** wondered if OpenAI might implement a filter to verify information and allow for the correction or deletion of inaccuracies.
3. **Doxin** mentioned GDPR exceptions that permit companies to store data for certain purposes and speculated on potential arguments OpenAI might use in response to the complaint.
4. **mb** pointed out Google's frontend tool highlighting mistakes to demonstrate how companies can address inaccuracies effectively.
5. **phlpwhk** mentioned that the Irish authority would handle the complaint against OpenAI.
6. **hptr** sarcastically commented on the AI predicting wrong birth dates for public figures.
7. **RecycledEle** suggested giving ChatGPT a large memory to facilitate corrections, while **wizzwizz4** countered that it might not be a viable solution.

Overall, the discussion highlighted concerns regarding AI's accuracy in handling personal data, potential solutions like implementing filters or memory corrections, and the complexities companies like OpenAI face in complying with data protection regulations such as GDPR.

