## AI Submissions for Tue Aug 20 2024 {{ 'date': '2024-08-20T17:12:37.847Z' }}

### Artificial intelligence is losing hype

#### [Submission URL](https://www.economist.com/finance-and-economics/2024/08/19/artificial-intelligence-is-losing-hype) | 472 points | by [bx376](https://news.ycombinator.com/user?id=bx376) | [708 comments](https://news.ycombinator.com/item?id=41295923)

In recent weeks, the enthusiasm surrounding artificial intelligence (AI) has taken a notable hit, particularly in Silicon Valley, where tech investors are recalibrating their expectations. Following a peak in share prices, AI-driven companies have seen a significant 15% drop in valuations. The industry is now grappling with the sobering realization that while billions of dollars have been poured into AI development, adoption rates remain low. Current statistics reveal that only 4.8% of American businesses utilize AI in their operations, a slight decrease from earlier this year. As big tech firms continue to make extravagant promises regarding AI's transformative potential, critics are growing increasingly skeptical about the actual limitations and viability of large language models. This shifting sentiment prompts a larger question: will AI ultimately fulfill the soaring expectations of both investors and the marketplace?

The discussion on Hacker News primarily revolves around the recent downturn in enthusiasm for AI, particularly regarding large language models (LLMs). Users express skepticism about the practicality and transformative potential of these technologies, suggesting that investment hype surrounding AI may not align with its current application capabilities.

Several commenters argue that although LLMs can enhance productivity, their effectiveness often depends on the specific context and user input, leading some to question whether they are truly revolutionary. Some acknowledge the struggle in effectively integrating AI tools like GitHub Copilot into their workflows, pointing out that these models sometimes fall short in providing useful suggestions.

There is a feeling of disappointment regarding AI's ability to solve complex programming problems or deliver accurate results. Some users note the need for human oversight and expertise to rectify inadequacies in AI responses, suggesting that AI might serve more as a supplementary tool rather than a full replacement for human skills in programming or other specialized tasks.

Additionally, the debate touches on critiques of the competitive investment climate in the AI sector, with concerns about whether current funding and innovation can lead to meaningful advancements in technology. Overall, the sentiment hints at a cautionary outlook on AI's future and its capacity to meet heightened investor and market expectations.

### Zed AI

#### [Submission URL](https://zed.dev/blog/zed-ai) | 362 points | by [dahjelle](https://news.ycombinator.com/user?id=dahjelle) | [254 comments](https://news.ycombinator.com/item?id=41302782)

Zed, a team of experts with a rich background in programming languages and text manipulation, has unveiled Zed AI—a groundbreaking text editor integrated with AI capabilities. Over the past two years, Zed has honed its focus on creating an intuitive text editor and exploring the integration of large language models (LLMs) into their coding workflows. Their dedication caught the attention of Anthropic, a top AI company, leading to a collaboration that culminated in Zed AI.

Zed AI offers developers an advanced coding environment powered by Anthropic's Claude 3.5 Sonnet. It's designed for seamless interaction, allowing users to access AI-supported features directly within their editing workspace. During the initial launch phase, users can experience Zed AI’s robust functionality for free.

Key highlights of Zed AI include:
- **Assistant Panel**: Unlike traditional chat interfaces, Zed’s assistant panel is a full-fledged text editor that provides comprehensive control over AI requests. Developers can utilize slash commands to pull in relevant code snippets and diagnostics, allowing the AI to assist more effectively.
- **Inline Transformations**: This feature allows for real-time code generation and transformations through natural language prompts, with immediate feedback via a custom streaming diff protocol for a highly responsive experience. 

Zed's focus on transparency ensures that every interaction with the AI is clear and under the user's control, reinforcing the tool's practical application for complex coding tasks. Enthusiasm surrounding this launch illustrates a promising future for AI-assisted coding, making Zed AI a compelling addition to any developer's toolkit.

The discussion surrounding the launch of Zed AI contains a mix of excitement, skepticism, and technical insights from the Hacker News community. Here are the main points highlighted in the comments:

1. **Zed AI Reception**: Many users expressed positive sentiments about Zed AI's functionality and its integration with Anthropic's Claude 3.5 Sonnet. They appreciate the smooth experience in coding workflows that Zed provides, though some called for more direct interaction with Anthropic itself, instead of being mediated through Zed AI.

2. **Concerns About Proprietary Models**: A recurring theme is skepticism over proprietary models and the potential issues arising from the company’s business model. Some commenters voiced worry about hidden costs and the sustainability of relying on a closed ecosystem for developers, potentially leading to trouble with funding and long-term viability.

3. **Open Source vs. Proprietary Software**: Several discussions highlighted the importance of open-source software. Users advocated for a balance between proprietary offerings and open-source contributions, arguing that it is crucial for creating a vibrant community around software, with some expressing a desire for Zed to adopt a more open-source-friendly licensing model.

4. **Technical Limitations and Suggestions**: Some users noted technical challenges they faced when trying Zed AI, particularly regarding cursor control and user experience features that may need refinement. Suggestions for improvements included better integration of shortcut commands for coding assistance functions.

5. **Comparison with Other Editors**: Commenters frequently compared Zed AI with other popular text editors and IDEs, discussing their respective functionalities and highlighting potential strengths or weaknesses. Some mentioned the need for extensibility and customization, which they felt might be lacking in Zed AI compared to established tools like VSCode or Sublime Text.

6. **Business Model Discussions**: There were insights into different business models for software, including subscription-based versus one-time purchase models. Some users voiced concerns about ongoing costs associated with using Zed AI, contemplating its impact on the broader developer community.

In summary, while Zed AI's launch was met with enthusiasm, especially for its innovative features, there were notable concerns regarding its closed-source nature, user experience, and ongoing business practices that could shape its adoption.

### New Phi-3.5 Models from Microsoft, including new MoE

#### [Submission URL](https://huggingface.co/microsoft/Phi-3.5-MoE-instruct) | 23 points | by [thecal](https://news.ycombinator.com/user?id=thecal) | [3 comments](https://news.ycombinator.com/item?id=41303780)

The latest advancement in AI models, Phi-3.5-MoE, has been unveiled, showcasing its capabilities as a lightweight yet powerful option for a variety of commercial and research applications. This model leverages high-quality synthetic data and carefully filtered public documents to enhance its reasoning and multilingual abilities, all while supporting a generous context length of 128K tokens.

Designed for environments where memory and compute resources are limited, Phi-3.5-MoE excels particularly in scenarios demanding fast response times and strong logical reasoning—important for code, math, and logic tasks. Its rigorous training process included supervised fine-tuning and safety optimizations, making it a robust choice for developers.

The versatility of this model opens doors to numerous use cases, from general AI applications to potential innovations in language and multimodal features. However, developers are cautioned to evaluate its limitations and ensure responsible usage, especially in high-stakes situations. Phi-3.5-MoE will soon be integrated into the official transformers library, with detailed guidance provided for local implementation.

Early benchmarking shows that Phi-3.5-MoE stands strong against competitors, outpacing several established models in critical reasoning tests and code generation tasks. With its comprehensive support for multi-language, advanced safety measures, and ready-to-use tokenizer, Phi-3.5-MoE is set to be a game changer in the landscape of generative AI.

In the discussion about Phi-3.5-MoE, several points were raised by the commenters. One user highlighted a potential limitation regarding the model's token window, pointing out that while it boasts a long context window of 128K tokens, there seems to be a practical limit of 4K tokens in some scenarios. Another commenter provided links to benchmark results and resources related to Phi-3.5-MoE, suggesting that its performance could be thoroughly evaluated through these metrics. Finally, one user noted that Phi models are designed to excel in benchmarking tests, particularly in real-world performance compared to other competing models. Overall, the conversation reflects both cautious optimism about the model's capabilities and an emphasis on scrutinizing its real-world applications and performance metrics.

### AI Cheating Is Getting Worse

#### [Submission URL](https://www.theatlantic.com/technology/archive/2024/08/another-year-ai-college-cheating/679502/) | 12 points | by [noobermin](https://news.ycombinator.com/user?id=noobermin) | [23 comments](https://news.ycombinator.com/item?id=41303266)

As the academic world continues to grapple with the implications of generative AI, Kyle Jensen, head of Arizona State University’s writing programs, is preparing for another challenging semester. Last year brought an overwhelming wave of AI-generated essays, leading to widespread cheating and a crisis of trust between students and faculty. With over 23,000 students enrolled in writing classes, Jensen and his colleagues are determined to find a balance that embraces AI while maintaining academic integrity.

Despite initial fears about AI rendering traditional college essays obsolete, Jensen now advocates for using these AI tools to enhance education. His work, supported by the National Endowment for the Humanities, aims to instill generative-AI literacy among instructors. However, the aftermath of the first “AI college” year was a mixed bag—widespread misuse of technology left educators feeling demoralized and uncertain about how to evaluate student work.

Teachers have expressed growing concern as they prepare for the upcoming term, eager for effective measures to combat cheating. The excitement over potential new AI detection tools has not quelled uncertainty, as many remain unproven and insufficient against the ingenious ways students exploit technology. 

Numerous innovative strategies have been proposed to tackle this dilemma, from watermarking output to tracking changes in student writing. Yet the consensus remains that detecting AI-generated content without built-in markers is still out of reach, leading to an ongoing arms race between educators and AI developers.

With the specter of academic dishonesty looming large, universities are now on a quest for coherent strategies that balance the benefits of AI with the necessity for integrity in education. The future of learning in this AI era hangs in the balance as educators strive to restore trust and engage students meaningfully in a rapidly evolving landscape.

The discussion surrounding the implications of generative AI in academic writing highlights a range of concerns and perspectives from educators. Some participants argue that traditional college writing courses need to adapt to better prepare students for real-world writing, which often requires clear communication and collaboration skills. Many voices express frustration over the widespread cheating facilitated by AI, citing it as a reason that students may not engage deeply with the material. 

Educators share various strategies for combatting AI-induced cheating, including creating assessments that encourage understanding over rote learning. There's a debate on whether existing AI detection tools are effective, with many educators expressing skepticism about their reliability. Some participants suggest that the focus should shift from merely detecting cheating to fostering skills that promote genuine learning.

Additionally, there are concerns about how academic integrity will be maintained in light of AI's capabilities. The tension lies in balancing the benefits of AI in education with the necessity for honest and substantive assessments of students' abilities. Teachers seem to agree that developing a curriculum that acknowledges and utilizes AI's potential—while also addressing its misuse—is crucial as they prepare for the evolving demands of the educational landscape. Overall, a consensus appears to be building around the need for innovative assessment methods and a focus on meaningful learning experiences.

### Condé Nast Signs Deal with OpenAI

#### [Submission URL](https://www.wired.com/story/conde-nast-openai-deal/) | 79 points | by [spenvo](https://news.ycombinator.com/user?id=spenvo) | [59 comments](https://news.ycombinator.com/item?id=41302493)

In a significant move for the media landscape, Condé Nast has entered a multi-year partnership with OpenAI, allowing the AI company to utilize content from its prestigious media brands, including The New Yorker, Vogue, and WIRED. This collaboration aims to adapt to the evolving digital landscape while ensuring fair attribution and compensation for the content creators behind these iconic publications.

Condé Nast CEO Roger Lynch expressed that this partnership is a proactive step to recover lost revenue amidst the ongoing struggles of the publishing industry, which has faced challenges from tech companies and changes in search algorithms. Lynch, a vocal advocate for licensing agreements, previously criticized AI data scraping practices, labeling unlicensed content usage as akin to "stolen goods." The specifics of the deal remain undisclosed, but it reflects a growing trend of media organizations collaborating with generative AI firms amidst fears of AI undermining their work.

However, the partnership hasn't come without controversy. Many Condé Nast employees have voiced concerns about how their content will be used, fearing it may contribute to the proliferation of misinformation. The union representing the editorial staff is seeking clarity about the deal to protect their members’ rights and address these anxieties.

Overall, this collaboration raises important questions about the intersection of journalism, technology, and ethical practices in an era increasingly dominated by AI. As more publishers align with AI companies to secure their place in the digital economy, the implications for journalism and content creation are sure to unfold in the years to come.

The discussion surrounding the partnership between Condé Nast and OpenAI reveals a mix of apprehensions and insights regarding the implications of AI's integration into the media landscape. Several commenters expressed confusion about the underlying mechanics that enable such partnerships, emphasizing concerns about proper attribution and intellectual property rights.

Critics highlighted the potential for AI to generate misleading content, leading to worries about misinformation proliferation, particularly given the union’s push for clarity on member protections. Others debated the legality of training AI on copyrighted materials without adequate compensation for creators, with some drawing parallels to past controversies such as Google Books.

Some participants noted that while large organizations can negotiate favorable terms with AI companies, smaller publishers may struggle under similar circumstances. The conversation also touched on the potential backlash from editorial staff and the ethical considerations of AI's impact on journalism.

In conclusion, the dialogue reflects a broader apprehension about how AI partnerships might transform the relationship between content creators and distributors, with key themes being the need for fair compensation, the risk of misinformation, and the legal complexities of copyright in the digital age.

