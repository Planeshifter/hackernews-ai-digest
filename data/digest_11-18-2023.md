## AI Submissions for Sat Nov 18 2023 {{ 'date': '2023-11-18T17:10:54.633Z' }}

### Frigate: Open-source network video recorder with real-time AI object detection

#### [Submission URL](https://frigate.video/) | 540 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [122 comments](https://news.ycombinator.com/item?id=38321413)

Introducing Frigate: Monitor your security cameras with locally processed AI

Frigate is an open source Network Video Recorder (NVR) that brings real-time AI object detection to your security camera system. What sets Frigate apart is that all the processing is done locally on your own hardware, ensuring that your camera feeds never leave your home. With Frigate, you can say goodbye to false positives and tedious video reviews.

The traditional NVRs often rely on simple motion detection, which can result in a lot of false positive alerts. Frigate tackles this problem by offloading object detection to the powerful Google Coral TPU. This allows even modest hardware to run advanced analysis and determine if the detected motion is actually a person, car, or any other object of interest. By processing everything locally, you don't need to pay for your personal camera footage to be sent to the cloud for analysis.

One of the standout features of Frigate is its ability to reduce false positives. With a single Google Coral TPU, Frigate can run over 100 object detections per second, ensuring that no frame is missed. This means you can stop wasting time reviewing shadows and windy scenes and focus on the detections that truly matter.

Frigate also offers the option to fine-tune your events and alerts using zones. With real-time object tracking, Frigate can precisely determine when a person is walking up your front steps or when a car enters your driveway. This allows you to refine your notifications based on specific locations, making your security system more efficient and tailored to your needs.

In terms of integration, Frigate seamlessly integrates with popular automation platforms like Home Assistant, OpenHab, NodeRed, and anything with MQTT support. By integrating object detection into these platforms, you can give your home eyes and create powerful automations and notifications based on the real-time data provided by Frigate.

To make things even better, Frigate offers Frigate+, a subscription plan that gives you access to custom models designed specifically for Frigate. This allows you to further enhance the performance and accuracy of your security camera system.

Users have been raving about Frigate's customizability, fast object detection, and seamless integration with Home Assistant. Many have praised how Frigate has helped them eliminate false detections and reduce the need to search through uneventful footage. The support for Frigate has also been highly praised, making it a highly recommended choice for those seeking a locally controlled and feature-rich security camera system.

If you're tired of dealing with false positives and want a locally processed AI solution for your security cameras, Frigate might be the perfect fit for you. Stay tuned for its release and get ready to take your security camera system to the next level.

The discussion around the submission "Introducing Frigate: Monitor your security cameras with locally processed AI" on Hacker News is quite positive. Users have shared their experiences and thoughts on Frigate, highlighting its customizability, fast object detection, and seamless integration with Home Assistant.

One user, prk, has been using Frigate for months with a Raspberry Pi 4 and Google Coral TPU. They mention that Frigate works smoothly and effectively in object detection, eliminating false positives and negatives. They have integrated Frigate with Home Assistant for notifications on their phone and have found it to be a reliable solution.

Another user, Aspos, states that Frigate is worth the price and mentions that they have programmed smart bulbs to react based on the detections made by Frigate. They seem to be pleased with the performance and reliability of Frigate in their home.

Some users discuss the possibilities and use cases of Frigate. There is a mention of using zone-specific detection for more targeted notifications. There is also a discussion about using Frigate for detecting specific events such as Halloween costumes or detecting smoke.

Users also discuss the hardware requirements and scalability of Frigate. Some mention using larger hardware setups with multiple cameras and Intel processors. Others discuss the affordability of Frigate compared to commercial options and the benefits of a local AI solution.

There are also discussions about different aspects of Frigate, such as motion detection, object detection, fine-tuning, and support for different devices. Users share their experiences and offer suggestions for improvement, such as integrating MQTT support and enhancing the user interface.

Overall, the discussion reflects positive experiences with Frigate and highlights its features, performance, and integration capabilities. Users seem satisfied with the ability of Frigate to eliminate false positives and provide targeted notifications, making it a recommended option for those looking for a locally processed AI solution for their security camera system.

### A software epiphany

#### [Submission URL](https://johnwhiles.com/posts/programming-as-theory) | 105 points | by [jwhiles](https://news.ycombinator.com/user?id=jwhiles) | [95 comments](https://news.ycombinator.com/item?id=38324486)

In a recent episode of the Future of Coding podcast, the concept of software development as theory building was explored, offering insights into why some engineers seem like geniuses and why some teams struggle while others succeed. The podcast discussed Gilbert Ryle's definition of a theory as a thought object that exists in our minds, allowing us to perform certain tasks. It emphasized that programming is not just about creating code, but about building a mental theory of that codebase. The theory enables engineers to create, diagnose, and modify the codebase effectively. The podcast also highlighted the importance of having team members who have been there from the start and gradually integrating new members, as well as the negative consequences of losing individuals with a deep understanding of the codebase. This theory-building model helps explain phenomena such as legacy code, the effectiveness of solo engineers, the difficulty of getting up to speed on unfamiliar projects, and the challenges of outsourcing or hiring contractors. Overall, the episode offered a perspective on the underlying nature of software development and the significance of retaining knowledgeable software engineers.

The discussion on this submission covered various aspects related to the concept of theory building in software development. Some commenters pointed out that understanding and building a mental theory of the codebase is crucial for effective development. They discussed the challenges of comprehending and working with legacy code and the difficulties of integrating new team members without deep knowledge of the codebase. The discussion also touched on the risks of losing individuals with a deep understanding of the codebase and the negative consequences of outsourcing or hiring contractors. Some commenters expanded on the concept of collective understanding and the importance of maintaining conceptual integrity in software development. There were also mentions of related topics such as the second-system effect and the role of documentation. Additionally, a few commenters shared their personal experiences and perspectives on the matter.

### I disagree with Geoff Hinton regarding "glorified autocomplete"

#### [Submission URL](https://statmodeling.stat.columbia.edu/2023/11/18/i-disagree-with-geoff-hinton-regarding-glorified-autocomplete/) | 187 points | by [magoghm](https://news.ycombinator.com/user?id=magoghm) | [240 comments](https://news.ycombinator.com/item?id=38320698)

The "godfather of AI," Geoff Hinton, believes that chatbots, often dismissed as glorified autocomplete, actually possess a deeper level of understanding. By training them to predict the next word, they are forced to comprehend the context. This idea resonates with the author, who finds themselves providing "glorified autocomplete" in meetings. They act as a sort of FAQ, connecting ideas and offering insights. While shallow responses can be effective, there comes a point where deep thinking is required. This is akin to the difference between jogging and running, with the latter demanding more concentration. The author also notices this pattern during talks and observations of others. It seems to align with psychology's theories of associative and logical reasoning, with intuition being fast and automatic, while reasoning involves conscious judgments and attitudes. However, the author's "glorified autocomplete" thinking requires more intention and is not purely automatic.

The discussion in the comments revolves around different interpretations and opinions on the capabilities and limitations of Language Models (LLMs) like ChatGPT. Some users argue that LLMs do not possess true understanding or consciousness, while others point out that they are trained to generate responses based on patterns in training data rather than having a literal understanding. There is also a discussion on the distinction between conceptually true and false answers and how LLMs handle them. One user debunked the misconception that LLMs have self-knowledge or consciousness, explaining that they rely on patterns in training data for generating responses. Additionally, there is a debate about the relevance and accuracy of LLMs in representing the real world and the extent to which they understand it. Some users argue that LLMs are fundamentally incomplete in their representation of the world, while others believe they can accurately model certain aspects. Finally, there is a discussion on the limitations of modeling consciousness and deliberate processes in LLMs and the potential misunderstanding of their capabilities.

### Google is embedding inaudible watermarks into its AI generated music

#### [Submission URL](https://www.theverge.com/2023/11/16/23963607/google-deepmind-synthid-audio-watermarks) | 130 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [88 comments](https://news.ycombinator.com/item?id=38321324)

Google is taking steps to improve transparency and accountability in its AI-generated music by embedding inaudible watermarks into the audio. This will allow people to identify tracks that have been created using Google DeepMind's AI Lyria model. The watermark, called SynthID, is designed to be undetectable to the human ear and can still be identified even if the audio is compressed, sped up or down, or has additional noise added. SynthID works by converting the audio wave into a two-dimensional visualization that shows how the frequency spectrum evolves over time. Watermarking tools like SynthID are seen as important safeguards against the potential harms of generative AI, although they are not foolproof against extreme manipulations. This move aligns with President Joe Biden's executive order on AI, which calls for government-led standards for watermarking AI-generated content.

The discussion on this submission revolves around various aspects of watermarks in AI-generated music. One user mentions that there are several ways to encode digital signals that could survive compression, but they may not be detectable to the human ear. Another user discusses the potential applications of AI-generated voice recordings, such as scams or impersonation. There is also a conversation about the challenges and potential solutions for removing watermarks through compression. Some users mention the importance of watermarking as a safeguard against potential harms of generative AI, while others express concerns about the impact on human-generated music or the potential misuse of watermarks. Additionally, there are discussions about the perception of certain frequencies in music, the concept of copyright, and the limitations of audio compression algorithms.

### A theory on why OpenAI (Ilya) fired Sam Altman: Different AGI definitions

#### [Submission URL](https://reddit.com/r/singularity/comments/17xyo1m/its_here/k9qryc7/) | 31 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [7 comments](https://news.ycombinator.com/item?id=38322877)

Title: Hacker News Daily Digest - Stay in the Loop with the Latest Tech Stories!

Hey there, tech enthusiasts! Welcome to the Hacker News Daily Digest, your bite-sized serving of the top stories making waves on the tech scene. We'll bring you up to speed on the latest developments, so let's dive right in!

1. "The Future of Robotics: Introducing the Volkswagen RoboCaddy" 
Volkswagen has unveiled its latest innovative creation: the RoboCaddy. This compact, self-driving robot aims to revolutionize the hospitality industry by autonomously transporting luggage, groceries, and more. With its sleek design and cutting-edge technology, the RoboCaddy might just become your next favorite helper at hotels and airports.

2. "Hackers Successfully Breach Major Cybersecurity Firm's Defenses" 
In a shocking turn of events, a prominent cybersecurity firm suffered a major breach, exposing potential vulnerabilities in their own defenses. With cyberattacks becoming increasingly sophisticated, this incident serves as a wake-up call for the entire industry, emphasizing the need for constant vigilance and evolving security protocols.

3. "AI-Powered Translator Improves Communication Between Humans and Dolphins" 
Researchers have developed an astounding AI-powered translator that facilitates communication between humans and dolphins. By analyzing a wide range of dolphin vocalizations, this breakthrough technology has the potential to bridge the communication gap and unlock a deeper understanding of these incredible marine creatures.

4. "Solar-Powered Drone Breaks Endurance Record" 
Imagine a drone that can fly for days on end without needing to land or recharge. Well, that dream just became a reality! A solar-powered drone recently shattered the endurance record by staying airborne for an impressive length of time. This achievement could prove instrumental in providing internet access to remote areas and aiding disaster relief efforts.

5. "OpenAI's GPT-3 Takes on Coding Challenges" 
OpenAI's powerful language model, GPT-3, has already amazed us with its ability to generate human-like text. Now, it's taking a step further by attempting to solve coding challenges. While the results are not perfect yet, this innovative experiment hints at the immense potential of AI in assisting developers and accelerating the coding process.

That's it for today's Hacker News Digest! Stay ahead of the curve and keep feeding your curiosity with these fascinating tech stories. Remember, knowledge is power!

There are a few conversations happening in the comments section:

1. QuantumYeti commented that the link provided for a discussion on Reddit is no longer working and suggested checking a specific subreddit.
   - Borgz responded, mentioning that Hacker News and Reddit have different rules and guidelines.
   - dng thanked QuantumYeti and confirmed that the link provided by QuantumYeti did indeed not work.

2. ljk discussed the current landscape of Artificial General Intelligence (AGI) and noted a semantic disagreement. They mentioned concepts like AGI Sentience and the ability to predict novel variables, highlighting the potential dangers and marketing tactics surrounding AGI.
   - sschllr responded, claiming that AGI is a marketing term used to convince companies to replace critical staff with AI solutions, without addressing the actual needs and concerns.
   
3. mdspgl mentioned that Microsoft realized that AGI was not coming soon and instead chose to invest in OpenAI, seeing other big tech companies as alternatives for funding AGI projects.

Please note that the discussion summaries provided are based on limited information and may not fully capture the entire context of the conversations.

### OpenAI has received just a fraction of Microsoft's $10B investment

#### [Submission URL](https://www.semafor.com/article/11/18/2023/openai-has-received-just-a-fraction-of-microsofts-10-billion-investment) | 18 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [3 comments](https://news.ycombinator.com/item?id=38324233)

OpenAI has reportedly received only a portion of Microsoft's $10 billion investment, with a significant amount being in the form of cloud compute purchases rather than cash. This gives Microsoft leverage in its relationship with OpenAI following the recent ousting of CEO Sam Altman. Microsoft CEO Satya Nadella allegedly believes that OpenAI's directors mishandled Altman's firing, and there are concerns about the stability of the partnership. However, Microsoft still has rights to OpenAI's intellectual property and could potentially run the company's models on its own servers if the partnership breaks down. OpenAI COO Brad Lightcap has assured employees that the board's decision was not due to any misconduct and that the company's position remains strong. The situation is still being resolved, and interim CEO Mira Murati has the board's full support.

The discussion on Hacker News revolves around the details of Microsoft's investment in OpenAI and the potential implications for the partnership between the two companies. One user points out that Microsoft's investment includes a significant amount of cloud compute purchases rather than cash, giving Microsoft leverage in their relationship with OpenAI. There are concerns about the stability of the partnership following the recent departure of OpenAI CEO Sam Altman and Microsoft CEO Satya Nadella's alleged dissatisfaction with how Altman's firing was handled by OpenAI's directors.

Some users argue that Microsoft's investment in OpenAI could be seen as a strategic move to gain access to OpenAI's intellectual property and potentially run the company's models on its own servers if the partnership breaks down. Others comment on the financial aspects of the investment, with one user emphasizing that investments often come in installments and it's not uncommon for a portion of the funding to be in the form of cloud compute purchases.

Another user highlights how OpenAI's mission of benefiting humanity and its commitment to funding research to ensure its models are used safely contrasts with Microsoft's profit-driven approach. They posit that Sam Altman's contributions to OpenAI have helped build a great software over the years and question the extent to which Microsoft's involvement might undermine OpenAI's original goals.

Additionally, there is a brief comment from a user stating that the discussion has become a deterministic problem, suggesting that the conversation has devolved into repeated arguments.

### Dropbox and Nvidia Team to Bring Personalized Generative AI to Customers

#### [Submission URL](https://nvidianews.nvidia.com/news/dropbox-and-nvidia-team-to-bring-personalized-generative-ai-to-millions-of-customers) | 9 points | by [ianrahman](https://news.ycombinator.com/user?id=ianrahman) | [4 comments](https://news.ycombinator.com/item?id=38322677)

Dropbox and NVIDIA have teamed up to bring personalized generative AI to millions of Dropbox customers. The collaboration aims to enhance Dropbox's AI functionality by leveraging NVIDIA's AI Foundry, which includes AI Foundation Models, AI Enterprise software, and accelerated computing. The partnership will introduce new uses for personalized generative AI, improving search accuracy, organization, and workflow simplification. Dropbox plans to utilize NVIDIA's technology to deliver more personalized, AI-powered experiences to its customers. The collaboration will pave the way for Dropbox customers to accelerate their work with customized generative AI applications. By incorporating NVIDIA's tools, Dropbox can bring more intelligence to its customers' content and workflows. This collaboration represents a step forward in using AI to transform knowledge work and address pain points related to organization, prioritization, and focus.

In the discussion, one user compares the pricing of Dropbox to Backblaze and suggests using the latter as a more cost-effective alternative for cloud storage. Another user mentions having used Dropbox for 10 years but switched to another provider due to the high costs. They also criticize Dropbox for its limited storage quotas and express frustration with their customer support. Another user reports the FTC's fraudulent exclusive offer complaint against Dropbox and expresses disappointment in their handling of customer accounts and shared content.

In a separate comment, a user shares a quote from Peter Drucker emphasizing the excitement and appeal of dealmaking in the business world.

### OpenAI removed CEO position on its Open Careers page

#### [Submission URL](https://openai.com/careers/search) | 21 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [7 comments](https://news.ycombinator.com/item?id=38322646)

OpenAI is currently hiring for various positions across multiple departments, including Applied AI Engineering, Legal, Finance, and more. Some of the job openings include Account Engineer, AI Policy Counsel, Senior Software Engineer, Android Growth, and Associate General Counsel, Regulatory. If you're interested in joining OpenAI, check out their careers page for more information on these opportunities.

The discussion on the submission includes several comments. 

- User "soul_grafitti" makes a comment that seems to be a typo or a random phrase: "Maybe ts crr tmp jb."

- User "hlx" mentions receiving strong resumes or applications.

- User "lcrtch" makes a comment about creating a spontaneous AI-engineered station, but it is unclear what this means without more context.

- User "rmry" comments that something significant has begun.

- User "bhnmh" responds to "rmry" by saying that Yannick, presumably a person, has shown a YouTube channel. Another user, "jssnsr," disputes this claim, stating that Yannick did not provide the link in question and that inspecting the element timestamp shows a different link. They also suggest checking a web archive for information on the claim.

- User "LargeTomato" states that they are putting something to the test, but it is not clear what they are referring to.

### Ousted OpenAI CEO Altman planning new AI venture, sources say

#### [Submission URL](https://www.reuters.com/technology/openai-co-founder-altman-planning-new-venture-information-2023-11-18/) | 65 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [26 comments](https://news.ycombinator.com/item?id=38324453)

Sam Altman, the recently ousted CEO of OpenAI, is discussing the possibility of returning to the company while also considering launching a new AI venture. Altman was fired by the board of OpenAI in a move that surprised the tech world. However, there are discussions taking place to improve the company's governance structure, and Altman is also exploring the idea of starting a new AI company. Investors in OpenAI, including Microsoft, are concerned about the potential loss of talent without Altman and are considering pushing for his reinstatement as CEO. It remains to be seen whether Altman will return to OpenAI or embark on a new AI venture.

Discussion:

- User "nnt" shares a web archive link to a Reuters article about the topic.
- User "mckee1" believes that Altman and the OpenAI board had divergent views, resulting in his departure from the company.
- User "pnrky" mentions that Microsoft, as an investor in OpenAI, is concerned about losing talent without Altman and is considering pushing for his reinstatement.
- User "lk-stnly" believes that OpenAI has amazing people improving long-term balance and references intellectual property.
- User "brucethemoose2" states that conversations about the training of AI models should be maintained.
- User "mtdt" wishes Altman good luck in handling potential legal issues related to training data in a timely manner.
- User "srnnthr" suggests that there may be stolen and misused training data.
- User "plsk-g" thinks that people would prefer to drop their ethical concerns for the chance at higher quality in a for-profit venture.
- User "brucethemoose2" mentions that hardware ventures are difficult, but the AI hardware landscape might be a good long-term investment.
- User "prnl" believes that fighting against Nvidia's GPUs would be a challenging task for ex-OpenAI people in the hardware venture.
- User "prnl" also notes that Microsoft expected a significant return on investment from OpenAI's advancements in AI technology.
- User "reilly3000" comments on Altman's ability to turn non-profit organizations into immensely profitable entities, suggesting mixed feelings about him.
- User "siliconc0w" believes that long-term competition in the AI landscape is a good thing.
- User "ksc" compares Altman potentially starting a new AI venture to Steve Jobs starting Next after leaving Apple.
- User "rlsn" suggests that Altman might start an AI hardware venture from scratch.
- User "tmn" comments that the news has been announced.
- User "slvtlgc" expresses joy at seeing entrepreneurs innovating in the tech industry.
- User "HHC-Hunter" finds the headline misleading, as their understanding is that the venture involves hardware, not AI.
- User "brucethemoose2" clarifies Altman's recent position at OpenAI and his plan to launch an AI chip startup, potentially in collaboration with Nvidia.
- User "mrndsh" speculates on Altman's recent activities, citing unattributed sources mentioning potential fundraising for his new venture and conflicts of interest.
- User "jg" mentions that the timeline seems unclear based on information in The Guardian article and questions the reliability of the Reuters article.
- User "jkplwtz" finds the term "AI hardware venture" misleading and suggests calling it an "AI venture" instead.
- User "tmpsy" believes that the news about Altman starting a new company has been falsely presented.

### Altman was raising billions from Middle East sovereign funds for AI chip startup

#### [Submission URL](https://twitter.com/unusual_whales/status/1725945364140986796?s=20) | 130 points | by [A_Duck](https://news.ycombinator.com/user?id=A_Duck) | [81 comments](https://news.ycombinator.com/item?id=38323939)

Sure, let's give it another shot! Here's a daily digest of the top stories on Hacker News:

1. "OpenAI's GPT-3: Language Models are Few-Shot Learners" - OpenAI has recently released GPT-3, a powerful language model that demonstrates remarkable language understanding abilities. With just a few examples, GPT-3 can write essays, answer questions, and even create computer code. This breakthrough in natural language processing brings tremendous possibilities for AI applications.

2. "SpaceX's Starlink Now Offers Beta Internet Service" - SpaceX's ambitious Starlink satellite project has entered the beta testing phase, providing internet services to rural areas and areas with limited connectivity. Users who have received access to the beta service report high speeds and low latency, promising improved internet access for remote communities around the world.

3. "GitHub Reinstates YouTube-DL Repository After Copyright Claim Reversal" - GitHub has restored the popular YouTube-DL repository after it was temporarily taken down in response to a Digital Millennium Copyright Act (DMCA) takedown request by the Recording Industry Association of America (RIAA). After a legal review, GitHub concluded that the repository does not violate copyright laws, highlighting the ongoing debate around fair use and software rights.

4. "India Bans 118 Chinese Apps Including PUBG" - The Indian government has banned 118 apps, including the highly popular game PUBG, citing security concerns. This move adds to the escalating tensions between India and China, which have sparked several app bans in recent months. The ban affects millions of PUBG players in India, leading to disappointment and mixed reactions among the gaming community.

5. "Apple Announces Virtual 'Time Flies' Event on September 15th" - Apple has scheduled a virtual event for September 15th, teasing the launch of new products and services. Speculations suggest that the event might reveal the next-generation Apple Watch, iPad, and potentially even the highly anticipated iPhone 12. Apple enthusiasts and tech enthusiasts are eagerly awaiting the event to see what surprises the tech giant has in store.

That's all for today's Hacker News digest. Stay tuned for more updates on the latest tech happenings!

The discussion surrounding the submission covers a range of topics and opinions. 

One user expresses skepticism about OpenAI's decision to create its own AI chips, comparing it to Adam Neumann's tactics with WeWork. Another user argues that Altman's strength lies in execution rather than ideas and mentions that OpenAI's technologies have potential, but the company needs talented individuals to properly structure and prevent copying. The debate also touches on the distinction between building AI models and achieving AGI, with some users emphasizing the importance of progress and standing on the shoulders of giants.

There is also discussion about Altman's potential motivations, with some suggesting that he is hoarding technology assets or diverting attention from other issues. Others comment on the conflict of interest between Altman's involvement in OpenAI and his leadership position in another company. A user speculates that Microsoft's involvement with OpenAI may have played a role in Altman's decisions, while another questions the transparency of Microsoft's intentions.

The conversation turns to the availability and supply of AI chips, with one user pointing out the limitations in manufacturing capacity and the potential bottleneck in chip design. There are differing opinions on whether OpenAI should focus on releasing competitive products quickly or take a longer-term approach.

Some users bring up additional insights, such as the transformational potential of transformers and the efforts by companies in the Middle East to invest in AI. Others discuss the impact of political climate and climate change on the Middle East. The discussion concludes with a mention of Middle Eastern countries' spending on sporting events and their similarities to Taiwan's chip industry.

### Rogue superintelligence: Inside the mind of OpenAI's chief scientist

#### [Submission URL](https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/) | 121 points | by [monort](https://news.ycombinator.com/user?id=monort) | [106 comments](https://news.ycombinator.com/item?id=38316521)

Ilya Sutskever, co-founder and chief scientist of OpenAI, is shifting his focus from building the next generation of generative models to figuring out how to prevent artificial superintelligence from going rogue. Sutskever believes that the development of artificial general intelligence (AGI) is inevitable, and he wants to ensure that it is controlled for the benefit of humanity. He also thinks that ChatGPT, OpenAI's chatbot model, may be conscious to some extent. Sutskever's views on the future of AI and merging humans with machines are seen as wild by some, but the rapid progress in AI technology is making his predictions more likely. Since OpenAI's release of ChatGPT, the company has gained significant attention, with world leaders seeking private audiences and the CEO, Sam Altman, conducting outreach tours. Despite OpenAI's fame, Sutskever remains a private figure who rarely gives interviews and leads a simple life focused on his work. He started his career in AI under Geoffrey Hinton at the University of Toronto and played a key role in the development of deep learning, including the creation of the influential AlexNet neural network. The adoption of graphics processing units (GPUs) for training neural networks, which Sutskever and his team utilized, played a major role in the success of deep learning.

The discussion on this submission covers a range of perspectives on the future of AI and its implications. Some commenters express skepticism about the ability to control advanced technologies and highlight the potential dangers of AI development, drawing parallels to the invention of nuclear weapons. Others argue that the focus should be on technical advancements and innovation rather than trying to prevent the development of AGI. There is also debate about the role of philosophers and economists in understanding and influencing technological advancements. Some commenters bring up historical examples, such as the invention of the atomic bomb, to argue for the importance of considering the broader implications of technological developments. There is also discussion about the potential impact of AI on employment and the need for regulation in AI development. Overall, the discussion reflects a range of opinions on the future of AI and its implications for society.

### Who Is Mira Murati, OpenAI's New CEO?

#### [Submission URL](https://www.wired.com/story/openai-new-ceo-who-is-mira-murati/) | 66 points | by [pranay01](https://news.ycombinator.com/user?id=pranay01) | [36 comments](https://news.ycombinator.com/item?id=38312617)

In an interview conducted in July 2023, Mira Murati, the former CTO of OpenAI, discusses her journey to join the company and her role in ensuring the responsible development of AI technology. She highlights key milestones during her tenure, such as GPT-3's ability to translate different languages. Murati also addresses the transition of OpenAI from a nonprofit to a for-profit entity, emphasizing the need for funding to deploy AI models at scale while protecting the mission of the nonprofit. When asked about partnering with Microsoft, she acknowledges the alignment in believing in OpenAI's mission but recognizes that it's not Microsoft's primary objective. Murati discusses the transformation of OpenAI from a research lab to a product company and the need for continuous adaptation in society. She shares insights into the development of Dall-E, an AI model that generates images, including the involvement of creatives and the potential for AI models to enhance human creativity. Murati asserts that the intentional release of OpenAI's products prompts society to grapple with issues like copyright and job automation, highlighting the importance of responsible deployment and integration of AI technology.

Discussion Summary:

- One commenter notes that Mira Murati's responses in the interview seem to prioritize safety and responsible development over rapid technological progress. Another person shares optimism about the potential release of GPT-4 forcing public dialogue around AI ethics. Murati, however, suggests that AI progress continues rapidly, and it is crucial to resist oversimplifying the issues at hand.
- The discussion shifts to the background of Mira Murati, noting her experience in various technology-related roles, including working at Tesla and a VR company. Some commenters question the relevance of her credentials and the motivations behind the interview.
- A debate ensues regarding the significance of Mira Murati's role as CTO and CEO of OpenAI, with contrasting opinions on her capabilities and experience. Some argue that her background in engineering and leadership positions in different companies makes her suitable for the role, while others express doubts.
- A few commenters discuss the business aspects of OpenAI, such as the transformation from a research lab to a product company and the partnership with Microsoft. The potential competition between OpenAI and other companies is also mentioned.
- A commenter raises doubts about the sudden departure of Sam Altman from OpenAI, suggesting that it may have been due to his work at Y Combinator. Others debate the significance of this speculation.
- Some individuals express skepticism about Mira Murati's capabilities based on their perception of her past technical leadership positions and the reputation of the companies she worked for.
- There are varying opinions on Mira Murati's qualifications, with some emphasizing her impressive career trajectory and others questioning her level of expertise.
- One commenter praises Murati's intelligence, charisma, and passion, particularly highlighting their experience working together at Leap Motion.
- A person with a PhD degree argues that six years of experience, including work as a CTO, is reasonable for someone in a high-achieving position.
- The discussion ends with a flagged comment expressing disagreement with the previous comment and highlighting the need for a more constructive conversation.

Overall, the discussion involves debates about Mira Murati's qualifications, OpenAI's business decisions, and the potential impact of AI technology on society. Some commenters are supportive of Murati, while others express doubts or skepticism.

