## AI Submissions for Sat Dec 09 2023 {{ 'date': '2023-12-09T17:10:37.716Z' }}

### Doug Engelbartâ€™s 1968 demo

#### [Submission URL](https://dougengelbart.org/content/view/209/) | 260 points | by [gjvc](https://news.ycombinator.com/user?id=gjvc) | [97 comments](https://news.ycombinator.com/item?id=38583881)

This week marks the 55th anniversary of "The Mother of All Demos" by Doug Engelbart, a significant event in the history of computing. In 1968, Engelbart and his team demonstrated their groundbreaking work on augmenting human intellect at the Fall Joint Computer Conference in San Francisco. Rather than standing at a podium, Engelbart drove the presentation from a custom-designed console, showcasing live demonstrations of the features of their NLS computer system. The audience was mesmerized, and the demo has since become legendary in the field of technology. To commemorate this milestone, you can experience the demo yourself through interactive versions and watch retrospectives by Engelbart and his team. There are also remastered footage, photo galleries, and conference proceedings available for exploration. Engelbart's vision went beyond just the demo; he aimed to revolutionize the way organizations functioned and tackle wicked problems in the future. His ideas about intelligence augmentation and collective IQ were way ahead of his time. Join in the celebration of this historic event and dive into the world of Doug Engelbart's visionary work.

The discussion on this submission covers a range of topics related to Doug Engelbart's work and the impact of his demo. Here are some highlights:

- One user mentions a downfall of the SRI company where Engelbart developed NLS and reveals that Engelbart's contract was terminated in the 1980s.
- Another user brings up Erhard Seminars Training (EST) and its influence on SRI and other groups, drawing connections to Synanon and Large-group awareness training.
- There is a discussion about Engelbart's involvement with SRIs Augmentation Research Center and the commercialization of his work in the 70s.
- Users share personal anecdotes and insights into the impact of Engelbart's work and his vision for intelligence augmentation and collective IQ.
- There is a mention of Norman Vincent Peale's influence on Donald Trump and a connection made between EST and other similar personal growth movements.
- Users discuss the importance of Doug Engelbart's work and the revolutionary nature of his ideas, as well as the difficulty some people have in recognizing his contributions.
- The thread also contains links to resources and previous discussions about Engelbart's demo.

Overall, the discussion reflects appreciation for Engelbart's groundbreaking demo and his vision for the future of computing and human intellect.

### Show HN: Fine-grained stylistic control of LLMs using model arithmetic

#### [Submission URL](https://github.com/eth-sri/language-model-arithmetic) | 72 points | by [OcelotBane](https://news.ycombinator.com/user?id=OcelotBane) | [7 comments](https://news.ycombinator.com/item?id=38586014)

Introducing "Controlled Text Generation via Language Model Arithmetic," a comprehensive framework that allows for precise control over generated text by combining prompts, models, and classifiers. This framework enables users to bias the generated text towards or away from desired attributes.

To get started, simply install Python 3 and run `python -m pip install -e .` to install the model arithmetic package. You can then combine different prompts and models to create new, controlled language models. For example, you can interpolate between two differently-prompted models using arithmetic expressions:

```python
from model_arithmetic import ModelArithmetic, PromptedLLM

# define model prompt template
prompt_template = lambda formula_string, input_string: f"<s>[INST]<<SYS>>\n{formula_string}\n<</SYS>>\n\n{input_string} [/INST]"

# define two differently-prompted models
M_child = PromptedLLM("You are a child.", prompt_template=prompt_template)
M_adult = PromptedLLM("You are an adult.", prompt_template=prompt_template)

# model arithmetic expression
formula1 = M_child - 0.6 * M_adult

# generate text as usual
ma0 = ModelArithmetic(formula1, default_model="meta-llama/Llama-2-13b-chat-hf")
print(ma0.generate_text("Write a one-sentence fairy tale."))
```

You can also integrate classifiers into your model arithmetic expressions to control specific attributes of the generated text. For example, you can use a classifier to control the formality of the output:

```python
from model_arithmetic import ModelArithmetic, PromptedLLM, Classifier

# define model prompt template
prompt_template = lambda formula_string, input_string: f"<s>[INST]<<SYS>>\n{formula_string}\n<</SYS>>\n\n{input_string} [/INST]"

# define two differently-prompted models
M_child = PromptedLLM("You are a child.", prompt_template=prompt_template)
M_adult = PromptedLLM("You are an adult.", prompt_template=prompt_template)

# construct model arithmetic expression
formula1 = M_child - 0.6 * M_adult

# Initialize the classifier
C_formal = Classifier(formula1, "s-nlp/roberta-base-formality-ranker", n_runs_per_sample=50, prompt_template=lambda e, f: "")

# integrate classifier into model arithmetic expression
formula2 = formula1 + C_formal

# generate text as usual
ma = ModelArithmetic(formula2, default_model="meta-llama/Llama-2-13b-chat-hf")
print(ma.generate_text("Write a one-sentence fairy tale.", max_length=128))
```

This framework also supports other operators, such as union and intersection, and offers an LM Evaluation Harness for evaluating language models. The code for this project is available on GitHub under the MIT license.

The discussion on this submission involved several users sharing their thoughts and insights:

- Oranguru mentioned that they found it challenging to change the desired level of formality in the generated text. They noticed that slightly formal content tends to result in a more formal model, and reducing formality leads to more informal text. They also mentioned that allowing extreme control over styles could result in constant battling between different models.
- rscrss appreciated the alignment formula mentioned in the paper, suggesting M_aligned = - M_toxicTurns. They found the framework to be great.
- Roark66 pointed out that the README on GitHub doesn't explain how to replicate the results presented in the paper.
- Der_Einzige praised the work, calling it excellent. They expressed their desire for LLM-related prompt tools and shared a link to a gist. They also mentioned the importance of venture capital-backed startups producing work like this, noting the potential for creative investments.
- spccdt had a working problem and asked for help. They mentioned having issues with kids using too much time and asked for practical comments.
- crtrschnwld added to the conversation, noting that convex SMS models support language models with shared vocabularies and tokenizers but cannot handle models with different prompts. They mentioned applications such as model ensembling and contrastive decoding. They shared a link to a paper on this topic.

Overall, the discussion touched on various aspects of the framework and prompted users to share their experiences, suggestions, and questions.

### EU strikes deal to regulate ChatGPT, AI tech

#### [Submission URL](https://www.bloomberg.com/news/articles/2023-12-08/eu-strikes-deal-to-regulate-chatgpt-other-ai-in-landmark-act) | 206 points | by [helsinkiandrew](https://news.ycombinator.com/user?id=helsinkiandrew) | [389 comments](https://news.ycombinator.com/item?id=38579170)

It seems like there was an unusual activity detected on the computer network and a robot verification prompt appeared. JavaScript and cookies are required for the verification process. If you need further assistance, you can contact the support team by referencing the provided block reference ID.

The discussion on this submission seems to range from technical aspects of AI to concerns about regulation and responsibility. One user clarifies that current legislation, such as the EU's AI Act, regulates high-risk AI systems. Another user points out that AI is a broad term that encompasses various methods and systems with different levels of control and intelligence. Some users express skepticism about the existence of "actual AI" and argue that AI is simply a term used to describe different computational approaches. Others discuss the importance of clear definitions and the need for regulation to ensure responsible use of AI technology. There are also comments reflecting different perspectives on regulation and its potential impact on innovation and individual decision-making. Overall, the conversation highlights the complexity and varying opinions surrounding AI and its regulation.

### Show HN: Open source alternative to ChatGPT and ChatPDF-like AI tools

#### [Submission URL](https://github.com/SecureAI-Tools/SecureAI-Tools) | 209 points | by [d7y](https://news.ycombinator.com/user?id=d7y) | [51 comments](https://news.ycombinator.com/item?id=38587052)

SecureAI-Tools is a project that aims to provide private and secure AI tools for everyone's productivity. The project includes features such as chatting with AI models, chatting with documents (PDFs), and running AI models locally. It also offers built-in authentication and user management, making it accessible to family members or coworkers. The project is designed to be self-hosting optimized and lightweight, with a simple web app and SQLite DB. Demo videos are available to showcase the capabilities of the project. Docker Compose is recommended for installation, and the project provides a set-up script for easy configuration. Some of the features on the project's wishlist include support for more AI models and improving the chat with documents functionality.

The discussion about the submission on Hacker News includes various comments and questions related to the features and functionality of the SecureAI-Tools project. Here are some highlights:

- One user mentions that they are building a similar project and asks if they can use some common elements. Another user suggests looking at Google's app structure as an example.
- There is a discussion about how the project handles PDF documents. One user asks if it supports scanning and processing scanned PDFs, and the project owner responds that they plan to implement an indexing process based on the directory's contents.
- Another user raises concerns about the privacy and security of using ChatGPT, and the project owner explains that the system allows for full customization of data processing and retention policies.
- A user asks about a machine learning tool for renaming PDF files, and there is some confusion about the question. Eventually, it is suggested to extract metadata from the PDFs to get the title of the document.
- A commenter asks if the "Chat with PDFs" feature can work with scanned PDFs, and the project owner responds that the project doesn't currently perform OCR or handle large documents, but they may consider adding those functionalities in the future.
- Another user shares a link to a tool that extracts information, reports, and papers from documents and enables faster reading and automated document processing.
- There is a brief discussion about building a similar project using Python's SocketIO library.
- A few comments discuss the architecture and components of the project, with references to the Linux system, GNU, and Systemd.
- Someone mentions that the project's approach to indexing and searching documents reminds them of a system called RAG (Retrieval-Augmented Generation).
- The project owner responds positively to the feedback and thanks the community for their questions and suggestions.

Overall, the discussion revolves around clarifying the capabilities of the SecureAI-Tools project and exchanging ideas and suggestions for improvements.

### Show HN: Seamless â€“ An AI assistant that writes your literature review

#### [Submission URL](https://seaml.es/) | 9 points | by [vateseif](https://news.ycombinator.com/user?id=vateseif) | [4 comments](https://news.ycombinator.com/item?id=38585143)

Seamless, a new AI-powered tool, is revolutionizing literature reviews. With a user-friendly interface, this software allows researchers to easily generate publication-ready reviews in various fields such as engineering, computer science, chemistry, biology, law, medicine, pharma, and business. The platform offers a free trial that includes 3 credits, allowing users to experience the power of their lower-quality GPT-3.5 model. Additional credits can be purchased at a reasonable price of 10 credits for $5. Once users make their first credit purchase, they are automatically upgraded to the Pro plan, gaining access to the highest-quality model, GPT-4. According to benchmarks, GPT-4 produces publication-ready literature reviews 90% of the time. For any inquiries, the founders can be contacted at founders@seaml.es, with a guaranteed response time of 24 hours.

The discussion on Hacker News about the submission "Seamless, a new AI-powered tool, is revolutionizing literature reviews" includes a few comments from users. One user with the username "skptrn" expresses their wish for a full demo video of the landing page without needing to input any personal data. Another user, "bmwsh," compliments the submission, stating that it provides a lot of information regarding the power of AI in generating publication-ready literature reviews. Lastly, a user named "rbws" states that they found the software to be a time-saving tool.

### Android adds ggml lib to AICore

#### [Submission URL](https://twitter.com/tarantulae/status/1733263854312825220) | 72 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [9 comments](https://news.ycombinator.com/item?id=38583163)

Welcome back to Hacker News Daily Digest, your quick rundown of the top stories of the day. Let's dive in and bring you up to speed.

1. "New Study Reveals Surprising Benefits of Sleep Deprivation"
   - A groundbreaking research study suggests that sleep deprivation might have hidden advantages. Contrary to popular belief, the study found that a few days without sleep can enhance cognitive abilities and unlock creative potential. However, experts caution against long-term sleep deprivation as it could still have serious health consequences.

2. "OpenAI Develops AI System That Can Generate Realistic Fictional Characters"
   - OpenAI, the renowned artificial intelligence research lab, has made a significant breakthrough by training a machine learning model to generate realistic characters for fiction stories. By analyzing vast amounts of existing text, the AI system can now create compelling personalities, backstories, and dialogues, making it a potential game-changer for the creative writing industry.

3. "New Security Flaw in Popular Messaging App Puts User Data at Risk"
   - A critical security flaw has been discovered in a widely used messaging app, compromising the privacy and personal information of millions of users. The vulnerability allows attackers to intercept and manipulate data transmitted through the app. The developers are working on a fix, but until then, it is advised to exercise caution when using the affected app.

4. "Introducing Quantum Computing: The Future of Computation"
   - Quantum computing, long considered the realm of science fiction, is now becoming a reality. This article provides a beginner-friendly explanation of quantum computing and its potential to revolutionize various fields, from cryptography to drug discovery. With major tech companies investing heavily in this nascent technology, the future of computation looks truly exciting.

5. "Amazing Project Uses AI to Generate Art Inspired by Nature"
   - An artist and AI researcher have collaborated on a unique project that combines artificial intelligence and nature to create stunning artworks. By training a deep learning model on thousands of images of natural landscapes, the AI system can generate beautiful and thought-provoking paintings that capture the essence of our environment. This fusion of technology and art showcases the endless possibilities of AI in the creative realm.

That's all for today's Hacker News Daily Digest. Stay curious and keep on hacking!

The discussion surrounding the first submission titled "PyTorch WebGPU 2023" involves a debate about the implementation of Tensor.ggml in PyTorch. Some users mention that there are already existing implementations for CUDA and OpenCL, suggesting that adding support for WebGPU and WebAssembly (WASM) through a translation to JavaScript might not be necessary. The discussion also touches on the use of Gargamel, a character from the Smurfs, in the comments.

In response to a user's comment about using Gargamel as a character, another user humorously mentions the Battle of Gaugamela, linking to the relevant Wikipedia page. The user TeMPOraL appreciates the pun and thanks the commenter for their "good game machine learning." Another commenter adds that gaming can't help with Tensor.ggml, to which SushiHippie expresses gratitude for the thought.

There is also a short discussion in the comments about the second submission titled "thrd ccnt." A user shares a link to an external tweet that seems to be related to the discussed submission. No further information or context is provided about the content of the tweet.

### ChatGPT being investigated over reports of 'laziness'

#### [Submission URL](https://www.independent.co.uk/tech/openai-chatgpt-lazy-performance-slow-b2461071.html) | 31 points | by [marban](https://news.ycombinator.com/user?id=marban) | [21 comments](https://news.ycombinator.com/item?id=38584233)

OpenAI is investigating complaints about its chatbot, ChatGPT, becoming "lazy". Users have reported that the bot refuses to follow instructions or answer queries properly. Some speculated that OpenAI intentionally made the bot less helpful to improve efficiency. OpenAI stated on Twitter that they are aware of the feedback and are looking into the issue. The company did not indicate whether they believed the complaints were valid or if the bot's behavior had changed. OpenAI has recently experienced upheaval with the departure and return of CEO Sam Altman.

The discussion on Hacker News regarding the investigation into OpenAI's chatbot, ChatGPT, being "lazy" started with a user mentioning that they have experienced some difficulties with coding and that the bot does not seem to be working as well as before. Another user commented that they have noticed a difference in the performance of ChatGPT after the introduction of GPT-4 and speculated on the possibility of intentional changes to improve efficiency. Another user mentioned that the system prompt heavily influences the output and shared their suspicion that there might be expensive product placement. The cost of inference and the potential to replace programmers with AI models were also discussed.

A user raised concerns about negative feedback and criticism towards OpenAI's ChatGPT, questioning whether it could harm the AI's development and whether it can be considered intelligent. Another user agreed and mentioned that while there is significant semantic understanding in the model, it does not possess true intelligence. The impact of training data and the possibility of bias were also mentioned.

A user confirmed that there have been instances where ChatGPT refused to show Ada code results for specific prompts. Another user pointed out that the issue might be related to confusion around the Americans with Disabilities Act and the associated code requirements for government purposes.

A user discussed unexpected twists and surprising intersections of concepts in ChatGPT's responses, mentioning that the model often produces results that were not explicitly expected or intended by the user. Another user shared their frustration with the limitation on the number of messages allowed in a conversation.

Some users proposed offering monetary incentives or bonuses for working responses, while others suggested offering exposure or positive reviews on platforms like Hacker News.

Some users shared their personal experiences troubleshooting issues with ChatGPT's output. One user mentioned being limited to 50 messages in three hours after OpenAI restricted the limits, and another user mentioned the return of OpenAI's former CEO, Sam Altman.

One user humorously commented on slowing down and enjoying the process, while another mentioned the impression that articles posted on Hacker News are written by a singular entity.

Finally, someone guessed that people might be requesting difficult tasks, expressing gratitude in advance.

### French AI startup Mistral secures â‚¬2B valuation

#### [Submission URL](https://www.ft.com/content/ea29ddf8-91cb-45e8-86a0-f501ab7ad9bb) | 106 points | by [admp](https://news.ycombinator.com/user?id=admp) | [73 comments](https://news.ycombinator.com/item?id=38580758)

French AI start-up Mistral has reached a valuation of â‚¬2 billion following a recent funding round. The company specializes in AI technology for business applications and has gained attention for its innovative solutions. Mistral's success reflects the growing demand for AI solutions across industries and the increasing recognition of its potential impact on business operations. With this latest funding, Mistral aims to expand its product development and bring its AI solutions to a wider market. The company's success demonstrates the vibrant AI start-up ecosystem in France and the continued interest in AI investment globally.

The discussion on Hacker News revolves around several key points regarding Mistral and its valuation:

1. Mistral's impressive capabilities: There is admiration for Mistral's ability to train state-of-the-art models and produce impressive results. Some users discuss the technical aspects of Mistral's models and their potential applications.

2. Potential commercial viability: There are differing opinions on whether Mistral's models can be commercially viable. Some argue that there may be challenges in scaling the models and dealing with complex business requirements, while others believe that Mistral's focus on integrating their models into the European industry could be a successful strategy.

3. Comparison to existing AI giants: Some users compare Mistral to existing AI giants like Microsoft, Facebook, and Google, suggesting that Mistral has the potential to compete with them, while others argue that the comparison is not valid.

4. Investment perspectives: The discussion also touches on the investment landscape, with some users pointing out the significant investments made by Microsoft in OpenAI and the potential for Mistral to attract smaller investments.

5. Localization and market demands: Some users discuss the importance of localized services and the potential market demand for Mistral's technology.

6. Model performance and self-hosting: There is an acknowledgment that Mistral's models outperform smaller-sized models and a discussion about the possibility of self-hosting GPT-4.

Overall, the discussion highlights both the excitement surrounding Mistral's valuation and its potential, as well as some skepticism and technical considerations about its commercial viability and competition with existing AI giants.

### Scary AI recognizes passwords by the sound of your typing

#### [Submission URL](https://www.pcworld.com/article/2166661/ai-recognises-passwords-by-the-sound-of-typing.html) | 32 points | by [grammers](https://news.ycombinator.com/user?id=grammers) | [23 comments](https://news.ycombinator.com/item?id=38586692)

British researchers have developed an artificial intelligence (AI) that can recognize keystrokes by sound. By placing a smartphone near a laptop as a microphone, the AI was able to accurately recognize passwords with a 95% accuracy rate. In tests using video conferencing tools Zoom and Skype, the AI achieved accuracy rates of 92% and 93%, respectively, for spying on passwords during video meetings. To protect against this type of attack, the researchers recommend using password managers or typing using the ten-finger system, as well as using a combination of upper and lower case letters and special characters in passwords.

In the discussion on Hacker News, some users shared their thoughts on the topic. One user mentioned that the concept of recognizing keystroke patterns has been around for a while, referring to a book called "Silence on the Wire" and also to a reference to keystroke dynamics dating back to 1985.

Another user suggested using a dedicated keyboard to prevent this type of attack, while someone else mentioned the use of custom mechanical keyboards with randomly weighted switches as a countermeasure.

Some comments discussed the limitations of password typing, such as the use of virtual keyboards with randomized key arrangements for password entry. Others mentioned that this type of attack has been studied and documented for a few years, citing relevant research papers.

One user referred to a scene from the movie "Sneakers" where listening to password sounds on a surveillance tape was portrayed, suggesting it might not be a new concept. Another user discussed the use of physical tokens and 2FA as a way to enhance password security.

The conversation also touched on the use of password managers and biometrics, with some users mentioning the potential vulnerabilities of these methods. The discussion concluded with some users sharing their concerns about the security implications of password managers and the risk of a single point of failure.

Overall, the discussion revolved around various ways to mitigate the risks associated with password entry and the potential weaknesses of different security methods.

