## AI Submissions for Fri Apr 12 2024 {{ 'date': '2024-04-12T17:09:38.807Z' }}

### Lessons after a Half-billion GPT Tokens

#### [Submission URL](https://kenkantzer.com/lessons-after-a-half-billion-gpt-tokens/) | 44 points | by [lordofmoria](https://news.ycombinator.com/user?id=lordofmoria) | [13 comments](https://news.ycombinator.com/item?id=40015185)

In a recent blog post by Ken Kantzer, the CTO of Truss, he shared some insights after processing over 500 million GPT tokens for their startup. Here are some key takeaways:
Lesson 1: Less is more when it comes to prompts. Ken discovered that being less specific in prompts often led to better results as GPT performed well when given vague instructions. For example, asking GPT to simply provide the full name of a state instead of specifying detailed instructions improved performance.
Lesson 2: Ken found that using just the chat API from OpenAI was sufficient for their needs, highlighting that additional features like langchain were unnecessary. Keeping it simple with a single function for extracting JSON data proved to be effective.
Lesson 3: Implementing a streaming API and displaying variable-speed typed characters to users improved the user experience significantly, showcasing the potential of this approach as a UX innovation.
Lesson 4: GPT struggled with returning nothing if it couldn't find relevant information, often opting to hallucinate rather than providing a blank output. This led to instances where GPT generated random bakery names when faced with empty text blocks.

Overall, Ken's experiences shed light on optimizing the use of GPT models for text-based tasks, emphasizing the importance of effective prompts and keeping the workflow straightforward for better outcomes.

The discussion on the Hacker News post delves into different aspects of the insights shared by Ken Kantzer from Truss regarding their experience with processing GPT tokens. Here are some key points raised by the community:

1. **thsgsnwhr** highlighted the challenges faced in abstracting the prompts and the issues with hallucinations from the model. They mentioned the similarity with the evolution of DevOps in the 2000s, emphasizing the need for simplicity in implementing solutions.
2. **tmpz22** agreed with the comparison to DevOps, pointing out the trade-offs and complexities involved in modern development workflows.
3. **mvkl** brought attention to GPT's difficulty in handling null outputs, suggesting specific string-matching treatments for better results.
4. **CuriouslyC** discussed the expensiveness of utilizing model training for substantial prompts and the importance of providing conclusive statements rather than hypotheses.
5. **trln** shared personal experiences of using Langchain for tasks efficiently and switching between models for validation.
6. **gnvl** commended the capabilities of Claude3 and Langchain in handling contextual nuances effectively, highlighting the practical problem-solving aspects of these tools.
7. **dsqrd** mentioned encountering issues with data retrieval but successfully resolving them with ChatGPT's assistance.
8. **KTibow** pointed out that extracting JSON data might be more suitable for smaller language models for efficient generation and extraction.
9. **WarOnPrivacy** discussed the importance of providing precise prompts to ensure accurate results and shared experiences with GPT-3.5 trials.
10. **Yacovlewis** shared insights into the differences between Langchain and RAG models, emphasizing the significance of logical handling in predicting suitable responses.
11. **mnd-blght** speculated on the significant difference in handling named entity recognition tasks by utilizing embeddings, highlighting the importance of diverse datasets in different business contexts.

The discussion primarily focused on the challenges faced in working with GPT models, the importance of prompt optimization, model capabilities, and practical applications of tools like Langchain and Claude3.

### Cipherleaks is the first demonstrated attack against AMD SEV-SNP (2021)

#### [Submission URL](https://cipherleaks.com/) | 36 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [11 comments](https://news.ycombinator.com/item?id=40016468)

Today on Hacker News, the spotlight is on CIPHERLEAKs, the first attack demonstrated against AMD SEV-SNP. This attack leverages a vulnerability in the design of SEV's memory encryption to breach the constant-time RSA and ECDSA implementation in the latest OpenSSL library, using the ciphertext of the encrypted VM Save Area as side channels. By monitoring changes in the ciphertext, attackers can infer changes in the corresponding plaintext, enabling them to breach encryption methods. The root causes of this vulnerability lie in two features of SEV: the use of XOR-Encrypt-XOR (XEX) encryption mode with a fixed entropy tweak function that leads to the same plaintext having the same ciphertext, and the lack of prevention of the hypervisor from accessing the ciphertext of the encrypted memory, creating a ciphertext side channel.

Two case studies are presented to illustrate the effectiveness of the CIPHERLEAKs attack, showing that the private keys of RSA encryption and secret nonces in ECDSA signatures can be recovered with 100% accuracy. The CIPHERLEAKs attack has been disclosed to AMD, who has acknowledged the vulnerability and filed an embargo until August 10, 2021, with a CVE number assigned to the vulnerability. AMD has also announced a security bulletin and a hardware patch for SEV-SNP in August 2021 to address the issue. For more details, the research paper on CIPHERLEAKs can be accessed to understand the full extent of the attack. Researchers involved in this discovery include individuals from The Ohio State University, Baidu Security, and NIO Security Research.

This exploit affects all SEV, SEV-ES, and SEV-SNP supported by AMD EPYC server processors, and the vulnerability has been reserved under the CVE number CVE-2020-12966.

SEV (Secure Encrypted Virtualization) is an AMD Virtualization extension that provides security features for virtual machines, while SEV-SNP (Secure Nested Paging) is a recent addition aimed at protecting against attacks exploiting memory integrity flaws. As software solutions may not be effective due to collection of function's internal state by Advanced Programmable Interrupt Controller (APIC), hardware-level patches from AMD are expected to mitigate the CIPHERLEAKs attack.

The discussion on the CIPHERLEAKs submission includes various points:

1. **H8crilA** mentions exchanging information about side-channel solutions involving various kinds of steps in response to the vulnerability demonstrated in CIPHERLEAKs. They talk about Trusted Execution Environments (TEEs), Clouds, the FBI vs Apple encryption dispute, corporate staff meetings being hacked with malware, and the distrust towards DRM and anti-cheating mechanisms. They point out the importance of controlling privileged kernel code and utilize Intel's Software Guard Extensions (SGX) as a potential solution.
2. **the8472** notes that Intel has discontinued desktop chips that use Software Binary Player Digital Rights Management (DRM) with SGX, emphasizing a shift in their technology focus.
3. **stypc** appreciates the addition of the 2021 tag to the submission.
4. **tus666** brings up the frustration around highly annoying exclusive domain names registered for individual CVEs. **frgmd** discusses human psychology and how certain domain names evoke emotional responses, highlighting the impact they can have indirectly. **mistrial9** dives into the visibility and costs associated with domain names, expressing concerns about the vanity aspect and how it can lead to various manipulations and complications in the cybersecurity domain. **xnthr** suggests pricing domain names at $30 per year or less to deter vanity exploitation. **sqgz** mentions a price of $10 per year for domain names.

### Palo Alto Networks PAN-OS Zero-Day Exploitation

#### [Submission URL](https://www.volexity.com/blog/2024/04/12/zero-day-exploitation-of-unauthenticated-remote-code-execution-vulnerability-in-globalprotect-cve-2024-3400/) | 88 points | by [sky_nox](https://news.ycombinator.com/user?id=sky_nox) | [54 comments](https://news.ycombinator.com/item?id=40016985)

Volexity recently uncovered a zero-day exploitation of a critical vulnerability in Palo Alto Networks PAN-OS GlobalProtect, marked as CVE-2024-3400. The attack involved a threat actor, known as UTA0218, remotely exploiting the firewall device to gain unauthorized access, create a reverse shell, and download additional tools onto the compromised system. The attacker's primary focus was on extracting configuration data from the devices and using it to move laterally within victim organizations. Through collaboration with Palo Alto Networks, the vulnerability was confirmed as an OS command injection issue with a severity rating of 10.0 on the CVSS scale. Palo Alto Networks has released an advisory for CVE-2024-3400, including a threat protection signature and a fix expected by April 14, 2024.

Volexity's investigation revealed that UTA0218 attempted to install a custom Python backdoor, named UPSTYLE, on the firewalls to execute additional commands via network requests. The attacker's tactics included deploying malicious payloads and moving swiftly through victims' networks to gather sensitive information and credentials. While the full extent of the exploitation is not yet determined, organizations using Palo Alto Networks GlobalProtect firewall devices are advised to review the advisory for protection measures. It's crucial to take proactive steps to ensure systems are secure and investigate for potential compromises to prevent unauthorized access. The incident highlights the importance of prompt security measures in response to zero-day vulnerabilities and emphasizes the need for continuous monitoring and mitigation strategies to safeguard against sophisticated cyber threats.

The discussion on the submission covers various aspects related to the zero-day exploitation in Palo Alto Networks PAN-OS GlobalProtect marked as CVE-2024-3400:

- **wfcclr** highlighted the availability of the Palo Alto Networks advisory for CVE-2024-3400 and suggested applying the Threat Prevention measures while temporarily disabling device telemetry.
- **numpad0** discussed the basic principles of Palo Alto, F5 Networks, and Fortinet firewalls, emphasizing the importance of understanding the fundamental aspects of networking and security protocols.
- **ml** and **thphybr** engaged in a discussion regarding the security implications of modern Layer 7 firewalls conducting MITM without MITM, mentioning specific examples related to Palo Alto's Applipedia and security policies.
- **WirelessGigabit** shared an experience where their company faced issues with MITM TLS setups causing disruptions in software and OS certificate stores.
- **lrmyn** mentioned their experience working with F500 companies relying on DNS IP filtering for SSL inspection.
- **p_l** and **mlt** discussed the implications of TLS MITM proxy configurations and the potential risks associated with certificate manipulation in TLS traffic.
- **unethical_ban** raised concerns about decrypting traffic for banking and health-related data passing through networks.
- **srbntr** brought up the concept of MITM proxy blocking and its implications for companies.
- **mistrial9** touched upon the importance of data passing through networks in a business context and the role of packet inspection in monitoring server content.

The comments showcase a varied perspective on the security implications of the vulnerability and the potential risks associated with network traffic interception and manipulation techniques. Discussions range from technical considerations to ethical concerns surrounding data privacy and security practices in the context of modern firewall technologies.

### Amazon virtually kills efforts to develop Alexa Skills

#### [Submission URL](https://arstechnica.com/gadgets/2024/04/amazon-virtually-kills-efforts-to-develop-alexa-skills-disappointing-dozens/) | 164 points | by [Stratoscope](https://news.ycombinator.com/user?id=Stratoscope) | [188 comments](https://news.ycombinator.com/item?id=40008170)

Amazon's once promising plan for Alexa Skills has hit a roadblock, as the company has decided to discontinue the incentives program for developers. The move has left many third-party developers questioning their future with Alexa, especially as Amazon gears up for a generative AI and subscription-based version of the voice assistant. With little interest and money associated with developing Skills, many developers are reevaluating their commitment to the platform. The top Alexa Skills are currently basic tasks like playing trivia games rather than groundbreaking technological feats, highlighting the challenges developers face in monetizing their creations. Despite Amazon's assurance that developers play a critical role in Alexa's success, the future of third-party apps on the platform remains uncertain.

The discussion on the submission about Amazon discontinuing the incentives program for Alexa Skills highlighted various challenges and frustrations faced by developers. Users shared their experiences with Alexa projects, including limitations and issues with voice recognition, as well as comparisons between Alexa and Google Home functionalities. Some users pointed out the shortcomings in the Alexa platform, such as latency and bandwidth problems, while others discussed the limitations of developing skills due to the platform's complexity. Additionally, there were debates on the effectiveness of voice user interfaces (VUIs) compared to graphical user interfaces (GUIs) in providing information and controlling devices. Lastly, users raised concerns about privacy and security in voice-controlled devices and emphasized the importance of maintaining control over personal data.

### Zephyr 141B, a Mixtral 8x22B fine-tune, is now available in Hugging Chat

#### [Submission URL](https://huggingface.co/chat/models/HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1) | 28 points | by [osanseviero](https://news.ycombinator.com/user?id=osanseviero) | [12 comments](https://news.ycombinator.com/item?id=40014558)

HuggingChat, the latest offering from Hugging Face, is putting the power of AI chat models into the hands of the community. This exciting tool allows you to access some of the best AI chat models available, potentially making your tasks easier and more efficient. However, it comes with a disclaimer acknowledging that AI, being an evolving field, can have issues like biased generation and misinformation. So, while HuggingChat can be a valuable resource, it's wise not to rely on it for critical decisions or advice. You can dive in as a guest or sign in with Hugging Face to explore the capabilities of HuggingChat version 0.8.1. From writing emails to coding a snake game, this tool offers a range of functionalities to assist you in various tasks. Just keep in mind that the generated content, especially when web searching is enabled, may not always be entirely accurate or reliable. Explore the potential of HuggingChat, but approach it with caution, especially for important matters.

The discussion on Hacker News covered a range of topics related to AI models and their applications. 
1. The first thread discussed the Zephyr 141B Mixtral 8x22B model, highlighting its features and specifications such as being fine-tuned with advanced algorithms, trained on a large dataset, and offered as open-source with various resources available. There was also a mention of the ORPO algorithm and its relevance.
2. The second thread featured comments about the TGI inference engine going open-source under the Apache 2.0 license, which was considered good news. Additionally, there were comments about the difficulty in finding related links.
3. One user thanked another for providing a link to a model table.
4. A conversation about linguistic nuances and fruit comparisons ensued, involving discussions around statements comparing fruit qualities and the logical reasoning behind them, particularly focusing on the relationship between cherries and bananas.
5. The same conversation delved into the complexities of training models, especially in generating responses that are logically correct, along with a reference to the challenges of working with formal logic in natural language processing tasks.

Overall, the discussions covered topics ranging from AI model capabilities and open-source initiatives to the intricacies of natural language processing and logic reasoning in text generation tasks.

### Andrew Ng Appointed to Amazon's Board of Directors

#### [Submission URL](https://www.aboutamazon.com/news/company-news/dr-andrew-ng-joins-amazon-board-of-directors) | 90 points | by [bbzjk7](https://news.ycombinator.com/user?id=bbzjk7) | [7 comments](https://news.ycombinator.com/item?id=40008788)

Dr. Andrew Ng, a prominent figure in artificial intelligence, has joined Amazon's Board of Directors as Managing General Partner of AI Fund. With vast experience in AI and education technology, Dr. Ng's expertise will enhance the Board's perspectives on the transformative potential of AI. Meanwhile, Judy McGrath will not seek re-election, ending her decade-long service on the Board. Amazon expresses gratitude to her and welcomes Dr. Ng to the team. This strategic move reflects Amazon's commitment to innovation and leadership in the realm of AI. For more details, visit the Amazon newsletter.

The discussion on the Hacker News submission about Dr. Andrew Ng's appointment to Amazon's Board of Directors revolves around various points. 
1. **mhlshh** suggests that Amazon is now a thought leader in AI, rivaling Google and Meta, and speculates that they are possibly making significant advancements.
2. **gndlfgrybr** highlights Andrew Ng's work in AI/ML and his familiarity with the inner workings of Silicon Valley, indicating that Ng's presence will strengthen Amazon's strategic direction in the field and add credibility.
3. **phtnbm** raises questions about the value boards add, implying that they often lack direct involvement in decision-making regarding business operations, leading to guesswork and optics-based decision-making in the fast-paced world of AI.
4. **blckybltzr** argues that boards do not necessarily contribute a sense of meaning, as CEOs often have the final say, which could result in various opinions being thrown around without much practical impact, especially in the rapidly evolving world of AI.
5. **znglshhr** states that Amazon's move reflects a serious commitment to AI, indicating that the company is strategically positioning itself to apply AI in smarter ways, specifically mentioning advancements in Alexa.
6. **aprilthird2021** brings up the example of Condoleezza Rice serving on the Dropbox board, attributing the appointment to her Stanford connections and suggesting that having prominent figures on boards can lead to good optics and discussions about relevant topics.

Overall, the discussion touches on Amazon's strategic approach to AI, the role and impact of board members, and the significance of having well-known figures in the tech industry on company boards.

