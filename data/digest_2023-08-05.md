## AI Submissions for Sat Aug 05 2023 {{ 'date': '2023-08-05T17:10:11.043Z' }}

### New acoustic attack steals data from keystrokes with 95% accuracy

#### [Submission URL](https://www.bleepingcomputer.com/news/security/new-acoustic-attack-steals-data-from-keystrokes-with-95-percent-accuracy/) | 390 points | by [mikece](https://news.ycombinator.com/user?id=mikece) | [216 comments](https://news.ycombinator.com/item?id=37013704)

Researchers from British universities have developed a deep learning model that can steal data from keyboard keystrokes using a microphone with 95% accuracy. The model, called CoAtNet, was trained using sound recordings of keystrokes and achieved an accuracy of 95% when recordings were made from a smartphone and 93% when made through Zoom. Acoustic attacks like this have become more dangerous due to the widespread use of microphone-bearing devices and advancements in machine learning. The team of researchers recommends altering typing styles or using randomized passwords as possible mitigation measures against this type of attack.

Discussion Summary:

- Some users believe that this acoustic attack is not very practical because it requires specific keyboard types and it is unlikely that people would unknowingly use compromised keyboards.
- Others suggest that using mechanical keyboards with different switch types or adding gy bottoms to the keys can help mitigate this attack.
- Some users argue that the sensitivity of microphones and the ability to capture keystrokes is not surprising. They mention instances of microphones picking up background noise, such as breathing or playing music.
- One user suggests integrating a gain knob on mechanical keyboards to control the volume of the key sounds.
- Another user points out that certain IBM keyboards from the past were notorious for their loud typing sounds and suggests that this attack would not work on keyboards with a similar mechanism.
- Some users discuss the idea of implementing background noise or randomized key presses to make it more challenging for attackers to decipher keystrokes.
- There is a discussion about the accuracy of the attack model and how it can be mitigated through the use of strong, complex passwords or passphrase-based security.

Overall, the discussion around this submission highlights different perspectives on the feasibility and potential mitigations of acoustic attacks targeting keyboard keystrokes.

### IBM and NASA open-source largest geospatial AI foundation model on Hugging Face

#### [Submission URL](https://newsroom.ibm.com/2023-08-03-IBM-and-NASA-Open-Source-Largest-Geospatial-AI-Foundation-Model-on-Hugging-Face?sf180690117=1) | 260 points | by [anigbrowl](https://news.ycombinator.com/user?id=anigbrowl) | [22 comments](https://news.ycombinator.com/item?id=37015290)

IBM and Hugging Face have announced that IBM's watsonx.ai geospatial foundation model, built from NASA's satellite data, will now be openly available on Hugging Face. This marks the largest geospatial foundation model on Hugging Face and the first-ever open-source AI foundation model built in collaboration with NASA. The model aims to democratize access and application of AI to generate new innovations in climate and Earth science. Trained on Harmonized Landsat Sentinel-2 satellite data (HLS), the model has shown a 15% improvement over state-of-the-art techniques using half as much labeled data. It can be repurposed for tasks like tracking deforestation, predicting crop yields, or monitoring greenhouse gases. A commercial version of the model will be available later this year through the IBM Environmental Intelligence Suite.

The discussion on this submission covers various aspects of the geospatial foundation model released by IBM and Hugging Face. Some comments discuss the technical details of the model, such as its size and the data it was trained on. Others express interest in using the model for tasks like tracking deforestation and predicting crop yields. There is also discussion about the availability of the model, with one commenter wondering if there will be a commercial version. The collaboration between IBM, Hugging Face, and NASA is seen as a positive development in democratizing access to AI for climate and Earth science research. Some commenters even discuss the limitations of the model and suggest potential improvements. Overall, there is excitement about the potential impact of this collaboration in addressing environmental challenges and advancing AI technology.

### Mass Editing Memory in a Transformer

#### [Submission URL](https://arxiv.org/abs/2210.07229) | 82 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [12 comments](https://news.ycombinator.com/item?id=37017166)

Mass-Editing Memory in a Transformer is a recent paper that introduces a method called MEMIT, which allows for the direct updating of a language model with multiple memories. The authors demonstrate that MEMIT can scale up to thousands of associations for large language models like GPT-J and GPT-NeoX, surpassing previous work by a significant margin. This advancement opens up possibilities for updating language models with new information and replacing outdated memories more efficiently. The paper includes experimental results, code, and data for further exploration.

The discussion on this submission covers a range of topics related to artificial intelligence (AI) and its potential implications. 

One commenter notes that the ability to assign sensory and semantic meaning to memories is critical for implementing intelligence. They express amazement and fear at the idea of being able to modify memories, as it is a fundamental aspect of human decision-making. However, another commenter argues that decision support systems and machines can function effectively by providing analytical assessments and explicit analysis, even if they lack the emotional connection to memories.

The conversation then shifts to the concept of artificial general intelligence (AGI), with one commenter expressing their wish for AGI and another expressing their confusion about the enthusiasm for it. They mention that AGI could potentially solve complex problems but also highlight the dangers of uncontrolled AI and AI-driven decision-making.

Another commenter points out the limitations of technology in managing complex societal problems and mentions the potential dangers of AI being used for self-preservation and influencing government decision-making. They express concerns about the speed and effectiveness of AI in manipulating information and diverting attention.

The discussion then touches on the importance of wisdom in contrast to intelligence, noting that intelligence without wisdom can lead to ignorance and harmful consequences. The commenter argues that people should focus on cultivating wisdom and not solely rely on intelligence.

In response to a comment about the memory of the fictional AI character HAL, someone references a scene from the movie "2001: A Space Odyssey." They mention a fictional character's creation of HAL's memory, highlighting the concept of memories being a vulnerable aspect of systems.

The discussion concludes with a brief comment about training a machine learning model using a Transformer model and its associated cost.

### Double neural bypass restores movement, sense of touch after paralysis

#### [Submission URL](https://feinstein.northwell.edu/news/the-latest/bioelectronic-medicine-researchers-restore-feeling-lasting-movement-in-man-living-with-quadriplegia) | 177 points | by [kvee](https://news.ycombinator.com/user?id=kvee) | [28 comments](https://news.ycombinator.com/item?id=37007809)

Feinstein Institutes researchers have achieved a major breakthrough in restoring movement and sensation in a man living with quadriplegia. In a first-of-its-kind clinical trial, microchips were implanted into the man's brain, and artificial intelligence (AI) algorithms were developed to reconnect his brain to his body and spinal cord. The double neural bypass forms an electronic bridge that allows information to flow between the man's paralyzed body and brain, effectively restoring movement and sensation in his hand, as well as lasting gains in his arm and wrist. This groundbreaking progress marks a significant step towards giving people living with paralysis the ability to live fuller, more independent lives.

The discussion on this submission covered a wide range of topics related to the breakthrough in restoring movement and sensation in quadriplegia. 

One commenter raised concerns about the long-term viability of brain implants, pointing out that the brain tissue may degrade over time and that replacement surgeries are not a simple solution. Another commenter mentioned deep brain stimulation (DBS) hardware and its limitations, noting that most DBS systems do not provide sensing feedback and that the electrodes in the brain can cause damage.

There was a discussion about the possibility of grafting electrodes to fresher nerves and the potential for brain-specific regions to control specific parts of the body. Brain plasticity was also mentioned, with examples given of people integrating prosthetics and controlling them through related nerves.

Some commenters suggested alternative approaches, such as using temperature conductors, magnetic fields, or induction waves to manage nerves and sensations.

The discussion also touched on the power of artificial intelligence (AI) in medical technology. Some expressed optimism about AI's potential to solve real-world problems, while others raised concerns about the ethical implications of AI as a powerful tool.

One commenter pointed out the challenges of developing personalized drugs based on individual genetic expressions, emphasizing the need for a formalized and scaled approach.

Another commenter brought up the book "Interface" by Neal Stephenson and George Jewsbury, recommending it as a relevant read.

### MK-1

#### [Submission URL](https://mkone.ai/blog/introducing-mk1) | 279 points | by [ejz](https://news.ycombinator.com/user?id=ejz) | [45 comments](https://news.ycombinator.com/item?id=37016413)

MK-1 is a new startup that aims to provide companies with the same efficient language model capabilities as elite AI powerhouses like OpenAI and Google. Their first product, MKML, is an inference runtime that can significantly reduce the costs and improve the performance of large language models on GPUs.

One of the main challenges that MKML addresses is the large memory footprint of these models, which can limit performance and increase costs. MKML has developed a compression technique that can reduce the size of models by about 60%, while maintaining a high fidelity to the original model. For example, a Llama-2 13B model that initially requires 26GB of memory can be shrunk down to just 10.5GB with MKML.

The benefits of using MKML are twofold. Firstly, it allows companies to use lower-cost GPU instances that have less memory capacity, without sacrificing performance. For example, the compressed Llama-2 13B model can now fit on a single A10 24GB instance, which is about 45% less expensive than the A100 instance. Secondly, for companies that can afford the more powerful A100 instance, MKML can increase performance by up to 2.0x compared to the baseline model.

MKML is designed to be easy to integrate into existing workflows and works seamlessly with popular ecosystems like Hugging Face and PyTorch. With just a few lines of Python code, developers can compress their models and use MKML for inference.

The performance of MKML has been benchmarked with different batch sizes and GPUs, and the results consistently show that it outperforms the baseline model in terms of token generation speed. Additionally, the compressed models maintain a high level of fidelity, with only a small difference in perplexity compared to the original models.

MK-1 is currently in closed beta release, but if you're interested in becoming an early partner and gaining access to new features, you can contact them for more information. With MKML, companies can optimize their inference stack, reduce costs, and improve the efficiency of their language models.

The discussion around the submission on Hacker News revolves around various aspects of MKML and its comparison to existing methods.

One commenter points out that quantization methods that are already available usually provide comparable results to what MKML is claiming. They mention that these techniques have already been widely used and question the novelty of MKML's approach.

The founder of MK-1, Paul Merolla, responds to address the comments. He explains that MKML is designed to be a targeted solution that focuses on compressing models with high performance and efficiency. He highlights that MKML builds on the existing framework of Hugging Face and other popular ecosystems. He also mentions that the performance of MKML has been benchmarked with different batch sizes and GPUs, consistently outperforming the baseline models.

Another commenter raises a question about the integration of MKML and the existing frameworks like Hugging Face. Paul Merolla responds and clarifies that MKML is not simply repackaging existing frameworks, but rather integrating its own compression scheme. He emphasizes that MKML targets multi-task, multi-prompt batch=1 use cases and achieves faster token generation speed compared to other methods.

The discussion further delves into specific technical questions about memory footprint, batch sizes, and model performance. Paul Merolla provides detailed answers and also mentions that MK-1 is working on wrapping their techniques and tools into open-source software.

There are also discussions about other quantization techniques, such as 4-bit and 8-bit quantization, and their potential application to speed up model inference.

Overall, the discussion is a mix of skepticism, technical questions, and comparisons to existing methods. Some commenters are interested in seeing more comprehensive benchmarks and comparisons to validate MKML's claims. Others express concern about proprietary dependencies and the lack of open-source solutions for model compression.

### The Myth of AI Omniscience: AI's Epistemological Limits

#### [Submission URL](https://cpwalker.substack.com/p/the-myth-of-ai-omniscience-ais-epistemological) | 82 points | by [cpwalker](https://news.ycombinator.com/user?id=cpwalker) | [98 comments](https://news.ycombinator.com/item?id=37012501)

In his recent article, Chris Walker explores the myth of AI omniscience and the epistemological limits of artificial intelligence. He highlights the apocalyptic prophecy surrounding AI, with discussions of superintelligence either saving or destroying humanity. OpenAI's investment into "superalignment" research further fuels this discourse. Walker addresses the notion of a superintelligence having "vast power" and examines Elon Musk's xAI venture, which aims to understand the true nature of the universe. He argues that AI models, regardless of their architecture, are ultimately limited by the fact that they are trained on human-written texts. Therefore, their understanding of the universe is shaped by human understanding and does not go beyond our current knowledge. Walker draws upon the philosophical perspective of William James to emphasize that human understanding of truth is constructed and shaped by our experiences, interests, and concepts, and AI models are bound by these limitations. In conclusion, he challenges the idea that an AI can achieve an absolute understanding of the universe and emphasizes the need to focus on the AI issues that truly matter for society.

The discussion revolves around the limitations of language models (LLMs) and their ability to combine existing concepts in novel ways. Some users argue that LLMs are fundamentally limited by the vocabulary and concepts they are trained on, while others suggest that LLMs can generate novel combinations of concepts in unique ways. There is also debate about the significance of artistic creativity and whether LLMs can surpass human abilities in that regard. Other topics discussed include the difficulty of combining language in novel ways, the challenges of defining and understanding language, and the potential for LLMs to learn from training data without truly understanding it. There is also a brief mention of withholding code or data to prevent complete training of LLMs, although one user cautions against publishing code on GitHub due to potential exposure.

### AI wonâ€™t replace humans, but humans with AI will replace humans without AI

#### [Submission URL](https://hbr.org/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai) | 230 points | by [sahin](https://news.ycombinator.com/user?id=sahin) | [222 comments](https://news.ycombinator.com/item?id=37009698)

In an article titled "AI Won't Replace Humans - But Humans With AI Will Replace Humans Without AI," Harvard Business School professor Karim Lakhani emphasizes the importance of businesses embracing artificial intelligence (AI) to stay competitive. Lakhani explains that just as the internet revolutionized information transmission, AI will lower the cost of cognition. He highlights the need for business leaders to experiment, create AI sandboxes, and develop AI use cases not just for technology workers, but for all employees. Lakhani believes that customers will soon expect AI-enhanced experiences from companies, making AI integration essential for modern organizations.

The discussion on this submission covers a variety of topics related to the impact of AI on society. One user points out that throughout history, various technologies have shaped human culture and suggests that AI will be no different. Another user argues that AI will fundamentally change society and that there will be a need for a large number of people involved in its production. They draw parallels to historical events such as the Industrial Revolution and the Black Death. Others discuss the concept of self-replicating ideas and how AI allows for the rapid dissemination and reinforcement of certain narratives. The debate also touches on the potential societal consequences of AI replacing human workers and the definition of a "good quality of life." Some argue that quality of life should focus on enjoyment, while others highlight mental health and substance abuse issues as important factors. The discussion brings up the role of the environment and its impact on quality of life, as well as the assumption that a higher birth rate automatically equates to a better quality of life. Overall, the discussion delves into the various implications and considerations surrounding the integration of AI into society.

