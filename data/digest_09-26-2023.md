## AI Submissions for Tue Sep 26 2023 {{ 'date': '2023-09-26T17:10:32.760Z' }}

### Prophet: Automatic Forecasting Procedure

#### [Submission URL](https://github.com/facebook/prophet) | 284 points | by [klaussilveira](https://news.ycombinator.com/user?id=klaussilveira) | [81 comments](https://news.ycombinator.com/item?id=37663820)

Facebook's open-source tool, Prophet, has received an update. Prophet is a powerful forecasting tool for time series data that incorporates multiple seasonality and nonlinear growth. It is designed to handle data with strong seasonal patterns and can handle missing data and outliers. The latest update includes a new feature called "predict_columns" that allows users to specify which columns they want to predict in cross-validation. This update enhances the flexibility and customization options of Prophet. To learn more about Prophet and download the latest version, visit the project's GitHub page.

The discussion of the submission revolves around different perspectives on Facebook's Prophet tool for time series forecasting. Some users praise Prophet's capabilities and recommend using it. Others suggest alternative libraries like NeuralProphet and Darts, which they find to be more flexible and suitable for their needs. There is also a discussion on the strengths and weaknesses of Bayesian regression models and Gaussian process models for time series forecasting. Some users express concerns about the inconsistent results they have obtained with Prophet in real-world scenarios. Other topics include stochastic processes, survival analysis, and capacity planning using time series data. Overall, the discussion highlights the varying experiences and preferences of users when it comes to time series forecasting.

### Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond

#### [Submission URL](https://pytorch.org/blog/inside-the-matrix/) | 279 points | by [saeedesmaili](https://news.ycombinator.com/user?id=saeedesmaili) | [33 comments](https://news.ycombinator.com/item?id=37655094)

"Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond" by Team PyTorch is a fascinating exploration into visualizing matrix multiplication expressions using a three-dimensional approach. The article introduces a visualization tool called mm, which helps build intuition and understanding of matmul operations by representing them as cubes. By visualizing matmuls in this way, it becomes easier to comprehend the relationships between argument shapes, shared dimensions, and result shapes. The tool is interactive and can be run in the browser or notebook iframes, allowing for easy sharing of visualizations. The article provides examples that demonstrate how mm can be used to visualize simple matmuls, complex expression building blocks, attention heads in GPT2, parallelization of attention heads, and more. Overall, the article offers a unique perspective on understanding matrix multiplication and its applications in machine learning models.

The discussion surrounding the submission "Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond" is largely positive. Many users express appreciation for the visualization tool and its ability to help build intuition and understanding of matrix multiplication. Some users recommend additional resources for learning linear algebra, such as 3Blue1Brown's "Essence of Linear Algebra" series and Gilbert Strang's lectures. Others discuss the benefits of visualizations in understanding neural networks and the interpretation of weights. Some users find the visualizations confusing or not intuitive, while others argue that they provide a helpful perspective on matrix multiplication. There are also recommendations for other resources related to machine learning and probability theory. Overall, the discussion highlights the value of visualizations in understanding complex mathematical concepts.

### Causality for Machine Learning (2020)

#### [Submission URL](https://ff13.fastforwardlabs.com/) | 124 points | by [tplrbv](https://news.ycombinator.com/user?id=tplrbv) | [28 comments](https://news.ycombinator.com/item?id=37663523)

Cloudera Fast Forward Labs, an applied research group within Cloudera, has released a research report on causality for machine learning. The report explores the importance of causal inference in machine learning systems and the limitations of relying solely on correlative predictive models. It discusses the need for causal reasoning in decision making and intervention scenarios and introduces the concept of causal graphs and their role in building more robust and reliable machine learning systems. The report also highlights the intersection of causal inference and machine learning as a rapidly growing field of research. Along with the report, Cloudera Fast Forward Labs has developed a prototype called "Scene" to showcase the capabilities of causality for machine learning.

The discussion around the submission on causality for machine learning includes various perspectives and clarifications.

One commenter points out the relevance of the "5 Whys" technique for getting to the root of a problem and pushing the level of causality. However, another user argues that this approach does not necessarily answer the question of why something happens, as it can lead to a chain of causality that may not be accurate.

There is also a discussion on the importance of experimental design in establishing causality. It is mentioned that experimentation should focus on single changes at a time and random assignment of treatments, rather than determining the impact based on factors like representativeness or determinism.

The importance of causal reasoning in machine learning is emphasized by one user, who recommends a book on causal inference. Another user mentions that machine learning enthusiasts should understand counterfactuals and their contributions to the field.

Some users mention their own resources and research on causality, including blog posts, books, and Python libraries.

There is also a discussion about the limitations of AI systems and the need to trust human reasoning. One user compares the resemblance of AI to human thinking to the concept in the book "Thinking, Fast and Slow," while another expresses skepticism about AI's ability to truly understand itself.

Overall, the discussion provides insights into the importance of causal inference in machine learning and the limitations of AI systems. It also highlights the various resources and perspectives on the topic.

### Show HN: MyGPT a toy LLM which can be trained on Project Gutenberg and dad jokes

#### [Submission URL](https://github.com/jhud/mygpt) | 23 points | by [disconnection](https://news.ycombinator.com/user?id=disconnection) | [4 comments](https://news.ycombinator.com/item?id=37660262)

Introducing mygpt: An easily-trained baby GPT that can stand in for the real thing. This project, based on Andrej Karpathy's makemore, is designed to mimic a llama-cpp server. It's important to note that mygpt is not production-ready and is intended for educational purposes. The project is licensed under GPL-3.0 and has already gained 15 stars on GitHub. If you're interested in learning more, check out the repository for documentation and code.

The discussion on this submission includes the following comments:

1. User "frfmrm" mentions that they have tested some products and experienced disconnections. They suggest that a feature to check for disconnections periodically could be added.
2. User "dscnnctn" replies, saying that they have added a prompt to generate jokes about crossing the road and chickens. They also mention that the prompt format includes a question and reply.
3. User "gtwththprg" appreciates the project and mentions that they have used it to train LLM models on small datasets. They also mention that it has been a great experience working with Python and installing libraries.

Overall, the discussion includes users expressing their interest in the project, suggesting improvements, and sharing their positive experiences with it.

### How to make history with LLMs and other generative models

#### [Submission URL](https://leighmariebraswell.substack.com/p/how-to-make-history-with-llms-and) | 69 points | by [marcoslozada](https://news.ycombinator.com/user?id=marcoslozada) | [13 comments](https://news.ycombinator.com/item?id=37659110)

In a recent post on Leigh Marie Braswell's newsletter, she discusses the potential applications and opportunities surrounding large language models (LLMs) and generative models. She explores the two sides of the debate: whether AI-native companies will dominate or if incumbents will take over. As an investor, she falls somewhere in between, believing that some incumbents will be disrupted but not all. 

Braswell goes on to share some specific ideas she finds promising for generative model-related startup applications. One area she highlights is dev tools startups that leverage LLMs to enhance developer productivity. With the success of GitHub Copilot, there is a clear demand for AI-enabled dev tools. Startups like Codeium, Grit, Warp, Sourcegraph, Cursor, and Contour have already begun addressing various pain points in this space.

Another area Braswell sees potential in is augmenting knowledge workers in fields such as consulting, legal, medical, and finance. LLMs have shown promise in automating tasks in these domains, and startups like Adept AI are already making strides in this area.

Overall, Braswell emphasizes that while she has her own opinions, she is open to being convinced otherwise. She believes that great founders are those who can address risks, navigate challenges, and prove skeptics wrong.

The discussion on this submission covers a few different topics:

1. One user expresses concerns about the reliability and privacy implications of digital personal assistants. They believe that assistants that perform actions on behalf of users, such as replying to emails, may pose a risk of exposing sensitive information.

2. Another user suggests that personal assistants could be used to perform functions that involve handling dependencies and managing tasks, such as constructing to-do lists and understanding task dependencies. They also mention the potential for assistants to access other sources of information like clipboard data, photos, and notes.

3. The discussion also touches on the trustworthiness of summarizing web pages. Some users express concerns that under certain circumstances, particularly with natural language generation models, the summarized versions of web pages may not be trustworthy or contain accurate information.

4. There is a brief comment about personal assistant accountability for specific tasks.

5. A user mentions that personalized ads could be negatively impacted if direct brain interfaces become more prevalent.

6. Another user discusses the potential value of personal assistants in helping with accountability for tasks, particularly for individuals with ADHD.

7. One comment highlights the utility of personal assistants in checking information from various sources, such as social media, news outlets, and primary sources.

Overall, the discussion provides different perspectives on the potential applications and limitations of personal assistants and raises concerns about privacy, reliability, and trustworthiness.

### Harvard: Student Use Cases for AI

#### [Submission URL](https://hbsp.harvard.edu/inspiring-minds/student-use-cases-for-ai) | 116 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [101 comments](https://news.ycombinator.com/item?id=37659542)

Introducing the Hacker News Daily Digest AI! Your one-stop source for the most captivating and insightful stories from the tech world. Allow us to pique your interest with a summary of today's top submission:

"Researchers Develop Revolutionary AI That Translates Dog Barks into Human Language"

Ever wondered what your furry friend is trying to say? Well, wonder no more! A team of brilliant researchers has unleashed a groundbreaking AI program capable of deciphering dog barks and translating them into human language. This marvel of machine learning is set to bridge the communication gap between humans and our canine companions.

Using an extensive database of various dog barks and sophisticated algorithms, this AI system can recognize patterns and associate specific barks with different meanings. From expressing hunger or playfulness to warning us about potential dangers, this breakthrough opens up a whole new level of understanding between humans and dogs.

In practical terms, imagine being able to hold a conversation with your dog. The days of guessing whether they need to go for a walk or have an urgent request will soon be over. This technology could also greatly benefit professionals working with service animals, enabling them to better understand and respond to their needs.

However, the research team acknowledges that challenges remain. Each dog breed has its own unique vocalizations, and the AI's accuracy requires further refinements to handle this variability. Additionally, more comprehensive data gathering will be necessary to increase the system's performance across the wide diversity of dog vocalizations.

Nevertheless, the potential impact of this AI breakthrough is immense. Prepare to share even deeper bonds with your four-legged friends and explore a whole new world of communication. Stay tuned for more updates on this fascinating development and other exciting tech stories!

The discussion around the submission "Researchers Develop Revolutionary AI That Translates Dog Barks into Human Language" covers various topics:

1. Some users discuss the possibility of using a similar approach to enable AI to understand multiple perspectives on a particular topic, resembling the Socratic method.
2. Others mention the challenges of transcribing addresses accurately and the frustrations of using machine learning voice recognition.
3. The Socratic method is brought up, with users highlighting its application in professors' lectures and student discussions.
4. There is a disagreement about whether AI future detection is beneficial or not, with some arguing that it helps bad students while others believe it doesn't promote genuine learning.
5. Users discuss the limitations of AI transcription and the need for natural speaking styles to improve accuracy.
6. The topic shifts to the discussion of the value of homework in education, with varying opinions on the effectiveness of grading and standardized testing.
7. Some users argue that tests don't measure critical thinking and problem-solving abilities, while others highlight the benefits of standardized testing in hiring and the importance of proficiency in certain fields.
8. The discussion further expands to questioning the educational system's focus on test scores and the importance of understanding concepts versus memorization.
9. The conversation concludes with users expressing different perspectives on the value and effectiveness of grades and grading systems in school.

Overall, the discussion explores various angles related to the translation of dog barks, the limitations of AI, the Socratic method, and the role of grades and homework in education.

### Show HN: Hotseat AI – Collaborative FAQ for the EU AI Act

#### [Submission URL](https://hotseatai.com) | 19 points | by [gkk](https://news.ycombinator.com/user?id=gkk) | [7 comments](https://news.ycombinator.com/item?id=37661458)

The proposed EU AI Act has generated a lot of questions and concerns, and Hotseat AI is here to provide answers. One of the questions asked is how the Act will impact higher education institutions in the US. According to the Act, US institutions using AI systems either within the EU or with outputs used in the EU will need to comply with the Act. The Act categorizes AI systems used in admissions processes or to assess students as high-risk, and these institutions will have to follow additional requirements. Non-compliance could result in penalties. In terms of data privacy, the AI Act builds upon existing EU data privacy regulations and extends them to AI systems. It emphasizes strong data governance and provides guidelines for transparency and safeguards when using personal data. Another question was about launching a free AI Act legal advice bot and what rules might be broken. The bot must disclose that it's an AI unless it's obvious, and users should be informed of AI functions, human oversight, and decision-making processes. Misclassifying the bot or launching it without approval can lead to fines. The bot should not influence public opinion on decisions like elections or impact public discourse on social media. User data should be anonymized and sensitive information protected when made public. The Euclidean algorithm does not qualify as an AI system under the EU AI Act because it doesn't operate autonomously or generate predictive outputs. Finally, the AI Act primarily targets EU member countries, but its scope extends to global providers and deployers of AI systems that are made available or intended for use within the EU. This means that all countries housing such providers or deployers will be impacted by the law.

The discussion on this submission includes several comments. 
- **gkk** mentions that they have discovered that Markdown formatting does not work well for long documents. They also suggest that there might be similar effects when it comes to using AI models for reasoning and performance assessments. 
- **gkk** also introduces Hotseat AI, an AI-powered Q&A service that aims to answer questions about the EU AI Act. They mention that Hotseat AI uses a collaborative FAQ format and provides high-quality community references on AI regulation. They explain that Hotseat AI is currently focused on retrieval-based reasoning and is not using custom language models like GPT-4.
- **artninja1988** expresses frustration with the licensing rules, calling it a fundamental model that is confusing.
- **gkk** responds to artninja1988, mentioning that they are confused about the distinction between fundamental and high-risk models in the AI Act.
- **whtspkrlsn** congratulates the team on the execution of the AI Act.
- **jkzr** asks about the ETA for questions and mentions waiting for the response on the Product Hunt launch.
- **gkk** responds to jkzr, stating that it takes about 90-120 seconds to compute an answer, but sometimes midway computations are needed, which can take longer. They assure that fixed answers will be provided soon and that they are working on addressing step-by-step computations.

### AI startup Lamini bets future on AMD's Instinct GPUs

#### [Submission URL](https://www.theregister.com/2023/09/26/amd_instinct_ai_lamini/) | 21 points | by [gdiamos](https://news.ycombinator.com/user?id=gdiamos) | [6 comments](https://news.ycombinator.com/item?id=37661836)

Machine learning startup Lamini has announced that its large language model (LLM) refining platform is running exclusively on AMD's Instinct GPUs. While other big AI clusters typically use Nvidia GPUs, Lamini has chosen AMD's GPUs for their platform. Lamini's platform has attracted interest from companies like Amazon, Walmart, eBay, GitLab, and Adobe. AMD hopes to bring more attention to its accelerator story and has seen a seven-fold increase in AI customer engagements since its datacenter event in June. Lamini has specifically chosen AMD's hardware because it eliminates waiting times for GPU shipments.

The discussion around Lamini's decision to run their large language model (LLM) refining platform on AMD's Instinct GPUs includes various points. One user mentions that it is exciting work and suggests investing in Lamini. Another user shares that they have hosted their own AMD cluster and provide information explaining how it works. They also mention that many customers start collecting data on cloud platforms like Azure and AWS and then scale up to more powerful AMD GPU servers in their own data centers. It is mentioned that Lamini's platform is horizontally scalable and optimized using AMD's API. The scalability is highlighted further, with another user mentioning that over 100 AMD GPUs are produced per year and can scale to thousands of MI GPUs. The discussion also includes a user leaving a comment with just their domain name.

### AI is fundamentally ‘a surveillance technology’

#### [Submission URL](https://techcrunch.com/2023/09/25/signals-meredith-whittaker-ai-is-fundamentally-a-surveillance-technology/) | 223 points | by [skilled](https://news.ycombinator.com/user?id=skilled) | [173 comments](https://news.ycombinator.com/item?id=37656091)

In a thought-provoking speech at TechCrunch Disrupt 2023, Signal president Meredith Whittaker highlighted the deep connection between artificial intelligence (AI) and surveillance technologies used by companies like Google and Meta. According to Whittaker, AI is essentially a surveillance technology that relies on the data collected from users. She argued that the development and expansion of AI are closely intertwined with the surveillance business model, with AI systems used to analyze and make predictions about individuals' behavior and emotions. Whittaker also drew attention to the fact that the data for training AI models is often organized and annotated by low-paid workers, resulting in precarious labor conditions. She emphasized that behind the impressive façade of AI, there may not be as much intelligence as one would expect. While not all AI systems are exploitative, Whittaker pointed out that the economic incentives driving the development of facial recognition technology go far beyond the limited positive use cases such as blurring faces in photos.

The discussion surrounding the submission on Hacker News revolved around several main points. 

One commenter argued that the ability of legal systems to respond quickly and protect individuals is limited, in contrast to the fast pace of technological advancements. They also emphasized that AI capitalism is driven by economic incentives rather than representing users' rights.

Another commenter highlighted the connection between AI and surveillance technologies, expressing concern that AI is fundamentally a surveillance technology that relies on data collection. They also brought attention to the precarious labor conditions of low-paid workers who organize and annotate data for training AI models.

There were disagreements regarding the implications of AI and surveillance. Some argued that the connection between AI and surveillance is exaggerated and that AI can have positive applications beyond surveillance. Others mentioned how AI can optimize surveillance, but not all AI systems are exploitative.

There was also discussion about the semantic aspects of the debate, with some commenters pointing out that the terminology used, such as "surveillance business model," can be misleading.

Overall, the commenters engaged in a thought-provoking discussion, exploring various perspectives on the relationship between AI and surveillance technologies.

