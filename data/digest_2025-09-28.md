## AI Submissions for Sun Sep 28 2025 {{ 'date': '2025-09-28T17:15:26.552Z' }}

### The AI coding trap

#### [Submission URL](https://chrisloy.dev/post/2025/09/28/the-ai-coding-trap) | 641 points | by [chrisloy](https://news.ycombinator.com/user?id=chrisloy) | [393 comments](https://news.ycombinator.com/item?id=45405177)

The AI coding trap: Code gets written 10x faster, delivery improves maybe 10%

This essay argues that coding is the easy, visible slice of software work; the real effort is understanding the domain, shaping requirements, designing abstractions, testing, and integration. AI agents flip the flow to “code first, ask questions later,” which makes human review and integration harder because the thinking happened after the fact. Hence the gap between flashy “10x coding” and the ~10% gains teams actually see.

The author likens this to the tech lead’s dilemma: either fairly delegate (slower now, stronger team later) or “mollycoddle” by hoarding the hardest work (faster now, brittle later). Over-reliance on a single expert leads to silos, burnout, and fragility.

The proposed “third way” is process, not heroics: practices that minimize rework and maximize learning—code reviews, incremental delivery, modular design, TDD, pair programming, good docs, and CI. In an AI-first world, treat LLMs like lightning-fast but unpredictable junior engineers: powerful contributors inside guardrails, not autonomous code cannons.

**Summary of Discussion:**

The discussion revolves around the tension between AI's coding speed and the broader challenges of software development. Key points include:

1. **Code Quality & Understanding**:  
   - AI-generated code often lacks the underlying reasoning and domain understanding humans develop, leading to "messy" codebases. However, participants debate whether this differs meaningfully from legacy human-written code, which also requires significant effort to decipher.  
   - Inheriting AI-generated code forces developers into constant "Day 1" scenarios, fixing issues without building mental models, risking stagnation.

2. **Accountability & Process**:  
   - Accountability remains with engineers, not AI. While AI tools can expedite tasks, humans must validate outputs, enforce testing, and maintain documentation.  
   - Traditional practices (code reviews, TDD, modular design) are emphasized as critical guardrails to manage AI’s unpredictability.

3. **AI's Role vs. Human Expertise**:  
   - Some argue AI excels at automating tedious tasks (e.g., boilerplate code), freeing developers for higher-level design and problem-solving. Others warn against over-reliance, noting AI’s tendency to introduce subtle errors and incomplete solutions.  
   - Skilled developers using AI may produce better outcomes than novices, highlighting the enduring value of expertise in prompting and contextual reasoning.

4. **Cultural Shifts & Paradigms**:  
   - The industry faces a paradigm shift: AI’s exponential growth could render some tasks (e.g., writing trivial code) obsolete, but understanding system architecture and domain logic remains irreplaceable.  
   - Concerns arise about "lazy" practices, where AI-generated code bypasses critical thinking, leading to fragile systems.

5. **Historical Parallels**:  
   - Comparisons to past struggles (e.g., COBOL code maintenance) suggest messy code is not new, but AI amplifies scalability challenges. Proper documentation and validation are seen as timeless solutions.

**Conclusion**:  
Participants agree AI is a powerful tool but stress that its value hinges on integration with human oversight, robust processes, and a focus on cultivating deep domain knowledge. The real challenge lies in balancing speed with sustainable engineering practices.

### The QMA Singularity

#### [Submission URL](https://scottaaronson.blog/?p=9183) | 78 points | by [frozenseven](https://news.ycombinator.com/user?id=frozenseven) | [31 comments](https://news.ycombinator.com/item?id=45406911)

Scott Aaronson: Limits to black-box amplification in QMA — and an AI-assisted proof step

- Aaronson and Freek Witteveen posted “Limits to black-box amplification in QMA” to arXiv, showing that black-box methods can’t push QMA completeness beyond doubly-exponentially close to 1, nor make soundness super-exponentially small, relative to a quantum oracle.
- This matches—and proves optimality of—the recent Jeffery–Witteveen amplifier that achieves doubly-exponential completeness. To beat that would require non–black-box, nonrelativizing techniques.
- Context: QMA is the quantum analogue of NP. Whether QMA can have “perfect completeness” (QMA = QMA1) remains open. Aaronson’s 2008 result gave an oracle where QMA ≠ QMA1; the new paper makes that separation quantitative using complex approximation theory.
- Notably, Aaronson credits “GPT5-Thinking” with a key idea: analyze Tr[(I − E(θ))^{-1}] to track how close the top eigenvalue can get to 1 via a bounded-degree rational function in θ—an insight that unlocked their lower bound.
- Takeaway: a crisp limit on error-reduction in QMA and a striking example of modern AI contributing a nontrivial step to a theoretical CS proof. Slides are linked in the post.

**Summary of Discussion:**

The discussion revolves around the role of AI (specifically "GPT5-Thinking") in contributing a key step to Scott Aaronson’s quantum complexity theory paper. Key themes include:

1. **Surprise and Skepticism**:  
   - Many express surprise that an AI model provided a critical insight, given expectations that such problems might already be addressed in existing literature (e.g., 1950s textbooks). Some speculate GPT-5 may have recycled patterns from training data rather than offering novel solutions, likening its output to "fuzzy approximations" of mathematical concepts.  
   - Skeptics argue the AI’s suggestion might have been a plausible-but-incorrect idea later refined by humans, akin to a "bright grad student" proposing an approach requiring correction.

2. **Originality and Attribution**:  
   - Debate arises over whether the AI’s proposed function (Tr[(I − E(θ))⁻¹]) is novel or resembles known constructs like the **Stieltjes transform** in random matrix theory. Some users note difficulty verifying originality due to the sheer volume of mathematical literature.  
   - Criticisms emerge about Aaronson not exhaustively checking prior work, though others defend the challenge of identifying relevant results in specialized fields.

3. **AI’s Role in Research**:  
   - Supporters highlight the efficiency gain: AI could compress weeks of human effort into hours, accelerating proofs. Critics counter that AI’s value lies in pattern-matching structured formal languages rather than "true reasoning."  
   - Broader implications are discussed: Could AI disrupt academia by solving problems faster than humans, or will it remain a tool aiding experts?

4. **Conflict of Interest Concerns**:  
   - Aaronson’s affiliation with OpenAI and stock options draw scrutiny, with some questioning potential bias. Others dismiss this, emphasizing the paper’s technical rigor over financial motives.

5. **Philosophical and Existential Musings**:  
   - A tangent explores AI’s long-term impact on mathematics and science, including timelines for human irrelevance, economic disruption, and existential risks. Some envision a future where AI dominates research, rendering human efforts obsolete.

**Notable Subpoints**:  
- Comparisons to **Batson-Spielman-Srivastava** techniques in eigenvalue analysis.  
- References to academic integrity (e.g., AI watermarking, plagiarism detection) amid ChatGPT’s rise.  
- Humorous nods to AI "singularities" and the irony of quantum computing experts relying on AI breakthroughs.

**Conclusion**: The discussion reflects cautious optimism about AI’s potential in theoretical research, tempered by skepticism about originality, attribution, and broader ethical/financial implications.

### Use the Accept Header to Serve Markdown Instead of HTML to LLMs

#### [Submission URL](https://www.skeptrune.com/posts/use-the-accept-header-to-serve-markdown-instead-of-html-to-llms/) | 68 points | by [hahnbee](https://news.ycombinator.com/user?id=hahnbee) | [57 comments](https://news.ycombinator.com/item?id=45409001)

Nicholas Khami proposes a simple content-negotiation trick: if a request’s Accept header prefers text/markdown or text/plain over text/html, serve a Markdown version of your pages. LLM agents don’t need CSS/JS-heavy HTML, and Markdown can cut token usage dramatically (Bun’s team reported ~10x fewer tokens), which could make your pages cheaper to crawl, more likely to be scraped, and potentially help SEO as agent traffic grows.

How it works
- Build-time conversion: Use @wcj/html-to-markdown-cli to turn your static site’s HTML into Markdown alongside your normal build output.
- Simple scripts: Move generated HTML into dist/html, convert to dist/markdown mirroring the structure, and keep both around.
- Content negotiation: If Accept includes text/markdown or text/plain before text/html, return the Markdown; otherwise, serve HTML.
- Try it live: curl -H "Accept: text/markdown" https://www.skeptrune.com

Cloudflare Workers setup
- Bind your build output as a static assets namespace via wrangler.jsonc and route all requests through a Worker.
- The Worker checks the Accept header order and serves from dist/markdown or dist/html using env.ASSETS.fetch.
- Tip learned later: run_worker_first = ["*"] can force the Worker to run before static assets, avoiding file shuffling.
- If you use a traditional reverse proxy (Nginx/Caddy), this is simpler to express with standard rules.

Why it matters
- Lower token costs for LLM scrapers and agents.
- Faster agent responses and fewer irrelevant tokens spent on styling/scripts.
- Potential SEO upside if agents are a meaningful share of traffic and cheaper pages get crawled more.

Quick start
- npm install -D @wcj/html-to-markdown-cli
- Add a post-build script to convert dist/html → dist/markdown
- In your edge/proxy layer, prefer Markdown when Accept lists text/markdown or text/plain ahead of text/html
- Test with curl as above

Author: Nicholas Khami (Skeptrune)
Date: September 27, 2025

Here's a streamlined summary of the Hacker News discussion on serving Markdown to LLMs:

### Key Themes  
1. **SEO Implications**  
   - Mixed views on whether optimizing for LLMs will replace traditional SEO. Some fear reduced human traffic if AI summaries answer queries directly (e.g., Google’s AI Overviews potentially lowering click-through rates). Others argue businesses must adapt to AI-driven traffic, as LLM recommendations could become a new "search engine."  
   - Concerns about LLMs favoring specific brands (e.g., LG/Samsung appliances) through structured recommendations, akin to product placement.  

2. **Technical Implementation**  
   - Debate on **content negotiation**: Suggestions to include `Vary: Accept` headers and `Link` tags for caching transparency. Some noted that reverse proxies (Nginx/Caddy) simplify Markdown/HTML routing.  
   - Skepticism about **browser-native Markdown support**, with most agreeing HTML remains dominant. Server-side conversion (e.g., lightweight parsers like `linkedom`) is favored over client-side rendering.  

3. **Utility of Markdown for LLMs**  
   - Critics questioned the need for Markdown, as LLMs can process HTML directly (e.g., stripping tags). Proponents argued pre-converted Markdown cuts token costs and speeds up scraping, especially for documentation sites (e.g., Mintlify adoption).  
   - Tools like Jina Reader, Readability.js, and Playwright were compared for HTML-to-Markdown efficiency.  

4. **Ethical and Practical Concerns**  
   - Risks of LLMs amplifying SEO spam or biased content. OpenAI’s cookbook suggests LLMs can parse XML/Markdown natively, raising questions about long-term relevance of this approach.  
   - Anecdotes of SaaS products gaining traction via LLM recommendations without traditional SEO, hinting at shifting discovery dynamics.  

### Notable Takeaways  
- **Adoption Risks**: Websites may face trade-offs between LLM optimization and human usability.  
- **Tooling Ecosystem**: Lightweight converters and server-side logic are preferred for scalability.  
- **Future-Proofing**: The approach hinges on LLM scraping trends, with some predicting it’s a temporary edge as AI adapts to HTML natively.  

The discussion reflects cautious optimism, balancing technical ingenuity with skepticism about long-term viability in the evolving AI landscape.

