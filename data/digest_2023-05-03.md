## AI Submissions for Thu May 03 2023 {{ 'date': '2023-05-03T15:01:43.244Z' }}

### GPT-4 Can’t Replace Striking TV Writers, but Studios Are Going to Try

#### [Submission URL](https://www.vice.com/en/article/pkap3m/gpt-4-cant-replace-striking-tv-writers-but-studios-are-going-to-try) | 48 points | by [shscs911](https://news.ycombinator.com/user?id=shscs911) | [36 comments](https://news.ycombinator.com/item?id=35806470)

The Writers Guild of America is currently on strike, protesting the use of AI as a replacement for human writers in film and television. The guild proposed to regulate the use of AI on union projects, but the Alliance of Motion Picture and Television Producers rejected the notion, calling the guild's request "absurd." Fears among writers include being underpaid to rewrite what they consider AI-generated "trash," and being replaced altogether by the machines. However, the reality is that AI still struggles to distinguish between true facts, has trouble personalizing outputs to users, and is very sensitive to framing and wording of prompts.

In the comments, users argue that AI is not yet advanced enough to fully replace human writers and that the WGA's request for regulations may be based on populist sentiment rather than a genuine need to protect its members. Some also suggest that AI-generated content could be useful for background material or non-dialogue scenes, while others question the legality of AI-generated material being awarded writing credits.

### Beware of AI pseudoscience and snake oil

#### [Submission URL](https://www.baldurbjarnason.com/2023/beware-of-ai-snake-oil/) | 233 points | by [bertman](https://news.ycombinator.com/user?id=bertman) | [171 comments](https://news.ycombinator.com/item?id=35800667)

The submission discusses the exaggerated claims of AI capabilities, the need for concrete evidence to back them up, and the importance of being skeptical. The discussion includes comments on the difference between pessimism and optimism in measuring AI capabilities, the misleading claims made by companies for marketing purposes, the risk posed by AI if not regulated properly, and the practical applications of AI. There is also a conversation about the terminology used to describe AI, including whether the term "lying" is appropriate, and criticism of the media for using sensational language to describe AI. Finally, there is a comparison made between the hype surrounding AI and the hype surrounding virtual machines and containers in the past, and the importance of technical experts in the decision-making process.

### NYC considers facial recognition ban for businesses, landlords after MSG debacle

#### [Submission URL](https://gothamist.com/news/nyc-council-facial-recognition-biometric-ban-businesses-landlords) | 18 points | by [lisasays](https://news.ycombinator.com/user?id=lisasays) | [5 comments](https://news.ycombinator.com/item?id=35810770)

New York City is considering introducing two bills that would restrict the use of facial recognition and other biometric surveillance technology by private businesses and landlords. The first bill would ban businesses from using facial scans or other biometric technology to identify customers, while the second would prohibit residential landlords from using the same sort of biometric identification of tenants and guests. The proposed legislation also includes requirements for explicit consent from tenants or customers for any other types of biometric data collection, and a ban on selling such data to third parties. The hearing follows previous efforts to restrict facial recognition tech in New York, including state legislators attempting to curb its use by landlords, government agencies and police.

The discussion revolves around the specifics of the bills, with some participants citing security concerns as a reason to allow the use of such technology while others argue in favor of privacy protection. Some commenters also dispute the effectiveness of facial recognition technology in preventing crime and suggest alternative solutions. One user proposes a solution of implementing a blacklist of people who have caused trouble in the past rather than resorting to facial recognition technology.

### The Discord Where Thousands of Rogue Producers Are Making AI Music

#### [Submission URL](https://www.vice.com/en/article/y3wdj7/inside-the-discord-where-thousands-of-rogue-producers-are-making-ai-music) | 21 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [3 comments](https://news.ycombinator.com/item?id=35808173)

A group of music producers and songwriters recently released an entire album called UTOP-AI that featured AI-generated versions of rapper Travis Scott's voice and other artists. However, the album was quickly taken down due to a copyright claim from Warner Music Group. As AI music becomes more popular, it has provoked a cultural debate. While AI creators defend the technology as a way to make music more accessible, many music industry professionals and other critics accuse creators of copyright infringement and cultural appropriation. The Discord server AI Hub hosts a large community of AI music creators behind some of the most viral AI songs, and it has over 21,000 users. However, the copyright issue in AI music is being heavily debated, with labels and publishers gearing up to tackle this new issue in the music industry.

One commenter named "slyll" asserts that copyright claims are becoming increasingly dubious since music producers can create songs with a similar style to famous artists without directly copying their music or lyrics. They argue that as long as the creator does not claim to be the original artist, and does not directly copy the music or lyrics, it should be legal. Another comment from "Nition" clarifies that the vocals used in AI-generated music are entirely created by an AI and not just manipulated versions of the original artists' vocals. A third commenter named "llmjms" did not have anything to add to the discussion.

### Amnesty International criticised for using AI-generated images

#### [Submission URL](https://www.theguardian.com/world/2023/may/02/amnesty-international-ai-generated-images-criticism) | 101 points | by [johnyzee](https://news.ycombinator.com/user?id=johnyzee) | [88 comments](https://news.ycombinator.com/item?id=35800210)

Amnesty International has faced backlash after using artificial intelligence (AI)-generated images to promote their reports on social media regarding the 2021 protests in Colombia. The images, which depicted instances of police brutality towards protesters, were criticised for being unrealistic and for undermining the human rights advocacy group's work by potentially feeding conspiracy theories. Amnesty's use of AI images raised questions about plagiarism and ethics in photojournalism. The group eventually removed the images and acknowledged the criticism but defended their intention of protecting protesters with anonymity.

Some commenters argue that the use of AI-generated images is part of a trend of human rights organisations relying on emotionally manipulative marketing campaigns to generate donations. Others point out that Amnesty International's budget is heavily spent on research and advocacy, rather than advertising, and that its efforts to protect protesters' anonymity were well-intentioned. The conversation also touched on related topics such as the use of AI-generated porn and the challenges of verifying identities in the porn industry. Amnesty International has acknowledged the criticism and removed the AI-generated images.

### AI vs. Hollywood: Writers battle “plagiarism machines” in union talks

#### [Submission URL](https://arstechnica.com/tech-policy/2023/05/ai-vs-hollywood-writers-battle-plagiarism-machines-in-union-talks/) | 19 points | by [m-watson](https://news.ycombinator.com/user?id=m-watson) | [3 comments](https://news.ycombinator.com/item?id=35806197)

The Writer's Guild of America (WGA) is seeking to limit the use of AI in writing film and TV scripts during an ongoing strike. WGA writers have raised concerns over AI-generated content being used as training data and the prospect of them being tasked with fixing "sloppy first drafts" created by AI. They also argue that existing scripts should not be used to train AI to avoid intellectual property (IP) theft. So far, studios have rejected WGA's proposals, instead offering to discuss new technologies annually. The strike is the first in 15 years and comes amid growing concerns over the impact of automation on jobs.

The first comment by "askin4it" expresses sarcasm towards the Writer's Guild of America for seeking to limit the use of AI in scriptwriting during a strike. The second comment by "crtrmn" suggests that the conflict could be easily resolved through cross-licensing deals. The third comment by "mansion7" argues that Hollywood and Silicon Valley are both supportive of high immigration numbers and replacing lower-paid American workers with foreigners, leading to political donations and complaints of xenophobia.

### “All Tomorrow’s Parties”: AI Synthesis – The End of Copyright as We Knew It

#### [Submission URL](https://www.heise.de/meinung/All-Tomorrow-s-Parties-AI-Synthesis-The-End-of-Copyright-as-We-Knew-It-8985282.html) | 23 points | by [walt74](https://news.ycombinator.com/user?id=walt74) | [11 comments](https://news.ycombinator.com/item?id=35799116)

In the age of machine learning, intellectual property and copyright laws face radical upheaval due to generative AI systems. Lawsuits against AI companies highlight concerns over protecting and promoting art and creativity. The distribution mechanisms of collecting societies like GEMA or VG Wort managing member copyrights risk fraudulent claims with easy-to-use AI-generated content capable of boosting profits. Generative AI models like Stable Diffusion or ChatGPT operate like library-like cultural technologies that provide access to and multiply knowledge creating “stochastic libraries” for interpolable data spaces computed by algorithms. The interpolative nature of AI models creates a huge explosive force for existing systems of copyright with each synthetic image or generative text the result of multidimensional interpolation of the latent space posing unprecedented problems for copyright law.

The submission discusses how generative AI systems are challenging intellectual property and copyright laws. The comments address issues such as the difficulty of capturing 99% of AI-generated content under copyright law and the need for consistency in digital property concepts. Some argue that licensing systems could benefit creators, but others point out that copyright-based systems are based on capital purchase and disregard inherent creators. There are concerns about synthetic AI-generated voices causing problems for contracts requiring identifiable voices, as well as the potential for AI to become a tool for criminals. The discussion highlights the complexity of IP and copyright laws in the age of AI.

### Google, Microsoft CEOs Called to AI Meeting at White House

#### [Submission URL](https://www.reuters.com/technology/google-microsoft-openai-ceos-attend-white-house-ai-meeting-official-2023-05-02/) | 89 points | by [kamban](https://news.ycombinator.com/user?id=kamban) | [104 comments](https://news.ycombinator.com/item?id=35802698)

The CEOs of Google, Microsoft, OpenAI, and Anthropic are set to meet with Vice President Kamala Harris and other top officials to discuss AI-related concerns on Thursday. The invitation, seen by Reuters, emphasized President Joe Biden's expectation that companies ensure their AI products are safe for public use. The concerns around AI technology include privacy violations, bias, and proliferation of scams and misinformation. The Biden administration has also been seeking public comments on proposed accountability measures for AI systems. The meeting will be attended by Biden's Chief of Staff, National Security Adviser, and Secretary of Commerce, among others.

There was a lengthy discussion on this submission, covering a range of topics related to AI. Some users expressed concern that regulating AI is difficult and that existing regulations can unintentionally harm innovation or favor established players. Others argued that regulations can protect consumers and create a level playing field. There was also discussion around the rise of language models like GPT and how they could be used to deceive people. Several users remarked that LLMs need to be regulated to prevent misinformation, while others noted the difficulty of regulating speech and the potential for unintended consequences. Some users suggested that AI regulation would require the expertise of qualified committees and government agencies. Finally, one user suggested that OpenAI and Anthropic should focus on demonstrating the safe use cases of their technology, rather than solely lobbying for regulation.

### GPT AI Enables Scientists to Passively Decode Thoughts in Groundbreaking Study

#### [Submission URL](https://www.artisana.ai/articles/gpt-ai-enables-scientists-to-passively-decode-thoughts-in-groundbreaking) | 8 points | by [ianrahman](https://news.ycombinator.com/user?id=ianrahman) | [4 comments](https://news.ycombinator.com/item?id=35810969)

Scientists have used a ChatGPT-like AI model to decode human thoughts with unprecedented 82% accuracy from functional MRI recordings, opening up new opportunities for neuroscience, communication, and human-machine interfaces. However, this breakthrough also raises serious concerns about mental privacy, emphasizing the need for policies to prevent potential misuse of this technology. The researchers also acknowledged the limitations of the current model and stressed the importance of using a subject's own brain recordings for accurate AI model training.

The first comment by user "djmps" states that using technology like ChatGPT can help people with disability to communicate better. The subsequent comment by user "lrmls" adds that such technology could also improve diagnostic accuracy in neurological conditions and could potentially replace the current gold standard - neurological examination - which has low fidelity.

The second comment by user "p--w" expresses amazement at the technology's accuracy and is reading technical papers that explain how it works. Another user "strng" responds by saying that while the technology is impressive, it is essential to validate the AI's ability to decode thoughts from fMRI data. They also mention that speech and thoughts are not necessarily the same, so listening to speech signals may not always be equivalent to decoding thoughts accurately.

### 25% of jobs set to be disrupted in the next 5 years – A.I. could play a key role

#### [Submission URL](https://www.cnbc.com/2023/05/02/nearly-25percent-of-jobs-are-set-to-be-disrupted-in-the-next-five-years-wef.html) | 46 points | by [hochmartinez](https://news.ycombinator.com/user?id=hochmartinez) | [71 comments](https://news.ycombinator.com/item?id=35804808)

According to a report from the World Economic Forum, approximately 23% of all jobs will be disrupted in the next five years. The report indicates that technological advancements such as Artificial Intelligence and climate change are key drivers in the job losses expected to take place, with administrative and traditional security roles being the most affected. However, the report also highlights that certain industries such as education, agriculture, and health will see higher creation of jobs enabled by technology. The report stresses that the rise of the green economy and higher standards for environmental, social and governance practices within companies will provide the biggest drivers for future job creation.

The debate in the comments centers on the impact of increased productivity and whether it benefits consumers or producers more. Some see the destruction of jobs as inevitable and emphasize the need for higher qualifications, while others believe that growth and progress can coexist with job security. Some are also critical of socialism and suggest that capitalism helps channel people's efforts into constructive endeavors.

