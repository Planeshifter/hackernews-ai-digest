## AI Submissions for Sat Nov 11 2023 {{ 'date': '2023-11-11T17:09:37.043Z' }}

### Google uses int8 for LLM training

#### [Submission URL](https://old.reddit.com/r/LocalLLaMA/comments/17sbjsv/google_blog_posts_suggests_that_google_using_int8/) | 45 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [20 comments](https://news.ycombinator.com/item?id=38229928)

Google is utilizing reduced numerical precision of 8-bit integers (INT8) instead of 16-bit floats (BF16) for training its language models, according to a blog post. The company has built an accurate quantized training (AQT) library that allows machine learning engineers to achieve higher performance during training and higher model quality in production. This approach takes advantage of the fact that ML accelerators have twice the compute speed when using INT8 operations compared to BF16 operations. If Google can successfully train models using INT8, it could potentially pave the way for more cost-effective training methods that could be adopted by the open-source community.

Discussion:

1. User "nbckng" points out that the use of reduced precision in training models can lead to suboptimal solutions and may not converge to the desired outcome. They mention that some researchers have published work on binary activations and stochastic fashion for training neural networks.
2. User "sigmoid10" adds that differentiability is essential in training models using gradient descent, regardless of the specific mathematical methods employed. They mention that there are alternative training methods for neural networks that do not rely on differentiability.
3. User "stvnhng" disagrees with the statement that the human brain does not work similarly to how training models do. They mention that there is relevant research suggesting that the brain reduces uncertainty by making predictions based on internal models.
4. User "thrwbdbd" suggests that building mathematical numbers using bits can be done by operating between partitions. User "rscy" adds that arithmetic can be implemented between partitions, but lower precision and smaller value ranges may lead to fewer bits being required.
5. User "_nalply" believes that four bits might be sufficient for quantization because small changes have small effects in differentiable mathematical functions.
6. User "blstnc" comments with a sarcastic remark about the discussion.
7. User "xrd" questions the significance of the missing mental model and suggests that the difference in representation and cost between GPU and CPU storage may be the primary reason for not using floating-point values.
8. User "wlg" brings up Elon Musk's statement about using int8 training for Tesla's Full Self-Driving (FSD) system.
9. User "gnzl" argues that high precision is needed in touch interactions, mentioning that it is necessary for precise positioning.

The discussion mainly revolves around the benefits and limitations of using reduced precision in training language models, with users sharing their thoughts, opinions, and providing additional information or examples related to the topic.

### Show HN: GPT-4 vision utilities to browse the web

#### [Submission URL](https://github.com/reworkd/tarsier) | 8 points | by [asim-shrestha](https://news.ycombinator.com/user?id=asim-shrestha) | [4 comments](https://news.ycombinator.com/item?id=38234305)

Reworkd has released an open-source utility library called Tarsier, designed to help automate web interactions. Tarsier is specifically targeted at multimodal web agents, such as agents that combine natural language processing with vision capabilities. The library allows users to visually "tag" interactable elements on a webpage, providing a mapping between elements and identifiers for the agent to take actions on. Tarsier also includes OCR utilities that can convert a screenshot of a webpage into a text representation that can be understood by agents without vision capabilities. The library currently supports Google Cloud Vision, with plans to add support for other OCR services in the future. Tarsier is available on GitHub under the MIT license.

The discussion on this submission mainly revolves around the README of Tarsier not accurately reflecting the mentioned features. One user points out that the README states that the library supports Google OCR, while the OpenAI API key makes more sense in the context of GPT-4 version. Another user suggests that the Google OCR should convert the screenshot into whitespace-structured text, which would be more useful for multimodal language models (LLMs) such as GPT-4V. The original submitter thanks for the feedback and promises to clarify the information.

### AI startups in France

#### [Submission URL](https://techcrunch.com/2023/11/09/theres-something-going-on-with-ai-startups-in-france/) | 51 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [58 comments](https://news.ycombinator.com/item?id=38232006)

France is emerging as a major hub for artificial intelligence (AI) startups, with a large talent pool of PhD students in math, computer science, and engineering. Companies like Facebook and Google have set up AI research labs in Paris, attracting top talent. Mistral AI, a French AI startup that raised €105 million in seed funding, demoed its open-source language model, Mistral AI Chat, at a tech meetup. Poolside, a company aiming to make coding easier using AI, raised $126 million and is based in Paris. Other AI startups, such as Dust and Nabla, are also gaining traction in France's growing AI ecosystem. The French government is providing public support to AI startups, offering grants worth millions of euros. European AI startups are distinguishing themselves by considering regulation and compliance from day one. Additionally, several stealth AI startups are emerging in Europe, including Adaptive, which helps companies iterate on their AI applications, and Wiem Gharbi's Paris-London-based AI venture. Notable French entrepreneurs are also starting AI startups, such as Steeve Morin, co-founder of Zenly, and Maxime Germain, founder of mental health startup Jour. With a surge in AI startup activity in France, venture capital firms are vying for the most competitive funding rounds.

The discussion on this submission covers a range of topics related to France's AI ecosystem, the influence of language on thinking and problem-solving, and the challenges of doing business in France. 

- Some users discuss the strong mathematics culture in France, attributing it to the country's education system and the emphasis on math in schools. They also mention the strong presence of French mathematicians in international competitions like the International Mathematical Olympiad (IMO).
- Others comment on the trendiness of AI and how France, particularly Paris, has become a hub for AI research and startups. They attribute this trend to factors such as the presence of top talent, the establishment of AI research labs by companies like Google and Facebook, and public support from the French government.
- A few users engage in a discussion about language and its influence on thinking and problem-solving. They touch on topics like the Sapir-Whorf hypothesis and the differences between languages in terms of how they represent concepts and affect cognition.
- Some users share personal experiences working with French researchers and point out the challenges of language barriers in international collaborations.
- There is also a brief exchange about the difficulties of doing business in France, including labor laws and paperwork requirements. Some users highlight the protections provided by labor laws, while others mention the potential barriers and extra costs for businesses.
- The topic of holidays and work-life balance in France is briefly mentioned, with some users comparing it to the work culture in other countries, particularly the United States. The discussion touches on the length of vacations, the perception of productivity, and the importance of taking time off.

Overall, the discussion provides insights into the strengths and challenges of France's AI ecosystem, the role of language in cognition, and the nuances of doing business in the country.

### Show HN: Stories for Kids Using AI

#### [Submission URL](https://storybee.app) | 14 points | by [niksmac](https://news.ycombinator.com/user?id=niksmac) | [20 comments](https://news.ycombinator.com/item?id=38228672)

Introducing StoryBee, the AI-powered platform that effortlessly converts stories into audio! With StoryBee, you can generate kids' stories anytime and anywhere. The platform features curated stories generated by AI, including heartwarming fairy tales like "The Kindness of the Orange Tabby Cat" and thrilling adventures like "The Mysterious Kingdom Under the Sea." Creating stories with StoryBee is a breeze – simply provide a story hint, customize it to your liking, and let the AI work its magic. StoryBee aims to ignite children's curiosity, fuel their dreams, and take them on enchanting journeys through magical storytelling. Whether you're a parent or an educator, StoryBee is the perfect tool for creating captivating and educational stories for children. So dive into the world of magical storytelling with StoryBee and watch dreams come to life!

The discussion on this submission revolves around the concept of AI-generated storytelling and its impact on children. One user points out that AI-generated stories lack depth and genuine character development, compared to human-written stories. Another user shares their frustration with the lack of quality reading time children have due to exposure to native language speakers and YouTube videos.

There is also discussion about the potential benefits of AI-generated illustrations and the suggestion to incorporate screen time in small kids' school activities. Some users express concerns about the ethical implications of relying solely on AI-generated content for children.

The conversation diverges to discussing the importance of reading real books and the role of parents and teachers in spending quality time with children. There is also a mention of the responsibility of parents to ensure the quality and appropriateness of content for their children.

The topic of AI-generated stories is further explored, with one user sharing an example of an AI-generated story and expressing concerns about the perpetuity of AI-generated content. There is a brief discussion about the terms of service and privacy policy of StoryBee, and the need for simplicity and clarity in legal terms.

In the later part of the discussion, users suggest alternatives to StoryBee, such as using GPTs or exploring other platforms focused on illustrations. There is also mention of pricing comparisons and the potential launch of downloadable PDF versions of stories for interested parents.

### Fourteen Years of Go

#### [Submission URL](https://go.dev/blog/14years) | 218 points | by [keyle](https://news.ycombinator.com/user?id=keyle) | [291 comments](https://news.ycombinator.com/item?id=38229001)

Today marks the fourteenth birthday of the Go open source release, and the Go team is celebrating a great year of milestones. Two feature-filled releases, Go 1.20 and Go 1.21, focused on implementation improvements rather than new language changes. One notable improvement is the profile-guided optimization (PGO) feature, which allows the Go compiler to optimize the parts of a program that run most frequently. Workloads typically saw CPU usage improvements of 2% to 7% with PGO enabled. The Go team also made strides in compatibility, with improvements in backward compatibility through expanded conventions for using GODEBUG, as well as nifty new tooling features like built-in toolchain management and on-disk indexes in gopls. In terms of language enhancements, Go 1.21 introduced Go's first generic standard libraries, as well as the log/slog package for structured logging. The Go web community also got support for the WebAssembly System Interface (WASI) preview 1. On the security front, the Go team launched Govulncheck 1.0, a tool to help developers identify dependencies and vulnerabilities. They also made significant progress in ensuring reproducible toolchain builds. Looking ahead to Go's fifteenth year, the team has exciting plans, including redefining for loop semantics to avoid potential aliasing bugs. The Go team would like to express their gratitude to all the contributors and the Go community for their support and contributions. They wish everyone the best for the year ahead.

The discussion on the submission revolves around various aspects of the Go programming language. Some users express disappointment with the lack of certain language features and the trade-offs made by the language designers. There is a debate about the handling of errors and the usefulness of different language constructs. Some users argue that Go's lack of certain features is intentional and promotes simplicity, while others argue that these features are important for complex programs. One user points out that Go's design choices may not align with everyone's preferences and that different programming languages have different trade-offs. Another user mentions the importance of comprehensive testing and error checking to address common programming mistakes.

There is also a discussion about the naming conventions and usage of operators in Go, with some users finding them confusing or misleading. The debate touches on topics such as operator overloading and the limitations of the Go language in supporting certain assumptions. Additionally, there are comments expressing skepticism about the effectiveness of AI in assisting with programming and suggesting that the design of a program should be guided by human programmers rather than relying on AI-generated code.

Overall, the discussion reflects a mix of opinions on the strengths and weaknesses of the Go programming language and the trade-offs made in its design.

### Met Police Scans Almost 250k Faces Using Facial Recognition Technology in 2023

#### [Submission URL](https://bylinetimes.com/2023/11/10/revealed-met-police-scans-almost-quarter-of-a-million-faces-using-facial-recognition-technology-in-2023/) | 43 points | by [BerislavLopac](https://news.ycombinator.com/user?id=BerislavLopac) | [8 comments](https://news.ycombinator.com/item?id=38228709)

The Metropolitan Police in London has scanned nearly a quarter of a million faces using live facial recognition (LFR) software in 2023, according to Freedom of Information requests filed by Byline Times. The LFR system automatically scans the faces of passers-by and matches them against a watchlist. The Met took several months to respond to the FOI request, which revealed it had scanned an estimated 247,764 faces in 2023 during 13 deployments across London, resulting in just 12 arrests. Civil liberties groups and MPs have criticized the use of LFR, saying it is incompatible with human rights and has a chilling effect on freedom of speech. The use of LFR technology is currently being banned by the EU, but officers in London are continuing to use it.

The discussion surrounding the submission includes various perspectives on the use of live facial recognition (LFR) technology by the Metropolitan Police in London. One commenter, mb5, points out that the director of intelligence for the Met immediately deletes pixelated images. Others, such as adhesive_wombat, criticize the extensive surveillance and lack of regulatory oversight, suggesting that policing should focus on areas like schools, roads, and healthcare rather than using expensive AI systems. YuccaGloriosa suggests deleting the images once their purpose is fulfilled. InCityDreams mentions that face masks, which have become more common recently due to COVID-19, make LFR less effective in public spaces like shopping centers and road intersections. Finally, k1ns expresses surprise at the low number of arrests despite the large number of faces scanned.

