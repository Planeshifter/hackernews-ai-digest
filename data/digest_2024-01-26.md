## AI Submissions for Fri Jan 26 2024 {{ 'date': '2024-01-26T17:09:32.888Z' }}

### Google TPU v5p beats Nvidia H100

#### [Submission URL](https://www.techradar.com/pro/google-is-rapidly-turning-into-a-formidable-opponent-to-bff-nvidia-the-tpu-v5p-ai-chip-powering-its-hypercomputer-is-faster-and-has-more-memory-and-bandwidth-than-ever-before-beating-even-the-mighty-h100) | 168 points | by [wslh](https://news.ycombinator.com/user?id=wslh) | [128 comments](https://news.ycombinator.com/item?id=39148544)

Google has unveiled its latest tensor processing unit (TPU), the TPU v5p, which is its most powerful AI accelerator to date. The TPU v5p is designed to power Google's "AI Hypercomputer," a supercomputing architecture built specifically for AI applications. The TPU v5p features 8,960 chips per pod, compared to the 4,096 chips in the previous version, and offers four times the scalability in terms of total availability of FLOPs per pod. It also has 95GB of high-bandwidth memory (HBM) compared to 32GB in the previous version. Google claims that the TPU v5p is up to 2.8 times faster at training large language models than the TPU v4 and offers 2.1 times better value for money. The new TPU is also said to be rivaling Nvidia's H100 GPU, which is highly sought after for AI workloads. The TPU v4 is estimated to be between 1.2 and 1.7 times faster than Nvidia's A100 GPU, according to research published by Google in April. More detailed benchmarking is needed to determine the exact performance of the TPU v5p compared to the H100.

The discussion on Hacker News revolves around several key points:
1. There is skepticism about the dominance of Nvidia GPUs in training and inference, with comments suggesting that Nvidia's GPUs may not necessarily be the best choice for all AI applications.
2. There is a debate about the size and capabilities of training and inference models, with some commenters noting that larger models require more resources and specialized hardware to achieve optimal performance.
3. There is a discussion about the technical details of Google's TPU v5p and its comparison to Nvidia's H100 GPU. Some commenters analyze the specifications and suggest potential differences and advantages of each.
4. Commenters discuss the business and stock market implications of Google's TPU v5p and Nvidia's GPUs, questioning the understanding and perception of Wall Street regarding the technical details and profitability of these technologies.
5. The discussion also touches on the usage of TPUs compared to GPUs, with some commenters noting the differences and advantages of each for machine learning and graphics applications.
6. There are comments speculating about the internal testing and capabilities of Google and Nvidia's hardware, as well as the potential market demand and adoption of their products.
7. There is a technical debate about the specifications of Nvidia's GH200 and Google's TPU v5p, with some commenters providing detailed comparisons based on available documentation.

Overall, the discussion explores various aspects of Google's TPU v5p announcement and its potential implications for the AI industry, raising questions and offering different viewpoints on the topic.

### Tweets to Citations: The Impact of Social Media Influencers on AI Research

#### [Submission URL](https://arxiv.org/abs/2401.13782) | 65 points | by [sebg](https://news.ycombinator.com/user?id=sebg) | [47 comments](https://news.ycombinator.com/item?id=39144845)

In a new study titled "Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility," researchers Iain Xie Weissburg and his team explore the role of social media influencers in increasing the visibility and impact of machine learning research. With the number of accepted papers at AI and ML conferences continuously growing, it has become uncertain how researchers access and read research publications. The study focuses on the specific impact of social media influencers in boosting citation counts for papers they share. The researchers compiled a comprehensive dataset of over 8,000 papers, analyzing tweets from December 2018 to October 2023. They also created a control group of papers matched in terms of publication year, venue, and abstract topics. Their findings revealed a significant increase in citation counts for papers endorsed by these influencers, with median citation counts 2-3 times higher compared to the control group.

Moreover, the study delves into the geographic, gender, and institutional diversity of the highlighted authors, emphasizing the expanding influence of social media in scholarly communication. These findings underline the importance of embracing an evolving digital academic landscape and highlight the impact of social media in the dissemination of AI research. This study sheds light on the growing significance of social media influencers in the visibility and impact of AI research. It provides valuable insights for researchers, institutions, and the broader AI community on leveraging social media platforms to enhance research visibility and influence.

The discussion on this submission covers a range of topics related to AI research, social media influencers, and information dissemination. Here are some key points from the comments:

- Some commenters express skepticism about the causal relationship between social media influencers and citation counts for AI research. They argue that correlation does not prove causation and that other factors may contribute to increased visibility.
- Several users suggest alternative ways to stay updated on AI research, including using RSS readers or specific websites dedicated to aggregating and highlighting trending research papers.
- The idea of creating a searchable database for AI research papers is mentioned, with a user sharing a website called "trendingpapers.com" that was launched to help researchers find and explore trending papers.
- The discussion touches on the decline of Google Reader and the difficulty of finding alternative platforms to replace it for content aggregation.
- Some users discuss the challenges of keeping up with trends in AI research on Twitter and ask for recommendations on who to follow for AI paper recommendations.
- The use of Discord channels and GitHub repositories is mentioned as alternative platforms for discussions and sharing of research papers.
- A user questions the power of informal networks and the difficulty of quantifying their impact on citation metrics.
- There is a debate about the role of social media influencers in the AI research community, with some questioning the value of following specific individuals on Twitter for research recommendations.
- The issue of bias and gatekeeping in paper selection is briefly mentioned, with a user suggesting that relying on the recommendation of renowned researchers can lead to a narrow view of what constitutes important research.
- Some users express frustration with the current state of publication and citation practices in AI research, highlighting difficulties in understanding and reproducing results.
- The comment section also includes discussions about computer science digital libraries, the challenges of publishing in the field, and the inclusion of various subfields within computer science.

Overall, the discussion reflects a mix of perspectives on the influence of social media influencers, the availability of alternative platforms for research dissemination, and the challenges and limitations of current AI research practices.

### AMD Publishes XDNA Linux Driver: Support for Ryzen AI on Linux

#### [Submission URL](https://www.phoronix.com/news/AMD-XDNA-Linux-Driver-Ryzen-AI) | 216 points | by [pella](https://news.ycombinator.com/user?id=pella) | [85 comments](https://news.ycombinator.com/item?id=39137502)

AMD has released an open-source Linux driver, called XDNA, to provide support for Ryzen AI processors. The driver is currently out-of-tree but can be found on GitHub for those who want to check it out. AMD received more than 1,000 requests for Linux support following its October statement, and it seems they have been quietly working on it since then. The XDNA driver is compatible with AMD Phoenix/Strix SoCs and has been tested on Ubuntu 22.04 LTS with the Linux 6.7 kernel or newer. It also requires the Xilinx XRT software to be built to work with the driver. The documentation does not currently outline any plans for upstreaming the driver or the full extent of AMD's Linux support plans. However, Phoronix will be working to gather more information about AMD's Ryzen AI and XDNA Linux plans.

The discussion on the submission focuses on different topics related to AMD's open-source Linux driver and their support for Ryzen AI processors.
One commenter mentions that AMD has been supporting open-source software (OSS) for their network interface cards (NICs) for over 10 years and provides a link to Solarflare's project on GitHub that showcases their involvement. They also note that while there wasn't much collaboration in the past, there seems to be more support for open-source projects recently, including in Docker-related projects.
Another commenter raises a question about whether Strix Point and Strix Halo, which are mentioned in the summary, have been released. Another user replies that AMD's CEO recently confirmed the release of Strix Point laptop Zen 5, which is currently being tested by AMD partners, including Microsoft. They mention that Strix Point is still in the testing phase with external partners for preliminary versions of the software.
The discussion then shifts towards compatibility issues with AMD's ROCm framework on Linux for the 7900 XT graphics card. A user mentions that the ROCm team at Debian is working hard to get it to work, but there are challenges with building CI networks, testing packages, and handling dependencies. Another user suggests trying a fresh Linux install with Debian or Ubuntu to see if that resolves the issues.
There is also a conversation around AMD's software support and whether they prioritize it as much as their hardware. Some users express frustration with the quality of AMD drivers compared to Nvidia's drivers, particularly in gaming on Windows. One user mentions that AMD may not invest as much in software because Nvidia dominates the gaming market, while another user says that they expect Intel and Apple to provide alternatives to Nvidia's CUDA in the future.
Another user points out that AMD's OpenGL and Vulkan drivers on Linux have been performing well, and they are satisfied with the improvements in their GPU department under Lisa Su's leadership. However, there are contrasting opinions on whether AMD's software support matches their hardware quality.
A commenter raises the issue of AMD neglecting software development, suggesting that they lack the necessary resources to manage the complexities of software and criticize their lack of support for ML-based technologies like DLSS. Others join the discussion, highlighting the challenges of developing software for hardware and the frustration with AMD's software in comparison to their excellent hardware.
A discussion also emerges about the comparison between AMD's FidelityFX Super Resolution (FSR) and Nvidia's DLSS. Some users argue that FSR is worse than DLSS in terms of performance and quality, while others mention that the results vary depending on user experiences and personal preferences.
There are additional comments discussing the installation and requirements of PyTorch with AMD's ROCm, with users providing suggestions and clarifications.
Finally, a user expresses optimism about AMD's packaging and support in Debian, stating that they believe Debian's packaging system is reliable and recommending it for installation.

### Google's New AI-Powered Browser Could Mark the End of the Human Internet

#### [Submission URL](https://nymag.com/intelligencer/2024/01/new-ai-powered-google-chrome-browser-end-of-human-internet.html) | 90 points | by [leotravis10](https://news.ycombinator.com/user?id=leotravis10) | [91 comments](https://news.ycombinator.com/item?id=39147275)

Google is set to introduce an AI writing assistant in its Chrome browser, enabling users to write with more confidence. The feature will offer statistically likely responses and allow users to adjust the tone and length of their writing. Initially available as a right-click feature, the tool will potentially allow billions of people to have software write on their behalf in various online contexts, including emails, comment sections, social media sites, and job applications. The release of such AI writing assistants will be a test of how people want to use generative AI, with some questioning their suitability for social situations and contexts where evidence of humanity is valued.

The discussion on Hacker News revolves around various aspects of AI writing assistants. Some users express skepticism about the reliability and relevance of generated content, while others discuss the potential impact on different industries and the economy. There are also conversations about the limitations and challenges of benchmarking AI models, the use of AI for content generation in shadow libraries, the economic implications of AI replacing human work, and the potential problem of AI-generated content manipulation. Other discussions touch on the business models behind AI writing assistants, the implications for search engines, concerns about the loss of human touch and authenticity in communication, and the importance of clear and understandable communication. Some users also raise concerns about the potential misuse of AI-generated content for spam or deceptive purposes. Finally, there are discussions about the technical aspects of AI models, such as the size and efficiency of models, the use of WASM and TensorFlow.js, and the influence of various factors in the writing process.

### OpenAI and Others Will Have to Warn US Govt When They Start New AI Projects

#### [Submission URL](https://www.wired.com/story/openai-tech-giants-us-government-ai-projects/) | 6 points | by [antiviral](https://news.ycombinator.com/user?id=antiviral) | [5 comments](https://news.ycombinator.com/item?id=39149737)

The Biden administration is planning to use the Defense Production Act to require tech companies, including OpenAI, Google, and Amazon, to inform the US government whenever they train an AI model using a significant amount of computing power. The new rules are part of a White House executive order issued last year that aims to gain access to information about powerful new AI models in development, including details about computing power usage, data ownership, and safety testing. The requirement could take effect as soon as next week. The move comes amid concerns about the rapid progress in AI development and the potential risks associated with superintelligent models. Some experts argue that the government needs to be aware of what AI companies are working on, but others believe that more comprehensive AI regulation is needed. The Commerce Department is also set to implement another requirement of the executive order, which will compel cloud computing providers to report if a foreign company uses their resources to train a large language model.

The discussion about the submission on Hacker News revolves around a few different points. 
One user expresses concern about the potential impact the implementation of the Defense Production Act may have on the technology industry, specifically mentioning that it may disrupt the software industry and lead to job losses. Another user responds by arguing that artificial intelligence is already harmful to the software industry and that people have been too gullible about its promises. 
There is also a brief comment that warns the readers to consider the trade-offs associated with these regulations, without any further elaboration.
Overall, the discussion touches on the potential consequences of the government's involvement in AI development and regulation, with some expressing worry about the impact on industries and others highlighting existing concerns about AI's effects.

