## AI Submissions for Wed Apr 17 2024 {{ 'date': '2024-04-17T17:11:48.834Z' }}

### Collapse of self-trained language models

#### [Submission URL](https://arxiv.org/abs/2404.02305) | 87 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [30 comments](https://news.ycombinator.com/item?id=40068170)

Today's top story on Hacker News is about a research paper titled "Collapse of Self-trained Language Models" submitted by David Herel and Tomas Mikolov. The paper delves into the concept of self-training language models on their own outputs, similar to how humans learn and build on their previous knowledge. However, the research uncovers that prolonged self-training of the GPT-2 model results in a decline in performance, leading to repetitive and collapsed token output. This study sheds light on the practical limitations of this approach in the field of language models. If you're curious to learn more, you can access the full paper with the arXiv-issued DOI via DataCite.

The discussion on the research paper "Collapse of Self-trained Language Models" delves into various aspects related to self-training language models and their limitations. Some users discuss the progressive token generation process and the issue of the model's performance decline if trained for too long. Others explore the concept of Long Short-Term Memory networks and the challenges faced by self-training models. There are also discussions around the potential of self-training models in mimicking human learning behaviors, with some skepticism around the concept of infinite knowledge accumulation by humans. Additionally, there are mentions of the need for selecting criteria in training models effectively and how self-training can lead to degradation in AI systems. The conversation touches on a variety of topics related to language models, training methodologies, and the implications of self-learning mechanisms in AI research.

### Stable Diffusion 3 API Now Available

#### [Submission URL](https://stability.ai/news/stable-diffusion-3-api) | 239 points | by [roborovskis](https://news.ycombinator.com/user?id=roborovskis) | [55 comments](https://news.ycombinator.com/item?id=40065114)

The latest update on the Stability AI Developer Platform API introduces Stable Diffusion 3 and Stable Diffusion 3 Turbo, promising cutting-edge text-to-image generation capabilities, thanks to the innovative Multimodal Diffusion Transformer (MMDiT) architecture. By teaming up with Fireworks AI for reliable API services with high availability, Stability AI aims to provide enterprise-grade solutions for generative AI tasks. Emphasizing safety and responsible AI practices, Stability AI is dedicated to preventing misuse of their models and continually improving them with integrity. Excitingly, they plan to make model weights available for self-hosting soon, offering users the chance to explore their creativity with state-of-the-art AI tools. Stay tuned for more updates from Stability AI on their progress and deployment options!

The discussion on Hacker News revolves around the new Stable Diffusion 3 update on the Stability AI Developer Platform API. Users discuss various aspects, such as model releases for free commercial projects, subscription and revenue thresholds, undisclosed enterprise subscription pricing, and concerns regarding transparency. There are debates on pricing strategies, the implications of undisclosed enterprise pricing, and the impact on competition and negotiation. Additionally, users comment on the potential of the AI models released, self-hosting model weights, and comparisons with other platforms like Hugging Face.

### Security Vulnerability in Browser Interface Allows Computer Access via GPU

#### [Submission URL](https://www.tugraz.at/en/tu-graz/services/news-stories/media-service/singleview/article/sicherheitsluecke-in-browser-schnittstelle-erlaubt-rechnerzugriff-ueber-grafikkarte) | 99 points | by [jiripospisil](https://news.ycombinator.com/user?id=jiripospisil) | [48 comments](https://news.ycombinator.com/item?id=40062987)

The researchers at TU Graz have made a groundbreaking discovery regarding a security vulnerability in the browser interface that allows computer access via the graphics card. By exploiting the WebGPU interface, they were able to perform three different side-channel attacks successfully, even during normal internet surfing. This raises significant concerns about the security and privacy implications of utilizing the GPU for computing tasks on modern websites. The team's findings emphasize the importance of addressing access to the GPU as a critical security concern for browser manufacturers.

The discussion on Hacker News regarding the security vulnerability discovered by the researchers at TU Graz covers various topics related to disabling JavaScript, implications of GPU access through WebGPU, concerns about security and privacy, and the potential risks associated with GPU-based AES encryption. Users discuss the idea of selectively enabling JavaScript for trusted websites, the challenges with disabling hardware acceleration to prevent GPU access, and various opinions on the practicality and risks of different browsing configurations. There is also a conversation around the potential threats posed by WebUSB, WebSerialPort, and other web APIs that grant hardware access, raising concerns about device security and potential vulnerabilities. Additionally, there are mentions of WebBluetooth, WebUSBHID security concerns, and the possibility of malicious attempts to exploit these technologies. The discussion delves into the technical aspects of the WebGPU attack, the feasibility of such attacks, and the implications for AES encryption processed via the GPU. Further discussions touch upon the role of GPUs in JavaScript, the challenges of monitoring and analyzing data transferred between the GPU and CPU, and differing perspectives on the practicality and efficiency of potential attack scenarios involving GPU-based AES encryption.

### Show HN: Desbordante 2.0 – A high-performance data profiler

#### [Submission URL](https://github.com/Desbordante/desbordante-core) | 32 points | by [chernishev](https://news.ycombinator.com/user?id=chernishev) | [12 comments](https://news.ycombinator.com/item?id=40063137)

Desbordante is making waves in the data profiling world with its high-performance capabilities for discovering various data patterns using advanced algorithms. Whether you need to clean up data or enhance machine learning models, Desbordante's got your back. From functional dependencies to unique column combinations, this tool's got it all. Plus, you can access Desbordante through a console version, Python bindings, or a user-friendly web application. Dive into the world of data patterns with Desbordante today!

The discussion on the submission about Desbordante on Hacker News included various users sharing their insights and feedback. 

- **jszymbrsk** mentioned a comparison between different languages and their pronunciation variations of Desbordante. 
- **BrandoElFollito** delved into the etymology of the word "Desbordante" in French, hinting at its metaphorical implications.
- **lnvlllbs** shared a comment about sending messages in Spanish, receiving feedback from another user.
- **rmnvrs** discussed about checking the readme and expressing the need for improvements. This sparked a conversation with **chrnshv** suggesting enhancements and sharing useful links related to Desbordante.
- **rstrk** highlighted the clarity and user-friendliness of Desbordante with Python bindings, while also mentioning the idea of starting a Discord server, which **chrnshv** supported and shared a Google Groups link for communication purposes.

### Tailscale SSH is now Generally Available

#### [Submission URL](https://tailscale.com/blog/tailscale-ssh-ga) | 202 points | by [yarapavan](https://news.ycombinator.com/user?id=yarapavan) | [85 comments](https://news.ycombinator.com/item?id=40060901)

The latest announcement from Tailscale is that Tailscale SSH is now Generally Available. Tailscale SSH allows for managing the authentication and authorization of SSH connections on your tailnet. Users can utilize SSH as normal, authenticating with Tailscale according to configurable rules while taking advantage of features such as SSO, MFA, key rotation, and precise permissions enforcement in ACLs. This release is part of Tailscale's efforts to offer a fully zero-trust remote access solution, complete with enterprise features like user and group provisioning with SCIM.

Tailscale SSH has already become a crucial component for many users, particularly as a foundational element of enterprise ZTNA strategies, providing strong security-by-default and flexibility without the need for additional hardware or complex firewall rules. During the Beta period, Tailscale SSH has been refined and improved, now offering features like the Tailscale SSH Console for browser-based SSH sessions, support for remote port forwarding and SELinux, session recording, and a VS Code extension for editing remote files on nodes across your tailnet.

Whether you are already using SSH for remote access or looking to enhance your current setup, Tailscale SSH is available today on Personal, Premium, and Enterprise plans. The release of Tailscale SSH marks a significant step forward in providing secure and efficient remote access solutions for individuals and enterprises alike.

- **mkcl** shared their experience using Tailscale, emphasizing on its security features and the ease of managing SSH connections within a network using Tailscale.
- **hywdlh** expressed interest in SSH features and inquired about certain functionalities, such as notifications for successful login attempts and the use of journalctl for logging in Tailscale SSH.
- **bnnpb** raised concerns about potential security compromises related to immediate network access with Tailscale and the company's ACL configuration.
- **fransje26** highlighted the availability of a free tier for Tailscale and discussed its pricing compared to other offerings, adding insights on the business model and scalability costs.
- **zphr** recommended Tailscale for its cost-effectiveness and reliable performance, especially for VPN connections, addressing concerns about paid services and the value provided.
- **nine_k** discussed the unique handling of SSH by Tailscale, focusing on the authorization method through authorized_keys and its impact on network encryption.
- **dvdgl** explained the operation of Tailscale SSH command as a wrapper for the system's SSH command, enhancing functionalities like MagicDNS resolution and ProxyCommand system.
- **wnyny** compared Tailscale with Cloudflare Tunnels, highlighting differences in handling traffic and functions related to SSH offerings.

The discussion covers various aspects of Tailscale SSH, including security, pricing models, user experience, and comparisons with other networking solutions such as Cloudflare Tunnels. Users shared their experiences, concerns, and recommendations regarding Tailscale's features and functionalities.

### Feds appoint "AI doomer" to run US AI safety institute

#### [Submission URL](https://arstechnica.com/tech-policy/2024/04/feds-appoint-ai-doomer-to-run-us-ai-safety-institute/) | 17 points | by [notamy](https://news.ycombinator.com/user?id=notamy) | [3 comments](https://news.ycombinator.com/item?id=40070515)

The US AI Safety Institute, a part of NIST, has revealed its leadership team with Paul Christiano, a prominent figure in AI safety, at the helm. Known for his work in reinforcement learning from human feedback and his cautious stance on AI development potentially ending in catastrophe, Christiano's appointment has stirred controversy within NIST. Some fear his "AI doomer" perspective could overshadow the institute's objectivity.

Critics have raised concerns about Christiano's influence on NIST's focus, suggesting that attention on theoretical doomsday scenarios might divert efforts from tackling real-world AI challenges like ethics and bias. Despite differing opinions, Christiano's background in AI risk mitigation and founding the Alignment Research Center indicate his capability to lead the safety institute effectively.

Amidst the debate, the safety institute's leadership team comprises individuals with diverse expertise, including a Commerce Department official, an AI teaming expert, and a global AI policy specialist. This selection reflects a strategic approach to addressing AI risks while leveraging its benefits, as highlighted by US Secretary of Commerce Gina Raimondo.

As the US AI Safety Institute navigates the complex landscape of AI ethics and security, the impact of Christiano's leadership and the team's collective experience will shape the institute's contributions to advancing responsible AI practices.

The discussion on Hacker News includes comments on the choice of Paul Christiano to lead the US AI Safety Institute. One user, Vecr, criticizes the selection by stating that Christiano may not have experience managing large teams and that he comes from a theoretical physics background. Another user, rndcrw, expresses approval for NIST's decision, mentioning Christiano's technical expertise and ability to navigate political aspects in Washington. This user implies that critics may be motivated by corporate interests hindering advancements in AI for profit. Another user, remarkEon, questions the qualifications of AI safety scientists, suggesting that creating AI poses evident problems.

### Full Line Code Completion in JetBrains IDEs

#### [Submission URL](https://blog.jetbrains.com/blog/2024/04/04/full-line-code-completion-in-jetbrains-ides-all-you-need-to-know/) | 40 points | by [lolinder](https://news.ycombinator.com/user?id=lolinder) | [15 comments](https://news.ycombinator.com/item?id=40063252)

JetBrains IDEs have introduced a new feature called full line code completion in their latest update, v2024.1, which is powered by AI and runs locally without sending data over the internet. This feature offers gray-toned, single-line suggestions that complete lines based on the context of the current file, supporting languages like Java, Kotlin, Python, and more. With the goal of saving time and increasing coding speed, full line code completion works offline and does not send data over the internet. It is deeply integrated into JetBrains IDEs, providing correctly formatted suggestions and utilizing static analysis to filter out incorrect suggestions.

This feature distinguishes itself from JetBrains AI Assistant by focusing solely on code completion, while the AI Assistant offers a broader range of functionalities such as context-aware smart chat and test generation. Full line code completion is trained in-house using open-source code datasets and runs locally on the user's machine for efficiency. For developers looking to incorporate AI into their workflows without cloud connectivity, full line code completion in JetBrains IDEs offers a valuable solution to enhance coding productivity.

The discussion on the submission about JetBrains IDEs introducing a new full line code completion feature powered by AI is quite diverse. 

- Some users find the feature distracting and feel that it can potentially lead to errors if blindly accepted without verifying the suggestions or understanding the context.
- Others appreciate the convenience of full line code completion, particularly for completing boilerplate code quickly and efficiently.
- Concerns are raised about potential distractions caused by AI suggestions, especially when comparing it to existing AI assistants like Tabnine and GPT-4.
- Users discuss the benefits and drawbacks of AI-powered code completion, with some preferring single-line completions over multi-line suggestions for better focus and accuracy.
- The integration of AI in JetBrains IDEs, which works offline and respects user privacy by not sending data over the internet, is acknowledged as a significant advantage.
- There is also a technical discussion about code-assisted cases and the implications of full line code completion on different coding tasks such as refactoring and code implementation.
- Users compare the full line code completion feature in JetBrains IDEs to other AI-assisted tools like Copilot, highlighting differences in usability and distraction levels between single-line and multi-line completions.

