## AI Submissions for Wed Feb 04 2026 {{ 'date': '2026-02-04T17:26:29.442Z' }}

### AI is killing B2B SaaS

#### [Submission URL](https://nmn.gl/blog/ai-killing-b2b-saas) | 450 points | by [namanyayg](https://news.ycombinator.com/user?id=namanyayg) | [664 comments](https://news.ycombinator.com/item?id=46888441)

SaaS vs “vibe-coded” AI tools: why renewals are at risk and how to survive

Thesis
- AI has made it easy for teams to “vibe-code” internal tools that feel good and work fast, eroding the appeal of many B2B SaaS products.
- Customers now expect flexible, tailor-fit workflows—and will churn if they don’t get them.
- The market is pricing this in: software baskets lag tech, some marquee SaaS names are down sharply, and analyst sentiment is souring.

What’s happening
- Vibe coding: Non-technical teams can assemble CRUD/workflow apps across APIs with modern AI tooling. It’s fun, fast, and often “good enough.”
- Hidden fragility: These DIY tools skip fundamentals—auth, RBAC, rate limits, audit logs, backups, compliance (SOC 2, GDPR, HIPAA), secure key handling. They work…until they don’t.
- Churn pressure: Buyers see what’s possible and expect vendors to adapt. Examples: a team replaces a $30k engineering productivity tool with GitHub + Notion APIs; a six‑figure account at risk over a specific failure-reporting workflow the SaaS won’t support.

Survival playbook
- Be the System of Record: If daily workflows and data live in your product, you’re embedded and harder to rip out. Expect more SaaS to reposition their robust SoR as the core value, not just the app layer.
- Sell security and robustness explicitly: The value is invisible when it works. Educate customers on the true cost of DIY—auth, permissions, uptime, resilience, auditability, and regulatory obligations.
- Adapt to the customer: Win by being ultra‑customizable. Provide flexible workflows, APIs, extensions, and low-friction UI tailored to frontline users. Underutilized seats are the seed of churn.

Why it matters
- AI lowers switching costs and raises expectations. SaaS vendors that don’t offer deep extensibility and enterprise‑grade guardrails will lose renewals to fast, vibe‑coded alternatives—until those alternatives break.
- The opportunity: own the record, be the secure backbone, and make customization a first-class product feature.

**The Political Cost of "Vibe-Coding"**

While the article argues that AI enables rapid tool creation, the Hacker News discussion focuses heavily on the organizational barriers that prevent internal tools from replacing SaaS: corporate politics, liability, and the "hero" narrative.

*   **SaaS as Liability Insurance:** The top commenter argues that management often prefers expensive SaaS over bespoke internal tools—even "vibe-coded" ones—because vendors provide accountability. Buying software gives management "a throat to choke" when things break; building it internalizes the risk.
*   **The "Weekend Rewrite" Trap:** Several engineers shared anecdotes of rewriting bloated, failing enterprise projects in a single weekend, only to face backlash rather than praise. Commenters cited Robert Greene’s *The 48 Laws of Power* ("Never Outshine the Master"), noting that solving a problem too efficiently can embarrass leadership or expose the incompetence of larger teams, leading to career sabotage rather than advancement.
*   **The Firefighter Paradox:** User `fslth` highlighted a perverse incentive structure: organizations reward "firefighters" who fix visible crises caused by complex, bad software, while ignoring those who build simple, robust systems that prevent fires in the first place. This makes "boring," stable internal tools less career-advantageous than managing complex SaaS integrations.
*   **A "Build" Win:** offering a counter-narrative, user `ny` shared a success story of rejecting an expensive Google/Spanner proposal from consultants in favor of a simple, robust PostgreSQL/Elixir solution built internally for a fraction of the cost, emphasizing that technical simplicity can sometimes defeat the "sales pitch."

### Claude Code for Infrastructure

#### [Submission URL](https://www.fluid.sh/) | 252 points | by [aspectrr](https://news.ycombinator.com/user?id=aspectrr) | [169 comments](https://news.ycombinator.com/item?id=46889703)

Fluid: instant sandbox VMs that turn your shell session into Ansible

What it is:
- A context-aware CLI that clones isolated VMs in seconds so you can test changes safely before touching production.
- Logs every command and change for a full audit trail.
- Auto-generates Ansible playbooks from what you did in the sandbox, making ad‑hoc fixes reproducible.

Demo highlight:
- Spun up Ubuntu 22.04 sandbox SBX-demo1234.
- Ran apt update, installed Apache, added a custom index.html, verified with systemctl and curl.
- Produced an Ansible playbook (httpd-setup) with four tasks: update apt cache, install Apache, create index.html, enable and start apache2.

Why it matters:
- Bridges hands-on debugging with infrastructure-as-code, reducing risk and drift while improving reviewability and compliance.

Questions to watch:
- What’s the isolation backend (local hypervisor vs. cloud) and clone speed at scale?
- Cross-distro support and idempotency of generated playbooks.
- Secret management, diff/rollback capabilities, and pricing/licensing.

**Discussion Summary:**

The discussion branches into a critique of the developer-tool ecosystem and a broader debate regarding the intersection of software engineering and domain expertise:

*   **The "Tools" Pyramid Scheme:** Some users express cynicism regarding the "tools building tools" economy, describing it as a circular or pyramid-like scheme where value is exchanged between developers rather than reaching an end user. This drew comparisons to the Facebook App era of 2007, where the monetization strategy was circular and relied on viral mechanics rather than utility.
*   **Domain Experts vs. Software Engineers:** The core of the discussion debates whether it is more effective to teach a software engineer a complex domain (e.g., physics, finance) or to teach a domain expert how to code.
    *   **Argument for Experts:** Several commenters argue that deep domain knowledge (like theoretical physics) is harder to acquire than the Python scripts required to model it, suggesting domain experts can easily pick up coding as a tool.
    *   **Argument for Engineers:** Counter-arguments highlight that while scripting is accessible, building maintainable, scalable, and architecturally sound software requires specific professional expertise that domain experts rarely develop.
*   **The Role of AI:** Participants note that LLMs are shifting this dynamic, analyzing how AI allows domain experts to spin up software solutions that replace "Excel Hell." However, developers caution that this can lead to maintenance issues or hallucinations if not audited by professionals.
*   **The "Wizard" Effect:** The thread concludes with anecdotes about developers entering non-tech traditional industries; by using simple scripts to automate manual scheduling or logistics, they are often viewed as "wizards" by efficient but non-technical coworkers.

### RS-SDK: Drive RuneScape with Claude Code

#### [Submission URL](https://github.com/MaxBittker/rs-sdk) | 116 points | by [evakhoury](https://news.ycombinator.com/user?id=evakhoury) | [42 comments](https://news.ycombinator.com/item?id=46888142)

RS-SDK: A RuneScape-style bot sandbox for agentic development

What it is
- An open-source, research-focused starter kit for building and testing MMO automation bots, optimized for coding agents.
- Comes with a TypeScript SDK, an enhanced web client, a gateway, and a 2004-era RuneScape server emulator (fork of LostCity).
- Includes a public demo server and a leaderboard ranking bots by highest total level per lowest playtime.

Why it matters
- Provides a safe, bot-only environment to experiment with goal-directed program synthesis and multi-agent collaboration/competition without touching the real game.
- Useful for evaluating “agentic” development patterns, autonomy loops, and coordination in a rich, persistent world with economic and spatial complexity.

How it works
- Bots connect through a gateway to a web client that relays state and executes low-level actions (e.g., walkTo(x,y)).
- The demo server tweaks gameplay to speed up testing: faster leveling, infinite run energy, and no anti-bot random events.
- Chat is off by default to reduce scamming/prompt-injection risks; can be enabled via env.

Getting started
- Clone repo, install with Bun, and spin up a bot; includes a “create-bot” script and example integrations (e.g., Claude).
- You can run the full stack locally (engine, webclient, gateway) or target the hosted demo server.
- MIT licensed.

Caveats
- Not affiliated with Jagex; bots built here won’t work on official OSRS servers.
- Demo server uptime/data persistence not guaranteed; intended strictly for education and research.

Link: github.com/MaxBittker/rs-sdk (hiscores: rs-sdk-demo.fly.dev/hiscores)

**Legitimacy & Nostalgia**
The discussion is heavy with nostalgia, with many users citing RuneScape botting as their original gateway into programming. Commenters reminisced about historical tools like AutoRune, SCAR (Pascal/Delphi), and AutoHotKey, noting how the desire to automate gameplay drove them to learn coding concepts.

**Technical & Research Potential**
The creator (*pkpkpk*) and others discussed the project's utility for AI research.
*   Users see potential for testing explicit non-LLM machine reinforcement learning.
*   The creator expressed interest in fine-tuning smaller vision-language-action models.
*   It was clarified that the project runs on a fork of "Lost City" (a private server engine), creating a completely detached environment from Jagex's live servers.

**The "Nursing Home" Scenario**
A popular sub-thread revolved around a user's fantasy of retiring to a nursing home and running a simulated 2001–2003 era server populated by thousands of bots to recreate the game's "glory days." Others pointed out that projects like Open RuneScape Classic (rsc.vet) already keep these environments alive with a mix of bots and real players.

**The Philosophy of the Grind**
A debate emerged regarding the purpose of botting in MMOs:
*   **Pro-Bot:** Some argued that modern games use artificial tedium to force monetization (pay-to-skip), making botting a rational response to bypass repetitive tasks and access interesting content.
*   **Anti-Bot:** Others countered that in Old School RuneScape (OSRS), the grind *is* the game. They argued that because skills aren't usually pay-walled, botting to max level renders the achievement hollow and misses the point of the experience.

### Show HN: Morph – Videos of AI testing your PR, embedded in GitHub

#### [Submission URL](https://morphllm.com/products/glance) | 34 points | by [bhaktatejas922](https://news.ycombinator.com/user?id=bhaktatejas922) | [11 comments](https://news.ycombinator.com/item?id=46891827)

What it does: Glance reads your PR diff plus a staging URL and automatically figures out what to test in the browser—no manual scripts. It records videos, grabs screenshots, and collects console/network logs, then posts the results back to your PR.

How it works:
- “Diff-powered” testing: targets UI flows likely affected by the change
- Artifacts: MP4/WebM videos, animated WebPs (handy for Slack/Notion), screenshots, error and network logs
- BYO browser: run on managed browsers or your own via Playwright, Puppeteer, or Browserbase
- CI/CD: works in GitHub Actions, GitLab CI, etc., and supports common hosts (Vercel, Cloudflare, Railway)
- Framework-agnostic: React, Vue, Next.js, Svelte, Astro—anything that renders in a browser
- Org view: watch all PR runs across repos

Why it’s interesting: Reviewers can “see” what changed without booting the app, and teams get early UI regression signals—positioning it as a QA co-pilot inside the PR.

Pricing/availability: Installable GitHub app; $10/month in free compute to start.

Open questions HN may have: reliability/flakiness of auto-generated flows, auth/session handling details, tuning which paths it exercises, and costs beyond the free tier.

**Morph Glance: AI-generated PR test videos**
While the submission promises a QA co-pilot to auto-generate test videos for PRs, the discussion focused heavily on the broader implications of AI in the code review process.

*   **Visual Proof vs. Code Literacy:** Users were divided on the utility of video artifacts. `DhruvBhatia0` argued that visual proof is superior for speed, noting that previous employers mandated screen recordings because "watching a PR being tested" conveys logic faster than reading code. However, `cmeacham98` viewed this as a "major red flag," fearing it encourages a lack of professionalism where developers ship massive, AI-generated modifications without actually reading or understanding the underlying code.
*   **The Scale of Human Attention:** Responding to concerns that tools like this will normalize unmanageable 2,000-line PRs, the maker (`bhaktatejas922`) argued that human reviewers are already hitting a ceiling (averaging ~150 lines of code reviewed per day). They suggested that because human attention cannot scale to meet modern code demands, AI assistance is becoming a necessity rather than just a shortcut.
*   **Guardrails:** `dndgng` suggested the tool should default to requiring manual intervention rather than fully automated flows, positioning it as an aid for explicit conversations rather than a bypass for oversight.
*   **Meta Concerns:** There was minor skepticism regarding building tooling on proprietary platforms (`tstl`) and some meta-commentary regarding the signal-to-noise ratio on the front page.

### A real-world benchmark for AI code review

#### [Submission URL](https://www.qodo.ai/blog/how-we-built-a-real-world-benchmark-for-ai-code-review/) | 50 points | by [benocodes](https://news.ycombinator.com/user?id=benocodes) | [26 comments](https://news.ycombinator.com/item?id=46891860)

Qodo releases a code review benchmark that injects defects into real, merged PRs to test both bug detection and best‑practice enforcement at PR scale. Instead of backtracking from historical fix commits (à la Greptile/Augment), Qodo analyzes active, production-grade repos to extract project-specific rules, filters for clean merged PRs, then uses an LLM to inject compliance violations and 1–3 functional bugs per PR across diverse stacks (TypeScript, Python, JS, C, C#, Rust, Swift). The initial dataset spans 100 PRs and 580 issues, aiming to mirror full, system-level review complexity. In head-to-head tests against seven AI code review tools, Qodo reports the top F1 score at 60.1%. The benchmark and evaluated reviews are publicly available on GitHub.

**Discussion Summary:**

The discussion on Hacker News focused heavily on skepticism regarding the benchmark's validity and criticism of the product's pricing model:

*   **Benchmark Skepticism:** Users immediately flagged the potential conflict of interest, summarized by one commenter as "Company creates benchmark, company tops benchmark." There were concerns about overfitting and the exclusion of State-of-the-Art (SOTA) models—specifically Anthropic’s Claude—from the comparison, leading to accusations that the tests were designed to favor Qodo.
*   **Pricing & Limits:** Substantial criticism was directed at the pricing structure ($30/dev/month), with specific backlash against the 20 PRs/month limit. Senior developers argued this cap is "highly limiting" or akin to a "toy product," noting that active developers often exceed that volume in a single day.
*   **Methodology Debate:** While Qodo injects bugs into "clean" merged PRs, commenters debated this approach. Some suggested that historical data (analyzing reverts and subsequent bug fixes) provides a better ground truth for what constitutes a bad PR than artificial injection. Others noted that LLMs are often better at pattern enforcement (custom linting) than providing the deep, architectural insights promised.
*   **Alternatives:** Users compared the value proposition unfavorably to tools like Cursor or simply using an LLM API directly, with some competitors promoting cheaper alternatives in the comments.

### Claude is a space to think

#### [Submission URL](https://www.anthropic.com/news/claude-is-a-space-to-think) | 472 points | by [meetpateltech](https://news.ycombinator.com/user?id=meetpateltech) | [253 comments](https://news.ycombinator.com/item?id=46884883)

Anthropic says Claude will stay ad-free, positioning the chatbot as “a space to think,” not a place for ads.

Key points
- No ads or product placements: Claude’s responses won’t be influenced by advertisers, and users won’t see sponsored slots beside chats.
- Why: AI chats are open-ended and often personal; ad incentives could subtly steer advice, prioritize engagement over usefulness, and introduce unpredictable behavior as models optimize for revenue.
- Even “separate” or opt-in ads are a no-go: Anthropic argues ad incentives tend to expand over time and erode clarity about motives.
- Business model: Revenue comes from enterprise contracts and paid subscriptions. They’ll reinvest into Claude, keep a strong free tier via smaller frontier models, and consider lower-cost tiers and regional pricing. If this stance changes, they promise transparency.
- Access efforts: Discounts for nonprofits, educator programs in 60+ countries, and national AI education pilots with governments.
- Privacy and safety: Conversation analyses are private/anonymous; early research shows both benefits and risks, reinforcing caution about ads.
- Commerce stance: They’ll support user-driven “agentic commerce” (Claude handling purchases/bookings on your behalf) and tools to find/compare/buy—without advertising.

Why it matters
- A clear line in the sand on AI monetization, contrasting with ad-funded internet models.
- Positions Claude as a trusted work/thinking tool for enterprises and individuals, while betting on subscriptions over attention.

Based on the discussion, users reacted with a mix of cautious optimism and deep cynicism regarding Anthropic’s "no ads" pledge.

**"Good Guy Marketing" vs. Genuine Values**
Much of the conversation focused on whether this stance is a moral choice or a strategic differentiator.
*   **differentiation:** Users argued this is calibrated "Good Guy Marketing" designed to contrast sharply with OpenAI, especially as rumors circulate about OpenAI introducing ads. By positioning themselves as the "ethical" alternative, Anthropic captures a specific market segment.
*   **The Apple Comparison:** several commenters likened this to Apple’s stance on privacy—a business decision that happens to align with user benefits, but ultimately serves the bottom line.
*   **Skepticism:** Users noted that "corporations are psychopaths" (referencing *Meditations on Moloch*) and that profit incentives usually override values over time. While some hope Anthropic’s Public Benefit Corp (PBC) status offers protection, others fear they will eventually succumb to shareholder demands and "sell out" like competitors.

**Anthropic vs. OpenAI**
The thread framed Anthropic largely in opposition to OpenAI.
*   Sam Altman was characterized by some as a "villain" or "Darth Vader," making Anthropic the default "good guy" simply by not being OpenAI.
*   Users expressed a "lesser of evils" preference; even if Anthropic is just paying lip service to ethics, users prefer that over companies that don't bother trying at all.

**Concerns Beyond Ads**
despite the praise for the ad-free stance, users flagged other areas where Anthropic’s "ethical" branding feels inconsistent:
*   **Defense & Surveillance:** Commenters pointed to partnerships with Palantir and potential defense contracts as evidence that the company is willing to compromise values for revenue.
*   **Regulation & Open Source:** Critics noted Anthropic’s lobbying against open data/weights and support for regulation, viewing it as an attempt to pull up the ladder against open-source competition rather than a safety measure.
*   **Funding:** There was a disputed back-and-forth regarding whether the company has taken Saudi investment, adding to the trust debate.

### Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation

#### [Submission URL](https://arxiv.org/abs/2602.00294) | 160 points | by [fheinsen](https://news.ycombinator.com/user?id=fheinsen) | [91 comments](https://news.ycombinator.com/item?id=46886265)

HN Summary: Self-Attention at constant cost per token via symmetry-aware Taylor features

- The pitch: Heinsen and Kozachkov claim a drop‑in reformulation of Transformer self‑attention whose compute and memory per token don’t grow with context length. You pick a precision, pay a fixed per‑token cost, and can then generate unbounded sequences without quadratic (or even linear) growth.

- How it works (intuitively): Softmax attention depends on exp(q·k). They expand this with a Taylor series and reorganize the terms into symmetric tensor “chains,” then exploit symmetry to build a minimal polynomial‑kernel feature basis. Queries/keys are mapped through lightweight feed‑forward transforms into these features; attention reduces to a constant‑size set of running statistics you update once per token.

- Why this is different from prior “linear attention”: Kernelized/feature‑map attentions (e.g., Performer/FAVOR+) approximate softmax with random or structured features. The novelty here is a symmetry‑aware Taylor decomposition that removes redundant terms and yields a minimal, deterministic basis you can scale to arbitrary precision (by increasing order) while keeping per‑token cost independent of context length.

- Practical implications:
  - Fixed compute/memory per token enables truly streaming, unbounded generation and long‑context inference on modest hardware.
  - Because cost is tied to head dimension (and “fixed inversely in proportion to head size,” per the authors), you can potentially afford more attention heads per token than usual at the same budget.
  - Could cut inference energy and infra costs for LLMs if it holds up at scale.

- What’s validated: An implementation and empirical checks that the approximation reproduces standard attention as you increase order. The paper is 12 pages (+appendix) with code linked.

- Caveats to watch:
  - “Arbitrary precision” means you pick an approximation order; higher precision increases the constant factor. The trick is whether a low order suffices for real LLMs without quality loss.
  - Stability, training dynamics, and integration with common tricks (causal masking, rotary/relative positions, multi‑query/grouped KV, mixed precision) need to be shown at scale.
  - Prior polynomial/feature approaches sometimes degrade on difficult distributions or very long contexts; benchmarks beyond correctness tests will matter.

- Bottom line: A clean, theory‑driven route to constant‑cost attention by collapsing softmax into a compact symmetric polynomial feature space. If it trains and serves large models competitively, it could be a meaningful step toward cheap long‑context LLMs. Code is available; worth keeping an eye on real‑world throughput/quality results.

Here is a summary of the discussion:

**Skepticism and Theoretical Limits**
*   **The "Free Lunch" Debate:** A significant portion of the discussion focuses on whether constant-cost attention is theoretically possible without degrading quality. User `lgcchns` argues that sub-quadratic attention must inherently lose information, preventing perfect recall of previous tokens. They posit that checking relationships between $N$ tokens is fundamentally similar to sorting or extensive logical comparison, which cannot be compressed without loss.
*   **Counter-arguments on Complexity:** Others (`rlp`, `CrazyStat`) push back against the "information loss" argument by citing other algorithms (FFTs, Karatsuba multiplication, convolutions) that perform global operations or interactions faster than their naive quadratic or polynomial complexities. They argue that if the underlying structure admits a compressed representation (like the proposed Taylor features), $O(N^2)$ compute is not a strict requirement for accuracy.
*   **Comparison to Prior Failures:** User `thmshl` notes a "graveyard" of hundreds of papers claiming near-linear attention that failed because they masked lower quality or couldn't overcome lower bounds on specific matrix problems.

**Numerical Precision and Stability**
*   **Magnitude of Error:** There is debate over the paper's claimed error rates. `jcrrr` and `cptrt` note that with 4-8 Taylor terms, the method reproduces conventional attention with error magnitudes comparable to Float16 resolution, which is generally acceptable for current AI applications.
*   **Taylor Series Behavior:** `trgns` raises concerns about the use of Taylor series, noting they can converge slowly for certain functions or exhibit "Gibbs oscillations" (energetic swings) near discontinuities, potentially introducing instability that standard Softmax avoids.
*   **Context Rot:** `fhnsn` points out that standard quadratic attention already suffers from "context rot" in long sequences due to accumulated numerical errors in low-precision (4-bit to 16-bit) environments. They argue that if the new method's error is within that existing noise floor, it may be viable.

**Practical Implementation & Structural Assumptions**
*   **Latent Structure:** `nskng` observes that the method relies on exploiting latent structure in the data. If the target problem (e.g., complex logic or reasoning) does not fit this approximated structure, the "universal approximation" capabilities might fail where brute-force attention succeeds.
*   **Training vs. Inference:** `dave_universetf` clarifies for others that while standard inference is technically $O(N)$ per token (due to scanning the KV cache), this proposal reduces it to $O(1)$ (constant state update). However, they note that the quadratic bottleneck remains a fundamental constraint during the training of Transformer architectures.

**Tone**
*   The reaction is mixed with strong caution. while some see it as a potential "black swan" or "Millennium Prize" level breakthrough if true (`energy123`), the majority treat it as likely another approximation that will degrade on hard benchmarks, similar to previous linear attention attempts.

### Show HN: Ghidra MCP Server – 110 tools for AI-assisted reverse engineering

#### [Submission URL](https://github.com/bethington/ghidra-mcp) | 288 points | by [xerzes](https://news.ycombinator.com/user?id=xerzes) | [66 comments](https://news.ycombinator.com/item?id=46882389)

Ghidra MCP Server: AI tooling for reverse engineering lands in production shape

What it is
- A production-ready Model Context Protocol (MCP) server that lets AI tools drive Ghidra. Think decompilation, call graphs, xrefs, memory mapping, bulk renames/comments/typing—exposed as MCP tools for automation and LLM-assisted workflows.

Why it matters
- Bridges modern AI assistants and reverse engineering at scale: sub‑second responses for most ops, atomic batch transactions, and cross‑binary documentation via function-hash matching to keep symbols/comments consistent across versions.

Highlights
- 100+ MCP tools/endpoints covering function analysis, data/segments, xrefs, disassembly, and full call graphs
- Cross-binary docs: normalized opcode hashing for matching functions across builds
- Batch operations with big API-call reductions and all‑or‑nothing semantics
- Live integration with Ghidra’s analysis engine, multi-program support, headless mode
- Stdio (for AI tools) and SSE transports; Docker/headless workflows supported
- Apache-2.0 licensed

How to try
- Requirements: Java 21, Maven 3.9+, Ghidra 12.0.2, Python 3.8+
- Build and deploy the extension, run bridge_mcp_ghidra.py (stdio or SSE), then in Ghidra: Tools > GhidraMCP > Start MCP Server (defaults to http://127.0.0.1:8080/)
- API includes calls like decompile_function, get_function_call_graph, get_xrefs_to/from, analyze_data_region, get_bulk_function_hashes

Repo: https://github.com/bethington/ghidra-mcp

Here is a summary of the discussion on Hacker News regarding the Ghidra MCP Server:

**The Problem and The Solution**
The project's author (*xrzs*) entered the discussion to explain the specific pain point this tool solves: the loss of work when analyzing software updates. Typically, when a binary updates (e.g., v1.07 to v1.08), memory addresses shift, breaking existing annotations. This tool uses a normalized function hashing system (ignoring specific addresses and immediate values) to fingerprint functions logic. This allows annotations, variable types, and names to port over automatically. The author validated this approach by rebuilding the symbol registry for dozens of patch versions of *Diablo II*.

**Comparisons and Alternatives**
The release sparked a discussion on how this differs from existing solutions:
*   **BinDiff / FunctionID:** Users questioned if Ghidra’s native version tracking capabilities were sufficient. It was noted that native tools often produce false positives or negatives due to poor operand masking, whereas this tool layers additional heuristics to improve correlation.
*   **The "MCP" Ecosystem:** Commenters noted a rapidly growing field of similar tools, comparing this submission to projects like **ReVa**, **GhidrAssist**, and **LaurieWired’s GhidraMCP**. The author clarified that this project actually began as a fork of LaurieWired’s plugin but expanded significantly (from ~15 tools to 110+ tools and ~28k lines of code) to support complex batch operations and Docker workflows.

**AI in Reverse Engineering (RE)**
Multiple users shared success stories regarding AI-assisted RE, validating the utility of the tool:
*   One user successfully generated a keygen for software that "phones home" to a defunct server, finding the AI workflow much faster than writing manual scripts.
*   Another is using the tool to assist in porting a PowerPC game to Apple Silicon.
*   A third user utilized AI to extract encryption keys hidden within Android app shaders (a method used to bypass standard API monitors).

**Model Performance**
There was specific feedback on which LLMs perform best for decompilation tasks:
*   **Gemini 1.5 Flash:** Several users criticized it for "silent failures," such as omitting switch blocks or producing plausible-looking but functionally incorrect code.
*   **Claude (Opus/Sonnet) & Qwen:** These models were generally cited as superior for generating accurate C code from disassembly, with fewer hallucinations than the Gemini models.

### Show HN: Interactive California Budget (By Claude Code)

#### [Submission URL](https://california-budget.com) | 39 points | by [sberens](https://news.ycombinator.com/user?id=sberens) | [18 comments](https://news.ycombinator.com/item?id=46891290)

I’m ready to summarize, but I don’t see the submission. Please provide one of the following:
- The Hacker News link or item ID
- The article URL
- The title plus the text/content you want summarized

Also let me know your preferred length (e.g., 2–3 sentences or a short paragraph).

Based on the comments provided, here is the summary of the discussion regarding a tool used to visualize the **California State Budget**:

**Discussion**
Users praised the tool for its UI and open availability, with several requesting features like inflation adjustments (constant vs. nominal dollars) and longer historical timelines to better contextualize data. The conversation sparked a policy debate about California's spending efficiency, particularly regarding Prop 98 (K-12 education) and whether high funding levels align with educational outcomes or are lost to administrative overhead. Other users scrutinized specific items, such as a sharp $8 billion increase in higher education spending—attributed by some to high expected tax revenues from the AI boom—and expressed broader skepticism regarding debt growth and the efficacy of housing non-profits.

### Epstein Financed German AI Researcher Joscha Bach

#### [Submission URL](https://www.zdfheute.de/politik/ausland/epstein-deutscher-forscher-foerderung-100.html) | 36 points | by [doener](https://news.ycombinator.com/user?id=doener) | [7 comments](https://news.ycombinator.com/item?id=46891631)

ZDF: Newly released DOJ “Epstein files” show Jeffrey Epstein bankrolled German AI researcher Joscha Bach with over $1M from 2013–2019, helping move his family to Boston, covering living costs and travel, and brokering an MIT Media Lab affiliation. Emails, chats, and bank records reviewed by ZDF with Der Spiegel and Der Standard depict repeated requests from Bach followed by transfers ranging from $25k to $115k, including help with a 2018 tax bill. A 2014 email has Epstein introducing Bach to former US Treasury Secretary Larry Summers as “my AI guy.” An MIT internal report had previously tallied about $300k from Epstein tied to Bach’s Media Lab work. Bach confirmed Epstein “significantly enabled” his US stay, said funding had “no strings” and didn’t influence his research, but now says he should have given greater weight to ethical concerns. The documents also show Bach attending Epstein-hosted meetings and visiting Little St. James in 2015. The revelations deepen scrutiny of Epstein’s reach into elite science networks and revive questions about academic funding due diligence, particularly at MIT.

The discussion surrounding the ZDF report turns a critical eye toward Joscha Bach’s defense strategies and the specific content of his correspondence with Jeffrey Epstein.

*   **Critique of Bach's Defense:** Users shared links to Bach’s Substack response and a Reddit thread analyzing it, characterizing his defense as "damning." A significant portion of the conversation focused on a rebuttal by journalist Nafeez Ahmed, who challenged Bach's claim that the controversy stems from a "public misunderstanding of private scientific discussion." Ahmed argued that Bach’s scientific framing of race, heritability, and developmental variance is fundamentally misleading and unsupported by the literature he cites.
*   **eugenics and Fascism Claims:** Commenters highlighted disturbing excerpts from the emails exposed in the investigation. Beyond AI funding, the correspondence allegedly included proposals regarding "genetically altering populations," "mass executions" of the elderly, and "rational framed fascism."
*   **Moral Condemnation:** Users expressed outrage that Bach appears to be "playing the victim" and complaining about "control of public discourse" rather than apologizing. Commenters contrasted this with others associated with Epstein who have publicly expressed shame. The combination of taking money from a convicted sex offender (post-2008) and engaging in "pseudoscientific discussions supporting fascist conclusions" drew sharp rebukes.
*   **Media Presence:** There was tangential criticism of Bach’s interview style. Some users described him as someone who "eloquently talks shit," suggesting that interviewers like Lex Fridman provide "ultra-softball" platforms that allow such rhetoric to go unchallenged.

