## AI Submissions for Thu Jun 12 2025 {{ 'date': '2025-06-12T17:11:54.747Z' }}

### EM Eavesdropping Attack on Digital Microphones Using Pulse Density Modulation

#### [Submission URL](https://www.usenix.org/conference/usenixsecurity25/presentation/onishi) | 33 points | by [gnabgib](https://news.ycombinator.com/user?id=gnabgib) | [3 comments](https://news.ycombinator.com/item?id=44263577)

In a groundbreaking study, researchers from the University of Electro-Communications and the University of Florida have revealed a novel electromagnetic side-channel attack that can covertly eavesdrop on digital MEMS microphones using pulse density modulation (PDM). This innovative method capitalizes on the ability to retrieve audio information from the harmonics of digital pulses through standard FM demodulation, enabling attackers to listen in on conversations without any physical tampering or software interference on the targeted devices.

The study demonstrated this vulnerability on various devices, such as laptops and smart speakers, achieving remarkable accuracy in recognizing spoken digits even from a distance of 2 meters and through a 25 cm concrete wall. Impressively, the attack managed to transcribe speech using popular speech-to-text APIs with low error rates, utilizing only a rudimentary copper tape antenna.

Current defense mechanisms, such as signal resampling, prove inadequate against this type of attack, prompting the authors to propose a new defense strategy based on clock randomization. This research underscores a significant security flaw in modern digital microphones, urging the reconsideration of how we protect electronic communications from unforeseen electromagnetic threats.

The full study and its proceedings are freely accessible, thanks to USENIX's commitment to Open Access. This means anyone interested in exploring the research can review the detailed findings, thus promoting transparency and awareness in cybersecurity advancements.

The Hacker News discussion highlights two key points from the research on electromagnetic side-channel attacks targeting digital MEMS microphones:

1. **Prior Art Recognition**: A user ([HocusLocus](https://news.ycombinator.com/user?id=HocusLocus)) references [related 2016 research](https://techcrunch.com/2016/11/23/security-researchers-can-turn-headphones-into-microphones/) demonstrating how headphones could be repurposed as microphones, suggesting this new study builds on earlier vulnerabilities in audio hardware.  
2. **Mitigation Debate**:   
   - A commenter ([tetris11](https://news.ycombinator.com/user?id=tetris11)) speculates about potential software-based defenses.  
   - Another user ([dnkrs](https://news.ycombinator.com/user?id=dnkrs)) clarifies that the paper proposes a **hardware-level countermeasure** (clock randomization) rather than a software fix.  

The exchange underscores familiarity with prior research in this domain and clarifies the nature of the defense mechanism proposed in the study.

### Show HN: Eyesite – Experimental website combining computer vision and web design

#### [Submission URL](https://blog.andykhau.com/blog/eyesite) | 125 points | by [akchro](https://news.ycombinator.com/user?id=akchro) | [23 comments](https://news.ycombinator.com/item?id=44253307)

In a fascinating DIY project, an innovative tech enthusiast sought to mimic the capabilities of Apple’s Vision Pro without shelling out the hefty $3,500 price tag. The result? A homemade eye-tracking website interface dubbed "Eyesite" that lets users interact with webpages just by looking at them. Using the WebGazer.js library, the creator laid the groundwork for eye-tracking on a budget. 

Through a method involving calibration—getting users to look at, and click on, specific points for accurate gaze mapping—this project combines computer vision and web design in a novel way. The gaze functions as a virtual mouse, while users click with the spacebar, echoing the Vision Pro's look-and-pinch feature.

Initially, a red dot visualized the user's focus area, but it proved more of a distraction, so it was axed for a more seamless experience. To indicate interaction, buttons glow and pop when the user's gaze lands on them, despite the inherent jitteriness of the eye-tracking. This necessitated larger UI elements, ensuring usability on bigger screens.

The creator notes that Eyesite is a demo, with its code openly accessible on GitHub. While it might not be the epitome of clean coding practices, it’s a fun and immersive project ripe for iteration and development by other tech enthusiasts. Visit [GitHub here](https://github.com/akchro/eyesite) if you’re interested in exploring or expanding upon this innovative project.

The Hacker News discussion around the DIY eye-tracking project **Eyesite** highlighted several key themes:  

### **Technical Feedback & Improvements**  
- Users critiqued the **calibration process**, suggesting dynamic methods (e.g., Lissajous patterns or Tobii-like gaming calibration) to replace static points, which were deemed tedious.  
- Challenges like **jittery gaze data**, drift, and latency were noted, with proposals for smoother feedback (e.g., "ghost cursor" approximations) and optimizations using tools like Mediapipe’s face landmarks.  
- Technical limitations: Webcam-based tracking struggles with blink detection and requires larger UI elements for reliability on bigger screens.  

### **Academic Context & Prior Work**  
- Commenters referenced foundational research, including **WebGazer** (Brown University/Georgia Tech, 2016) and studies on gaze-based page-load optimization (USENIX NSDI 2017), positioning Eyesite within broader HCI (Human-Computer Interaction) research.  

### **Privacy & Ethical Concerns**  
- Debates arose over **surveillance risks**—e.g., public eye-tracking billboards for ads—and the ethics of attention-grabbing digital displays (e.g., animated road ads in the Netherlands). Critics labeled ubiquitous tracking a "negative externality," while others pragmatically accepted advertising’s role in commerce.  

### **Creative Applications & Accessibility**  
- Suggestions included **eye-tracking games** (via WebGL) and navigation interfaces for accessibility, though concerns about overhead and lag were raised.  
- Users praised the project’s experimental spirit, comparing it to Apple’s Vision Pro for its "natural" feel, despite being a rough demo.  

### **Creator Engagement**  
- The creator (**kchr**) engaged with feedback, acknowledging calibration fatigue, experimenting with blink detection, and expressing interest in implementing ghost cursors.  

### **Broader Implications**  
- Discussion veered into societal impacts of eye-tracking tech, citing examples like intrusive Malaysian building ads and dystopian "spy mannequins" in retail.  

Overall, the thread blended technical problem-solving with ethical reflection, celebrating DIY innovation while urging caution about privacy and usability. The project’s GitHub openness invites further tinkering, embodying HN’s hacker ethos.

### Agentic Coding Recommendations

#### [Submission URL](https://lucumr.pocoo.org/2025/6/12/agentic-coding/) | 271 points | by [rednafi](https://news.ycombinator.com/user?id=rednafi) | [198 comments](https://news.ycombinator.com/item?id=44255608)

With the tech community abuzz about agentic coding, Armin Ronacher dives into how he's navigating this paradigm shift. Relying predominantly on Claude Code's Sonnet model via an economical Max subscription, he highlights an efficient, agent-based approach to coding that deprioritizes traditional IDEs. This workflow has reignited his use of minimalist editors like Vim, even as innovation rapidly transforms best practices.

Cutting through the complexity, Ronacher shares his strategy of disabling permission checks—for efficiency—while acknowledging associated risks. He leverages the powerful yet underused MCP protocol selectively, citing its utility in specific scenarios like browser automation using playwright-mcp.

In choosing tools, simplicity reigns: Ronacher recommends Go for backend projects, favoring its straightforward context management and test caching capabilities, which streamline agentive loops—contrasting his frustration with Python's complexity and performance. For frontend needs, Tailwind, Vite, React with Tanstack’s query, and router prevail, despite some minor agent confusion in file naming peculiarities.

Overall, Ronacher's insights underscore the importance of adaptive yet efficient tool utilization in agent-driven development, reflecting on how this swiftly-evolving field requires continuous recalibration of practices and technology stacks.

**Summary of Hacker News Discussion:**

The discussion around Armin Ronacher’s agentic coding workflow reveals mixed reactions and nuanced insights from developers experimenting with AI tools like Claude Sonnet. Key themes include:

1. **AI Efficiency vs. Skepticism**:  
   - Many praise AI (e.g., Claude Sonnet) for automating tedious tasks like fixing `mypy` errors, reducing boilerplate, and aiding code comprehension. However, skeptics argue AI often generates verbose or incorrect code, requiring significant human validation. One user likened LLMs to "producing boilerplate at scale," risking technical debt if not carefully managed.

2. **Workflow Strategies**:  
   - Users shared workflows leveraging Claude within VS Code, emphasizing **context management** (e.g., detailed prompts, project-specific Markdown files) to improve AI accuracy. Some recommend splitting tasks into planning/implementation phases, with tools like Gemini Pro for complex planning and Sonnet for execution.
   - Criticisms of AI’s limitations include struggles with file-naming conventions, overcomplicating solutions, and failing to grasp local project context without explicit guidance.

3. **Language Preferences**:  
   - **Go** is favored for backend work due to simplicity and test caching, while **Rust** is praised for clear error messages that aid AI debugging. Python’s type-checking complexity and performance issues drew frustration, though AI tools help mitigate some pain points.

4. **Challenges and Risks**:  
   - Users highlighted risks like AI-generated code introducing subtle bugs, reliance on corporate AI providers, and the "jarring" hype cycle around agentic tools. Some noted that while AI accelerates mundane tasks, it may distract from deeper problem-solving.

5. **Community Resources**:  
   - References to blog posts by Simon Willison, Cloudflare’s tools, and Steve Klabnik’s writings were shared as practical guides for integrating AI into coding workflows.

**Takeaway**: The consensus is that AI tools like Claude Sonnet offer tangible productivity gains but require careful oversight, clear context, and iterative refinement to avoid pitfalls. Developers stress balancing AI-assisted efficiency with critical thinking to maintain code quality.

### It took longer to get the API key

#### [Submission URL](https://algarch.com/blog/the-api-keys-took-longer-than-the-code-why-human-processes-are-the-real-bottleneck-in-ai-development) | 24 points | by [jdalton](https://news.ycombinator.com/user?id=jdalton) | [35 comments](https://news.ycombinator.com/item?id=44258189)

In a striking post that captures the frustrations many developers face, one coder shared an experience highlighting just how backwards our industry priorities have become. Tasked with integrating Google’s Indexing API into their Laravel app, the developer turned to Claude, an AI assistant, and within 34 seconds, the integration was complete. This wasn't some quick and dirty hack job, but a thorough, production-ready implementation including comprehensive error handling, environment checks, and documentation, all tailored to the project’s needs.

However, acquiring the Google API keys was a different story, drenched in bureaucracy and inefficiency. It took 20 minutes of navigating through multiple Google consoles, managing service accounts, downloading cryptic JSON files, and setting permissions. This glaring discrepancy between AI’s rapid, on-point delivery and the sluggish human processes presents a significant bottleneck in modern development.

The post argues that we, as an industry, have become obsessed with optimizing our code and tools, while overlooking the more glaring inefficiencies—our processes. The AI managed to handle the complex engineering tasks with ease, yet it was the human bureaucracy that consumed the time. In actual projects, up to 80% of time can be spent navigating approvals and configurations, a striking contrast to the actual coding.

This experience shouldn’t just perturb developers but keep managers awake at night. The efficiency and pace at which AI can develop solutions underscore an urgent need to streamline how organizations handle processes. As AI capabilities grow, the bottleneck isn’t technical prowess but bureaucratic overhead—a "Process Tax" of human coordination.

Organizations need to rethink traditional workflows and redefine their competitive edge. The focus should shift towards minimizing process delays—by ensuring rapid environment provisioning, automating workflows in lieu of manual ones, and favoring speed and iteration over elaborate planning. The winners in the tech landscape will be those who not only embrace AI’s technical potential but who also drastically cut down on the time lost to processes, achieving what the author calls a “new competitive moat” based on process efficiency rather than solely technical ability.

The discussion revolves around the juxtaposition of AI's rapid coding capabilities versus the inefficiencies of bureaucratic processes, especially in acquiring API keys. Key points from the comments include:

1. **AI-Generated Code**:  
   - While AI (like Claude) can generate **production-ready code** in seconds, concerns arise about its **maintainability** and adherence to existing patterns. Critics argue that code quality, consistency, and security require human oversight (e.g., code reviews, QA).  
   - Some users dismiss AI-generated code as "disposable" if not maintained by humans, emphasizing that follow-through (debugging, documentation) matters more than initial speed.

2. **Process Overhead**:  
   - Acquiring API keys (Google, AWS, etc.) is universally criticized as **overly complex and time-consuming**, reflecting systemic inefficiencies in big cloud providers.  
   - Participants highlight **non-coding tasks** (meetings, approvals, context-switching) as major time sinks, with one user noting engineers spend more time on "ancillary work" than coding itself.

3. **Proposed Solutions**:  
   - A "**traffic-light system**" for PR reviews: AI handles low-risk (green) checks, humans handle critical (red) reviews, and ambiguous (yellow) cases require collaboration.  
   - Automating workflows (e.g., Jira integrations) could reduce delays, though skeptics point out that AI can't yet fix broken project management processes.

4. **AI's Role in Human Workflows**:  
   - While AI excels at generating code within specific contexts, **trust issues** persist. Some worry AI could devalue developer roles, comparing it to "fast food" work, while others see it as a tool to augment productivity.  
   - Security risks (e.g., exposing API keys via AI) are flagged as a critical barrier to full automation.

5. **Industry Critiques**:  
   - Google’s APIs are singled out as historically cumbersome, contrasting with smaller providers’ simplicity.  
   - **Cultural inertia** in tech (e.g., ITIL, overplanning) is blamed for stifling agility, with calls to prioritize speed and iteration over bureaucracy.

**Takeaway**: The consensus is that AI transforms coding speed but faces limits in replacing human judgment and navigating institutional inefficiencies. The future hinges on balancing AI’s technical potential with streamlined processes, emphasizing collaboration rather than replacement.

### Builder.ai did not "fake AI with 700 engineers"

#### [Submission URL](https://newsletter.pragmaticengineer.com/p/the-pulse-137) | 74 points | by [tanelpoder](https://news.ycombinator.com/user?id=tanelpoder) | [76 comments](https://news.ycombinator.com/item?id=44260556)

In the latest edition of "The Pragmatic Engineer," Gergely Orosz addresses and corrects a sensational claim that had made waves last week: that Builder.ai, a now-defunct AI startup, was faking its AI functionalities with 700 engineers working behind the scenes as a human facade. This story, which quickly caught the attention of media outlets worldwide, has proven to be unfounded upon closer inspection and conversations with former employees of the company.

The reality is less outlandish than creating a "Mechanical Turk" scenario a la the 18th-century chess automaton—a clever ruse hiding a human inside the machine. Builder.ai, it turns out, was developing a code generator utilizing large language models like Claude, not employing hordes of engineers in disguise.

The editorial takes an entertaining detour into an imaginative exercise: how one might theoretically construct such a deceptive system, highlighting the impracticalities and ethical pitfalls of such an endeavor. It explores questions of methodology, latency, and incentives that would be needed to maintain the pretense, concluding that functional AI cannot be faked in such a manner for long, especially not efficiently or ethically in today’s tech environment.

Beyond this correction, Orosz touches on other industry developments. He notes NVIDIA and Anthropic's changes in stock vesting processes, a potential repeal of Section 174 affecting tech taxes, Meta's financial struggle with solving AI problems, and Google possibly preparing for staffing adjustments amidst ChatGPT's growing threat to its Search dominance.

Readers are also cautioned against the risks of "vibe-coded" apps—applications with informal or quirky design sensibilities—that can often become security liabilities. This piece serves as both a correction to misinformation and a broader reflection on the industry's fast-evolving landscape.

Overall, The Pulse provides a comprehensive and insightful look into technology's current events, while offering clarification on previous reporting missteps, reaffirming The Pragmatic Engineer's commitment to accuracy and deeper understanding of tech narratives.

The discussion surrounding the corrected claim about Builder.ai faking AI with human engineers reveals several key themes and reactions:

1. **Skepticism Towards Sensational Claims**: Many users dismissed the original story as unfounded, pointing out logical flaws. For example, they argued that the sheer impracticality of hiding 700 engineers or generating real-time responses through humans made the claim implausible. Comparisons to Mechanical Turk-style fraud were deemed sensationalistic and inconsistent with modern AI tooling (e.g., tools like Claude or ChatGPT can generate code efficiently).

2. **Insider Perspectives**: Commenters shared firsthand experiences, such as a negative interview process with Builder.ai, criticizing its product quality and management. This added credibility to critiques of the company’s operations but did not validate the fraud allegations.

3. **Technical Debates**: Users dissected technical details, like typography nuances (curved vs. straight apostrophes) in comments, to argue whether text was AI-generated or human-written. Others discussed the feasibility of AI-generated code vs. human labor, noting that while contractor code quality can be poor, it doesn’t imply a systemic fraud.

4. **Scaling and Resource Allocation**: Some defended Builder.ai’s focus on internal tools, arguing that building custom systems (e.g., Jira workflows) is a legitimate part of scaling. Critics countered that overcomplicating internal tools can signal disorganization, referencing Uber’s past struggles with fragmented environments.

5. **Broader Industry Critique**: The conversation expanded to critique media sensationalism, with users blaming social platforms for amplifying unverified stories. Others highlighted the risks of “vibe-coded” apps and the disconnect between marketing (“AI-assisted”) and technical reality.

6. **Ethical and Practical AI Development**: Many emphasized that while AI tools still require human oversight, this isn’t fraudulent—it’s a pragmatic approach. The discussion underscored the challenges of balancing automation with transparency, especially as startups navigate investor expectations.

Overall, the thread reflects a mix of technical scrutiny, skepticism toward viral narratives, and broader reflections on tech industry practices, emphasizing the need for evidence-based discourse over sensationalism.

### Show HN: ChatToSTL – AI text-to-CAD for 3D printing

#### [Submission URL](https://huggingface.co/spaces/flowfulai/ChatToSTL) | 50 points | by [flowful](https://news.ycombinator.com/user?id=flowful) | [6 comments](https://news.ycombinator.com/item?id=44260649)

It seems that you're trying to fetch metadata from the Hugging Face (HF) Docker repository and encountered a refresh action. While the details are sparse, this might indicate an update or retrieval operation concerning Docker images hosted by Hugging Face. Docker repositories like this typically host pre-configured images for machine learning models, tools, or applications, making it easier for developers to deploy and manage their projects. If you're refreshing the metadata, it might be to ensure you have the latest information on available images or to update local references with the newest versions. If you encounter any issues during this process, ensure your network settings are correct and the repository access permissions, if required, are set up properly. Keep an eye on Hacker News for any updates or community discussions regarding Docker and Hugging Face developments!

Here’s a concise summary of the Hacker News discussion:

1. **Build123d and OpenSCAD Integration**:  
   A user highlights the utility of `build123d` (a Python library) combined with OpenSCAD and VSCode plugins for generating 3D models. They note its potential for creating larger, more complex designs compared to basic OpenSCAD examples. Another user praises the integration with Python for visualization and mentions using tools like Plotly to display STL data.

2. **OpenAI API Key Debate**:  
   A suggestion to "Try OpenAI-Key" sparks discussion about cost and practicality. Some argue that requiring users to "Bring Your Own Key" (BYOK) is reasonable for hobby projects, as free-tier API calls are not sustainable for large-scale use. Others humorously criticize the idea (e.g., "Lol try jrk"), reflecting mixed feelings about relying on paid APIs for open-source or personal projects.

**Key Themes**:  
- Interest in Python-based 3D modeling tools and workflows.  
- Tension between accessibility (free APIs) and cost realities for AI/ML projects.  
- Community humor and skepticism toward monetized services in hobbyist contexts.

### 2025 State of AI Code Quality

#### [Submission URL](https://www.qodo.ai/reports/state-of-ai-code-quality/) | 42 points | by [cliffly](https://news.ycombinator.com/user?id=cliffly) | [50 comments](https://news.ycombinator.com/item?id=44257283)

In the evolving landscape of software development, trust in AI is emerging as a crucial factor in the success of AI-generated code. According to Itamar Friedman, Co-founder & CEO of Qodo, AI coding is now measured not just by the volume of code it can create but by the confidence it instills in developers. This transition means that AI tools must evolve beyond being simple autocompletion engines to become context-aware reviewers that enhance code quality and consistency.

A recent survey from 2025 comprising 609 developers highlights key insights into AI's role in coding. Confidence and contextual understanding are foundational, with 65% of developers pointing out that AI frequently misses relevant context, which is critical for refactoring and code reviews. Developers wish for AI that deeply understands team standards and project contexts to improve trust in its outputs.

There’s a clear link between AI’s accuracy and its adoption: developers encountering fewer errors are more willing to trust AI-generated code without manual review. Furthermore, when AI is implemented with a focus on context and continuous review, significant productivity gains are reported—teams see up to 81% improvements in code quality compared to those who speed through volumes without such checks.

Adoption rates reflect AI's growing importance in coding workflows. A striking 82% of developers use AI tools daily or weekly, often deploying multiple tools in tandem. Smaller teams, in particular, are agile in adopting these innovations, although larger organizations are catching up as they develop governance patterns.

AI-generated code is increasingly entering production, with 65% of developers recognizing that at least a quarter of their code is influenced by AI—a number set to grow. While productivity and quality improvements are evident, challenges remain as developers continue to seek ways to increase AI's contextual understanding and reduce the need for oversight.

For AI to fulfill its transformative potential in software development, the industry must focus on embedding robust AI systems that prioritize trust and accuracy, thereby integrating the benefits seamlessly into the entire software development lifecycle.

**Summary of Discussion:**

The Hacker News discussion highlights mixed sentiments about AI-generated code, focusing on its impact on code quality, developer workflows, and the role of junior developers. Key themes include:

1. **Code Quality & Technical Debt**:  
   - Critics argue AI tools often produce verbose, low-quality code ("vb-coding") that introduces technical debt, especially when juniors accept flawed suggestions without scrutiny. Examples include AI-generated code with unnecessary complexity (e.g., "200-line service classes") or deviations from project standards.  
   - Some predict a future wave of maintenance issues as AI-generated code enters production, though optimists hope for simpler, more maintainable software to emerge.

2. **Junior Developers & Critical Thinking**:  
   - Concerns arise that juniors over-rely on AI, skipping critical problem-solving steps. Senior developers emphasize the irreplaceable value of foundational understanding and judgment.  
   - One analogy compares AI-assisted coding to pharmacists using AI for prescriptions: while helpful for routine cases, complex scenarios still require human expertise honed through experience.

3. **LLMs’ Limitations**:  
   - LLMs (like GPT) are seen as prone to "hallucinating" solutions, picking buzzwords over context, and degrading in quality if prompts are poorly structured. Users note that refining prompts and adding context can mitigate these issues.  
   - A recurring point: AI cannot replace human judgment in understanding project foundations or navigating edge cases.

4. **Adoption & Workflow Shifts**:  
   - Startups and smaller teams adopt AI tools faster, while larger organizations lag due to governance challenges.  
   - Proponents highlight productivity gains (e.g., reducing boilerplate), but critics argue time saved on typing is offset by debugging and re-prompting efforts.

5. **Language & Tool Debates**:  
   - Functional programming and strongly typed languages are suggested as safeguards against bad code, though dynamic languages (Python/JS) remain popular.  
   - Some advocate for stricter coding standards and AI tools trained on project-specific guidelines to improve output relevance.

6. **Error Rates & Trust**:  
   - Reports that 25% of AI suggestions contain factual errors fuel skepticism. A divide exists between "Pro-AI" developers (who trust tools with proper guardrails) and "Anti-AI" skeptics (who fear overconfidence and hidden flaws).  

7. **Future Outlook**:  
   - While some predict rapid AI improvement through feedback loops, others warn of short-term "disasters" from rushed adoption. The need for context-aware AI and better developer training is emphasized.  

**Conclusion**: The discussion reflects cautious optimism tempered by skepticism. While AI tools offer productivity benefits, their success hinges on addressing context gaps, fostering developer oversight, and balancing automation with foundational coding discipline.

