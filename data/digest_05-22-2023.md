## AI Submissions for Mon May 22 2023 {{ 'date': '2023-05-22T17:10:45.112Z' }}

### Re-Evaluating GPT-4's Bar Exam Performance

#### [Submission URL](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4441311) | 40 points | by [homarp](https://news.ycombinator.com/user?id=homarp) | [6 comments](https://news.ycombinator.com/item?id=36036343)

A paper by Eric Martinez of MIT has questioned the performance claims made by OpenAI for its GPT-4 model's application to the Uniform Bar Exam (UBE). Martinez finds that the touted 90th percentile proficiency of the model is based on flawed data analysis and that the percentile estimate for individuals who passed the UBE examination - that is, those who are or will be licensed attorneys - is estimated to be as low as the 48th percentile. The researcher's findings raise questions about the real-world application of GPT-4 and the need for transparent and rigorous evaluations of AI capability.

The discussion on Hacker News revolves around the recently published research paper by Eric Martinez of MIT, which questions OpenAI's claims about GPT-4's performance on the Uniform Bar Exam (UBE). Some users note that the paper highlights the need for transparent and rigorous evaluations of AI capabilities. However, others argue that the paper's findings are not entirely conclusive, as they rely on flawed data analysis and conservative statistical assumptions. Some commenters suggest that OpenAI should be more honest and transparent in its marketing and not make exaggerated claims about the performance of its models. Overall, the discussion suggests that while GPT-4's performance on the UBE may be impressive, it may not be as reliable or accurate as OpenAI has claimed.

### Meta AI announces Massive Multilingual Speech code,  models for 1000+ languages

#### [Submission URL](https://github.com/facebookresearch/fairseq/tree/main/examples/mms) | 657 points | by [crakenzak](https://news.ycombinator.com/user?id=crakenzak) | [216 comments](https://news.ycombinator.com/item?id=36034211)

Facebook AI Research has released the Massively Multilingual Speech (MMS) project, which aims to expand speech technology from around 100 languages to over 1,000 languages. MMS built a single multilingual speech recognition model, which supports over 1,100 languages, language identification models that can identify over 4,000 languages, pretrained models supporting over 1,400 languages, and text-to-speech models for over 1,100 languages. The goal of MMS is to make it easier for people to access information and use devices in their preferred language. You can find details in their paper and their blog post.

Facebook AI Research has released the Massively Multilingual Speech (MMS) project, which aims to expand speech technology from around 100 languages to over 1,000 languages. The project comprises of a single multilingual speech recognition model that supports over 1,100 languages, language identification models that can identify over 4,000 languages, pretrained models for over 1,400 languages, and text-to-speech models for over 1,100 languages. People on the forum discussed the accuracy of speech to text models, generalizations, the availability of STT and TTS translation models on GitHub, and renting GPUs to run AI models. They also spoke about the challenges in developing speech recognition models, the use of docker containers, and how containers can help store data and avoid manual installation.

### Parallels in the ways that humans and ML models acquire language skills

#### [Submission URL](https://www.quantamagazine.org/some-neural-networks-learn-language-like-humans-20230522/) | 106 points | by [theafh](https://news.ycombinator.com/user?id=theafh) | [35 comments](https://news.ycombinator.com/item?id=36031446)

A recent study by Gašper Beguš and colleagues at the University of California, Berkeley, has suggested that natural and artificial neural networks learn language in very similar ways. The researchers compared the brain waves of humans listening to a simple sound to the signal produced by a neural network analyzing the same sound and found that they were remarkably alike. They also discovered that even very general purpose neural networks without specific speech or sound biases still showed a correspondence to human neural coding. The study's results may help demystify how ANNs learn and suggest that human brains may not be pre-equipped with language-specific hardware and software.

The recent study by Gašper Beguš and colleagues at UC Berkeley on how natural and artificial neural networks learn language sparked a discussion in the comments on Hacker News. Some commenters were skeptical of the study's conclusion that human brains may not be pre-equipped with language-specific hardware and software, while others found it fascinating and could see how it could apply to machine learning. The discussion also touched on Noam Chomsky's theory on the innate ability of humans to learn language, with some agreeing and others disagreeing. Some commenters also shared their own experiences with learning language and the importance of understanding language in the context of human communication.

### Go+ is a successor to Golang, optimised for data science

#### [Submission URL](https://goplus.org/) | 18 points | by [gus_leonel](https://news.ycombinator.com/user?id=gus_leonel) | [5 comments](https://news.ycombinator.com/item?id=36033889)

Have you heard of Go+? It's a static typed language that boasts performance as fast as Go, but with a script-like style that can be mastered by children. It's fully compatible with Go and supports Go code generation and bytecode backend. While it doesn't offer DSL support, it's Specific Domain Friendly and has powerful built-in data processing capabilities. Applications written in Go+ can range from 2D games to DevOps tools to data processing. Give it a try and see if it's the right fit for your engineering, STEM education, or data science needs!

The discussion around the Go+ submission on Hacker News revolves around various aspects. One comment points out that the website lacks advantages of the language and makes assumptions about visitors being familiar with Go. Another user shares a link to documentation and notes that Go+ is similar to other languages such as Odin and Vlang. One user mentions waiting for Go++ and another suggests that Go# is better. A final comment criticizes the approach taken in Go+ by not providing enough advanced features.

### India Declares CPU Independence with Aum HPC Processor

#### [Submission URL](https://www.nextplatform.com/2023/05/17/india-declares-cpu-independence-with-aum-hpc-processor/) | 31 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [6 comments](https://news.ycombinator.com/item?id=36036099)

India's Center for Development of Advanced Computing (C-DAC) has developed a custom processor, named Aum, under the National Supercomputing Mission of the Indian government. The processor is designed to give HPC independence to India, from the processor all the way up to complete systems and software. Aum CPU, based on Arm architecture, could outperform popular CPUs such as Fujitsu's A64FX and Nvidia's Grace and could also be used in the AI and generic cloud computing markets. The chip is expected to be available in 2024 and will initially deploy in a pilot HPC system with over 1 petaflops of performance.

The discussion on this submission covers a few topics. One commenter, programmer_dude, questions the independence promised by the custom processor developed by India's C-DAC since it uses ARM architecture. Another commenter, fncyfrdbt, argues that ARM doesn't actually prevent India from manufacturing their own CPU architecture and suggests that the lack of clarity from the Indian government may be the real issue. 

Another commenter, vllgx, makes a joke about using RISC-V instead and criticizes the Indian government's policies on language and culture. ngnsk responds to vllgx's comment and explains that the names used in the project are common and meaningful in Indian culture and that the government's naming policy is aimed at promoting Hindi and countering cultural imperialism. 

The discussion then moves on to a broader debate about the importance of community names in the context of infrastructure, products, and public projects. vllgx makes a case for taking into account the majority community's preferences, while also respecting the linguistic and cultural diversity of India. They argue that the current state policies favor certain religious and regional groups, which can lead to conflict and inefficiencies. The debate ends with a few examples of the controversies that arise when infrastructure projects clash with local customs and beliefs.

### UK’s GDPR replacement could wipe out oversight of live facial recognition

#### [Submission URL](https://www.theregister.com/2023/05/19/dpib_2_surveillance_oversight/) | 183 points | by [belter](https://news.ycombinator.com/user?id=belter) | [146 comments](https://news.ycombinator.com/item?id=36030337)

The UK's Biometrics and surveillance camera commissioner Professor Fraser Sampson has warned that proposed data protection measures, set to replace the country's implementation of GDPR, may undermine independent oversight of facial recognition technology. Sampson, whose responsibilities include encouraging "compliance with the Surveillance Camera Code of Practice", stated that the current drafts of clauses 104 and 105 meant that the legislation may abolish the regulatory office overseeing biometrics and surveillance and repeal the Surveillance Camera Code of Practice that governs public space surveillance. Critics of the DPDI bill have also raised concerns over how it defines 'personal data' and its potential impact on privacy.

The UK's Biometrics and surveillance camera commissioner, Professor Fraser Sampson, has warned that proposed data protection measures could undermine independent oversight of facial recognition technology. Critics of the DPDI bill have also raised concerns over how it defines 'personal data' and its potential impact on privacy. The discussion on this submission largely focused on Brexit and its impact on the UK's laws and regulations. Some users argued that Brexit presented an opportunity for the country to improve things, while others felt that it would benefit special interests or even fascists. There were also comments about surveillance and the trade-off between security and privacy. One user highlighted that people are not listening to the warnings of experts like Professor Sampson.

### Apple is rewriting Foundation in Swift

#### [Submission URL](https://github.com/apple/swift-foundation) | 255 points | by [hnand](https://news.ycombinator.com/user?id=hnand) | [242 comments](https://news.ycombinator.com/item?id=36026038)

Apple's Swift-Foundation project is a new and unified Swift implementation of Foundation for all platforms, aiming to provide a small set of basic utility types and support platform independence. The package aims to enhance portability and demonstrate conventions that can be widely adopted by the Swift ecosystem. The development focus for 2023 is on quality and performance, with plans to refine the core API, expand to other platforms, and bring high-quality Swift implementations of additional important Foundation API. The package is written in Swift, providing major benefits over previous versions, including better performance and faster common tasks.

Apple has officially announced plans to fully replace the implementation of Foundation with Swift-Corelibs-Foundation. The Swift Foundation project aims to provide a small set of basic utility types that support platform independence, enhance portability, and demonstrate conventions that can be widely adopted by the Swift ecosystem. The development focus for 2023 is on quality and performance, with plans to refine the core API, expand to other platforms, and bring high-quality Swift implementations of additional important Foundation API. The package is written in Swift, providing major benefits over previous versions, including better performance and faster common tasks.

Comments on the thread discuss the benefits of Swift over Objective-C and the potential impact of the move towards Swift on existing Apple platforms and their users. Some users express concerns about changes to the runtime requirements, while others highlight the benefits of Swift's static typing system and object-oriented programming principles. The use of protocols in Swift for object-oriented programming and the potential for Swift to replace Objective-C completely in the future is another topic of discussion. Overall, many users see the move towards Swift as a positive development for Apple and the Swift ecosystem.

### Malicious VSCode extensions with more than 45k installs

#### [Submission URL](https://blog.checkpoint.com/securing-the-cloud/malicious-vscode-extensions-with-more-than-45k-downloads-steal-pii-and-enable-backdoors/) | 312 points | by [chha](https://news.ycombinator.com/user?id=chha) | [180 comments](https://news.ycombinator.com/item?id=36029020)

edibly popular code editor, Visual Studio Code (VSCode), was found to have hosted malicious extensions on its marketplace, potentially allowing attackers to access personal information and remotely control infected machines. The extensions had over 45,000 downloads and were quickly removed by the VSCode marketplace team after being reported by Check Point Research's CloudGuard Spectral tool. VSCode has become a popular choice among developers due to its customization and extensibility. This discovery highlights the need for thorough and continual security checks on open-source components.

The popular code editor, Visual Studio Code, has hosted malicious extensions on its marketplace, according to Check Point Research's CloudGuard Spectral tool. The extensions had over 45,000 downloads and were quickly removed by the VSCode marketplace team. The discussion on the submission highlights the need for thorough and continual security checks on open-source components. Some commenters discussed the principle of privileges in Linux programs and how Linux distributions have different security approaches. SELinux and AppArmor were mentioned as complicated but effective security measures. Others suggested practical solutions like using Snap or Flatpak. There were also comments regarding the fundamental security problem in Linux systems and the importance of users for the security process.

### Compromising LLM-integrated applications with indirect prompt injection

#### [Submission URL](https://arxiv.org/abs/2302.12173) | 43 points | by [greshake](https://news.ycombinator.com/user?id=greshake) | [20 comments](https://news.ycombinator.com/item?id=36037308)

Researchers have identified new attack vectors, using Indirect Prompt Injection, that can compromise Large Language Model (LLM)-integrated applications. These attacks enable adversaries to remotely exploit LLM-integrated applications by strategically injecting prompts into data likely to be retrieved, even if not directly prompted by the user. The team derived a comprehensive taxonomy from a computer security perspective to systematically investigate the impacts and vulnerabilities of PI attacks on LLMs, including data theft, worming, information ecosystem contamination, and other novel security risks. They also demonstrated the practical viability of these attacks against real-world systems, such as Bing's GPT-4 powered Chat and code-completion engines, and synthetic applications built on GPT-4.

A recent submission on Hacker News warns that researchers have identified new attack vectors using Indirect Prompt Injection (PI) that can compromise Large Language Model (LLM)-integrated applications. This attack involves injecting prompts into data, likely to be retrieved, even if not prompted directly by the user, to remotely exploit LLM-integrated applications. The discussion in the comments section covers different aspects of the submission. One user discusses the BERT and DIET frameworks, which are highly customizable and handle complex messages and series. Another user questions if the suggested technique is similar to injecting malicious instructions or content in data stored or retrieved. A solution was posted for detecting prompt injection attacks, and many users discussed SQL injection and the importance of escaping user input when storing it in databases. The vulnerability of LLMs and applications using them was demonstrated against real-world applications such as Bing's Chat. Many users expressed concern about these attack vectors and the potential ways in which the vulnerabilities they create could be exploited.

### LIMA: Less Is More for Alignment

#### [Submission URL](https://arxiv.org/abs/2305.11206) | 23 points | by [lebek](https://news.ycombinator.com/user?id=lebek) | [8 comments](https://news.ycombinator.com/item?id=36027141)

A new paper titled "LIMA: Less Is More for Alignment" proposes that almost all knowledge in large language models is learned during pretraining, and only limited instruction tuning data is necessary to teach models to produce high-quality output. The paper presents LIMA, a 65B parameter LLaMa language model fine-tuned with only 1,000 carefully curated prompts and responses, without any reinforcement learning or human preference modeling. LIMA demonstrates remarkably strong performance, surpassing GPT-4 in 43% of cases in a controlled human study, suggesting that pretraining is the key to success for large language models.

The paper titled "LIMA: Less Is More for Alignment," which proposes that pretraining is the key to the success of large language models, is discussed on Hacker News. One user mentions that when they fine-tuned LIMA with only 1,000 prompts and responses, it surpassed GPT-4 in 43% of cases in a controlled human study. Others note that the direct application of the term "alignment" is somewhat misleading, and the training details in the paper are not clear. Some users express interest in the direction of research on large language models and their applicability in industry, while others point out that human learning depends on good teachers who provide consistent correction and guidance.

### AI-generated photo of fake Pentagon explosion sparks brief stock selloff

#### [Submission URL](https://nypost.com/2023/05/22/ai-generated-photo-of-fake-pentagon-explosion-sparks-brief-stock-selloff/) | 25 points | by [the-printer](https://news.ycombinator.com/user?id=the-printer) | [19 comments](https://news.ycombinator.com/item?id=36035981)

A fake AI-generated photo of an explosion at the US Pentagon spread rapidly on social media on Monday, causing mass confusion among users and a brief selloff in the US stock market. The fake photo, which showed smoke billowing outside the Pentagon, was shared by Russian state media outlet and other accounts alongside claims that an explosion had occurred at the complex. US stocks appeared to briefly dip as the photo circulated but quickly rebounded after the picture was exposed as a hoax. Critics fear advanced AI systems will allow bad actors around the world to spread misinformation and sow chaos online.

A fake, AI-generated photo of an explosion at the Pentagon circulated on social media on Monday, causing confusion and brief market fluctuations. Some users discuss the dangers of relying on social media and speculate about Wall Street's responsibility in reaction to fake news. Others note that the photo was likely a random creation and that the market quickly rebounded once the hoax was exposed. There is discussion about the reliability of news sources, with some emphasizing the importance of fact-checking and critical thinking. One user references the phrase "Moab," likely in reference to a large non-nuclear bomb used by the U.S. military.

