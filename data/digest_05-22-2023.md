## AI Submissions for Mon May 22 2023 {{ 'date': '2023-05-22T17:10:45.112Z' }}

### Re-Evaluating GPT-4's Bar Exam Performance

#### [Submission URL](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4441311) | 40 points | by [homarp](https://news.ycombinator.com/user?id=homarp) | [6 comments](https://news.ycombinator.com/item?id=36036343)

A paper by Eric Martinez of MIT has questioned the performance claims made by OpenAI for its GPT-4 model's application to the Uniform Bar Exam (UBE). Martinez finds that the touted 90th percentile proficiency of the model is based on flawed data analysis and that the percentile estimate for individuals who passed the UBE examination - that is, those who are or will be licensed attorneys - is estimated to be as low as the 48th percentile. The researcher's findings raise questions about the real-world application of GPT-4 and the need for transparent and rigorous evaluations of AI capability.

Some users note that the paper highlights the need for transparent and rigorous evaluations of AI capabilities. However, others argue that the paper's findings are not entirely conclusive, as they rely on flawed data analysis and conservative statistical assumptions. Some commenters suggest that OpenAI should be more honest and transparent in its marketing and not make exaggerated claims about the performance of its models. Overall, the discussion suggests that while GPT-4's performance on the UBE may be impressive, it may not be as reliable or accurate as OpenAI has claimed.

### Meta AI announces Massive Multilingual Speech code,  models for 1000+ languages

#### [Submission URL](https://github.com/facebookresearch/fairseq/tree/main/examples/mms) | 657 points | by [crakenzak](https://news.ycombinator.com/user?id=crakenzak) | [216 comments](https://news.ycombinator.com/item?id=36034211)

Facebook AI Research has released the Massively Multilingual Speech (MMS) project, which aims to expand speech technology from around 100 languages to over 1,000 languages. MMS built a single multilingual speech recognition model, which supports over 1,100 languages, language identification models that can identify over 4,000 languages, pretrained models supporting over 1,400 languages, and text-to-speech models for over 1,100 languages. The goal of MMS is to make it easier for people to access information and use devices in their preferred language. You can find details in their paper and their blog post.

People on the forum discussed the accuracy of speech to text models, generalizations, the availability of STT and TTS translation models on GitHub, and renting GPUs to run AI models. They also spoke about the challenges in developing speech recognition models, the use of docker containers, and how containers can help store data and avoid manual installation.

### Parallels in the ways that humans and ML models acquire language skills

#### [Submission URL](https://www.quantamagazine.org/some-neural-networks-learn-language-like-humans-20230522/) | 106 points | by [theafh](https://news.ycombinator.com/user?id=theafh) | [35 comments](https://news.ycombinator.com/item?id=36031446)

A recent study by Gašper Beguš and colleagues at the University of California, Berkeley, has suggested that natural and artificial neural networks learn language in very similar ways. The researchers compared the brain waves of humans listening to a simple sound to the signal produced by a neural network analyzing the same sound and found that they were remarkably alike. They also discovered that even very general purpose neural networks without specific speech or sound biases still showed a correspondence to human neural coding. The study's results may help demystify how ANNs learn and suggest that human brains may not be pre-equipped with language-specific hardware and software.

The paper sparked a discussion in the comments on Hacker News. Some commenters were skeptical of the study's conclusion that human brains may not be pre-equipped with language-specific hardware and software, while others found it fascinating and could see how it could apply to machine learning. The discussion also touched on Noam Chomsky's theory on the innate ability of humans to learn language, with some agreeing and others disagreeing. Some commenters also shared their own experiences with learning language and the importance of understanding language in the context of human communication.

### UK’s GDPR replacement could wipe out oversight of live facial recognition

#### [Submission URL](https://www.theregister.com/2023/05/19/dpib_2_surveillance_oversight/) | 183 points | by [belter](https://news.ycombinator.com/user?id=belter) | [146 comments](https://news.ycombinator.com/item?id=36030337)

The UK's Biometrics and surveillance camera commissioner Professor Fraser Sampson has warned that proposed data protection measures, set to replace the country's implementation of GDPR, may undermine independent oversight of facial recognition technology. Sampson, whose responsibilities include encouraging "compliance with the Surveillance Camera Code of Practice", stated that the current drafts of clauses 104 and 105 meant that the legislation may abolish the regulatory office overseeing biometrics and surveillance and repeal the Surveillance Camera Code of Practice that governs public space surveillance. Critics of the DPDI bill have also raised concerns over how it defines 'personal data' and its potential impact on privacy.

The discussion on this submission largely focused on Brexit and its impact on the UK's laws and regulations. Some users argued that Brexit presented an opportunity for the country to improve things, while others felt that it would benefit special interests or even fascists. There were also comments about surveillance and the trade-off between security and privacy. One user highlighted that people are not listening to the warnings of experts like Professor Sampson.

### Compromising LLM-integrated applications with indirect prompt injection

#### [Submission URL](https://arxiv.org/abs/2302.12173) | 43 points | by [greshake](https://news.ycombinator.com/user?id=greshake) | [20 comments](https://news.ycombinator.com/item?id=36037308)

Researchers have identified new attack vectors, using Indirect Prompt Injection, that can compromise Large Language Model (LLM)-integrated applications. These attacks enable adversaries to remotely exploit LLM-integrated applications by strategically injecting prompts into data likely to be retrieved, even if not directly prompted by the user. The team derived a comprehensive taxonomy from a computer security perspective to systematically investigate the impacts and vulnerabilities of PI attacks on LLMs, including data theft, worming, information ecosystem contamination, and other novel security risks. They also demonstrated the practical viability of these attacks against real-world systems, such as Bing's GPT-4 powered Chat and code-completion engines, and synthetic applications built on GPT-4.

The discussion in the comments section covers different aspects of the submission. One user discusses the BERT and DIET frameworks, which are highly customizable and handle complex messages and series. Another user questions if the suggested technique is similar to injecting malicious instructions or content in data stored or retrieved. A solution was posted for detecting prompt injection attacks, and many users discussed SQL injection and the importance of escaping user input when storing it in databases. The vulnerability of LLMs and applications using them was demonstrated against real-world applications such as Bing's Chat. Many users expressed concern about these attack vectors and the potential ways in which the vulnerabilities they create could be exploited.

### LIMA: Less Is More for Alignment

#### [Submission URL](https://arxiv.org/abs/2305.11206) | 23 points | by [lebek](https://news.ycombinator.com/user?id=lebek) | [8 comments](https://news.ycombinator.com/item?id=36027141)

A new paper titled "LIMA: Less Is More for Alignment" proposes that almost all knowledge in large language models is learned during pretraining, and only limited instruction tuning data is necessary to teach models to produce high-quality output. The paper presents LIMA, a 65B parameter LLaMa language model fine-tuned with only 1,000 carefully curated prompts and responses, without any reinforcement learning or human preference modeling. LIMA demonstrates remarkably strong performance, surpassing GPT-4 in 43% of cases in a controlled human study, suggesting that pretraining is the key to success for large language models. Some users express interest in the direction of research on large language models and their applicability in industry, while others point out that human learning depends on good teachers who provide consistent correction and guidance.

### AI-generated photo of fake Pentagon explosion sparks brief stock selloff

#### [Submission URL](https://nypost.com/2023/05/22/ai-generated-photo-of-fake-pentagon-explosion-sparks-brief-stock-selloff/) | 25 points | by [the-printer](https://news.ycombinator.com/user?id=the-printer) | [19 comments](https://news.ycombinator.com/item?id=36035981)

A fake AI-generated photo of an explosion at the US Pentagon spread rapidly on social media on Monday, causing mass confusion among users and a brief selloff in the US stock market. The fake photo, which showed smoke billowing outside the Pentagon, was shared by Russian state media outlet and other accounts alongside claims that an explosion had occurred at the complex. US stocks appeared to briefly dip as the photo circulated but quickly rebounded after the picture was exposed as a hoax. Critics fear advanced AI systems will allow bad actors around the world to spread misinformation and sow chaos online.

Some users discuss the dangers of relying on social media and speculate about Wall Street's responsibility in reaction to fake news. Others note that the photo was likely a random creation and that the market quickly rebounded once the hoax was exposed. There is discussion about the reliability of news sources, with some emphasizing the importance of fact-checking and critical thinking. One user references the phrase "Moab," likely in reference to a large non-nuclear bomb used by the U.S. military.

