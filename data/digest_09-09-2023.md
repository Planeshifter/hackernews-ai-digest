## AI Submissions for Sat Sep 09 2023 {{ 'date': '2023-09-09T17:09:45.510Z' }}

### SmartKnob – Haptic input knob with software-defined endstops and virtual detents

#### [Submission URL](https://github.com/scottbez1/smartknob) | 264 points | by [e3a8](https://news.ycombinator.com/user?id=e3a8) | [42 comments](https://news.ycombinator.com/item?id=37448659)

Introducing SmartKnob: an open-source input device with software-configurable endstops and virtual detents. This innovative gadget combines a brushless gimbal motor with a magnetic encoder to provide closed-loop torque feedback control, allowing users to dynamically create and adjust the feel of detents and endstops. The SmartKnob View, which includes an integrated display, is currently under active development. Motors are now available for purchase, thanks to the community's efforts in identifying the original manufacturer and collaborating with SparkFun Electronics. While SmartKnob is a DIY project, it requires advanced soldering skills and troubleshooting abilities due to its small-pitch surface-mount soldering and delicate assembly process.

The discussion on Hacker News about the submission "Introducing SmartKnob: an open-source input device with software-configurable endstops and virtual detents" covers various topics related to the project. Here are some highlights:

- Users express their admiration for the well-documented source hardware project and discuss the challenges of software projects, 3D design printing, hardware sourcing, component selection, and support from the community.
- There is a discussion about the feasibility of low-cost PCB manufacturing, availability of affordable tooling, such as CO2 laser cutters, and the increasing popularity of hobbyist hardware projects.
- One user asks a technical question about voltage protection for the motor and the TMC6300 IC schematic connection. Another user, who has electrical engineering knowledge, provides a response and mentions high resistance, low-kV motors, and the importance of handling high voltage correctly.
- The conversation also touches on the difficulties of handling high RPM motors and the potential issues with ESCs (Electronic Speed Controllers) and motor braking.
- Users express their appreciation for the UX (user experience) aspect of the project and discuss the detection of flexing in the PCB and the need for magic touch buttons.
- Several users share their interest in similar projects, such as building digital jukeboxes with physical controls and knob controls for shuffling tracks.
- There is a mention of a YouTube video demonstrating the behavior of a rotary encoder and the availability of software-based detents.
- One user compares the project with existing commercial products, such as the 3Dconnexion SpaceNavigator and SpaceMouse Pro, pointing out the similarities in behavior.
- The discussion veers into the field of music synthesis, with users highlighting the importance of control panels, hardware synthesizers, and the ability to quickly modify parameters for improved performance.
- The topic expands to include haptics and electronic instruments, with users mentioning specific devices and their design, such as the Roland/Boss GT-100 guitar processor and the TP-7 with haptic feedback.
- There are mentions of DIY smart thermostats, power button rotary knobs, flight simming, and even a humorous comment about Tesla's shifters.

Overall, the discussion shows a mix of technical questions, positive feedback about the project, and various related topics sparked by the submission.

### Advanced NLP with SpaCy

#### [Submission URL](https://course.spacy.io/en/) | 136 points | by [auraham](https://news.ycombinator.com/user?id=auraham) | [52 comments](https://news.ycombinator.com/item?id=37442574)

Chapter 1: Finding words, phrases, names, and concepts

In this chapter, you will be introduced to the fundamentals of text processing using spaCy. You will learn about the different data structures and how to leverage them to work with trained pipelines. By the end of this chapter, you will also be able to predict various linguistic features within your text.

Chapter 2: Large-scale data analysis with spaCy

Once you have grasped the basics, this chapter will dive into extracting specific information from massive amounts of text. You will discover techniques to efficiently utilize spaCy's data structures and effectively combine statistical and rule-based approaches for text analysis. With these skills, you'll be able to perform large-scale analysis on vast volumes of textual data.

Chapter 3: Processing Pipelines

If you want to explore the inner workings of spaCy's processing pipeline, this chapter is for you. You will gain an in-depth understanding of what happens behind the scenes when you process text. Additionally, you will learn how to create your own pipeline components and integrate them seamlessly into spaCy. The chapter also covers how to enhance documents, spans, and tokens with custom attributes to include your own metadata.

Chapter 4: Training a neural network model

In this chapter, you will learn how to fine-tune spaCy's statistical models to tailor them to your specific needs. You'll discover how to train your own model from scratch, allowing you to predict new entity types or conduct custom natural language processing (NLP) tasks. By understanding the fundamentals of training and leveraging useful tips and tricks, you'll be well-equipped to create successful custom NLP projects.

The discussion on this submission covers various topics related to natural language processing (NLP) and the use of large language models (LLMs), specifically focusing on spaCy. Here are the key points discussed:

- Some users argue that traditional NLP approaches can effectively solve many NLP tasks, while LLMs are often considered black boxes. However, others claim that LLMs can achieve good results, especially in tasks like named entity recognition (NER) and text classification.
- There is a debate about the accuracy and efficiency of LLMs compared to traditional methods. Some users express skepticism about replacing traditional methods entirely, while others believe that LLMs can outperform them.
- The need for manually correcting the output of LLMs is discussed, with some users pointing out that manually correcting the errors produced by LLMs might not be a feasible solution for larger datasets.
- The use of LLMs in text summarization, information extraction, and search tasks is mentioned. LLMs are noted for their ability to understand context, handle tokenization, and improve search performance.
- The deterministic nature of LLMs is questioned, and it is highlighted that using an API to control LLMs can lead to non-deterministic behavior. Some users suggest using specific versions of LLMs or training them deterministically.
- The advantages and disadvantages of LLMs compared to traditional methods, such as higher costs and lack of interpretability, are discussed.
- The importance of transparency, traceability, and explainability in NLP applications is emphasized, especially in business domains.
- The limitations and trade-offs of LLMs are acknowledged, and it is mentioned that LLMs might not be a complete solution for all tasks in the NLP field.
- The CTO of spaCy, mentioned as the "Original thr spaCy Explosion CTO," provides clarification on the terminology related to LLMs and contrasts them with task-specific classification models.

Overall, the discussion covers the capabilities, limitations, and potential use cases of LLMs in NLP, with differing opinions on their effectiveness compared to traditional methods.

### Show HN: WhatsApp-Llama: A clone of yourself from your WhatsApp conversations

#### [Submission URL](https://github.com/Ads-cmu/WhatsApp-Llama) | 115 points | by [advaith08](https://news.ycombinator.com/user?id=advaith08) | [49 comments](https://news.ycombinator.com/item?id=37448005)

Introducing WhatsApp-Llama: Fine-tune Llama 7b to Mimic Your WhatsApp Style

Have you ever wanted an AI that speaks just like you? Well, now you can! A team from Carnegie Mellon University has forked the popular Llama-recipes repository and created WhatsApp-Llama, a tool that allows you to train a language model to replicate your personal texting style on WhatsApp.

By inputting your WhatsApp conversations, you can fine-tune the Llama-2 7b chat model to respond just like you do. The team used parameter efficient finetuning (QLoRA) and int4 quantization on a single GPU to achieve impressive results.

In their experiments, the fine-tuned Llama-2 model quickly picked up on the nuances of the user's texting style. The average number of words generated by the finetuned Llama-2 was 300% more than the vanilla Llama-2 model. The model accurately replicated common phrases and emoji usage.

To test the model's performance, the team conducted a Turing Test with friends. They asked their friends to ask three questions on WhatsApp and then responded with two candidate responses, one from themselves and one from the Llama-2 model. The friends had to guess which response was from the user and which one was from the AI. The model fooled 10% of the friends, with some of its responses being eerily similar to the user's own.

To get started with WhatsApp-Llama, you need to export your WhatsApp chats and preprocess the dataset. The detailed steps can be found in the README file of the repository. The team recommends exporting 10 WhatsApp chats from friends you frequently speak to, excluding media.

With WhatsApp-Llama, you can have an AI that speaks just like you on WhatsApp. This opens up possibilities for personalization and automation in text-based communication. So go ahead, unleash your AI clone and start chatting!

The discussion around the submission "Introducing WhatsApp-Llama: Fine-tune Llama 7b to Mimic Your WhatsApp Style" on Hacker News covered various topics. Here is a summary of the key points:

- One user mentioned that they haven't watched Silicon Valley, prompting another user to share a link to a funny clip from the show.
- There was a reference to the Black Mirror episode "Be Right Back," which reminded another user of the episode.
- Discussions shifted to the technical aspects of using Llama models. One user mentioned that using a 13B model instead of a 7B model significantly improved results. However, others pointed out that the cost of using larger models, such as the 3090 GPU, could be high.
- Users expressed their experiences with the Llama models and the level of accuracy in mimicking their texting style.
- Some users shared their interest in replicating other famous fictional characters, such as Harry Potter portraits.
- The conversation then moved to discussions about other topics, including the Black Mirror series, text messaging durations, and the potential of personalizing AI dialogue systems.
- Users expressed interest in the development of grief counseling AI systems and techniques for healthier AI-human interactions.
- There were discussions regarding the potential profitable business opportunities based on training Llama models and charging for access to personalized AI models.
- Users shared their experiences and plans for exporting chat histories from WhatsApp or other platforms and the necessary pre-processing steps.
- Some users discussed the potential privacy implications of training AI models on personal chat histories.
- There were inquiries about the hardware requirements for running Llama models, and users shared their experiences with different GPUs and services like Google Colab.
- Users mentioned different versions of Llama models, such as Llama 2, and asked about the differences between them.
- The conversation concluded with users discussing other messaging platforms like Telegram and Discord.

Overall, the discussion covered a range of topics, from technical details and experience with Llama models to potential privacy concerns and broader implications of AI conversation systems.

### Show HN: TaleBot – AI-Generated Personalized Bedtime Stories for Kids

#### [Submission URL](https://talebotai.com/) | 16 points | by [cagrisarigoz](https://news.ycombinator.com/user?id=cagrisarigoz) | [16 comments](https://news.ycombinator.com/item?id=37443790)

Introducing TaleBot, the ultimate companion AI storyteller for your children! Tired of telling the same old fairytales? With TaleBot, you can customize characters, develop new storylines, and create personalized bedtime stories in minutes. Say goodbye to monotony and hello to endless giggles and unforgettable memories.

Parenting is a tough job, especially at the end of a long day. Just when you think you can finally relax, your child asks for a story. Instead of resorting to tired old tales, why not let their imagination soar? With TaleBot, they'll become the heroes of their dreams, embark on wild adventures, and bring along their favorite friends, real or imaginary. It's the perfect way to teach them values, nurture curiosity, and ignite their creativity.

Using TaleBot is a breeze. Simply name your main character, choose an adventure, add a moral, and let our AI bot work its magic. Don't worry, we respect your privacy and only ask for non-identifiable information to personalize the story. In just a few minutes, you'll have a unique and engaging story ready to be enjoyed.

But don't just take our word for it. Here's what some of our happy parents have to say: "My 4-year-old loved the story we created together!" Praises like these make us smile and motivate us to provide the best possible experience.

When you create a story with TaleBot, you'll receive a PDF copy as well as an AI-narrated audio recording right in your inbox. The story is yours to keep, share, and cherish as a precious memory. And with your permission, we can even publish your story on our website or podcast, spreading the joy to others.

But that's not all! We're constantly working on new features to enhance your storytelling experience. Keep an eye out for upcoming updates like AI voice selection and video storytelling. We want to make personalized storytelling even more magical and immersive for you and your children.

So, why wait? Start your storytelling journey with TaleBot today and experience the wonder of creating unique and captivating stories. Let your child's imagination flourish, one story at a time.

The discussion on Hacker News regarding the submission about TaleBot, an AI storyteller for children, touched on several points:

1. User "brknbyclds" shared a link to Shutterstock's announcement about launching a new content moderation feature for YouTube Kids. User "rchbll" commented that it's an endless void of content and suggested that a great alternative to YouTube Kids could be personalized storytelling with services like TaleBot.

2. User "strtsgr" pointed out that many people try to get their lost time back by falling for scams like credit card payment screens. User "cgrsrgz" apologized for not including a coupon code in the post and assured that they would promptly refund anyone who made a mistake in their payment. Another user, "nssts," expressed skepticism about the service, feeling that it may be misleading.

3. User "the_biot" commented that they find TaleBot horrifying, without providing further explanation.

4. User "pbrnz" had a positive experience using a similar AI storytelling service called ChatGPT Midjourney and mentioned their comfort in facilitating the creation of clothed content for children to enjoy.

5. User "jbtz" raised a possible concern, but didn't elaborate. Subsequent comments from "wndrngmnd" and "jgalt212" criticized the quality of AI-generated children's books, with "wndrngmnd" suggesting that they were absolute nonsense and "jgalt212" drawing a parallel to a children's version of Romeo and Juliet that they found forgettable.

6. User "dgtctphd" noted that the market for physical children's books is different from the market for digital products that don't require printing or shipping costs. They also mentioned considering a more affordable subscription model to generate consistent revenue.

7. Lastly, user "btwz" mentioned "The Young Lady's Illustrated Primer," a book referenced in Neal Stephenson's novel "The Diamond Age" that shares a concept similar to TaleBot.

Overall, the discussion covered concerns about content moderation on platforms like YouTube Kids, potential scam risks, the quality of AI-generated children's stories, and the business model of TaleBot. There were also positive experiences shared by users who enjoyed AI storytelling services.

