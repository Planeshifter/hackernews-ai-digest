## AI Submissions for Sun Mar 17 2024 {{ 'date': '2024-03-17T17:10:48.909Z' }}

### LLM4Decompile: Decompiling Binary Code with LLM

#### [Submission URL](https://github.com/albertan017/LLM4Decompile) | 374 points | by [Davidbrcz](https://news.ycombinator.com/user?id=Davidbrcz) | [120 comments](https://news.ycombinator.com/item?id=39733275)

The top story on Hacker News today is about a project called LLM4Decompile, which focuses on decompiling binary code with Large Language Models. The creators aim to release the first open-source Large Language Model dedicated to decompilation and have constructed a decompilation benchmark focused on re-compilability and re-executability. By compiling a million C code samples into assembly code and fine-tuning the DeepSeek-Coder model, they have achieved significant results in assessing the quality of decompiled code based on re-compilability and passing test cases. The project offers various models with different parameters sizes and provides instructions on how to use them effectively. It's a fascinating dive into the world of reverse engineering and code decompilation using cutting-edge technology.

The discussion on the Hacker News submission revolves around the project LLM4Decompile and the challenges and intricacies of decompiling binary code using Large Language Models (LLMs). Some users emphasize the importance of reproducibility in decompiled code and the limitations of current methodologies in ensuring the accuracy of the decompilation process. Others delve into topics such as the reproducibility of source code from binaries, the role of LLMs in reverse engineering, and the prospects of LLMs in generating functional equivalents of binary code. The conversation also touches on issues related to formal verification, the generalization capabilities of LLMs, and the potential advancements in AI-generated code. The exchange showcases a deep exploration of the complexities and possibilities surrounding code decompilation and the utilization of cutting-edge technology in the field.

### Show HN: 3DGS.cpp â€“ performant, cross platform Gaussian Splatting with Vulkan

#### [Submission URL](https://github.com/shg8/3DGS.cpp) | 43 points | by [0x02A](https://news.ycombinator.com/user?id=0x02A) | [17 comments](https://news.ycombinator.com/item?id=39738561)

3DGS.cpp is an ambitious cross-platform implementation of Gaussian Splatting, designed to bring high-performance point-based radiance fields to a wider audience. Unlike many other implementations that rely on CUDA or OpenGL, 3DGS.cpp leverages the Vulkan API and compute pipelines for its rendering prowess. With support for platforms like Windows, Linux, macOS, iOS, and visionOS, it aims to democratize access to advanced rendering techniques. The project offers a range of features and options, including Vulkan validation layers, GPU selection, different window modes, GUI controls, and more. Building the project on different operating systems comes with its set of dependencies and configurations, such as Vulkan headers, validation layers, glslangValidator, glfw, and glm. Furthermore, the project roadmap includes plans for better controls and GUI on GLFW apps for iOS and visionOS, an immersive app using the Compositor Service framework, OpenXR support, and the integration of advanced algorithms like parallel radix sort. The project welcomes contributions and suggestions for feature enhancements. With a focus on cross-platform support and a commitment to expand the adoption of research in the field, 3DGS.cpp offers a compelling opportunity for researchers and developers interested in Gaussian Splatting and related rendering techniques.

The discussion on Hacker News about the submission "3DGS.cpp: High-Performance Renderer for Gaussian Splatting Using Vulkan Compute" covers various aspects of the project and related topics such as Gaussian Splatting, cross-platform support, and performance optimizations. Here are the key points:

1. **0x02A** highlighted the project's exploration of rendering radiance fields in real-time on standalone VR and AR headsets, leveraging Vulkan compute pipelines for better performance compared to CUDA implementations. The project aims to make Gaussian Splatting more accessible to a wider audience and welcomes feedback and contributions. The user also shared previous discussions on Gaussian Splatting for context.
2. **hlphbcdd** expressed interest in the project and mentioned starting a project that utilizes pixel merging mesh for Gaussian Splatting, aiming to optimize scenes and explore different implementations.
3. **pz** found the project interesting but noted a potential issue with supporting iOS due to licensing LGPL 2.1 and restrictions from the App Store, suggesting alternatives for LGPL software on iOS.
4. **w-m** praised the project for its work on Gaussian Splatting, shared their experience working with similar techniques like compressing 3D scenes, and provided links to relevant resources. They also discussed performance bottlenecks and potential improvements for Intel Macbook GPUs.
5. **Cloudef** wondered if the technique could bring back the PS1-style pre-rendered background aesthetic to games, leading to a discussion on pre-rendered contexts and scene recrafting in 3D.
6. **pntlmn** expressed interest in trying the scene files related to the Gaussian Splatting project, and **w-m** shared the link to download the scenes from the original 3DGS paper on GitHub.

Overall, the discussion revolved around the project's technical aspects, potential applications, platform support, licensing concerns, and performance considerations related to Gaussian Splatting and Vulkan compute pipelines. Users engaged in sharing insights, asking questions, and providing feedback on various aspects of the project.

### Microsoft is giving Copilot users access to GPT-4-Turbo for free

#### [Submission URL](https://www.tomsguide.com/ai/copilot/microsoft-is-giving-copilot-users-access-to-gpt-4-turbo-for-free) | 60 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [27 comments](https://news.ycombinator.com/item?id=39735864)

Microsoft is shaking things up by making the powerful GPT-4-Turbo, the latest and greatest large language model from OpenAI, free for all users on its Copilot platform. This move gives everyone access to cutting-edge AI technology that was previously only available to paid subscribers. GPT-4-Turbo boasts significant improvements, such as a larger context window and the ability to handle tens of thousands of words in a single chat. Microsoft's decision to offer this enhanced version for free aligns with its strategy to integrate AI into its products and services seamlessly. With the competition heating up in the AI space, especially with potential leaks hinting at OpenAI's next big model, Microsoft's move to provide access to GPT-4-Turbo to all Copilot users is a significant development.

1. User "nxtwrddv" expressed a desire for a better completion system prompt in ChatGPT Copilot, which received responses about the power and nuances of the system.
2. User "frcll" started a discussion comparing Copilot with VSCode and extensions, prompting comments on Microsoft's rebranding strategies and product positioning against competitors like OpenAI.
3. User "xyst" critiqued Microsoft's approach to the terms of service for Copilot, leading to comments regarding the accessibility and business tactics of AI tools.
4. User "jzzyjcksn" shared thoughts on using Copilot after reading an article, sparking conversations about its integration with Windows features and potential applications on different platforms.
5. User "rcnmchnr" highlighted a news article about Bing Chat in Sydney and its connection to Copilot, drawing attention to Microsoft's engagement in AI technologies.
6. User "mdkkrs" criticized ChatGPT's sluggish performance and suggested exploring other AI development resources like Anthropic, with a side discussion on the features and subscription aspects of ChatGPT-4-Turbo.
7. User "hckrlght" mentioned concerns about the release of GPT-45, leading to discussions on the saturation of large language models in the market and the competitive landscape with companies like Google, Apple, and Microsoft.

### Imitation Learning (2023)

#### [Submission URL](https://geohot.github.io//blog/jekyll/update/2023/11/18/imitation-learning.html) | 84 points | by [surprisetalk](https://news.ycombinator.com/user?id=surprisetalk) | [37 comments](https://news.ycombinator.com/item?id=39733746)

After seven years of innovation and evolution, comma.ai's journey in developing self-driving technology has been a rollercoaster of ideas and solutions. The initial concept involved training a model to predict steering angles from images, but this approach failed to keep the car driving straight on highways due to accumulated errors. The team then introduced a model to predict lane positions, which served as a corrective measure for the steering angle model. However, the challenge of defining ground truth for lane lines led to further refinements in their system. Despite striving to eliminate reliance on lanes in their technology stack, the team found that some hand-coded assumptions were still necessary. They have since made significant progress in reducing this dependency, with openpilot being able to navigate dirt roads without lane lines by 2020. As they continue to evolve, comma.ai is revisiting behavioral cloning as a potential solution. The key lies in addressing the cumulative errors that affect the model's predictions over time, requiring an accurate estimator of accumulated errors to ensure effective driving behavior. By introducing a correction function that accounts for accumulated errors, comma.ai aims to achieve a more robust and reliable self-driving system. As they grapple with the challenge of establishing ground truth for this correction function within an end-to-end framework, the team's dedication to pushing the boundaries of autonomous driving technology remains unwavering.

The discussion on Hacker News around the comma.ai's journey in developing self-driving technology covers a wide range of topics.
- Some users emphasize the importance of continuous learning and adaptation in machine learning, particularly in the field of behavioral cloning. They discuss the challenges of accumulating errors in predictive models and the necessity of refining methods to address these issues.
- Others delve into the educational aspects of learning methodologies, suggesting that traditional approaches may need to evolve to keep pace with technological advancements. There is a debate on the value of formal education versus hands-on experience in fields like machine learning and robotics.
- The conversation also extends to practical applications and real-world implications of self-driving technology. Users discuss the scalability of models, the challenges of translating research findings into large-scale deployment, and the limitations of current methods in addressing complex, real-world scenarios.
- Additionally, there are discussions on reinforcement learning, model training, and the interplay between different algorithms in optimizing self-driving systems. Some users highlight the need for robust methodologies that can generalize effectively across diverse driving environments.

Overall, the discussion showcases a diverse range of perspectives on the challenges and opportunities in developing self-driving technology, highlighting the complexities involved in creating autonomous systems that can navigate real-world scenarios accurately and reliably.

