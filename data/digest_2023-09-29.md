## AI Submissions for Fri Sep 29 2023 {{ 'date': '2023-09-29T17:09:13.891Z' }}

### RealFill: Image completion using diffusion models

#### [Submission URL](https://realfill.github.io/) | 549 points | by [flavoredquark](https://news.ycombinator.com/user?id=flavoredquark) | [178 comments](https://news.ycombinator.com/item?id=37708292)

RealFill is a new approach for image completion that fills in missing regions with content that should have been there, based on a few reference images of the same scene. Unlike previous models that generate inauthentic content, RealFill uses personalized generative inpainting to create visually compelling and faithful completions. It can handle scenarios with different viewpoints, lighting conditions, camera settings, and image styles. RealFill outperforms existing approaches in a diverse and challenging image completion benchmark. The method involves fine-tuning a pre-trained model on reference and target images, learning the scene's contents, lighting, and style, and using the model for diffusion sampling to complete the target image. However, RealFill is slower due to the fine-tuning process and struggles with extreme viewpoint changes and challenging cases for the base model. Nonetheless, it achieves high scene fidelity compared to baseline methods. The study authors express gratitude for the valuable discussions and feedback received from various individuals and acknowledge others' contributions to the evaluation dataset.

The discussion around the RealFill image completion model on Hacker News covers a variety of topics. One user discusses the functionality of Google Photos, mentioning that while it can provide functional photos, it may struggle with historical photos. Another user suggests using compression techniques to mitigate space constraints for photo collections. Other comments touch on the manipulation and trustworthiness of photographs. Some argue that photographs have always been manipulated to some extent and that AI photo manipulation is not significantly different. However, others express concerns about the impact of AI manipulation on trust and objectivity.

There are also discussions about the potential applications of the RealFill model, including its use in film and TV post-production work, as well as the challenges of converting widescreen content to vertical formats.

Overall, the comments cover a range of perspectives on the RealFill model and its implications for image completion and manipulation.

### AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model

#### [Submission URL](https://arxiv.org/abs/2309.16058) | 38 points | by [babakd](https://news.ycombinator.com/user?id=babakd) | [4 comments](https://news.ycombinator.com/item?id=37699312)

Researchers have introduced AnyMAL, an efficient and scalable Any-Modality Augmented Language Model. AnyMAL is a unified model that can reason over diverse input modality signals such as text, image, video, audio, and IMU motion sensor data, and generate textual responses. This model inherits the powerful text-based reasoning abilities of state-of-the-art Language and Vision Models (LLMs) and converts modality-specific signals to the joint textual space. To enhance the model's capabilities, it is fine-tuned with a multimodal instruction set covering diverse topics and tasks. The researchers conducted comprehensive evaluations, including both human and automatic evaluations, and demonstrated state-of-the-art performance on various multimodal tasks. The paper, authored by Seungwhan Moon and his team, offers valuable insights into the development of powerful and versatile language models.

The discussion on this submission includes a few comments. 

One user, lsdmb, points out that people in the field of machine learning (ML) seem to have stopped caring about existing acronyms. They have seen multiple papers where ML acronyms are replaced with new, catchy acronyms. Another user, 3abiton, comments that even in the field of low-power, long-range wireless communication (LoRa), existing acronyms are also being replaced frequently. 

Another user, techbro92, jokingly suggests that they hope somebody creates a group controlling quadrupeds with a language and vision model (LLM). This comment is likely referencing the capabilities of AnyMAL and how it can reason over diverse input modalities such as text, image, video, audio, and IMU motion sensor data.

### Meta unveils Llama 2 Long AI beats GPT-3.5 Turbo and Claude 2 on some tasks

#### [Submission URL](https://venturebeat.com/ai/meta-quietly-releases-llama-2-long-ai-that-outperforms-gpt-3-5-and-claude-2-on-some-tasks/) | 36 points | by [nickthegreek](https://news.ycombinator.com/user?id=nickthegreek) | [11 comments](https://news.ycombinator.com/item?id=37710591)

Meta Platforms, the parent company of Facebook, Instagram, and WhatsApp, showcased a range of new AI features for its consumer-facing services at the Meta Connect conference. However, the biggest reveal came in the form of a computer science paper published by Meta researchers on arXiv.org. The paper introduces Llama 2 Long, an AI model that outperforms competitors like OpenAI's GPT-3.5 Turbo and Claude 2 in generating responses to long user prompts. The researchers achieved this by pretraining Llama 2 with longer training sequences and incorporating more longer text data sources. They also made modifications to the positional encoding of the model. The success of Llama 2 Long highlights Meta's commitment to open-source generative AI and its ability to compete with closed-source models from well-funded startups.

The discussion on this submission revolves around the restrictions and licensing of Meta's AI models. One user mentions that Meta's closed API-only offerings may pose a challenge for those willing to invest in them, as compared to the more open approach taken by OpenAI. Another user points out that the terms of service for Meta's models have certain restricted use cases, with limitations related to ITAR compliance and specific sensitive subjects. Another user suggests that training one's own models might be important, considering the restrictive nature of Meta's models.

There is also a discussion about the foundations of Meta's models and the popularity of open-source Language Model Libraries (LLMs). One user mentions that the foundations of Meta's models are built on popular open-source LLMs. Another user highlights the significance of open-source models by mentioning their literal code and architectural differences for implementing and training models.

A user mentions that Meta's models are subject to restrictive licensing, while another user points out that Meta's AI models are open-sourced.

The final comment simply says "pinned source," which could be a reference to the request for the source code of Meta's models.

In summary, the discussion focuses on the restricted nature of Meta's models and their licensing, as well as the importance of open-source language models and the potential challenges they pose for users.

### Farm robots inspired by ant brains

#### [Submission URL](https://techxplore.com/news/2023-09-farm-robots-ant-brains.html) | 22 points | by [wglb](https://news.ycombinator.com/user?id=wglb) | [6 comments](https://news.ycombinator.com/item?id=37706353)

Farmers have been benefiting from the rise of AI in the agriculture industry, with new farm tools revolutionizing traditional farming practices. One such innovation is the Ecorobotix, a solar battery-powered robot that navigates crop fields with GPS assistance and efficiently destroys weeds. Another example is the LettuceBot, which uses advanced scanning technology to differentiate between weeds and crops, allowing for optimal growth and reduced pesticide usage. 

Researchers from the Universities of Edinburgh and Sheffield in the UK have taken inspiration from ants to tackle the challenge of visual navigation through dense vegetation. Ants are known for their efficient organization and complex problem-solving skills, which researchers believe can be translated to robotic structures. In a recent study published in the journal Science Robotics, the researchers developed an artificial neural network that mimics the route memory abilities of ants. By collecting images along unfamiliar routes and using the neural network algorithm, the researchers achieved positive results in navigating challenging, vegetation-dense fields. 

This research holds promise for advancements in agricultural robotics, as it provides a low-power and efficient solution for navigation in complex environments. By integrating insect-inspired navigation systems into robotic tools, future applications in agriculture, forestry, and environmental monitoring could greatly benefit from this technology.

The discussion on this submission revolves around a few different topics.

One commenter, "bcx," mentions a science fiction book called "Children Time" by Adrian Tchaikovsky that explores the concept of interconnected robots that clean.

Another commenter, "lmtbt," discusses the LettuceBot and its ability to scan crop geometry and distinguish between weeds and crops, which can help with optimal growth and reduced pesticide usage. They also mention the potential for these types of tools to replace pesticides and the low energy consumption and cost associated with them.

Another commenter, "myshp," suggests that tools that replace pesticides have the potential to be more impactful in terms of biodiversity preservation. They mention the possibilities of robots selectively pruning or changing fertilizer usage, and using machine learning systems to optimize multi-crop growing patterns and minimize risk while helping maintain local ecosystems.

A commenter named "dnfx" makes a brief comment about machine learning and AI technologies being used in internal document retrieval systems.

The last comment is a humorous one, simply saying "Holy cmm splc Batman."

### UK dismisses independent AI advisory board

#### [Submission URL](https://thenextweb.com/news/uk-dismisses-independent-ai-advisory-board-alarming-tech-sector) | 60 points | by [webmaven](https://news.ycombinator.com/user?id=webmaven) | [11 comments](https://news.ycombinator.com/item?id=37704036)

The UK government has quietly dismissed the independent advisory board of its Centre for Data Ethics and Innovation (CDEI), which was tasked with promoting the responsible deployment of data and AI technologies, especially within the public sector. The board's webpage was officially shut down on September 9, but a rather uninformative public announcement was released only yesterday. This move has raised concerns among tech business founders in the UK, who worry about transparency and trust in the government and call for a new era of accountability. The government's approach to AI governance has strongly focused on mitigating existential risks, while the CDEI's work has been focusing on the actual, day-to-day uses of data and AI.

The discussion on Hacker News regarding the dismissal of the independent advisory board of the UK's Centre for Data Ethics and Innovation (CDEI) revolves around several key points:

1. Some users highlight that the CDEI's independent advisory board was dissolved, and its webpage was shut down. They express concerns about transparency and trust in the government and call for more accountability.

2. Others argue that the advisory board was never truly independent, as it was a specific government body within a specific government department. They say that it was not 100% clear and independent, but rather subject to political influence.

3. Some users point out that the UK government's approach to AI governance has largely focused on mitigating existential risks, while the CDEI's work focused on the day-to-day uses of data and AI. They suggest that the government's priorities may have played a role in the dismissal of the advisory board.

4. There is a discussion about the potential implications of this move, with some users speculating that it may reflect a shift towards a surveillance state or a lack of attention to ethical considerations in government programs.

5. Several users express disappointment about the lack of communication and transparency surrounding the dismissal of the advisory board. They note that the government's webpage for the board is closed, and there is limited information available.

6. One user mentions that the advisory board did not have access to future risk reports, implying a lack of necessary information for informed decision-making.

Overall, the discussion highlights concerns about the transparency, independence, and ethical considerations in the UK government's approach to data and AI governance.

### Show HN: SapientML – Generative AutoML for Tabular Data

#### [Submission URL](https://github.com/sapientml/sapientml) | 82 points | by [ya9do](https://news.ycombinator.com/user?id=ya9do) | [8 comments](https://news.ycombinator.com/item?id=37698506)

SapientML is an AutoML technology that can generate high-quality pipelines for predictive tasks using tabular data. It learns from existing datasets and their human-written pipelines to efficiently generate pipelines for new datasets. With SapientML, you can run AutoML, obtain and run generated code, and access a model consisting of the generated code. The technology behind SapientML is based on a research paper published at the International Conference on Software Engineering (ICSE). You can find more details and examples in the GitHub repository.

The discussion on the submission is as follows:

1. User "nwfcg" comments that they compared SapientML with other AutoML tools such as AutoGluon, FLAML, and H2O. They suggest that an independent benchmarking paper should be published to establish SapientML's superiority.
2. User "blprnv" disagrees with the assumption that SapientML is an example of AGI (Artificial General Intelligence). They express skepticism and suggest that the comment might be jumping to conclusions without relevant evidence. They apologize for the word choice in their comment.
3. User "Philpax" responds with a brief comment, stating that they wouldn't speculate on the matter.
4. User "tmhgns" explains that the reason for the generation of tabular AutoML solutions is simply due to the fact that it is a traditional approach. They mention that these systems learn from existing solutions and generate pipelines accordingly, citing a relevant research paper.
5. User "dcryn" suggests that there are already commercial offerings that outperform open-source tabular AutoML approaches, such as Datarobot, Azure AutoML, Vertex Bigquery AutoML, Alteryx, Dataiku, and SAS. They believe that if someone is starting with AutoML, commercial space has better options than open source.
6. User "nwfcg" responds that benchmarks and practical validations are needed to support claims about the superiority of commercial offerings. They mention that they haven't seen any commercial offerings outperform AutoGluon Tabular to date.
7. User "hrfrcmmnts" shares that there is a global ML Hackathon in November and they can't wait to try it.
8. User "lttrgrm" references a similar generative space caught back in 2017 and provides a link to an article. They express their astonishment at what might be happening internally within companies like Google.

### Food Delivery Robots Are Feeding Camera Footage to the LAPD

#### [Submission URL](https://www.404media.co/serve-food-delivery-robots-are-feeding-camera-footage-to-the-lapd-internal-emails-show/) | 16 points | by [giuliomagnifico](https://news.ycombinator.com/user?id=giuliomagnifico) | [3 comments](https://news.ycombinator.com/item?id=37705895)

In a surprising turn of events, it has been revealed that a food delivery robot company in Los Angeles, which delivers for Uber Eats, provided video footage filmed by one of its robots to the Los Angeles Police Department (LAPD) as evidence in a criminal case. The incident has sparked discussions about the constant surveillance that these delivery robots engage in and the potential privacy concerns associated with their use. The company, Serve Robotics, expressed an interest in working more closely with the LAPD, and the police department readily seized the opportunity. The specific incident involved an attempted theft of a Serve Robotics robot, which resulted in the arrest and conviction of the suspects. This case has shed light on the fact that delivery robots are always filming, raising questions about the extent of their surveillance capabilities and the potential implications for privacy. The deployment of such robots in urban areas has already become a contentious issue, with social media accounts documenting their presence and the challenges they pose to pedestrians and pets. While the LAPD claims that this incident is an isolated one, the use of video footage from delivery robots in criminal investigations has sparked a debate about the balance between public safety and individual privacy.

The discussion on this submission contains two comments. 

The first comment, made by user Legend2440, criticizes the headline of the article for not mentioning that the incident involving the food delivery robot company and the LAPD was a theft. The user points out that the surveillance aspect is not the main issue but rather the fact that the robots provided evidence in a criminal case.

The second comment, made by user chfrtz, labels the submission as a duplicate and provides a link to another discussion on the same topic. Another user, glmgnfc, simply thanks chfrtz for sharing the duplicate link.

Overall, the discussion in the comments section appears to be minimal, focusing on the content of the headline and providing a duplicate link.

