## AI Submissions for Tue Jun 06 2023 {{ 'date': '2023-06-06T17:14:27.704Z' }}

### Show HN: Arroyo – Write SQL on streaming data

#### [Submission URL](https://github.com/ArroyoSystems/arroyo) | 89 points | by [necubi](https://news.ycombinator.com/user?id=necubi) | [27 comments](https://news.ycombinator.com/item?id=36214393)

Arroyo is a distributed stream processing engine designed with Rust to efficiently execute stateful computations on data streams. The engine offers real-time streaming operations, including windows and joins, with state checkpointing for fault-tolerance and recovery of pipelines. Arroyo provides a web UI, API, and console for pipeline management. The engine is designed to run on modern cloud environments, supporting seamless scaling, recovery, and rescheduling and is built to enable non-experts to build real-time data pipelines. Arroyo is licensed under Apache-2.0 and MIT.

Arroyo is a distributed stream processing engine built from Rust, designed to execute stateful computations on data streams efficiently, with windows and joins, and state checkpointing. The engine was developed to enable non-experts to build real-time data pipelines, and comes with a web UI, API, and console for pipeline management. Discussions about Arroyo revolved around how it compares to Apache Flink and Kafka's KSQL. In particular, Arroyo was praised for its ability to scale and recover seamlessly on modern cloud environments, while Materialize was touted as a good alternative for view maintenance and ClickHouse for a backend. Discussions also touched on the documentation's mention of how events arriving after the watermark can be dropped, with comments pointing out that it is configural and soon will be altered to provide richer semantics of late arriving events. The engine's name which in Spanish means 'stream' was also brought up in discussions, and people shared the various meanings of Arroyo, ranging from seasonal desert streams to rivers. Additionally, there were brief discussions of other Rust-based developments such as TBlogs' tinybird and Arroyo's alternative to Apache KSQL, Confluent.

### Next-Generation CAMM, Mr-DIMM Memory Modules Show Up at Computex

#### [Submission URL](https://www.anandtech.com/show/18893/next-generation-camm-mr-dimm-modules-at-computex) | 22 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [6 comments](https://news.ycombinator.com/item?id=36213242)

ADATA demonstrated potential candidates for replacing traditional SO-DIMMs and RDIMMs/LRDIMMs, at the Computex 2023 trade show in Taipei. These new memory modules include Compression Attached Memory Modules (CAMMs) for ultra-thin notebooks and compact desktops; Multi-Ranked Buffered DIMMs (MR-DIMMs) for servers; and CXL memory expansion modules for machines that need extra system memory. The CAMM specification is slated to be finalized by JEDC later this year, and it promises benefits such as higher transfer rates, lower costs, higher DRAM density, reduced thickness, and dual-channel connectivity on a single module. MR DIMM technology promises to start at 8,800 MT/s with Gen1, then evolve to 12,800 MT/s with Gen2, and then to 17,600 MT/s in Gen3. Meanwhile, CXL memory modules feature a Compute Express Link and connect to host CPUs via a PCIe interface, expanding system memory for servers at a relatively low cost.

The discussion thread for the submission on ADATA's new memory modules includes several comments discussing the potential benefits and drawbacks of the technology. One user jokes about the naming convention for MR-DIMMs, while another suggests that CAMMs could be beneficial for Apple's expandable computers. A user proposes the idea of a "RAM Box" that could connect to a computer's system through Thunderbolt or USB4, while another user discusses the technical details of memory mapping and PCIe interfaces. Finally, one user disputes the claim that CAMMs offer significantly increased memory throughput, arguing that current CPUs do not support the high transfer rates that CAMMs are capable of.

### GGML – AI at the Edge

#### [Submission URL](http://ggml.ai) | 831 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [212 comments](https://news.ycombinator.com/item?id=36215651)

GGML is a tensor library for machine learning that enables large models and high performance on commodity hardware. Its features include automatic differentiation, built-in optimization algorithms, integer quantization support, and more. It is optimized for Apple Silicon, and can simultaneously run multiple instances of large models on a single chip. Whisper.cpp and llama.cpp are two projects that use GGML, and allow for high-performance speech-to-text and language model inference, respectively. GGML is open source and freely available under the MIT license, and the company behind it is seeking to hire full-time developers.

Discussions revolve around related projects such as Llama and Whisper.cpp, which are focused on speech-to-text and natural language inference, respectively. Additionally, issues related to funding and backing are discussed, with some expressing hope for more support for open-source projects and concerns about the impact of closed-source competition. There are also discussions on practical applications of machine learning and the challenges of working with private data.

### Nvidia releases new AI chip with 480GB CPU RAM, 96GB GPU RAM

#### [Submission URL](https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/) | 370 points | by [logicchains](https://news.ycombinator.com/user?id=logicchains) | [277 comments](https://news.ycombinator.com/item?id=36209047)

NVIDIA has announced the Grace Hopper Superchip, a CPU designed specifically for giant-scale AI and high-performance computing applications. The superchip offers up to 10 times the performance of standard CPUs for heavy-duty tasks, such as running terabytes of data. Its features include a 900 GB/s coherent interface, 30 times the system memory bandwidth to GPUs compared to the NVIDIA DGX A100, and compatibility with all NVIDIA software stacks and platforms, from HPC to AI. The chip is already part of the NVIDIA HGX for AI and HPC, as well as the NVIDIA BlueField-3. It joins more than 400 configurations of NVIDIA architectures being produced to support the widespread demand for AI.

Commenters discussed the history of supercomputers and computer memory and debated the significance of the Grace Hopper Superchip for the AI and high-performance computing industry. Some pointed out that the chip's compatibility with all Nvidia software stacks and platforms could be a game-changer. Others discussed the high-speed IO and the slow growth of available memory, indicating that building cards with 100GB RAM would be of little use to businesses. Overall, commenters were interested in the advancement of technology and the implications of this new CPU for the industry.

### MeZO: Fine-Tuning Language Models with Just Forward Passes

#### [Submission URL](https://github.com/princeton-nlp/MeZO) | 138 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [21 comments](https://news.ycombinator.com/item?id=36216532)

Princeton University's Natural Language Processing group has developed a new memory-efficient optimizer that fine-tunes language models (LMs) using just forward passes. Dubbed MeZO, the method adapts the zeroth-order SGD method to operate in-place, thus improving memory efficiency for tasks such as LM fine-tuning. The team claims their solution can train a 30-billion parameter OPT model using just a single A100 80GB GPU, while fine-tuning with Adam can only train a 2.7-billion parameter LM. MeZO reportedly performs comparably to fine-tuning with backpropagation, with memory reduction of up to 12 times.

The discussion on Hacker News explores various aspects of the method, including its comparison with backpropagation, its potential for swarm optimization, and the significance of its memory-reducing capabilities. There are also discussions around other related topics such as forward-forward algorithms and inference vs. training speed.

### visionOS

#### [Submission URL](https://developer.apple.com/visionos/) | 96 points | by [soheilpro](https://news.ycombinator.com/user?id=soheilpro) | [87 comments](https://news.ycombinator.com/item?id=36208735)

Apple has announced visionOS, a new platform for designing and developing apps and games for its upcoming Apple Vision Pro. It offers an infinite spatial canvas for experimentation, exploration and play, and enables developers to create fully immersive environments or fluid experiences that can seamlessly transition between a 3D window and a fully immersive scene. The platform includes windows, volumes and spaces, and leverages familiar frameworks and tools such as SwiftUI, RealityKit, ARKit and Unity. The visionOS SDK will be released later this month, along with Xcode, the visionOS Simulator, Reality Composer Pro, documentation, sample code and design guidance.

Commenters discussed various related topics, such as the use of 3D elements in standard HTML, the use of POSIX for full-stack development, and the possibility of using a global standard for 3D elements. Others talked about potential killer apps for watchOS, the health implications of screen time, the challenges of AR and VR technologies, and the need for better standards for augmented and virtual reality. Some commenters also discussed Furcadia, a 20-year-old game that uses 2D graphics.  Overall, the discussion covered a variety of topics related to the recent release of visionOS and the broader issues facing developers and users of augmented and virtual reality technologies.

### Redditor creates working anime QR codes using Stable Diffusion

#### [Submission URL](https://arstechnica.com/information-technology/2023/06/redditor-creates-working-anime-qr-codes-using-stable-diffusion/) | 568 points | by [samizdis](https://news.ycombinator.com/user?id=samizdis) | [94 comments](https://news.ycombinator.com/item?id=36218281)

A Reddit user named "nhciao" has created functional QR codes using the Stable Diffusion AI image-synthesis model that reflect artistic styles in anime and Asian art. Despite the presence of intricate AI-generated designs and patterns, smartphone camera apps on both iPhone and Android are still able to read them as functional QR codes. Stable Diffusion is an AI-powered image-synthesis model released last year that can generate images based on text descriptions. Ordinary black-and-white QR codes could be turned into unique pieces of art with this technique, enhancing their aesthetic appeal.

The comments section discussed other topics like different kinds of QR codes, their historical development, and their correct labeling. Furthermore, others discussed the limitations and reliability of Machine Learning (ML) algorithms and its effects on QR code implementations. One user pointed out that generating images through Stable Diffusion AI is impressive and can be used on products other than QR codes. Another user mentioned that the aesthetics of anime and Asian art is distinct and might create different interpretations.

### Vector Database in a Jupyter Notebook

#### [Submission URL](https://zilliz.com/blog/exploring-magic-vector-databases-jupyter-notebooks) | 69 points | by [fzliu](https://news.ycombinator.com/user?id=fzliu) | [6 comments](https://news.ycombinator.com/item?id=36207009)

In this article, the author explains the concept of vector databases and their usefulness in powering similarity search applications. They particularly highlight the need for vector databases in solving one of the main challenges that large language models (LLMs) face, which is a lack of domain knowledge and up-to-date data. The article then goes on to explain how to use Milvus (Lite) in your Jupyter Notebook, a vector database with a distributed system native backend that is purpose-built to handle indexing, storing, and querying vector data at a billion scales. The author provides step-by-step instructions on how to get started with Milvus (Lite) and shares resources for those who want to use a standalone vector database instance.

The comments on the submission include some discussions about related topics. One commenter shared a YouTube link that could be helpful for those interested in vector databases. Another commenter mentioned the importance of vector databases in natural language processing (NLP) applications and machine learning model integration. They provided examples of vector databases beyond semantic text search, including spatial data and structured data vectorization for machine learning. The conversation then shifted to personal introductions and networking, with one commenter expressing interest in learning more about the Semantic Kernel.

### Apple releasing segmentation/pose for humans and animals, embedding for 27 lang

#### [Submission URL](https://developer.apple.com/wwdc23/topics/ml-vision/) | 216 points | by [sumodm](https://news.ycombinator.com/user?id=sumodm) | [70 comments](https://news.ycombinator.com/item?id=36209014)

Apple's WWDC23 sessions offered in-depth explorations of machine learning and computer vision, with a focus on Apple's Core ML, Create ML, and Vision frameworks. Sessions delved into topics such as animal pose detection, 3D body pose and person segmentation, lifting subjects and developing live camera-tracking experiences. Create ML's updates in image understanding, text-based tasks with multilingual BERT embeddings, and multi-label classification were also discussed. Labs offered one-on-one appointments with Apple engineers to discuss machine learning in app development, and Q&A sessions let attendees ask questions on topics including image understanding and machine learning more broadly.

One Hacker News user was skeptical of the usefulness of pose detection exercises for personal fitness, while others noted that many fitness apps already use similar technology. Some users discussed the benefits and drawbacks of building apps specifically for Apple's platform vs. creating platform-agnostic software. One user suggested that Apple's subscription-based business model is geared towards retaining existing customers. Other users shared their experiences with various fitness apps and platforms.

### Phishing Darknet Users for Bitcoins

#### [Submission URL](https://shufflingbytes.com/posts/ripping-off-professional-criminals-by-fermenting-onions-phishing-darknet-users-for-bitcoins/) | 100 points | by [campuscodi](https://news.ycombinator.com/user?id=campuscodi) | [58 comments](https://news.ycombinator.com/item?id=36212480)

A hacker has developed a Proof of Concept of a method for stealing from fraudsters operating on the darknet. The Onion Fermenter (OF) uses traffic modifying reverse proxy to create fake darknet sites and redirect transactions to the hacker's wallet, ensuring there are no breadcrumbs for investigators to follow. Darknet sites have no central trusted source for checking legitimacy and descriptions cannot differentiate between fake and real, making it easy to plant sites for the unwary. Other phishing attempts have previously been reported, but OF can be deployed quickly and easily across Kubernets making it potentially far more lucrative.

The discussion includes arguments about the moral and legal justification for stealing from criminals, with some people calling for consistent moral codes to be applied across all situations. One commenter pointed out that high-trust societies respect themselves and play by their own moral codes, while others argued against vigilantism. The discussion also included technical details about the effectiveness of the OF method and the perception of different games and crimes. Finally, the discussion touched on the topic of phishing schemes and how they exploit the unwary on the darknet.

### AI: Nvidia Is Taking All the Money

#### [Submission URL](https://seekingalpha.com/article/4609485-ai-nvidia-is-taking-all-the-money) | 71 points | by [TradingPlaces](https://news.ycombinator.com/user?id=TradingPlaces) | [29 comments](https://news.ycombinator.com/item?id=36214749)

Nvidia Corporation has dominated the AI hardware and software market with their GPUs and software since 2012, making them a major target for competitors. Their GPUs have enabled exponential growth in AI model size, allowing them to charge high prices for their data center GPUs with a 75% gross margin. Microsoft's cloud operating margin has been impacted by the cost of Nvidia GPUs, and the cost to run large models in production has drastically increased due to Nvidia's monopoly. While competitors are working on non-GPU hardware, smaller models, and new software, it will be difficult for them to knock Nvidia off its perch as the default for AI research.

The discussion covers the finite demand for AI and how the high cost of Nvidia GPUs is impacting the industry. AMD is viewed as a potential competitor to Nvidia, but CUDA remains the industry standard. There is hope for a standardized software that does not require special customization and incentives for using non-Nvidia devices in AI training and inference.

### Hyperparameter Optimization for LLMs via Scaling Laws

#### [Submission URL](https://arxiv.org/abs/2302.00441) | 81 points | by [Lindizz](https://news.ycombinator.com/user?id=Lindizz) | [12 comments](https://news.ycombinator.com/item?id=36210727)

Researchers from the field of computer science and machine learning have proposed a new method called Deep Power Laws (DPL) to optimize hyperparameters of machine learning algorithms. The method utilizes an ensemble of neural network models conditioned to provide predictions that follow a power-law scaling pattern. The DPL method dynamically selects which configurations to pause and train incrementally, making use of grey-box evaluations. The researchers compared their method with 7 state-of-the-art competitors on 59 diverse tasks related to tabular, image, and NLP datasets. They achieved the best any-time results, obtaining the best results compared to all competitors.

The discussion in the comments includes various strategies for hyperparameter optimization, including starting with a default configuration and using Hyperband, DL1, and Bayesian search methods. Additionally, some users commented on the use of smaller models with dynamic budgets and configurations, while others discussed the specific application of DPL for NLP and computer vision datasets. Some users also expressed issues with hyperparameter optimization and the need for more research in this area.

### Tips for better coding with ChatGPT

#### [Submission URL](https://www.nature.com/articles/d41586-023-01833-0) | 150 points | by [isingle](https://news.ycombinator.com/user?id=isingle) | [104 comments](https://news.ycombinator.com/item?id=36211250)

OpenAI's chatbot, ChatGPT, is a powerful AI tool that researchers can use to debug code, translate software from one programming language to another, and perform rote operations. However, users must remember that chatbots are not intelligent; they are stochastic parrots that randomly echo what they have seen before. Therefore, it is critical to use caution when working with ChatGPT and related tools based on large language models. Here are six tips to maximize the utility of chatbots in coding: choose your applications wisely, trust but verify their responses, read responses carefully, test them thoroughly, keep up with software engineering, and use them as a conversational interface to Stack Overflow.

The discussion among Hacker News users provided mixed opinions on the utility of ChatGPT in coding, with some calling it productive and helpful, and others describing it as useless or requiring context and business requirements. Some commentators noted that large language models (LLMs) have difficulty answering complex questions or tasks that require specific domain knowledge. There were also discussions on the potential risks of using AI tools like ChatGPT and the importance of context in interpreting its responses.

### First impressions: Yes, Apple Vision Pro works and yes, it’s good

#### [Submission URL](https://techcrunch.com/2023/06/05/first-impressions-yes-apple-vision-pro-works-and-yes-its-good/) | 276 points | by [thatsso1999](https://news.ycombinator.com/user?id=thatsso1999) | [530 comments](https://news.ycombinator.com/item?id=36207705)

Apple has previewed its new mixed reality headset, the Apple Vision Pro, and after a 30-minute demo, industry insiders are impressed with its capabilities. With an eye-tracking and gesture control feature recognised as perfect, and the ability to pass-through a real-time 4K view of the world around the user, the headset is being applauded for eliminating issues of long-session VR or AR wear by passing through an image and including a "breakthrough" mechanism to warn of intruders. Though priced at the high end at $3,500, insiders see it as a power users' device and believe it has the potential to be a new computing mode. Some commenters are skeptical about the high price of the headset and whether it will appeal to a broad audience, while others believe it has the potential to be a new computing mode and replace laptops or even TV. Overall, there are mixed opinions about the potential success of the Apple Vision Pro and its place in the current market.

### Sextortionists are making AI nudes from your social media images

#### [Submission URL](https://www.bleepingcomputer.com/news/security/sextortionists-are-making-ai-nudes-from-your-social-media-images/) | 38 points | by [nazgulsenpai](https://news.ycombinator.com/user?id=nazgulsenpai) | [27 comments](https://news.ycombinator.com/item?id=36219621)

The FBI has alerted the public to a disturbing new trend in sextortion attacks. Scammers are taking publicly available images of their targets from social media and using them to create AI-generated sexually explicit content. While these images and videos are not real, they look very convincing and can be used to blackmail victims into paying money or sending real sexually explicit content. This trend has also impacted minors. To protect oneself, the FBI advises that parents monitor their children's online activity, adults restrict viewing access to a small private circle of friends, and anyone who discovers deepfake content of themselves on pornographic sites should report it to the authorities and contact the hosting platform for removal.

### Healthcare org with over 100 clinics uses GPT-4 to write medical records

#### [Submission URL](https://www.theregister.com/2023/06/06/carbon_health_deploys_gpt4powered_tools/) | 29 points | by [beardyw](https://news.ycombinator.com/user?id=beardyw) | [9 comments](https://news.ycombinator.com/item?id=36215907)

Carbon Health, a US healthcare chain, has introduced an AI tool for generating medical records automatically. Dubbed Carby, the tool is powered by OpenAI's latest language model, GPT-4. If a patient consents to having their meeting recorded and transcribed, the audio recording is passed to Amazon's AWS Transcribe Medical cloud service, which converts the speech to text. The transcript is then passed to an ML model that produces notes summarising important information gathered in the consultation. Carbon Health claims the tool produces consultation summaries in four minutes, compared to the 16 minutes it takes a single doctor to do it; clinics can therefore see more patients.

There were a few discussions about Carbon Health's AI tool for generating medical records. Some users were surprised that the healthcare providers allowed patient data to be sent to OpenAI given HIPAA regulations. However, it was noted that OpenAI's security page claims to have experience with helping customers meet regulatory industry requirements such as HIPAA. There was also a discussion about how the tool uses AI to produce consultation summaries in four minutes, which is much faster than a single doctor taking 16 minutes to do it. While some were skeptical about the accuracy of generative AI models, Carbon Health claimed that physicians verified 88% of the AI-generated text and made edits for the remaining 12% of the time. Finally, there was a discussion on the legal and privacy implications of using AI in healthcare, with some mentioning that Eric Schmidt, former CEO of Google, predicted in 2018 that AI will be widely used in healthcare in the future.

