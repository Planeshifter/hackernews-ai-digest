## AI Submissions for Wed Sep 24 2025 {{ 'date': '2025-09-24T17:15:24.293Z' }}

### Learning Persian with Anki, ChatGPT and YouTube

#### [Submission URL](https://cjauvin.github.io/posts/learning-persian/) | 249 points | by [cjauvin](https://news.ycombinator.com/user?id=cjauvin) | [84 comments](https://news.ycombinator.com/item?id=45359524)

A language learner outlines a repeatable, low-friction workflow for mastering Farsi using spaced repetition, AI, and YouTube—optimized for phrases over isolated words.

- Core: A “never-ending” Anki deck built from screenshots. Two card types: one-sided Persian-only cards for reading practice (to tackle contextual letter forms and missing vowels), and “basic & reversed” cards pairing romanized phrases with English/French translations.
- On-demand tutor: When stuck during reviews, they paste a screenshot into a dedicated ChatGPT “Persian” project for instant refreshers and explanations—repeating questions until concepts stick.
- YouTube pipeline: Videos (notably from Majid’s Persian Learning channel) plus Dual Subtitles for parallel Farsi/English, and Tweaks for YouTube to nudge playback by 1 second for micro-replays. Screenshots from subtitles feed new Anki cards.
- Listening technique: Play at 75% speed; glance at English first to prime meaning; then listen closely to Farsi so the known meaning maps onto the sounds; read the Farsi script to disambiguate; repeat out loud; loop the same segment until understanding is real-time.
- Why it works: Phrase-based SRS, frictionless capture (screenshots), micro-iteration on audio, and AI as a just-in-time coach create a high-feedback system that targets reading, listening, and speaking together.

Takeaway: A simple, reproducible stack that blends SRS, subtitles, and AI can make progress in a non-Latin script language feel fast and tangible—especially when you train with phrases and iterate ruthlessly on short clips.

**Discussion Summary:**

The conversation revolves around language learning strategies, focusing on tools like Anki, cultural nuances, and practical experiences. Key themes include:

1. **Anki Workflow & Customization:**
   - Users praised Anki for vocabulary building but debated pre-built vs. custom decks. Many emphasized **personalized decks** as more effective, arguing pre-made decks (e.g., for Spanish C1) often lack context and feel algorithmically generated. Tools like LLM-powered Anki extensions were recommended for generating tailored cards.
   - A user shared success with **KOFI conjugation decks** for Spanish/French, highlighting their structured approach to mastering verb forms, though irregular verbs remain challenging.

2. **Cultural Blunders & Nuances:**
   - Humorous anecdotes surfaced about **language mishaps**, such as confusing "chaqueta" (jacket) with a vulgar term in Mexican Spanish or Dari/Pashto misunderstandings in Afghanistan. These stories underscored the importance of cultural context and the risks of over-relying on direct translations.

3. **Tool Recommendations:**
   - **Clozemaster** and **Assimil** were cited for immersive learning, while **YouTube channels** (e.g., French Comprehensible Input) and **Yabla** were suggested for listening practice.
   - For Persian/Farsi, **Majid’s Persian Learning channel** and **Dual Subtitles** were highlighted as key resources.

4. **Practical Insights:**
   - A user working in Afghanistan with the ICRC shared how learning Dari/Pashto was crucial for humanitarian work, stressing the value of **in-country immersion** and crash courses.
   - Others emphasized **comprehensible input** (e.g., native TV, comics) and **spaced repetition** systems (SRS) as foundational to progress, advising learners to transition to native content early.

**Takeaway:** The discussion champions a blend of structured tools (Anki, LLMs) and immersive, context-rich learning, while acknowledging the humor and humility required to navigate cultural-linguistic pitfalls.

### How HubSpot scaled AI adoption

#### [Submission URL](https://product.hubspot.com/blog/context-is-key-how-hubspot-scaled-ai-adoption) | 69 points | by [zek](https://news.ycombinator.com/user?id=zek) | [43 comments](https://news.ycombinator.com/item?id=45361140)

HubSpot’s two-year journey from AI-curious to near-universal adoption of coding assistants

- What happened: Starting with a GitHub Copilot pilot in Summer 2023, HubSpot moved from cautious trials to organization-wide use of AI coding tools, reporting modest-but-real productivity gains that compounded over time.

- Why it worked: Executive sponsorship (from founders Dharmesh Shah and Brian) aligned legal, security, and engineering, enabling fast pilots and rollout with guardrails. Entire teams trialed the tools for 2+ months, with training, Q&A channels, and velocity metrics to counter bias.

- Cost calculus: Even early gains justified Copilot’s ~$19/user/month price. The team stayed patient, betting the tech would improve—and saw larger gains as usage deepened.

- Centralization as a force multiplier: In Oct 2024, HubSpot formed a small Developer Experience AI team to:
  - Drive adoption across the org
  - Inject HubSpot-specific context into AI (from shared Cursor rules to richer architecture/best-practice knowledge)
  - Build community and internal advocacy
  - Speed procurement (month-to-month contracts, rapid trials)
  - Run empirical evaluations instead of relying on anecdotes

- The “context is king” insight: Quality jumped when AI tools knew HubSpot’s opinionated stack, libraries, and conventions—turning generic assistants into org-aware ones.

- Playbook you can copy:
  - Secure strong exec buy-in early
  - Pilot with whole teams, not scattered individuals
  - Invest in enablement and a public forum for wins/warts
  - Instrument impact using existing engineering velocity metrics
  - Stand up a small central team to own adoption, context, evaluation, and procurement agility
  - Start with guardrails; relax as data and confidence grow

- Why it matters: Scaling AI beyond early adopters is an org design problem as much as a tooling one. Central teams, org-specific context, and measurement turn modest early gains into durable productivity improvements.

- What’s next: HubSpot hints at more advanced, context-rich tools and practices in this series as they continue to expand AI’s role in their developer workflow.

**Hacker News Discussion Summary: HubSpot’s AI Adoption Journey**

The discussion around HubSpot’s AI adoption journey reveals a mix of skepticism, technical debate, and criticism of the company’s history and practices. Key themes include:

---

### **Skepticism About HubSpot’s Narrative**
- **Cultural Criticism**: Users reference Dan Lyons’ book *Disrupted*, which portrays HubSpot’s culture as overly hyped and akin to "Facebook-style" aggressive tactics. Comments highlight perceived parallels between HubSpot’s "passive-aggressive" workplace culture and Silicon Valley’s darker traits.  
- **Ethics and Controversies**: Past scandals, including a hacking incident targeting a journalist (linked to a 2014 Finextra article) and comparisons to eBay’s stalking scandal, are cited as reasons to doubt HubSpot’s virtuous image. Critics argue the submission overlooks these issues.  

---

### **Debates About AI’s Impact**
- **Measurement Concerns**: Many question the lack of concrete data in the submission. Users demand rigorous, transparent metrics (e.g., code review burden, velocity, incident rates) instead of vague "modest gains" claims.  
- **Productivity Tools vs. Mandates**: Discussions erupt over mandating AI tools (e.g., GitHub Copilot) and IDEs. Some argue enforcement stifles productivity, while others defend standardized tooling for collaboration.  
- **AI’s Utility**: A subset dismisses AI tools as "dumb" or overhyped, emphasizing that 98% of code is straightforward, with human intervention still critical for edge cases.  

---

### **Criticism of HubSpot’s Business Model**
- **Inbound Marketing Backlash**: While HubSpot is credited with popularizing inbound marketing, critics liken its content-driven approach to "spam," arguing it prioritizes quantity (blogs, whitepapers) over quality. The tactic is seen as outdated, with AI now accelerating low-value content creation.  
- **Dubious Reviews**: Users debate the legitimacy of glowing Google/X reviews, suspecting they’re manufactured or gamed.  

---

### **Workplace Dynamics**
- **AI Fluency Pressures**: Concerns emerge about hiring expectations—companies increasingly demand AI proficiency, potentially sidelining existing engineers resistant to workflow changes.  
- **Overwork and Surveillance**: Jokes about mandated monitors and keyboard tracking reflect broader anxieties about surveillance and productivity grind in tech.  

---

### **Call for Nuance**
- **Acknowledgment of Strategy**: A few users concede that HubSpot’s centralized AI team and focus on org-specific context (e.g., internal RPC systems) could offer lessons for scaling AI adoption effectively.  
- **Need for Balance**: One commenter notes that while HubSpot’s execution is flawed, its survival in a competitive landscape (vs. Salesforce) is notable.  

---

### **Conclusion**
The discussion tempers HubSpot’s success story with reminders of its controversial past, skepticism about self-reported metrics, and debates over AI’s real-world impact. While some praise the tactical approach to AI adoption, broader distrust of corporate narratives and ethical concerns dominate the thread.

### Zed's Pricing Has Changed: LLM Usage Is Now Token-Based

#### [Submission URL](https://zed.dev/blog/pricing-change-llm-usage-is-now-token-based) | 176 points | by [meetpateltech](https://news.ycombinator.com/user?id=meetpateltech) | [196 comments](https://news.ycombinator.com/item?id=45362425)

Zed switches its AI pricing to “pay for what you use,” cuts Pro in half, and adds top-tier models

- What’s new: Zed is moving from prompt caps to token-based billing. For new users it’s live today; existing users migrate over the next three months.
- Pro price drop: Pro goes from $20 to $10/month and now includes $5 in token credits. Additional hosted usage is billed at provider list price +10% (to cover infra/support and higher rate limits).
- Free stays useful: Free plan still includes 2,000 accepted edit predictions. Hosted prompt quotas are gone.
- Pro still unlimited where it counts: Unlimited accepted edit predictions remain on Pro.
- More models: Hosted lineup expands to Claude Sonnet/Opus plus GPT-5 (including mini/nano) and Gemini 2.5 Pro/Flash.
- Rationale: LLM bills became Zed’s biggest cost; prompt pricing didn’t track value (fixing a typo vs multi-file refactors cost the same). Tokens align cost with usage and simplify adding models.
- Alternatives built in: Bring your own API keys (OpenAI, Anthropic, Grok, etc.), use local models via Ollama, connect third‑party agents via ACP, or route spend through Copilot, OpenRouter, Bedrock. You can also disable AI entirely.
- Trials and subsidies: Pro trial remains 14 days but now comes with $20 in token credits. Zed says future subsidies will be targeted (e.g., student discounts).
- Migration timeline: 
  - Pro customers: migrate by Dec 17, 2025 (or switch earlier to access new models).
  - Free users: move to the new Free plan on Oct 15, 2025, with a fresh Pro trial available anytime starting now.
  - Trial users: moved back to the old Free plan today (Sep 24) and get a new trial.

Big picture: Zed is aligning revenue with actual inference costs so it can invest in speed, reliability, and collaboration features, while keeping Pro affordable and flexible for heavy users and letting everyone else plug in their own AI.

Here's a concise summary of the Hacker News discussion about Zed's AI pricing changes and editor ecosystem:

### Key Themes in the Discussion:
1. **Performance Concerns**  
   - Users reported issues with handling large files (e.g., 1GB+ files caused 20GB+ memory spikes) and macOS/Linux font rendering glitches. Some experienced crashes when opening large projects.  
   - Comparisons to **Sublime Text** and **VS Code** surfaced, with Sublime praised for speed/robustness with huge files, while others noted JetBrains IDEs (e.g., CLion, Goland) handle massive codebases more reliably.  

2. **AI Integration vs. Core Editor Functionality**  
   - Skepticism arose around Zed’s heavy AI focus: "AI minority priority" vs. practical needs like stability. Some felt AI features distracted from improving core text-editing UX.  
   - Users debated AI's true utility, with remarks like "thr’s disproprtionate mention of AI in blog posts" and fears of "existential dread" when relying on AI agents mid-task.  

3. **Market Alternatives**  
   - **Sublime Text** was lauded but criticized for closed-source/licensing decisions. Users expressed interest in open-source alternatives like **SpartanJ’s experimental editor** (GPU-accelerated, designed for performance) but noted challenges matching Sublime’s polish.  
   - VS Code remains a popular fallback despite Zed’s speed advantages, especially for its extensions and familiarity.  

4. **Pricing & Priorities**  
   - Zed’s new token-based pricing was seen as logical, but concerns lingered about long-term VC-driven profit motives overriding user-centric development.  
   - Some questioned whether Zed’s "aggressive AI vision" aligns with developer workflows, preferring focus on collaboration tools (e.g., multiplayer editing) and refinement of basics.  

### Notable Quotes:
- **On Performance**: *"Opening a 1GB text file caused macOS to run out of system memory... Zed quickly ate 20GB during a search operation."*  
- **On AI Fatigue**: *"Companies are selling AI as the thing you do day-to-day... often non-technical management drives this."*  
- **On Alternatives**: *"Sublime’s biggest gap is being closed-source. Zed, while VC-backed, at least feels like a step toward modernizing without losing performance."*  

### Bottom Line:
The discussion reflects enthusiasm for Zed’s speed and modern features but highlights tension between AI ambitions and foundational editor reliability. Performance pitfalls and skepticism about over-indexing on AI (vs. refining core UX) dominate concerns, while alternatives like VS Code and Sublime remain entrenched for their stability.

### Greatest irony of the AI age: Humans hired to clean AI slop

#### [Submission URL](https://www.sify.com/ai-analytics/greatest-irony-of-the-ai-age-humans-being-increasingly-hired-to-clean-ai-slop/) | 202 points | by [wahvinci](https://news.ycombinator.com/user?id=wahvinci) | [114 comments](https://news.ycombinator.com/item?id=45356226)

The piece argues that while AI is displacing creative jobs, it’s simultaneously creating a new labor market for “digital janitors” paid to fix its mistakes. “AI slop”—low-quality, plausible-but-wrong text, images, music, and video—now floods platforms, forcing companies to hire writers, designers, and VFX artists not to create, but to clean up.

Notable examples
- Viral AI videos: a seagull smashing a car window for a fry (~140M views) and “CCTV-style” trampoline animals (rabbits ~200M; bears similar), with telltale glitches like two-headed bunnies and vanishing frames.
- Brand/ads: a screenshot from an AI-assisted Coca-Cola holiday commercial spelling “Coca-Coola.”
- Real-world fallout: thousands in Dublin reportedly showed up for a non-existent Halloween parade after AI-made ads with gibberish text spread.
- Definition: Jack Izzo (Yahoo) calls AI slop the evolution of spam—empty-calorie content that overwhelms feeds and blurs what’s real.

Why it matters
- Industrialized misinformation and the “enshittification” of culture as feeds, playlists, and marketplaces fill with AI remixes.
- Rising demand for human cleanup—content rewriters, fact-checkers, retouchers, VFX fixers—often the very people AI was meant to replace.
- Environmental costs: water and electricity usage to generate mountains of low-value content.
- Creative burnout and a shift from authorship to maintenance.

HN discussion starters
- Are “AI janitor” roles a sustainable career path or a race to the bottom?
- Can provenance/labeling or platform policy slow the slop flood?
- Does paying humans to polish AI output entrench the problem—or buy time until models improve?

**Summary of Hacker News Discussion:**

The discussion revolves around the paradox of AI displacing creative jobs while creating new roles for humans to clean up its errors ("AI slop"). Key themes include:

1. **Job Market Shifts**:  
   - Junior roles (e.g., interns, entry-level designers) are increasingly replaced by AI, disrupting traditional talent pipelines. Without juniors gaining experience, industries face a shortage of future senior talent.  
   - Skepticism exists about whether "AI janitor" roles (e.g., fact-checkers, content fixers) are sustainable or merely a "race to the bottom."  

2. **Quality & Creativity**:  
   - AI-generated content often lacks specificity and validation. Humans are still needed to catch errors (e.g., nonsensical text, visual glitches) that AI overlooks.  
   - Some argue AI homogenizes creativity, favoring "safe" outputs over originality, leading to cultural "enshittification."  

3. **Comparisons to Manufacturing**:  
   - Fixing AI errors is likened to factory quality control, but with key differences: AI’s "defects" are harder to detect (e.g., subtle logical flaws vs. visual defects) and require mental labor rather than physical rework.  
   - Concerns about energy costs and efficiency if AI produces vast low-quality output needing human cleanup.  

4. **Economic & Cultural Concerns**:  
   - Doubts about government job data (BLS) accurately reflecting AI’s impact, with references to politicized reporting.  
   - The creative economy risks collapse if mid-tier roles vanish, leaving only high-cost agencies or automated slop.  

5. **Technological Optimism vs. Skepticism**:  
   - Some see AI as part of a broader industrial revolution, improving over time. Others question its revolutionary status, noting current limitations and the need for human oversight.  

**Notable Points**:  
- A user highlighted India’s service industry, where workers manually fix faulty items instead of discarding them, suggesting parallels to AI slop cleanup.  
- Debate over whether AI’s flaws will self-correct with advancements (e.g., GPT-5) or entrench reliance on human intervention.  

Overall, the discussion reflects tension between AI’s potential and its current limitations, with concerns about economic sustainability, cultural degradation, and the evolving role of human labor.

### The Data Commons Model Context Protocol (MCP) Server

#### [Submission URL](https://developers.googleblog.com/en/datacommonsmcp/) | 17 points | by [meetpateltech](https://news.ycombinator.com/user?id=meetpateltech) | [3 comments](https://news.ycombinator.com/item?id=45362038)

Data Commons launches an MCP server to make its public stats instantly usable by AI agents

- What’s new: A public Model Context Protocol (MCP) server that exposes Data Commons’ interconnected public datasets in a standardized way for AI agents—no custom API wrangling required.
- Why it matters: Anchors agent answers in sourced, real-world statistics to cut LLM hallucinations and speed up building data-rich, agentic apps.
- Capabilities: Handles exploratory (“What health data do you have for Africa?”), analytical (“Compare life expectancy, inequality, GDP growth for BRICS”), and generative (“Report on income vs. diabetes in US counties”) workflows.
- Integrations: Designed to slot into Google Cloud’s Agent Development Kit (ADK) and Gemini CLI, but works with any MCP client. Getting started via a PyPI package, a Colab sample agent, and a GitHub repo.
- Real-world use: ONE Campaign’s ONE Data Agent taps the MCP server to search tens of millions of health financing datapoints in seconds, visualize results, and export clean datasets—e.g., quickly flag countries most reliant on external health funding.
- Big picture: Moves Data Commons from “API to learn” to a first-class agent tool, aiming to make trustworthy public data a default context for AI.

**Summary of Discussion:**  
- **User Optimism on MCP Capabilities:** One user highlights that AI agents leveraging the MCP server can efficiently parse complex queries, retrieve structured data, and reduce reliance on error-prone LLM-generated outputs. They note that current AI models effectively translate natural language into SQL, minimizing manual cross-checking and potential misalignment in results.  
- **Real-World Implementation:** Another user shares a deployed example of the MCP server (linked), demonstrating its practical use for remote data access.  

**Key Themes:**  
1. Confidence in MCP’s ability to streamline data workflows and anchor AI agents in verified statistics.  
2. Emphasis on how natural language-to-SQL transformation reduces LLM “hallucinations” and errors.  
3. Community interest in deploying/running MCP server instances for applications.

