## AI Submissions for Tue May 02 2023 {{ 'date': '2023-05-02T14:21:15.829Z' }}

### Jsonformer: Generate structured output from LLMs

#### [Submission URL](https://github.com/1rgs/jsonformer) | 300 points | by [yunyu](https://news.ycombinator.com/user?id=yunyu) | [78 comments](https://news.ycombinator.com/item?id=35790092)

Jsonformer is a new approach to generating structured JSON from language models, which addresses the challenges and limitations of current approaches. It is a wrapper around HuggingFace models that fills in the fixed tokens during the generation process, and only generates the content tokens. This makes it more efficient and bulletproof than existing approaches that rely on prompt engineering, fine-tuning, and post-processing. Jsonformer currently supports a subset of JSON Schema and comes with features such as bulletproof JSON generation, efficiency, and flexibility. It is built on top of the HuggingFace transformers library, making it compatible with any model that supports the HuggingFace interface. It is released under the MIT License, and you can install it via pip.

The discussion thread raised different issues such as the efficacy of the wrapper, the potential of Cue, and the complexities of long-form language models. Other contributors shared their approaches, ideas, and explorations of tools and libraries such as Recmos Cria, Llama Numpy, Transformers, and Clue. They addressed testing models, constraints and modifications, interoperability, and the role of language modeling in AI development and research.

### Avoiding hallucinations in LLM-powered applications

#### [Submission URL](https://vectara.com/avoiding-hallucinations-in-llm-powered-applications/) | 128 points | by [ofermend](https://news.ycombinator.com/user?id=ofermend) | [107 comments](https://news.ycombinator.com/item?id=35794010)

Hallucinations can occur when an LLM encounters an edge case or a rare scenario for which it wasn't adequately trained. Additionally, the LLM may generate responses by incorporating biases and patterns present in the training data, which can lead to nonsensical or biased answers. It's crucial to address these issues to improve the reliability and trustworthiness of LLM-powered applications. One promising solution to avoid hallucinations is "Grounded Generation," a research project that aims to ground LLMs in the real world by incorporating external knowledge sources. By providing contextual information to LLMs, Grounded Generation can help prevent hallucinations and generate more accurate and reliable responses.

 The discussion in the comments explores various approaches to addressing this issue, including incorporating external knowledge sources through "Grounded Generation" and the difficulty of modeling human-like truth-telling. Issues of biased and nonsensical responses generated by LLMs are also addressed and the importance of training data and testing is emphasized. The feasibility of categorizing and creating training data is also discussed.

### AI-generated beer commercial contains joyful monstrosities, goes viral

#### [Submission URL](https://arstechnica.com/information-technology/2023/05/ai-generated-beer-commercial-contains-joyful-monstrosities-goes-viral/) | 73 points | by [nobody9999](https://news.ycombinator.com/user?id=nobody9999) | [23 comments](https://news.ycombinator.com/item?id=35797258)

A surreal AI-generated beer commercial called "Synthetic Summer" has gone viral. Created by Privateisland.tv, the 30-second video appears to have been made with Runway's new Gen-2 AI model, which can create short video clips based on written prompts. However, the technology is still relatively primitive and requires human effort to generate even acceptable results. In the case of "Synthetic Summer", Privateisland.tv generated the clips, selected the best ones, and added music and sound effects to create the final product. While the video may be impressive in its own right, it shows that generative AI still has a long way to go before it can create autonomously bedazzling memes.

Some commenters argue that the AI-generated content is gibberish, while others note that it offers an interesting and nostalgic marketing angle. The discussion also covers the limitations of AI and how it is different from human intelligence. One commenter suggests that instead of building AI systems to mimic human behavior, they should focus on creating interesting and unique AI-generated content, such as physical character movements, that humans cannot produce. Another commenter mentions that AI-generated videos featuring monsters can be traumatizing, and one commenter suggests that the video appears to verge on the surreal.

### IBM to pause hiring in plan to replace 7,800 jobs with AI

#### [Submission URL](https://finance.yahoo.com/news/ibm-pause-hiring-plans-replace-212747073.html) | 261 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [194 comments](https://news.ycombinator.com/item?id=35784814)

IBM's CEO Arvind Krishna has stated in an interview that the company is expected to pause hiring for certain roles, as those positions could be replaced by artificial intelligence in the coming years. This move could impact roughly 7,800 jobs in the company. However, IBM has yet to officially comment on the matter.

The discussion on Hacker News largely centers around speculations about the impact of AI on employment and IBM's business strategy. Some users view IBM's move to embrace AI as a strategic business opportunity, while others criticize the company's approach of cutting jobs and reducing investment in research. There are also discussions about IBM's reliance on consulting services and concerns about the company's declining revenue in recent years.

### Samsung bans use of A.I. like ChatGPT for employees

#### [Submission URL](https://www.cnbc.com/2023/05/02/samsung-bans-use-of-ai-like-chatgpt-for-staff-after-misuse-of-chatbot.html) | 236 points | by [mrkramer](https://news.ycombinator.com/user?id=mrkramer) | [239 comments](https://news.ycombinator.com/item?id=35787454)

Samsung has temporarily restricted the use of generative AI tools like ChatGPT by its employees after cases were reported of their misuse. Some of the staff at Samsung's division had uploaded sensitive code on the AI chatbot ChatGPT, which is developed by US firm OpenAI, and is trained on vast amounts of data to generate responses to user queries. Samsung has advised its employees to be cautious while using such services outside work and not to enter personal or company-related data in them. The South Korean giant is also exploring ways to safely deploy generative AI to enhance employee productivity and efficiency.

The discussion on the thread highlights that companies with sensitive information need to be especially cautious of AI usage, and must have strong governance policies in place to mitigate risk. The discussion also touches upon similar issues relating to the use of cloud services and web-based tools like Google Docs and Office365.

### Mojo â€“ a new programming language for AI developers

#### [Submission URL](https://www.modular.com/mojo) | 526 points | by [lairv](https://news.ycombinator.com/user?id=lairv) | [212 comments](https://news.ycombinator.com/item?id=35790367)

Mojo, a new programming language that combines the usability of Python with the performance of C, has been created for AI developers. It allows users to program low-level AI hardware with no need for C++ or CUDA. Mojo offers features such as progressive types, ownership and borrow checker, and portable parametric algorithms, which reduces boilerplate. It also offers zero-cost abstractions, parallel heterogenous runtime, and auto-tuning. Users can unleash the full power of their hardware, including multiple cores, vector units, and exotic accelerator units with the world's most advanced compiler, and they can achieve performance on par with C++ and CUDA without the complexity. Mojo is interoperable with the Python ecosystem, seamlessly intermixing arbitrary libraries with custom code. Users can extend their models with pre and post-processing operations or replace operations with custom ones with ease. Mojo is available to try in a Jupyter note-based playground.

The discussion in the comments covers various topics, including comparisons with languages such as Julia, Python's strengths and weaknesses, garbage collection, and the suitability of different languages for different purposes. Overall, the response to the submission is mostly positive, with many users praising Mojo's innovative features and potential for AI development.

### Make your Python functions return something meaningful, typed, and safe

#### [Submission URL](https://returns.readthedocs.io/en/latest/index.html) | 45 points | by [dr_kiszonka](https://news.ycombinator.com/user?id=dr_kiszonka) | [63 comments](https://news.ycombinator.com/item?id=35792949)

If you want to make your Python functions more functional, declarative, and readable, check out Returns. This library provides primitives to write declarative business logic, such as Maybe and RequiresContext containers, which get rid of None and let you use typed functional dependency injection. Returns is fully typed with annotations and checked with mypy, and adds emulated Higher Kinded Types support as well as type-safe interfaces to create your own data types with enforced laws. The library also has a bunch of helpers for better composition, and is Pythonic and pleasant to write and read. You can install Returns with pip and configure mypy to use it, and then start using its containers right away.

Some users in the comments discuss the tradeoff of using static typing in Python, with some arguing that it improves safety and readability, and others stating that it can make the code harder to read and write. Some users suggest that Python should not try to be like Haskell and instead focus on being a great language in its own right. Another post discusses Python's ability to handle recursion and functional programming concepts, even if it is not a purely functional language like Haskell.

### Dark Matter Developers: The Unseen 99% (2012)

#### [Submission URL](https://www.hanselman.com/blog/dark-matter-developers-the-unseen-99) | 133 points | by [BiteCode_dev](https://news.ycombinator.com/user?id=BiteCode_dev) | [121 comments](https://news.ycombinator.com/item?id=35784157)

In a 2012 blog post, Scott Hanselman coined the term "Dark Matter Developers" to refer to the unseen 99% of developers who don't read or write blogs, attend user groups or large conferences, and aren't active on social media. These developers may be using well-known, mature technologies to get their work done, and they value productivity over keeping up with the latest trends. Hanselman reminds readers of their importance, as they are quietly using technology to solve business problems and produce results. He advocates for a balance between the loud-online-pushing-things-forward 1% and the patient and focused Dark Matter Developers.

The discussion on Hacker News included comments from developers who agreed with the importance of these developers and others who felt that being publicly active in the tech community was necessary to keep up with the newest technologies and not be left behind. There was also discussion about the challenges of discussing current work under NDA restrictions and the tendency for engineers to fall victim to hype and neglect the importance of staying up to date with current technology trends.

### MLCopilot: Human Expertise Meets Machine Intelligence for Efficient ML Solutions

#### [Submission URL](https://arxiv.org/abs/2304.14979) | 58 points | by [mercat](https://news.ycombinator.com/user?id=mercat) | [11 comments](https://news.ycombinator.com/item?id=35785573)

A new paper titled "MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks" has been released, outlining a new framework that aims to bridge the gap between machine intelligence and human knowledge. The framework leverages state-of-the-art Large Language Models (LLMs) to develop machine learning solutions for novel tasks, making it easier and less time-consuming for developers. The LLMs are designed to comprehend structured inputs and perform thorough reasoning to deliver promising results for new tasks. This framework could potentially make machine learning more accessible, efficient, and competitive.

The discussion on the submission includes comments about the framework's potential applications and criticisms of using Large Language Models (LLMs) for machine learning solutions. Some users discuss their experience working with ML and the importance of math skills in developing solutions with LLMs. The discussion also includes a debate on the price of accessing the framework through an API and concerns about the cost and effectiveness of LLMs compared to other machine learning models. Some users argue that LLM based solutions may not perform as well as human models and that there is a need to understand the LLM system to trust its outputs. One commenter mentions a possible solution for understanding the LLM system is to study its structure, while others express skepticism about LLMs being able to fully understand and replicate human knowledge.

### CraftAI: GPT-Powered Admin Generator

#### [Submission URL](https://ai.craftable.pro/#) | 15 points | by [palypster](https://news.ycombinator.com/user?id=palypster) | [7 comments](https://news.ycombinator.com/item?id=35785806)

Crafted with the help of GPT-4, CraftAI is an admin panel generator designed to create stunning back-office systems without any coding. All you need to do is enter your prompt, verify your email, and let the team prepare your environment for you. Once completed, CraftAI will send you a unique link to your isolated environment, and you're ready to go! This admin panel generator is built with Craftable PRO, a Laravel admin generator, which allows you to manage data entities and their attributes while defining and creating relationships. With CraftAI, you can expect to create beautiful admin panels in just five minutes!

The discussion in the comments is mainly focused on the technical aspects of CraftAI and its usefulness in generating admin panels without any coding. There is a discussion on using prompts and placeholders, and how this approach can make it easier to create a front-end screen. Users are also discussing the possibility of generating custom domain panels using a single line of code. There is also some discussion about machine learning and how it can be used to improve the performance of CraftAI. Overall, users seem interested in the potential of CraftAI to improve the workflow for creating admin panels.

### Sal Khan: The amazing AI super tutor for students and teachers [video]

#### [Submission URL](https://www.ted.com/talks/sal_khan_the_amazing_ai_super_tutor_for_students_and_teachers/c) | 42 points | by [bilsbie](https://news.ycombinator.com/user?id=bilsbie) | [19 comments](https://news.ycombinator.com/item?id=35791433)

Sal Khan, founder and CEO of Khan Academy, gave a TED talk on the potential of artificial intelligence (AI) to revolutionize education. He envisions a future where every student has a personal AI tutor and every teacher has an AI teaching assistant, fostering a collaborative learning environment between humans and machines. Khan also showcased the latest features of Khanmigo, their educational chatbot, which utilizes AI to provide personalized learning experiences. Khan Academy has developed a unique ethical framework to ensure responsible AI development, and their new "AI for Education" course provides resources for students and teachers to leverage the power of AI.

The comments cover a range of opinions on the use of AI in education, including concerns about job displacement, the role of teachers, and ethical considerations in AI development. Some commenters recommend individualized learning and mastery-based teaching, while others advocate for a village or community-based approach to education. The discussion also includes comparisons of teacher pay and job security to other professions and criticism of the current education system.

### AI adoption in US hospitals is a hot mess, study reveals

#### [Submission URL](https://arstechnica.com/science/2023/05/ais-chaotic-rollout-in-big-us-hospitals-detailed-in-anonymous-quotes/) | 15 points | by [aheck](https://news.ycombinator.com/user?id=aheck) | [5 comments](https://news.ycombinator.com/item?id=35795080)

Health care systems have struggled with inefficient and unsuccessful AI attempts for years, according to a study by Duke University. The study chronicles implementations of AI tools in 11 health care organisations including Duke Health, Mayo Clinic and Kaiser Permanente. The authors recommend a practical eight-step framework for health systems looking to integrate new AI tools into their workflows. Last week's JAMA Internal Medicine study, which found an AI chatbot outperformed physicians in providing empathetic and high-quality responses to medical questions on Reddit threads, could help reduce burnout, free up time and resources and help improve care for patients less likely to visit doctors in person, the authors said.

The commenters on this submission discuss the reliability and potential usefulness of AI in healthcare. One person expresses skepticism about the AI chatbot study that outperformed physicians in providing empathetic responses, while others mention the importance of doctors and hospital staff having a basic understanding of technology. Another commenter suggests that hospitals may be motivated to replace talent with AI tools for bottom-line benefit, while another points out the challenges that healthcare systems face with implementing any new technology. Overall, the discussion highlights the need for cautious and strategic adoption of AI in healthcare.
