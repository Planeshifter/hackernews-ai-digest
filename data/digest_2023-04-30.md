## AI Submissions for Sun Apr 30 2023 {{ 'date': '2023-04-30T18:13:17.272Z' }}

### Necrobrands – Digital End-Stage Capitalism

### Show HN: EVA – AI-Relational Database System

#### [Submission URL](https://github.com/georgia-tech-db/eva) | 218 points | by [jarulraj](https://news.ycombinator.com/user?id=jarulraj) | [33 comments](https://news.ycombinator.com/item?id=35764355)

Georgia Tech researchers have developed EVA, an AI-relational database system that combines SQL and deep learning. EVA simplifies the process of building faster AI-powered applications and offers support for structured and unstructured data using a range of pre-built machine learning models. EVA also includes optimizations such as function caching and cost-based predicate reordering, which can boost AI pipeline speeds by 10 to 100 times. The fully Python-based system is available for download via pip and is licensed under the Apache license.

The discussion includes comments about EVA's support for NLP models, database integrations, and local GPUs and remote GPU servers. There is also a discussion about a potential application of EVA in combating prompt injection attacks on SQL databases. Additionally, EVA offers support for weighted similarity searches and can wrap PyTorch models as UDFs.

### AI / ML / LLM / Transformer Models Timeline

#### [Submission URL](https://ai.v-gar.de/ml/transformer/timeline/) | 90 points | by [vemgar](https://news.ycombinator.com/user?id=vemgar) | [17 comments](https://news.ycombinator.com/item?id=35766022)

Viktor Garske has compiled a timeline and list of papers on Large Language Models and Transformer Models, with a focus on recent developments. The list includes models such as GPT-3, DALLE, and Pythia, as well as methods and analyses related to these models. The list is actively updated and organized by publication date, with clickable links to the papers. Additionally, Garske has included a curated list of Large Language Models and Transformer models based on causal models, including models like Alpaca, BERT, and CLIP.

The comments discuss various related topics such as keeping up with developments, best practices for selecting models, benchmarks, the importance of understanding causal models, recent breakthroughs in AI, and custom-built systems. One comment points out a related Transformer Models Introduction Catalog, and another discusses Hallucination as a known issue in AI.

### Are emergent abilities of large language models a mirage?

#### [Submission URL](https://arxiv.org/abs/2304.15004) | 115 points | by [chewxy](https://news.ycombinator.com/user?id=chewxy) | [79 comments](https://news.ycombinator.com/item?id=35768824)

A new paper titled "Are Emergent Abilities of Large Language Models a Mirage?" by Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo, challenges recent claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. The authors suggest that existing claims of emergent abilities are creations of the researcher's analyses, not fundamental changes in model behavior on specific tasks with scale. They present their explanation in a simple mathematical model and test it in three complementary ways, finding strong evidence that emergent abilities may not be a fundamental property of scaling AI models.

The discussion in the comments is centered around the validity and limitations of metrics to measure emergent abilities and the importance of human perception in understanding complex systems. Some commenters express doubts about the validity of the claims made about emergent abilities and the usefulness of metrics in measuring them. Others argue that emergent abilities are real, but the limitations of our metric systems may make them hard to understand or quantify.

### Lego Googol Machine

#### [Submission URL](https://brickexperimentchannel.wordpress.com/2023/04/29/lego-googol-machine/) | 97 points | by [galfarragem](https://news.ycombinator.com/user?id=galfarragem) | [21 comments](https://news.ycombinator.com/item?id=35761457)

This impressive machine built entirely out of Lego parts visualizes just how big a googol is. With a gear ratio of approximately googol:1, the machine features 186 Lego gears organized into a series of gear reductions. The gear ratio, which is almost exactly the size of a googol, results in exponential growth with each additional gear pair increasing the total gear ratio. While the last gear in the machine holds a Lego minifig statue, it will rotate incredibly slowly due to physical limits in each gear and supporting structure, but the machine is designed to continue running forever.

The discussion in the comments includes topics such as the physics behind the machine, the transfer of energy, relativistic effects, and the potential for mechanical computers to solve a googol-sized problem. Some also mentioned similar machines they had seen before and the issues of waste and durability of the plastic LEGO pieces.

### Show HN: I built a database GUI with ChatGPT integration

#### [Submission URL](https://www.dbpilot.io/) | 83 points | by [Dennizz](https://news.ycombinator.com/user?id=Dennizz) | [56 comments](https://news.ycombinator.com/item?id=35761979)

DB Pilot AI is a database GUI client that's enhanced by artificial intelligence (AI). Its AI assistant, powered by GPT-3.5, can help users write SQL queries, convert code to SQL, explain queries, and more. The embedded DuckDB instance acts as a local hub for users to easily run SQL queries and store query results from any database locally for later reference. The GUI also allows users to connect with various file formats, including CSV, JSON, and Parquet files, either stored locally or remotely. The current version supports PostgreSQL, with plans to add support for more databases. Users can download the app for a 5-day free trial before purchasing a license.

Some users report issues with the product not working with certain databases, and the creator promises to look into the issue. The AI's language model is GPT-3.5, not BERT. Overall, the product receives positive feedback, and the creator takes note of the feedback and suggests plans for future development.

### MLC-LLM: GPT/Llama on consumer-class GPUs and phones

#### [Submission URL](https://github.com/mlc-ai/mlc-llm) | 289 points | by [junrushao1994](https://news.ycombinator.com/user?id=junrushao1994) | [105 comments](https://news.ycombinator.com/item?id=35763483)

MLC LLM is a new solution that utilizes machine learning compilation (MLC) to enable the development, optimization, and deployment of AI models for inference across a range of devices. The solution offers a repeatable, systematic, and customizable workflow that empowers developers and AI system researchers to implement models and optimizations in a productivity-focused, Python-first approach. The cornerstones of the solution include Tokenizers from HuggingFace and Google, as well as open-source LLMs like Llama, Vicuna, and Dolly. With MLC LLM, everything runs locally with no server support and accelerated with local GPUs on your phone and laptops, enabling everyone to develop, optimize, and deploy AI models natively on everyone's devices.

The comments discussed various technical aspects of the solution, including its potential to accelerate AI model development and concerns about device performance and privacy. Some users explored the idea of using LLMs for generating text, while others focused on the technical challenges involved in developing and optimizing AI models.

### Speed Is All You Need: On-Device Acceleration of Large Diffusion Models

#### [Submission URL](https://arxiv.org/abs/2304.11267) | 56 points | by [Pelayu](https://news.ycombinator.com/user?id=Pelayu) | [8 comments](https://news.ycombinator.com/item?id=35766741)

A group of researchers have developed a series of implementation optimizations for on-device deployment of large diffusion models, which have gained attention for their ability to generate photorealistic images and support various tasks. The optimizations achieve the fastest reported inference latency to-date on GPU-equipped mobile devices. The benefits of on-device deployment include lower server costs, offline functionality, and improved user privacy. The enhancements to these models broaden the applicability of generative AI and improve the overall user experience across a wide range of devices.

One user noted the use of OpenCL kernels for optimizations on CPUs, while another commented on the ability for on-device deployment to improve user privacy and reduce server costs. There was also a discussion on the benefits and drawbacks of different machine learning models and the limitations of current technology. Finally, there were some off-topic comments on cryptocurrency and Elon Musk.
