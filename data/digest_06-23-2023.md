## AI Submissions for Fri Jun 23 2023 {{ 'date': '2023-06-23T17:12:02.524Z' }}

### Open source licenses need to leave the 1980s and evolve to deal with AI

#### [Submission URL](https://www.theregister.com/2023/06/23/open_source_licenses_ai/) | 79 points | by [gumby](https://news.ycombinator.com/user?id=gumby) | [103 comments](https://news.ycombinator.com/item?id=36444854)

Open source licenses and free software have yet to adequately evolve to handle AI models, which raise grayer legal issues than code-centric software. With programming datasets so reliant upon open source and free software code, Stefano Maffulli, executive director at Open Source Initiative, among other tech leaders, is looking into ways to align AI and open source licenses for more clarity. Concerns over copyright infringement and proprietary licenses mean that tech companies producing AI-generated code will ultimately regard them as private IP, just as software code was considered the property of the software company in previous years. Other discussions pertained to how to license datasets involved with AI models, despite how they don't fit under traditional copyright models, and the difficulties found with open sourcing medical data versus commercial LLM datasets, which are typically black boxes. Several organizations are collaborating on defining a common understanding of open source AI principles that they intend to use to lobby legislative bodies. In the ensuing discussion, users debated the legal issues regarding AI models, such as whether AI-generated weights should be considered copyrightable, and whether there is a clear precedent in copyright law for AI. Additionally, the discussion highlighted the complexities of licensing AI and how some view AI-generated data as non-copyrightable.

### Millions of GitHub repos likely vulnerable to RepoJacking, researchers say

#### [Submission URL](https://www.bleepingcomputer.com/news/security/millions-of-github-repos-likely-vulnerable-to-repojacking-researchers-say/) | 124 points | by [pyeri](https://news.ycombinator.com/user?id=pyeri) | [47 comments](https://news.ycombinator.com/item?id=36452322)

AquaSec's security team, Nautilus, has issued a warning that millions of repositories on GitHub may be vulnerable to dependency repository hijacking, or RepoJacking. The attack involves a malicious actor registering a username under the name of an older repository, used by an organisation that has since changed their name or had a change in ownership. Any project using the dependency of the attacked project will subsequently fetch dependencies and code from the attacker-controlled repository, which could contain malware. AquaSec scanned major organisations and found exploitable cases in repositories managed by Google and Lyft, in which vulnerable dependencies pointed to rogue repositories.

The discussion includes various comments, such as the difficulty of implementing global namespaces, the use of SSL certificates, and the dangers of compromised domain names. Furthermore, there are some comments about the importance of maintaining package lockfiles and regularly auditing packages for vulnerabilities in package managers like npm. The discussion also touches on GitHub integration systems and the differences between package managers such as npm and Python. Finally, there is a comment about potential alternatives to GitHub.

### Twilight of the programmers?

#### [Submission URL](https://danielbmarkham.com/twilight-of-the-programmers/) | 82 points | by [signa11](https://news.ycombinator.com/user?id=signa11) | [69 comments](https://news.ycombinator.com/item?id=36445513)

As a programmer, there is something very important that we are losing in today's world, according to an article on Hacker News. The author believes that programming should be telling us more than we are telling it, and that we've got it all backwards. Unlike other professions, when a programmer encounters a situation where conflicting meanings happen, each of which is correct, it is a much more profound piece of information to provide the client. The article ends with a quote from a friend: "I think some of the best programs were essays, in the sense that the authors didn't know when they started exactly what they were trying to write."

The submission on Hacker News discusses how programming should be telling us more than we are telling it. The discussion that follows explores the limitations of the current programming system, especially in the context of part-time employees, and the importance of abstractions. Some commenters argue that abstractions are broken, but others point out that they can be useful in creating a better understanding of complex concepts. Additionally, some commenters assert that different professionals have different approaches to their work and that there is no universal logical world. Others suggest that the key to solving business problems is dependent on the depth of knowledge and intelligence of the business partners and that there should be more personal learning opportunities. Overall, the conversation touches on the role of programming in the real world and the complexities it faces.

### From word models to world models

#### [Submission URL](https://arxiv.org/abs/2306.12672) | 97 points | by [dimmuborgir](https://news.ycombinator.com/user?id=dimmuborgir) | [100 comments](https://news.ycombinator.com/item?id=36445197)

A group of researchers has proposed a framework for language-informed thinking that combines neural models of language with probabilistic models for rational inference. The framework, called "rational meaning construction", views linguistic meaning as a context-sensitive mapping from natural language into a "probabilistic language of thought" (PLoT), which is a general-purpose symbolic substrate for probabilistic, generative world modeling. The paper illustrates the framework in action through examples covering four core domains from cognitive science and extends the framework to integrate cognitively-motivated symbolic modules to provide a unified, commonsense thinking interface from language.

A group of researchers have suggested a framework for language-informed thinking that combines neural models of language with probabilistic models for rational inference. However, several users are skeptical about the approach, with one argument being that the models currently lack high-quality training data and cannot answer complex questions. Some users believe that the language models' ability to understand the world in a limited symbolic representation is not fully effective for intelligence. Still, others contend that natural language processing is a vital step towards achieving artificial general intelligence. Some users suggest that the research illustrates the limitations of current large language models, while others argue that such models can drink and perform very well. There are also discussions about the capacity of humans to comprehend complex thought and whether machines can do likewise.

### What is a transformer model? (2022)

#### [Submission URL](https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/) | 288 points | by [Anon84](https://news.ycombinator.com/user?id=Anon84) | [51 comments](https://news.ycombinator.com/item?id=36449788)

Transformers are driving a wave of advances in machine learning, earning them the nickname "transformer AI." These neural networks learn context and meaning by tracking relationships in sequential data, using a set of mathematical techniques called attention or self-attention to detect subtle influences among distant data elements. Transformers are already being used in a host of applications, from preventing fraud to improving healthcare, and can analyze sequential text, image, or video data. Stanford researchers call transformers "foundation models", as they see them driving a paradigm shift in AI and replacing the most popular types of deep learning models from just five years ago.

In the comments, users recommend resources for learning about transformers from building them from scratch to implementing them in a practical application, as well as discussing the capabilities and limitations of transformers compared to other models like CNNs and RNNs. Some users express concern about the potential negative impacts of transformers on society and the need for responsible research practices.

### AudioPaLM: A Large Language Model That Can Speak and Listen

#### [Submission URL](https://google-research.github.io/seanet/audiopalm/examples/) | 111 points | by [ml_basics](https://news.ycombinator.com/user?id=ml_basics) | [32 comments](https://news.ycombinator.com/item?id=36443676)

Google has introduced AudioPaLM, a new large language model for speech understanding and generation that combines text-based and speech-based language models. It uses a unified multimodal architecture that can process and generate text and speech, with applications including speech recognition and speech-to-speech translation. AudioPaLM was able to outperform existing systems for speech translation tasks and also demonstrated zero-shot speech-to-text translation for many languages not seen in training. The model significantly improved speech processing by leveraging the larger quantity of text training data used in pretraining. AudioPaLM inherits the capability to preserve paralinguistic information such as speaker identity and intonation from AudioLM and linguistic knowledge present only in text large language models such as PaLM-2.

The discussion on the submission included comments about the accuracy of the translation and the potential for spam calls to be intercepted with AudioPaLM. There were also discussions about the benefits of bilingual models for literal translations and how LLMs can represent different languages. Some commenters expressed skepticism towards the model's capabilities and the possibility of spying.

### Show HN: A package manager for AI plugins

#### [Submission URL](https://openpm.ai/) | 81 points | by [maccaw](https://news.ycombinator.com/user?id=maccaw) | [17 comments](https://news.ycombinator.com/item?id=36447683)

OpenPM is a package manager for AI plugins that simplifies the integration of various APIs. It offers a seamless process for exploring, publishing, and integrating APIs into AI platforms. With OpenPM, developers can easily discover and use new AI plugins, while API providers can publish their plugins to the registry and make them available to the community. Its API search function streamlines the integration process, removing the need for manual coding to connect various APIs. Overall, OpenPM represents a handy tool for streamlining AI development and integration processes.

The discussion around the OpenPM submission on Hacker News includes several topics related to AI development and integration. One commenter raises concerns about security and the supply chain attacks that can occur. Others discuss the packages available, including Cloudflare's Worker building AI plugins and WorkGPT, a framework for working with GPT functions. There are also discussions about API search and preview functionality, the adoption of AI plugins, and the role of OpenPM in streamlining AI development. Some comments also touch on the confusion between OpenPM and other similar tools like OpenAPI and OpenAI. Another contributor compares alternative platforms and suggests that OpenAI is leading the industry with its commitment to regulation and support for open-source alternatives.


