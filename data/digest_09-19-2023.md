## AI Submissions for Tue Sep 19 2023 {{ 'date': '2023-09-19T17:10:35.468Z' }}

### A closer look at BookCorpus, a key dataset in machine learning

#### [Submission URL](https://towardsdatascience.com/dirty-secrets-of-bookcorpus-a-key-dataset-in-machine-learning-6ee2927e8650) | 60 points | by [Kaibeezy](https://news.ycombinator.com/user?id=Kaibeezy) | [18 comments](https://news.ycombinator.com/item?id=37568847)

A working paper by researchers Nicholas Vincent and Jack Bandy has shed light on the "dirty secrets" of BookCorpus, a dataset used in training large language models such as Google's BERT, OpenAI's GPT, and Amazon's Bort. The researchers found several major concerns, including copyright violations, duplicate books, skewed genre representation, and potentially problematic content. They discovered that BookCorpus included books that explicitly stated they couldn't be redistributed, as well as books that now cost money on Smashwords, the dataset's source. Additionally, thousands of books in BookCorpus were duplicates, and the dataset had skewed genre representation, favoring romance and vampire genres. There were also concerns about potentially problematic content and potentially skewed religious representation. Further analysis and attention are needed to address these issues and ensure fairness and bias mitigation in machine learning datasets.

The discussion on Hacker News revolves around several points related to the submission. 

- One user points out the necessity of obtaining permission and respecting copyright when using datasets like BookCorpus in machine learning research. They suggest that organizations and research groups should be more mindful of using publicly available datasets and relying on third-party data collection.

- Another user mentions that the value of certain books in the dataset, such as romance and fantasy novels, can be traced back to scraping sources like Wikipedia and other public domain works.

- A user provides a link to a related research paper called "The Pile," which contains a larger dataset than BookCorpus and includes both book and non-book content. They emphasize the high quality of books as a source of long-form content for language modeling tasks.

- An interesting discussion arises around copyright violations and the need to respect the rights of creators. Some users argue that copyright lasts forever and protects the interests of copyright owners, while others believe that the current copyright systems primarily benefit corporations and fail to benefit living artists.

- One user demonstrates that large language models like GPT are capable of accurately quoting copyrighted texts, providing an example from the Declaration of Independence.

- A discussion on the alignment of OpenAI's papers and their acknowledgment of the SmashWords books in BookCorpus takes place, suggesting that researchers tend to prefer suppressing certain findings that may contradict their own.

- Another user mentions that the concerns raised about BookCorpus have been highlighted by researchers at machine learning conferences like NeurIPS, and they suggest that people should acknowledge these issues instead of suppressing them.

- A user shares their experience as an AI developer and expresses their puzzlement over the lack of books or detailed discussions on the topic, implying that the AI community might not be paying enough attention to the issue.

- Finally, a user provides a link to a research paper called "Addressing Documentation Debt in Machine Learning Research: A Retrospective Datasheet for BookCorpus" as a helpful resource for further exploration.

Overall, the discussion covers a range of topics, including copyright violations, dataset quality, acknowledgment of sources, biases in machine learning datasets, and the need for better documentation in machine learning research.

### Show HN: Symphony – Use GPT-4 to call functions in sequence

#### [Submission URL](https://www.symphony.run/) | 83 points | by [jrmyphlmn](https://news.ycombinator.com/user?id=jrmyphlmn) | [29 comments](https://news.ycombinator.com/item?id=37571732)

Today's top story on Hacker News is about an exciting new development in the world of AI. Researchers have successfully utilized GPT-4, a powerful language model, to call functions in sequence. This innovation has significant potential for automating complex tasks and processes. 

In this specific example, the functions being called are related to time, light, and weather. There are functions to retrieve the current time, get the light conditions, set the lights, retrieve weather data, and convert temperature from Kelvin to Celsius. 

Now, to answer your query about changing the dining lights to match the weather and time in Bahrain, it is certainly possible to achieve that using this framework. By appropriately integrating the functions mentioned above, one can create a program that retrieves the current time, fetches the weather data for Bahrain, converts the temperature to Celsius, and sets the dining lights accordingly. This kind of automation can bring a new level of convenience and ambiance to your dining experience.

The discussion on this submission covers several topics related to the use of GPT-4 and the potential limitations of AI systems:

1. The first commenter expresses enthusiasm for the concept of directed function calling using models like GPT-4, while acknowledging the need to narrow the scope to domain-specific functions.
2. Another commenter suggests the possibility of extracting functions and defining interfaces for better integration with UI components.
3. There is a brief discussion about whether GPT-4 should be called non-trivially or not.
4. One commenter mentions the PHP framework Symphony, leading to a clarification that PHP is spelled Symfony.
5. The topic shifts briefly to TypeChat and the idea of defining functions in TypeScript, leveraging the OpenAI function calling.
6. A user mentions Delphi and its AI assistant, while another user clarifies the compatibility between Symphony and GPT-4.
7. The concept of expert systems and their limitations in terms of determinism is brought up.
8. The limitations of function availability within GPT-4 and the need to handle conversations and context are discussed.
9. The issue of passing descriptions to functions and wrapping them with a wrapper function is raised.
10. A user suggests considering the cost and power implications of using GPT-4 for this purpose.
11. There is a brief discussion about the usage of the ChatGPT API and the limitations it imposes.
12. A few comments express confusion or frustration with the limitations of GPT-4's capabilities.
13. There is a mention of the LangChain project.
14. One comment is marked as "true" without any further explanation.

Overall, the discussion touches on the potential of GPT-4 for directed function calling, integration with different programming languages and frameworks, limitations of expert systems, and the challenges of working with AI models in real-world applications.

### Graph Neural Networks use graphs when they shouldn't

#### [Submission URL](https://arxiv.org/abs/2309.04332) | 126 points | by [Pseudomanifold](https://news.ycombinator.com/user?id=Pseudomanifold) | [20 comments](https://news.ycombinator.com/item?id=37571535)

Graph Neural Networks (GNNs) have become a popular approach for learning on graph data in various domains. However, a new paper titled "Graph Neural Networks Use Graphs When They Shouldn't" by Maya Bechler-Speicher and her colleagues challenges the assumption that GNNs always make accurate predictions based on graph structure. The researchers show that GNNs tend to overfit the graph structure, even when it is non-informative for the predictive task. They provide a theoretical explanation for this phenomenon and propose a graph-editing method to mitigate the overfitting. The paper concludes with empirical evidence that this method improves the accuracy of GNNs across multiple benchmarks. This research has implications for the use of GNNs in fields such as social networks, molecular biology, and medicine.

The discussion on the submission revolves around various aspects of Graph Neural Networks (GNNs) and their use in learning on graph data. Here are some key points raised by the commenters:

- One commenter mentions that GNNs tend to overfit the graph structure, even when it is non-informative for the predictive task at hand. They provide links to the research paper challenging this assumption.
- Another commenter suggests that attention layers and nested graph convolution layers can help GNNs learn graph structures effectively.
- There is a discussion on the use of graph editing and graph representation in mitigating overfitting in GNNs.
- Some commenters share their experiences with working on GNNs and highlight the importance of studying the behavior and dynamics of GNNs.
- The limitations and challenges of using GNNs in practical applications are also mentioned, such as computational complexity and the need for regularization techniques.
- It is pointed out that GNNs can have a problem of overfitting due to imbalanced class distribution and dependence on specific graph interactions.
- Several papers and research works related to GNNs are shared, covering topics like message passing, algorithmic reasoning, diffusion, sparsity, training tricks, expressive power, and over-squashing.

Overall, the discussion highlights the potential issues and solutions related to the use of GNNs in various domains.

### Show HN: Spirals – Generate beautiful AI spiral art with one click

#### [Submission URL](https://spirals.vercel.app/) | 21 points | by [steventey](https://news.ycombinator.com/user?id=steventey) | [8 comments](https://news.ycombinator.com/item?id=37577589)

Introducing Spirals: Generate Stunning AI Spiral Art with Ease!

Enter a mesmerizing world of creativity with Spirals, a groundbreaking project by the talented Steven Tey. This artistic marvel brings together the power of Artificial Intelligence (AI), Vercel, and Replicate to offer you a seamless experience in generating stunning spiral art effortlessly.

With just one click, Spirals unleashes a wave of visually captivating artwork that will leave you awestruck. The AI algorithm at the heart of Spirals works its magic, effortlessly transforming simple input into intricate and awe-inspiring spiral designs.

Powered by Vercel, Spirals offers a smooth and enjoyable user experience, making the creation process a breeze. Vercel's robust infrastructure ensures lightning-fast response times and seamless functionality, ensuring you can effortlessly explore countless possibilities without any technical hiccups.

Furthermore, Spirals leverages the power of Replicate, elevating your creative journey to new heights. Replicate supercharges the AI capabilities within Spirals, allowing it to continuously evolve its design generation abilities. With each use, Spirals becomes smarter, keeping you hooked with its ever-improving creations.

Whether you're an artist seeking inspiration, a designer yearning for new patterns, or simply someone who appreciates the beauty of art, Spirals has something to offer to everyone. Get ready to dive into an endless world of mesmerizing spiral art, brought to life by the fusion of AI, Vercel, and Replicate.

Don't miss out on this remarkable project. Embrace the magic of Spirals as it takes you on a mesmerizing journey through the world of spiral art, one click at a time.

The discussion on this submission involves several comments. 

- User "Minor49er" provides a series of prompts they have tried with the Spirals application, sharing links to the generated spiral art.
- User "xnx" comments that the project seems to be driven by a slight variation of a viral post on Reddit.
- User "crs" describes their experience with the AI command, mentioning generating spiral designs resembling checkerboards.
- User "rgzzn" shares that they listened to an episode of a podcast called "gtkpng" related to the topic.
- User "yldcrv" contributes a comment about the cost of the project.
- User "ywnxyz" replies to "yldcrv" saying that the project works with Vercel, implying that Vercel may be paying for it.
- User "yldcrv" raises concerns about the pricing of Replicate.
- User "quickthrower2" suggests that Vercel possibly pays for the project.

### The physical process that powers a new type of generative AI

#### [Submission URL](https://www.quantamagazine.org/new-physics-inspired-generative-ai-exceeds-expectations-20230919/) | 96 points | by [digital55](https://news.ycombinator.com/user?id=digital55) | [14 comments](https://news.ycombinator.com/item?id=37570743)

Physicists at MIT have introduced a new method of generative AI called the Poisson flow generative model (PFGM). Rather than using black box algorithms like traditional neural networks, PFGM is based on the principles of diffusion and the distribution of charged particles. PFGM represents data with charged particles that create an electric field, and the model learns to estimate that electric field through the training process. This allows PFGM to generate high-quality images, similar to diffusion-based models, but at a much faster speed. The use of physical processes in AI models could open the door to harnessing other physical phenomena to improve neural networks.

The discussion on Hacker News surrounding the submission about the Poisson flow generative model (PFGM) involves various perspectives. 

One commenter points out that the concept of Boltzmann Machines is nothing new, and the use of black box algorithms in neural networks has been replaced by diffusion-based models. Another commenter adds that implementing Poisson flow generative models could be challenging due to memory constraints, but a breakthrough in GPU RAM manufacturing could potentially solve this issue. The discussion then diverges into a debate about the reliance on AI SaaS subscription services and the associated costs.

Another thread of the discussion touches on the idea that physical processes can be effectively modeled in neural networks, opening up possibilities for incorporating other physical phenomena. However, a commenter from the World Economic Forum mentions the challenges in accurately predicting service waiting times.

Some comments express interest in the differences between Poisson flow generative models and traditional diffusion models, while others discuss the potential benefits of utilizing physical processes in network modeling.

One commenter wonders why the article does not provide direct comparisons between Poisson flow generative models and other diffusion models, while another commenter provides a link to relevant research papers.

There is also appreciation for the elegance of incorporating principles from physics into AI models. However, someone points out that counting on quantum computing to solve such problems might be wishful thinking.

Lastly, there is a discussion about how swapping decoding techniques in NLP frequently leads to generating novelty in text generation tasks, but traditional methods still have their merits. The debate focuses on the trade-off between control and novelty in generating text.

### A Hands-On Introduction to Machine Learning

#### [Submission URL](https://www.cambridge.org/highereducation/books/a-hands-on-introduction-to-machine-learning/3E57313A963BF7AF5C6330EB88ADAB2E) | 56 points | by [teleforce](https://news.ycombinator.com/user?id=teleforce) | [12 comments](https://news.ycombinator.com/item?id=37575137)

Title: "A Hands-On Introduction to Machine Learning: A Comprehensive Guide for Beginners"

Subtitle: Learn machine learning step-by-step with practical examples and real-world applications

Introduction:
Machine learning is one of the most rapidly growing fields in technology today, with applications ranging from autonomous vehicles to personalized recommendations. If you've been wanting to dive into the world of machine learning but don't know where to start, look no further than "A Hands-On Introduction to Machine Learning." This comprehensive textbook, written by Dr. Chirag Shah from the University of Washington, is designed to teach machine learning in a way that is easy to understand and apply, even for those with no prior programming experience.

Summary: 
"A Hands-On Introduction to Machine Learning" covers all the essential topics needed to gain a working knowledge of machine learning. Through a series of real-world examples, practical activities, and industry insights, Dr. Shah takes readers on a journey from the basics to more advanced concepts. The book begins with an introduction to machine learning and its applications, followed by an exploration of supervised and unsupervised learning techniques. Readers will learn how to build and train various types of machine learning models, including neural networks, and gain an understanding of reinforcement learning.

In addition to teaching the technical aspects of machine learning, Dr. Shah also addresses the ethical considerations and challenges facing the industry. This holistic approach prepares readers for the real-world issues they may encounter in their future careers.

Key Features:
1. Assumes no prior exposure to programming or machine learning: This makes it ideal for non-Computer Science majors and professionals who are new to the field.

2. Hands-on approach: The book includes practical activities, allowing readers to build a skillset while they learn. This helps reinforce concepts and enhances understanding.

3. Industry insights: Dr. Shah provides real-world context throughout the book, giving readers a glimpse into the applications and challenges of machine learning in various industries.

Conclusion: 
Whether you're a student or professional looking to learn machine learning, "A Hands-On Introduction to Machine Learning" is a valuable resource. Dr. Shah's clear and concise explanations, combined with hands-on activities and real-world examples, make this textbook an engaging and practical guide for beginners. By the end of the book, readers will have acquired the knowledge and skills necessary to start applying machine learning techniques in their own projects and contribute to the field's ongoing advancements.

The discussion on the Hacker News submission titled "A Hands-On Introduction to Machine Learning: A Comprehensive Guide for Beginners" covers various topics related to machine learning.

One user, ben174, commented in a non-standard format, mentioning difficulty finding accessible resources to learn machine learning. Other users, such as brdly and znsvn, discussed the usefulness of textbooks and generally recommended learning from books.

ShamelessC stated that studying computer science helps in understanding machine learning concepts. They mentioned starting with topics like single-layer perceptrons and forward-backward propagation. Some users, like mptst and bmskts, recommended the use of online resources, such as the YouTube series by 3blue1brown, to learn machine learning concepts effectively.

Another user, rrtnl, shared their perspective that a majority of machine learning work requires statistical knowledge. lmrgr added that modern machine learning also involves applying optimization, calculus, and derivatives. Some users, like tncnv, raised concerns about the blurry boundaries between machine learning and statistics and the varying levels of rigor and assumptions made in practice.

dw expressed their opinion that machine learning is an experimental discipline that is implemented using computers, and programming is sufficient for learning and practicing machine learning.

Overall, the discussion covers a range of perspectives on learning machine learning, including book recommendations, the relevance of computer science knowledge, the role of statistics, and the importance of practical experience.

### 64-bit bank balances ‘ought to be enough for anybody’?

#### [Submission URL](https://tigerbeetle.com/blog/2023-09-19-64-bit-bank-balances-ought-to-be-enough-for-anybody/) | 237 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [347 comments](https://news.ycombinator.com/item?id=37568856)

TigerBeetle, a systems programming company, has decided to use 128-bit integers to store financial amounts and balances, moving beyond the previous use of 64-bit integers. While some may argue that 64 bits is sufficient, TigerBeetle realized they needed to go beyond this limit to store all kinds of transactions adequately. By using binary encoding, computers can represent numbers, and larger numbers require more bits. Fractions and decimal numbers pose challenges for computers, as they cannot accurately express decimal numbers using binary floating point. TigerBeetle solves this problem by representing money as whole numbers, using a minimal integer factor defined by the user. They also avoid using negative numbers and instead keep separate positive integer amounts for debits and credits. 128-bit integers are necessary to represent values smaller than a cent and meet the precision and scale requirements of various applications. TigerBeetle's database, called TigerBeetle, can count not only money but anything that can be modeled using double-entry accounting, such as inventory items or API calls. The company also considers the future-proof aspect of their system, as long-running systems can accumulate high transaction volumes over time. Unexpected events like hyperinflation can also push a currency towards the upper limits of a 64-bit integer, making 128-bit integers a necessary choice. Overall, TigerBeetle's decision to switch to 128-bit integers ensures more robust and flexible financial storage capabilities.

The discussion on this submission revolves around the use of decimal points and rounding in financial software. Some commenters discuss the problems that arise when handling fractions and decimals in computer systems and emphasize the importance of accurately calculating taxes and sales transactions. Others mention the different regulations and rules in different jurisdictions regarding rounding and decimal precision. Some commenters express surprise at the number of people who overlook decimal precision and make mistakes in billing and financial calculations. There is also discussion about the use of integer arithmetic and the limitations of binary representation in computers. Overall, commenters emphasize the need for precise and accurate financial calculations and highlight the challenges and potential pitfalls in implementing billing and accounting software.

### Google DeepMind's AI successor predicts how 71M mutations cause disease

#### [Submission URL](https://endpts.com/google-deepminds-alphafold-successor-predicts-how-71m-mutations-cause-disease/) | 52 points | by [birriel](https://news.ycombinator.com/user?id=birriel) | [7 comments](https://news.ycombinator.com/item?id=37578616)

Google DeepMind has announced the development of a new AI system called AlphaMissense. This technology is the successor to AlphaFold, which was known for its ability to predict the structures of proteins. AlphaMissense, on the other hand, focuses on predicting the likelihood that genetic mutations, specifically 71 million missense mutations, will cause disease. Each missense mutation refers to a single-letter change in an amino acid that makes up a protein sequence. The announcement of AlphaMissense comes alongside the publication of a paper in the journal Science.

The discussion surrounding the announcement of Google DeepMind's AlphaMissense AI system on Hacker News includes several comments:

1. User "blvl" wrote a quick script that checked 23andme data and found various percentages of mutated genes associated with different conditions.
2. User "kgtsmn" thanked "blvl" for the information and added percentages of mutated genes classified as benign, pathogenic, and likely benign across different classifications.
   a. "kgtsmn" also mentioned the MTHFR C677T mutation and its association with reduced enzyme activity and elevated homocysteine levels in individuals with decreased activity in the AA genotype.
3. "blvl" responded, stating that the rabbit hole goes deep and mentioned the SIRT1 mutation's association with longevity traits.
4. User "pknmd" expressed their understanding of 23andme data and questioned the need for medical professionals due to the self-reported nature of the data. They also found it interesting to compare the percentages of pathogenic and non-pathogenic mutated genes.
5. User "pfd1986" shared a link to the published paper in the journal Science regarding AlphaMissense and an additional link to a non-paywalled article about it.
6. User "PBnFlash" speculated about the potential impact of powerful AI systems like AlphaMissense on healthcare and medical research.
7. User "7e" made a general comment about experts not making decisive guesses.

Overall, the discussion involved users sharing their findings, questioning the need for medical professionals in analyzing genetic data, and discussing the potential implications of AI systems like AlphaMissense in the field of healthcare and genetics.

### The Princeton researchers calling out ‘AI snake oil’

#### [Submission URL](https://www.semafor.com/article/09/15/2023/the-princeton-researchers-calling-out-ai-snake-oil) | 32 points | by [irtefa](https://news.ycombinator.com/user?id=irtefa) | [7 comments](https://news.ycombinator.com/item?id=37576259)

The Princeton researchers, Arvind Narayanan and Sayash Kapoor, behind the popular newsletter and upcoming book "AI Snake Oil" are on a mission to dispel hype and clarify the limits of AI. They focus on distinguishing between predictive AI and generative AI, with most of the snake oil concentrated in predictive AI. They highlight the lack of statistical validity in certain predictive AI applications, such as AI hiring tools. They also express concerns about the potential flood of disinformation from generative AI, but argue that addressing other AI-related harms, like non-consensual deepfakes, should take precedence. The researchers propose that AI companies publish regular transparency reports to shed light on potential harms and usage patterns. They also discuss the need for better controls on the open access archive arXiv.org to prevent misinterpretation of AI research studies.

The discussion on this submission seems to cover a range of topics related to AI and its limitations:

1. Some commenters discuss the distinction between predictive AI and generative AI, with the consensus that most of the "snake oil" is concentrated in predictive AI.

2. A link is shared regarding the challenges of replacing scientific reproducibility with machine learning approaches.

3. The potential risks of AI are debated, with one comment suggesting that the greatest risk comes from humans controlling the technology.

4. There is a discussion about the potential shortcomings of GPT-4 when it comes to professional benchmarks and generating the correct answers to wrong questions.

5. The capabilities of ChatGPT as a "bullshit generator" are mentioned, with some being impressed by its ability to generate seemingly plausible responses.

6. A suggestion is made to focus on addressing non-consensual deepfakes and the spread of misinformation as priorities rather than the harms of generative AI.

7. The idea of companies publishing transparency reports to shed light on potential harms and usage patterns of AI is proposed.

8. Concerns are raised about the need for better controls on the open access archive arXiv.org to prevent misinterpretation of AI research studies.

9. A link to an archive discussing the potential dystopian aspects of AI is shared.

10. A commenter expresses their amusement with the ongoing discussion and suggests not taking it too seriously.

The conversation also includes some meta-discussion, with one commenter requesting others not to engage in shallow dismissals and to provide constructive criticism. Another commenter flags a comment as snarky.

### Tackling the curse of dimensionality with physics-informed neural networks

#### [Submission URL](https://arxiv.org/abs/2307.12306) | 75 points | by [jhoho](https://news.ycombinator.com/user?id=jhoho) | [17 comments](https://news.ycombinator.com/item?id=37565140)

In a recent paper submitted to arXiv, researchers Zheyuan Hu, Khemraj Shukla, George Em Karniadakis, and Kenji Kawaguchi introduce a new method for tackling the curse of dimensionality with Physics-Informed Neural Networks (PINNs). The curse of dimensionality refers to the heavy computational burden that exponentially increases as the dimensionality of a problem increases. The authors propose a method called Stochastic Dimension Gradient Descent (SDGD) that decomposes the gradient of Partial Differential Equations (PDEs) into pieces corresponding to different dimensions and randomly samples a subset of these dimensional pieces in each iteration of training PINNs. The proposed method has been experimentally demonstrated to solve notoriously hard high-dimensional PDEs, such as the Hamilton-Jacobi-Bellman and Schrödinger equations, in thousands of dimensions very quickly on a single GPU. In fact, the researchers were able to solve nontrivial nonlinear PDEs in 100,000 dimensions in just 6 hours on a single GPU using SDGD with PINNs. This new method has the potential to scale up the solving of arbitrary high-dimensional PDEs using PINNs.

The discussion on this submission covers various topics related to the dimensions and complexity of problems, as well as the potential advantages of quantum computers.

One user notes that in machine learning, vectors are typically considered to have numerical properties, while in physics, vectors can represent multiple dimensions. Another comment clarifies that the confusion arises from how different disciplines define and describe dimensions in their specific contexts.

Another user mentions that solving the Schrödinger equation in thousands of dimensions is possible for non-quantum mechanical systems, but it becomes more challenging for quantum-hard problems. A response to this comment suggests trying to solve the quantum harmonic oscillator potential, which is analytically solvable. However, another user points out that the Schrödinger equation is a separable differential equation that implies a specific network structure, which may not apply in general cases.

The discussion then moves to the advantages of quantum computers in solving complex problems. One user mentions that classical computers can calculate mean field energies for thousands of interacting electrons, but quantum computers have an advantage when it comes to calculating exchange correlation energies for interacting electrons. Another user adds that the evaluation of transition probabilities and energy differences can also be advantageous in quantum computers.

Ultimately, the comments touch on various aspects related to the dimensions and complexity of problems, highlighting differences in approaches between machine learning and physics, and discussing the potential advantages of quantum computers in solving complex equations.

