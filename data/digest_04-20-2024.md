## AI Submissions for Sat Apr 20 2024 {{ 'date': '2024-04-20T17:11:00.592Z' }}

### Financial market applications of LLMs

#### [Submission URL](https://thegradient.pub/financial-market-applications-of-llms/) | 232 points | by [andreyk](https://news.ycombinator.com/user?id=andreyk) | [106 comments](https://news.ycombinator.com/item?id=40099344)

In the financial world, the allure of using Large Language Models (LLMs) like GPT-3 for predicting stock prices and trades has intrigued many quantitative traders. These autoregressive learners excel at predicting the next element in a sequence based on previous tokens, much like predicting the next word in a sentence. However, the challenge lies in the vast amount of noisy data in financial markets, making it difficult to extract meaningful signals for accurate predictions.

At the same time, innovations in AI, such as multimodal learning and residualization strategies, show promise in combining different types of data sources to enhance predictive models. By leveraging various information modalities like text, images, and sentiment analysis, financial experts aim to improve forecasting accuracy and make better investment decisions.

While the road to using LLMs in financial market applications is filled with challenges, the potential for incorporating diverse datasets and refining prediction models through advanced AI techniques offers new avenues for exploring the intersection of artificial intelligence and quantitative trading.

The discussion on the Hacker News thread covers various perspectives on the application of Large Language Models (LLMs) in finance. Some users express concerns about the accuracy and reliability of LLMs in predicting financial trends, suggesting that they may not fully understand market complexities. Others argue that using LLMs could help decipher Federal Reserve remarks and predict market impacts, while also pointing out challenges such as noise in financial data. Additionally, there are discussions on topics like market efficiency, arbitrage opportunities, the role of human judgment, and the potential for LLMs to assist in analyzing financial documents and generating text citations. Overall, the intersection of AI and quantitative trading sparks both interest and skepticism among the Hacker News community.

### Bostrom's Deep Utopia

#### [Submission URL](https://www.overcomingbias.com/p/bostroms-deep-utopia) | 32 points | by [paulpauper](https://news.ycombinator.com/user?id=paulpauper) | [13 comments](https://news.ycombinator.com/item?id=40101273)

Nick Bostrom's new book, "Deep Utopia," delves into a future where artificial intelligence has solved all our problems. Imagine a world where you don't have to work, where your every desire is fulfilled with a mere gesture. Bostrom explores the implications of living in a utopia where AI caters to our every whim. While he leaves some questions unanswered, he invites readers to ponder what life would be like in a society of endless peace, wealth, and control over all aspects of life. Despite the challenges of envisioning compelling utopias, Bostrom's work sheds light on how our values may evolve in a world of advanced AI. The future, as he suggests, will be vastly different from anything we can fathom today.

The discussion on Nick Bostrom's new book "Deep Utopia" covers a range of opinions and interpretations. 

- One user expresses frustration with the disjointed nature of the book and compares it to Hansons' work, which is more concise and focused.
- Another user praises Bostrom for engagingly concise writing and touches on the significance of the book cover featuring Sisyphus.
- There is a lengthy comment discussing the concept of intelligent species and their relationship with fertility and intelligence, including references to different sci-fi scenarios and the Fermi Paradox.
- A user revisits Bostrom's work and points out the difficulty in interpreting his content and the relevant discussion about preemptive tendencies and non-apology apologies in intellectual circles.
- A debate arises on a critical letter written by Bostrom years ago, with one user arguing against its racist undertones and another defending its language as not intended to be offensive.
- The conversation touches on the current trend of using trigger words and cancel culture, with a user criticizing censorship and emphasizing the importance of free speech.

Overall, the discussion provides a deep dive into different aspects of Bostrom's work, societal perceptions, and the current cultural climate surrounding intellectual discourse and freedom of expression.

### Show HN: LLM Scraper â€“ turn any webpage into structured data

#### [Submission URL](https://github.com/mishushakov/llm-scraper) | 66 points | by [ushakov](https://news.ycombinator.com/user?id=ushakov) | [15 comments](https://news.ycombinator.com/item?id=40100824)

The latest buzz on Hacker News is about a fascinating project called LLM Scraper. This TypeScript library enables converting any webpage into structured data using Language Model APIs. The library supports various models like GGUF, OpenAI, and Groq chat models, ensuring full type-safety with TypeScript. It utilizes the Playwright framework for crawling multiple pages, offering four input modes for versatility. Developers can now easily extract data from webpages by leveraging the power of LLM Scraper. It's definitely a tool worth checking out and giving a star on GitHub!

- **jsg**: Appreciates the great work done with the LLM Scraper project. Mentions the incredibly interesting application of generating reusable script for LLM and expressing concern about the massive cost reduction calls the LLM. Also, the person points out that the source code does not change to make it sustainable for consistent frequent monitoring.
  
- **dptn**: Shares a paper called "Evaporate+" and a link to learn more about it. It discusses the function candidate functions generated by LLMs for sampled structured data.
  
- **frms**: Faces a problem regarding the sources when the HTML structure maps after interest, making the information hidden in the text virtually impossible to access.
  
- **nbbr**: Expresses that they do not understand the Wonder prompt.
  
- **shkv**: Expresses thanks and mentions they are working on supporting local LLMs and llmcpp currently, emphasizing the high cost and wanting some synonym suggestions.
  
- **jeffybefffy519**: Talks about the challenges faced with large models like GPT-4 regarding tracking costs and scaling content size.
  
- **msp26**: Talks about their work with Python and Playwright, mentioning latency with web LLMs, and looking to switch to the llama3 function calling.
  
- **tl**: Discusses operating modes not yet supported by someone but mentions handling JavaScript states has seen a huge improvement. Also praises a nice Markdown tip in a recent addition.
  
- **sn**: It's flagged as true by the author.

### Self-reasoning tokens: teaching models to think ahead

#### [Submission URL](https://reasoning-tokens.ghost.io/reasoning-tokens/) | 151 points | by [fesens](https://news.ycombinator.com/user?id=fesens) | [26 comments](https://news.ycombinator.com/item?id=40099252)

In the realm of AI research, a fascinating exploration focuses on enhancing the reasoning capabilities of language models like GPT. By delving into the internal workings of transformers, researchers have uncovered that these models anticipate and plan for future tokens beyond just the immediate next one. Through clever mathematical formulations and experiments, such as the introduction of "Reasoning Tokens," promising results have been achieved in training models to think ahead in a self-supervised manner.

The concept behind Reasoning Tokens involves incentivizing models to pre-cache information that will be useful for future tokens, thereby fostering the capacity for long-range dependencies in predictions. Early experiments have shown significant reductions in loss, indicating that equipping models with the ability to reason ahead can enhance their performance efficiency. This approach holds potential for revolutionizing how models learn to plan and strategize within sequences of data.

As this research unfolds, the development of Reasoning Tokens offers a peek into the future of AI capabilities, paving the way for novel applications and advancements in the field. Stay tuned for more updates and breakthroughs on this exciting frontier of AI innovation.

The discussion on the submission about enhancing the reasoning capabilities of language models such as GPT involves various perspectives and insights:

- User "wntsngnt" mentions the concept of Reasoning Tokens for incentivizing models to pre-cache information useful for future tokens and achieving promising results.
- User "wrsh07" discusses understanding the generation of tokens, specifically reasoning tokens, and the potential implications for network decoding and generalization.
- User "XenophileJKO" delves into the challenges and implications of GPT-3.5 Turbo in terms of anticipating outputs and creating specific decision points within the model.
- User "rslp" raises the issue of improving existing models through smart methods like branching searches and the trade-offs between model complexity and efficiency.
- User "jcbsmn" shares experiences with similar experiments on large language models generating internal and external dialogues.

The comments cover diverse viewpoints on the research, including discussions on training methods, token generation, model complexities, and potential future applications.

### HelloKitty ransomware rebrands, releases CD Projekt and Cisco data

#### [Submission URL](https://www.bleepingcomputer.com/news/security/hellokitty-ransomware-rebrands-releases-cd-projekt-and-cisco-data/) | 69 points | by [sam42](https://news.ycombinator.com/user?id=sam42) | [55 comments](https://news.ycombinator.com/item?id=40099739)

In a surprising turn of events, the infamous HelloKitty ransomware operation has rebranded itself as 'HelloGookie,' with the original creator 'Gookee/kapuchin0' at the helm. The ransomware group made headlines by releasing passwords for stolen CD Projekt and Cisco data, including source code for popular games like Witcher 3 and internal network information.

Interestingly, developers have already compiled Witcher 3 from the leaked source code, hinting at potential future leaks and developments. The leaked data, totaling 450 GB, contains valuable information on various gaming titles and console SDKs. The group behind the compilation, led by 'sventek,' has a history of similar leaks, having previously worked on Cyberpunk 2077 and GTA V source code leaks.

The rebranding to HelloGookie comes after HelloKitty's halt in operations in 2023, with the new threat actor releasing older decryption keys and stolen information on the dark web. The data leak also includes NTLM hashes from a Cisco breach, shedding light on a possible collaboration between HelloKitty and the Yanluowang ransomware group.

As experts dig deeper into this development, the tech world watches closely to see if HelloGookie will achieve the same infamy and impact as its predecessor. The saga continues with this cyber thriller involving stolen data, ransomware leaks, and the ever-evolving landscape of online security threats.

The discussion on Hacker News regarding the submission focuses on the leaked source code of Witcher 3, Gwent, Cyberpunk, and console SDKs totaling 450 GB. Users delve into the technical aspects of handling such large assets and speculate on the implications and possibilities arising from the leak.

Some users discuss the compression and handling of such massive data, debating on the feasibility of managing 450GB of uncompressed data in today's computing environment. Others point out specific aspects like the texture files and potential modifications made to the source code, such as tweaking game balance.

There is a mention of the size of Google's code repository and comparisons made to the leaked data, highlighting the immense scale of the assets involved. Additionally, users explore the implications of leaked source code on game development practices, including the impact on third-party licensed libraries and the challenges faced by companies like CD Projekt Red in safeguarding their source code.

The conversation also touches on the release of decryption keys and hints at potential developments related to the leaked data, including references to StarCraft and Warcraft. Overall, the discussion showcases a mix of technical analysis, speculation, and reflections on the broader implications of the leaked source code on the gaming industry and cybersecurity landscape.

### GitHub comments abused to push malware via Microsoft repo URLs

#### [Submission URL](https://www.bleepingcomputer.com/news/security/github-comments-abused-to-push-malware-via-microsoft-repo-urls/) | 131 points | by [nateb2022](https://news.ycombinator.com/user?id=nateb2022) | [35 comments](https://news.ycombinator.com/item?id=40097818)

The GitHub platform is facing an exploit where threat actors are distributing malware through URLs associated with legitimate Microsoft repositories, making the files appear trustworthy. McAfee discovered a new LUA malware loader distributed through a Microsoft GitHub repository for the "C++ Library Manager for Windows, Linux, and MacOS." These malicious files were uploaded as comments on the repository, generating auto-generated download links that continue to work even if the comment is deleted. This flaw could be used by threat actors to create convincing lures on any public repository on GitHub, impacting software companies' reputations. Despite the issue being brought to light, there are currently no settings available to manage files attached to projects on GitHub, leaving repositories vulnerable to abuse.

1. **bttrlsstst**: Users attempted to create a comment containing a link by submitting an issue, but the link continued to work even after the comment was deleted. They believe that some suggested solutions below are worth trying out to address the issue.

2. **lppz**: It was mentioned that this type of behavior where malware is hidden in legitimate platforms is common, such as in YouTube comments or Instagram posts. The method of hiding malicious links in plain sight has proved to be effective.

3. **btwz**: A user mentioned a vulnerability similar to the current GitHub issue which occurred in the past involving FTP servers.

4. **thih9**: A simple fix suggested was to deactivate links that didn't point to published comments, as they were intentionally hidden.

5. **Animats**: A warning was issued about hosting hostile content and the need to be vigilant about services running phishing scams.

6. **Avi-D-cdr**: A user proposed a straightforward solution of removing repository information from links to prevent redirects to malicious content, particularly as some legitimate packages rely on files uploaded in GitHub comments.

7. **nst**: It was noted that file links in comments do not support page or repository name organization.

8. **ranger_danger**: Highlighted the issue of sensitive data being distributed through comments and suggested examining the permanence of such content on version control services.

9. **cute_boi**: Raised the point that file links should not include repository information to avoid potential security risks.

### Show HN: Open-source SDK for creating custom code interpreters with any LLM

#### [Submission URL](https://github.com/e2b-dev/code-interpreter) | 61 points | by [mlejva](https://news.ycombinator.com/user?id=mlejva) | [16 comments](https://news.ycombinator.com/item?id=40093257)

Today on Hacker News, a new project caught the community's attention: "Code Interpreter SDK" by e2b-dev. This SDK allows running AI-generated Python code with shared context, enabling subsequent runs to reference variables and definitions from past executions. The code interpreter runs within the E2B Sandbox, a secure micro VM designed for running untrusted AI-generated code and agents. 

Key features of the SDK include compatibility with any LLM and AI framework, support for streaming content like charts and output, Python & JS SDK, serverless and edge function compatibility, and being 100% open source. To get started, users can sign up for an E2B API key, install the SDK for Python or JavaScript, and run the code interpreter to execute and share code context.

The project provides examples on customizing the code interpreter sandbox, getting charts and displayable data in Python and JS, and streaming code output. The SDK's design caters to scenarios where AI-generated code blocks reference each other, mirroring the interactions familiar in Jupyter notebooks, and aims to optimize the context-sharing process for Python use cases with LLMs like GPT-3.5 and 4.

Discussion Summary:

- **jnthn-dly** noted that the project is similar to Docker container running exact code but with the ability to tentatively install/uninstall dependencies. They stressed the importance of dependency management and discussed the potential infrastructure concerns related to DDoS attacks.

- **mljv** chimed in on the project supporting REST API and Firecracker microVMs for enhanced security against DDoS attacks. They highlighted the challenge of making production cost-efficient while running sandboxes using E2B serverless execution and Firecracker snapshots.

- **yikes_awjeez** shared links to additional discussion threads about similar projects for others to explore.

- **fdcps** praised E2B as a great solution though slightly expensive for solo hosting.

- **sndrs** expressed happiness about the project's progress and how it has enabled them to build dynamic things efficiently.

- **mljv** introduced themselves as the CEO of the company behind the SDK, E2B. They explained the technology behind E2B, including the usage of nested containers for security and snapshots for reliability. They highlighted the functionalities and capabilities of the SDK in Python and JavaScript for AI applications.

- **Bnjoroge** requested language support for Python and JavaScript, to which **mljv** clarified the SDK's support for custom sandboxes and various languages.

- **jmsmrdz** and **jrjmsr** simply expressed their admiration for the project.

