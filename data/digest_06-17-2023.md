## AI Submissions for Sat Jun 17 2023 {{ 'date': '2023-06-17T17:10:07.334Z' }}

### The Secret Sauce behind 100K context window in LLMs: all tricks in one place

#### [Submission URL](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c) | 421 points | by [T-A](https://news.ycombinator.com/user?id=T-A) | [94 comments](https://news.ycombinator.com/item?id=36374936)

that, just like how a person can have a deeper understanding of a situation with more context, a language model can also provide better results when given a larger context window. However, this poses a challenge for the technical implementation of the model due to the increased computational complexity. Nonetheless, there are several techniques that can be used to speed up the training and inference of LLMs, enabling the use of larger context windows up to 100K input tokens. These techniques include ALiBi positional embedding, Sparse Attention, FlashAttention, Multi-Query attention, Conditional computation, and the use of 80GB A100 GPUs. With these tricks in hand, it is possible to unlock the full potential of LLMs and take a significant stride towards a more personalized and effective natural language processing experience.

The submission discusses the benefits and challenges of using larger context windows in language models (LLMs), and suggests techniques such as ALiBi positional embedding, Sparse Attention, FlashAttention, Multi-Query attention, Conditional computation, and the use of 80GB A100 GPUs to make training and inference of large context window LLMs more computationally efficient. The comments discuss related topics such as the use of prompt instructions, the limitations and potential of LLMs compared to recurrent neural networks (RNNs), and the effectiveness and feasibility of compressing large models. Some commenters also provide their own experiences and observations in developing and experimenting with LLMs.

### Are chiplets enough to save Moore’s Law?

#### [Submission URL](https://www.eetimes.com/are-chiplets-enough-to-save-moores-law/) | 66 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [68 comments](https://news.ycombinator.com/item?id=36371651)

Nvidia and MediaTek announced at a press conference that Nvidia will supply GPU chiplets to MediaTek for incorporation into a yet-to-be-designed system-on-chip for in-cabin automotive applications. This latest announcement adds more validation for chiplets as a concept that many semiconductor makers are using to help keep Moore’s Law alive. Chiplets are not a new concept. The industry has been making multi-chip modules for decades, however, the ecosystem for commercial chiplets remains absent. In both AMD and Intel's cases, chiplets have proved so successful that they now employ chiplet technology throughout their respective product lines, including their flagship processor products. However, the lack of physical and electrical interface standards continues to hold back the broad commercialization of chiplets.

Nvidia will supply GPU chiplets to MediaTek for system-on-chip for in-cabin automotive applications. While chiplets are not a new concept for the industry, the ecosystem for commercial chiplets still remains absent. However, the lack of physical and electrical interface standards continues to hold back the broad commercialization of chiplets. The discussion revolved around the technical aspects of chiplets, their ability to keep up with Moore’s Law, the challenges faced, and their usage in different areas including the RISC-V community and the progress of Linux desktops. There were also suggestions for solutions to the issues faced, including the development of vertical chip stacking and the creation of a library.

### GPT4 Can’t Ace MIT

#### [Submission URL](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864) | 236 points | by [YeGoblynQueenne](https://news.ycombinator.com/user?id=YeGoblynQueenne) | [116 comments](https://news.ycombinator.com/item?id=36370685)

Great! To get started, let's first discuss the format and content of the daily digest. Would you like the AI to provide a brief summary for each of the top stories using natural language, or would you prefer a more bullet-point style approach? Additionally, do you have any preferences for the types of stories that should be included (e.g. technology-focused, general interest, etc.)?

The discussion centers around GPT-4, a language model developed by OpenAI, and the recent claims that it achieved perfect scores in an exam. Some commenters noted that manual verification of correct answers is usually necessary in such cases, while others argued that the exam may not have been challenging enough. There were also concerns about the validity of benchmarks used to evaluate natural language processing models and the importance of ensuring human evaluators are still involved in the grading process. One commenter mentioned OpenAI's attempts to use GPT-4 for question-answering and explainability and another noted that GPT-4 may be reaching its limits and that future progress could rely on other approaches to language modeling.

### Reddit 1.0 was written in Lisp

#### [Submission URL](https://github.com/reddit-archive/reddit1.0) | 214 points | by [newsoul](https://news.ycombinator.com/user?id=newsoul) | [134 comments](https://news.ycombinator.com/item?id=36367241)

Sorry, there is no story to summarize from this GitHub repository. This appears to be the Reddit 1.0 archive repository, which has been made read-only by its owner.

This thread on Hacker News discusses the benefits and drawbacks of using Lisp as a startup programming language. Some users argue that Lisp's productivity benefits and its ability to streamline development processes make it a good choice, while others point out difficulties in finding developers experienced with the language. Some users also bring up historical examples of successful Lisp-based startups, while others argue that language choice is not a significant factor in a startup's success. Additionally, some users share personal experiences with using Haskell and Clojure in startups and note the high level of education and quality of work among Lisp developers. Overall, the thread presents a nuanced discussion of the merits and limitations of Lisp as a startup language.

### Show HN: Explore large language models with 512MB of RAM

#### [Submission URL](https://github.com/jncraton/languagemodels) | 133 points | by [jncraton](https://news.ycombinator.com/user?id=jncraton) | [32 comments](https://news.ycombinator.com/item?id=36369934)

LanguageModels is a Python package that allows learners and educators to explore large language models on any computer with 512 MB of RAM. The package provides simple functions using standard types, making it easy to interact with. The models are open and light-weight, and do not require any API keys as they perform all inference locally by default. Examples of basic usage include text completions, instruction following, chat, and external retrieval. The package also includes a semantic search function. All models included are free for educational use.

A Python package called LanguageModels has been introduced in a submission on Hacker News that allows learners and educators to explore large language models on any computer with 512 MB of RAM. Users can interact with the models, which are open and light-weight, without the need for API keys as they perform all inference locally by default. The models' basic usage includes chat, text completion, instruction following, and external retrieval. The thread discussion touches on several aspects of LanguageModels, such as how it works, how large models compare to smaller ones, and whether it is possible to teach an AI system common sense and practical knowledge. The conversation also broadens to cover other AI-related topics such as how LLMs operate, how they rely on statistical patterns, and the technical challenges in developing them.

### Firefox 116 Should Have Experimental PipeWire Camera Support

#### [Submission URL](https://www.phoronix.com/news/Firefox-116-PipeWire-Camera) | 108 points | by [LinuxBender](https://news.ycombinator.com/user?id=LinuxBender) | [28 comments](https://news.ycombinator.com/item?id=36371378)

Mozilla's Firefox 116 web-browser is set to release with experimental PipeWire camera support for Linux users, as the company continues to embrace PipeWire for audio and video streams on the desktop. The feature is expected to be enabled in "about:config", and has been achieved with the help of Red Hat and Jan Grulich. The move is expected to provide several benefits, including improved sandboxing and multiplexing of the camera. The relevant code for using the XDG camera portal and PipeWire was merged into the application's system this week.

Mozilla's Firefox 116 web-browser will soon release with experimental PipeWire camera support for Linux, which offers improved sandboxing and multiplexing of the camera while supporting XDG camera portals. The move was achieved with the help of Red Hat and Jan Grulich. While some people expressed concerns regarding PulseAudio, others mentioned issues such as Bluetooth headphones' reliability that Pipewire has fixed. Pipewire is seen as a promising development for the Linux desktop, but some users find it too complex. Video capture and recording were also among the discussed topics. Finally, some users lamented the lack of download support for YouTube videos on Firefox Desktop and reported some issues with certain applications, including Microsoft Teams.

### Congress is racing to regulate AI. Silicon Valley is eager to teach them how

#### [Submission URL](https://www.washingtonpost.com/technology/2023/06/17/congress-regulating-ai-schumer/) | 35 points | by [robg](https://news.ycombinator.com/user?id=robg) | [39 comments](https://news.ycombinator.com/item?id=36375992)

Washington lawmakers are finding themselves under pressure to draft laws addressing the promises and risks of AI as it rapidly develops. With the European Union already leapfrogging ahead of Washington with regards to advancing robust AI legislation, Members of Congress and their staffs are seeking a crash course on AI. However, the technical complexity behind AI has made it challenging for even experts to address the issue properly. Nevertheless, Corporate interests have started to provide congressional staff with information. These corporations are keenly interested in the process of developing AI without hindrance, and in some cases have outright recommended that they be allowed to set their own rules. Nevertheless, some consumer advocates are concerned about the level of influence corporate interests may have on lawmakers.

Lawmakers in Washington are under pressure to draft laws addressing the promises and risks of AI as it rapidly develops, as the European Union is already ahead of Washington in advancing robust AI legislation. Although the technical complexity behind AI has made it challenging for even experts to address the issue properly, corporate interests have started to provide congressional staff with information. These corporations are keenly interested in developing AI without hindrance and, in some cases, have outright recommended that they be allowed to set their own rules. Consumer advocates are concerned about the level of influence corporate interests may have on lawmakers. Discussion on the submission covers a range of topics, such as why laws should be based on understanding AI, whether Google and other corporations would comply with any regulations, and the significance of AI as a fundamental advancement for the internet and society. Some commenters express concern that potential regulations for AI may be difficult due to the selfish reasons of companies and the existential threat to their businesses, and it is suggested that community efforts will be key in making progress quickly and regulating the technology.

### Show HN: State Trooper – Tiny, no frills state machine for Go

#### [Submission URL](https://github.com/hishamk/statetrooper) | 97 points | by [hishamk](https://news.ycombinator.com/user?id=hishamk) | [46 comments](https://news.ycombinator.com/item?id=36370396)

StateTrooper is a Go package that provides a finite state machine (FSM) for managing states. This package allows developers to define and enforce state transitions based on predefined rules, providing a structured, serializable way to constrain and track state transitions. It offers generic support for different comparable types, transition history with metadata, thread safety, and is super minimal without triggers/events or actions/callbacks. The package is easy to install and use, and comes with an example usage with a custom entity struct and state enum.

StateTrooper is a Go package that enables a finite state machine (FSM) for governing states. It enforces state transitions based on predefined rules and creates a structured, serializable way to limit and track state transitions. Developers can specify allowable state transitions for a variety of comparable types, along with transition history metadata. The package is minimalist, with no events/triggers or callback/actions, yet it is easy to install and use. Commenters offered suggestions for naming conventions, documentation clarity, and expanding valid transition functions. They shared usage examples and discussed implementation differences between different programming languages. Some warned of potential race conditions when reading exported fields without mutexes.

### Researchers warn of ‘model collapse’ as AI trains on AI-generated content

#### [Submission URL](https://venturebeat.com/ai/the-ai-feedback-loop-researchers-warn-of-model-collapse-as-ai-trains-on-ai-generated-content/) | 78 points | by [belter](https://news.ycombinator.com/user?id=belter) | [51 comments](https://news.ycombinator.com/item?id=36368848)

Researchers from the UK and Canada have discovered that as AI-generated content proliferates, it causes "irreversible defects" in generative AI, leading to poorer performance over time and a distortion of reality. The use of model-generated data in AI training ultimately leads to what is called model collapse, which means that the AI learns based on other models, dropping the true underlying data distribution for mistakes. These mistakes in generated data compound over time, ultimately leading the AI model to misperceive reality.

Researchers from the UK and Canada have identified that as AI-generated content becomes more widespread, it causes "irreparable damage" in generative AI, leading to lower performance over time and a distortion of reality. The use of model-generated data in AI training can ultimately lead to model collapse, which means that the AI learns based on other models, dropping the true underlying data distribution for mistakes. These errors compound over time, ultimately leading the AI model to misunderstand reality. There was also a discussion about the limitations of generative AI models and the potential implications for human-AI interaction, along with some suggestions for potential solutions such as a more systematic training approach and the use of multiple AI models. Additionally, there were some concerns about the exploitation of AI-generated content for profit and the need for privacy laws to limit access to human data.

