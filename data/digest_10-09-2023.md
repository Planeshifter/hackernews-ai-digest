## AI Submissions for Mon Oct 09 2023 {{ 'date': '2023-10-09T17:09:51.135Z' }}

### Disney Packed Big Emotion into a Little Robot

#### [Submission URL](https://spectrum.ieee.org/disney-robot) | 51 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [11 comments](https://news.ycombinator.com/item?id=37818009)

At the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), a Disney Research team unveiled a new robotic character that combines animation and reinforcement learning to achieve emotive movements. The robot, developed by a team led by Moritz BÃ¤cher from Disney Research in Zurich, features a child-size body with an expressive head, wiggly antennae, and stubby legs. Disney has a long history of programming robots to exhibit emotive behaviors, but as robots become more advanced and mobile, it becomes challenging to develop motions that are both expressive and compatible with real-world constraints. The team spent a year developing a new system that leverages reinforcement learning to convert an animator's vision into robust and expressive motions that can work in different environments. The robot, which is mostly 3D printed, has a four-degree-of-freedom head and five-degree-of-freedom legs with hip joints for dynamic walking and balancing. Disney's expertise in character animation coupled with technical expertise in building mechanical systems allows them to create lifelike performances.

The discussion about the submission on Hacker News includes various comments from users:

- User "daniel_reetz" mentions that Disney Research faces great challenges in exploring constraints and finding creative connections between simulations and real-world engineering. They highlight that some impossible parts are solved with artistic tricks, making the research work more robust and compelling.

- User "rob74" shares a link to Walker, the All-Terrain vehicle from Star Wars, as it looks similar to Disney's robot.

- User "spfrdmms" provides a link to BD units from Star Wars, which resemble Disney's robot.

- User "cjyz" suggests that Disney's research is aimed at fitting hardware into a long-term business model.

- User "sysh" comments that other companies can make similar and smaller robots from factories.

- User "skntfnd" compares Disney's robot to Wall-E from the movie, Wall-E. User "cptnplm" adds that it reminds them of BD-1, a character from Star Wars Jedi Fallen Order. User "grcy" believes it is similar to Johnny 5, a robot from the movie Short Circuit. User "mystrydp" simply comments that it sounds "turtles."

- User "dwghttk" comments with the phrase "ql mtn."

- User "hmmck" suggests a quick and abstract interpretation that the internal state of the robot generates mental expression.

### Language Agent Tree Search Unifies Reasoning Acting and Planning in LMs

#### [Submission URL](https://arxiv.org/abs/2310.04406) | 72 points | by [yuchiz](https://news.ycombinator.com/user?id=yuchiz) | [11 comments](https://news.ycombinator.com/item?id=37816614)

Researchers have introduced a new framework called Language Agent Tree Search (LATS) that aims to enhance the decision-making capabilities of large language models (LLMs). While LLMs have shown impressive performance on decision-making tasks, they often lack the ability to act as autonomous agents. LATS utilizes LLMs as agents, value functions, and optimizers, drawing inspiration from Monte Carlo tree search in model-based reinforcement learning. The framework incorporates an environment for external feedback, offering a more deliberate and adaptive problem-solving mechanism. Experimental evaluation in various domains, including programming and web browsing, demonstrates the effectiveness and generality of LATS. For instance, LATS achieves a score of 94.4% for programming on HumanEval with GPT-4 and an average score of 75.9 for web browsing on WebShop with GPT-3.5. This research opens doors for enhancing the capabilities of language models in reasoning, acting, and planning.

The discussion on this submission begins with a request to copy the paragraph for easier reference. Another commenter points out that the abstract of the linked article contains some technical and methodological details. 

One user provides a high-level summary of the submission, noting that the Language Agent Tree Search (LATS) framework combines reasoning, planning, and decision-making capabilities of large language models (LLMs). They further explain that LATS adapts the Monte Carlo Tree Search (MCTS) approach used in AlphaZero to enable high-level planning in LLMs.

Another commenter shares a link to the associated Github repository for the project. 

One user mentions their attempt to implement a similar project, focusing on creating different types of agents with planned subtasks using natural language. They describe the challenges they faced in understanding the graph search and thought-contraction-reflection selection process.

Another commenter compares this approach to Graph Thoughts and suggests looking into it for further understanding.

One user mentions the success of the LATS framework in the WebShop task, achieving a lower score of 38 in LaserWebgum.

Lastly, a user mentions notifying others about the discussion on reasoning.

### Safe AI Image Generation

#### [Submission URL](https://www.smbc-comics.com/comic/generation) | 237 points | by [dsr_](https://news.ycombinator.com/user?id=dsr_) | [133 comments](https://news.ycombinator.com/item?id=37819855)

In today's top story on Hacker News, we have a fascinating blog post titled "GenerationPosted: Exploring the Fascinating Intersection of Science, AI, and Sex." This thought-provoking piece delves into the potential implications and advancements that emerge when these three powerful domains collide. Written by an AI enthusiast named Bea Wolf, the blog takes readers on a captivating journey through innovative research, ethical considerations, and the evolving nature of human relationships. It's an engaging read that offers a fresh perspective on the influence of science and technology on our intimate lives. Don't miss out on this intriguing exploration â€“ check out the blog post for yourself!

The discussion on the submission revolves around copyright infringement and the legal implications of using AI to generate content. One user argues that refusing to use human tracking in creative ways is making it harder for them to identify and address copyright violations. Another user points out that copyright infringement can occur even if it's unintentional and suggests that understanding the details of intellectual property rights can help avoid infringement. There is a debate about the legal definition of copyright and the restrictions and exceptions that apply. Some users mention YouTube's copyright enforcement mechanisms and the challenges faced by content creators. Additionally, there are comments about the AI-generated content and the potential impact of AI on various industries. The discussion touches on topics such as the suppression of certain discussions and the perceived safety concerns related to AI.

### Show HN: Self hosted Embedding Server | OpenAI compatible

#### [Submission URL](https://github.com/toshsan/embedding-server) | 9 points | by [sansah](https://news.ycombinator.com/user?id=sansah) | [3 comments](https://news.ycombinator.com/item?id=37821971)

ðŸ“¢ Private Embedding Server API: A drop-in replacement for OpenAI's python embedding API, this project aims to provide a solution for AI use cases like classification, clustering, semantic search, and recommendations while ensuring data privacy. With this server, you can use official OpenAPI libraries without worrying about leaking your data to external APIs. The server supports shared key authentication and downloads model data to cache on first use. It currently has 11 stars on GitHub. Check it out!

In the comments section, user "snsh" points out that Microsoft Azure is supported in the private embedding server API. They provide a link to the documentation for Azure support. Another user, "skptrn", simply comments "dp."

### Bitten by the black box of iCloud

#### [Submission URL](https://sixcolors.com/post/2023/10/bitten-by-the-black-box-of-icloud/) | 70 points | by [voisin](https://news.ycombinator.com/user?id=voisin) | [34 comments](https://news.ycombinator.com/item?id=37826944)

In a recent incident, tech journalist Dan Moren experienced a frustrating iCloud outage that left him unable to access his email, sync his data, or use various iCloud-dependent apps and services. Despite initially troubleshooting the issue himself, he eventually reached out to Apple support, who informed him that his services would be back up and running approximately 12 hours after they initially went down. Moren had to wait through the day with limited functionality before everything finally started working again at exactly 9 p.m. Although he was relieved when his iCloud services were restored, he was left with unanswered questions about why the outage occurred and why there was no advanced warning or communication from Apple about the issue.

The discussion surrounding the submission includes various perspectives on the iCloud outage experienced by journalist Dan Moren. Some users sympathize with Moren's frustration and criticize Apple for the lack of communication and advanced warning about the issue. Others argue that it is the user's responsibility to have a backup strategy and that relying solely on iCloud may not be the best approach. Some users recommend using a NAS to mirror the contents of iCloud regularly. Additionally, there are discussions about alternative backup solutions, such as Elcomsoft's Phone Breaker and Time Machine, as well as the issue of privacy with iCloud. Some users express their distrust in cloud services, emphasizing the importance of personal backups on external hard drives. Others share their negative experiences with iCloud, such as disappearing storage and issues with iCloud DriveFuse.

### IBM CEO in damage control mode after AI job loss comments

#### [Submission URL](https://www.itpro.com/technology/artificial-intelligence/ibm-ceo-in-damage-control-mode-after-ai-job-loss-comments) | 19 points | by [belter](https://news.ycombinator.com/user?id=belter) | [6 comments](https://news.ycombinator.com/item?id=37824149)

IBM CEO Arvind Krishna has stated that the company has no intention of laying off developers or programmers and plans to increase hiring in these areas. Krishna wants to ramp up hiring of software engineering and sales staff over the next four years to accommodate the company's focus on generative AI. The announcement follows IBM's decision earlier this year to cut 8,000 staff positions in its HR division in order to automate roles. Krishna has been vocal about AI-related job losses, stating in August that the influx of generative AI tools should make people "feel better," despite concerns about their impact on the labor market.

The discussion on this submission revolves around IBM's decision to focus on hiring developers and programmers for its generative AI efforts while cutting staff positions in its HR division. 

One user, Aerroon, highlights that the number of job cuts in the HR division is significant, considering the large workforce dedicated to HR in the company. Another user, lxf, points out that the summary of the article is poorly quoted and suggests that the HR cuts are similar to those faced by customer-facing roles. Aerroon acknowledges this and realizes a part of his original comment doesn't make sense.

In response to the news, ptr mentions that future employment at IBM will likely focus on generative AI, rather than HR roles, which can be automated. Unfrozen0688, however, voices skepticism about the reliance on AI and suggests that the decision to cut HR roles is based on a biased perspective on technology and a dismissive view of non-technical staff. Snpcstr agrees, saying that the cuts are based on bias against HR roles.

### GitHub Copilot loses an average of $20 a month per user

#### [Submission URL](https://www.wsj.com/tech/ai/ais-costly-buildup-could-make-early-products-a-hard-sell-bdd29b9f) | 46 points | by [skilled](https://news.ycombinator.com/user?id=skilled) | [21 comments](https://news.ycombinator.com/item?id=37821756)

Tech giants like Microsoft and Google may be making big claims about their AI technology, but they are struggling to turn the hype into profits. While they are touting AI products that can generate business memos or computer code, they are still figuring out how to monetize these offerings. As AI development continues to be costly, companies are facing the challenge of creating products that customers are willing to pay for. The journey to translating AI advancements into profitable ventures is proving to be a difficult one.

The top comments on this submission revolve around observations and opinions about Microsoft and Github Copilot, as well as the cost and capabilities of AI technology.

- Some users comment on the limitations of Github Copilot, stating that it generates incomplete functions and often fails to properly handle protected code. They also mention the lack of support for Python in the chat interface and question its value for the price.
- Others share positive experiences with Copilot, highlighting its usefulness for generating code and its potential for changing the game when it comes to DRY (Don't Repeat Yourself) programming.
- One user presents a study comparing the typing speed of typists and their perception of the value of Copilot's code generation function in an IDE editor. They speculate that slower typists may find more value in it.
- There is a link shared to an archive of an article on PH, but the content of the link is not specified.
- A commenter posits that as AI models progress and optimization techniques continue to reduce hardware requirements, the cost of AI services will decrease over time.
- The discussion mentions the use of smaller, specialized models versus larger corporate models, suggesting that the former may have better performance in certain cases.
- Some commenters discuss the pricing of Copilot, mentioning that it is worth the $100/month for professionals, while others argue that the standard completion version, rather than the chat version, is what matters.
- The cost of GPU infrastructure is also brought up, with one user mentioning the high price of A100 GPUs and the difficulty of finding affordable alternatives with sufficient memory.
- Lastly, there is a user who humorously comments "dd," possibly indicating they have nothing substantive to contribute to the discussion.

Overall, the discussion seems centered around the capabilities, limitations, and pricing of AI technology like Github Copilot, as well as the potential impact it may have on coding practices and the market.

