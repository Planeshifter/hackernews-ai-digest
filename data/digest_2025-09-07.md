## AI Submissions for Sun Sep 07 2025 {{ 'date': '2025-09-07T17:14:57.044Z' }}

### Using Claude Code to modernize a 25-year-old kernel driver

#### [Submission URL](https://dmitrybrant.com/2025/09/07/using-claude-code-to-modernize-a-25-year-old-kernel-driver) | 783 points | by [dmitrybrant](https://news.ycombinator.com/user?id=dmitrybrant) | [254 comments](https://news.ycombinator.com/item?id=45163362)

- The project: A data-recovery enthusiast who rescues data from QIC-80 tapes (popular in the 1990s) modernized the ftape Linux kernel driver so it builds and loads on contemporary kernels (tested around 6.8), instead of being stuck on ancient distros like CentOS 3.5.

- Why ftape matters: These low-cost tape drives piggybacked on the PC‚Äôs floppy controller (about 500 Kb/s) via a messy, BIOS-opaque protocol. Proprietary DOS/Windows tools existed, but ftape was the only open-source path to dumping raw tape data‚Äîcrucial for later decoding proprietary formats. ftape fell out of the kernel circa 2.4/2000.

- How the AI helped:
  - The author fed compiler errors from the old 2.4-era code to Claude Code, iterating until deprecated APIs/structs were replaced with modern equivalents.
  - Claude then set up an out-of-tree Kbuild so the driver could be compiled as a standalone .ko, avoiding a full kernel tree.
  - For runtime debugging (requiring sudo), the author manually loaded/unloaded the module and pasted dmesg logs to Claude, comparing against a known-good log from an older working setup.

- The fix: The module was loading but not talking to the hardware. Claude spotted that key module parameters (I/O base addresses, etc.) defaulted to invalid values (e.g., -1). Supplying the correct addresses unlocked communication with the drive.

- Why it‚Äôs interesting:
  - A concrete example of ‚Äúcompiler-in-the-loop‚Äù LLM refactoring: the AI handles mechanical API churn across decades, while the human owns the privileged testing and hardware validation.
  - Shows a viable path to reviving legacy drivers for digital preservation without rewriting from scratch.
  - Highlights the risks and boundaries: kernel-space code still needs human caution, real hardware testing, and careful parameterization.

- Likely discussion on HN:
  - Safety of trusting LLM-generated kernel changes; testing strategies and maintainability.
  - Sharing the updated code and whether it could be upstreamed or maintained out-of-tree.
  - Broader applications for resurrecting vintage hardware and file formats.
  - Nostalgia and war stories about QIC tapes, FDC quirks, and throughput limits.

**Summary of Hacker News Discussion:**

The discussion revolves around the use of AI (specifically Claude) to modernize legacy Linux drivers, sparking debates on AI's role in software development, boilerplate code, and the balance between automation and human expertise. Key points include:

1. **AI's Role in Development**:
   - Supporters highlighted AI's ability to automate repetitive tasks (e.g., updating deprecated code, reducing boilerplate), enabling rapid iteration and exploration of larger projects. One user noted that Claude streamlined debugging by parsing `dmesg` logs and fixing I/O address issues in the `ftape` driver.
   - Skeptics raised concerns about reliability, arguing that LLMs' stochastic nature risks introducing errors in deterministic systems like kernel code. Comparisons were made to "throwing dirt until something sticks," emphasizing the need for rigorous testing.

2. **Boilerplate Code Debates**:
   - Some argued boilerplate is a necessary evil, serving as scaffolding for complex systems. Critics viewed it as poor design, citing frameworks that minimize redundancy (e.g., Haskell's type system). A joke Haskell package called `blrplt` humorously underscored efforts to eliminate boilerplate.
   - Analogies to **Japanese carpentry** emerged, where precise joinery eliminates screws. Critics countered that software's abstract nature makes such perfectionism impractical, favoring adaptable abstractions over rigid "frictionless" designs.

3. **Human vs. AI Collaboration**:
   - Many agreed AI excels at "grunt work" (e.g., syntax updates), freeing developers to focus on high-level design. However, users stressed that human oversight remains critical, especially for low-level systems like kernel modules, where incorrect parameters could cause hardware issues.

4. **Historical Context & Language Design**:
   - Older developers reminisced about past efficiency constraints (e.g., limited CPU/memory), contrasting with today's resource abundance. Discussions touched on language trends, with Python's subprocess module and Haskell's type system cited as examples of balancing flexibility and boilerplate reduction.

5. **Nostalgia & Broader Implications**:
   - Beyond technical debates, users shared nostalgia for 1990s hardware and QIC tapes, praising efforts to preserve obsolete formats. Some pondered AI's potential to revive legacy systems, though questions about upstreaming AI-assisted code lingered.

**Key Takeaway**: While AI accelerates development and preserves digital history, the consensus underscored a symbiotic relationship‚ÄîAI handles tedious tasks, but human expertise ensures robustness, especially in critical systems. The debate reflects broader tensions in tech: efficiency vs. reliability, abstraction vs. control, and nostalgia vs. progress.

### Taco Bell AI Drive-Thru

#### [Submission URL](https://aidarwinawards.org/nominees/taco-bell-ai-drive-thru.html) | 137 points | by [planetdebut](https://news.ycombinator.com/user?id=planetdebut) | [202 comments](https://news.ycombinator.com/item?id=45162220)

Taco Bell‚Äôs AI Drive-Thru Meets Its Match: ‚ÄúExtra Sauce, Hold the Sanity‚Äù

What happened
- Taco Bell rolled out voice AI ordering at 500+ drive-thrus, betting it could tame the chaos of custom taco orders.
- Per the Wall Street Journal (Isabelle Bousquette, Aug 28, 2025), the reality was glitches, delays, and a wave of customers trolling the bot with absurd requests.
- The company is ‚Äúreassessing‚Äù where AI fits best and weighing human intervention during peak times‚Äîwhile still insisting voice AI remains core to the roadmap.

Why it matters
- Drive-thrus are a worst-case environment for voice AI: accents, noise, menu sprawl, rapid-fire customization, and time pressure.
- Systems must handle not just edge cases but adversarial users‚Äîsomething lab benchmarks rarely reflect.
- The episode underscores the need for human-in-the-loop designs and staged rollouts before scaling to hundreds of locations.

HN take
- Speech AI is impressive in demos but brittle in the wild; hybrid ops may beat ‚Äúfull automation‚Äù for years.
- Corporate AI optimism often underestimates messy human behavior‚Äîand the cost when UX goes sideways.
- Expect more walk-backs as voice AI moves from call centers to noisy, real-time, customer-facing edges.

The Hacker News discussion highlights skepticism toward AI-driven drive-thrus and broader reflections on automation challenges in fast-food environments. Key themes include:

1. **Preference for Human Interaction**:  
   Many users shared frustrations with AI systems (e.g., Wendy‚Äôs, Taco Bell) struggling to handle nuanced requests, accents, or adversarial behavior. Some noted that rigid AI interactions felt impersonal and inefficient compared to human clerks who adapt quickly to context or errors.

2. **Real-World AI Limitations**:  
   Participants emphasized that lab-tested AI often fails in chaotic drive-thru settings due to noise, menu complexity, and unpredictable customer behavior. Hybrid models (AI + human oversight) were suggested as more viable, especially during peak times.

3. **Corporate Over-Optimism**:  
   Critics argued companies prioritize cost-cutting and automation hype over customer experience, leading to poorly implemented systems. One user likened corporate AI mandates to ‚ÄúMBA-driven detachment‚Äù from ground realities, where rigid rules clash with human flexibility.

4. **Operational Challenges Beyond AI**:  
   Broader issues like long drive-thru wait times (e.g., Starbucks, McDonald‚Äôs) were attributed to understaffing, third-party delivery apps (DoorDash) overwhelming kitchens, and poor physical infrastructure design. Some noted that AI could exacerbate bottlenecks without addressing root causes.

5. **Skepticism Toward Full Automation**:  
   Comments highlighted the importance of human judgment in handling exceptions or complex orders. A recurring sentiment: AI may excel in controlled environments but falters in the ‚Äúmessy‚Äù real world, where empathy and adaptability matter.

**Takeaway**: The discussion underscores a cautious outlook on AI in customer-facing roles, advocating for incremental integration, human-AI collaboration, and addressing systemic operational flaws before scaling automation.

### Show HN: Semantic grep with local embeddings

#### [Submission URL](https://github.com/BeaconBay/ck) | 171 points | by [Runonthespot](https://news.ycombinator.com/user?id=Runonthespot) | [73 comments](https://news.ycombinator.com/item?id=45157223)

ck: a ‚Äúsemantic grep‚Äù for code

What it is
- A Rust CLI that searches code by meaning, not just keywords. You can ask for ‚Äúerror handling‚Äù and find try/catch blocks, error returns, or exception paths‚Äîeven if those exact words aren‚Äôt present.
- Three modes: classic regex (grep-compatible), semantic (--sem, uses embeddings), and hybrid (--hybrid) that fuses both via Reciprocal Rank Fusion.

Why it matters
- Cuts through regex noise and speeds up code spelunking.
- Designed for both humans and AI agents: clean JSON output, relevance scores, top-k, thresholds, and the ability to return entire functions/classes for context.

Notable features
- Drop-in grep ergonomics: supports -n, -A/-B, -l/-L, --no-filename, globbing, excludes, etc.
- Agent-friendly: --json, --scores, --topk, --full-section to return complete definitions.
- Smart filtering: respects .gitignore and auto-excludes build/cache dirs (node_modules, target, __pycache__, .fastembed_cache).
- Project index for fast semantic queries: ck --index once, then run semantic or hybrid searches instantly.

Try it
- Install: cargo install ck-search
- Index: ck --index .
- Search: ck --sem "error handling" src/ or ck --hybrid "database connection pooling" src/

Caveats
- Requires an index for semantic/hybrid searches; match quality depends on embeddings and threshold tuning.

Repo: https://github.com/BeaconBay/ck (approx. 500 stars)

Here's a concise summary of the Hacker News discussion around **ck**, the semantic grep tool:

---

### Key Discussion Themes  
1. **Technical Integration**  
   - Users explored how ck compares to tools like LSP-based code navigators, My Code Search (MCP), and others. Some highlighted its hybrid semantic/regex approach as unique.  
   - Indexing mechanics (e.g., chunking files under 600 lines for LLM compatibility) and Rust performance optimizations were praised.  

2. **Developer Experience**  
   - Mixed reactions on UX: Some appreciated depth for power users, while others worried about complexity overshadowing benefits. Debate arose over whether "lazy" developers adopt such tools.  
   - Maintainers clarified design choices (e.g., `--index` for speed, `.gitignore` support) and confirmed plans for Ruby/Elixir support.  

3. **AI/LLM Synergy**  
   - Discussed ck's role in AI workflows (e.g., RAG for code context retrieval). Some contrasted it with Claude Code‚Äôs "buggy" cursor-based search.  
   - Prompt engineering ideas emerged, like training LLMs on ASTs or combining ck with compiler errors for code fixes.  

4. **Comparisons & Alternatives**  
   - Mentioned alternatives: `semgrep`, My Code Search, LlamaIndex. Users debated tradeoffs (simplicity vs. extensibility).  
   - Requests for TypeScript support and comparisons with AI-focused tools like SemTools.  

5. **Community & Development**  
   - Maintainers engaged actively, addressing feedback (e.g., fixing a chunking bug, explaining architecture decisions).  
   - Interest in vector embedding models (BAAI, Google) and lightweight CLI design principles.  

---  

### Notable Quotes  
- **On UX**: *"Powerful tools require careful UX‚Äîdevelopers won‚Äôt adopt complexity unless the benefit is immediate."*  
- **On AI Integration**: *"Could ck‚Äôs semantic search reduce AI hallucinations by improving code context retrieval?"*  
- **On Language Support**: *"Java support would be huge given enterprise codebases... Clojure when? üëÄ"*  

The discussion reflects excitement for ck‚Äôs potential to modernize code search, balanced with practical considerations for real-world adoption.

### Google's new AI mode is good, actually

#### [Submission URL](https://simonwillison.net/2025/Sep/7/ai-mode/) | 123 points | by [xnx](https://news.ycombinator.com/user?id=xnx) | [64 comments](https://news.ycombinator.com/item?id=45158586)

Simon Willison: Google‚Äôs new ‚ÄúAI mode‚Äù search is surprisingly great‚Äîfast, useful, but opaque

- Willison, who recently praised GPT-5-powered search, says Google‚Äôs new AI mode feels similarly strong but is notably faster.
- He went in with low expectations after bad experiences with AI Overviews and the generic ‚ÄúAI mode‚Äù branding, but early tests impressed him.
- Example query: researching whether labs physically cut up books for training data‚ÄîAI mode returned solid results.
- Biggest gripe: opacity. It shows ‚Äúrunning 5 searches‚Äù but won‚Äôt reveal what they are; he argues seeing the underlying queries is key for trust (a longstanding complaint with Gemini, too).
- Availability caveat: AI mode isn‚Äôt accessible in the EU; he discovered this while in France.
- Takeaway: Google finally seems to be leveraging its search infrastructure for genuinely good AI-assisted search, but credibility would improve with transparent query workflows.

**Summary of Hacker News Discussion:**

The discussion around Simon Willison‚Äôs praise for Google‚Äôs new AI-powered search mode reflects mixed reactions, technical debates, and broader concerns about AI search tools:

1. **Positive Reception of Google‚Äôs AI Mode**:  
   - Users acknowledge its speed and utility, with some noting it rivals alternatives like Perplexity for concise answers.  
   - Comparisons highlight Gemini‚Äôs faster performance over ChatGPT in certain tasks (e.g., transcription accuracy).  

2. **Criticisms and Concerns**:  
   - **Opacity**: Frustration over Google not revealing the specific searches it runs, echoing long-standing transparency issues with Gemini.  
   - **EU Availability**: The AI mode‚Äôs absence in the EU led some users to recommend alternatives like Perplexity.  
   - **Accuracy & Misinformation**: Skepticism about AI Overviews‚Äô reliability, with examples of misleading answers (e.g., Anthropic‚Äôs copyright settlement details). Some users report scripts to block AI results over trust issues.  

3. **Technical Infrastructure Debates**:  
   - Discussions about Google‚Äôs TPUv7 hardware vs. Nvidia‚Äôs Blackwell GPUs, with speculation on performance trade-offs.  
   - Praise for Gemini‚Äôs speed attributed to TPU optimizations.  

4. **Competitor Comparisons**:  
   - Perplexity is lauded for deep technical queries (e.g., sourcing GCP docs) and syncing across devices.  
   - DuckDuckGo gains mentions as users flee Google‚Äôs AI inaccuracies, though SEO-spam remains a universal pain point.  

5. **Broader Industry Trends**:  
   - Concerns about AI-generated spam degrading search quality and incentivizing low-effort content.  
   - Debates over whether Google‚Äôs AI integration prioritizes speed over accuracy, with some fearing cognitive laziness in users.  

**Key Takeaway**: While Google‚Äôs AI search impresses with speed and integration, skepticism about transparency, regional access, and accuracy persists. Alternatives like Perplexity thrive in niche technical use cases, but the broader ecosystem grapples with balancing innovation against reliability and ethical concerns.

### The CoPilot Productivity Paradox

#### [Submission URL](https://www.marginalia.nu/log/a_125_ai_assistants/) | 43 points | by [Bogdanp](https://news.ycombinator.com/user?id=Bogdanp) | [14 comments](https://news.ycombinator.com/item?id=45154044)

The CoPilot productivity paradox: An experienced developer describes uninstalling GitHub Copilot (and JetBrains‚Äô local AI) after finding it slowed real work despite speeding up rote tasks. The core complaint isn‚Äôt model quality but integration: inline LLM suggestions are noisy, non-deterministic, and arrive with variable latency, which breaks IDE muscle memory and forces constant ‚Äúmental model‚Äù updates. Evaluating and fixing half-right snippets often takes as long as writing the code cleanly, while draining scarce cognitive bandwidth.

Key points:
- Good at accelerating boring, deterministic transformations; bad at everything that requires steady focus.
- Human factors matter: mental bandwidth, determinism, latency, and the cost of context-switching.
- Classic IDE completions work because they‚Äôre fast and predictable; LLM completions aren‚Äôt.
- Better workflow: keep LLMs in a separate chat to ask questions or draft sketches with explicit context, then refine manually.
- Caveat: Copilot can shine when you‚Äôre working in unfamiliar languages.

Bottom line: As a drop-in autocomplete, LLMs can hinder more than help; invest in editor fluency and treat the model as an external collaborator.

**Summary of Discussion:**

The Hacker News discussion explores mixed perspectives on LLMs (like GitHub Copilot) in software development, echoing the submission‚Äôs critique while highlighting broader debates:

1. **Potential vs. Practical Disruption**:  
   Some argue LLMs could enable disruptive tools (e.g., a Rust-based Fusion 360 alternative) by automating rote tasks. However, others counter that assuming shared context in programming is flawed, leading to communication gaps and conflicting ‚Äúworld models‚Äù between humans and AI.

2. **Integration Challenges**:  
   Users emphasize that LLM-driven IDE integrations (e.g., Copilot) introduce friction due to latency, unpredictability, and cognitive overhead‚Äîvalidating the submission‚Äôs core argument. One comment notes IntelliJ plugins feel ‚Äúunstable,‚Äù reinforcing concerns about workflow disruption.

3. **Copyright and Legal Risks**:  
   Concerns arise about AI-generated code ownership, with references to Microsoft‚Äôs claim that 30-50% of code is AI-written. Questions linger about copyright validity and legal exposure for developers.

4. **Niche Use Cases**:  
   Supporters suggest LLMs excel in narrow B2B applications (HR, payroll) or as external tools for drafting code sketches, technical drawings, or unfamiliar languages. However, creativity and clean architecture are seen as inherently human domains.

5. **Model Quality vs. Workflow Design**:  
   A subthread clarifies that the submission‚Äôs criticism targets IDE integration flaws, not model quality. Better workflows (e.g., separate LLM chat for queries) are proposed to preserve focus.

**Bottom Line**:  
The debate mirrors the submission‚Äôs tension: LLMs hold promise but face adoption hurdles due to integration issues, contextual mismatches, and legal ambiguities. Success may lie in treating them as collaborative tools rather than drop-in replacements.

