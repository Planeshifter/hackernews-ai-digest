## AI Submissions for Tue May 21 2024 {{ 'date': '2024-05-21T17:12:26.339Z' }}

### Images that Sound: Generating spectrograms that are also images

#### [Submission URL](https://ificl.github.io/images-that-sound/) | 200 points | by [smusamashah](https://news.ycombinator.com/user?id=smusamashah) | [42 comments](https://news.ycombinator.com/item?id=40426890)

A group of researchers from the University of Michigan has introduced a fascinating concept: creating spectrograms that not only resemble images but also produce sounds when played. In their paper, they discuss how natural images, when converted to spectrograms, yield unusual audio results. Their innovative method, utilizing text-to-image and text-to-spectrogram diffusion models, generates spectrograms that both look like images and sound like natural audio. This technique, described as "images that sound," involves denoising noisy latents with audio and image diffusion models simultaneously, resulting in samples that align with both visual and audio prompts. The team provides detailed insights and examples in their paper, showcasing the potential of this multifaceted approach. This breakthrough opens up exciting possibilities at the intersection of visual and auditory experiences.

The discussion on the submission about creating spectrograms that resemble images and produce sounds when played covers various aspects related to machine learning processes, practical applications, and creative projects inspired by the concept. Some users discussed historical references to synthesizers like the ANS synthesizer and commercial products like Metasynth. There were also comparisons made between machine learning processes inspired by human neural systems and the practicality of such systems in real-world applications. Other contributors delved into the technical aspects of spectrograms, sound representation, and artistic interpretations of the generated sounds. Several users shared related projects they found interesting, such as the Oscillofun project and the Riffusion project, showcasing different interpretations and applications of sound and image manipulation techniques. There was also mention of AI-generated content and references to music and art inspired by the concept of images that can be converted into sound. The discussion covered a wide range of topics, including creative applications, technical insights, historical references, and user experiences with similar projects and technologies.

### We created the first open source implementation of Meta's TestGenâ€“LLM

#### [Submission URL](https://www.codium.ai/blog/we-created-the-first-open-source-implementation-of-metas-testgen-llm/) | 137 points | by [gronky_](https://news.ycombinator.com/user?id=gronky_) | [38 comments](https://news.ycombinator.com/item?id=40426995)

Today, in the world of software engineering, a groundbreaking development has occurred with the release of the first open-source implementation of Meta's TestGen-LLM Code Integrity by Cover Agent900. Previously introduced by Meta researchers in a paper titled "Automated Unit Test Improvement using Large Language Models," TestGen-LLM shook the industry with its promise of enhancing test coverage with guaranteed improvements over existing code bases.

While Meta didn't make the TestGen-LLM code publicly available, the team behind Cover Agent900 took matters into their own hands to implement and release it today. Their journey involved overcoming common pitfalls of automated test generation using Generative AI, ensuring that the tests not only compiled and ran effectively but also increased code coverage substantially.

Cover-Agent v0.1, the result of their efforts, follows a meticulous flow of receiving user inputs, generating tests, validating them, and updating the existing test suite until the desired code coverage threshold is met or the maximum iterations are reached. Challenges arose during the implementation process, such as handling language-specific issues like indentation requirements in Python or dealing with complex code that necessitated multiple iterations.

To address these challenges, the team introduced features like `--additional-instructions` for users to provide specific prompts to the Large Language Models and `--included-files` to supplement the context for the unit test generation process. These enhancements aim to empower developers to customize Cover-Agent for their projects and improve the quality of generated tests significantly.

The release of the first open-source implementation of TestGen-LLM by Cover Agent900 marks a significant milestone in the quest for automated test generation using Large Language Models, opening up new possibilities for enhancing test coverage and code integrity in real-world software development.

The discussion on Hacker News revolved around the release of the first open-source implementation of Meta's TestGen-LLM by Cover Agent900. 

- Some users shared their experiences with AI-generated tests, mentioning that while the tests provided good coverage for simpler functions, they struggled with more complex scenarios. They highlighted the importance of tweaking the generated tests and ensuring they behave as expected. Others expressed skepticism about the value of LLM-generated tests, noting limitations and the need for human-written tests for validation.

- There was a debate about the effectiveness of AI-generated tests compared to manually written tests, with some users emphasizing the importance of writing tests that cover specific behaviors and edge cases to ensure code reliability. 

- Users discussed the challenges of integrating AI-generated tests into existing codebases, pointing out the need for additional testing strategies like end-to-end tests to complement the generated tests effectively.

- The thread also touched on the difficulty of automated test generation for more complex logic and the potential pitfalls of relying solely on AI-generated tests without human validation.

Overall, the discussion highlighted the ongoing exploration of AI-generated tests and the nuances involved in their integration and effectiveness in ensuring code quality and coverage.

### New Windows AI feature records everything you've done on your PC

#### [Submission URL](https://arstechnica.com/gadgets/2024/05/microsofts-new-recall-feature-will-record-everything-you-do-on-your-pc/) | 49 points | by [quantisan](https://news.ycombinator.com/user?id=quantisan) | [28 comments](https://news.ycombinator.com/item?id=40426620)

Microsoft unveils a new AI-powered feature called "Recall" for Copilot+ PCs at the Build conference event. This feature allows Windows 11 users to search and retrieve their past activities on their PC, including app usage, communications, and web browsing. Despite encryption and local storage, privacy concerns arise due to the potential for unwanted access to user data. Recall takes snapshots of the screen at regular intervals, and users can search and access specific moments or events using these snapshots. However, the feature raises questions about user privacy, as anyone with access to the Windows account could view the recorded activities. Microsoft assures that the Recall index remains private, encrypted, and linked to a specific user account, with options to pause, stop, or delete captured content. The feature is exclusive to "Copilot Plus PCs" powered by Qualcomm's Snapdragon X Elite chips and has minimum storage requirements. Recall is currently in preview status, with plans to gather feedback and improve the user experience. The feature's announcement has sparked mixed reactions, with some users expressing privacy concerns and others seeing it as a smart marketing move by Microsoft.

The discussion on the submission about Microsoft's new AI-powered feature "Recall" for Copilot+ PCs at the Build conference included various perspectives. Some users raised privacy concerns about the potential for unwanted access to user data due to the feature taking snapshots of the screen at regular intervals, even though Microsoft assured that the Recall index remains private and encrypted. Other users mentioned technical challenges in addressing trust concerns with AI capabilities, such as E2E encryption and user control options. There were also discussions about Microsoft collecting user data for training AI systems, similarities with Google's data collection practices, and concerns about AI advancements and data privacy. Additionally, there were comments providing alternative perspectives and insights related to the topic. Overall, the discussion touched on privacy, data security, AI trust, user control, and corporate data collection practices.

### Windows Copilot Runtime

#### [Submission URL](https://blogs.windows.com/windowsdeveloper/2024/05/21/unlock-a-new-era-of-innovation-with-windows-copilot-runtime-and-copilot-pcs/) | 69 points | by [plurby](https://news.ycombinator.com/user?id=plurby) | [49 comments](https://news.ycombinator.com/item?id=40433425)

At the recent Build conference, Microsoft unveiled the groundbreaking Copilot+ PCs, a new category of Windows devices that are faster and more intelligent than ever. These PCs feature Neural Processing Units (NPUs) capable of delivering exceptional performance for AI workloads, making them up to 20 times more powerful and 100 times more efficient than traditional PCs. The Copilot+ PCs will debut in June with Qualcomm's Snapdragon X Series processors, offering developers a powerful platform to create innovative AI experiences.

Alongside the Copilot+ PCs, Microsoft introduced the Snapdragon Dev Kit for Windows, equipped with the same NPU technology for developers to experiment with advanced AI applications. This developer-focused kit boasts impressive specs, including a high-performance CPU, ample memory and storage, support for multiple external displays, and eco-friendly materials.

To empower developers further, Microsoft announced the Windows Copilot Runtime, an AI-infused platform that transforms Windows at its core to enable accelerated AI development. This runtime includes the Windows Copilot Library with pre-built AI models, tools for developers to bring their models to Windows, and new capabilities like Windows Semantic Index and Phi Silica API designed specifically for the Copilot+ PCs. Additionally, Microsoft is bringing native support for PyTorch and Web Neural Network (WebNN) Developer Preview to Windows, enhancing AI capabilities for web apps.

Microsoft is striving to democratize AI development by making Windows the most open platform for building innovative AI experiences. With the introduction of Windows Copilot Runtime, developers can leverage a comprehensive system that spans the entire Windows ecosystem, enabling them to create cutting-edge AI applications seamlessly. Don't miss out on the latest advancements in AI development; stay tuned for more updates from Microsoft's keynote at Build!

The discussion on Hacker News regarding Microsoft's unveiling of Copilot+ PCs mainly revolves around different aspects of the technology featured in these devices. Users shared their excitement about the new AI capabilities and the potential for running Linux on these PCs. Some users highlighted concerns about the environmental impact of the device packaging and the integration of recycled materials in manufacturing.

There was also a debate about the practicality and performance of AI features in these devices, with some users expressing skepticism about the utility of AI-focused features compared to traditional software development practices. Additionally, discussions touched on the comparison between the Copilot+ PCs and existing processors like Apple's M3/M4 and NVIDIA's AI capabilities, emphasizing the different approaches to AI processing and power efficiency.

Overall, the conversation included a mix of technical analysis, environmental considerations, and speculation about the future impact of Microsoft's new technology on the computing industry.

### Building an AI game studio: what we've learned so far

#### [Submission URL](https://braindump.me/blog-posts/building-an-ai-game-studio) | 270 points | by [FredrikNoren](https://news.ycombinator.com/user?id=FredrikNoren) | [280 comments](https://news.ycombinator.com/item?id=40426382)

The team at Braindump is taking a unique approach to game creation by integrating LLMs and generative AI into an AI game studio. With Braindump, you can build top-down/2.5D games or interactive worlds simply by typing prompts, allowing you to bring your dream game to life with the help of AI-generated assets and scripts.

In their recent update, the Braindump team shares their journey from initial prototypes to the current state of the platform, highlighting features like 3D model generation, multiplayer functionality, and an intuitive natural language prompting interface. Users can define units, abilities, populate game maps, create rules and logic, and even design 3D models using Meshy.

Two key challenges faced by the team include designing a user-friendly prompting UX and crafting a game API that enables the LLM to generate code effectively. By adopting an iterative prompting approach and providing structured blueprints and rules for code generation, Braindump aims to enhance the user experience and streamline the game development process.

If you're interested in exploring the possibilities of AI-driven game creation, consider signing up for the alpha release of Braindump to try out the platform and provide valuable feedback to the team. Join their Discord community or check out their TikTok for more insights into their innovative approach to building an AI game studio.

The discussion on the Braindump submission revolves around the use of AI in various creative fields such as web design, game development, and visual art. One commenter mentions the limitations of AI in understanding complex mechanics in game creation, while another highlights the potential for AI to assist in generating assets like animations, 3D models, and more efficiently. There is a debate about the level of sophistication AI can achieve in understanding and creating content based on natural language inputs.

Furthermore, there is a discussion on the challenges faced by AI in interpreting complex functional requirements written in plain English and the implications for creative industries like video games and movies. The topic of democratizing creative tools through AI and its impact on traditional creative roles is also touched upon, with opinions varying on the extent to which AI can revolutionize these industries. Additionally, issues related to the commoditization of creative work and the balance between technical advancements and human creativity are discussed.

### GitHub Introduces Copilot Extensions

#### [Submission URL](https://github.blog/2024-05-21-introducing-github-copilot-extensions/) | 35 points | by [emadabdulrahim](https://news.ycombinator.com/user?id=emadabdulrahim) | [7 comments](https://news.ycombinator.com/item?id=40430111)

GitHub has announced a game-changing update to Copilot with the introduction of GitHub Copilot Extensions. Developers can now tap into a wide range of partner tools and services directly from the IDE, enhancing the developer experience by enabling them to work seamlessly in natural language without switching between different platforms.
This new feature allows developers to access a variety of tools like DataStax, Docker, LaunchDarkly, Microsoft Azure, MongoDB, and more directly within GitHub Copilot Chat, Visual Studio, and VS Code. These extensions streamline workflows, providing developers with quick access to resources, documentation, and best practices.
For example, the LaunchDarkly extension allows developers to access documentation and best practices alongside their code, while the DataStax extension enables interaction with databases and application building with AstraDB. Additionally, the Sentry extension helps resolve pipeline issues using natural language.
Furthermore, Microsoft has introduced the GitHub Copilot for Azure extension, demonstrating the power of natural language development by assisting developers with Azure-related tasks, from selecting services to deploying applications.
To access these extensions, users can join the Copilot Partner Program and explore the expanding ecosystem of tools and services. The goal is to make GitHub Copilot the most intelligent and integrated AI platform, empowering developers worldwide to build and innovate effortlessly using natural language programming.
This update marks just the beginning of a more inclusive future for software development, where barriers are lowered, and innovation is accessible to everyone. With GitHub Copilot Extensions, the possibilities for collaboration and productivity in the development process are endless.

- **cmpalmer52** commented on the potential value of NET MAUI Copilot in aiding Xamarin Maui pre-release team training and documentation.
- **rohansood15** expressed interest in Sentry's use of a chat-based IDE interface and how it caters to developers preferring multi-tool multi-step workflows with background synchronous tasks.
- **bnchrch** brought up the topic of vertical integration, sharing concerns about Amazon's competitiveness following Microsoft's release of Azure Extensions. They discussed the potential productivity gains for developers using Azure and AWS extensions.
- **ralph84** and **mdnl** discussed the surprising fact that Amazon has not acquired Atlassian, GitLab, or Google, hinting at Microsoft's developer-focused DNA versus its advertising company image. They mentioned the synergy between developing platforms and cloud platforms, particularly how Google by Atlassian might have been a missed opportunity.
- **brtgy** humorously exclaimed their dismay at the thought of GitLab being acquired by a big corporation.
- **impulser_** mentioned that Google owns a 15% stake in GitLab, making it the largest shareholder of the company.

### AI Needs Enormous Computing Power. Could Light-Based Chips Help?

#### [Submission URL](https://www.quantamagazine.org/ai-needs-enormous-computing-power-could-light-based-chips-help-20240520/) | 45 points | by [jolieli](https://news.ycombinator.com/user?id=jolieli) | [39 comments](https://news.ycombinator.com/item?id=40425504)

Today's top story on Hacker News discusses the immense computing power needed for artificial intelligence (AI) and explores the potential for light-based chips to revolutionize the industry. As AI demands grow even faster than Moore's Law predicts, researchers are turning to optical neural networks that use photons instead of electrons for processing. These light-based systems offer advantages such as increased bandwidth, faster processing speeds, and higher efficiency compared to traditional electronic chips. The article delves into the use of light for AI dating back to the 1980s and highlights recent breakthroughs in matrix multiplication using optical systems. With companies like Lightmatter working on developing chips that combine electronic hardware with light-based interconnects, the future of AI computing may soon be illuminated by photons.

The discussion on the top Hacker News story encompasses various perspectives and insights regarding the use of light-based chips in artificial intelligence (AI) computing. 

One user explains the differences between bosons and fermions, highlighting the challenges of interactions with light and electrons. Another user appreciates an explanation of the technology, emphasizing the limitations of fiber optics in switching photon and electron signals quickly. In response, another user agrees with the challenges of using fiber optic cables and mentions the issue of latency in transitioning signals between photons and electrons.

The discussion then delves into quantum mechanics, with a user discussing the role of particles like photons and fermions in carrying information. The conversation expands to networking and the transmission of information over long distances, touching on the limitations and possibilities in current hardware development. A user adds historical context by comparing the transmission of energy in electrical power cables and the efficiency of photons in information flow on integrated circuits.

In another thread, the conversation shifts to the comparison of processing power between HITOP and Nvidia chips, leading to a discussion on computational efficiency and energy consumption. The implications of particle chips are explored, mentioning a potential increase in battery life and a decrease in energy usage compared to traditional electronic chips. Users also discuss the impact of AI-driven technologies on various industries like mobile phones.

Further discussions touch on the potential applications of light-based amplifiers and the challenges of optimizing resource usage with AI-driven techniques. The conversation transitions to the advancements in quantum computing and the considerations of utilizing carbon chips, logical chips, and particle chips as alternatives to traditional silicon-based chips. The potential for exponential growth in computing capabilities and the need to explore alternative technologies as silicon-based ones reach limitations are also highlighted.

Overall, the discussion provides a multi-faceted exploration of the advancements and challenges in AI computing, with users offering insights into the technical, theoretical, and practical aspects of implementing light-based chips in the industry.

### iTerm2 and AI Hype Overload

#### [Submission URL](https://xeiaso.net/notes/2024/ai-hype/) | 166 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [286 comments](https://news.ycombinator.com/item?id=40432446)

In the latest update of the popular macOS terminal emulator iTerm2, an AI integration feature has been introduced, allowing users to generate natural language commands using models such as GPT-3.5 and GPT-4. The new "Codecierge" feature guides users step-by-step through tasks by analyzing terminal contents. However, despite its utility, the inclusion of AI in iTerm2 has sparked backlash from users wary of AI hype and concerned about transparency and privacy issues.

Some users have expressed frustration over the AI integration being perceived as forced rather than optional, leading some to consider switching to alternative terminal emulators. The general sentiment reflects a weariness with the pervasive presence of AI in various tech tools and the lack of transparency in AI decision-making processes. The debate raises questions about user agency, open-source software practices, and the necessity of clear communication and choice in implementing AI features.

The broader context of AI saturation in the technology sector has contributed to a backlash against iTerm2's AI integration, highlighting concerns around user autonomy, data privacy, and the need for transparent AI systems. The controversy underscores the complex relationship between AI technology and user preferences, emphasizing the importance of informed choice and open dialogue in software development.

The discussion around the update of the iTerm2 terminal emulator with AI integration has sparked a debate among Hacker News users. Some users expressed frustration over the perceived forced inclusion of AI and its potential privacy issues. Others highlighted concerns about the saturation of AI in tech tools and the lack of transparency in decision-making processes. Some users discussed the limitations and ethical implications of AI assistance in software development, while others shared their experiences with AI assistants in their work environments. The conversation evolved to cover topics such as AI ethics, interview processes involving AI, and the impact of AI on job expectations. There were also discussions about the complexities of integrating AI features in software development, the importance of user choice, and the ethical considerations of introducing new features.
