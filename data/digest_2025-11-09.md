## AI Submissions for Sun Nov 09 2025 {{ 'date': '2025-11-09T17:15:27.507Z' }}

### The Principles of Diffusion Models

#### [Submission URL](https://arxiv.org/abs/2510.21890) | 214 points | by [Anon84](https://news.ycombinator.com/user?id=Anon84) | [23 comments](https://news.ycombinator.com/item?id=45866572)

What is it
- A concise monograph that puts diffusion, score-based, and flow-based generative models under one roof.
- Core thesis: all these methods share a time-dependent velocity field that transports a simple prior into the data distribution; sampling is solving a differential equation along this flow.

Key ideas
- Variational view: denoising step-by-step (VAE-flavored).
- Score-based view: learn ∇ log p_t(x) to push samples toward higher density (energy-based roots).
- Flow-based view: learn a smooth velocity that deterministically moves noise to data (normalizing-flow vibe).
- Practical topics: classifier/free guidance for controllable generation, efficient numerical solvers, and “flow-map” models that learn direct mappings between arbitrary times (think one-shot jumps instead of long trajectories).

Why it matters
- Gives a clean mental model that explains why SDE/ODE samplers, guidance tricks, and recent “consistency/flow-matching”-style methods are variations on the same backbone.
- Useful as a teaching resource and for practitioners choosing samplers, guidance strategies, or faster inference schemes.

Audience
- Readers with basic deep-learning background; math-forward but conceptual.

Link: https://arxiv.org/abs/2510.21890
DOI: https://doi.org/10.48550/arXiv.2510.21890

The discussion around the submission on diffusion models includes several key points and tangents:

1. **Related Educational Resources**:  
   - A user references Stefano Ermon's CS236 lectures on deep generative models, noting their availability on YouTube. Another wishes Stanford continued offering the course.

2. **Submission Guidelines Debate**:  
   - A subthread debates whether the submission violates HN’s repost rules, with a moderator clarifying that significant updates or new attention justify resubmission. Users discuss proper etiquette for addressing HN in posts and avoiding low-effort submissions.

3. **Technical Terminology**:  
   - Humorous exchanges occur about the term “Fokker-Planck” (mentioned 97 times in the paper), including debates over hyphenation and searchability. One user jokes, “AI [is] definitely related to dashes.”

4. **Comparisons and Reactions**:  
   - The monograph’s unifying framework is likened to the comprehensive understanding of transformers in another context.  
   - A user quips about being intimidated by the math (“scared maths”), met with a playful “you’re scared” reply.

5. **Philosophical AI Debate**:  
   - A comment critiques current AI as “brute-forced intelligence,” sparking discussion on whether evolution and machine learning share parallels in compressing complex processes. Others argue intelligence emerges from learned algorithms, even if reasoning is not explicitly programmed.

6. **Document Length Reaction**:  
   - The 470-page length of the monograph prompts a humorous “FML” reaction, highlighting its daunting size.

**Overall Tone**: Mixes technical curiosity, humor, and meta-discussion about HN guidelines, with lighthearted debates on AI’s nature and the challenges of digesting dense academic work.

### Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican

#### [Submission URL](https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/) | 163 points | by [simonw](https://news.ycombinator.com/user?id=simonw) | [74 comments](https://news.ycombinator.com/item?id=45862802)

Simon Willison found a cheeky loophole to try the newly teased GPT-5-Codex-Mini before OpenAI ships a public API. Since the model is currently only exposed via the open-source Codex CLI and VS Code extension, he forked the Apache-2.0 Rust CLI and added a “codex prompt” subcommand that pipes your text directly through the same authenticated path the tool already uses—no private endpoints touched, just a smarter client.

The experiment doubles as a tour of Codex’s agenty internals. Using the CLI to build itself, he iterated on Rust changes to list models, set system prompts, and stream output. Early runs kept acting like a code-editing agent—spilling “reasoning summary” logs, trying to inspect a workspace, and refusing to just answer with SVG. Forcing a no-tools path initially hit a 400 “Instructions are not valid,” revealing how tightly the CLI couples prompts to its tool/sandbox assumptions. With more tweaks (and the --debug stream), he ultimately coaxes GPT-5-Codex-Mini into doing what he wanted—like drawing a pelican on a bicycle—and shares a video and full transcript. Takeaway: when an open-source client fronts a privileged backend, the boundary gets interesting, and agent wrappers can be surprisingly opinionated.

Here's a concise summary of the Hacker News discussion:

**Technical Experiment & Creativity**  
- Simon Willison's blog post ([linked](https://simonwillison.net/2025/Nov/9/pelican-bike-raytr/)) demonstrated using GPT-5-Codex-Mini via a modified Rust CLI to generate creative outputs like a pelican-on-bicycle SVG and benchmark tests. Users shared related AI-generated art examples (e.g., Claude and Gemini outputs).  
- The CLI project involved iterating with Codex to automate Rust builds, though initial attempts revealed rigid agent-like behavior (e.g., unwanted "reasoning summaries" and workspace inspections).  

**Debate on AI Tools & Skill Impact**  
- **Pro-AI Efficiency**: Some praised AI for simplifying tasks like Rust project setup (`cargo install`), debugging, and documentation. Willison highlighted using Codex to generate boilerplate code and streamline workflows.  
- **Concerns About Over-Reliance**: Others argued excessive delegation to LLMs risks eroding problem-solving skills, debugging intuition ("neglecting `cargo build` issues"), and deeper system understanding. Critics likened it to "copy-pasting Stack Overflow without learning."  
- **Middle Ground**: Several noted AI’s value for low-risk, repetitive tasks (e.g., linting, parallelizing commands) but emphasized critical thinking remains essential for complex decisions.  

**Rust/Cargo Learning Curve**  
- Users debated Rust’s build system (`cargo`), with some calling it intuitive for professionals but overwhelming for newcomers. Comparisons were made to PHP/C++ ecosystems, with Rust ranking 16th on TIOBE despite its hype.  
- Willison’s experiment sparked discussion on whether AI tools lower the barrier to entry or encourage "shortcut mentality" in learning new languages.  

**Community Reactions**  
- Humorous engagement with the pelican/bicycle theme contrasted with serious critiques of AI’s societal impact. Some dismissed fears as overblown ("bad actors exist in any tech"), while others warned of degraded learning in younger developers.  

**Key Takeaway**: The experiment showcased AI's potential to enhance coding workflows but ignited a broader debate on balancing automation with skill retention and system mastery.

