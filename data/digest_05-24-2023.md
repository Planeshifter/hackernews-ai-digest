## AI Submissions for Wed May 24 2023 {{ 'date': '2023-05-24T17:12:48.607Z' }}

### Show HN: Image background removal without annoying subscriptions

#### [Submission URL](https://pixian.ai/remove-image-backgrounds) | 310 points | by [jacobn](https://news.ycombinator.com/user?id=jacobn) | [99 comments](https://news.ycombinator.com/item?id=36064639)

Pixian.AI is a new background removal service that uses powerful GPUs and multi-core CPUs to analyze images and remove their backgrounds. The service is free while in beta, with long-lasting Pay-As-You-Go credit packs expected to be priced competitively once the beta ends. Pixian.AI has optimized every aspect of its business to maximize the quality and minimize the price of its service, with the aim of bringing background removal to graphics professionals and hobbyists at a "makes sense" price. The service currently supports JPEG, PNG, BMP, GIF, and WebP as input formats, and produces PNG as output.
The comments on the submission include discussions about other existing background removal services and their pricing and accuracy, as well as suggestions for improving the service. There is also discussion about using AI for image manipulation and the challenges and pricing associated with it. Some users have bookmarked the Pixian.AI service for future use, while others have recommended alternative services.

### QLoRA: Efficient Finetuning of Quantized LLMs

#### [Submission URL](https://arxiv.org/abs/2305.14314) | 282 points | by [Garcia98](https://news.ycombinator.com/user?id=Garcia98) | [97 comments](https://news.ycombinator.com/item?id=36064568)

A new approach to finetuning quantized language models has been presented in a paper called QLoRA by Tim Dettmers and three other authors. The approach reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. The team use QLoRA to finetune more than 1,000 models and provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations. They find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. The team release all of their models and code, including CUDA kernels for 4-bit training.

However, some users on Hacker News commented that the testing of the GPT-4 models was not comprehensive and may not be trustworthy for evaluation purposes. Other discussions revolved around the benefits and challenges of open-source AI models, and the importance of integrating AI models into existing systems and platforms. The discussion also touched on the limitations of AI models in processing messy and imperfect data and the challenges of AI integration into different platforms.

### Why the original transformer figure is wrong, and some other tidbits about LLMs

#### [Submission URL](https://magazine.sebastianraschka.com/p/why-the-original-transformer-figure) | 229 points | by [rasbt](https://news.ycombinator.com/user?id=rasbt) | [47 comments](https://news.ycombinator.com/item?id=36057183)

Sebastian Raschka shares four papers that provide a historical perspective on understanding transformers. The first paper discusses the discrepancy in the original transformer figure from Attention Is All You Need and suggests that Pre-LN works better than Post-LN. The second paper, written in 1991, proposes an alternative to recurrent neural networks called Fast Weight Programmers, which is similar to modern transformers. The third paper, Universal Language Model Fine-tuning for Text Classification, is noteworthy for proposing pretraining language models and transfer learning for downstream tasks. Lastly, the fourth paper discusses the use of transformers for image recognition and shows promising results. In the discussion, users share their views and ask questions about transformers, including their nature, working and advantages.

### DeviceScript: TypeScript for Tiny IoT Devices

#### [Submission URL](https://microsoft.github.io/devicescript/) | 184 points | by [glutamate](https://news.ycombinator.com/user?id=glutamate) | [94 comments](https://news.ycombinator.com/item?id=36059878)

Microsoft has released a technical preview for TypeScript for IoT, aimed at making it easier to develop applications for Internet of Things devices. This new solution offers familiar syntax and tooling for users, along with a small bytecode interpreter for devices with limited power, flash or memory. It also has a client/server architecture for sensors and actuators, debugging capabilities within Visual Studio Code, and simulation and testing features. Additionally, Microsoft has created a development gateway that will enable users to prototype cloud services, manage devices, deploy firmware, and access message queues. The preview is open for discussion and feedback.

Comments discuss the advantages of using Lua as an interpreter, the pros and cons of implementing TypeScript, and the challenge of developing languages for microcontrollers. Some users mention the success of MicroPython for rapid prototyping, and others bring up NanoFramework's compatibility with Raspberry Pi Pico.

### OpenAI Outage

#### [Submission URL](https://status.openai.com/incidents/jbt079x532bg) | 125 points | by [zurfer](https://news.ycombinator.com/user?id=zurfer) | [150 comments](https://news.ycombinator.com/item?id=36063166)

OpenAI has experienced elevated error rates in multiple engines, including text-davinci-003, the moderations endpoint, gpt4, and chatgpt, which affected API and chat.openai.com. While chatgpt has seen a recovery in rates, Whisper, and Turbo engines have also been impacted. The root cause has been identified, and the team is working on a fix, with OpenAI keeping users updated on the status of the incident. The comments on Hacker News mostly discuss the issue of SLAs (service-level agreements), with some users noting that OpenAI offers a decent SLA, while others argue that the price for an SLA is too high. Other commenters discuss the state of AI writing and the potential risks of relying too much on AI-generated text. Some users emphasize the importance of critical thinking and creativity, while others appreciate the value of AI in enhancing human communication.

### ChainForge: An open-source visual programming environment for testing prompts

#### [Submission URL](https://github.com/ianarawjo/ChainForge) | 116 points | by [azhenley](https://news.ycombinator.com/user?id=azhenley) | [10 comments](https://news.ycombinator.com/item?id=36056907)

ChainForge is an open-source visual programming environment designed to battle-test prompts to LLMs (Language Learning Models). It allows for quick and effective testing of prompt ideas and variations, comparison of response quality across prompt permutations and models, and immediate visualization of results across prompts, prompt parameters, and models using evaluation metrics. Currently in open alpha, ChainForge supports OpenAI models GPT3.5 and GPT4, Anthropic's Claude, Google PaLM2 (text-bison), and Alpaca 7B (through Dalai) at default settings. It is built on ReactFlow and Flask, and can be installed with Python 3.8 or higher via pip.

The comments on this submission discuss the importance of tracking signals, documenting collection strategies, and important UI frameworks for prompt building. One user shared their experience working on a project for keyword extraction and building smarter prompts with the help of frameworks. Another user mentioned that the current version of the project only supports Google Chrome and requested support for other browsers. However, another user pointed out that the project was probably not funded to cover browser compatibility issues. One user recommends not making assumptions about prompts and shares a similar tool they use. The rest of the comments express appreciation for the tool and praise the UI design.

### Dynaboard AI

#### [Submission URL](https://dynaboard.com/blog/dynaboard-ai) | 27 points | by [datarem](https://news.ycombinator.com/user?id=datarem) | [4 comments](https://news.ycombinator.com/item?id=36061839)

Dynaboard AI has launched a suite of AI features that accelerates the building of production-grade software regardless of complexity. The suite includes UI generation, code generation, and code refactoring. With UI generation, developers can quickly create UIs and forms for data-rich applications by simply typing prompts into the command bar. Dynaboard AI also generates JavaScript/TypeScript, SQL, and CSS and connects with a PostgreSQL, MySQL, or BigQuery database. The AI can modify existing apps using real-time filtering of data and responds to natural language prompts to provide always up-to-date dropdowns. Dynaboard AI's goal is to minimize the effort required to build and maintain apps with more AI-powered features to come.

The discussion surrounding Dynaboard AI's suite of features includes praise for its code refactoring capabilities. One commenter notes that the AI's ability to select list per defined components and generate correct formatting is impressive. The founder of Dynaboard AI also chimes in to provide more technical details on the company's AI-powered tools, such as code refactoring that works through recursive refinement loops and fetching relevant DB schema data for existing component data. The thread ends with the original poster expressing anticipation for future releases.

### Meta Open-Sources Computer Vision Foundation Model DINOv2

#### [Submission URL](https://www.infoq.com/news/2023/05/meta-dinov2-vision/) | 220 points | by [thread_id](https://news.ycombinator.com/user?id=thread_id) | [88 comments](https://news.ycombinator.com/item?id=36053592)

Meta has open-sourced DINOv2, a computer vision (CV) foundation model pretrained on a curated dataset of 142 million images. DINOv2, which is based on the Vision Transformer architecture, can serve as a backbone for several CV tasks, including image classification, semantic segmentation, depth estimation, and video action recognition. Meta said it plans to integrate the model, which helps AI systems reason on images in a richer way, into larger, complex systems that can interact with large language models. During tests, DINOv2 outperformed other self-supervised models and achieved comparable or better results than weakly-supervised models.

The top story on Hacker News is about Metaâ€™s release of DINOv2, an open-sourced computer vision (CV) foundation model, which can be used as a backbone for image classification, semantic segmentation, depth estimation and video action recognition tasks. The comments section highlights discussions about the benefits and drawbacks of open sourcing models, and how it affects businesses and competitors. Some users are optimistic about how open sourcing can improve software and encourage contributions from the community, while others see it as a potential threat to newer startups. Meanwhile, others point out the similarities between Meta and other tech giants like Google and Microsoft, and how they all compete with one another to release the best AI models.

### VanillaNet: The power of minimalism in deep learning

#### [Submission URL](https://arxiv.org/abs/2305.12972) | 33 points | by [pizza](https://news.ycombinator.com/user?id=pizza) | [5 comments](https://news.ycombinator.com/item?id=36058695)

Researchers have introduced VanillaNet, a neural network architecture that embraces simplicity in design, avoiding high depth, shortcuts, and intricate operations like self-attention. By being refreshingly concise, yet remarkably powerful, each layer is carefully crafted to be compact and straightforward, making it ideal for resource-constrained environments. The easy-to-understand and simplified architecture of VanillaNet opens new possibilities for efficient deployment, delivering performance on par with renowned deep neural networks and vision transformers, showcasing the power of minimalism in deep learning. The pre-trained models and codes are available for developers to try out for themselves.

The discussion about the submission revolves around the complexity of deep learning research and how the VanillaNet architecture embraces simplicity. One user notes that the abstract sounds like marketing copy, but praises VanillaNet for being refreshingly concise yet powerful. Another user raises concerns about the complicated training regimen and the fragility of the system when searching for hyperparameters. A comparison is made between VanillaNet and MobileNet, with VanillaNet being faster and more accurate on a server-class GPU. Another user points out that Transformers are not optimal for vision tasks that do not require processing large amounts of data.

### Nvidia shares spike 18% on forecast beat driven by A.I. chip demand

#### [Submission URL](https://www.cnbc.com/2023/05/24/nvidia-nvda-earnings-report-q1-2024.html) | 37 points | by [tim_sw](https://news.ycombinator.com/user?id=tim_sw) | [14 comments](https://news.ycombinator.com/item?id=36063758)

Nvidia has reported better-than-expected earnings for the first quarter of its fiscal year 2024 and given a bullish forecast for the current quarter. The chipmaker said it expected sales of around $11 billion in Q2, more than 50% higher than Wall Street estimates of $7.15 billion. The strong performance was driven by surging demand for data centre products, which saw sales of $4.28 billion, a 14% YoY increase, while the gaming division's revenue dropped 38% to $2.24 billion. The automotive division, including self-driving technologies, grew 114% YoY but stood at under $300m in sales for the quarter.

Some users believe that Nvidia's sales growth is unsustainable and that the hype around the company is overblown, recommending short-selling the stock. Others argue that Nvidia's dominance in the data center and AI computing markets justifies its high valuation and that the demand for its GPUs will continue to rise in the coming years. Some users also mention Nvidia's partnerships with AWS, Microsoft, and other large internet companies as a key factor in its growth story. One user points out that Nvidia's revenue from the gaming division has dropped significantly, although this is partially offset by the growth of its self-driving technology division. Overall, the discussion highlights the complex dynamics of the semiconductor industry and the challenges of predicting the future of high-growth tech companies.


