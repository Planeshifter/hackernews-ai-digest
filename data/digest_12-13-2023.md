## AI Submissions for Wed Dec 13 2023 {{ 'date': '2023-12-13T17:14:34.570Z' }}

### SMERF: Streamable Memory Efficient Radiance Fields

#### [Submission URL](https://smerf-3d.github.io/) | 578 points | by [duckworthd](https://news.ycombinator.com/user?id=duckworthd) | [136 comments](https://news.ycombinator.com/item?id=38632492)

Researchers from Google DeepMind and Google Research have introduced a new view synthesis approach called SMERF (Streamable Memory Efficient Radiance Fields) that enables real-time rendering of near-photorealistic scenes on commodity smartphones and laptops. Unlike previous methods that use either explicit scene representations or neural fields for ray marching, SMERF combines both approaches to achieve high quality and real-time performance. The researchers developed a hierarchical model partitioning scheme to increase model capacity while constraining compute and memory consumption. They also used a distillation training strategy to improve image fidelity by leveraging a state-of-the-art offline radiance field as a teacher model. SMERF outperforms existing real-time methods on large scenes, achieves faster rendering speeds, and is compatible with a wide variety of devices, including smartphones. The technology allows for full six degrees of freedom (6DOF) navigation within a web browser. The researchers have provided video demonstrations of SMERF's capabilities on various scenes, such as Berlin, NYC, London, and more. The code and pre-trained models are open source and can be accessed on GitHub.

The discussion on this submission covers a wide range of topics related to the technology and its applications:

- Some users express their amazement at the capabilities of the SMERF technology, particularly in terms of rendering photorealistic scenes in real-time on smartphones.
- There is a discussion about the potential applications of this technology in the real estate market, allowing users to virtually navigate properties in a realistic manner.
- Users share their experiences and thoughts on the quality of the rendered scenes, with comments about specific locations like Berlin and NYC.
- There are comments about the spooky and ghostly effects seen in some of the rendered scenes, particularly reflections and blurriness.
- Discussions also touch on the technical aspects of the technology, such as the challenges of 3D reconstruction and rendering highly reflective surfaces.
- Some users express interest in the code and models used in SMERF, requesting access to them or asking about the licensing.
- There is also a mention of other related technologies, such as Gaussian Splatting and the use of DSLRs for photogrammetry.
- Finally, there are comments expressing excitement about the advancements in VR technology and the potential for future developments.

Overall, the discussion highlights both the impressive capabilities of the SMERF technology and the various technical and practical aspects related to its use.

### The limitations of deep learning (2017)

#### [Submission URL](https://blog.keras.io/the-limitations-of-deep-learning.html) | 43 points | by [andrelaszlo](https://news.ycombinator.com/user?id=andrelaszlo) | [13 comments](https://news.ycombinator.com/item?id=38635452)

In a post from the book "Deep Learning with Python," the author discusses the simplicity of deep learning and how it operates in a geometric space. Deep learning models use parametric models trained with gradient descent to transform input data into output data. This transformation is broken down into simple geometric transformations performed by different layers in the model. The key is that the transformation must be differentiable to allow for gradient descent. The author compares this process to uncrumpling a paper ball in 3D. However, there are limitations to what deep learning can accomplish. Tasks that require reasoning, algorithmic-like data manipulation, and long-term planning are out of reach for deep learning models. Additionally, most programs cannot be expressed as continuous geometric transformations, making them difficult to learn. Increasing the number of layers and training data can only partially alleviate these limitations. The author also warns against anthropomorphizing deep learning models, as they do not truly understand the content they are working with.

The discussion on this post revolves around several points. 
One commenter argues that anthropomorphizing AI and treating it as if it has human-like consciousness is incorrect and stems from a narrow perspective on intelligence. They believe that animals possess various forms of intelligence and consciousness that are different from human cognition, and it is incorrect to attribute human-like qualities to AI.
Another commenter disagrees and suggests that AI does not possess significant cognitive abilities or intelligence similar to humans. They argue that animals have different types of intelligence and consciousness, and AI does not possess those qualities.
In response to the discussion on anthropomorphizing AI, another commenter brings up the limitations of deep learning. They discuss that it is not feasible for deep learning models to generate papers, codebases, or complex systems just by reading product descriptions. They argue that the complexity threshold for generating functioning code is quite high, and deep learning models would require multiple rounds of correction and a significant amount of time to achieve any level of success.
Another commenter points out that the original post from the book "Deep Learning with Python" has limitations in terms of its perspective on AI progress. They believe that progress has been slower than predicted, and there are still many challenges to overcome in natural language processing and generalization.

Overall, the discussion touches on the limitations of deep learning, the anthropomorphizing of AI, and the challenges in AI progress.

### Google Imagen 2

#### [Submission URL](https://cloud.google.com/blog/products/ai-machine-learning/imagen-2-on-vertex-ai-is-now-generally-available) | 237 points | by [geox](https://news.ycombinator.com/user?id=geox) | [178 comments](https://news.ycombinator.com/item?id=38628417)

Google Cloud has announced the general availability of Imagen 2 on Vertex AI, their advanced text-to-image technology. Imagen 2 allows customers to generate high-quality, photorealistic, and aesthetically pleasing images from natural language prompts. It also supports text rendering in multiple languages, logo generation, visual question and answering, and more. Imagen 2 is integrated with safety features to ensure responsible AI usage, including digital watermarking and safety filters. Customers such as Snap, Shutterstock, and Canva have already started leveraging Imagen API to enhance their products and services.

The discussion on Hacker News about Google Cloud's announcement of Imagen 2 on Vertex AI revolves around various topics. 
One user mentions trying to use Imagen 2 but facing issues with changing JavaScript variables, while another user points out that the documentation is incomplete. There is also a comment expressing disappointment in Google's presentation of their AI products.
The discussion then diverges into a comparison between Android and iOS, with users discussing the advantages and disadvantages of each platform.
Some users express frustration with Google's marketing tactics and difficulty in accessing AI tools like Imagen. Others mention the importance of stability and reliability in AI models and caution against cherry-picking impressive examples.
There is a comment about the difficulty in understanding composition instructions when generating images using AI models like Imagen, and a suggestion to use text-to-music generation as an alternative.
The discussion also touches on the nature of AI advancements and the challenges designers and illustrators face in adapting their work to different platforms.

Overall, the discussion covers a range of topics including technical issues, marketing strategies, and the complexities of generating images using AI models.

### Artificial intelligence systems found to excel at imitation, but not innovation

#### [Submission URL](https://techxplore.com/news/2023-12-artificial-intelligence-excel-imitation.html) | 118 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [109 comments](https://news.ycombinator.com/item?id=38627816)

Artificial intelligence (AI) systems excel at imitation but struggle with innovation, according to researchers at the University of California, Berkeley. While humans, including young children, are able to find novel uses for everyday objects, AI systems lack this ability. The researchers conducted experiments comparing the performance of AI language models with that of children and adults. They found that while the AI models could imitate human responses, their ability to innovate and find non-obvious solutions was lacking. The researchers suggest that AI systems act more like "libraries" or search engines, summarizing existing knowledge rather than creating new ideas. However, they also note that there is still much to be learned about AI and its potential for innovation in the future.

The discussion on the submission revolves around the topic of AI's ability to innovate compared to humans. Some comments argue that AI's lack of innovation is due to its composition and reliance on existing knowledge, while others point out that innovation requires a combination of randomness and composition. There is also debate about whether innovation should be based on random generation or tested combinations. Some users argue that AI models have limited training in text messages, while others believe that machines with higher fidelity connections to the world can manipulate objects and generate higher-level concepts. The limitations and potential of AI in terms of creativity and innovation are also discussed, with some users emphasizing the role of observation and experience in human creativity. Additionally, there is discussion about the difference in quality and content between AI-generated and human-generated content.

### Partnership with Axel Springer to deepen beneficial use of AI in journalism

#### [Submission URL](https://openai.com/blog/axel-springer-partnership) | 26 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [10 comments](https://news.ycombinator.com/item?id=38627619)

OpenAI has partnered with publishing house Axel Springer to integrate journalism into AI technologies. This collaboration will enhance the user experience of OpenAI's ChatGPT by incorporating recent and authoritative content from Axel Springer's media brands, such as POLITICO, BUSINESS INSIDER, BILD, and WELT. Users will receive summaries of selected global news articles, even those behind paywalls, with attribution and links to the full articles for transparency. The partnership aims to support independent journalism, improve content experiences, and create new financial opportunities. Additionally, Axel Springer's quality content will contribute to the training of OpenAI's large language models.

The discussion on the submission revolves around various aspects of the partnership between OpenAI and Axel Springer.

- One user criticizes Axel Springer's Bild-Zeitung and accuses it of being a sensationalist newspaper with poor journalistic ethics.
- Another user expresses disappointment with Axel Springer's content on Samsung phones' Upday app, referring to it as trash and suggesting that OpenAI should be careful about partnering with such companies.
- One user comments on the irony of OpenAI, a company known for its focus on AI ethics, integrating journalism from a publication accused of sticking to its own facts.
- The CEO of Axel Springer, Mathias Dopfner, is mentioned by a user in a negative light for allegedly using derogatory terms to describe East Germans and being politically biased.
- The potential dangers of AI-generated news and the impact on people's trust in journalism are discussed.
- A user shares a tweet from OpenAI announcing the partnership with Axel Springer.
- One user expresses concern about the inclusion of news in ChatGPT, suggesting that it could lead to biased or worrisome news consumption.

Overall, the comments highlight skepticism and concerns about the collaboration between OpenAI and Axel Springer, particularly in terms of the journalistic ethics and content quality of Axel Springer's media brands.

### QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models

#### [Submission URL](https://arxiv.org/abs/2310.16795) | 41 points | by [titaniumtown](https://news.ycombinator.com/user?id=titaniumtown) | [11 comments](https://news.ycombinator.com/item?id=38632390)

Researchers Elias Frantar and Dan Alistarh have developed a new compression and execution framework called QMoE, which allows for the practical compression of trillion-parameter models to less than 1 bit per parameter. This addresses the memory problem associated with large language models (LLMs) using mixture-of-experts (MoE) architectures. In their paper, titled "QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models," the authors describe how QMoE can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB, enabling the execution of trillion-parameter models on affordable commodity hardware. The framework achieves this with only minor accuracy loss and runtime overheads, making it a significant step toward more accessible and efficient deployment of large language models.

The discussion on Hacker News revolves around different aspects of the QMoE compression framework for trillion-parameter models. 
One user, "iTokio," comments that the affordable commodity hardware needed to run large models would include a single server with four NVIDIA A6000 and eight NVIDIA 3090 GPUs. They express excitement about the potential for affordable hardware.
Another user, "jtrnk," mentions that the cost of running models is reasonable at $4/hour, suggesting that the affordability of deployment is a significant advantage.
In response, user "wthnbrdm" discusses the cost of living in different countries and states that even in low-cost regions, the expenses for running large models can be too high.
A user named "nine_k" compares the cost of running models to the price of a hamburger, stating that if someone cannot afford a hamburger, then there may be problems with compressing trillion-parameter models.
User "vmch" humorously adds to the previous comment, saying that they cannot afford a hamburger either.
The user "sms" contributes by stating that running models for research purposes is affordable, especially since the starting points are small self-bootstrapped startups. However, they acknowledge that the expenses may become significant for data scientists working with full-scale models.
User "rnsr" suggests that NVIDIA's prices distort people's perception of affordability.
Moving on to the technical aspects of QMoE, user "krmkz" explains that QMoE can compress the 16 trillion-parameter SwitchTransformer-c2048 model to 160GB, achieving a compression ratio of 20x with 0.8 bits per parameter and only minor accuracy loss. They go on to explain briefly how QMoE achieves this compression level.
User "chssgck" expresses interest in whether QMoE exploits the low entropy of model parameters to achieve compression below 1 bit per parameter. They speculate that larger models might have smaller redundancy and warrant closer attention.
User "cynydz" suggests that sparse models might have negligible entropy, leading to almost zero compression using standard compression algorithms.
Lastly, user "kslm" offers a simple comment, stating "Nice."

### 2nd Batch of the A16Z Open Source AI Grant

#### [Submission URL](https://a16z.com/announcing-our-latest-open-source-ai-grants/) | 37 points | by [rajko_rad](https://news.ycombinator.com/user?id=rajko_rad) | [9 comments](https://news.ycombinator.com/item?id=38632827)

The announcement of the second batch of a16z Open Source AI Grant recipients has been made. The program aims to support the open-source AI ecosystem by providing grant funding to developers and small teams. This cohort focuses on two areas: tools for training language models and models and communities built around visual AI. The recipients include Common Crawl, Axolotl, SkyPilot, LMSys, LLaVA, Deforum, and Lucidrains. These projects contribute to strengthening the open-source AI ecosystem and advancing the field.

The discussion around the submission includes various comments about the different projects mentioned. Here are the key points:
- One user mentions that the support from a16z is significant for advancing the field of self-teaching process learning using Transformers in language models. They note that there are many implementations of Transformer-related papers in PyTorch, making it one of the largest publicly available collections.
- Another user points out that the grant recipients are not disclosed in the article, which sparks a brief conversation.
- There is a discussion about GPU strain monitoring, with one user mentioning that a GPU tool they checked showed a GPU utilization of 43%. Another user shares their love for this kind of technology.
- One user makes a comment about a hanging mobile, which is unrelated to the main topic.
- The mention of "Axolotl" in the submission title leads one user to think of the fictional creature from the Dune franchise. Another user clarifies that "Axolotl" refers to a type of salamander, and provides links to the creature's information.
- One user expresses surprise at the financial cost of the Common Crawl project, noting that it seems quite high for crawling a massively bloated, modern web.

Overall, the discussion touches on topics such as self-teaching process learning, GPU strain monitoring, the Dune franchise, and the cost of web crawling.

### First Impressions with Google Gemini

#### [Submission URL](https://blog.roboflow.com/first-impressions-with-google-gemini/) | 80 points | by [zerojames](https://news.ycombinator.com/user?id=zerojames) | [25 comments](https://news.ycombinator.com/item?id=38630349)

Google recently announced Gemini, a new Large Multimodal Model (LMM) that can process text, images, and audio. The Roboflow team analyzed Gemini's performance across various computer vision tasks and found that it excelled in some areas but struggled in others. Gemini is capable of answering questions about text, images, and audio. It launched with demos that showcase its ability to write code, explain math problems, find similarities between images, and more. However, there were claims that one or more demos were edited, raising doubts about the extent of Gemini's capabilities. Gemini has three versions: Ultra, Pro, and Nano. The Ultra model, which is currently unavailable, reportedly outperforms other LMMs on academic benchmarks. The Pro model is designed to scale across different tasks, while the Nano model is intended for use on mobile devices.

To run Gemini, you can use the Google Cloud Vertex AI Multimodal playground or send requests to the Gemini API. The API documentation provides more information on how to integrate Gemini into your applications. The Roboflow team evaluated Gemini on four computer vision tasks: Visual Question Answering (VQA), Optical Character Recognition (OCR), Document OCR, and Object Detection. Gemini performed well in some tests, accurately counting coins in an image and identifying a movie from a screenshot. However, it struggled with OCR, providing incorrect responses when asked to read a serial number or extract text from an image. Gemini's performance varied compared to other LMMs. For example, LLaVA, BakLLaVA, and CogVLM performed well in some tests where Gemini struggled. Overall, while Gemini shows promise in its multimodal capabilities, there are areas where it can be further improved.

You can try Gemini yourself using the Google Cloud Vertex AI Multimodal playground or explore its capabilities on the Roboflow Gemini playground page.

The discussion on the submission about Gemini, Google's new Large Multimodal Model (LMM), touched on various points:

- One commenter shared their experience with the web interface, mentioning intermittent performance in object detection and regularly running tests.
- There was speculation about whether Gemini could solve captchas related to safety.
- Some users commented on the readability and SEO optimization of the article, expressing a desire for more optimized articles that are easier to read.
- The analysis of Gemini's performance was discussed, with one commenter pointing out that Gemini struggled with certain tasks such as OCR but performed well in others.
- The formatting of the article was criticized for condensing the content too much and not providing sufficient depth, resulting in a summary that didn't fully capture the details.
- There was feedback on the inconsistencies and lack of clarity in the linking within the article, as well as repetitive screenshots that didn't provide much value.
- One commenter mentioned that they didn't find the article interesting enough to read it in Safari's reader mode.
- A comment pointed out that the discussion wasn't filtered by an AI prompt, which caused the responses to not flow smoothly.
- Some users discussed the possibility of using Gemini for data generation and training purposes.
- There was a question about how to achieve empty responses from the model using the HTTP API.
- Comparison between Gemini and GPT4 was mentioned, with Gemini reportedly outperforming GPT4 in some tests.
- There was an exploration of using GPT4 Vision directly through the API and analyzing its responses to image-related prompts.
- The effectiveness of Gemini's response to a prompt about counting coins was debated, with some users expressing doubts about the intelligent reasoning behind the answer.
- Overall, there were comments appreciating the analysis and discussing Gemini's performance in comparison to other models.

### GM says it's dropping Apple CarPlay and Android Auto because they're unsafe

#### [Submission URL](https://jalopnik.com/gm-drops-apple-carplay-android-auto-unsafe-phone-1851093013) | 181 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [415 comments](https://news.ycombinator.com/item?id=38622476)

General Motors (GM) is facing criticism for its decision to drop Apple CarPlay and Android Auto in favor of its in-house system, Ultifi. To defend its decision, GM claims that the popular phone mirroring programs actually pose safety risks by encouraging drivers to use their phones while behind the wheel. GM's head of product for infotainment, Tim Babbit, cited stability issues with CarPlay and Android Auto, such as bad connections and slow responses, which lead drivers to pick up their phones and take their eyes off the road. GM believes that if their in-house system is robust enough, drivers will be less likely to rely on their phones for their infotainment needs. The Ultifi system, debuting in the 2024 Chevy Blazer EV, uses Google apps like Maps and Assistant for enhanced voice controls. Additionally, GM is hoping to profit from driver data and subscription services through the Ultifi system. The success of this gamble remains to be seen as more GM vehicles integrate with Ultifi from next year.

The discussion on Hacker News revolves around the decision by General Motors (GM) to drop Apple CarPlay and Android Auto in favor of its in-house system, Ultifi. Some users sympathize with GM's position, noting that phone mirroring programs like CarPlay and Android Auto can be unreliable and may encourage drivers to use their phones while driving. Others argue that GM's decision is driven by self-interest and a desire to profit from driver data and subscription services. The discussion also touches on the reliability of infotainment systems in general, with users sharing their experiences with different car brands. Some users express concerns about the increasing control that Apple and Google have over the automotive industry, while others believe that vehicle manufacturers should focus on building their own in-house systems. Overall, the discussion highlights the varying opinions on the role of phone mirroring programs and the future of infotainment systems in cars.

