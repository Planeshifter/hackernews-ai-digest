## AI Submissions for Tue Dec 19 2023 {{ 'date': '2023-12-19T17:09:45.282Z' }}

### Borges and AI

#### [Submission URL](https://arxiv.org/abs/2310.01425) | 34 points | by [alexmolas](https://news.ycombinator.com/user?id=alexmolas) | [15 comments](https://news.ycombinator.com/item?id=38693120)

The paper titled "Borges and AI" by Léon Bottou and Bernhard Schölkopf explores the connection between large language models (LLMs) and artificial intelligence (AI) through the imagery of Jorge Luis Borges, a famous 20th-century writer known for his works in magical realism and postmodern literature. The authors argue that understanding LLMs and AI through the lens of Borges' literary concepts can provide a new perspective on the relationship between language modeling and artificial intelligence. This paper challenges the common science fiction-based imagery surrounding AI and dives into a more nuanced understanding of the phenomenon at hand.

The discussion around the submission "Borges and AI" on Hacker News covers a range of perspectives and interpretations of the paper. Some users comment on Borges as their favorite writer and the influence of his works on the article. Others provide links to collections of Borges' short stories and essays for further reading.

One user points out the difficulty of finding meaningful information in large language models (LLMs) due to their tendency to generate nonsensical outputs. They mention the challenge of lacking a created index to easily find relevant information.

Another user argues that the definition of artificial intelligence (AI) is often misunderstood, and suggests that it is not necessarily based on the concept of a killer machine like Terminator or HAL. They mention their own experience working on AI since 1998, focusing on planning and non-player characters in video games.

There is also discussion around the paper's use of Borges and its connection to LLMs. Some suggest that the metaphor of Borges' Library of Babel, which contains incomprehensible texts produced by humans, is not applicable to LLMs. They argue that LLMs struggle to handle new tasks and cannot perform the type of reasoning humans can.

One user sees a flaw in the approach of the paper, claiming that it lacks clear conclusions and only offers insights without developing a theory.

The discussion then delves into a debate about the capabilities of LLMs and how they can aid in understanding models and fine-tuning.

There is a mention of Funes, a character from Borges' works with exceptional memory, and a user expresses confusion about attributing consciousness to LLMs, considering it a terrible idea.

Overall, the discussion explores different perspectives on the connection between Borges' literature and AI, as well as the capabilities and limitations of LLMs.

### TuneNN: A transformer-based network model for pitch detection

#### [Submission URL](https://github.com/TuneNN/TuneNN) | 107 points | by [CMLab](https://news.ycombinator.com/user?id=CMLab) | [38 comments](https://news.ycombinator.com/item?id=38694719)

TuneNN is a transformer-based network model for pitch detection in musical instruments. The model aims to capture the timbre of musical notes by considering various factors like harmonic relationships, harmonic strengths and weaknesses, instrument resonant peaks, and structural resonant peaks over time. It utilizes web audio and tensorflow.js for an online experience. The model employs different types of spectra, such as the STFT spectrum, Bark spectrum, and Cepstrum, to extract relevant features. These features are then processed using a sliding adjacent windows approach with a transformer-based network model. TuneNN supports tuning for 12+ instrument types. You can find more information and try it out at aifasttune.com.

The discussion on the submission "TuneNN: A Transformer-Based Network Model for Pitch Detection in Musical Instruments" on Hacker News covered various aspects of pitch detection and related topics. Here are some key points from the discussion:

- One commenter highlighted the complexity of pitch detection, stating that it is not solved by using Fast Fourier Transform (FFT) alone. They mentioned that determining the fundamental frequency is a challenging task and that simple physical measurements may not be sufficient for accurate pitch detection.
- Another user shared a link to an article discussing missing fundamentals and how they can affect perceived pitch. They explained how different tones and musical instruments can produce different harmonics and harmonic frequencies, which can impact the perception of pitch.
- A user mentioned the CREPE model and its high latency in instrument pitch recognition. They also shared a link to the TuneNN model's website and expressed interest in trying it out.
- One commenter provided a summary of the TuneNN model, mentioning its use of transformer-based network modeling to capture the timbre of musical notes and support tuning for over 12 instrument types.
- The license of TuneNN was a topic of discussion, with one user asking about the license and another sharing a link to the PESTO model, which learns pitch prediction with a self-supervised objective.
- The cost of tuning apps and their comparison with traditional methods was debated. Some users mentioned that software-based tuning techniques can be cost-effective, while others argued that professional tuning can involve additional nuances and complexities.
- A user shared their interest in implementing the Nebula1 algorithm for pitch detection and another user mentioned the McLeod Pitch Method as their favorite pitch detection method.
- The topic of licensing and open-source implementations came up, with one user discussing issues related to licensing the YIN and PYIN implementations of pitch detection algorithms.
- The effectiveness of the TuneNN model compared to traditional digital signal algorithms was discussed, with one user noting its significantly higher accuracy and robustness.
- The relevance of pitch detection to specific sounds, such as smoke alarms or 3D printer collisions, was discussed briefly.
- A user faced an error related to microphone permission while running the TuneNN website and mentioned their system configuration involving Ubuntu, KDE, and Firefox.

Overall, the discussion covered various perspectives on pitch detection, licensing, open-source implementations, and the effectiveness of the TuneNN model compared to traditional algorithms.

### A Mathematical Perspective on Transformers

#### [Submission URL](https://arxiv.org/abs/2312.10794) | 72 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [6 comments](https://news.ycombinator.com/item?id=38699331)

The paper "A mathematical perspective on Transformers" by Borjan Geshkovski and his colleagues explores the inner workings of Transformers, which are a fundamental component of large language models. The authors develop a mathematical framework for analyzing Transformers as interacting particle systems, revealing the emergence of clusters over time. This study offers new perspectives for mathematicians and computer scientists alike. The paper delves into subjects such as Machine Learning, Analysis of PDEs, and Dynamical Systems. Overall, this research contributes to a deeper understanding of Transformers and their applications.

In the comments on Hacker News, there is a mix of reactions to the submission about the paper on the mathematical perspective on Transformers. Some users express interest in the abstract and look forward to reading the research. One user mentions that they are interested in understanding the extraction skills of large language models and identifying relevant topology. 

There is one comment expressing disappointment because they were expecting designs of robots or something similar. 

Another user suggests that the study could also be approached from a statistical physics perspective.

### VideoPoet A large language model for zero-shot video generation

#### [Submission URL](https://sites.research.google/videopoet/) | 119 points | by [fchyan](https://news.ycombinator.com/user?id=fchyan) | [39 comments](https://news.ycombinator.com/item?id=38702141)

VideoPoet is a powerful language model that can generate high-quality videos based on text prompts. It can produce a wide range of visually stunning scenes, such as a dog listening to music, a robot cat eating spaghetti, and a golden retriever wearing VR goggles in Paris. VideoPoet can also generate audio to match a given video without any text guidance. This model is capable of multitasking on various video-centric inputs and outputs, including text-to-video, image-to-video, stylization, and outpainting tasks. It can create videos in square or portrait orientation, and even generate long videos by predicting one-second video clips repeatedly. Get ready to be amazed by the creative possibilities of VideoPoet!

The discussion about the VideoPoet submission on Hacker News covers various aspects of the model and its applications. Some users highlight the impressive results achieved by VideoPoet, noting that it can generate high-quality videos based on word prompts. They mention examples such as an 8K HD prompt engine and creative outputs like a dog listening to music or a robot cat eating spaghetti.

Others point out the technical aspects of the model, discussing the underlying technologies used, such as VQGAN+CLIP Stable Diffusion. They also mention the potential dangers of relying on AI-generated content and its impact on human employment.

There is a discussion about the commercialization of AI products and the role of companies like RunwayML and Google in bringing AI technology to the market. Some users express skepticism or disappointment with Google's promotion and suggest that the claims made by the company might be exaggerated.

There are also references to other AI models and their capabilities, such as image-to-video generation and the potential impact on artistic professions. The potential of VideoPoet for personal entertainment, including TikTok short video storytelling, is also discussed.

Overall, the discussion covers topics like the technical aspects of VideoPoet, the commercialization of AI, AI-generated content's impact on employment, and the entertainment value of AI models like VideoPoet.

### The Illustrated GPT-2: Visualizing Transformer Language Models (2019)

#### [Submission URL](https://jalammar.github.io/illustrated-gpt2/) | 209 points | by [epberry](https://news.ycombinator.com/user?id=epberry) | [5 comments](https://news.ycombinator.com/item?id=38691583)

The Illustrated GPT-2 is an in-depth exploration of the architecture and inner workings of the OpenAI GPT-2 language model. The GPT-2 is a transformer-based model trained on a massive dataset to generate coherent and passionate essays. This post dives into the self-attention layer of the GPT-2 and explains how it enables the model to produce such impressive results. The author also explains the evolution of transformer blocks and discusses applications of transformer models beyond language modeling, such as machine translation, summarization, transfer learning, and music generation. If you're fascinated by the capabilities of machine learning models like GPT-2, this post is a must-read.

The discussion includes a few different comments. 

- "xnsh" shares several resources related to the topic, including links to the Illustrated Transformer, Beyond Illustrated Transformer, and LLM Visualization.
- "tlsnb" provides an excellent explanation of the self-attention mechanism and recommends exploring tensor network-like diagrams and examples. 
- "3abiton" mentions that recent posts on the topic have gained traction and discusses the changes from GPT2 to GPT4.
- "kridsdale1" adds to the discussion by mentioning the significant changes in the GPT3 architecture, including the use of mixture of experts models and the increase in dimensionality of embedding vectors.
- "Der_Einzige" compliments the author, Jay Alammar.

Overall, the comments provide additional resources, explanations, and insights related to the architecture and capabilities of language models like GPT-2.

### UK plan to digitise wills and destroy paper originals "insane" say experts

#### [Submission URL](https://www.theguardian.com/society/2023/dec/18/ministry-of-justice-plan-to-destroy-historical-wills-is-insane-say-experts) | 159 points | by [ilamont](https://news.ycombinator.com/user?id=ilamont) | [205 comments](https://news.ycombinator.com/item?id=38699007)

The UK Ministry of Justice is facing criticism for its proposal to destroy millions of historical wills in order to save on storage costs. The plan involves digitising and then discarding around 100 million paper originals of wills dating back over 150 years, with the aim of saving £4.5 million ($5.9 million) annually. Historians and archivists have called the proposal "insane" and "sheer vandalism," expressing concern that important historical records could be lost. While the government plans to keep the originals of wills belonging to famous individuals, such as Charles Darwin and Princess Diana, others may be destroyed after 25 years. Critics argue that the physicality of the original documents is important to understanding the context and significance of the wills.


The discussion around the submission on Hacker News focused on several different aspects of the UK Ministry of Justice's proposal to destroy historical wills. Here are some key points:

- Some users questioned the necessity and wisdom of destroying the original paper wills, arguing that they hold historical and cultural significance that cannot be replicated by digital copies. They expressed concern about the loss of physical artifacts and the potential for digital data loss or cyber attacks.
- Others pointed out that digitizing the wills could make them more accessible and facilitate easier search and retrieval. They also mentioned the possibility of implementing measures to ensure the integrity and authenticity of the digital copies.
- The discussion touched on the importance of physical documents in historical and legal contexts, as well as the challenges and risks associated with long-term preservation of digital records. Some users highlighted the importance of redundancy and the need for multiple copies of records.
- There was also mention of the cost-saving aspect of the proposal, with some arguing that digital storage could be a more cost-effective solution in the long run compared to maintaining physical records.
- Users debated the potential risks of relying solely on digital records, including data loss or corruption, the need for technological infrastructure to support long-term preservation, and the issue of changing file formats and technology.
- Lastly, there were discussions about the role of government in managing and preserving archives, with users expressing different opinions about the government's responsibility and the potential impact of cost-saving measures on historical records.

Overall, the discussion on Hacker News reflected a range of perspectives on the proposal to destroy historical wills in favor of digitization. Some users emphasized the importance of physical artifacts and the potential risks of relying solely on digital records, while others highlighted the benefits of digitization for accessibility and cost-saving.

### Andrew Ng: 'Do we think the world is better off with more or less intelligence?'

#### [Submission URL](https://www.ft.com/content/2dc07f9e-d2a9-4d98-b746-b051f9352be3) | 17 points | by [mgreg](https://news.ycombinator.com/user?id=mgreg) | [7 comments](https://news.ycombinator.com/item?id=38702791)

Andrew Ng, a computer scientist known for his work in artificial intelligence (AI), argues that fears of AI leading to doomsday scenarios are overhyped. Ng, who has been involved in groundbreaking AI research projects, believes that regulators who buy into the alarmist narrative around AI will only benefit vested interests. He advocates for open-source AI development and criticizes government efforts to overly regulate the technology. Ng also demonstrates the capabilities of open-source AI models on his laptop, running inference without the need to send data to the cloud. While he acknowledges the limitations of these smaller models, he sees their potential for simple tasks like brainstorming and basic information retrieval.

The discussion on this submission involves several commenters sharing their thoughts on the topic. 

One commenter, xchp, criticizes the article for oversimplifying the complexity of the issues surrounding AI by presenting a simplistic narrative that ignores essential details and nuances.

Another commenter, artninja1988, responds to xchp's comment with confusion, as they only read the headline of the article and did not fully understand the discussion.

There is a mention of an interview with Andrew Ng, the subject of the submission, by patrickhogan1.

Another commenter, jbrkr, expresses their view that the intelligence in the world is not concentrated but distributed, and that concentrating intelligence in one place can be detrimental. They further mention that distributed individual and regional governance can be harmful to society.

In response to jbrkr's comment, ntnllrvd argues that humans benefit from intelligence that is more broadly distributed, which helps in mitigating existential threats. However, they also note that the extent to which non-human intelligence in the world can be considered intelligence is questionable and subject to change.

Overall, the discussion touches on the complexity of AI and its potential impact, with varying opinions on the concentration of intelligence, the benefits of distributed intelligence, and the nature of non-human intelligence.

### Turquoise taillights tell you this Mercedes is driving autonomously

#### [Submission URL](https://arstechnica.com/cars/2023/12/turquoise-taillights-tell-you-this-mercedes-is-driving-autonomously/) | 28 points | by [addaon](https://news.ycombinator.com/user?id=addaon) | [15 comments](https://news.ycombinator.com/item?id=38698854)

Mercedes-Benz has received approvals from authorities in California and Nevada to test out a new car-to-human communication feature. The automaker will use turquoise-colored marker lights to indicate when its partially automated driver assistance feature, Drive Pilot, is operating. Drive Pilot is a Level 3 system, allowing the driver to take their hands and eyes off the road at speeds of up to 40 mph. This approval makes Drive Pilot the first Level 3 system to gain regulatory approval for deployment. The marker lights, chosen for their differentiation from other colored lights on the road, are intended to signal to other road users that the vehicle is operating autonomously.

The discussion on Hacker News about Mercedes-Benz's car-to-human communication feature involves various topics and perspectives. 

One user points out that international standards usually use a different color to signify autonomous control in self-driving cars. They mention that in Japan, green lights are slightly blue, as the Japanese language evolved differently when it comes to traffic lights. Another user adds that this can cause confusion for people who are colorblind.

There are discussions about the usefulness of the turquoise marker lights in indicating the vehicle's intentions to other road users. One user thinks that it can be helpful, but there might be challenges in understanding the level 3 autonomous driving terminology and differences between car manufacturers. Another user suggests using fluorescent square lights to signal different ADAS activities, referring to the iconic lighting in the movie Close Encounters of the Third Kind.

Some users discuss colorblindness and its implications for traffic lights. One user explains that for a colorblind person, a green traffic light might appear gray. Another user mentions that traffic lights have specific designs to help identify them, and that colorblindness can make it harder to distinguish colors while driving or walking.

There is a discussion about the location and design of lights on vehicles to help with identification. One user shares a gradient of different types of colorblindness, while another user suggests using the location rotation to help with identification.

One user raises concerns about driving behind a car that is operating autonomously, suggesting that it may be difficult to respond to sudden changes in lane position. Another user suggests that the behavior of autonomous vehicles in passing can vary and may pose risks, such as aggressive passing or unpredictable lane changes.

Overall, the discussion covers topics such as the use of colors to signify autonomous control, the challenges for colorblind individuals, and safety concerns regarding the behavior of autonomous vehicles on the road.

### An In-depth Look at Gemini's Language Abilities

#### [Submission URL](https://arxiv.org/abs/2312.11444) | 118 points | by [tbruckner](https://news.ycombinator.com/user?id=tbruckner) | [68 comments](https://news.ycombinator.com/item?id=38695583)

A recent paper titled "An In-depth Look at Gemini's Language Abilities" explores the language abilities of Google Gemini models, comparing them to the OpenAI GPT series. The authors provide a third-party, objective comparison with reproducible code and transparent results, evaluating the models across 10 datasets that test various language abilities such as reasoning, question answering, math problem solving, translation, code generation, and instruction following. The analysis shows that Gemini Pro performs slightly inferior to GPT 3.5 Turbo in terms of accuracy across all benchmarked tasks. The paper also discusses reasons for this under-performance, including difficulties with mathematical reasoning, sensitivity to multiple-choice answer ordering, and content filtering. However, areas where Gemini demonstrates high performance include generating non-English languages and handling longer and more complex reasoning chains. The paper provides code and data for reproducibility.

The discussion on Hacker News revolves around the recent paper on Gemini's language abilities and includes various perspectives on the topic. 

One user points out the inaccuracy of the Chatbot Arena Leaderboard in predicting model performance compared to human judgment and suggests using 5 years of performance work and competency SAT scores as a better evaluation metric. Another user provides a link to a paper arguing that GPT-4 matches controlled crowd-sourced human preferences at an 80% agreement level, making it a scalable and explainable approximation of human preferences. 

There is a discussion about the inclusion of other interesting models, such as the Phi-2 model and Solar-107B, in the leaderboard. Another user mentions the significance of performance differences between models and the capabilities demonstrated in benchmark domains. A user raises the issue of non-blind voting results and the lack of identification of the winning model in conversations. 

There are discussions regarding the filtering of votes and the quality improvement of voting results based on filtering conversation length and consistency. Some users express confusion about the inclusion of avatars instead of humans in the evaluation process. 

The size and performance of Mixtral, a model missing from the paper, are discussed, with users pointing out its rank on the Chatbot Arena Leaderboard. The accuracy of OpenAI's leaderboard and the need for non-blinded voting results are debated. 

There is a discussion on the difference between Gemini Ultra and Mixtral, and a user comments on the withdrawal of an arXiv article due to inappropriate sourcing, mentioning the confusion caused by the article's claims. The GPU compute time and effectiveness in discarding company results are also mentioned. 

The origins of MistralAI and the involvement of individuals from Deepmind and Google Brain in its development are discussed.

