## AI Submissions for Tue Dec 03 2024 {{ 'date': '2024-12-03T17:11:39.866Z' }}

### AI poetry is indistinguishable from human poetry and is rated more favorably

#### [Submission URL](https://www.nature.com/articles/s41598-024-76900-1) | 103 points | by [lr0](https://news.ycombinator.com/user?id=lr0) | [187 comments](https://news.ycombinator.com/item?id=42306857)

A recent study published on Nature highlights a fascinating development in the world of AI-generated poetry: readers are struggling to tell it apart from human-authored works. The research involved two experiments with over 16,000 non-expert poetry readers who were asked to identify whether poems were written by AI or by renowned poets. Surprisingly, participants only achieved an accuracy rate of 46.6%, suggesting a significant challenge in distinguishing the two.

What’s even more intriguing is that the study found participants were more inclined to mistakenly categorize AI poems as human-written rather than the actual human-authored ones. The elements that contributed to this misidentification included favorable evaluations of the AI-generated works, particularly in areas like rhythm and beauty. This led readers to prefer the simplicity of AI poetry over the often complex nature of human poems, which they might misinterpret as incoherent.

Previous studies on AI-generated artwork have hinted at similar patterns of misjudgment. As AI continues to evolve, especially with large language models producing texts that closely mimic human writing, it raises new questions about creativity, art, and the human touch in writing.

The findings of this study add to a growing conversation about our perceptions of AI and creativity, suggesting that AI’s advances in generating poetry might indeed be “more human than human,” while also inviting readers to reconsider their biases towards AI-generated content.

The discussion on Hacker News regarding the study of AI-generated poetry reveals a varied perspective on the implications of AI's ability to produce work that closely resembles human-created art. Some commenters, like "thrwwycmm," raise questions about the methodology and challenges in comparing AI-generated poetry to that of established poets such as Walt Whitman or Sylvia Plath. They express concerns about the difficulty in evaluating poetic complexity and significance in AI versus human contributions.

Others, such as "jrdklws," suggest that the study highlights a broader issue with literary appreciation, noting that there might be a diminishing interest in traditional literary poetry among general readers, which could impact their judgments. They emphasize the importance of understanding both poetry and AI's capabilities when interpreting the results of the study.

Commenters also reflect on the notion of popularity and familiarity, suggesting that readers may prefer simpler, AI-generated forms due to their accessibility, compared to the complexities and depth found in human-authored poetry. As the conversation unfolds, points about the need for differentiation in assessing artistic merit and the potential biases readers might bring to their evaluations of AI-generated content emerge.

Overall, the thread illustrates an ongoing debate over AI's role in creative fields and the evolving perceptions of art, emphasizing a need for deeper inquiry into how AI's advancements can coexist with traditional human artistry.

### MTA's A.I. bus cameras issue mistaken parking violations

#### [Submission URL](https://www.nbcnewyork.com/investigations/mta-bus-camera-issue-mistake-parking-violations/6020986/) | 81 points | by [croes](https://news.ycombinator.com/user?id=croes) | [108 comments](https://news.ycombinator.com/item?id=42308682)

In a technologically charged misstep, New York's Metropolitan Transportation Authority (MTA) has issued nearly 3,800 erroneous parking tickets due to a malfunction in its AI-powered bus lane cameras. The tickets were particularly directed at vehicles parked lawfully on the M79 and Bx35 routes. Among those affected was George Han, who received ten violations for being parked legally, raising concerns about the system's reliability.

Drivers like Johnatan Cuji shared similar frustrations, pointing out that photo evidence accompanying their tickets clearly showed their vehicles parked in legal zones. The MTA admitted that the cameras had not been programmed correctly and were actively misidentifying legal alternate-side parking as violations. Thankfully, the agency has vowed to reverse all erroneous tickets and refund any associated payments.

As concerns around AI systems deepen, Han emphasized the necessity for greater oversight in deploying such technologies. The company behind the cameras, Hayden AI, has a hefty $83 million contract for their installation and maintenance. Despite the hiccup, the MTA boasts that bus commute speeds have improved by approximately 5% since the rollout, though violations have surged dramatically, with more than 293,000 vehicles caught blocking bus lanes in 2024 alone.

As the MTA plans to enhance its automated enforcement, this incident serves as a reminder of the need for caution and thorough checks when integrating AI into everyday practices.

In the discussion prompted by the MTA's erroneous parking tickets, participants expressed varied frustrations regarding automated ticketing systems and their reliability. Users shared personal experiences of receiving unjust tickets based on AI misidentification, similar to the MTA incident. Some pointed out systemic issues where human oversight is lacking in modern enforcement technologies.

One commenter discussed their challenges with wrongful charges related to vehicle registration issues, suggesting that AI could hinder the fairness of legal processes in cases of mistaken identity. There were references to Kafkaesque experiences in self-publishing and other areas, highlighting how bureaucratic processes can feel disempowering.

Others debated the implications of strict enforcement of laws when AI systems fail, expressing concern over the lack of accountability and oversight. Discussions included broader reflections on human processes, the need for fair juridical standards, and the potential for machine errors to escalate into severe consequences, including criminal charges.

Overall, the conversation underscored widespread skepticism about the integration of automated systems in enforcement, emphasizing the necessity for a balance between technology and human intervention to safeguard fairness.

### Show HN: Copper – Open-source robotics in Rust with deterministic log replay

#### [Submission URL](https://github.com/copper-project/copper-rs/wiki/Copper-Release-Log) | 158 points | by [gbin](https://news.ycombinator.com/user?id=gbin) | [35 comments](https://news.ycombinator.com/item?id=42302026)

The latest release of the Copper project, version 0.5.0, brings a host of exciting new features and crucial enhancements aimed at improving performance and usability for developers. Key highlights include a groundbreaking deterministic log replay capability, allowing deterministic outputs for deterministic tasks—ideal for consistent results in complex applications. The release also introduces an aligner task that synchronizes multiple inputs for coordinated data processing, particularly valuable in sensor fusion scenarios.

Moreover, the team has simplified the codebase by removing unnecessary lifecycle traits from task implementations, easing the development process. On the compatibility front, Windows users will benefit from enhanced support, including a mock for cu_ads7883.

The team has also ensured extensive bug fixes for stability in simulations, notably improving balancebot-sim's reliability upon exit. Other enhancements include named output mapping for tasks, better handling of time validity instances, and overall clean-up to maintain a tidy code environment. 

In a nod to continuous improvement, previous releases (0.4.1 and 0.4.0) also introduced features like Iceoryx2 support, improved simulation capabilities, and enhancements for cross-platform compatibility. This steady evolution cements Copper’s position as a vital tool for developers focused on real-time data processing and simulation tasks.

In the Hacker News discussion surrounding the latest release of the Copper project (version 0.5.0), several key points were highlighted by various users, primarily contrasting its architecture with that of ROS 2 (Robot Operating System). 

1. **Architecture Comparison**: Users noted the differences in approach between Copper and ROS 2, particularly in how the two handle multi-processing versus single-process architectures. Copper's focus on deterministic log replay capabilities and simplified codebase was praised, indicating potential advantages in robotic applications that require consistent performance.

2. **Performance Insights**: Some participants emphasized that Copper's design facilitates lower latency and enhanced logging, making it suitable for real-time applications. The performance metrics shared suggested significant improvements in latency and speed compared to the existing decentralized message-passing structures found in ROS 2.

3. **Concerns about ROS 2**: Some comments raised concerns regarding the inherent limitations of ROS 2, particularly the complexities introduced by its network transparency and the potential latency issues stemming from its default settings. There were opinions that the centralized messaging system could hinder performance in real-time robotics projects.

4. **Reactions to Copper**: The deterministic capabilities of Copper sparked enthusiasm among users, with some indicating that its features are particularly beneficial for developing and testing complex robotics systems. The potential for Copper to fill gaps in the existing ecosystem was discussed, as well as its implications for simplifying certain developmental processes.

5. **Robotics Framework Evolution**: A broader discussion on the evolution of robotics frameworks occurred, with many users recognizing Copper as a significant innovation that could pave the way for future advancements in the field. The importance of frameworks that prioritize performance and usability in robotics was reiterated, underscoring the need for continuous improvement in this rapidly evolving sector.

Overall, the conversation reflected a mix of excitement about Copper's advancements and critical analysis of the strengths and weaknesses of existing frameworks like ROS 2. Participants collectively acknowledged the growing complexity in robotics and the need for adaptable solutions.

### Show HN: I built an AI tool to analyze SEC filings the minute they're released

#### [Submission URL](https://docdelta.ca) | 60 points | by [docdeltaneer](https://news.ycombinator.com/user?id=docdeltaneer) | [56 comments](https://news.ycombinator.com/item?id=42310165)

**SEC Filings Insight Tool Launching Soon: AI-Powered Analysis and Alerts**

A groundbreaking tool for investors is on the horizon, aimed at transforming how SEC filings are analyzed. The new platform uses advanced AI technology to swiftly detect critical changes in SEC filings, helping users to interpret risk factors, management discussions, and vital financial metrics before the market reacts. 

The platform offers real-time alerts and deep competitive insights, with features such as critical change detection, financial metrics tracking, and comprehensive risk assessments. For example, recent filings from NVIDIA highlight their impressive performance with a 112% year-over-year growth driven by AI demand, despite facing regulatory challenges and supply chain complexities.

Users can choose from three subscription tiers catering to individual investors and professional firms, all designed to streamline SEC filing analysis, saving up to 85% of the time typically spent. The strong emphasis on AI-driven insights promises to empower investors with immediate and actionable information. Take advantage of a free basic account to explore how this tool can enhance investment strategies before its official launch!

The discussion surrounding the launch of an AI-powered SEC filings insight tool highlights a mix of engagement, skepticism, and excitement among users on Hacker News. Key points include:

1. **Competition and Pricing**: Several users mentioned the tool's pricing model, with subscriptions ranging from $20 to $6,000 per month. Some found it potentially overpriced compared to established services like Quartr, which offers a more affordable plan for accessing full-text searches.

2. **Effectiveness of AI**: While many expressed enthusiasm for AI's ability to process data quickly and effectively, there was skepticism about its practicality, particularly for retail investors. Users noted that AI might not significantly improve stock trading analytics over traditional methods, especially given the noisy nature of SEC filings.

3. **Market Dynamics**: Commenters discussed the broader implications of the tool in relation to market trends, including the impact of rapid changes in stock prices post-earnings announcements and how institutional investors might benefit more than individual ones.

4. **User Experience and Value**: Some users shared experiences with existing tools, praising both the speed and capability of their services, while others were concerned about the implied usefulness of the new tool for casual investors as investment strategies become increasingly complex.

5. **General Sentiment**: The sentiment overall reflected a cautious optimism, with many eager to see how effective the tool will be in practice, especially regarding real-time alerts and risk assessment features, which could offer significant advantages in a fast-paced trading environment.

In conclusion, while the anticipated launch of the SEC filings insight tool generated considerable interest, there remain questions about its overall value, practical effectiveness for different types of investors, and how it will compete with existing services in the market.

### Certain names make ChatGPT grind to a halt, and we know why

#### [Submission URL](https://arstechnica.com/information-technology/2024/12/certain-names-make-chatgpt-grind-to-a-halt-and-we-know-why/) | 46 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [17 comments](https://news.ycombinator.com/item?id=42304333)

In a revealing exploration of OpenAI's ChatGPT, a pattern has emerged where certain names consistently trigger the model to halt conversation, leaving users perplexed. Names such as "David Mayer," "Jonathan Zittrain," and "Jonathan Turley" have prompted the chatbot to mysteriously respond with errors or abruptly end discussions, a behavior attributed to hard-coded filters likely implemented to prevent the AI from making potentially harmful fabrications.

This chatter around the issue started when the Australian mayor Brian Hood discovered ChatGPT inaccurately branded him as a criminal, leading to a defamation threat and subsequent legal resolution that likely spurred the introduction of these filters. The consequences of such hard-coded protections raise concerns about targeted interruptions, leaving users vulnerable to adversarial manipulation, especially since these filters could inhibit information sharing about individuals with common names.

OpenAI has responded to the recent alarms, specifically noting that the "David Mayer" block was unintentionally flagged as a glitch and is being corrected. This revelation not only underscores the challenges surrounding AI's information processing but also highlights how emerging technology continues to navigate complex legal and ethical terrains. As AI chatbots evolve, the balance between safety and usability remains a pivotal discussion.

The discussion on Hacker News revolves around OpenAI's handling of certain names that trigger ChatGPT to halt conversation due to hard-coded filters. Users express frustration and humor about the AI's behavior, particularly referencing the case of David Mayer, who has become a symbolic example in the discourse.

Some commenters note that if a teacher or student with a common name like David Mayer were to use ChatGPT for class tasks, they might face difficulties due to the chatbot refusing to process their request. Others suggest that people might try to bypass the filters for fun, highlighting the challenges and absurdities of AI censorship.

There are also remarks about the implications of this automatic filtering, with discussions on how it could lead individuals to change their names to avoid issues with the AI or how it may reflect a broader trend of algorithmic constraints. Suggestions for handling the situation range from simply changing names in requests to the potential legal ramifications of such filters.

In general, the tone varies from lighthearted to critical regarding the effectiveness and rationale behind these filters, while some participants reflect on the impacts of AI's decision-making processes and the ethical dilemmas they raise.

