## AI Submissions for Mon Aug 07 2023 {{ 'date': '2023-08-07T17:11:02.785Z' }}

### How Zoomâ€™s terms of service and practices apply to AI features

#### [Submission URL](https://blog.zoom.us/zooms-term-service-ai/) | 322 points | by [chrononaut](https://news.ycombinator.com/user?id=chrononaut) | [167 comments](https://news.ycombinator.com/item?id=37037196)

Zoom, the popular video conferencing platform, has updated its terms of service to clarify how it uses customer data for AI features. The company has made it clear that it will not use audio, video, or chat customer content to train its AI models without the customer's consent. This move is part of Zoom's commitment to transparency and user control. The updated terms of service, which were changed in March 2023, affirm that customers own and control their own content, even if Zoom uses it for value-added services. The company also emphasizes that healthcare and education customers' content, including education records and protected health information, will not be used for AI training without their consent. Zoom recently introduced generative AI features, such as Zoom IQ Meeting Summary and Zoom IQ Team Chat Compose, which offer automated meeting summaries and AI-powered chat composition. Account owners and administrators have full control over enabling these features and can provide consent for training AI models using their customer content. Zoom also ensures that participants are notified when its generative AI services are in use during meetings. Overall, Zoom aims to provide transparency and empower its customers to make informed decisions about their Zoom accounts.

The discussion around the submission touches on several points. Some users express concerns about potential deception in Zoom's marketing and the terms of service, questioning whether users are truly giving informed consent. There is also discussion about the compatibility of end-to-end encryption with certain features and whether Zoom's terms of service actually constitute consent. Other users mention the importance of protecting sensitive health information and the need for legal agreements to ensure compliance. Some users bring up the issue of privacy and recommend alternative video conferencing platforms. There are also comments about the limited ability to analyze meeting content and the desire for exceptions in certain cases.

### British Gas starts to turn off Hive smart home devices forever

#### [Submission URL](https://www.t3.com/news/british-gas-starts-to-turn-off-hive-smart-home-devices-forever) | 169 points | by [mindracer](https://news.ycombinator.com/user?id=mindracer) | [150 comments](https://news.ycombinator.com/item?id=37030481)

Hive, the smart home brand owned by British Gas, has announced the shutdown of several of its security products. The Hive Nano 1 Hub, Hive Camera, and Hive Leak Sensor are all being discontinued in August and September 2023. These devices will stop working and will no longer connect to the Hive servers. The most significant shutdown is the Nano 1 Hub, as it is responsible for enabling all smart home features through the Hive app and smart speakers. However, Hive is offering 50% discounts on the Nano 2 Hub for existing Nano 1 users. Other products, such as the Boiler IQ WiFi, Hive HomeShield, Hive View indoor camera, and Hive View outdoor camera, will be discontinued in 2025. Customers will need to upgrade to the Nano 2 Hub to continue using Hive devices through the app.

The discussion on Hacker News includes various perspectives on the topic of Hive discontinuing its security products. Some users express frustration with companies shutting down connected systems and the inconvenience it causes for consumers. Others argue that open source software offers advantages in terms of cost and flexibility, citing examples of FOSS tools that programmers find useful. There is a debate about the value of open source hardware and how it compares to open source software. Some users mention the importance of considering non-technical factors in software development, such as user interface design. The discussion also touches on the challenges faced by independent developers and the benefits of open source software in different countries. Overall, the conversation highlights the complexities and trade-offs involved in the world of smart home technology.

### ChatGPT's odds of getting code questions correct are worse than a coin flip

#### [Submission URL](https://www.theregister.com/2023/08/07/chatgpt_stack_overflow_ai/) | 27 points | by [mikece](https://news.ycombinator.com/user?id=mikece) | [19 comments](https://news.ycombinator.com/item?id=37042223)

In a study conducted by Purdue University, it was found that OpenAI's chatbot, ChatGPT, gives incorrect answers to software programming questions over half of the time. The researchers analyzed ChatGPT's answers to 517 Stack Overflow questions and found that 52% of the answers were incorrect, while 77% were verbose. Despite this, the bot was able to fool a third of the participants in the study. The study also found that ChatGPT's answers were preferred 39.34% of the time due to their comprehensive and well-articulated language style. However, among these preferred answers, 77% were actually wrong. The researchers concluded that users often fail to identify errors in ChatGPT's answers, especially when the errors are not easily verifiable. The study also highlighted the persuasive power of ChatGPT's language style, which made completely wrong answers seem correct to participants.

The discussion on this submission revolves around the study conducted by Purdue University regarding OpenAI's chatbot, ChatGPT. Here are some key points from the discussion:

- RecycledEle comments that their computer programming questions were only correctly answered 48% of the time.
- Tkglly shares that they manually collected 1,517 questions, extracted the question body and tags, and fed them to ChatGPT to generate answers. They also mention using CSV files and an additional 2,000 questions with ChatGPT's Turbo API.
- Sam0x17 points out that ChatGPT was trained on questions, so it makes sense that it would struggle with coding questions that fall outside the training data.
- Jychng mentions that coding questions shouldn't be expected to have high accuracy, as the field evolves. Sam0x17 adds that true/false answers to programming questions are not useful.
- Lcff shares their personal experience, saying that ChatGPT sometimes provides partially correct answers but also offers helpful insights and time-saving tips in their Ruby programming world.
- Cnplxn suggests that 30% of participants finding ChatGPT's language style impressive is significant, while Mechanical_bear comments on the preference for wrong answers in programming questions.
- Kerb_ shares a positive experience with ChatGPT, mentioning that it helped install plugins for a Minecraft server and configure commands with near-perfect accuracy.
- 1B05H1N mentions that ChatGPT helps them understand and review code by rewriting it 50% of the time.
- Hppytgr brings up the scalability factors and the purpose of the study, suggesting that it aims to test a hypothesis.
