## AI Submissions for Tue Nov 07 2023 {{ 'date': '2023-11-07T17:11:23.878Z' }}

### Seeing like a bank

#### [Submission URL](https://www.bitsaboutmoney.com/archive/seeing-like-a-bank/) | 549 points | by [arkadiyt](https://news.ycombinator.com/user?id=arkadiyt) | [405 comments](https://news.ycombinator.com/item?id=38180477)

A recent article in The New York Times highlighted a concerning trend of banks closing customer accounts. This may not come as a surprise to those familiar with the issues faced by banks when it comes to organization and tracking money. The common theme in user experiences is that banks often appear disorganized and unreliable. So why does this happen across various aspects of banking, such as fraud, account closures, and foreclosures? The problem lies in the way banks track information. While they excel at ledger tracking, they struggle with other forms of truth. Some users find that their interactions with the bank feel like a never-ending loop, where previous promises, information shared, and historical context are forgotten. But how did banks end up in this situation? 
Like any bureaucratic system, banks rely on a formal system of recordkeeping. However, there is an unrecognized and often illegible shadow system that actually enables their operations. The interactions between these systems and their optimization for certain types of tracking result in many of the issues observed. The core system, which most banks use to conduct their primary banking activities, interfaces with other systems within the bank, including ledgers. But these systems, as a whole, fall short in representing reality as accurately as one might hope.
Banks, especially smaller ones, typically license their core system from third-party providers rather than developing bespoke systems. Over the years, these systems grow through the processes of software development, regulatory changes, and competitive pressures. No system can completely answer all user inquiries, and banks are aware that there will be occasional issues. While the front-end customer support has been largely automated, operational and customer support teams handle the more complex cases.
One major technological advance that has helped banks in recent decades is the implementation of ticketing systems. However, ticketing systems alone cannot solve all the problems. They enforce an invariant rule that ensures proper responsibility transfer between different subsystems or groups within the bank. But since the ticketing system is separate from the core system, integrating it with other subsystems poses new challenges and introduces new types of issues.
Banking systems are a combination of intentional design and accidental developments. They accumulate layers of complexity much like sedimentary layers. Consolidation within the banking industry further complicates matters as merged banks must run their systems in parallel while working on integration. This integration often results in one system surpassing the other, but elements of the losing system are retained indefinitely, requiring further integration efforts.
In conclusion, the issues faced by banks in tracking and managing customer accounts stem from the complexities of their recordkeeping systems and the challenges associated with integrating various subsystems. While ticketing systems have helped to some extent, the core system's limitations and the constant evolution of banking processes continue to present new obstacles.

The discussion around the submission revolves around the complex nature of banking systems and the challenges they face in terms of recordkeeping and customer support. Some commenters agree with the points made in the article, highlighting the difficulties banks face in managing their systems and the limitations of ticketing systems. Others share their personal experiences with customer support and suggest that human involvement in support processes is crucial. The discussion also touches on related topics such as the role of AI-generated content, the challenges of scaling systems, and the potential solutions to improve the banking industry. Additional resources, such as books on the subject, are recommended by users.

### Show HN: Roboco-op, a computational blackboard for efficient human/AI collab

#### [Submission URL](https://observablehq.com/@tomlarkworthy/robocoop) | 79 points | by [tlarkworthy](https://news.ycombinator.com/user?id=tlarkworthy) | [21 comments](https://news.ycombinator.com/item?id=38183641)

Today's top story on Hacker News is about a powerful tool called Observable, which allows users to build their own data visualizations. Whether you're a data professional or just someone interested in exploring data, Observable provides an interactive platform to create visualizations and share insights. The tool is being praised by the Hacker News community for its ease of use and ability to empower data teams. If you're looking to dive into the world of data visualizations, this might be the perfect tool for you. Check it out and start visualizing your data today!

The discussion on the submission about Observable, a tool for data visualizations, covers various topics. One comment suggests that they have experience working as a data scientist and mentions the tools they use, such as SQL, Python, Splunk, and Elastic. They also mention their interest in exploring new tools and techniques for visualization.

Another comment requests a clearer introduction to the article and mentions the difficulty in distinguishing between the AI-generated content and the human-written summaries.

A noteworthy comment explains that the AI-generated calls in the discussion are mixed with human-generated content, resulting in a bit of confusion. They suggest providing context and clarifications within the notebook to help with interpretation.

One user points out that the AI response's real value is in correcting child development, saving time, and solving hard tasks quickly. They see great potential in the tool for AI-generated tasks.

There is an unrelated comment about enjoying playing video games and finding cleaning a satisfying activity.

Another comment praises the tool and mentions that they are trying to harness its power.

A discussion arises regarding the format and modification of outputs in LLM Jupiter notebook environment. The conversation delves into the question of constructing an API for materialized calls and how to reconstruct the notebook context.

There is a mention of the impressiveness of the tool and a desire to understand its effects better.

A comment expresses intrigue and highlights the effectiveness of the tool.

Someone mentions how fantastic and resolving the tool seems to be for private libraries.

There is a comment pointing out a potential privacy issue due to the presence of an open API key in someone's notebook.

Another user shares their experience of sending a validated result back and receiving a broken code in return.

A comment suggests including more forward values selectively in cell values.

Someone responds with a humorous comment saying, "Stay troubled."

The final comment humorously says, "Dead [l]ev[y] year's coming."

### Adobe is selling fake AI images of the war in Israel-Gaza

#### [Submission URL](https://www.crikey.com.au/2023/11/01/israel-gaza-adobe-artificial-intelligence-images-fake-news/) | 67 points | by [doener](https://news.ycombinator.com/user?id=doener) | [10 comments](https://news.ycombinator.com/item?id=38179277)

Adobe is facing criticism for selling fake AI-generated images of the war in Israel-Gaza. Online publications have used these images without marking them as fake, leading to misinformation being spread on social media. Adobe allows people to upload and sell AI images on its stock image subscription service, Adobe Stock, but requires submitters to disclose whether the images were generated with AI. However, there is concern about the transparency of AI image use and whether audiences are able to recognize their use. RMIT senior lecturer Dr. T.J. Thomson highlighted that these images have the potential to mislead, distort reality, and disrupt our perception of truth.

The discussion surrounding the submission revolves around the criticism faced by Adobe for selling fake AI-generated images of the war in Israel-Gaza. Users discuss the need for Adobe to require submitters to disclose whether the images were generated with AI. Some highlight the potential for misinformation and distortion of reality caused by the use of AI-generated images. Others argue that there is a difference between stock images and fake AI-generated images in terms of impact on news stories. One user shares an article discussing the ethical implications of using stock photography in news articles. There is also a mention of the difficulty in finding the truth amidst propaganda and the potential consequences of engaging in misleading imagery.

### ELTP: Extending ELT for Modern AI and Analytics

#### [Submission URL](https://airbyte.com/blog/eltp-extending-elt-for-modern-ai-and-analytics) | 70 points | by [aaronsteers](https://news.ycombinator.com/user?id=aaronsteers) | [12 comments](https://news.ycombinator.com/item?id=38178297)

In a recent article, AJ Steers introduces the "ELTP" architecture to address common design mistakes in data pipelines for AI, analytics, and data engineering. The first mistake is designing everything as a single ETL operation, while the second mistake is assuming that the best place for processing data is also the best place to host it. The ELTP architecture, which stands for Extract, Load, Transform, and Publish, aims to prevent these mistakes. It involves performing the replication first (Extract and Load) as a standalone process, and then applying business logic and transformations after the data is safely landed in a database or data lake. The Publish step ensures efficient delivery of transformed data to downstream consumers and applications, including external SaaS applications, file stores, CRM systems, AI vector stores, and databases. Adding a Publish step to data architecture allows for sending data files to external systems, decentralizing analytic queries, and publishing to downstream applications and indexes.

The discussion revolves around the concept of the ELTP (Extract, Load, Transform, Publish) architecture and its application in data pipelines. 

One commenter points out that they don't understand the need for transforming unstructured data to structured data, while another criticizes the use of the term "dt" without proper context. They argue that ETL systems can handle both structured and unstructured data. There is a discussion on the complexity of designing ETL systems and the challenges of handling different data types.

The concept of Reverse ETL is mentioned, which refers to the process of sending data from data warehousing or analytics systems to other external systems or applications. Some commenters mention companies like Airbyte and Grouparoo that specialize in Reverse ETL.

There is a brief discussion on data flow interfaces, global DAG (Directed Acyclic Graph) sections, and the use of open-source AI pipeline systems.

Some commenters appreciate the clarity of the ELTP architecture and the distinction it provides between the process of landing data and controlling data. They explain that ELTP ensures reproducibility, efficiency, and performance in data processing.

There is a debate on the importance of the distinction between ELTP and Reverse ETL, with some arguing that the distinction is crucial for clear communication, while others believe it doesn't warrant separate terms.

One commenter mentions their experience with production data and the need for better integration boundaries and API delivery methods for Reverse ETL.

Overall, the discussion highlights various perspectives on the ELTP architecture and its potential benefits in data pipelines and data processing.

### The OpenAI Keynote

#### [Submission URL](https://stratechery.com/2023/the-openai-keynote/) | 116 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [71 comments](https://news.ycombinator.com/item?id=38177409)

The tech keynote, once a highly anticipated event, has lost its importance in recent years. Apple, for example, has completely eliminated its live presentations in favor of pre-recorded marketing videos. This shift reflects the fact that the most crucial questions around new products are now centered on marketing tactics rather than groundbreaking technological advancements. While iOS and Android have become mainstream, the future of technology lies in AI, but even the excitement around AI seems muted. However, the OpenAI developer conference showcased the immense interest in a consumer product with product-market fit. CEO Sam Altman delivered an engaging keynote, presenting new features and products that were available immediately. One standout announcement was GPT-4 Turbo, which includes six new features to improve usability and performance. Altman also announced that the OpenAI API would be cheaper, prioritizing lower prices to encourage increased experimentation. The keynote was followed by a brief interview with Microsoft CEO Satya Nadella, highlighting the collaboration between OpenAI and Microsoft in building the necessary infrastructure to support OpenAI's pricing.

The discussion on this submission covers a range of topics related to GPT models, their capabilities, and their potential applications. Some users point out the difficulties in getting correct reference documentation for GPT models and suggest improvements in this area. Others discuss the potential of GPT models in assisting with specific tasks and the need for specialized prompts. There is also speculation about OpenAI's strategy and the potential of genetically modified GPT models. Several users mention the challenge of building specialized agents and the benefits of allowing developers to work with AI models. Other points of discussion include the interface of GPT models, the potential investment in hardware by OpenAI, and the interaction between GPT models and human intent. The conversation touches on the relevance of GPT models in relation to Apple's Siri and the question of personal data privacy. Some users also mention Jony Ive's involvement with OpenAI and the potential impact of GPT models on the artificial intelligence industry.

### Buddhist office turns to Thai cyber police over AI-generated Facebook content

#### [Submission URL](https://thethaiger.com/news/national/buddhist-office-turns-to-thai-cyber-police-over-ai-generated-facebook-content) | 50 points | by [anigbrowl](https://news.ycombinator.com/user?id=anigbrowl) | [56 comments](https://news.ycombinator.com/item?id=38180112)

The National Office of Buddhism in Thailand has sought assistance from the Thai Cyber Police after discovering inappropriate content related to Buddhism on Facebook. The content, generated by AI, depicts Buddhist monks engaging in non-religious activities, such as playing musical instruments and racing on motorbikes. The images have raised concerns among the Buddhist community and are considered damaging to the image of the monastic community. The NOB has requested help to remove the inappropriate images and is investigating their origin. The use of AI to create defamatory images of monks is increasing, potentially leading to misunderstandings among those who see them.

The discussion around this submission on Hacker News covers various aspects of the topic. One user points out that the legal framework surrounding AI-generated content, while another user criticizes the lack of discussion on the actual content and its impact. Some users discuss the potential implications of AI-generated content for various religions and the need for protecting religious institutions. One user brings up the issue of Orientalism and its portrayal of Buddhism in Western culture. Another user makes a comparison between different religions and their adherents' behavior. Some users express concerns about the potential defamation and disrespect caused by AI-generated content, while others argue that it may be a freedom of speech issue. Overall, the discussion covers a range of perspectives on the topic.

### Automated, black-box method for jailbreaking GPT-4, Claude-2, Llama

#### [Submission URL](https://twitter.com/soroushjp/status/1721950722626077067) | 23 points | by [soroushjp](https://news.ycombinator.com/user?id=soroushjp) | [6 comments](https://news.ycombinator.com/item?id=38181330)

No worries, let's try this again! This AI will provide you with a daily digest of the top stories on Hacker News, summarizing these submissions in an engaging way.

The discussion revolves around the submission about a link to an arXiv paper. One user comments that they don't understand why people spend time on proprietary models instead of open-source models, considering the wastage of time. Another user suggests that it is the duty of hackers to explore more surprising and embarrassing things, which might be the reason why they don't stick to open-source models. Another user points out that uncensored and explicit content can be found on the internet, and even if one claims that it's uncensored, it may still have some limitations. The discussion then shifts to the topic of jailbreaking, with one user mentioning their dislike for the term and its association with GPT models. Another user jokingly comments about the lack of response in the context of jailbreaking and hints at the sometimes awkward prompts generated by AI. They go on to mention their experience in machine learning research and the vast amount of computing power used for distributed computing clusters. The conversation takes a humorous turn with mentions of unrelated topics like getting calculator inputs of "BOOBS," the hexadecimal value OxDEADBEEF, and a fictional game set in an imaginative world.

### Microsoft wants to use AI to reshape your gaming experience

#### [Submission URL](https://www.xfire.com/xbox-facing-backlash-recent-ai-partnership/) | 14 points | by [mdotk](https://news.ycombinator.com/user?id=mdotk) | [4 comments](https://news.ycombinator.com/item?id=38183438)

Microsoft's partnership with Inworld AI to bring advanced AI characters and dynamic experiences to Xbox games has sparked a heated debate within the gaming industry. While the collaboration aims to enhance game development and offer players unique gaming experiences, concerns about job security and the integrity of art have been raised. The video game industry, already facing layoffs, is wary of technologies that could automate production processes. Critics argue that generative AI may not match the quality of work produced by human professionals. However, Microsoft sees AI as an asset that will augment human creativity rather than replace it. The industry's response to these changes will shape the future of game development and the role of AI in creative industries.

The discussion on Hacker News about Microsoft's partnership with Inworld AI to bring advanced AI characters and dynamic experiences to Xbox games includes several comments. 

One commenter, "proc0," seems to be expressing their opinion on the partnership. Their comment suggests that the partnership might lead to the use of artificial intelligence in video games for generating levels, names, and extending dialogue. It seems like they are highlighting the potential value that AI could bring to game development.

Another commenter, "fty," simply states "dnt" which could be interpreted as a disagreement or opposition to the partnership but without any further explanation.

The last comment by "nthnldnsr" indicates that they have had positive experiences with games like Stardew Valley and Octopath Traveler. They express their intention to stick with these game titles, possibly implying that they prefer games that prioritize human creativity over AI-generated content. 

Lastly, the commenter "Raicuparta" adds to the discussion by mentioning that Octopath Traveler is a game developed by Square Enix.

Overall, the discussion seems to touch on different perspectives regarding the use of AI in game development, with some expressing concerns about the potential impact on creativity and others recognizing the potential benefits.

### Cruise confirms robotaxis rely on human assistance every 4 to 5 miles

#### [Submission URL](https://www.cnbc.com/2023/11/06/cruise-confirms-robotaxis-rely-on-human-assistance-every-4-to-5-miles.html) | 49 points | by [belltaco](https://news.ycombinator.com/user?id=belltaco) | [28 comments](https://news.ycombinator.com/item?id=38181095)

In response to allegations that its self-driving cars are not truly autonomous, GM-owned Cruise has confirmed that it employs remote assistants to provide wayfinding intel to the vehicles. Cruise CEO Kyle Vogt stated that the remote assistance team supports the cars about 2-4% of the time in complex urban environments. He explained that most assistance sessions are resolved quickly, with the remote assistants providing guidance through tricky situations. The confirmation follows the recent grounding of Cruise's driverless operations after a collision that injured a pedestrian in San Francisco. Vogt's comments clarify Cruise's use of human assistance and emphasize that the remote assistants do not remotely control the vehicles.

The discussion on Hacker News regarding the news about Cruise's use of remote assistants to support its self-driving cars touches upon several points. Some users express concern about the safety implications of the remote assistance, highlighting instances where the vehicles have dragged pedestrians or encountered potentially dangerous situations. Others argue that in complex urban environments, remote assistance can be necessary and beneficial, especially in optimizing human review of tricky situations. One user points out that the practice of remotely assisting vehicles on public roads may not be legally mandated, and another user discusses the impact of lobbying efforts on autonomous vehicle regulations. There is also a discussion about the role of AI in controlling people and the utility of AI in various settings. Some users mention Mechanical Turk as an example of human-assisted AI, and others discuss the advantages and acceptability of interventions by self-driving cars in certain situations. Additionally, there are comments about the difficulty of managing and intervening in heavy traffic and the impact of cost considerations on call centers. The discussions shift to the general perception of San Francisco and a debate about the transit opportunities and experiences in the city.

### GPT-4-turbo preliminary benchmark results on code-editing

#### [Submission URL](https://aider.chat/docs/benchmarks-1106.html) | 72 points | by [heliophobicdude](https://news.ycombinator.com/user?id=heliophobicdude) | [86 comments](https://news.ycombinator.com/item?id=38184426)

OpenAI has recently released new versions of their GPT-3.5 and GPT-4 models, and there is a lot of curiosity surrounding their coding capabilities compared to previous versions. To measure and evaluate the performance of these models, a code editing benchmark has been developed called Aider. Aider uses GPT to edit code in a local git repository and relies on a benchmark to assess its performance. The benchmark consists of 133 Python coding exercises from Exercism, where Aider gives GPT a stub code file and natural language instructions to complete the exercise. If the test suite fails, GPT is given the error output and asked to fix the code. Preliminary results show that the new GPT-4 model performs better than previous versions, with a 53% success rate in completing the exercises on the first try. However, due to rate limits imposed by OpenAI, the benchmarking process has been interrupted and requires frequent pausing and restarting. The GPT-3.5 models, including the latest November model, have been benchmarked using both whole and diff edit formats. The new GPT-3.5-turbo-1106 model completes the benchmark 3-4 times faster than previous versions, with a comparable success rate after the first try. Updates on the benchmark results will be provided as the rate limits allow.

The discussion on Hacker News revolves around the recent release of OpenAI's GPT-3.5 and GPT-4 models, specifically regarding their coding capabilities and performance. 

One user questions the claim that GPT-4 Turbo is faster and smarter than previous versions, suggesting that they haven't seen evidence of its improved understanding of code. Another user points out that the increased context size has a significant impact on the performance of the models. However, some users share their disappointments with other coding assistance packages, highlighting the challenges of training models with specific prompt types and providing feedback.

There is some debate about the performance comparisons between GPT-3.5 and GPT-4 Turbo, with one user suggesting that GPT-4 is worse in reasoning tasks. Another user provides their own non-code benchmark results, showcasing the performance of different versions of GPT models in a SAT-style reading comprehension test. Some users discuss the potential impact of Microsoft's GPU advancements on OpenAI's models.

The discussion also touches on the nature of GPT-4 and GPT-3.5 Turbo models, questioning whether they have been quantized or modified differently to achieve faster and cheaper inference. There are mentions of AI limitations and potential dangers, as well as comparisons to human productivity and employment implications.

Some users mention their experiences with GPT models and their coding capabilities, with one user noting the limitations of the ChatGPT interface and another user expressing the usefulness of Aider as a programming assistant. The limitations imposed by rate limits and the importance of training data are also discussed.

Finally, the conversation veers into the broader implications of AI and its potential to replace human jobs, with some users expressing concern while others argue that AI advancements have historically led to increased productivity and new job opportunities.

