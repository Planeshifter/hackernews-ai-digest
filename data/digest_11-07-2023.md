## AI Submissions for Tue Nov 07 2023 {{ 'date': '2023-11-07T17:11:23.878Z' }}

### Adobe is selling fake AI images of the war in Israel-Gaza

#### [Submission URL](https://www.crikey.com.au/2023/11/01/israel-gaza-adobe-artificial-intelligence-images-fake-news/) | 67 points | by [doener](https://news.ycombinator.com/user?id=doener) | [10 comments](https://news.ycombinator.com/item?id=38179277)

Adobe is facing criticism for selling fake AI-generated images of the war in Israel-Gaza. Online publications have used these images without marking them as fake, leading to misinformation being spread on social media. Adobe allows people to upload and sell AI images on its stock image subscription service, Adobe Stock, but requires submitters to disclose whether the images were generated with AI. However, there is concern about the transparency of AI image use and whether audiences are able to recognize their use. RMIT senior lecturer Dr. T.J. Thomson highlighted that these images have the potential to mislead, distort reality, and disrupt our perception of truth.

The discussion surrounding the submission revolves around the criticism faced by Adobe for selling fake AI-generated images of the war in Israel-Gaza. Users discuss the need for Adobe to require submitters to disclose whether the images were generated with AI. Some highlight the potential for misinformation and distortion of reality caused by the use of AI-generated images. Others argue that there is a difference between stock images and fake AI-generated images in terms of impact on news stories. One user shares an article discussing the ethical implications of using stock photography in news articles. There is also a mention of the difficulty in finding the truth amidst propaganda and the potential consequences of engaging in misleading imagery.

### ELTP: Extending ELT for Modern AI and Analytics

#### [Submission URL](https://airbyte.com/blog/eltp-extending-elt-for-modern-ai-and-analytics) | 70 points | by [aaronsteers](https://news.ycombinator.com/user?id=aaronsteers) | [12 comments](https://news.ycombinator.com/item?id=38178297)

In a recent article, AJ Steers introduces the "ELTP" architecture to address common design mistakes in data pipelines for AI, analytics, and data engineering. The first mistake is designing everything as a single ETL operation, while the second mistake is assuming that the best place for processing data is also the best place to host it. The ELTP architecture, which stands for Extract, Load, Transform, and Publish, aims to prevent these mistakes. It involves performing the replication first (Extract and Load) as a standalone process, and then applying business logic and transformations after the data is safely landed in a database or data lake. The Publish step ensures efficient delivery of transformed data to downstream consumers and applications, including external SaaS applications, file stores, CRM systems, AI vector stores, and databases. Adding a Publish step to data architecture allows for sending data files to external systems, decentralizing analytic queries, and publishing to downstream applications and indexes.

The discussion revolves around the concept of the ELTP (Extract, Load, Transform, Publish) architecture and its application in data pipelines. One commenter points out that they don't understand the need for transforming unstructured data to structured data, while another criticizes the use of the term "dt" without proper context. They argue that ETL systems can handle both structured and unstructured data. There is a discussion on the complexity of designing ETL systems and the challenges of handling different data types. The concept of Reverse ETL is mentioned, which refers to the process of sending data from data warehousing or analytics systems to other external systems or applications. Some commenters mention companies like Airbyte and Grouparoo that specialize in Reverse ETL.

There is a brief discussion on data flow interfaces, global DAG (Directed Acyclic Graph) sections, and the use of open-source AI pipeline systems. Some commenters appreciate the clarity of the ELTP architecture and the distinction it provides between the process of landing data and controlling data. They explain that ELTP ensures reproducibility, efficiency, and performance in data processing.

There is a debate on the importance of the distinction between ELTP and Reverse ETL, with some arguing that the distinction is crucial for clear communication, while others believe it doesn't warrant separate terms. One commenter mentions their experience with production data and the need for better integration boundaries and API delivery methods for Reverse ETL.

Overall, the discussion highlights various perspectives on the ELTP architecture and its potential benefits in data pipelines and data processing.

### The OpenAI Keynote

#### [Submission URL](https://stratechery.com/2023/the-openai-keynote/) | 116 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [71 comments](https://news.ycombinator.com/item?id=38177409)

The tech keynote, once a highly anticipated event, has lost its importance in recent years. Apple, for example, has completely eliminated its live presentations in favor of pre-recorded marketing videos. This shift reflects the fact that the most crucial questions around new products are now centered on marketing tactics rather than groundbreaking technological advancements. While iOS and Android have become mainstream, the future of technology lies in AI, but even the excitement around AI seems muted. However, the OpenAI developer conference showcased the immense interest in a consumer product with product-market fit. CEO Sam Altman delivered an engaging keynote, presenting new features and products that were available immediately. One standout announcement was GPT-4 Turbo, which includes six new features to improve usability and performance. Altman also announced that the OpenAI API would be cheaper, prioritizing lower prices to encourage increased experimentation. The keynote was followed by a brief interview with Microsoft CEO Satya Nadella, highlighting the collaboration between OpenAI and Microsoft in building the necessary infrastructure to support OpenAI's pricing.

The discussion on this submission covers a range of topics related to GPT models, their capabilities, and their potential applications. Some users point out the difficulties in getting correct reference documentation for GPT models and suggest improvements in this area. Others discuss the potential of GPT models in assisting with specific tasks and the need for specialized prompts. There is also speculation about OpenAI's strategy and the potential of genetically modified GPT models. Several users mention the challenge of building specialized agents and the benefits of allowing developers to work with AI models. Other points of discussion include the interface of GPT models, the potential investment in hardware by OpenAI, and the interaction between GPT models and human intent. The conversation touches on the relevance of GPT models in relation to Apple's Siri and the question of personal data privacy. Some users also mention Jony Ive's involvement with OpenAI and the potential impact of GPT models on the artificial intelligence industry.

### Buddhist office turns to Thai cyber police over AI-generated Facebook content

#### [Submission URL](https://thethaiger.com/news/national/buddhist-office-turns-to-thai-cyber-police-over-ai-generated-facebook-content) | 50 points | by [anigbrowl](https://news.ycombinator.com/user?id=anigbrowl) | [56 comments](https://news.ycombinator.com/item?id=38180112)

The National Office of Buddhism in Thailand has sought assistance from the Thai Cyber Police after discovering inappropriate content related to Buddhism on Facebook. The content, generated by AI, depicts Buddhist monks engaging in non-religious activities, such as playing musical instruments and racing on motorbikes. The images have raised concerns among the Buddhist community and are considered damaging to the image of the monastic community. The NOB has requested help to remove the inappropriate images and is investigating their origin. The use of AI to create defamatory images of monks is increasing, potentially leading to misunderstandings among those who see them.

The discussion around this submission on Hacker News covers various aspects of the topic. One user points out that the legal framework surrounding AI-generated content, while another user criticizes the lack of discussion on the actual content and its impact. Some users discuss the potential implications of AI-generated content for various religions and the need for protecting religious institutions. One user brings up the issue of Orientalism and its portrayal of Buddhism in Western culture. Another user makes a comparison between different religions and their adherents' behavior. Some users express concerns about the potential defamation and disrespect caused by AI-generated content, while others argue that it may be a freedom of speech issue. Overall, the discussion covers a range of perspectives on the topic.

### Microsoft wants to use AI to reshape your gaming experience

#### [Submission URL](https://www.xfire.com/xbox-facing-backlash-recent-ai-partnership/) | 14 points | by [mdotk](https://news.ycombinator.com/user?id=mdotk) | [4 comments](https://news.ycombinator.com/item?id=38183438)

Microsoft's partnership with Inworld AI to bring advanced AI characters and dynamic experiences to Xbox games has sparked a heated debate within the gaming industry. While the collaboration aims to enhance game development and offer players unique gaming experiences, concerns about job security and the integrity of art have been raised. The video game industry, already facing layoffs, is wary of technologies that could automate production processes. Critics argue that generative AI may not match the quality of work produced by human professionals. However, Microsoft sees AI as an asset that will augment human creativity rather than replace it. The industry's response to these changes will shape the future of game development and the role of AI in creative industries.

The discussion on Hacker News about Microsoft's partnership with Inworld AI to bring advanced AI characters and dynamic experiences to Xbox games includes several comments. 

One commenter, "proc0," seems to be expressing their opinion on the partnership. Their comment suggests that the partnership might lead to the use of artificial intelligence in video games for generating levels, names, and extending dialogue. It seems like they are highlighting the potential value that AI could bring to game development.

Another commenter, "fty," simply states "dnt" which could be interpreted as a disagreement or opposition to the partnership but without any further explanation.

The last comment by "nthnldnsr" indicates that they have had positive experiences with games like Stardew Valley and Octopath Traveler. They express their intention to stick with these game titles, possibly implying that they prefer games that prioritize human creativity over AI-generated content. 

Lastly, the commenter "Raicuparta" adds to the discussion by mentioning that Octopath Traveler is a game developed by Square Enix.

Overall, the discussion seems to touch on different perspectives regarding the use of AI in game development, with some expressing concerns about the potential impact on creativity and others recognizing the potential benefits.

### Cruise confirms robotaxis rely on human assistance every 4 to 5 miles

#### [Submission URL](https://www.cnbc.com/2023/11/06/cruise-confirms-robotaxis-rely-on-human-assistance-every-4-to-5-miles.html) | 49 points | by [belltaco](https://news.ycombinator.com/user?id=belltaco) | [28 comments](https://news.ycombinator.com/item?id=38181095)

In response to allegations that its self-driving cars are not truly autonomous, GM-owned Cruise has confirmed that it employs remote assistants to provide wayfinding intel to the vehicles. Cruise CEO Kyle Vogt stated that the remote assistance team supports the cars about 2-4% of the time in complex urban environments. He explained that most assistance sessions are resolved quickly, with the remote assistants providing guidance through tricky situations. The confirmation follows the recent grounding of Cruise's driverless operations after a collision that injured a pedestrian in San Francisco. Vogt's comments clarify Cruise's use of human assistance and emphasize that the remote assistants do not remotely control the vehicles.

The discussion on Hacker News regarding the news about Cruise's use of remote assistants to support its self-driving cars touches upon several points. Some users express concern about the safety implications of the remote assistance, highlighting instances where the vehicles have dragged pedestrians or encountered potentially dangerous situations. Others argue that in complex urban environments, remote assistance can be necessary and beneficial, especially in optimizing human review of tricky situations. One user points out that the practice of remotely assisting vehicles on public roads may not be legally mandated, and another user discusses the impact of lobbying efforts on autonomous vehicle regulations. There is also a discussion about the role of AI in controlling people and the utility of AI in various settings. Some users mention Mechanical Turk as an example of human-assisted AI, and others discuss the advantages and acceptability of interventions by self-driving cars in certain situations. Additionally, there are comments about the difficulty of managing and intervening in heavy traffic and the impact of cost considerations on call centers. The discussions shift to the general perception of San Francisco and a debate about the transit opportunities and experiences in the city.

### GPT-4-turbo preliminary benchmark results on code-editing

#### [Submission URL](https://aider.chat/docs/benchmarks-1106.html) | 72 points | by [heliophobicdude](https://news.ycombinator.com/user?id=heliophobicdude) | [86 comments](https://news.ycombinator.com/item?id=38184426)

OpenAI has recently released new versions of their GPT-3.5 and GPT-4 models, and there is a lot of curiosity surrounding their coding capabilities compared to previous versions. To measure and evaluate the performance of these models, a code editing benchmark has been developed called Aider. Aider uses GPT to edit code in a local git repository and relies on a benchmark to assess its performance. The benchmark consists of 133 Python coding exercises from Exercism, where Aider gives GPT a stub code file and natural language instructions to complete the exercise. If the test suite fails, GPT is given the error output and asked to fix the code. Preliminary results show that the new GPT-4 model performs better than previous versions, with a 53% success rate in completing the exercises on the first try. However, due to rate limits imposed by OpenAI, the benchmarking process has been interrupted and requires frequent pausing and restarting. The GPT-3.5 models, including the latest November model, have been benchmarked using both whole and diff edit formats. The new GPT-3.5-turbo-1106 model completes the benchmark 3-4 times faster than previous versions, with a comparable success rate after the first try. Updates on the benchmark results will be provided as the rate limits allow.

The discussion on Hacker News revolves around the recent release of OpenAI's GPT-3.5 and GPT-4 models, specifically regarding their coding capabilities and performance. 

One user questions the claim that GPT-4 Turbo is faster and smarter than previous versions, suggesting that they haven't seen evidence of its improved understanding of code. Another user points out that the increased context size has a significant impact on the performance of the models. However, some users share their disappointments with other coding assistance packages, highlighting the challenges of training models with specific prompt types and providing feedback.

There is some debate about the performance comparisons between GPT-3.5 and GPT-4 Turbo, with one user suggesting that GPT-4 is worse in reasoning tasks. Another user provides their own non-code benchmark results, showcasing the performance of different versions of GPT models in a SAT-style reading comprehension test. Some users discuss the potential impact of Microsoft's GPU advancements on OpenAI's models.

The discussion also touches on the nature of GPT-4 and GPT-3.5 Turbo models, questioning whether they have been quantized or modified differently to achieve faster and cheaper inference. There are mentions of AI limitations and potential dangers, as well as comparisons to human productivity and employment implications.

Some users mention their experiences with GPT models and their coding capabilities, with one user noting the limitations of the ChatGPT interface and another user expressing the usefulness of Aider as a programming assistant. The limitations imposed by rate limits and the importance of training data are also discussed.

Finally, the conversation veers into the broader implications of AI and its potential to replace human jobs, with some users expressing concern while others argue that AI advancements have historically led to increased productivity and new job opportunities.

