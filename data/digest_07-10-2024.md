## AI Submissions for Wed Jul 10 2024 {{ 'date': '2024-07-10T17:11:25.007Z' }}

### Vision language models are blind

#### [Submission URL](https://vlmsareblind.github.io/) | 413 points | by [taesiri](https://news.ycombinator.com/user?id=taesiri) | [170 comments](https://news.ycombinator.com/item?id=40926734)

A recent study by researchers from Auburn University and the University of Alberta reveals that cutting-edge Vision Language Models (VLMs) such as GPT-4o and Gemini-1.5 Pro, which excel at image-text tasks, struggle with basic visual tasks like counting line intersections and identifying overlapping circles. The VLMs performed poorly on tasks that seemed easy for humans, indicating that their visual capabilities might be akin to a person with myopia or even an intelligent blind person making educated guesses.

In one task, the VLMs were asked to count the number of intersections between two 2-segment linear functions on diagrams, and the models showed subpar performance. Another task involved determining if two circles were overlapping or touching, with the VLMs exhibiting inconsistent results, especially at smaller distances. Additionally, the study explored the VLMs' ability to identify specific letters circled within words, showing varying degrees of accuracy across different models.

Despite their success in many language-related challenges, the study highlights the limitations of VLMs in visual perception tasks that are fundamental for human vision. The findings prompt further investigation into improving the visual understanding capabilities of these advanced language models.

The discussion on the submission about the limitations of Vision Language Models (VLMs) highlights various perspectives. Some users point out the challenges VLMs face in basic visual tasks compared to their success in language-related challenges. They discuss how these models struggle with tasks like counting intersections and identifying overlapping circles, which are fundamental for human vision. A user mentions the need for further development in VLMs' visual understanding capabilities. Additionally, there are comments about the discrepancy between the models' performance on visual tasks and their success in language tasks, with suggestions for improving their capabilities.

There is also a discussion on the practical applications and limitations of VLMs, with some users expressing skepticism about the models' ability to perform certain tasks equivalent to human visual perception. Others mention their positive experiences with VLMs in tasks like Optical Character Recognition (OCR) but acknowledge the models' current limitations. Overall, the conversation delves into the complexities and challenges of enhancing VLMs' visual capabilities to reach human-level performance.

### Training of Physical Neural Networks

#### [Submission URL](https://arxiv.org/abs/2406.03372) | 130 points | by [Anon84](https://news.ycombinator.com/user?id=Anon84) | [43 comments](https://news.ycombinator.com/item?id=40926515)

The submission on Hacker News discusses a paper titled "Training of Physical Neural Networks" authored by Ali Momeni and 27 others. The paper explores the concept of Physical Neural Networks (PNNs), which leverage the properties of physical systems to perform computation. PNNs present exciting possibilities for training AI models that are significantly larger and capable of performing inference locally and privately on edge devices like smartphones or sensors. The research highlights the potential of PNNs to revolutionize AI systems by rethinking how models are trained and considering the constraints of underlying hardware physics. Various training methods for PNNs are being explored, showing promising advancements in scaling AI models beyond current capabilities. The study opens up new opportunities for efficient AI models and unprecedented-scale implementations.

The discussion on Hacker News regarding the submission about Physical Neural Networks (PNNs) touched upon various aspects related to the paper:

- The conversation highlighted the transferability of the model and its sensitivity to physical differences in devices, which raised concerns about the practical difficulty in transferring PNNs. 
- The use of neuro-morphic systems like Neuromorphic Intermediate Representation (NIR) for transferring models to hardware platforms was mentioned.
- Comments also compared the training costs between PNNs and traditional AI models like GPT-3, pointing out potential energy savings in the training of PNNs.
- There was a discussion on the capabilities and limitations of PNNs in comparison to neural networks and the potential implications on AI systems and hardware.
- The conversation also delved into the comparison between Physical Neural Networks and Analog Neural Networks, as well as the practical implementations and challenges associated with Physical Neural Networks. 

Overall, the discussion covered a range of topics related to the research paper on Physical Neural Networks, exploring its implications, challenges, and potential advancements in the field of AI systems.

### SimSig: Railway Signalling Simulations

#### [Submission URL](https://www.simsig.co.uk/) | 216 points | by [untilted](https://news.ycombinator.com/user?id=untilted) | [87 comments](https://news.ycombinator.com/item?id=40925025)

The latest posts on SimSig's forum cover upcoming games and various discussions about simulations. SimSig brings the excitement of running railway signaling systems to your PC. Operating as a signaller, you control signals and switches to ensure trains reach their destinations on time. The simulations replicate British IECCs with a focus on quality and realism. You can try out free demos before purchasing full simulations. Multiplayer options are available, allowing players to connect over the Internet or LAN. Users can contribute by creating timetables, and simulations can be linked together for a larger area experience. Join SimSig to experience the challenges of railway signaling firsthand!

The discussion on the Hacker News thread revolves around railway signaling systems simulations, including various software and games related to train signaling and control. Users mentioned their recommendations for simulations like Rail Route, OpenTTD, Factorio, and NIMBY Rails, along with comparisons and insights into their features. The conversation touched on the complexity and realism of these simulations, the challenges of train control systems, and the advancements in virtual air traffic control. Additionally, there were interesting insights shared about German railway signaling specifications, safety constraints, and the potential advancements in train control technology like Communication-Based Train Control (CBTC). Users also discussed the benefits and challenges of implementing advanced signaling systems in modern railways, such as closer train spacing and improved efficiency, emphasizing the need for compatible hardware and software systems. Additionally, the conversation touched upon the complexities and considerations in designing and implementing high-speed train systems like Hyperloop. The thread also highlighted the importance of efficient public transportation systems and the impact of transportation infrastructure on urban development.

### AMD to buy Silo AI for $665M

#### [Submission URL](https://www.ft.com/content/7b8d2057-2687-45b3-bae4-1488a75ac5b2) | 465 points | by [helsinkiandrew](https://news.ycombinator.com/user?id=helsinkiandrew) | [258 comments](https://news.ycombinator.com/item?id=40926648)

AMD, the renowned chipmaker, has made a bold move to boost its capabilities against Nvidia by acquiring Silo AI, a cutting-edge Finnish startup, for a staggering $665 million. This acquisition is set to enhance AMD's competitive edge in the tech industry, signaling a strategic shift towards harnessing AI technology to stay ahead in the game. With this move, AMD aims to position itself as a formidable force in the market, challenging the dominance of its competitors.

The discussion on Hacker News revolves around Nvidia's success in investing heavily in software and sponsoring professors to teach platforms like CUDA, leading to a dominant position in the market. Some users highlight the importance of software ownership and sponsorship in academia, while others discuss the comparison between CUDA and OpenCL. There is a comparison of Matlab and CUDA as well as the differing opinions on the significance of Nvidia's strategies in education. Additionally, the debate touches upon the challenges faced by AMD in competing with Nvidia, with some comments pointing out the differences in approach and strategy between the two companies. The conversation also delves into the potential impact of AMD's acquisition of Silo AI and the implications for the tech industry.

### RouteLLM: A framework for serving and evaluating LLM routers

#### [Submission URL](https://github.com/lm-sys/RouteLLM) | 235 points | by [djhu9](https://news.ycombinator.com/user?id=djhu9) | [35 comments](https://news.ycombinator.com/item?id=40922739)

Today's top story on Hacker News is about RouteLLM, a framework developed by LMSys and Anyscale for serving and evaluating LLM routers. This framework offers a solution to reduce LLM costs by up to 85% without compromising quality. By providing trained routers out of the box, RouteLLM allows users to route simpler queries to cheaper models while maintaining high performance, such as achieving a 95% GPT-4 performance level.

The core features of RouteLLM include serving as a drop-in replacement for OpenAI's client, enabling the easy comparison of router performance across multiple benchmarks, and the ability to extend the framework to include new routers. The installation process is straightforward, with options available to install from PyPI or from the source code.

Users can calibrate threshold values to control the tradeoff between cost and quality based on the types of queries received, ensuring optimal routing performance. By specifying the router and threshold in model fields when generating completions, requests can be efficiently routed between strong and weak models, thereby saving costs while maintaining quality responses.

RouteLLM also provides users with the ability to launch an OpenAI-compatible server for routing messages and offers support for various model pairs by leveraging LiteLLM. Additionally, the framework allows users to set up API keys for popular model providers and endpoints, making it versatile and user-friendly.

Overall, RouteLLM addresses the dilemma faced when deploying LLMs by offering a cost-effective solution that maintains high-quality performance, making it a valuable tool for those looking to optimize their LLM usage.

The discussion on Hacker News regarding the RouteLLM framework covers various aspects such as the potential of the framework in addressing practical challenges faced when deploying multiple LLMs, the importance of cost optimization and quality trade-offs, and the usefulness of trained routers in reducing costs by up to 85%. Some users mentioned specific use cases and scenarios where tools like RouteLLM could be beneficial, especially in optimizing LLM usage and managing costs.

There were discussions around the comparison of different models, the challenges of managing multiple LLMs efficiently, the implications of switching between models within workflows, and the technical aspects of using LLMs in different applications. Some users shared their experiences with similar projects and suggested alternative approaches or tools.

Overall, the conversation highlighted the significance of cost-effective solutions like RouteLLM in the realm of LLM deployment, emphasizing the need for tools that can balance cost savings with maintaining high-quality performance.

### Dola Decoding by Contrasting Layers Improves Factuality in Large Language Models

#### [Submission URL](https://arxiv.org/abs/2309.03883) | 56 points | by [johnsutor](https://news.ycombinator.com/user?id=johnsutor) | [20 comments](https://news.ycombinator.com/item?id=40928145)

The paper "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models" introduces a novel decoding strategy to address hallucinations in large language models. By contrasting the differences in logits from later versus earlier layers, the approach, DoLa, helps surface factual knowledge and reduce the generation of incorrect facts. This method shows promising results, enhancing truthfulness in various tasks and improving the performance of LLaMA family models on TruthfulQA significantly. The paper, presented at ICLR 2024, offers insights into making LLMs more reliable in generating truthful facts without the need for additional fine-tuning or external knowledge. The source code for the study is also available for further exploration.

The discussion in the comments section revolves around the topic of language models (LLMs) and their ability to attribute meanings. One user mentions that LLMs can attribute whatever labels people choose, leading to confusion between fundamental category errors and misconceptions. The conversation touches upon philosophical positions regarding the nature of computation, with references to mental instruction sets, Church-Turing-Deutsch principle, and the idea of programming mental states. Additionally, there is a comparison between the explanation of the mind using simpler versus more complex metaphors and the notion of Occam's razor in explaining the mind.

Regarding factual knowledge in LLMs, there is surprise expressed about the localization of specific transformer layers and their transferability. The discussion then shifts towards the concept of correction of hallucinations in LLMs, with contrasting views on the Orwellian aspect and the importance of discerning true from false information. An interesting philosophical discussion arises regarding realism versus nominalism, where realism argues for the inherent meaning of objects, while nominalism suggests that reality is mediated through language and consensus.

Overall, the conversation delves into the intricacies of language models, computation, philosophical positions, and the challenges of imparting factual knowledge in AI systems.

### Awsviz.dev simplifying AWS IAM policies

#### [Submission URL](https://www.awsviz.dev/) | 164 points | by [bscript](https://news.ycombinator.com/user?id=bscript) | [141 comments](https://news.ycombinator.com/item?id=40922740)

It looks like you want me to summarize the top stories on Hacker News for you. Is there a specific submission you would like me to focus on?

The discussion revolves around the complexities and challenges of using AWS Identity and Access Management (IAM). Users share their experiences and insights on problems such as managing credentials, permissions, and interactions within organizations. Some users highlight the difficulties encountered in setting up IAM policies, dealing with API calls, and ensuring proper security measures. Others suggest solutions like using Cloudtrail logs with Athena for better visibility and control. The conversation also touches on the significance of understanding AWS IAM for secure development and the importance of managing permissions effectively. Overall, the discussion emphasizes the need for careful planning and attention to detail when working with AWS IAM to ensure proper access control and security within cloud environments.

### Co-Dfns v5.7.0

#### [Submission URL](https://github.com/Co-dfns/Co-dfns/releases/tag/v5.7.0) | 39 points | by [Tomte](https://news.ycombinator.com/user?id=Tomte) | [7 comments](https://news.ycombinator.com/item?id=40928450)

Co-dfns v5.7.0 has been released with a focus on performance enhancements. The latest version includes improvements such as graph coloring allocation, preliminary dead code elimination, constant lifting, reduced reference counting, and more. These changes have led to a significant decrease in performance overhead, especially in basic benchmarks like n-body simulations. Additionally, the release addresses bug fixes and reliability issues, aiming to make the language more robust.

In the discussions about the release of Co-dfns v5.7.0, users on Hacker News provided insights and opinions on the performance enhancements mentioned in the submission. One user highlighted the use of labels like "graph algorithms," "good asymptotics," and "particularly succinct" to describe the language, noting that such terms may be confusing to some readers. Another user mentioned the challenges and benefits of graph algorithms and constant lifting in compilers. 

There was a thread discussing High-performance Reliable Parallel APL with comments about Co-dfns potentially generating GPU code and the benefits of GPU architectures for representing arrays and pointers efficiently. Another user mentioned the contributions to computer science and the possible advancements in structuring functional maps for compiler tasks and optimization with GPU processing. 

Finally, a user shared their experience installing drivers for ArrayFire and running Co-dfns, expressing gratitude for the update.

### ML Code Exercises

#### [Submission URL](https://www.deep-ml.com/) | 213 points | by [mchab](https://news.ycombinator.com/user?id=mchab) | [64 comments](https://news.ycombinator.com/item?id=40925896)

Here are the top ML code challenges of varying difficulties and categories:

1. **Matrix times Vector**
   - **Category:** Linear Algebra
   - **Difficulty:** Easy
   - **Status:** Unsolved

2. **Calculate Covariance Matrix**
   - **Category:** Linear Algebra
   - **Difficulty:** Medium
   - **Status:** Unsolved

3. **Solve Linear Equations using Jacobi Method**
   - **Category:** Linear Algebra
   - **Difficulty:** Medium
   - **Status:** Unsolved

4. **Singular Value Decomposition (SVD)**
   - **Category:** Linear Algebra
   - **Difficulty:** Hard
   - **Status:** Unsolved

5. **Determinant of a 4x4 Matrix using Laplace's Expansion**
   - **Category:** Linear Algebra
   - **Difficulty:** Hard
   - **Status:** Unsolved

6. **Linear Regression Using Normal Equation**
   - **Category:** Machine Learning
   - **Difficulty:** Easy
   - **Status:** Unsolved

7. **Linear Regression Using Gradient Descent**
   - **Category:** Machine Learning
   - **Difficulty:** Easy
   - **Status:** Unsolved

8. **Feature Scaling Implementation**
   - **Category:** Machine Learning
   - **Difficulty:** Easy
   - **Status:** Unsolved

9. **K-Means Clustering**
   - **Category:** Machine Learning
   - **Difficulty:** Medium
   - **Status:** Unsolved

10. **Cross-Validation Data Split Implementation**
    - **Category:** Machine Learning
    - **Difficulty:** Medium
    - **Status:** Unsolved

Stay tuned for more exciting ML challenges and sharpen your skills in deep learning, machine learning, and linear algebra!

The discussion on this submission covers a variety of topics related to machine learning, coding challenges, interviews, and more:

1. **TrackerFF** and **ptrmcnly** discuss reinventing standard scientific competitions and the challenges they pose compared to industry-standard packages.
2. **bArray** mentions the importance of learning machine learning principles for interviews.
3. **sfk** shares a project related to Singular Value Decomposition (SVD).
4. **rngd-ttr** expresses skepticism towards the interview process at FAANG companies and discusses the evolution of technical interviews.
5. **srbhv** talks about helpful GitHub repositories for learning Python.
6. **swzyjzy** discusses the importance of preparing for machine learning interviews and shares common topics that may be covered in such interviews.
7. **dmssnsgy** and **mchb** discuss the importance of preparing for technical interviews by practicing coding challenges.

Overall, the discussion touches on the challenges of ML coding challenges, interview preparation, and the evolving landscape of technical interviews in the field of machine learning.

