## AI Submissions for Fri May 26 2023 {{ 'date': '2023-05-26T17:11:26.581Z' }}

### TimL: Clojure-like Lisp dialect that runs on and compiles down to Vimscript

#### [Submission URL](https://github.com/tpope/timl) | 83 points | by [asimjalis](https://news.ycombinator.com/user?id=asimjalis) | [21 comments](https://news.ycombinator.com/item?id=36081091)

TimL is a Lisp dialect language that compiles to VimL, akin to Clojure. It features Clojure-like syntax and API, namespaces, macros, metadata, and more. TimL uses VimL interop to define symbols and interact with Vim variables, options, and exceptions. Getting started with TimL is recommended by using pathogen.vim and creating autoload/*.tim file. TimL is mostly underdocumented, adding additional overhead to the already slow host platform, leading to a possible lack of traction.

A new Lisp dialect language called TimL that compiles to VimL, similar to Clojure, was recently discussed on Hacker News. The language features Clojure-like syntax and API, namespaces, macros, metadata, and more. The comments section included multiple comparisons to similar languages such as Aniseed and Fennel, as well as discussion about the slow host platform and lack of documentation and traction. The discussion also touched on the topic of Vim versus Emacs, and included comments about the complexity of Vim configurations and Emacs Lisp, and the advantages and disadvantages of using Clojure and Lisp in general.

### AI Is Catapulting Nvidia Toward the $1 Trillion Club

#### [Submission URL](https://www.wsj.com/articles/how-ai-is-catapulting-nvidia-toward-the-1-trillion-club-14f42380) | 196 points | by [impish9208](https://news.ycombinator.com/user?id=impish9208) | [220 comments](https://news.ycombinator.com/item?id=36083093)

Nvidia is on track to become the first $1 trillion chip company thanks to its leading position in the artificial intelligence (AI) revolution. Tech giants such as Google, Microsoft, Amazon, and Facebook require expensive chips to support their growing AI capabilities, and Nvidia's chips are at the heart of this. The semiconductor company has come a long way since its beginnings 30 years ago, and its success in AI has put it in pole position for becoming the first chip company to break the $1 trillion barrier.

This has led to a discussion about the historical context of how technology companies have achieved their valuations, with some pointing to Intel's struggles in the early 2000s and the dotcom bubble. Others discuss the potential for smaller companies building AI technology, such as OpenAI, and some criticize the hype around AI as a market driver. The discussion also touches on competitors such as AMD and Google, and the risk of vertical integration in the industry.

### What Neeva's quiet exit tells us about the future of AI startups

#### [Submission URL](https://www.supervised.news/p/what-neevas-quiet-exit-tells-us-about) | 117 points | by [bobvanluijt](https://news.ycombinator.com/user?id=bobvanluijt) | [84 comments](https://news.ycombinator.com/item?id=36089055)

Snowflake's recent acquisition of Neeva, a generative AI startup founded by the former head of Google Advertising, offers insight into the current state of the AI industry. While Neeva's primary goal was to create a paid version of a search engine that offered better privacy and avoided ads, it struggled to gain traction against Google and Bing. The acquihire by Snowflake shows the growing importance of crossover experience in the AI industry, particularly in enterprise companies looking to gain a foothold in highly competitive markets. The Neeva team's knowledge and skill in building and deploying models will be invaluable to Snowflake as it seeks to break into machine learning.

The discussion on Hacker News touched on various points related to the current state of the AI industry, including the challenge of building AI products that compete with surface-visible results and the importance of expertise in building and deploying models. Another discussion focused on the misleading use of terms such as "Google Memo" and highlighted the importance of clear communication. The conversation also touched upon the need for specialized AI solutions to improve industry-specific workflows and the business challenges of developing AI products.

### A PhD student's perspective on research in NLP in the era of LLMs

#### [Submission URL](https://arxiv.org/abs/2305.12544) | 118 points | by [morgangiraud](https://news.ycombinator.com/user?id=morgangiraud) | [46 comments](https://news.ycombinator.com/item?id=36080886)

A group of PhD students in an academic research lab has compiled a list of NLP research directions that are rich for exploration, in a paper titled "A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models." While recent progress in large language models has enabled the deployment of many generative NLP applications, the students identify areas that still require exploration and caution against the misleading discourse that suggests that everything has been solved. The paper identifies a list of research areas that are not currently addressed by large language models but are worth exploring.

The comments discuss various topics related to NLP including resource allocation, the usefulness of various frameworks, and the need to validate hypotheses through experimentation. There are also debates about the validity of using pre-prints versus traditionally published work. Some readers argue that there are still many research directions that can be explored, while others are skeptical of the hype around large language models and argue that smaller-scale research could be just as productive. One commenter notes that the paper in question is not published in a reputable journal, while others argue that there is value in pre-print publications.

### Voyager: An Open-Ended Embodied Agent with LLMs

#### [Submission URL](https://voyager.minedojo.org/) | 85 points | by [jedixit](https://news.ycombinator.com/user?id=jedixit) | [23 comments](https://news.ycombinator.com/item?id=36085936)

NVIDIA, Caltech, UT Austin, Stanford, and ASU researchers collaborated to create Voyager, an embodied agent that explores and learns skills in Minecraft using large language models (LLMs). The agent features three key components: an automatic curriculum that aims to maximize exploration, an ever-growing skill library, and a new iterative prompting mechanism that improves programs based on environment feedback and execution errors. Empirical testing showed that Voyager outperformed prior state-of-the-art techniques by unlocking key tech tree milestones up to 15.3x faster and discovering new items and skills through self-driven exploration. The discussion on Hacker News primarily revolved around the technical aspects of LLMs and the limitations of GPT-4. Some users expressed skepticism about the potential of LLMs and others debated the effectiveness of direct vs. low-level control in Minecraft.

### The False Promise of Imitating Proprietary LLMs

#### [Submission URL](https://arxiv.org/abs/2305.15717) | 123 points | by [lebek](https://news.ycombinator.com/user?id=lebek) | [79 comments](https://news.ycombinator.com/item?id=36078739)

A new paper on arXiv analyses the efficiency of finetuning a weaker language model on outputs from a stronger model, such as a proprietary system like ChatGPT, to improve its quality. The authors find that while imitation models appear far better in their output and are rated as competitive with ChatGPT by crowd workers, they still have a substantial capabilities gap between open and closed LMs. The study concludes that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.

Comments in the discussion focused on the legal and ethical implications of the study, with some questioning whether imitation models are legal given their use of proprietary training data. Other users raised concerns about the potential dangers of AI and its impact on society. There was also a debate about the performance and value of large language models in general, with some arguing for the need to develop more specialized models for specific tasks.

### How much of AI's recent success is due to the Forer Effect?

#### [Submission URL](https://shkspr.mobi/blog/2023/02/how-much-of-ais-recent-success-is-due-to-the-forer-effect/) | 95 points | by [davidgerard](https://news.ycombinator.com/user?id=davidgerard) | [75 comments](https://news.ycombinator.com/item?id=36084881)

The article discusses the Forer Effect and how it applies to AI. The Forer Effect, also called "Forer Statements," occurs when people read general statements and believe them to be highly personal. The writer points out that AI can string together meaningless sentences that our human brains then ascribe meaning to. The author shares that reading AI-generated text can feel like getting a cold reading from a psychic, and then goes on to share some of Forer's original statements, including "Some of your aspirations tend to be pretty unrealistic."

The discussion on this submission is focused on the capabilities and limitations of AI-generated text and language models. Some users share their experiences playing games with AI text prompts and discuss their limitations in generating syntactically correct code. While others express concern that AI-generated text can lead to the Forer Effect, where people ascribe personal meaning to general statements. There are also discussions around the scalability of AI language models and their potential to replace human developers entirely. However, some users suggest that AI language models do have limitations and still require human input. Overall, the commenters express a mix of excitement and caution around the advancements in AI-generated language and their potential impact on various industries.


