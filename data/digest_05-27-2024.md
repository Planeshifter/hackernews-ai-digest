## AI Submissions for Mon May 27 2024 {{ 'date': '2024-05-27T17:11:20.737Z' }}

### Surveilling the masses with wi-fi-based positioning systems

#### [Submission URL](https://arxiv.org/abs/2405.14975) | 371 points | by [belter](https://news.ycombinator.com/user?id=belter) | [131 comments](https://news.ycombinator.com/item?id=40492234)

The latest buzz on Hacker News revolves around a paper titled "Surveilling the Masses with Wi-Fi-Based Positioning Systems" by Erik Rye and Dave Levin. The study sheds light on the potential privacy threats posed by Wi-Fi-based positioning systems, particularly focusing on Apple's WPS. The paper reveals an attack method that allows attackers to gather a global snapshot of Wi-Fi BSSID geolocations in just a matter of days. This technique has enabled the tracking of over 2 billion BSSIDs across the world, raising concerns about the longitudinal tracking of devices and potential privacy breaches. The authors outline various case studies, including tracking devices in conflict zones and during natural disasters. Recommendations for enhancing user privacy and mitigating vulnerabilities are also provided, along with insights into the responsible disclosure of these privacy issues. The community on Hacker News is abuzz with discussions surrounding the implications of such extensive data collection and the necessary measures to safeguard user privacy in the digital age.

The discussion on Hacker News around the paper "Surveilling the Masses with Wi-Fi-Based Positioning Systems" included a detailed conversation about MAC address randomization, vendor firmware, open-source implementations, and privacy issues. Participants touched on the challenges faced in preventing MAC address leakage, efforts towards open-source implementation of 802.11wf6 cards, and concerns about the effectiveness of MAC randomization. The debate also delved into legal aspects related to tracking people's locations, the development of Wi-Fi routers with default security settings, and the usage of specific hardware components like Rockchip RK3399 and RK3588 SoCs. The discussion further explored the role of open-source software in device security and the complexities of firmware development. Additionally, there was a mention of WLAN sensing technology and the potential privacy implications associated with it. Towards the end, the conversation shifted towards operating systems and their compatibility with different chipsets, particularly Qualcomm.

### Grokked Transformers Are Implicit Reasoners

#### [Submission URL](https://arxiv.org/abs/2405.15071) | 191 points | by [jasondavies](https://news.ycombinator.com/user?id=jasondavies) | [51 comments](https://news.ycombinator.com/item?id=40495149)

The paper titled "Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization" explores whether transformers can learn implicit reasoning over parametric knowledge. Authored by Boshi Wang and colleagues, the study reveals that transformers can indeed learn implicit reasoning through extended training beyond overfitting. The research uncovers variations in generalization levels for different reasoning types, with transformers succeeding in implicit reasoning for comparison but struggling for composition. The study delves into the model's internals and suggests improvements to the transformer architecture to enhance implicit reasoning induction. It also compares the performance of grokked transformers with non-parametric memory models for complex reasoning tasks, demonstrating the superiority of parametric memory in achieving near-perfect accuracy.

The discussion on this submission covers various aspects related to the study on Grokked Transformers and their ability to learn implicit reasoning. Some users point out the challenges and strengths of the research, highlighting the importance of training data distribution, the limitations of multi-layer transformers, and the need for clearer explanations in the paper. Others discuss the trade-offs between complexity and performance in model design, the difficulties in generalization for external memory models, and the significance of defining terms in research papers. Overall, the comments reflect both appreciation for the study's findings and constructive criticism regarding its presentation and implications.

### PcTattletale leaks victims' screen recordings to entire Internet

#### [Submission URL](https://www.ericdaigle.ca/pctattletale-leaking-screen-captures/) | 180 points | by [nneonneo](https://news.ycombinator.com/user?id=nneonneo) | [74 comments](https://news.ycombinator.com/item?id=40486991)

Today's top story on Hacker News is about a serious vulnerability in a stalkerware app called PCTattletale that allows attackers to obtain screen captures from any device where the app is installed. Despite attempts to alert the developers, they have not responded to fix the issue. The API vulnerability has led to the leaking of victims' screen recordings on the internet. The app's AWS infrastructure has been locked down by Amazon due to the incident. The original writeup of the vulnerability has been shared, revealing details of how the app works and the security flaws in its system. The post includes technical information on how the app functions and how the vulnerability was exploited. Hopefully, this exposure will prompt the developers to address the issue promptly.

The discussion on the submission "PCTattletale Vulnerability Exposes Victims Screen Recordings" covers various aspects of data protection, surveillance, and regulations. Users debated the encryption practices of Microsoft's Recall feature, the implications of storing sensitive data locally, and the potential privacy risks associated with screen recording software. Additionally, there were discussions on the contradictions in implementing surveillance tools, concerns about data security in corporate contexts, and the challenges of regulatory compliance, particularly in the EU. Some users expressed skepticism about the practices of tech companies in handling personal data and highlighted the importance of trust and transparency in data management. The debate also touched on the ethical considerations of surveillance technology, the balance between security and privacy, and the impact of monitoring tools on individuals' rights.

### AI Device Template Featuring Whisper, TTS, Groq, Llama3, OpenAI

#### [Submission URL](https://github.com/developersdigest/ai-devices) | 20 points | by [indigodaddy](https://news.ycombinator.com/user?id=indigodaddy) | [9 comments](https://news.ycombinator.com/item?id=40492789)

The AI Device Template on developersdigest.tech is making waves with its latest features supporting GPT-4 and Gemini-1.5 for Vision Inference. This project serves as an AI-powered voice assistant utilizing cutting-edge AI models like Whisper, GPT-3.5-Turbo, and more. It enables voice input, transcription, text-to-speech output, image processing, and function calling with conditionally rendered UI components. Inspired by devices like the Humane AI Pin and Rabbit R1, this template is sure to spark creativity in the AI development community. The setup is straightforward, requiring API keys for services like Groq, OpenAI, and others to unleash the full potential of this AI assistant. If you're into AI development, this project is a must-try for exploring the possibilities of AI devices.

- **sbstnnght** mentions that they are experimenting with AI in a box, highlighting that the AI server-side device seems useless unless there are specific GPU, LPU, TPU, or other hardware elements included. They express the idea that a portable box with these features might make more sense, similar to a smartphone.
- **bfngs** responds, emphasizing the importance of starting with minimal hardware and focusing on designing a working system based on local small computer capabilities. They suggest utilizing simple local natural language processing (NLP) processing and common protocols for communication within a connected group, steering away from overly complex hardware features.
- **wnplmr** contributes by pointing out that AI devices like phones and laptops simply do not understand reasoning due to dedicated devices lacking the same understanding ability.
- **crs** speculates that the reason for this lack of understanding could be to prevent access to data that AI does not need.
- **wnplmr** adds a comment about local Large Language Models (LLMs).
- **crs** explains the issue with cloud-based LLM, describing how the device could mistakenly upload personal data like pictures and contacts if given incorrect permissions.
- **Havoc** shares their interest in a project with a unique pricing structure unlike the monthly subscription model, with a validity of six months.
- **yigitkonur35** suggests trying the Exaai API as a potential solution.
- **Havoc** comments on different pricing models, mentioning that some providers require a minimum spend of 50 to 100.

Overall, the discussion involves thoughts on AI devices, hardware requirements, understanding capabilities, privacy concerns, and pricing structures for AI-related services.

### Google's AI is that stupid, feeds people answers from The Onion

#### [Submission URL](https://www.avclub.com/google-s-ai-feeds-answers-from-the-onion-1851500362) | 54 points | by [c420](https://news.ycombinator.com/user?id=c420) | [47 comments](https://news.ycombinator.com/item?id=40493136)

In a truly bizarre turn of events, Google's new AI Overview feature has been making some hilariously absurd suggestions when asked certain queries. From encouraging people to eat rocks to suggesting using glue on pizza, the AI seems to have a hard time distinguishing fact from fiction. It even mistakenly claimed the US has had a Muslim president, drawing attention to the dangers of relying solely on AI for information. Despite Google defending the product's quality, it's clear there are still some major kinks to work out. As the internet continues to be filled with questionable content, one can only wonder: will AI Overview ever truly be accurate, or will it remain a source of unintentional comedy straight out of The Onion?

The discussion surrounding the submission about Google's new AI Overview feature making absurd suggestions includes various viewpoints. Some users criticize Google for the flaws in the AI's suggestions, citing examples of nonsensical responses. Others defend Google, suggesting that most people just look for instant answers without delving deep into search results. The conversation also delves into the implications of relying on AI for information, with one user highlighting the importance of verifying sources. Additionally, there is discussion about the limitations of AI in distinguishing between fact and fiction, as well as the challenges in improving AI accuracy. Some users point out that the AI's responses resemble content from satire websites like The Onion, emphasizing the need for critical thinking when consuming AI-generated information. The conversation also touches on the role of AI in search engines, ethical considerations related to AI development, and comparisons with other search engines like Bing.

