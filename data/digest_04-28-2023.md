## AI Submissions for Fri Apr 28 2023 {{ 'date': '2023-04-28T14:01:21.977Z' }}

### JavaScript private class fields considered harmful

#### [Submission URL](https://lea.verou.me/2023/04/private-fields-considered-harmful/) | 39 points | by [feross](https://news.ycombinator.com/user?id=feross) | [25 comments](https://news.ycombinator.com/item?id=35747480)

In a blog post, Lea Verou, a library author, expresses her grief at the loss of encapsulation in her projects due to Vue 3's use of proxies for its reactivity system. Instances of classes that use private fields cannot be proxied, which creates several errors that may confuse the library users. Verou believes there is no workaround for proxy-ability, so she's decided to gradually refactor private class fields out of her existing libraries. Although she may still use private fields on a case-by-case basis, she won't reach for them without thought like she's been doing for the past few years.

The discussion about Lea Verou's blog post on Vue 3's use of proxies for its reactivity system centers around the loss of encapsulation in her projects due to instances of classes that use private fields not being proxied, causing several errors that may confuse the library users. Some commenters argue that private fields can remain private implementation details of a class as long as they're accessed via public methods or consumers must access internal state by passing fields. Others express frustration with JavaScript's lack of class features and the need to use private fields. TypeScript's support for private fields is welcomed by some, while others believe TypeScript doesn't fully solve this problem. There are also comparisons to similar problems in Java, C#, and Android development.

### Beautiful branchless binary search

#### [Submission URL](https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/) | 363 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [137 comments](https://news.ycombinator.com/item?id=35737862)

Malte Skarupke's blog post about a "Beautiful Branchless Binary Search" and was amazed at the efficiency of the algorithm, which eliminates one branch and makes the other nearly free. The search loop is simple and the generated assembly is beautiful. The algorithm works by jumping in powers of two and searching either the first or last elements of the array depending on whether the middle is less than or greater than the search value. In benchmark tests, it performed more than twice as fast as std::lower_bound in GCC for arrays with around 16k elements, but performed slower in Clang due to the comparison function being provided by the user.

Malte Skarupke's blog post about "Beautiful Branchless Binary Search" is the top story on Hacker News today. The post discusses an efficient branchless binary search algorithm that outperforms GCC's std::lower_bound on arrays with around 16k elements. However, it performed slower in Clang due to the comparison function being provided by the user. The discussion in the comments includes optimization techniques like prefetching, using Eytzinger layouts, and removing boundary checks. There are also debates about compilers, C++ hardware control, and the usefulness of branch predictors. Overall, the post and its associated discussion provide insights and ideas for optimization and efficient algorithms.

### Launch Lamini: The LLM Engine for Rapidly Customizing Models as Good as ChatGPT

#### [Submission URL](https://lamini.ai/blog/introducing-lamini) | 112 points | by [sharonzhou](https://news.ycombinator.com/user?id=sharonzhou) | [57 comments](https://news.ycombinator.com/item?id=35743664)

Lamini, an LLM engine, has emerged from stealth to allow any developer to train high-performing LLMs, as good as ChatGPT, on large datasets with just a few lines of code. The platform offers an advanced library for optimised prompt-tuning and typed outputs, as well as a first-ever hosted data generator for creating data needed to train instruction-following LLMs, initially licensed for commercial use. Lamini makes it easy to run multiple base model comparisons in a single line of code, from OpenAI’s models to open-source ones on HuggingFace. The company is also set to launch early access to a complete LLM training module.

Some users discussed the limitations of ChatGPT and LLMs in general, such as their struggles with certain types of language and inability to correctly answer numerical questions. Others questioned the usefulness of sticking to a specific dialect while generating words. There were also discussions around LLMs being built for specific sectors and the pricing difference between Lamini and OpenAI. Overall, the announcement of Lamini was met with excitement by developers.

### OpenAI closes its monster $10B funding round at $27B-29B valuation

#### [Submission URL](https://techcrunch.com/2023/04/28/openai-funding-valuation-chatgpt/) | 42 points | by [coloneltcb](https://news.ycombinator.com/user?id=coloneltcb) | [26 comments](https://news.ycombinator.com/item?id=35748540)

OpenAI, the startup behind the popular conversational AI model ChatGPT, has secured over $300 million in funding from a group of VC firms, including Tiger Global, Sequoia Capital, Andreessen Horowitz, Thrive, K2 Global, and Founders Fund, according to documents seen by TechCrunch. The cash injection values the company at $27 billion to $29 billion, following a $10 billion investment from Microsoft in January. OpenAI's army of technical teams works across multiple areas, but its impressive ChatGPT product, which lets anyone ask a natural question and receive a detailed answer, particularly caught the attention of investors. The startup's valuation reflects the massive growth potential perceived in AI and its related products, and the rapidly developing ecosystem around the technology.

Some users are skeptical, pointing out that while GPT-4 has promising improvements, it is not without its dangers and limitations. Others speculate that OpenAI will become the major provider of AI-powered products and that there will be competition ramping up. Lastly, a user noted an odd observation about Safari's reader mode displaying caps Lorem Ipsum.

### Gpt4free repo given takedown notice by OpenAI

#### [Submission URL](https://github.com/xtekky/gpt4free) | 264 points | by [freedmand](https://news.ycombinator.com/user?id=freedmand) | [223 comments](https://news.ycombinator.com/item?id=35740836)

The GitHub repository xtekky/gpt4free is a decentralized AI industry project that provides language model APIs free-of-charge. The project primarily focuses on GPT-4 and GPT-3.5 APIs from various websites, including writesonic.com and forefront.ai. The repository also includes a web-based graphical user interface for interacting with gpt4free, instructions on how to run it in a Docker container, and a ChatGPT clone with new features and scalability. The project is licensed under the GPL-3.0 license and is intended for educational purposes only.

There is discussion in the comments about the legality of the project and potential copyright infringement. Some commenters suggest that it may be subject to DMCA takedowns or may be infringing on intellectual property rights. Others argue that OpenAI's terms of service may not permit third-party services to use the APIs, and that the project may also be consuming computational resources without permission. There is also debate about the role of intellectual property in modern society and the importance of licensing and compensation for creators. One user notes that Google's crawlers and Bing's sourcing methods are different, with Bing being more sensitive to copyright infringement concerns. The submission has been flagged by a user for review.

### AI Will Rapidly Transform Labor, Exacerbating Inequality, Insecurity, Poverty

#### [Submission URL](https://www.scottsantens.com/ai-will-rapidly-transform-the-labor-market-exacerbating-inequality-insecurity-and-poverty/) | 16 points | by [23B1](https://news.ycombinator.com/user?id=23B1) | [17 comments](https://news.ycombinator.com/item?id=35749306)

The impact of AI on the job market is often boiled down to "technology will end all jobs" versus "everything will be fine." In reality, it is more nuanced, and although AI will get rid of many jobs, it doesn't mean everyone will be jobless forever. A recent working paper estimates that around 80% of the US workforce could have at least 10% of their work tasks impacted by the introduction of large language models, and those with bachelor's degrees will be the most impacted. The future of AI's impact on jobs is dependent on the adoption of an unconditional, universal basic income as a rising AI dividend to mitigate job disruption.

Some comments point out that the article lacks credibility and reasoning, and that the issue is much more complex than just implementing UBI. Some argue that UBI could create disincentives for innovation and productivity, and that it would be too expensive to implement. Other comments compare the impact of AI to past technological advancements and suggest that it will lead to lower costs of goods and services, but also to the need for redistribution of wealth. One commenter notes that the original Luddites were not against technology but were fighting against poor working conditions and low pay for textile workers.

### We're afraid language models aren't modeling ambiguity

#### [Submission URL](https://arxiv.org/abs/2304.14399) | 192 points | by [lnyan](https://news.ycombinator.com/user?id=lnyan) | [176 comments](https://news.ycombinator.com/item?id=35737397)

A recent paper published on arXiv, titled "We're Afraid Language Models Aren't Modeling Ambiguity", highlights the importance of ambiguity in natural language understanding and the challenges faced by current language models in recognizing and disentangling possible meanings. The authors characterize ambiguity in a sentence and collect a linguist-annotated benchmark of examples with diverse kinds of ambiguity. They then evaluate the performance of language models, including the recent GPT-4, in recognizing ambiguity and find that it remains extremely challenging. Finally, the authors demonstrate the value of ambiguity-sensitive tools by showing how a multilabel NLI model can flag political claims that are misleading due to ambiguity.

In the comments, there is some discussion about the limitations of language models compared to humans, as well as their strengths in statistical analysis. Some users also discuss the importance of context and personal knowledge in communication, while others reflect on their experiences playing language-based games such as 20 Questions.

### Nuke-launching AI would be illegal under proposed US law

#### [Submission URL](https://arstechnica.com/information-technology/2023/04/nuke-launching-ai-would-be-illegal-under-proposed-us-law/) | 21 points | by [upwardbound](https://news.ycombinator.com/user?id=upwardbound) | [3 comments](https://news.ycombinator.com/item?id=35744974)

US legislators have introduced bipartisan legislation to prevent nuclear launch decisions from being made by artificial intelligence (AI) systems. The Block Nuclear Launch by Autonomous Artificial Intelligence Act demands that automated systems should not launch nuclear weapons without "meaningful human control". Senator Edward Markey, who sponsored the bill with two congressmen and a congresswoman, said that humans needed to be solely responsible for triggering life-or-death decisions about the use of nuclear weapons. The Bill would also codify existing US Department of Defense policy. 

The comments on this submission include a discussion of whether AI should be trusted to make autonomous decisions related to nuclear weapons. One user found it comforting that there is a GUI chat dialog for Palantir's Wargame AI tool and the permissions to use it are checked, while another user pointed out that AI has been used in automated systems for more than 20 years and Dead Hand is an example of such a system. Another user expressed concern that people's stupidity is the flaw in the system, while another user suggested that we should not trust AI blindly.

### Stability AI releases StableVicuna, a RLHF LLM Chatbot

#### [Submission URL](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot) | 49 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [19 comments](https://news.ycombinator.com/item?id=35745682)

Stability AI has released StableVicuna, the AI world's first open-source chatbot trained via reinforced learning from human feedback (RLHF). The chatbot follows a three-stage RLHF pipeline, utilizing datasets such as OpenAssistant Conversations Dataset and GPT4All Prompt Generations, and is further instruction fine-tuned for performance. StableVicuna is available for download on the HuggingFace Hub, alongside its upcoming chat interface. The team plans to iterate on the chatbot and deploy a Discord bot to the Stable Foundation server to further improve the user experience.

In the comments, some users discuss the complexity and limitations of fine-tuned models, suggesting that getting 30B models may not be helpful and that there are possibly 65B behaviors that are different. Others recommend specific AI models under the Apache BSD license, and one user mentions that the project may focus more on optimization rather than benchmarks. Some users recommend trying StableVicuna at https://huggingface.co/spaces/CarperAI/StableVicuna, while others discuss the use of GPT-generated content and reducing content quality. There is also a discussion about licensing and affordability, with some users noting that the project is relatively low-risk and that internal development may benefit from LLaMa.

