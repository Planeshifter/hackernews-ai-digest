## AI Submissions for Tue Jun 13 2023 {{ 'date': '2023-06-13T17:12:05.683Z' }}

### The Curse of Recursion: Training on Generated Data Makes Models Forget

#### [Submission URL](https://arxiv.org/abs/2305.17493) | 156 points | by [indus](https://news.ycombinator.com/user?id=indus) | [102 comments](https://news.ycombinator.com/item?id=36319076)

Researchers have discovered a potential issue with large language models (LLMs), such as GPT-2, 3 and 4, which have demonstrated remarkable performance on a variety of language tasks. The research shows that training on generated data causes irreversible defects in the resulting machine learning models, where the tails of the original content distribution disappears. Known as Model Collapse, despite occuring in various generative models, it remains ubiquitous and requires careful consideration if the benefits of training large-scale data scraped from the web are to be achieved. The study warns that genuine human interactions with systems will be increasingly valuable when content generated by LLMs is prevalent.

The top comment describes how LLMs are changing the way we look at language, with some expressing skepticism for their ability to learn naturally. Another comment addresses the limitations of LLMs, citing the importance of constraining the model to a particular set of styles or subject areas. Other commenters discuss the potential of human input being increasingly valuable because of LLM-generated content and the possibility of simulated data to train models. Overall, there is recognition of the benefits of LLMs but also an acknowledgment of the need for careful consideration when using them.

### Teach yourself Computer Science functionally

#### [Submission URL](https://functionalcs.github.io/curriculum/) | 286 points | by [ggr2342](https://news.ycombinator.com/user?id=ggr2342) | [92 comments](https://news.ycombinator.com/item?id=36312603)

This article provides a collection of modern resource materials aimed at undergrad level computer science students interested in theory. The resources cover various topics, including an introduction to computer science, tools, and assumed mathematical background. Additionally, the article provides some studying strategies and ways to make learning these topics easier. An experimental curriculum is included for math from scratch, and a Discord channel is recommended for students looking to learn with a community. The article also mentions Robert Harper's blog and Dan Licata's version of the CMU 15-150 course for functional programming.

This discussion is about a collection of modern resource materials for undergrad level computer science students interested in theory. Some commenters recommend various alternatives to the curriculum, such as Robert Harper's blog and Dan Licata's version of the CMU 15-150 course for functional programming. Some commenters note the importance of math in computer science, while others argue for a more hands-on, practical approach. There is also discussion about the difficulty of learning certain topics and the importance of starting with abstract thinking or focusing on concrete concepts. Finally, one commenter argues that all functional programming languages are the same, which is disputed by others.

### Obsidian-Copilot: A Prototype Assistant for Writing and Thinking

#### [Submission URL](https://eugeneyan.com/writing/obsidian-copilot/) | 228 points | by [alexmolas](https://news.ycombinator.com/user?id=alexmolas) | [65 comments](https://news.ycombinator.com/item?id=36310689)

Eugeneyan has built a prototype called Obsidian-Copilot that helps draft a few paragraphs via retrieval-augmented generation, and even reflects on the past week as well as planning for the week ahead, when writing in a daily journal. The prototype parses documents into chunks, builds an OpenSearch index and a semantic index on these chunks, and uses embeddings-based retrieval and classical search (i.e., BM25 via OpenSearch) to help write drafts and reflect on the past week or plan. Eugeneyan has also integrated it with Obsidian via a TypeScript plugin and plans to extend it beyond productivity, possibly allowing it to retrieve from other online documents like product requirements, technical design docs, and even code.

The discussion is mainly focused on different techniques for parsing documents into chunks and the pros and cons of using global versus local context in the retrieval process. Some users suggest using sliding windows with logical maintenance of context, while others propose using custom recursive text splitters or using embeddings for retrieval. Additionally, there is some discussion on Obsidian and other note-taking systems, as well as the ethics of OpenAI's use of AI.

### Jim Keller on AI, RISC-V, Tenstorrentâ€™s Move to Edge IP

#### [Submission URL](https://www.eetimes.com/jim-keller-on-ai-risc-v-tenstorrents-move-to-edge-ip/) | 174 points | by [JoachimS](https://news.ycombinator.com/user?id=JoachimS) | [102 comments](https://news.ycombinator.com/item?id=36310145)

Tenstorrent's new CEO, Jim Keller, a legendary CPU designer with stints at Apple, Tesla, and AMD, has become an outspoken supporter of RISC-V. In a video interview with EE Times, Keller said he believes RISC-V will take over all data centers, especially in scientific computing and HPC, potentially even supercomputing. Tenstorrent also plans to open-source its own AI software stack and has recently licensed its Tensix AI accelerator core IP and its Ascalon CPU core IP to LG Electronics for use in smart TVs and automotive chips. Keller believes current alternative IP offerings in the edge AI market are too focused and difficult to program and thinks it's crucial to engage with smart people who want open-source access to its hardware.

The comments include discussions about the practicality and feasibility of RISC-V in data centers, the functioning of cloud services, the reality of traditional data centers, and the cost comparison between cloud and traditional data centers. The conversation shows a mix of perspectives and opinions.

### SnapFusion: Text-to-Image Diffusion Model on Mobile Devices Within Two Seconds

#### [Submission URL](https://snap-research.github.io/SnapFusion/) | 220 points | by [synapse26](https://news.ycombinator.com/user?id=synapse26) | [52 comments](https://news.ycombinator.com/item?id=36304716)

Snap Inc. researchers, in collaboration with Northeastern University, have developed a way for text-to-image diffusion models to run on mobile devices in less than two seconds. These models are used to generate stunning images from text descriptions, but their large size and computationally expensive architecture require high-end GPUs and cloud-based inference. The new approach includes an efficient UNet architecture that reduces computation, improved step distillation, and classifier-free guidance regularization. The resulting on-device demo generates better FID and CLIP scores than Stable Diffusion v1.5 with 50 steps, democratizing content creation for users.

However, some commenters raised questions about the validity of the claims being made and the practicality of using the technology due to the significant energy cost of generating images. Some also commented on the broader context of the AI industry and its impact on creativity and the role of human control in the creation of art. Overall, the discussion was mixed in its reception of the technology.

### Contra Marc Andreessen on AI

#### [Submission URL](https://www.dwarkeshpatel.com/p/contra-marc-andreessen-on-ai) | 37 points | by [DantesKite](https://news.ycombinator.com/user?id=DantesKite) | [25 comments](https://news.ycombinator.com/item?id=36317925)

In a recent essay, Marc Andreessen argues that AI will save the world, but he fails to engage with concerns about AI misalignment. Instead, he dismisses safety worriers as cultists and believes that we will completely control the AI systems we build. However, Dwarkesh Patel argues that AI can be dangerous, even if it doesn't have bad intentions, as it can pursue a goal in a way we never intended, leading to disastrous consequences. Furthermore, as AI becomes smarter, it may develop something like a mind, making it harder to control. Patel urges for a testable hypothesis to measure the danger of advanced AI.

There is a discussion on the need for testable hypotheses to measure the danger of advanced AI. One commenter believes that the AI alignment problem can be solved with regulation and that current players in the field need to be entrenched with restrictive regulations. Several comments are sceptical of AI's potential to solve humanity's problems. Another commenter argues that serious AI scientists understand the dangers and the need for caution. Finally, there is a mention of a forthcoming article that takes a different view from Patel and Andreessen.

### Oyster: Towards Unsupervised Object Detection from Lidar Point Clouds

#### [Submission URL](https://waabi.ai/oyster/) | 134 points | by [abrichr](https://news.ycombinator.com/user?id=abrichr) | [70 comments](https://news.ycombinator.com/item?id=36304979)

Researchers have proposed a new unsupervised object detection method, called OYSTER (Object Discovery via Spatio-Temporal Refinement), that can detect objects in a zero-shot manner without supervised fine-tuning and can improve itself given more rounds of iterative self-training. OYSTER exploits point clustering in near-range areas where the point clouds are dense, temporal consistency to filter out noisy unsupervised detections, translation equivariance of CNNs to extend the auto-labels to long range, and self-supervision for improvement. The proposed self-training loop is highly effective for teaching an unsupervised detector to self-improve and the model outperforms prior unsupervised methods by a significant margin on two real-world datasets, Pandaset and Argoverse 2 Sensor.

The comments revolve around the use of LIDAR in self-driving cars and the limitations of human drivers in comparison. Some commenters argue that adding sensors and data mapping can improve safety, while others argue that human-like decision-making is impossible to replicate in machines. There is also discussion about the importance of understanding the environment and the limitations of sensors and software in creating a self-driving system, with some commenters focusing on the need for creating a concrete path towards dealing with developing and presenting various types of sensors, while others argue that human drivers are necessary regardless of how advanced technology becomes. Overall, the discussion highlights the need to consider and address a wide variety of factors in the development of safe and effective autonomous driving technology.

### AMD Expands AI Product Lineup with GPU-Only Instinct Mi300X with 192GB Memory

#### [Submission URL](https://www.anandtech.com/show/18915/amd-expands-mi300-family-with-mi300x-gpu-only-192gb-memory) | 113 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [98 comments](https://news.ycombinator.com/item?id=36314744)

re taking on the AI and HPC market with their next-generation HPC-class processors, the AMD Instinct MI300 accelerator family. The latest addition to the line-up is the MI300X, a pure GPU part that boasts 192GB of HBM3 memory and is aimed squarely at the large language model market. Offering such a massive GPU with the synergy of offering both an APU and CPU in the same package is a big deal, and it sets AMD apart from their competitors. The MI300 family is set to ship later this year, and it will be interesting to see how it performs against rival NVIDIA's Grace Hopper superchip. Overall, the pressure on AMD to deliver is high, but with demand for AI accelerators skyrocketing, MI300 may be the product that the company needs to make a significant play in the market. However, there was a long discussion in the comments section on the pricing disparity between NVIDIA and AMD's products, with debate surrounding factors such as supply and demand and cost-performance efficiency. Some commenters also mentioned AMD's ROCm and compared it to NVIDIA's CUDA, while others speculated on AMD's market positioning.

### U.S. TSA expands controversial facial recognition program

#### [Submission URL](https://www.cbsnews.com/news/tsa-facial-recognition-program-airports-expands/) | 76 points | by [walterbell](https://news.ycombinator.com/user?id=walterbell) | [25 comments](https://news.ycombinator.com/item?id=36305027)

The Transportation Security Administration (TSA) is expanding its controversial digital identification program that uses facial recognition at 25 airports in the US and Puerto Rico. This comes as the TSA and other divisions of Homeland Security face mounting pressure from lawmakers to update technology and cybersecurity. TSA Administrator David Pekoske has defended the program, saying it is "much, much more accurate" and saves passengers time. However, there are concerns from privacy advocates over the lack of regulations around facial recognition and its tendency to be less accurate with people of color. However, privacy advocates raised concerns about the lack of regulations around facial recognition and its tendency to be less accurate with people of color. Additionally, there were comments about the Israeli start-up, AnyVision, which uses facial recognition and has been accused of helping to surveil Palestinians. The discussion also touched on issues of privacy, the convenience of technology, and governmental tracking.

