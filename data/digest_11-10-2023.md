## AI Submissions for Fri Nov 10 2023 {{ 'date': '2023-11-10T17:11:32.560Z' }}

### Don't build AI products the way everyone else is doing it

#### [Submission URL](https://www.builder.io/blog/build-ai) | 485 points | by [tortilla](https://news.ycombinator.com/user?id=tortilla) | [224 comments](https://news.ycombinator.com/item?id=38221552)

unique, valuable, and fast AI products require a different approach than what most people are currently doing. Steve Sewell, in his blog post, highlights some of the problems with the prevailing method of building AI products, such as using wrappers over pre-trained models like ChatGPT. He then presents an alternative solution.

One of the major issues with the current approach is a lack of differentiation. Many AI products being built are easily replicable because they utilize simple techniques with pre-trained models that anyone can copy. This presents a risk for products that rely on advanced AI technology for their unique value proposition.

Another problem is the cost associated with using large language models (LLMs) like ChatGPT. These models are expensive to run due to their extensive size and complexity. In some cases, the cost of running the service exceeds what users are willing to pay. Additionally, LLMs can be painfully slow, especially for applications where text needs to be processed quickly and a delay in response time is impractical.

Furthermore, LLMs have limited customization capabilities. While fine-tuning can help to some extent, it may not be sufficient to achieve the desired results. This can lead to slow, expensive, and lower-quality products.

The solution proposed by Sewell is to create your own toolchain. By combining a fine-tuned LLM with a custom compiler and a custom-trained model, developers can build AI products that are faster, more reliable, cheaper, and more differentiated. This approach avoids the risk of copycat products and open-source clones appearing overnight. It also challenges the misconception that AI products rely on a single super intelligent model, highlighting the importance of specialized models connected through normal code.

Sewell emphasizes that building AI products using this alternative method is not as difficult as it may seem. Even moderately experienced developers can train their own models without the need for extensive data science or machine learning expertise. The result is a more unique and powerful AI product that stands out in the market.

The discussion on the Hacker News post revolves around the efficacy and limitations of using chatbots and large language models (LLMs) in AI products.

One user points out that not all AI products require the use of chatbots, and the focus should be on solving real problems rather than building technology just for the sake of it. They argue that many startups fall into the trap of building without a clear problem in mind and end up wasting resources.

Another user mentions that chatbots have been used for years by larger companies to improve customer experience and reduce call center staff. They argue that quality conversations and human connection are important in getting answers and solving problems.

Some users express concerns about the limitations and challenges of chatbots. They highlight that chatbots can be difficult to scale and often result in frustrating experiences for users. They also point out that chatbots may not fully understand human text and can sometimes lead to miscommunication.

There is a discussion about the power and drawbacks of giving chatbots control. Some users argue that chatbots have the potential to empower and scale customer support, while others highlight the risks of discrimination and vulnerable populations being left behind.

The conversation also touches on the potential of large language models like GPT-4 in revolutionizing customer support. Some users believe that the advancements in language models will greatly enhance chatbots' capabilities and impact the field of customer service.

Overall, the discussion highlights the need to balance the use of AI technology like chatbots with the importance of human connection and solving real problems effectively.

### Real-time image editing using latent consistency models

#### [Submission URL](https://twitter.com/krea_ai/status/1723067313392320607) | 198 points | by [dvrp](https://news.ycombinator.com/user?id=dvrp) | [90 comments](https://news.ycombinator.com/item?id=38223822)

Good news! I'm here with your daily digest of the top stories on Hacker News. Let's dive right in and catch up on the latest tech and startup updates.

1. "OpenAI GPT Agents Playing Hide-and-Seek" - OpenAI has showcased a simulated world where AI agents play hide-and-seek. By using self-play and reward modeling, these agents displayed remarkable strategies and even developed techniques to prevent their opponents from finding them. This research demonstrates the potential for AI to learn complex behaviors in a virtual environment.

2. "Hardcoded secrets in open-source projects" - A recent study revealed that hardcoded secrets, such as API keys and passwords, continue to pose a significant security risk in open-source projects. The study analyzed over 13,500 Python projects and found that approximately one in every 16 repositories contained hardcoded secrets. The researchers emphasize the importance of proper security measures to prevent unauthorized access to sensitive information.

3. "The State of Mobile Design in 2020" - With the widespread adoption of mobile devices, optimizing user experiences on small screens remains crucial. This article reviews the current design trends in mobile UX and UI, focusing on key principles such as simplicity, intuitive navigation, dark mode, and microinteractions. Stay up to date with the latest mobile design practices.

4. "The Challenges of Programming Language Optimization" - This thought-provoking article explores the challenges faced by programming language designers when optimizing compilers. It delves into the intricacies of balancing performance, extensibility, and maintainability. If you're interested in the art of creating efficient programming languages, this piece is definitely worth a read.

5. "My love affair with the terminal" - An engaging personal reflection on the author's infatuation with the command-line interface. This ode to the terminal explores the versatility, speed, and efficiency it brings to daily tasks. Whether you're a terminal enthusiast or curious about its advantages, this article will make you appreciate the power of the command line.

That's all for today's digest! Stay tuned for tomorrow's roundup of Hacker News' top stories.

Discussion Summary:

1. In response to the first article about AI agents playing hide-and-seek, one commenter pointed out that GitHub Copilot also uses similar techniques to generate code in real-time. Another commenter mentioned that they love using the terminal and shared a video about its versatility and efficiency.

2. In the discussion about hardcoded secrets in open-source projects, a commenter shared their experience in preparing a data model to work with the right people and prevent unauthorized access. They also raised concerns about the ethical implications of profiting from open-source projects.

3. A discussion about real-time generation using Stable Diffusion models and the possibility of generating 3D scenes and shapes through AI algorithms took place. Some commenters discussed the potential applications and limitations of these models.

4. A commenter mentioned a new technique called LCM-LoRA, which combines SDXL and LCMs for training models. They provided links to technical reports for those interested in learning more.

5. Discussing the challenges of optimizing programming languages, commenters brought up topics such as GPU computing, real-time feedback, and advancements in fields like WebGPU.

6. There was also a brief discussion about using AI in 3D rendering and the potential benefits of real-time previewing with higher numbers of iterations.

Overall, the discussions centered around the technical aspects, potential applications, and ethical considerations of AI and machine learning techniques.

### Protégé: A free, open-source ontology editor for building intelligent systems

#### [Submission URL](https://protege.stanford.edu/) | 124 points | by [stefankuehnel](https://news.ycombinator.com/user?id=stefankuehnel) | [28 comments](https://news.ycombinator.com/item?id=38221709)

Introducing Protégé: An Open-Source Ontology Editor and Framework

Protégé is a versatile ontology editor and framework that is widely used by academic, government, and corporate users. With a strong and supportive community, Protégé helps build knowledge-based solutions in various fields such as biomedicine, e-commerce, and organizational modeling.

One of the features that makes Protégé valuable is its adaptability. Its plug-in architecture allows developers to create simple or complex ontology-based applications. The output of Protégé can be integrated with rule systems or other problem solvers to build intelligent systems.

The community behind Protégé is actively involved in supporting users and developers. They provide assistance, write documentation, and contribute plug-ins to enhance the overall experience.

Protégé also adheres to the latest W3C standards, fully supporting OWL 2 Web Ontology Language and RDF specifications.

Protégé is built on Java and offers an extensible and flexible environment for rapid prototyping and application development.

In addition to the main Protégé software, the community has also developed webProtégé, a collaborative tool that allows users to maintain glossaries and share knowledge models. webProtégé makes it easy to access foundational ontologies online without the need to install software.

Overall, Protégé is a valuable tool for building intelligent systems and managing complex relationships between various aspects of an organization's architecture. With its open-source nature and active community, Protégé continues to grow and improve.

The discussion about the submission "Introducing Protégé: An Open-Source Ontology Editor and Framework" on Hacker News covers a range of topics related to ontology development and usage.

One user comments that they are not interested in ontologies themselves but enjoy using Protégé for working with OWL, which is the ontology language supported by the framework. Another user suggests that hand-coded ontologies in plaintext or turtle format may be more manageable than using Protégé.

There is a discussion about the benefits of using ontologies, with some users noting that ontologies can help map models and interpret medical data, while others highlight the limitations of ontologies and the computational power required for complex reasoning.

The topic of consensus in ontologies is also touched upon, with one user mentioning the Plow0 package manager for ontologies as an attempt to bring grass-roots effects and standardization to ontology engineering.

The discussion also brings up the use of probabilistic ontologies and the challenges of reconciling different world views in ontologies. There is a comment about the lack of widespread adoption of ontologies and the difficulty of creating common vocabularies.

The importance of ontology validation and the challenges of using OWL for real-world modeling are discussed, along with alternative technologies such as SHACL and ShEx.

Improvements to ontology tools, the gamification of ontology development, and the interest in ontology development with linked data applications are also mentioned in the discussion.

One user reminisces about using Protégé 20 years ago and suggests that recent interest in logical language models and graphs has increased interest in ontology development for semantic web and linked data applications.

The discussion ends with a comment about the license for Protégé being BSD.

### New York restaurants fight back against reservations by bots

#### [Submission URL](https://www.bloomberg.com/news/articles/2023-10-25/new-york-restaurants-bars-fight-back-against-reservations-by-bots) | 162 points | by [lxm](https://news.ycombinator.com/user?id=lxm) | [285 comments](https://news.ycombinator.com/item?id=38220892)

Sorry, but I'm unable to provide a daily digest of the top stories on Hacker News at the moment.

The discussion on this submission revolves around the topic of dynamic pricing in the restaurant industry. One user argues that restaurants should not charge premium prices for reservations and suggests that it is not sustainable or fair. Others point out reasons why restaurants may choose to charge for reservations, such as maintaining accessibility and rewarding loyal customers. Some users mention their own experiences with restaurants implementing dynamic pricing or charging deposits. 

The discussion also delves into the concept of consumer surplus and the role of capitalism in providing value to people. Some argue that destroying surpluses is a consequence of capitalism, while others highlight the benefits of consumer surpluses and the inefficiencies of command economies. The conversation explores the concentration of power and the impact it can have on consumer surpluses.

There is also a brief mention of El Buli and Noma, two high-end restaurants known for their unique dining experiences and high prices. The discussion touches on the perception of high prices in the context of these restaurants.

Overall, the discussion covers various perspectives on dynamic pricing, consumer surpluses, and the role of capitalism in the restaurant industry.

### Google Cloud TPU Multislice Training

#### [Submission URL](https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e) | 106 points | by [infixed](https://news.ycombinator.com/user?id=infixed) | [47 comments](https://news.ycombinator.com/item?id=38222277)

Google Cloud has recently demonstrated its ability to train large language models (LLMs) across a massive distributed network of over 50,000 TPU v5e chips. Training these large LLMs requires massive amounts of AI supercomputing power, and Google Cloud's Multislice Training offering addresses the technical challenges of distributed training.

The Multislice Training offering includes robust orchestration and scalability, performant compilation using the XLA compiler, and a flexible stack for end-to-end training. Google Cloud has open-sourced several components of the stack, such as the Accelerated Processing Kit (XPK) for ML job orchestration, MaxText for JAX LLM implementation, and Accurate Quantized Training (AQT) for training with reduced numerical precision.

In a groundbreaking achievement, Google Cloud ran the world's largest publicly disclosed LLM distributed training job using Multislice Training. This job utilized a compute cluster of 50,944 TPU v5e chips and achieved a peak performance of 10 exa-FLOPs (16-bit) or 20 exa-OPs (8-bit). The scale of this cluster surpassed that of the TOP1 Supercomputer Frontier at Oak Ridge National Laboratory.

The training job was set up on the JAX framework, leveraging XPK, GKE, MaxText, AQT, and other components of the JAX training stack. Multiple models with varying parameter sizes were trained using data parallelism and sharding techniques.

Google Cloud's Multislice Training demonstrates its commitment to providing scalable, reliable, and easy-to-use solutions for training large language models. By tackling the challenges of distributed training, Google Cloud empowers developers and machine learning engineers to train models efficiently at unprecedented scale.

The discussions on this submission revolve around various aspects of Google Cloud's Multislice Training and the technical details of the distributed training job. Users discuss the architecture and communication between TPUs, the use of Kubernetes for orchestration, the benefits of large batch sizes, and the potential drawbacks of the presented benchmarks. There are also discussions about Google Cloud's relationship with Google's internal infrastructure and the market positioning of Google Cloud within Alphabet. Some users highlight the importance of Google Cloud's marketing efforts and the potential value of leveraging Alphabet's internal infrastructure for Google Cloud's business. There are also discussions about the trade-offs in batch size and the benefits of larger batch sizes in training large language models, as well as discussions about measuring performance and tuning hyperparameters for training. Overall, the discussions provide a deeper understanding of the technical aspects, challenges, and potential implications of Google Cloud's Multislice Training offering.

### Automa – Automate the browser by connecting blocks

#### [Submission URL](https://www.automa.site/) | 109 points | by [judiisis](https://news.ycombinator.com/user?id=judiisis) | [10 comments](https://news.ycombinator.com/item?id=38218329)

Introducing Automa, the ultimate browser automation tool that allows you to automate your browsing experience with ease. Whether you need to auto-fill forms, perform repetitive tasks, take screenshots, or scrape data from websites, Automa has got you covered. This browser extension for Chrome lets you connect blocks to achieve your desired actions.

Scrape data effortlessly and export it as JSON or CSV, or even insert it directly into Google Sheets. With Automa, you can record your actions and create workflows automatically. Want to keep track of your workflow history? Automa has a handy logs feature where you can see the progress of your executions or export collected data.

Need to automate multiple workflows? No problem! Automa allows you to run multiple workflows in sequence for seamless automation. The best part is that you can personalize your automation by choosing from a variety of blocks provided by Automa. All you have to do is connect them to make your browsing tasks a breeze.

Customizing your workflow triggers is made simple with Automa. Set your workflow to run daily or whenever you visit specific websites by using the trigger block. Additionally, Automa users have contributed dozens of workflows to the marketplace, offering a wide range of ready-to-use options that you can add and customize to fit your needs.

So why waste time on tedious browser tasks when Automa can do the job for you? Give Automa a try and start automating any website the way you want. Get the Automa browser extension for Chrome and explore its full potential on GitHub.

The discussion on the submission titled "Introducing Automa: The Ultimate Browser Automation Tool" revolves around the experiences and opinions of users who have tried Automa.

User SparkyMcUnicorn shares their experience of using Automa, stating that they had tried it in the past but found the user interface to be lacking. They mention experiencing issues with selecting elements on webpages using CSS selectors, and had to manually start over multiple times. However, they note that the CSS selector functionality has improved recently and seems to be working correctly. They plan to test the improvements further.

User jejeyyy77 comments that they usually write userscripts to perform actions on webpages and automate specific tasks. They mention using Automa for tasks like clicking expand buttons and filtering lists, which they find helpful for quickly obtaining specific information.

User trntrl expresses interest in Automa and mentions that they experienced a navigation issue on their iPhone, where the hamburger menu did not appear when clicking the documentation link on the landing page.

User mrws discusses their preference for visual workflow automation tools like Power Automate Desktop and MIT Scratch, which they find to have a better user experience. Another user, mgmmlt, agrees with the benefit of visual tools for building macros and shares a link to a platform that helps with building macros.

User mrntw mentions trying Automa and experiencing some typing issues. They found it strange that typing manually produces "hcm" instead of "hmc".

User cvlk adds a comment about the integrated n8n tool, which is a visual workflow automation tool.

Overall, the discussion includes both positive and negative experiences with Automa, with some users finding it helpful for specific tasks while others prefer alternative tools.

### We're sorry we created the Torment Nexus

#### [Submission URL](http://www.antipope.org/charlie/blog-static/2023/11/dont-create-the-torment-nexus.html) | 290 points | by [ttepasse](https://news.ycombinator.com/user?id=ttepasse) | [361 comments](https://news.ycombinator.com/item?id=38218580)

future sells, even if it's just a marketing gimmick. And that's where science fiction comes in. Charlie Stross, a renowned science fiction writer, explains in a recent talk how he and other SF authors are terrible guides to the future. However, their cautionary tales and imaginative visions of a technologically advanced world have captured the attention of billionaires like Elon Musk, Peter Thiel, Marc Andreesen, Jeff Bezos, and Mark Zuckerberg. These individuals, who have a combined net worth in the region of half a trillion euros, have taken the ideas and concepts from science fiction and tried to bring them to life. Stross highlights how science fiction has influenced the media landscape, with a significant number of big-budget movies being science fiction or fantasy blockbusters. Additionally, computer games are filled with SF and fantasy genres. However, when it comes to the physical environment, the influence of science fiction has been gathering pace. The future has become a marketing tool, with trends like streamlining, communication, and computers being associated with science fiction. This can be seen in the design of products like the Motorola Razr and the mis-selling of "self-driving" features in cars. Stross points out the danger of this trend, as the technology is not yet ready and can have lethal failure modes. Nonetheless, the allure of the futuristic sells, and science fiction continues to play a role in shaping our perception of what is possible.

The discussion on this submission revolves around the concept of science fiction and its influence on shaping the future. Some users argue that science fiction writers are not reliable guides to the future, while others believe that they can provide valuable insights and cautionary tales. There is a debate about the intelligence of tech people and their tendency to believe in the ideas presented in science fiction. The discussion also touches on the potential dangers of marketing futuristic technologies before they are ready, citing examples like self-driving cars. 

Some users bring up the example of the "Jurassic Park" novel and movie, pointing out the parallels between the cautionary messages in the story and real-life technological advancements. Others argue that science fiction should not be taken too literally and that it is the responsibility of society to carefully navigate the potential risks. 

There is also a discussion about human arrogance and the tendency to push boundaries, as seen in instances like the Deepwater Horizon oil spill and the Fukushima nuclear disaster. Some users argue that humans often underestimate the potential dangers and consequences of their actions. 

Overall, the discussion highlights the power of science fiction in shaping our perception of the future and the need for caution when bringing these ideas to life.

### GPU advancements in M3 and A17 Pro [video]

#### [Submission URL](https://developer.apple.com/videos/play/tech-talks/111375) | 186 points | by [bhj](https://news.ycombinator.com/user?id=bhj) | [136 comments](https://news.ycombinator.com/item?id=38214806)

Apple has announced the new Apple family 9 GPU architecture in A17 Pro and the M3 family of chips. These GPUs bring advancements in GPU performance and power efficiency to improve the performance of apps and games on Apple devices. The new shader core architecture enhances the performance and power efficiency of existing apps and allows for the development of next-generation apps. Hardware-accelerated ray tracing and mesh shading technologies further enhance rendering effects and geometry processing pipelines. The new GPUs deliver significant performance improvements for gaming and rendering applications.

The discussion on this submission revolves around the technical aspects of Apple's new GPU architecture and how it compares to Nvidia GPUs. 

One user mentions two posts about the shader permutation problem and how it affects GPU performance. They explain that GPUs have a large number of execution paths, making it difficult to optimize performance for all possible scenarios. 

Another user clarifies the terminology used by Apple and Nvidia to describe their GPUs. They explain that Apple refers to its GPU as having 8 cores, while Nvidia refers to its GPU as having 20 "stream multiprocessors" (SMs) consisting of 128 cores each. They also highlight the differences in thread counts between the two GPUs. 

There is also a discussion comparing GPU and CPU architectures, with users explaining the differences in context switching, memory hierarchy, and thread execution. They mention that GPU context switching is faster due to hardware scheduling, while CPU context switching has higher latencies. 

One user questions the performance of GPU latency hiding mechanisms, comparing it to hyper-threading on CPUs. Another user explains that GPU latency hiding is equivalent to hyper-threading, but the mechanisms are different due to architectural design. 

Overall, the discussion delves into the technical aspects of GPU architecture and how it affects performance.

### AI could cause 'catastrophic' financial crisis – Yuval Noah Harari

#### [Submission URL](https://www.theguardian.com/technology/2023/nov/09/yuval-noah-harari-artificial-intelligence-ai-cause-financial-crisis) | 16 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [20 comments](https://news.ycombinator.com/item?id=38220633)

Artificial intelligence (AI) has the potential to cause a "catastrophic" financial crisis, warns historian and author Yuval Noah Harari. He explains that the complexity of AI technology makes it difficult to anticipate all the dangers it poses. Unlike nuclear weapons, AI presents numerous dangerous scenarios, each with a small probability, that together could threaten human civilization. Harari sees last week's global AI safety summit, where leading governments expressed concern and pledged cooperation, as a significant step forward. He notes that AI's ability to make decisions, generate ideas, and learn independently makes it challenging to foresee and regulate all potential dangers. Harari highlights the finance sector as particularly vulnerable to AI-created crises, citing the 2007-08 financial crisis caused by poorly understood debt instruments. He warns that AI has the potential to create financial devices far more complex than anything humans can comprehend or regulate. While an AI-generated financial crisis may not directly destroy civilization, it could lead to indirect catastrophic consequences, such as triggering wars or conflicts. Harari emphasizes the need to establish powerful regulatory institutions that can swiftly identify and respond to emerging dangers, rather than relying solely on specific regulations and laws that may become outdated. He also suggests that AI safety institutes should employ experts knowledgeable about AI's potential impact on finance.

The discussion on Hacker News surrounding the submission about the potential financial crisis caused by AI is varied. Some users express skepticism about the claim, comparing AI to Bart Simpson driving a car off a cliff with cruise control. Others argue that the financial system is already disconnected from reality and that it would be difficult to comprehend the full implications of AI on finance. One user suggests that AI should be regulated to avoid unchecked control over systems that handle large amounts of money. Another user highlights the potential negative impacts of AI on investors. One user criticizes the article for proposing simple solutions to complex issues, while others point out that governments and major AI companies are already taking the dangers of AI seriously. The discussion also touches on topics such as mental health, the need for regulation, and the existing existential risks associated with AI. One comment is flagged for unclear reasons.

