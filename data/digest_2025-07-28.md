## AI Submissions for Mon Jul 28 2025 {{ 'date': '2025-07-28T17:16:50.359Z' }}

### Show HN: Companies use AI to take your calls. I built AI to make them for you

#### [Submission URL](https://www.pipervoice.com/) | 187 points | by [michaelphi](https://news.ycombinator.com/user?id=michaelphi) | [129 comments](https://news.ycombinator.com/item?id=44716414)

Get ready to wave goodbye to dreaded phone calls, thanks to Piper—your personal AI phone call agent that thrives on tackling customer service and scheduling tasks, so you can focus on anything else. Created by the brilliant minds at AssemblyAI, Piper is the latest innovation in voice AI technology.

Imagine spotting a phone number on any website, and with just a click and a simple request typed in, Piper jumps into action. Whether it’s booking a dinner reservation, settling a dispute with your insurance provider, or canceling a pesky subscription without a single guilt trip, Piper handles it all with ease and endless patience. Never again will you be trapped in phone menu purgatory or caught in retention trap guilt trips.

Piper also comes with a sleek Chrome extension that turns every phone number you encounter into a magical opportunity to offload tedious tasks. Whether you're sipping your morning coffee or deep in code review, Piper takes the calls you have no time for and gets results faster than you can say "customer service."

Worried about security or sounding robotic? Piper boasts bank-level encryption to ensure your data is safe and sounds more human than most before their morning caffeine hit. Beta testers get a taste of freedom with 60 free minutes and a lifetime half-price offer on subscription plans.

Piper is not just a tool but a personal assistant at your fingertips, making those mundane calls feel like a breeze. Ready to join the future of unburdened phone call experiences? Try Piper for free and revolutionize the way you handle calls—no credit card required. Embrace the paradise of a phone-free life today!

The Hacker News discussion on Piper, an AI phone call agent by AssemblyAI, reflects cautious optimism and practical skepticism:

1. **Mixed User Experiences**:  
   Users shared anecdotes about existing AI systems, noting successes (e.g., accurately capturing email details) but also frustrations with clunky, impersonal interactions. Some praised AI efficiency for simple tasks like balance checks, while others lamented its inability to handle nuanced issues or complex logic, leading to "phone menu purgatory."

2. **Skepticism About Complexity**:  
   Concerns arose about trusting AI with critical tasks (e.g., insurance disputes). While Piper’s handling of reservations or cancellations was seen as promising, users doubted its reliability for intricate scenarios requiring human judgment, like resolving technical hardware issues or negotiating customer retention.

3. **Human vs. AI Trade-offs**:  
   Discussions highlighted a tension between automation and human touch. Some preferred AI for avoiding hold times, while others emphasized the irreplaceability of human agents for empathy and context-aware problem-solving, especially in industries like plumbing or customer retention.

4. **Business Implications**:  
   Commentators debated whether businesses adopting AI could degrade customer service quality, pointing to poor experiences with Google’s support. Others envisioned AI streamlining small-business operations but worried about scalability challenges for large enterprises.

5. **Technical Concerns**:  
   Criticisms included resource waste from LLM-to-LLM communication and potential misalignments in standardized systems. Suggestions emerged for hybrid models, where AI handles initial queries but escalates complex cases to humans.

6. **Demo Suggestions**:  
   Users proposed real-world demos (e.g., booking reservations) to showcase Piper’s value, while questioning niche applications, like appliance repair logistics.

In summary, the community sees potential in Piper for routine tasks but emphasizes the need for AI to complement—not replace—human nuance in customer interactions.

### GLM-4.5: Reasoning, Coding, and Agentic Abililties

#### [Submission URL](https://z.ai/blog/glm-4.5) | 233 points | by [GaggiX](https://news.ycombinator.com/user?id=GaggiX) | [123 comments](https://news.ycombinator.com/item?id=44711106)

In today's tech spotlight, cutting-edge developments in AI modeling have taken center stage with the debut of GLM-4.5 and its leaner counterpart, GLM-4.5-Air. These models, developed by Z.ai, boast remarkable advancements in unifying reasoning, coding, and agentic capabilities, specifically tailored to meet the growing demands of complex agentic applications.

GLM-4.5, packing a hefty 355 billion parameters, and GLM-4.5-Air, a more compact 106 billion, deploy a dual-mode system. This system includes a "thinking mode" for intensive reasoning tasks and a "non-thinking mode" for rapid-response situations. Their versatility shines through Z.ai's user-friendly interface and accessible open-weights on platforms like HuggingFace.

In terms of performance, GLM-4.5 ranks impressively third across 12 diverse benchmarks evaluating agentic tasks, reasoning, and coding capabilities. Notably, its prowess in agentic tasks was validated on benchmarks like BFCL-v3 and BrowseComp, where it nearly matched the strong performance of Google's o4-mini-high and surpassed Claude-4-Opus.

Moreover, GLM-4.5 stands out in reasoning tasks involving mathematics and science, maintaining high accuracy rates even in challenging contexts like the AIME and GPQA benchmarks. Its abilities are further underscored in coding tasks, where it seamlessly integrates with existing toolkits to deliver comprehensive, full-stack development solutions, ranging from front-end design to backend deployment.

For practitioners and developers eager to explore these advancements, GLM-4.5 not only offers a glimpse into the future of AI's cognitive capabilities but also sets a new standard for efficiency and scalability in AI model development. Access to these powerful tools is available via the Z.ai platform, promising to revolutionize how we approach complex computational tasks.

The discussion revolves around user experiences and technical observations regarding the GLM-4.5 and Claude AI models. Key points include:  
- Users noted instances where **GLM models inconsistently identified themselves** (e.g., switching to "Claude AI" responses), raising questions about API routing or backend processing.  
- Skepticism emerged about **training data contamination**, with debates on whether models subliminally adopt behaviors from shared-training corpora. A cited paper suggested indirect influence without explicit markers.  
- **Technical critiques** addressed statelessness in LLMs, caching issues, and challenges in reprocessing conversations when switching providers mid-discussion. Some users experimented with content policies, triggering warnings for sensitive topics (e.g., Tiananmen Square).  
- Comparisons were drawn between GLM-4.5, Claude, and other models like DeepSeek, highlighting performance inconsistencies and probing transparency in training origins.  
- Overall, the thread blended **practical testing** with deeper concerns about model reliability, censorship, and the opacity of underlying infrastructure.

### Robot hand could harvest blackberries better than humans

#### [Submission URL](https://news.uark.edu/articles/79750/robot-hand-could-harvest-blackberries-better-than-humans) | 105 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [67 comments](https://news.ycombinator.com/item?id=44714954)

In a groundbreaking development for agriculture, a newly designed robot hand promises to revolutionize the berry-picking industry. Developed by Anthony Gunderman and his team at the University of Arkansas (U of A), the "Soft Robotic Gripper for Berry Harvesting" could address the labor shortages plaguing this multi-billion-dollar sector. 

Powered by biomimicry, the innovation borrows from nature, with its design inspired by the way a tulip opens and closes in sunlight. Each of its three soft, pliable fingers is equipped with a force sensor to ensure delicate blackberries are picked without damage, a crucial factor since rough handling can spoil the berries, making them undesirable for consumers and leading to rejections by the USDA.

But before this robotic hand can begin transforming farms, it needs further development in computer vision and positioning technologies to accurately locate berries on the plant. The current model, tested on various objects, shows promise not just for blackberry harvesting, but potentially for other soft fruits like raspberries and in applications assisting those with limited mobility.

Gunderman envisions this technology surpassing the human hand for this specific task, offering more consistent quality regardless of the picker’s experience level. With the patent secured by U of A's Technology Ventures, this innovation stands at the forefront of agricultural ingenuity, potentially setting a new standard for how delicate fruits are harvested.

For more details, read about the U of A's contributions to research and innovation on their website.

**Summary of Discussion:**

The discussion around the berry-picking robot hand highlights both optimism and skepticism, focusing on technical, economic, and practical challenges:

1. **Technical Hurdles**:  
   - Users emphasize that **computer vision and positioning** remain significant obstacles. Detecting ripe berries, especially amid leaves and branches, requires advanced systems not yet fully realized.  
   - Some compare the gripper to existing solutions (e.g., [OnRobot](https://www.onrobot.com/), [FingerVision](https://www.fingervision.jp/)), suggesting the concept isn’t entirely novel.  
   - Questions arise about durability in real-world conditions, such as dirt or moisture, with mentions of **pressure-washing requirements** for farm machinery, which could damage sensitive components.

2. **Economic Realities**:  
   - Critics argue **labor costs** in agriculture are still often cheaper than robotics, especially in regions reliant on low-wage workers. Transitioning to robots might be economically viable only for large-scale operations.  
   - Maintenance, repair, and initial hardware costs (e.g., vision models) are flagged as barriers, with one user noting that even a "$0.02 per pick" robot could struggle to offset human labor expenses.  

3. **Existing Alternatives**:  
   - Links to current technologies like **combine harvesters** modified for berries or mechanical shakers reveal that some automated solutions already exist, though they may damage crops.  
   - A commenter references **selective plant breeding** (e.g., thornless blackberries) as a complementary strategy to ease robotic harvesting.

4. **Skepticism and Timing**:  
   - Many doubt the “10-year prediction” for adoption, citing historical delays in agricultural robotics.  
   - University press releases are critiqued for overhyping prototypes, with users urging caution until rigorous field testing is done.  

5. **Miscellaneous Points**:  
   - Debate over whether the gripper’s biomimetic design offers meaningful advantages versus simpler mechanisms.  
   - Social concerns about labor displacement are briefly mentioned, though some counter that agribusinesses prioritize profit over worker welfare.  

In conclusion, while the innovation is seen as promising, the discussion underscores the gap between academic prototypes and scalable, cost-effective farm solutions. Challenges in vision systems, economic viability, and real-world durability remain significant hurdles.

### LLM Embeddings Explained: A Visual and Intuitive Guide

#### [Submission URL](https://huggingface.co/spaces/hesamation/primer-llm-embedding) | 433 points | by [eric-burel](https://news.ycombinator.com/user?id=eric-burel) | [84 comments](https://news.ycombinator.com/item?id=44708028)

Today on Hacker News, a submission that's gaining attention is from the GitHub project "hesamation/primer-llm-embedding." This project is designed to serve as a primer on large language models (LLMs) and their use of embeddings. With 175 users refreshing the page to explore more about implementations, it highlights a growing interest in understanding how LLMs process and make sense of complex datasets. By focusing on embeddings, the project aims to demystify a core component of how these models transform text into numerical representations, which is crucial for a range of applications like NLP and AI-driven insights. Whether you're a seasoned data scientist or a curious newcomer, this GitHub repository offers valuable resources and insights into the underpinnings of modern AI frameworks.

The Hacker News discussion on embeddings in LLMs revolves around their complexity, applications, and challenges. Key points include:

1. **Interpretability & Technical Nuances**  
   - Embeddings encode semantic meaning through training but are often **inscrutable**, despite efforts to make internal features interpretable (e.g., Anthropic’s Sonnet 3.1).  
   - Positional embeddings (e.g., RoPE, YaRN) are critical for handling long-context sequences, though debates persist about their coupling with attention mechanisms.  

2. **Mathematical Properties**  
   - High-dimensional embeddings are nearly **orthogonal**, making cosine similarity more effective than Euclidean distance for comparing vectors.  
   - Techniques like t-SNE help visualize clusters in lower dimensions, though user "nmbj" clarifies that vectors in high dimensions are inherently orthogonal, not just after projection.  

3. **Training & Implementation**  
   - Embeddings are **trained via backpropagation**, not static lookup tables. Indexing operations (token-to-vector mapping) are differentiable, enabling gradient updates.  
   - GPT’s decoder-only architecture generates text autoregressively, contrasting with BERT’s bidirectional encoder for contextual understanding.  

4. **Applications & Limitations**  
   - Used in **RAG systems** and vector databases for retrieval, though their abstraction limits direct human interpretability.  
   - Positional encoding adjustments and tokenization changes (e.g., recent papers like [arXiv:2507.07955](https://arxiv.org/abs/2507.07955)) address sequence-modeling challenges.  

5. **Comparisons & Resources**  
   - BERT (encoder) vs. GPT (decoder): BERT focuses on contextual understanding, while GPT prioritizes text generation.  
   - References to Hugging Face’s blog on modern BERT and tools like Logit Lens for probing intermediate embeddings.  

The dialogue underscores embeddings’ role as a "Rosetta Stone" bridging language and computation, paired with skepticism about their opacity and the technical hurdles in leveraging them effectively.

### LLMs can now identify public figures in images

#### [Submission URL](https://minimaxir.com/2025/07/llms-identify-people/) | 40 points | by [minimaxir](https://news.ycombinator.com/user?id=minimaxir) | [6 comments](https://news.ycombinator.com/item?id=44715132)

Imagine transforming the way we search for images by using a pipeline to represent them as semantic structured data through multimodal Large Language Models (LLMs). An innovative project explores this concept, starting from a straightforward test: identifying public figures in images, like President Barack Obama, using various LLMs. 

In a detailed experiment, several models were put to the test. ChatGPT and Claude, known for their cautious privacy policies, initially stumbled when tasked with identifying President Obama. These models have strict guidelines potentially preventing them from recognizing individuals, which might stem from a strong emphasis on AI safety and privacy.

In contrast, Google's Gemini, Meta's Llama, and models from Alibaba and Mistral showed no such hesitation and accurately identified notable figures. This divergence likely results from different training methods and reinforcement learning strategies among the LLMs. The results suggest that some models might handle privacy less strictly, especially when identifying well-known personalities.

Further tests involved less famous individuals, such as the author, who wasn't recognized by any model, re-affirming their criteria for notability. However, when analyzing an image of Mark Zuckerberg and Priscilla Chan, only some models successfully identified both figures, revealing differences not only in recognition capabilities but also in spatial awareness and ordering.

Through these experiments, the project underscores the varied performance and strategies of LLMs in image recognition and categorization. It opens up a discussion on privacy, training protocols, and the potential of LLMs in enhancing image searching and tagging through semantic data structuring. This study is a stepping stone for future explorations into integrating multimodal LLMs for more sophisticated and practical applications in image identification.

**Summary of Discussion:**

The discussion revolves around challenges and opinions regarding LLMs' ability to recognize faces and address privacy concerns. Key points include:  

1. **Face Recognition Tools & Limitations**:  
   - User **srk** argues that LLMs trained with RLHF (Reinforcement Learning from Human Feedback) may avoid identifying non-public figures due to ethical safeguards. Tools like **PimEyes** and **FaceCheck** were debated, with **Kuinox** claiming FaceCheck failed, while **srk** countered that it works but has UI limitations (e.g., difficulty selecting/cropping reference photos).  

2. **Privacy Concerns**:  
   - **phtskt** expressed surprise at LLMs' inaccuracies and raised alarms about privacy. They highlighted risks of models compiling public data (e.g., Facebook posts, Google profiles) and "stock photos," stressing the need for safeguards.  

3. **Model Performance**:  
   - **mcphg** questioned Google’s Gemini after it reportedly misidentified actor Ebon Moss-Bacharach.  
   - **throwaway314155** defended ChatGPT’s capabilities, hinting at its potential to support such tasks.  

**Themes**: Skepticism about LLMs' reliability for facial recognition, technical hurdles with existing tools, and debates over balancing accuracy with privacy protections.

### Claude Code Router

#### [Submission URL](https://github.com/musistudio/claude-code-router) | 154 points | by [y1n0](https://news.ycombinator.com/user?id=y1n0) | [53 comments](https://news.ycombinator.com/item?id=44705958)

In today's top Hacker News story, the Claude Code Router emerges as a robust tool designed to streamline communication between multiple model providers for coding infrastructure. Developed by musistudio, this open-source project allows users to efficiently route requests to various AI models, such as those offered by OpenRouter, DeepSeek, Ollama, Gemini, and more. This routing is customizable based on specific needs, like handling background tasks or long contexts.

The router leverages dynamic model switching capabilities, enabling users to pivot between models effortlessly using simple commands. Developers can also integrate this tool into GitHub Actions, facilitating automated workflows driven by Claude Code.

Installation of the Claude Code Router is straightforward, requiring users to have Claude Code installed and then configuring settings via a JSON file. This configuration includes options for setting API keys, logging preferences, and establishing rules for routing requests to different models. Moreover, the tool supports a plugin system to further enhance functionality through custom transformers.

With its powerful features and ease of setup, the Claude Code Router is a promising choice for those looking to harness the capabilities of different AI models in a seamless and efficient manner.

**Summary of Hacker News Discussion:**

The discussion around Claude Code Router highlights a mix of enthusiasm, skepticism, and practical concerns from developers:

1. **Security and Reliability Concerns**  
   - Users worry about vulnerabilities like **prompt injection** and false positives when relying on LLMs for code review. Some argue LLMs lack the stability for critical tasks, with error rates perceived as high (e.g., "50% failure rate" claims).  
   - Skeptics caution against overtrusting AI for security-sensitive workflows, though others note that newer models like Claude’s 200K-token context handling show promise.  

2. **Comparisons to Alternatives**  
   - Tools like **Aider** and **RooCode** are mentioned, with some users switching to Claude Code Router for better IDE integration (e.g., IntelliJ support) or workflow automation.  
   - Mixed experiences: Aider’s Git integration is praised, while Claude Code Router is seen as more flexible for multi-model routing.  

3. **Cost and API Usage**  
   - Users report varying API costs, with one noting a $40/day expense via Anthropic’s platform. OpenRouter and DeepSeek are suggested as cheaper alternatives.  
   - Debates arise over AI company profitability, with references to **“Hollywood accounting”** allegations against firms claiming losses despite high token sales.  

4. **Technical Capabilities**  
   - Claude’s 200K-token context is praised, but doubts linger about its reliability for complex tasks like code translation (e.g., C++ to C99+).  
   - Some highlight LLM strengths in syntax-heavy tasks, though others warn against overestimating current capabilities.  

5. **Broader Industry Sentiment**  
   - Comparisons to historical tech shifts (e.g., transistors) reflect debates on whether AI tools are transformative or incremental.  
   - Critiques emerge about the gap between “hype” and practical ROI, with one user mocking GenAI’s “$20,000 investment for $100 returns” scenarios.  

**Overall**: While Claude Code Router is seen as a flexible tool for multi-model workflows, the discussion underscores broader tensions about AI’s role in development—enthusiasm for automation is tempered by concerns over cost, reliability, and security.

### Why not Matrix (2023)

#### [Submission URL](https://telegra.ph/why-not-matrix-08-07) | 38 points | by [throwachimera](https://news.ycombinator.com/user?id=throwachimera) | [67 comments](https://news.ycombinator.com/item?id=44714994)

Matrix, the "open network for decentralized communication," has generated buzz in the tech community for its promise of providing a free, federated platform. While many projects have shifted from platforms like IRC, Discord, and Slack to embrace Matrix, the system's underlying complexity and privacy challenges present a few potential drawbacks.

At its core, Matrix functions as a distributed, partially-replicated graph database. Users interact in "rooms," which are actually directed acyclic graphs (DAGs), where events like messages and user actions form an append-only history. Although this structure ensures persistent records, it also implies that data accumulation is inevitable, complicating data deletion efforts—not ideal for applications requiring privacy and confidentiality.

The append-only nature of Matrix means events can't be easily erased. When deletions are needed, users can send "redaction events" requesting other servers to wipe specific data, but these requests can be ignored. A misbehaving server could retain and potentially share this supposedly deleted information, posing privacy risks.

Spam attacks are another threat, as joining the room with numerous bots can create a complex graph, burdening servers and client systems alike—particularly in encrypted rooms. To alleviate spam, recreating a room is often necessary.

Moreover, synchronizing room history across servers introduces inconsistency. Since the system relies on causal ordering and tiebreakers that can be tampered with, different servers might display messages in varying sequences, creating discrepancies in chat history.

While Matrix offers optional end-to-end encryption, it's necessary to maintain manageable public room operations but highlights a tradeoff in privacy. Unencrypted data can spread across servers in plaintext, making careful client-level encryption essential for private conversations.

Despite these concerns, the potential of Matrix's decentralized approach and open standard still holds significant appeal. As the network continues to evolve, addressing the enumerated challenges could solidify its standing as a robust, privacy-conscious communication platform.

**Summary of Discussion:**

The discussion around **Matrix** highlights mixed sentiments, balancing its potential as a decentralized platform with persistent technical and usability concerns:

1. **Technical Challenges & Improvements**:
   - Users acknowledge efforts to improve **end-to-end encryption (E2EE)** and data deletion (e.g., redaction events). However, skepticism remains around encryption fragility, unresolved bugs (e.g., "Unable to Decrypt" errors), and reliance on client compliance for security.
   - The Matrix team ("Arathorn") points to updates in 2024 addressing security, spam, and synchronization, including stricter server-client protocols and better history management. Critics argue issues like inconsistent message ordering and server trust persist.

2. **Client Ecosystem & Usability**:
   - Building reliable clients is seen as challenging, though projects using **Rust libraries** or protocols like **Simplex** (privacy-focused) receive praise. Official clients (e.g., Element) face criticism for **under-documented features** and poor user experience compared to Signal or Slack.

3. **Adoption vs. Centralization**:
   - Matrix's adoption by **European governments** (France, Germany) adds credibility but raises concerns about centralized control through large institutional deployments.
   - Alternatives like **XMPP** are suggested, though Matrix’s federated design is still favored by some for its decentralization.

4. **Privacy & Trust Concerns**:
   - Data retention and server compliance remain issues: malicious servers can ignore deletion requests, and unencrypted public rooms risk data exposure.
   - Comparisons to **Signal's protocol** highlight gaps in metadata privacy and encryption robustness, with doubts about Matrix’s ability to fully replace centralized platforms.

5. **Community Sentiment**:
   - Supporters praise Matrix for **self-hosting** and avoiding corporate surveillance, while critics stress its complexity and unfinished feel. User experiences vary widely, from seamless chats to frustration with sync issues and spam.

**Conclusion**: Matrix is seen as a promising but evolving platform, grappling with decentralization trade-offs and technical growing pains. While improvements are noted, trust in its ecosystem depends on resolving encryption quirks, enhancing client quality, and ensuring consistent privacy controls.

