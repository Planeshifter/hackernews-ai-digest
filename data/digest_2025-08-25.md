## AI Submissions for Mon Aug 25 2025 {{ 'date': '2025-08-25T17:14:46.327Z' }}

### Scamlexity: When agentic AI browsers get scammed

#### [Submission URL](https://guard.io/labs/scamlexity-we-put-agentic-ai-browsers-to-the-test-they-clicked-they-paid-they-failed) | 201 points | by [mindracer](https://news.ycombinator.com/user?id=mindracer) | [190 comments](https://news.ycombinator.com/item?id=45011096)

Guardio Labs tested today’s agentic AI browsers and found inconsistent or missing guardrails that let AIs click, buy, and hand over data without user awareness. They call the new risk landscape “Scamlexity” — familiar scams supercharged by AI that acts on your behalf.

What they did
- Target: Perplexity’s Comet (a publicly available agentic browser). Context: Microsoft Edge + Copilot and OpenAI’s experimental agent mode are heading the same way.
- Scenario 1: Fake Walmart shop spun up with Lovable. Prompt: “Buy me an Apple Watch.” Comet parsed the HTML, clicked through, and in some runs auto-filled saved address and credit card from the browser’s autofill, completing “purchase” on an obviously fake site. Google Safe Browsing didn’t block it. Behavior varied across runs (sometimes refused, sometimes asked for manual checkout).
- Scenario 2: Real, in-the-wild Wells Fargo phishing flow (email-to-site). The point: agents will confidently traverse inbox and web like a user, but with less skepticism.
- Scenario 3: “PromptFix,” a modern take on ClickFix: a fake CAPTCHA hides prompt-injection instructions to seize control of the agent.

Why it matters
- The scammer no longer needs to fool you — only your AI. With shared models and automated actions, one exploit can scale to millions.
- UX-first agent design plus AI’s compliance bias yields quiet, high-impact failure modes (payments, downloads, data entry).

What needs fixing
- Default-deny sensitive actions; explicit, per-step user approvals for payments, logins, downloads, and autofill.
- Disable or segregate browser autofill and wallets in agent sessions; isolate cookies and identities.
- Robust anti–prompt injection and “treat all page text as untrusted,” especially inside CAPTCHAs/overlays.
- Stronger URL/content reputation checks and e-commerce/phishing heuristics; human-in-the-loop “dry run” modes with visible action plans.
- Clear action logs and rollback; red-team and standardized safety evals for agentic browsing.

User tip: Don’t store cards in browser autofill if you’re experimenting with AI agents; require 2FA and manual confirmation for purchases.

The discussion revolves around the risks and implications of AI agents autonomously making purchases and completing tasks on behalf of users, with critiques and examples highlighting key concerns:

1. **Unintended Purchases and Exploitation**:  
   - Users compare AI agents to Amazon's Dash buttons and Alexa, which historically led to accidental purchases and profit-driven reframing of consumer behavior. For example, even a 1% accidental purchase rate with low return rates can generate profit for companies.  
   - Jokes are made about AI agents subscribing to "AI agent services" themselves (e.g., "$1995/month"), creating a cycle of automated spending.

2. **Mismatch with Real-World Needs**:  
   - Critics argue AI agents often solve problems primarily for wealthy tech users (e.g., restaurant reservations, luxury services) rather than addressing everyday needs, such as grocery shopping for regular households.  
   - Skepticism is raised about AI’s practicality for infrequent tasks like booking restaurants, which many users handle manually for special occasions.  

3. **Trust and Manipulation Risks**:  
   - Concerns include AI agents falling for scams, dynamic pricing schemes, or being influenced by retailers to prioritize profit over user interests. Proprietary web apps might limit price transparency, undermining fair competition.  
   - Examples highlight AI agents ordering counterfeit products (e.g., vitamins) or misinterpreting user intent, such as purchasing wrong school supplies.  

4. **Ethical and Economic Implications**:  
   - Users worry AI agents could escalate consumerism, with profit-driven incentives leading to "dark patterns" that manipulate spending. Critics liken this to a "capitalist innovation treadmill" favoring convenience over security.  
   - The potential for AI to centralize power with retailers (e.g., Amazon dictating prices) raises concerns about market fairness.  

5. **Calls for Safeguards and Critical Evaluation**:  
   - Suggestions include manual confirmation for purchases, isolating payment data, and stronger transparency in AI decision-making.  
   - Users emphasize the need to critically assess whether AI agents genuinely solve problems or merely create new risks for consumer autonomy.  

**Key Takeaway**: While AI agents promise convenience, their current implementations risk exploitation, misaligned incentives, and unintended consequences, demanding stricter safeguards and a reevaluation of their role in commerce.

### Show HN: Stagewise – frontend coding agent for real codebases

#### [Submission URL](https://stagewise.io/) | 35 points | by [glenntws](https://news.ycombinator.com/user?id=glenntws) | [15 comments](https://news.ycombinator.com/item?id=45015838)

What it is: A YC-backed tool that runs locally and overlays a toolbar on your live dev app. You click elements in the browser, prompt what you want, and Stagewise edits your actual codebase—aiming to be “Dreamweaver meets Copilot” for modern stacks.

How it works:
- Start your app (npm run dev), then run npx stagewise@latest in your project
- A browser toolbar analyzes your DOM, styles, and components
- Select elements, prompt changes, see updates instantly, and iterate visually

Notable features:
- Framework-agnostic: works with React, Vue, Angular, Svelte, Next.js, Nuxt
- Context-aware edits: understands component structure and existing design systems to make “smart” styling choices
- Visual development: comment on live elements and apply changes in place
- Plugin system: add framework-specific context (React/Vue/Angular plugins) to improve accuracy

Why it matters: Targets the designer–developer feedback loop by letting teams make production-ready UI changes rapidly without leaving the browser. Early testimonials claim significant time savings and smoother collaboration.

TL;DR: A local, browser-native AI coding agent for frontend teams—click an element, describe the change, and Stagewise updates your code with immediate visual feedback across popular frameworks.

**Summary of Hacker News Discussion on Stagewise:**

1. **Critiques of Code Generation:**
   - **Hardcoded CSS:** Users criticized the demo for using fixed pixel values (e.g., `298px` height) instead of modern CSS practices (variables, responsive units), questioning maintainability.
   - **Context Awareness:** Some argued the AI lacks understanding of CSS layout context (e.g., variables, constraints) and framework logic, leading to suboptimal code. A user noted, *“CSS requires understanding merging properties… this isn’t context-dependent.”*

2. **Design and Use Case Concerns:**
   - **Dynamic Components:** Questions arose about handling dynamic content (e.g., landing pages), with one user sharing a screenshot of their fix and warning about rigid design choices.
   - **“YOLOing” Design:** A comment joked about haphazard design decisions (e.g., *“Oracles processes using YOLOing”*), sparking debate on balancing creativity vs. structure in component design.

3. **Open-Source Interest:**
   - Users sought clarity on open-source availability, noting the lack of GitHub documentation. A maintainer linked an early repo and contribution guide but admitted limited progress.

4. **Technical and Security Notes:**
   - **Prompt Engineering:** Tweaking system prompts to respect project-specific styles (e.g., dark mode) was suggested to improve AI outputs.
   - **Sandboxing:** One user criticized the tool’s security for running AI agents directly in the browser without isolation.

**Key Takeaways:**  
While Stagewise’s visual editing and framework-agnostic approach were acknowledged, the discussion focused on concerns about rigid codegen, limited CSS context handling, and transparency (open-source, security). The team’s next steps might involve addressing these critiques with clearer documentation, responsive design examples, and community collaboration.

### Show HN: Async – Claude Code and Linear and GitHub PRs in One Opinionated Tool

#### [Submission URL](https://github.com/bkdevs/async-server) | 20 points | by [wjsekfghks](https://news.ycombinator.com/user?id=wjsekfghks) | [11 comments](https://news.ycombinator.com/item?id=45013572)

Async (bkdevs/async-server): an open-source tool that stitches together AI coding, task tracking, and code review into one opinionated workflow. Think Claude Code + Linear-style issues + GitHub PRs, with everything running in isolated cloud jobs so it doesn’t touch your local setup.

What it does
- Researches tasks first: clones your repo, analyzes the codebase, and asks clarifying questions before making changes.
- Executes safely in the cloud: creates a feature branch, breaks work into subtasks, commits each separately, and opens a PR.
- Streamlines review: shows stacked diffs per subtask; review comments can spawn new subtasks; approve to squash-and-merge.
- Handles the full loop: from imported GitHub issue → research → implementation → review → merged PR.

Why it’s interesting
- Targets mature codebases where “don’t break things” is key.
- Forces upfront planning and reduces context switching by running asynchronously in the background.
- Avoids PM bloat by treating GitHub issues as the source of truth.

How it works (under the hood)
- GitHub App imports issues; Google Cloud Run jobs handle research, execution, revision, and indexing.
- Uses Claude Code for implementation; OpenAI/Anthropic/Google models for research.
- Backend: FastAPI; data: Firebase Firestore; integrates GitHub, Stripe, email. MIT licensed.
- Includes a REST/WebSocket API and local dev setup; demo at async.build.

Here's a concise summary of the discussion around the Async tool:

**Key Themes & Feedback**  
1. **Philosophy & Approach**  
   - Commenters praise Async's "straight-through" workflow design for mature codebases, reducing context switching. Some question how it handles long-tail edge cases and stylistic nuances in PR reviews.  
   - Creator responds: System leverages Claude Code's strength in following strict prompts, with explicit comment requirements to maintain focus on functional requirements and code style.  

2. **AI Model Comparisons**  
   - Multiple users highlight Claude's superiority over GPT for code implementation tasks when given strong system prompts.  
   - One user proposes using multiple Claude instances as "workers" for complex research tasks, though others note this could add complexity vs single-instance approaches.  

3. **Deployment & UX**  
   - Self-hosting capability sparks interest as a potential selling point.  
   - Requests emerge for lightweight local UI options alongside cloud execution. Creator confirms local tooling/demo video is planned.  
   - Mobile-first approach (vs desktop) explained as intentional, though desktop version considerations are acknowledged.  

4. **Comparisons**  
   - Seen as complementary to GitHub Copilot Agent but differentiated by full workflow integration (issues → PR → review).  

**Creator Engagement**  
Maintainer actively addresses feedback, clarifying design decisions around mobile/cloud priorities, Claude's prompt engineering advantages, and roadmap items like local tooling.

### Cornell's world-first 'microwave brain' computes differently

#### [Submission URL](https://newatlas.com/computers/cornell-microwave-brain/) | 28 points | by [wjSgoWPm5bWAhXB](https://news.ycombinator.com/user?id=wjSgoWPm5bWAhXB) | [6 comments](https://news.ycombinator.com/item?id=45012191)

Cornell’s “microwave brain” is an analog neural chip that computes with RF waves instead of digital bits. It’s billed as the first fully integrated silicon microwave neural network, capable of doing ultrafast signal processing and wireless-comm tasks at the same time on-chip.

Key points
- What it is: An analog, microwave-domain neural network implemented on a silicon chip. It leverages the physics of RF propagation and interference to perform computation, rather than clocked digital logic.
- Why it matters: Analog RF computing can exploit parallelism and continuous values, potentially delivering lower latency and far better energy efficiency for edge inference tasks than digital accelerators.
- Reported metrics: Runs at “tens of GHz” while consuming ~200 mW; achieved 88% accuracy classifying wireless signal types in tests.
- Potential uses: On-device AI in phones/wearables without cloud round-trips; spectrum sensing and anomaly detection; hardware security features; radar target tracking; radio signal decoding.
- Research claims: A probabilistic computing approach that maintains accuracy on both simple and complex tasks without the added digital overhead for precision/error correction.
- Publication: Nature Electronics; work from Cornell University.

Why HN will care
- Edge AI inside radios: Folding inference directly into RF front-ends could shrink latency and power for 5G/6G, IoT, and radar workloads.
- Analog renaissance: Echoes classic analog VLSI/neuromorphic ideas (compute where the physics is), now pushed into the microwave regime with modern CMOS.

Caveats and open questions
- 88% on what dataset/task? How does it compare to lightweight digital baselines at equal power/latency?
- Programmability: How are “weights” set/tuned? Is training done digitally with analog-only inference?
- Robustness: How sensitive is it to noise, temperature, process variation, drift, and aging? What calibration is required?
- Scale: Network size, throughput (inferences/s), energy per inference, and how it composes with larger ML stacks.
- “First” claim: There’s prior RF/photonic/analog neuromorphic work; details of integration level and generality will matter.

Bottom line
If the power/latency numbers hold for real workloads, a microwave-domain neural layer embedded in radios could make spectrum intelligence and wireless-edge AI far more efficient. The headline accuracy is modest and the article is light on architecture/training details, but the direction—computing in the native physical domain of the signal—is compelling.

The Hacker News discussion on Cornell's "microwave brain" chip reflects mixed reactions and technical curiosity, with key points summarized below:

1. **Link Accessibility Issues**:  
   Users noted difficulties accessing the original Cornell University article, likely due to DNS blocking or URL formatting. An alternative link to the Nature Electronics publication was shared ([Nature article](https://www.nature.com/articles/s41928-025-01422-1)).

2. **Analog vs. Digital Debate**:  
   - **Pro-Analog Sentiment**: One user celebrated analog computing ("Long live analog"), aligning with the paper’s emphasis on analog’s efficiency for RF tasks.  
   - **Digital Skepticism**: Others questioned whether analog’s benefits outweigh digital’s precision, arguing that digital processing remains necessary for decoding signals and ensuring accuracy ("digital processing needed regardless of analog front-end").  

3. **Practical Concerns**:  
   A comment critiqued the submission’s phrasing ("digital killed analog parameters unnecessarily"), hinting at broader skepticism about analog’s real-world viability compared to established digital methods.  

**Summary**:  
The discussion highlights cautious optimism about analog RF computing’s potential but emphasizes practical hurdles (e.g., hybrid digital-analog workflows, accessibility of research details). While some praised the analog approach’s efficiency, others stressed digital’s irreplaceability in signal processing, reflecting HN’s engineering-focused scrutiny of novel claims.

