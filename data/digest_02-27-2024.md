## AI Submissions for Tue Feb 27 2024 {{ 'date': '2024-02-27T17:10:05.646Z' }}

### The Marvelous Automata of Antiquity (2018)

#### [Submission URL](https://daily.jstor.org/the-marvelous-automata-of-antiquity/) | 33 points | by [taupe-](https://news.ycombinator.com/user?id=taupe-) | [5 comments](https://news.ycombinator.com/item?id=39518535)

In a world long before the digital age, ancient engineers and craftsmen crafted wondrous automata that blurred the line between human and machine. From the elaborate special effects in the throne room of Constantine VII to Mark Antony's theatrical use of automata, these mechanical marvels aimed to evoke a sense of the miraculous. Automata were not always designed to unsettle; they often delighted and entertained audiences. In medieval Cairo, automata graced palaces, such as the singing girls carved from camphor and amber that charmed guests with their movements. One of the most influential works on automata was Ismail al-Jazari's "The Book of Knowledge of Ingenious Mechanical Devices," featuring intricate devices like the hand-washing tower with a bejeweled peacock. Al-Jazari's influence extended across continents, shaping the evolution of automata in Europe and the Middle East. Table fountains, popular in medieval times, exuded whimsy and enchantment, such as the elaborate fountain at the Cleveland Museum of Art. Legends of hidden automata guarding treasures beneath the earth captured the imagination, reflecting a belief in the enduring legacy of ancient empires through these mechanical guardians.

- "MyFirstSass" shared their surprise at discovering historical artifacts related to automata in Vienna and highlighted the detailed descriptions of advanced mechanical contraptions like banquet devices that left an impression on them. They vividly remembered seeing a ship-driven table musical come to life, as well as a miniature cannonball-shooting fort in 1585, both of which fascinated them.
- "jnndnly" recommended the book "Gods and Robots: Myths, Machines, and Ancient Dreams of Technology" by Adrienne Mayor for those interested in ancient Greek robots, citing its ISBN for reference.
- "tp-" thanked "jnndnly" for the book recommendation on the topic.
- "tp-" reflected on the importance of understanding the implications and potential of artificiality in human history, emphasizing the significance of terminology, art, and design in the creative process of crafting human-like mechanisms.
- "dr_dshiv" appreciated the find shared by "MyFirstSass" and mentioned collecting books related to Renaissance-era technology that intersect with early AI development.

### The /unblock API from Browserless: dodging bot detection as a service

#### [Submission URL](https://www.browserless.io/blog/2024/02/26/unblock-api/?apcid=00620de59ffc742367908900&utm_campaign=unblock-api-announcement&utm_content=unblock-api-announcement&utm_medium=email&utm_source=ortto) | 164 points | by [keepamovin](https://news.ycombinator.com/user?id=keepamovin) | [137 comments](https://news.ycombinator.com/item?id=39526797)

Browserless v2 has launched with the new /unblock API, offering a fresh approach to evading bot detectors. The constant battle between bots and WAFs necessitates more advanced solutions, as traditional methods like mimicking JavaScript APIs or adjusting Chrome flags are becoming less effective against Cloudflare's evolving protections. The /unblock API focuses on humanizing traffic by addressing subtle bot identifiers like the default browser size set by Puppeteer at 800x600 pixels. By modifying behavior at the Chrome DevTools Protocol layer, the API ensures that Chrome is launched in a more realistic 1920x1080 pixel setting, thus concealing bot fingerprints. This innovative API aims to simulate human browsing behavior to bypass bot detection while offering a range of features from connecting Puppeteer to unblocked browsers to generating cookies and screenshots. Developers can easily access the /unblock API by utilizing the new V2 service and following the provided code snippet. The API is now available for a 7-day trial with browserless, offering a resource-intensive process that requires additional Units beyond the free tier. Stay ahead of bot detection mechanisms with browserless and experience the benefits of seamless automation and scraping.

The discussion on the submission about Browserless v2 launching with the new /unblock API covers various perspectives. Some comments mention the conflict between developers trying to scrape data and businesses implementing measures to protect their content. There is also a debate on the legitimacy of scraping public versus semi-public data without consent and the ethical considerations of scraping content models. One user talks about the potential future of AI-generated content and the evolving landscape of bot detection. Other comments touch on challenges faced by developers in scraping data, the importance of gathering commercial data, and the complexities of balancing data access and protection.

Further discussions explore the issues around web scraping, such as the impact of negative sentiments derived from scraped data, strategies for bypassing bot detection mechanisms, and the implications of hosting websites that may be vulnerable to scraping. Additionally, there are conversations about the ethical aspects of scraping content, particularly in relation to data privacy and security concerns.

Overall, the comments reflect a broad range of opinions on the ethical, legal, and technical aspects of web scraping, highlighting the ongoing complexities and challenges in this field.

### Here lies the internet, murdered by generative AI

#### [Submission URL](https://www.theintrinsicperspective.com/p/here-lies-the-internet-murdered-by) | 112 points | by [ctoth](https://news.ycombinator.com/user?id=ctoth) | [45 comments](https://news.ycombinator.com/item?id=39527477)

The internet is in turmoil as generative AI floods online platforms with synthetic content, creating a chaotic landscape of misinformation and scams. From AI-generated books and articles to deepfake porn and fake social media accounts, the impact of this technology is far-reaching and insidious. Even reputable outlets like Sports Illustrated have been caught using AI-generated authors to churn out low-quality content for profit. As AI increasingly infiltrates every corner of the internet, the line between real and fake is becoming increasingly blurred, with toddlers being subjected to nonsensical AI-generated content on platforms like YouTube Kids. The consequences of this "semantic apocalypse" are dire, as we witness the gradual decay of online authenticity and integrity.

The discussion on Hacker News revolves around the implications of generative AI flooding online platforms with synthetic content, particularly impacting children viewing YouTube. Users express concerns about the proliferation of AI-generated content on platforms like YouTube Kids and the potential misinformation and harmful content it may expose children to. Some users share their experiences with trying to limit or control the content accessed by kids, such as installing Ubuntu Linux on devices instead of iPads. Other topics discussed include strategies to regulate AI-generated content, the role of technology in society, and the potential dangers of AI advancements.

### Tumblr's owner is striking deals with OpenAI and Midjourney for training data

#### [Submission URL](https://www.theverge.com/2024/2/27/24084884/tumblr-midjourney-openai-training-data-deal-report) | 61 points | by [Tomte](https://news.ycombinator.com/user?id=Tomte) | [4 comments](https://news.ycombinator.com/item?id=39529253)

In a recent report by 404 Media, it has been alleged that Tumblr's owner, Automattic, is in talks with AI companies, Midjourney and OpenAI, to provide training data scraped from users' posts. The report suggests that deals between the companies are imminent, sparking rumors and concerns among Tumblr users regarding data privacy. Automattic is reportedly planning to launch a new setting allowing users to opt out of data sharing with third parties, including AI companies. However, questions remain about the handling of past data and the specifics of the proposed agreements.
While Automattic has stated that they prioritize user choice and only share public content from sites that haven't opted out, details about the nature and scope of the partnerships with AI companies remain vague. The use of publicly available online data for training AI models has drawn criticism from artists and writers who are wary of their work being used without consent. This news comes amidst a trend of companies partnering with AI tool makers for training data, highlighting the ongoing tension between innovation and user privacy in the online space.
As more information unfolds about these potential deals and their implications, concerns about data privacy, user consent, and the monetization of platforms like Tumblr continue to be at the forefront. The evolving landscape of AI partnerships in the tech industry raises important questions about ethical data practices and the balance between innovation and user rights.

1. User "zrn900" mentioned that many organizations previously followed high deals upon the source of Automattic receiving $150 million in 2020, speculating about potential valuations and deals involving VC investors.
2. User "tchny" related this to the success story of Github, highlighting how it started as a bootstrapped company with 80 employees, but changed its path to accommodate VCs and their funding, drawing parallels to the current trend with AI companies like Microsoft.
3. User "Alifatisk" briefly mentioned the relationship between ClosedAI and OpenAI, focusing on their involvement with Reddit discussions.
4. User "ChrisArchitect" provided a reference to an article for further discussion, suggesting that readers visit a link for additional insights and perspectives on the topic.

### Synthetic data generation for tabular data

#### [Submission URL](https://github.com/sdv-dev/SDV) | 53 points | by [skadamat](https://news.ycombinator.com/user?id=skadamat) | [12 comments](https://news.ycombinator.com/item?id=39528192)

The Synthetic Data Vault (SDV) is a powerful Python library that enables the creation of synthetic tabular data using a variety of machine learning algorithms. With features like generating data for single tables, evaluating and visualizing data quality, and preprocessing and defining constraints, the SDV offers a comprehensive solution for creating synthetic datasets.
By leveraging models such as GaussianCopula and CTGAN, users can generate synthetic data that closely mimics real-world data patterns. The library allows for easy comparison between synthetic and real data, enabling users to diagnose issues and generate quality reports for further insights.
Whether you're looking to anonymize sensitive columns, preserve statistical patterns, or maintain data relationships, the SDV provides the tools to customize the synthetic data generation process. With tutorials, documentation, and a supportive community, the SDV is a valuable resource for those interested in synthetic data generation.
So, if you're exploring the realm of synthetic data or need a reliable tool for generating diverse datasets, the Synthetic Data Vault might just be the solution you've been searching for!

The discussion on the Synthetic Data Vault (SDV) project on Hacker News covers a range of perspectives and insights:

1. **Data Catering Project:** A user named "pitah1" mentions working on a similar project called Data Catering, which focuses on generating data while maintaining relationships from various metadata sources.
2. **Privacy Layer Workflow:** The user "n4atki" outlines a privacy layer workflow for end-to-end solutions, suggesting steps like connecting to a data source, training a generative AI model, creating synthetic data, and exporting it. They also raise concerns about the missing privacy layer in the SDV workflow.
3. **Workflow Process:** Another user, "dbsmt," discusses a workflow process involving prediction-equivalent databases, transforming functions using AI, and generating synthetic data for parallel processing and testing transformation functions.
4. **Quickstart Notebooks:** User "skdmt" shares Colab notebooks for generating single-table and multi-table synthetic data for those looking to quickly get started with the SDV project.
5. **Challenges with Synthetic Data:** Users highlight the challenges of using synthetically generated data, mentioning difficulties in replicating real-world data, issues in medical imaging where privacy and consent are crucial, and the limited success of techniques like GANs or SMOTE for synthetic data generation.
6. **Licensing Changes:** There's a discussion about the licensing of SDV, with users mentioning changes from MIT to MIT 4 years release licensing, and a debate around potential licensing models like AGPL or BSL that provide incentives for businesses while protecting commercial rights.

Overall, the discussion provides valuable insights into the challenges and possibilities of synthetic data generation and the ongoing developments and considerations in the SDV project.

### Defending LLMs against Jailbreaking Attacks via Backtranslation

#### [Submission URL](https://arxiv.org/abs/2402.16459) | 64 points | by [saliagato](https://news.ycombinator.com/user?id=saliagato) | [46 comments](https://news.ycombinator.com/item?id=39522908)

The paper titled "Defending LLMs against Jailbreaking Attacks via Backtranslation" by Yihan Wang and three other authors addresses the vulnerability of large language models (LLMs) to jailbreaking attacks. These attacks manipulate the input prompt to hide malicious intent. The proposed defense involves backtranslation, where the model is prompted to infer an input that leads to the response, helping to uncover the original intent. The effectiveness and efficiency of this defense method are highlighted, showing significant improvements over baselines with minimal impact on benign input prompt generation. The study falls under the categories of Computation and Language and Artificial Intelligence.

The discussion on the Hacker News submission about the vulnerability of large language models (LLMs) to jailbreaking attacks via backtranslation involved various viewpoints:

- **smnw** pointed out that the Hacker News post's title was incorrect and that the paper addressed the issue of prompt injection in jailbreaking attacks.
- **btbldm** discussed developing single LLMs to address specific domain problems, highlighting the importance of protecting against prompt injections.
- **spdstn** and **cjns** delved into the effectiveness of context in dealing with prompt injections and the security concerns associated with such attacks.
- **wntsngnt** expressed concerns about the challenges in solving jailbreaks in LLMs, suggesting the need for more comprehensive measures.
- **tpynt** discussed the effectiveness of using mathematical notation for describing issues, emphasizing the importance of precise language in defense strategies.
- **sam_dam_gai** highlighted the use of backtranslation in detecting malicious intent in prompt injections, while **Mizza** mentioned the use of LSTMs and CNNs for added security in preventing attacks.

Overall, the discussion touched upon the technical aspects and challenges associated with defending LLMs against jailbreaking attacks using methods like backtranslation and the need for robust security measures.

### Apollo calls AI a 'bubble' worse than even the dotcom era

#### [Submission URL](https://fortune.com/2024/02/26/nvidia-ai-bubble-apollo-asset-manager-dotcom-artificial-intelligence/) | 111 points | by [zekrioca](https://news.ycombinator.com/user?id=zekrioca) | [155 comments](https://news.ycombinator.com/item?id=39520343)

In the latest tech drama, Nvidia soared to a $2 trillion market cap, but billionaire Marc Rowan's Apollo Global Management is calling AI a "bubble" worse than the dotcom era. The warning from Rowan's asset manager comes as Nvidia's value skyrockets, fueled by demand for AI chips that power cutting-edge technologies like OpenAI's Sora. Concerns over valuation have led some, including ARK Invest's Cathie Wood, to reduce exposure to AI semiconductor companies like Nvidia. As the tech industry continues to evolve, the battle between hype and caution rages on, shaping the future of business.

The discussion on Hacker News about the submission regarding Nvidia's market cap and the concerns around AI being labeled a "bubble" drew various perspectives from the community:

1. Some users argued that AI is not necessarily a bubble, highlighting its high potential and the value of its products in the market.
2. The debate touched upon the definition of a bubble, with one user pointing out that the concept can vary depending on one's viewpoint.
3. There was a comparison made between AI and past phenomena like the dotcom era, with different opinions on whether AI companies are overvalued.
4. The discussion also delved into the implications of Nvidia's success and the broader implications for the market and investors.
5. Users brought up the analogy of "shovel sellers" in a gold rush to discuss the dynamics of overvaluation and hype in the market.
6. Some users expressed concerns about the potential risks associated with AI and ML technologies and their impact on stock markets and investments.

Overall, the conversation highlighted the complexities and varying viewpoints regarding the valuation of AI companies and the potential risks and rewards associated with investing in this sector.
