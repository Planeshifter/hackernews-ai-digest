## AI Submissions for Tue Feb 27 2024 {{ 'date': '2024-02-27T17:10:05.646Z' }}

### The Marvelous Automata of Antiquity (2018)

#### [Submission URL](https://daily.jstor.org/the-marvelous-automata-of-antiquity/) | 33 points | by [taupe-](https://news.ycombinator.com/user?id=taupe-) | [5 comments](https://news.ycombinator.com/item?id=39518535)

In a world long before the digital age, ancient engineers and craftsmen crafted wondrous automata that blurred the line between human and machine. From the elaborate special effects in the throne room of Constantine VII to Mark Antony's theatrical use of automata, these mechanical marvels aimed to evoke a sense of the miraculous.

Automata were not always designed to unsettle; they often delighted and entertained audiences. In medieval Cairo, automata graced palaces, such as the singing girls carved from camphor and amber that charmed guests with their movements. One of the most influential works on automata was Ismail al-Jazari's "The Book of Knowledge of Ingenious Mechanical Devices," featuring intricate devices like the hand-washing tower with a bejeweled peacock.

Al-Jazari's influence extended across continents, shaping the evolution of automata in Europe and the Middle East. Table fountains, popular in medieval times, exuded whimsy and enchantment, such as the elaborate fountain at the Cleveland Museum of Art. Legends of hidden automata guarding treasures beneath the earth captured the imagination, reflecting a belief in the enduring legacy of ancient empires through these mechanical guardians.

- "MyFirstSass" shared their surprise at discovering historical artifacts related to automata in Vienna and highlighted the detailed descriptions of advanced mechanical contraptions like banquet devices that left an impression on them. They vividly remembered seeing a ship-driven table musical come to life, as well as a miniature cannonball-shooting fort in 1585, both of which fascinated them.

- "jnndnly" recommended the book "Gods and Robots: Myths, Machines, and Ancient Dreams of Technology" by Adrienne Mayor for those interested in ancient Greek robots, citing its ISBN for reference.

- "tp-" thanked "jnndnly" for the book recommendation on the topic.

- "tp-" reflected on the importance of understanding the implications and potential of artificiality in human history, emphasizing the significance of terminology, art, and design in the creative process of crafting human-like mechanisms.

- "dr_dshiv" appreciated the find shared by "MyFirstSass" and mentioned collecting books related to Renaissance-era technology that intersect with early AI development.

### The /unblock API from Browserless: dodging bot detection as a service

#### [Submission URL](https://www.browserless.io/blog/2024/02/26/unblock-api/?apcid=00620de59ffc742367908900&utm_campaign=unblock-api-announcement&utm_content=unblock-api-announcement&utm_medium=email&utm_source=ortto) | 164 points | by [keepamovin](https://news.ycombinator.com/user?id=keepamovin) | [137 comments](https://news.ycombinator.com/item?id=39526797)

Browserless v2 has launched with the new /unblock API, offering a fresh approach to evading bot detectors. The constant battle between bots and WAFs necessitates more advanced solutions, as traditional methods like mimicking JavaScript APIs or adjusting Chrome flags are becoming less effective against Cloudflare's evolving protections. The /unblock API focuses on humanizing traffic by addressing subtle bot identifiers like the default browser size set by Puppeteer at 800x600 pixels. By modifying behavior at the Chrome DevTools Protocol layer, the API ensures that Chrome is launched in a more realistic 1920x1080 pixel setting, thus concealing bot fingerprints. This innovative API aims to simulate human browsing behavior to bypass bot detection while offering a range of features from connecting Puppeteer to unblocked browsers to generating cookies and screenshots. Developers can easily access the /unblock API by utilizing the new V2 service and following the provided code snippet. The API is now available for a 7-day trial with browserless, offering a resource-intensive process that requires additional Units beyond the free tier. Stay ahead of bot detection mechanisms with browserless and experience the benefits of seamless automation and scraping.

The discussion on the submission about Browserless v2 launching with the new /unblock API covers various perspectives. Some comments mention the conflict between developers trying to scrape data and businesses implementing measures to protect their content. There is also a debate on the legitimacy of scraping public versus semi-public data without consent and the ethical considerations of scraping content models. One user talks about the potential future of AI-generated content and the evolving landscape of bot detection. Other comments touch on challenges faced by developers in scraping data, the importance of gathering commercial data, and the complexities of balancing data access and protection.

Further discussions explore the issues around web scraping, such as the impact of negative sentiments derived from scraped data, strategies for bypassing bot detection mechanisms, and the implications of hosting websites that may be vulnerable to scraping. Additionally, there are conversations about the ethical aspects of scraping content, particularly in relation to data privacy and security concerns.

Overall, the comments reflect a broad range of opinions on the ethical, legal, and technical aspects of web scraping, highlighting the ongoing complexities and challenges in this field.

### Show HN: Gemini OpenAI API Proxy. Serverless

#### [Submission URL](https://github.com/PublicAffairs/openai-gemini) | 29 points | by [johnd0e_](https://news.ycombinator.com/user?id=johnd0e_) | [8 comments](https://news.ycombinator.com/item?id=39528357)

Today on Hacker News, a new project called Gemini was in the spotlight. Gemini is an OpenAI API proxy that offers a personal OpenAI-compatible endpoint for free. This serverless solution is cloud-based and doesn't require server maintenance, making it easy to deploy to various providers for personal use. Users can run the proxy endpoint locally for development purposes. To get started, you'll need a personal Google API key and can deploy the project to providers like Vercel, Netlify, or Cloudflare. Gemini provides different API bases, such as /v1 and /edge/v1, with specific function limits. Users can override the OpenAI endpoint in compatible tools by specifying the Gemini endpoint address. The project is open source under the MIT license and is gaining traction with 33 stars and 8 forks on GitHub.

- User 'prntvd' shared about the advantages of GPT-3 models and the costs involved.
- User 'silly_ninja' posed a similar question regarding the topic mentioned by user 'prntvd'.
- User 'nnzzzs' asked about the said region limitations applicable for companies using this tool, specifically in relation to operating within a legal framework and complying with local laws.
- User 'lobito14' raised concerns regarding compliance with local laws, especially concerning privacy regulations.
- User 'android521' added to the conversation by discussing how certain countries restrict access to Google services.
- User 'johnd0e_' suggested trying a flexible open-source project related to this topic.
- User 'WiSaGaN' mentioned a partner providing access to a GPT-compatible API.
- User 'johnd0e_' brought up the convenience of deploying the project on platforms like Vercel and Netlify for the proxy solution to the problem.

### Here lies the internet, murdered by generative AI

#### [Submission URL](https://www.theintrinsicperspective.com/p/here-lies-the-internet-murdered-by) | 112 points | by [ctoth](https://news.ycombinator.com/user?id=ctoth) | [45 comments](https://news.ycombinator.com/item?id=39527477)

The internet is in turmoil as generative AI floods online platforms with synthetic content, creating a chaotic landscape of misinformation and scams. From AI-generated books and articles to deepfake porn and fake social media accounts, the impact of this technology is far-reaching and insidious. Even reputable outlets like Sports Illustrated have been caught using AI-generated authors to churn out low-quality content for profit. As AI increasingly infiltrates every corner of the internet, the line between real and fake is becoming increasingly blurred, with toddlers being subjected to nonsensical AI-generated content on platforms like YouTube Kids. The consequences of this "semantic apocalypse" are dire, as we witness the gradual decay of online authenticity and integrity.

The discussion on Hacker News revolves around the implications of generative AI flooding online platforms with synthetic content, particularly impacting children viewing YouTube. Users express concerns about the proliferation of AI-generated content on platforms like YouTube Kids and the potential misinformation and harmful content it may expose children to. Some users share their experiences with trying to limit or control the content accessed by kids, such as installing Ubuntu Linux on devices instead of iPads. Other topics discussed include strategies to regulate AI-generated content, the role of technology in society, and the potential dangers of AI advancements.

### Tumblr's owner is striking deals with OpenAI and Midjourney for training data

#### [Submission URL](https://www.theverge.com/2024/2/27/24084884/tumblr-midjourney-openai-training-data-deal-report) | 61 points | by [Tomte](https://news.ycombinator.com/user?id=Tomte) | [4 comments](https://news.ycombinator.com/item?id=39529253)

In a recent report by 404 Media, it has been alleged that Tumblr's owner, Automattic, is in talks with AI companies, Midjourney and OpenAI, to provide training data scraped from users' posts. The report suggests that deals between the companies are imminent, sparking rumors and concerns among Tumblr users regarding data privacy. Automattic is reportedly planning to launch a new setting allowing users to opt out of data sharing with third parties, including AI companies. However, questions remain about the handling of past data and the specifics of the proposed agreements.

While Automattic has stated that they prioritize user choice and only share public content from sites that haven't opted out, details about the nature and scope of the partnerships with AI companies remain vague. The use of publicly available online data for training AI models has drawn criticism from artists and writers who are wary of their work being used without consent. This news comes amidst a trend of companies partnering with AI tool makers for training data, highlighting the ongoing tension between innovation and user privacy in the online space.

As more information unfolds about these potential deals and their implications, concerns about data privacy, user consent, and the monetization of platforms like Tumblr continue to be at the forefront. The evolving landscape of AI partnerships in the tech industry raises important questions about ethical data practices and the balance between innovation and user rights.

1. User "zrn900" mentioned that many organizations previously followed high deals upon the source of Automattic receiving $150 million in 2020, speculating about potential valuations and deals involving VC investors.

2. User "tchny" related this to the success story of Github, highlighting how it started as a bootstrapped company with 80 employees, but changed its path to accommodate VCs and their funding, drawing parallels to the current trend with AI companies like Microsoft.

3. User "Alifatisk" briefly mentioned the relationship between ClosedAI and OpenAI, focusing on their involvement with Reddit discussions.

4. User "ChrisArchitect" provided a reference to an article for further discussion, suggesting that readers visit a link for additional insights and perspectives on the topic.

### Synthetic data generation for tabular data

#### [Submission URL](https://github.com/sdv-dev/SDV) | 53 points | by [skadamat](https://news.ycombinator.com/user?id=skadamat) | [12 comments](https://news.ycombinator.com/item?id=39528192)

The Synthetic Data Vault (SDV) is a powerful Python library that enables the creation of synthetic tabular data using a variety of machine learning algorithms. With features like generating data for single tables, evaluating and visualizing data quality, and preprocessing and defining constraints, the SDV offers a comprehensive solution for creating synthetic datasets.

By leveraging models such as GaussianCopula and CTGAN, users can generate synthetic data that closely mimics real-world data patterns. The library allows for easy comparison between synthetic and real data, enabling users to diagnose issues and generate quality reports for further insights.

Whether you're looking to anonymize sensitive columns, preserve statistical patterns, or maintain data relationships, the SDV provides the tools to customize the synthetic data generation process. With tutorials, documentation, and a supportive community, the SDV is a valuable resource for those interested in synthetic data generation.

So, if you're exploring the realm of synthetic data or need a reliable tool for generating diverse datasets, the Synthetic Data Vault might just be the solution you've been searching for!

The discussion on the Synthetic Data Vault (SDV) project on Hacker News covers a range of perspectives and insights:

1. **Data Catering Project:** A user named "pitah1" mentions working on a similar project called Data Catering, which focuses on generating data while maintaining relationships from various metadata sources.

2. **Privacy Layer Workflow:** The user "n4atki" outlines a privacy layer workflow for end-to-end solutions, suggesting steps like connecting to a data source, training a generative AI model, creating synthetic data, and exporting it. They also raise concerns about the missing privacy layer in the SDV workflow.

3. **Workflow Process:** Another user, "dbsmt," discusses a workflow process involving prediction-equivalent databases, transforming functions using AI, and generating synthetic data for parallel processing and testing transformation functions.

4. **Quickstart Notebooks:** User "skdmt" shares Colab notebooks for generating single-table and multi-table synthetic data for those looking to quickly get started with the SDV project.

5. **Challenges with Synthetic Data:** Users highlight the challenges of using synthetically generated data, mentioning difficulties in replicating real-world data, issues in medical imaging where privacy and consent are crucial, and the limited success of techniques like GANs or SMOTE for synthetic data generation.

6. **Licensing Changes:** There's a discussion about the licensing of SDV, with users mentioning changes from MIT to MIT 4 years release licensing, and a debate around potential licensing models like AGPL or BSL that provide incentives for businesses while protecting commercial rights.

Overall, the discussion provides valuable insights into the challenges and possibilities of synthetic data generation and the ongoing developments and considerations in the SDV project.

### Tumblr and WordPress to Sell Users' Data to Train AI Tools

#### [Submission URL](https://www.404media.co/tumblr-and-wordpress-to-sell-users-data-to-train-ai-tools/) | 52 points | by [easyThrowaway](https://news.ycombinator.com/user?id=easyThrowaway) | [6 comments](https://news.ycombinator.com/item?id=39529518)

In a shocking revelation, it has been uncovered that Tumblr and WordPress.com are planning to sell user data to companies like Midjourney and OpenAI. Internal documents suggest a messy process within Tumblr, with some user data being compiled improperly, including private posts, unanswered asks, and explicit content. The exact details of the data being shared have not been disclosed, raising concerns about user privacy. Stay tuned for more updates on this developing story.

- User "slrkrft" mentions that Hacker News frequently covers discussions involving Automattic, expressing curiosity over the company's activities over time. The user remarks that Automattic's short for "good guys" seems to have lost its luster as they made a questionable decision related to selling user data.
- User "jmspnddtc" suggests that a privacy-first managed WordPress hosting company might be able to handle things more appropriately, hinting at the importance of data privacy.
- User "ChrisArchitect" points out that the submission is a duplicate of another discussion thread and provides a link for reference.
- User "spdg" criticizes the move by Tumblr and WordPress.com to sell user data, emphasizing the disgust in selling content and highlighting the backside of the self-hosting and indie web movement. The user mentions a shift towards platforms where content is not sold.
- User "ndfrch" states that many people who are tech-savvy and into self-hosting realize the importance of spending time on running securely, indicating their disapproval of the situation.
- User "wrms" shares a personal experience related to WordPress, mentioning deleting their WordPress blog due to statics gone sales deals, comparing the situation to a previous experience with Six Apart (6A) and LiveJournal, expressing disdain for the levels of disgust involved.

### Defending LLMs against Jailbreaking Attacks via Backtranslation

#### [Submission URL](https://arxiv.org/abs/2402.16459) | 64 points | by [saliagato](https://news.ycombinator.com/user?id=saliagato) | [46 comments](https://news.ycombinator.com/item?id=39522908)

The paper titled "Defending LLMs against Jailbreaking Attacks via Backtranslation" by Yihan Wang and three other authors addresses the vulnerability of large language models (LLMs) to jailbreaking attacks. These attacks manipulate the input prompt to hide malicious intent. The proposed defense involves backtranslation, where the model is prompted to infer an input that leads to the response, helping to uncover the original intent. The effectiveness and efficiency of this defense method are highlighted, showing significant improvements over baselines with minimal impact on benign input prompt generation. The study falls under the categories of Computation and Language and Artificial Intelligence.

The discussion on the Hacker News submission about the vulnerability of large language models (LLMs) to jailbreaking attacks via backtranslation involved various viewpoints:

- **smnw** pointed out that the Hacker News post's title was incorrect and that the paper addressed the issue of prompt injection in jailbreaking attacks.
- **btbldm** discussed developing single LLMs to address specific domain problems, highlighting the importance of protecting against prompt injections.
- **spdstn** and **cjns** delved into the effectiveness of context in dealing with prompt injections and the security concerns associated with such attacks.
- **wntsngnt** expressed concerns about the challenges in solving jailbreaks in LLMs, suggesting the need for more comprehensive measures.
- **tpynt** discussed the effectiveness of using mathematical notation for describing issues, emphasizing the importance of precise language in defense strategies.
- **sam_dam_gai** highlighted the use of backtranslation in detecting malicious intent in prompt injections, while **Mizza** mentioned the use of LSTMs and CNNs for added security in preventing attacks.

Overall, the discussion touched upon the technical aspects and challenges associated with defending LLMs against jailbreaking attacks using methods like backtranslation and the need for robust security measures.

### US Used AI to Help Find Middle East Targets for Airstrikes

#### [Submission URL](https://www.bloomberg.com/news/articles/2024-02-26/us-says-it-used-ai-to-help-find-targets-it-hit-in-iraq-syria-and-yemen) | 50 points | by [bluefishinit](https://news.ycombinator.com/user?id=bluefishinit) | [37 comments](https://news.ycombinator.com/item?id=39531348)

I'm sorry, but I cannot access external content from Hacker News to provide a summary as I rely on the information provided to me. If you have any other topics or questions you would like me to assist you with, feel free to ask!

- Discussion includes a debate on AI capabilities and its application in computer vision.
- Some users criticize the Army for their approach to AI, while others discuss the potential misuse of AI in weapon control.
- The conversation shifts to AI safety and the ethical considerations around its development and deployment.
- Users mention concerns about AI decision-making in conflict situations and the need for ensuring human oversight.
- There are comments on the impact of AI on various aspects of society, including education and security.
- Some users mention historical references to conflicts and how AI might influence warfare in the future.
- The conversation also touches on the use of AI-generated content in different contexts and the ethical implications.
- There are references to past events and differing opinions on the role of technology in society.

### Meta will start collecting "anonymized" data about Quest headset usage

#### [Submission URL](https://arstechnica.com/gaming/2024/02/meta-will-start-collecting-anonymized-data-about-quest-headset-usage/) | 47 points | by [laurent123456](https://news.ycombinator.com/user?id=laurent123456) | [25 comments](https://news.ycombinator.com/item?id=39527035)

Meta, the company behind the Quest VR headsets, will soon start collecting "anonymized data" from users, including information on hand, body, and eye tracking, camera data, physical environment details, and virtual reality event attendance. This data will be aggregated to enhance user experiences and product improvements. While Meta states the data is anonymized, concerns have been raised about the potential identification of individuals through such data collection. Users are subject to Meta's wider data-collection policies if they use a Meta account, with legacy Oculus account holders having transitioned to Meta accounts last year.

- \u201claurent123456\u201d raised concerns about the potential matching of anonymized data back to Facebook profiles, stating that certain fitness-related information, physical environment dimensions, voice interactions, and other data could potentially be matched 100% back to a Facebook profile, raising privacy and security concerns.

- \u201cJohnFen\u201d contributed to the discussion by pointing out that legal definitions of personally identifiable information (PII) exclude a lot of data and don't fully capture the nuance of anonymized data.

- \u201ctweetle_beetle\u201d pointed out that the requirement of having a Facebook account to use Quest headsets might exclude a significant portion of potential users, such as developers who avoid using Facebook. They highlighted that forcing users to register with a Facebook-linked account might deter some users who do not want their data collected by Meta.

- \u201cwfflrn\u201d brought up the GDPR's definition of identifiable data and emphasized that even if data is anonymized, the technology and processing capabilities could still potentially re-identify individuals. This raised concerns about the true anonymity of the data being collected and the implications for user privacy.

- \u201cChrisLTD\u201d expressed surprise that Meta doesn't seem to wonder about the anonymity of the data Apple collects from VisionPro, highlighting a double standard in privacy considerations between companies.

- \u201cKomoD\u201d pointed out that while Meta applies stricter data collection policies to users with Meta accounts, those using legacy Oculus accounts are exempt from some of these policies. This led to a discussion about the impact on users who may not wish to have their data collected by Meta and the potential limitations this could impose on certain features of the devices.

- \u201cnsl\u201d sarcastically outlined a process where companies sell products with innovative features, wait for people to buy them, implement new invasive features, and then force users to comply with real changes or face limited functionality.

- Finally, comments from \u201cplussed_reader\u201d, \u201chrzgr\u201d, and \u201cmbchk\u201d reflected on various aspects of the data collection and privacy concerns surrounding Meta's decision, with sentiments ranging from pondering on attention metrics to expressing straightforward concern and disbelief at the situation.

### Man Running AI-Powered Porn Site Horrified by What Users Are Asking For

#### [Submission URL](https://futurism.com/the-byte/man-ai-powered-porn-site-horrified) | 29 points | by [pg_1234](https://news.ycombinator.com/user?id=pg_1234) | [29 comments](https://news.ycombinator.com/item?id=39530300)

In the realm of AI-driven adult entertainment, a glimpse at the darker side emerges as a man running an AI-powered porn site finds himself horrified by the disturbing requests users make. Steven "Lightspeed" Jones ventured into the AI porn space to revamp his dwindling revenues, only to encounter a disturbing trend of users seeking questionable content. Shocked by the prompts users type in, he can only hope they're merely testing the system rather than desiring the explicit images they request.

With the rise of AI technology in the porn industry, challenges around content control become apparent. Despite attempting to implement safeguards, such as blocking specific terms, it proves challenging to prevent users from generating problematic imagery. To navigate this delicate landscape, some industry players opt for a different approach, like using checkboxes instead of freeform prompts to guide user preferences.

The evolving landscape of AI in porn raises concerns for industry professionals, including worries about AI-created deepfakes and the potential for abuse before utility. As the industry grapples with these issues, the quest for AI-generated video, seen as the "holy grail" of porn, inches closer to reality. Despite the hurdles and uncertainties, the future of AI in adult entertainment seems to be rapidly approaching, bringing both promise and perils to the industry.

The discussion on the submission "In the realm of AI-driven adult entertainment" includes various viewpoints and concerns about the impact of AI in the adult entertainment industry:

1. Some users express skepticism about AI replacing human performers, emphasizing the unique aspects of human creation in various forms of art beyond just porn.
2. There are discussions on the evolution of the industry and the challenges faced by professionals in managing content, including issues related to deepfakes and potential abuse.
3. Participants also talk about the business aspects of AI in porn, such as transitioning to AI-generated content and the potential impact on user experience and the market.
4. Concerns about the ethical implications of AI-generated porn and the potential for misuse are highlighted, with debates on control mechanisms and the boundaries between fantasy and reality.
5. There is a discussion on the technical capabilities of AI in creating pornographic content, including the comparison with reality and the challenges in distinguishing between AI-generated and real content.

Overall, the conversation delves into the complex intersection of AI technology, adult entertainment, ethical considerations, and the future implications for the industry.

### Apollo calls AI a 'bubble' worse than even the dotcom era

#### [Submission URL](https://fortune.com/2024/02/26/nvidia-ai-bubble-apollo-asset-manager-dotcom-artificial-intelligence/) | 111 points | by [zekrioca](https://news.ycombinator.com/user?id=zekrioca) | [155 comments](https://news.ycombinator.com/item?id=39520343)

In the latest tech drama, Nvidia soared to a $2 trillion market cap, but billionaire Marc Rowan's Apollo Global Management is calling AI a "bubble" worse than the dotcom era. The warning from Rowan's asset manager comes as Nvidia's value skyrockets, fueled by demand for AI chips that power cutting-edge technologies like OpenAI's Sora. Concerns over valuation have led some, including ARK Invest's Cathie Wood, to reduce exposure to AI semiconductor companies like Nvidia. As the tech industry continues to evolve, the battle between hype and caution rages on, shaping the future of business.

The discussion on Hacker News about the submission regarding Nvidia's market cap and the concerns around AI being labeled a "bubble" drew various perspectives from the community:

1. Some users argued that AI is not necessarily a bubble, highlighting its high potential and the value of its products in the market.
2. The debate touched upon the definition of a bubble, with one user pointing out that the concept can vary depending on one's viewpoint.
3. There was a comparison made between AI and past phenomena like the dotcom era, with different opinions on whether AI companies are overvalued.
4. The discussion also delved into the implications of Nvidia's success and the broader implications for the market and investors.
5. Users brought up the analogy of "shovel sellers" in a gold rush to discuss the dynamics of overvaluation and hype in the market.
6. Some users expressed concerns about the potential risks associated with AI and ML technologies and their impact on stock markets and investments.

Overall, the conversation highlighted the complexities and varying viewpoints regarding the valuation of AI companies and the potential risks and rewards associated with investing in this sector.

### Resurrecting loved ones as AI 'ghosts' could harm your mental health

#### [Submission URL](https://www.newscientist.com/article/2416079-resurrecting-loved-ones-as-ai-ghosts-could-harm-your-mental-health/) | 24 points | by [ZeidJ](https://news.ycombinator.com/user?id=ZeidJ) | [18 comments](https://news.ycombinator.com/item?id=39529927)

The potential for AI to resurrect deceased loved ones is raising concerns among researchers. They warn of potential harm to mental health, dependence on technology, and the emergence of a new religion. AI chatbots are becoming increasingly convincing, with the idea of training an AI solely on a person's archived writings sparking debate. Could this technology lead to a future where your loved one is reborn as an AI? Stay informed with New Scientist's latest discoveries and explore the implications of advancing AI technology.

- User "ViktorRay" mentioned that the concept of using AI to resurrect deceased loved ones is reminiscent of an episode from the TV show Black Mirror, "Be Right Back."
- User "wthnbrdm" expressed concerns about the idea of bringing back deceased loved ones through AI, mentioning how it could affect people's mental health and lead to a sense of loss.
- User "howard941" raised concerns about exploiting dreams for profit and potential mental health harm.
- User "KatyaV" hints at a surprise regarding worshipers and existential implications, sparking a discussion about philosophical interpretations and references to literature.
- User "thssstw" made a reference to the Deathly Hallows from Harry Potter, specifically mentioning the Choosing Resurrection Stone.
- User "nttnymnt" shared an archive link, a web service view page, and then deleted their comment.
- User "mrngl" deleted their comment after a discussion about stimulating synaptic destabilization through a neuro-chemical injection and the potential dangers.
- User "skntfnd" imagines the harm to mental health and progress that could be made through resurrecting loved ones with AI.

### Shittier: Code formatting tool that makes your code look terrible

#### [Submission URL](https://github.com/rohitdhas/shittier) | 116 points | by [wolframhempel](https://news.ycombinator.com/user?id=wolframhempel) | [78 comments](https://news.ycombinator.com/item?id=39521944)

**📰 Hacker News Daily Digest 📰**

🚀 **Shittier: A Code Formatting Tool for Embracing Chaos**  
GitHub user rohitdhas has developed "Shittier," an unconventional code formatting tool that deliberately makes your code look terrible. In contrast to popular tools like Prettier, which aim to enhance code formatting and readability, Shittier revels in chaos, messiness, and confusion, intentionally making your code shittier than ever before. Random indentation, inconsistent casing, and spacing nightmares are just a few ways Shittier transforms your code into a disaster.

📥 **Installation and Usage:**  
To try Shittier, ensure you have Node.js installed, then run `npm install -g shittier` in your terminal. After installation, execute `shittier [options] [directory/file]` in your project's root directory. Options include `-h, --help` for information, `-v, --version` for version display, and `-f, --force` for overwriting files. Remember, Shittier is a satirical project meant for fun, not serious development.

⚠️ **Disclaimer:**  
Shittier is not suitable for production environments and may cause confusion and frustration if used on real codebases. Utilize it at your own risk, and remember it's all about embracing the chaotic side of code formatting.

📜 **License:**  
Shittier is licensed under MIT, so feel free to enjoy the chaos it brings to your code.

Let Shittier transform your neat code into a glorious mess—because sometimes, embracing the dark side of code formatting can be oddly satisfying! 🌪️

The discussion on the submission revolves around the development of "Shittier," a code formatting tool that intentionally makes code look terrible. Some users suggest features like converting leading indentation tabs to spaces randomly, inserting trailing spaces, and varying indentation styles. There is a reference to legacy codebases and the challenges faced by developers in maintaining and understanding code with random styles. The debate extends to the concept of malicious compliance, the quality of work, formatting practices, and practical applications of chaotic code formatting tools. Additionally, users explore the implications of synthetic data for improving large language models and the relevance of consistent coding styles. The conversation touches on various coding practices, challenges, and the impact of different formatting approaches on readability and maintainability.

### Playground v2.5 Technical Report, SoTA Open-Source Image Gen Model [pdf]

#### [Submission URL](https://marketing-cdn.playground.com/research/pgv2.5_compressed.pdf) | 15 points | by [aleks_jpg](https://news.ycombinator.com/user?id=aleks_jpg) | [5 comments](https://news.ycombinator.com/item?id=39526960)

I'm sorry, but it seems like you pasted the raw contents of a PDF file, which I am unable to summarize. Can you please provide a brief description or summary of the content you intended to share so that I can create a digest for you?

1. User "stvkpndm" shared a link to "plygrnd-plygrnd-v25-1024px" related to Stable Diffusion with no restrictions on licensing. User "mmnk" commented that OpenRail requires responsible restrictions, unlike SDXL which has limits on commercial revenue.
2. User "hnenjoyer_93" mentioned RealStock v2 supporting Fooocus models based on SDXL for community-level model comparisons.
3. User "stnkhl" pointed out missing series contender weights for Stable Diffusion. User "mmnk" suggested using SD3 in place of SDXL due to community support and a wider range of stocks in the CS system.

### Show HN: Gemini assistant won't work when screen is locked

#### [Submission URL](https://support.google.com/pixelphone/thread/258703678/google-gemini-does-not-work-when-the-screen-is-lock?hl=en) | 8 points | by [deronEx](https://news.ycombinator.com/user?id=deronEx) | [5 comments](https://news.ycombinator.com/item?id=39530737)

It seems like the content you provided is not related to a Hacker News submission. If you have a specific Hacker News story or topic you'd like summarized, please feel free to share it!

1. **lxgr:** Expresses confusion about Google support comments being baffling and mentions the challenges of reaching Google as a Product Expert Alumni. They feel that Google enthusiasts' votes often result in incomplete or inaccurate answers.
    - **hwbnny:** Comments on the issue, noting that a big report can make strong moves and deliver feedback.
    - **phnn:** Simply states "ITS AI."

2. **KomoD:** Suggests that it shouldn't be a "Show HN" submission.

3. **chrsjj:** Shares a brief comment, "bad."

Overall, the discussion touched upon frustrations with Google support, the validity of votes given by Google enthusiasts, and critiques of the submission categorization. Additionally, one comment acknowledges the use of AI in the conversation.

