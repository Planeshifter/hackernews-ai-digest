## AI Submissions for Tue Jul 11 2023 {{ 'date': '2023-07-11T17:11:29.312Z' }}

### Classifying customer messages with LLMs vs traditional ML

#### [Submission URL](https://www.trygloo.com/blog/classify-text-llms-learnings) | 248 points | by [hellovai](https://news.ycombinator.com/user?id=hellovai) | [111 comments](https://news.ycombinator.com/item?id=36681839)

A recent post on Hacker News shared five key learnings from classifying 500k customer messages using Language Models (LLMs) compared to traditional Machine Learning (ML) techniques. The first learning emphasized that LLMs tend to prefer generating some output rather than none, leading to false-positives. To address this, the authors added a catch-all class like "other" to account for this tendency. 

The second learning highlighted the usefulness of tracking hallucinations, which are instances where the LLMs generate labels that are not present in the prompt. By analyzing these hallucinations, the authors found that simple and direct class names improved accuracy. They noted ongoing research regarding replacing class names with symbols to avoid bias towards using the class names themselves. The third learning emphasized the cost and latency advantages of using fine-tuned classification models in combination with LLMs. In one instance, a customer required lower-latency processing, so the authors trained Sentence-BERT (SBERT) using ChatGPT-labeled data. This approach achieved 85% parity with ChatGPT and over 90% accuracy on a subset of classes.

The fourth learning described "prompt engineering" as a well-known technique to enhance accuracy in text classification. By prompting the LLM to extract relevant clues before classification, state-of-the-art accuracy (96%+) can be achieved. The fifth learning stressed the importance of standardizing input for both fine-tuned models and LLMs. Longer text inputs can lead to less accurate predictions. To address this, the authors applied a preprocessing step to paraphrase the last user message with the previous context, particularly for multi-context chat messages, emails, long documents, and non-English messages.

The discussion on the Hacker News post includes various points and perspectives on the topic of using Language Models (LLMs) for text classification. Here are the key points that were discussed:

- Some users mentioned the use of keyword-based approaches or TF-IDF vectors for text classification, pointing out that the technique described in the post seemed to be categorizing and extracting semantic meaning from the text.
- Others noted that LLMs can be slower than traditional machine learning models and can be resource-intensive, especially when trained on large datasets.
- The topic of sentence embeddings and text embeddings was brought up, with some users expressing difficulty in understanding the underlying mathematics and concepts.
- A comparison was made between LLMs and attention algorithms, noting that they both have similar mechanisms.
- The relevance of the discussion to zero-shot learning was mentioned, with some users pointing out that although the technique described in the post is related, it is not exactly the same as zero-shot learning.
- The potential applications of LLMs in various domains and their ability to create novel solutions were discussed.
- Some users expressed skepticism and questioned the accuracy and reliability of LLMs for text classification tasks.

Overall, the discussion provided a mix of opinions and insights into the topic, with users sharing their experiences and raising interesting points for further exploration.

### PhotoPrism: AI-powered photos app for the decentralized web

#### [Submission URL](https://github.com/photoprism/photoprism) | 316 points | by [pretext](https://news.ycombinator.com/user?id=pretext) | [163 comments](https://news.ycombinator.com/item?id=36679368)

Introducing PhotoPrism: an AI-powered photos app for the decentralized web. This app uses the latest technologies to automatically tag and find pictures, making it easy for users to organize and access their photo collections. Whether you want to run it at home, on a private server, or in the cloud, PhotoPrism offers a user-friendly and privacy-focused solution. With features like browsing all your photos and videos, powerful search filters, and facial recognition for easy identification of family and friends, PhotoPrism is designed to meet your photo management needs. Check out their public demo to get a taste of what PhotoPrism can do!

The discussion on this submission revolves around various aspects of PhotoPrism, the AI-powered photos app for the decentralized web. Some users discuss the pricing plans and features offered by PhotoPrism, with one user mentioning the high cost of the Plus plan and suggesting alternatives like PhotoSync and Nextcloud. There is also a discussion on deduplicating photos, with users sharing different approaches such as SHA-based deduplication and using ExifTool to generate content hashes. The topic of AI identifying similarities in images and the benefits of deduplication are also discussed. Other users mention alternative software options and their personal experiences with similar projects. Some users discuss the technical challenges of deploying PhotoPrism, particularly when using Docker. Overall, the discussion provides insights into the features and possibilities of PhotoPrism, as well as alternative options and considerations for managing photo collections.

### GPT-Prompt-Engineer

#### [Submission URL](https://github.com/mshumer/gpt-prompt-engineer) | 336 points | by [sturza](https://news.ycombinator.com/user?id=sturza) | [152 comments](https://news.ycombinator.com/item?id=36677034)

Introducing gpt-prompt-engineer: a tool that takes prompt engineering to a whole new level. This tool leverages GPT-4 and GPT-3.5-Turbo to generate and test a variety of prompts based on a provided use-case and test cases. It then ranks the prompts using an ELO rating system to determine the most effective ones. Whether you're looking for a landing page headline or evaluating the sentiment of a prompt, gpt-prompt-engineer has got you covered. Give it a try and see how it can supercharge your prompt engineering process!

The discussion surrounding the submission revolves around various aspects of prompt engineering and the use of GPT-4. Some users express skepticism towards benchmarking and evaluating generated prompts, arguing that the performance of GPT-4 should be tested based on real-world applications rather than arbitrary prompts. Others mention existing tools and projects that focus on prompt engineering and evaluation. There is a debate about the correlation between GPT-4 and human evaluators, with some expressing discomfort over the idea that GPT-4 may outperform human evaluators on various tasks. Related to this, there is a discussion about the limitations and biases of GPT-4 and the need for proper validation and testing metrics. A few comments touch on the potential benefits of prompt engineering, such as improved communication and avoiding misunderstandings. Others question the effectiveness of prompt engineering, suggesting that it may not always lead to reliable results or solve certain problems. Overall, the discussion touches on the challenges, limitations, and potential merits of prompt engineering in the context of GPT-4. Users share different perspectives and raise valid points related to the topic.

