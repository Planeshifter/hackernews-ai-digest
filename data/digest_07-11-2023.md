## AI Submissions for Tue Jul 11 2023 {{ 'date': '2023-07-11T17:11:29.312Z' }}

### Classifying customer messages with LLMs vs traditional ML

#### [Submission URL](https://www.trygloo.com/blog/classify-text-llms-learnings) | 248 points | by [hellovai](https://news.ycombinator.com/user?id=hellovai) | [111 comments](https://news.ycombinator.com/item?id=36681839)

A recent post on Hacker News shared five key learnings from classifying 500k customer messages using Language Models (LLMs) compared to traditional Machine Learning (ML) techniques. The first learning emphasized that LLMs tend to prefer generating some output rather than none, leading to false-positives. To address this, the authors added a catch-all class like "other" to account for this tendency. 

The second learning highlighted the usefulness of tracking hallucinations, which are instances where the LLMs generate labels that are not present in the prompt. By analyzing these hallucinations, the authors found that simple and direct class names improved accuracy. They noted ongoing research regarding replacing class names with symbols to avoid bias towards using the class names themselves.

The third learning emphasized the cost and latency advantages of using fine-tuned classification models in combination with LLMs. In one instance, a customer required lower-latency processing, so the authors trained Sentence-BERT (SBERT) using ChatGPT-labeled data. This approach achieved 85% parity with ChatGPT and over 90% accuracy on a subset of classes.

The fourth learning described "prompt engineering" as a well-known technique to enhance accuracy in text classification. By prompting the LLM to extract relevant clues before classification, state-of-the-art accuracy (96%+) can be achieved.

The fifth learning stressed the importance of standardizing input for both fine-tuned models and LLMs. Longer text inputs can lead to less accurate predictions. To address this, the authors applied a preprocessing step to paraphrase the last user message with the previous context, particularly for multi-context chat messages, emails, long documents, and non-English messages.

Finally, the authors introduced a tool called Gloo designed to automate text classification problem-solving. Gloo enables the creation of LLM-based classifiers with prompt engineering, provides a means to measure the impact of prompt changes on production, facilitates training and deployment of BERT-based classifiers, and allows for combining both LLM and traditional models for new classes.

Those interested in improving the accuracy, latency, or cost of NLP text classifiers can reach out to Gloo for a free trial.

The discussion on the Hacker News post includes various points and perspectives on the topic of using Language Models (LLMs) for text classification. Here are the key points that were discussed:

- Some users mentioned the use of keyword-based approaches or TF-IDF vectors for text classification, pointing out that the technique described in the post seemed to be categorizing and extracting semantic meaning from the text.
- Others noted that LLMs can be slower than traditional machine learning models and can be resource-intensive, especially when trained on large datasets.
- The topic of sentence embeddings and text embeddings was brought up, with some users expressing difficulty in understanding the underlying mathematics and concepts.
- A comparison was made between LLMs and attention algorithms, noting that they both have similar mechanisms.
- The relevance of the discussion to zero-shot learning was mentioned, with some users pointing out that although the technique described in the post is related, it is not exactly the same as zero-shot learning.
- The potential applications of LLMs in various domains and their ability to create novel solutions were discussed.
- Some users expressed skepticism and questioned the accuracy and reliability of LLMs for text classification tasks.

Overall, the discussion provided a mix of opinions and insights into the topic, with users sharing their experiences and raising interesting points for further exploration.

### PhotoPrism: AI-powered photos app for the decentralized web

#### [Submission URL](https://github.com/photoprism/photoprism) | 316 points | by [pretext](https://news.ycombinator.com/user?id=pretext) | [163 comments](https://news.ycombinator.com/item?id=36679368)

Introducing PhotoPrism: an AI-powered photos app for the decentralized web. This app uses the latest technologies to automatically tag and find pictures, making it easy for users to organize and access their photo collections. Whether you want to run it at home, on a private server, or in the cloud, PhotoPrism offers a user-friendly and privacy-focused solution. With features like browsing all your photos and videos, powerful search filters, and facial recognition for easy identification of family and friends, PhotoPrism is designed to meet your photo management needs. Check out their public demo to get a taste of what PhotoPrism can do!

The discussion on this submission revolves around various aspects of PhotoPrism, the AI-powered photos app for the decentralized web. Some users discuss the pricing plans and features offered by PhotoPrism, with one user mentioning the high cost of the Plus plan and suggesting alternatives like PhotoSync and Nextcloud. There is also a discussion on deduplicating photos, with users sharing different approaches such as SHA-based deduplication and using ExifTool to generate content hashes. The topic of AI identifying similarities in images and the benefits of deduplication are also discussed. Other users mention alternative software options and their personal experiences with similar projects. Some users discuss the technical challenges of deploying PhotoPrism, particularly when using Docker. Overall, the discussion provides insights into the features and possibilities of PhotoPrism, as well as alternative options and considerations for managing photo collections.

### GPT-Prompt-Engineer

#### [Submission URL](https://github.com/mshumer/gpt-prompt-engineer) | 336 points | by [sturza](https://news.ycombinator.com/user?id=sturza) | [152 comments](https://news.ycombinator.com/item?id=36677034)

Introducing gpt-prompt-engineer: a tool that takes prompt engineering to a whole new level. This tool leverages GPT-4 and GPT-3.5-Turbo to generate and test a variety of prompts based on a provided use-case and test cases. It then ranks the prompts using an ELO rating system to determine the most effective ones. Whether you're looking for a landing page headline or evaluating the sentiment of a prompt, gpt-prompt-engineer has got you covered. Give it a try and see how it can supercharge your prompt engineering process!

The discussion surrounding the submission revolves around various aspects of prompt engineering and the use of GPT-4. Some users express skepticism towards benchmarking and evaluating generated prompts, arguing that the performance of GPT-4 should be tested based on real-world applications rather than arbitrary prompts. Others mention existing tools and projects that focus on prompt engineering and evaluation.

There is a debate about the correlation between GPT-4 and human evaluators, with some expressing discomfort over the idea that GPT-4 may outperform human evaluators on various tasks. Related to this, there is a discussion about the limitations and biases of GPT-4 and the need for proper validation and testing metrics.

A few comments touch on the potential benefits of prompt engineering, such as improved communication and avoiding misunderstandings. Others question the effectiveness of prompt engineering, suggesting that it may not always lead to reliable results or solve certain problems.

Overall, the discussion touches on the challenges, limitations, and potential merits of prompt engineering in the context of GPT-4. Users share different perspectives and raise valid points related to the topic.

### GPT-4 details leaked?

#### [Submission URL](https://threadreaderapp.com/thread/1678545170508267522.html) | 636 points | by [bx376](https://news.ycombinator.com/user?id=bx376) | [579 comments](https://news.ycombinator.com/item?id=36675934)

I'm sorry, but as an AI text-based model, I cannot access or interact with external websites or applications. However, if you provide me with the content or topic you'd like me to summarize, I'd be more than happy to help you with that.

The discussion revolves around the concept of Mixture of Experts (MoE) in artificial intelligence. Some users discuss how MoE involves dividing a problem into sub-problems and solving them with expert models. They also touch on topics like the distribution of data and the selection of experts.

Other users comment on the advantages and disadvantages of MoE. They highlight the potential for localized and individual inference-based learning, while noting the need for proper training and verified knowledge. Different perspectives are presented on the benefits and drawbacks of MoE in various settings, such as academia and entrepreneurship.

There is also a discussion about the importance of understanding and respecting different learning styles and backgrounds. Some users emphasize the value of domain knowledge and the benefits of combining it with creativity.

A few users criticize certain comments and express the need for respectful and constructive conversations. They argue that dismissing others' perspectives or intelligence is counterproductive.

Overall, the discussion covers various aspects of MoE, including its implementation, benefits, limitations, and the importance of respectful discourse.

### Keras Core: Keras for TensorFlow, Jax, and PyTorch

#### [Submission URL](https://keras.io/keras_core/announcement/) | 188 points | by [dewitt](https://news.ycombinator.com/user?id=dewitt) | [68 comments](https://news.ycombinator.com/item?id=36682008)

Keras Core: A New Library for Multi-Backend Deep Learning

The team behind Keras, a popular deep learning framework, has announced the release of Keras Core, a preview version of the future of Keras. Set to become Keras 3.0 in Fall 2023, Keras Core is a full rewrite of the Keras codebase that introduces a modular backend architecture. This allows Keras workflows to be run on top of various frameworks, starting with TensorFlow, JAX, and PyTorch.

Keras Core is a drop-in replacement for tf.keras, offering near-full backwards compatibility when using the TensorFlow backend. In most cases, existing code can be seamlessly transitioned by importing Keras Core as "keras_core" instead of using TensorFlow's keras module. Additionally, Keras Core improves performance with XLA compilation.

The decision to create a multi-backend Keras is a return to the project's roots. In the past, Keras was able to work with multiple backends like Theano, TensorFlow, and CNTK. However, in 2018, Keras shifted its focus exclusively to TensorFlow due to the discontinuation of other backends. In 2023, the landscape has changed, with TensorFlow and PyTorch capturing the majority of the market share for production ML and ML research, respectively. JAX has also gained traction among top players in generative AI. By supporting multiple frameworks, Keras hopes to foster a more inclusive and cross-framework deep learning ecosystem.

Using Keras Core offers several benefits. It allows developers to achieve the best performance for their models by dynamically selecting the backend that delivers optimal efficiency. Keras Core models can also be used across different frameworks, maximizing the available ecosystem surface. This means models can be deployed with TensorFlow tools like TF-Serving and TFLite, used with PyTorch ecosystem packages, or utilized in JAX's large-scale TPU training infrastructure.

Additionally, Keras Core simplifies the distribution of open-source models by making them accessible to a wider audience, regardless of their framework preferences. Data pipelines from various sources, such as tf.data.Dataset objects, PyTorch DataLoader objects, NumPy arrays, or Pandas dataframes, can be used seamlessly with Keras Core's fit(), evaluate(), and predict() routines.

The preview release of Keras Core includes the full Keras API, which is available for TensorFlow, JAX, and PyTorch. This encompasses over a hundred layers, metrics, loss functions, optimizers, and callbacks, as well as the training and evaluation loops, and saving and serialization infrastructure. Existing models that only use built-in layers can be immediately run in JAX and PyTorch by switching the keras import to keras_core.

Keras Core provides a cross-framework low-level language for deep learning, allowing the creation of components that work consistently across all supported backends. This includes a near-full implementation of the NumPy API, making it easier to leverage familiar functionality across different frameworks.

With Keras Core, developers gain the flexibility to choose the backend that fits their needs while retaining the ease-of-use and powerful features that have made Keras a popular choice in the deep learning community. By embracing multiple frameworks, Keras aims to break down the barriers between different deep learning ecosystems and enable smoother collaboration among developers.

The discussion on Hacker News about the submission revolves around various aspects of the Keras Core library and its implications for the deep learning community. Here are some key points:

1. Compatibility and Backends: Some users highlight the benefits of having a multi-backend Keras that allows developers to choose the backend that best suits their needs. They appreciate the effort to support TensorFlow, JAX, and PyTorch, and comment on the advantages of each framework in different scenarios.

2. Comparison with PyTorch: There is a discussion about the history of Keras shifting its focus to TensorFlow in 2018 and the benefits of embracing PyTorch as a backend in Keras Core. Some users express their preference for PyTorch in research, while others mention the advantages of TensorFlow for production ML.

3. API and Abstraction: There are comparisons between the APIs of Keras and PyTorch, with some users stating that PyTorch's Sequential API is similar to Keras. However, others point out that PyTorch offers more control and customization options at the cost of added complexity.

4. Deployment and Serving: Users discuss the potential for deploying models using Keras Core on various devices, such as Raspberry Pi and Arduino, and the compatibility with serving systems like TensorFlow Serving and PyTorch Serving.

5. Contributions and Appreciation: Multiple users express their gratitude and appreciation for the Keras team's work on Keras Core and their contributions to the deep learning community.

Overall, the discussion highlights the interest and excitement around Keras Core and the possibilities it offers to developers in terms of flexibility, compatibility, and collaboration across different frameworks.

