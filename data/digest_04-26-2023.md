## AI Submissions for Wed Apr 26 2023 {{ 'date': '2023-04-26T14:23:08.057Z' }}

### HDR-NeRF: High Dynamic Range Neural Radiance Fields

#### [Submission URL](https://xhuangcv.github.io/hdr-nerf/) | 142 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [32 comments](https://news.ycombinator.com/item?id=35717106)

Researchers from Northwestern Polytechnical University and Tencent AI Lab have developed a method called HDR-NeRF that can recover a high dynamic range radiance field from a set of low dynamic range views with different exposures. This allows for the generation of novel high dynamic range (HDR) and low dynamic range (LDR) views with varying exposures. The proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Experiments conducted on synthetic and real-world scenes validate the proposed method's ability to accurately control the exposures of synthesized views and render views with high dynamic range.

The discussion on the news discusses how the proposed method models the physical imaging process by using an HDR radiance field to encode the scene radiance and a tone mapper to model the mapping process that a ray hitting on the camera sensor becomes a pixel value. Some comments are about the advantages of using this method on smart-phones, while others discuss the limitations of the technology. The discussion also explores the naming convention of the technology and tone mapping. 

### Why did Google Brain exist?

#### [Submission URL](https://www.moderndescartes.com/essays/why_brain/) | 464 points | by [brilee](https://news.ycombinator.com/user?id=brilee) | [296 comments](https://news.ycombinator.com/item?id=35716216)

In this essay, former Google Brain employee Brian Kihoon Lee reflects on the existence of Google Brain and its relevance in today's economic conditions. He examines several reasons for its existence, including prestige, breakthrough discoveries, and maintaining a lead in machine learning. Lee suggests that while these reasons were valid in the past, economic pressures and increased competition from other AI companies mean that Google must be more responsible and directed in its research investments. He also notes a shift towards reduced researcher freedom and top-down direction within the company. Lee's perspective offers insights into the challenges facing industry research labs and the evolving landscape of AI development.

The discussion revolves around the validity of ML PhDs majoring in different fields such as chemistry and physics, and their proficiency in machine learning. Many users point out that while ML PhDs may not possess a deep understanding of the field they majored in, they are compensated for their lack of knowledge through their proficiency in ML. Others suggest that ML has helped cross disciplinary lines and created excellent interdisciplinary work. Some users argue that AI companies such as Google need to be more responsible and directed in their research investments, while others point out the need for foundational ML research. Overall, the discussion sheds light on the challenges facing the development of AI and industry research labs in general.

### DeepFloyd IF: open-source text-to-image model

#### [Submission URL](https://github.com/deep-floyd/IF) | 217 points | by [ea016](https://news.ycombinator.com/user?id=ea016) | [123 comments](https://news.ycombinator.com/item?id=35717871)

The StabilityAI team has developed a state-of-the-art open-source text-to-image model, called DeepFloyd IF, with high photorealism and language understanding. The model is composed of a frozen text encoder and three cascaded pixel diffusion modules that generate 64x64, 256x256, and 1024x1024 px images. The model uses the T5 transformer for text embedding and a UNet architecture with cross-attention and attention pooling. It outperforms other state-of-the-art models and achieves a zero-shot FID score of 6.66 on the COCO dataset. The DeepFloyd IF can be run locally and is also integrated with the Hugging Face Diffusers library.

The comments discuss DeepFloyd IF's capabilities compared to other text-to-image models and specific problems with the current implementation. Additionally, there is a discussion around hurdles with prompts and copyright laws. Some users express interest in trying the model with different prompts, while others debate the legal implications of using it.

### Mark Zuckerberg says Meta wants to ‘introduce AI agents to billions of people’

#### [Submission URL](https://www.theverge.com/2023/4/26/23699633/mark-zuckerberg-meta-generative-ai-chatbots-instagram-facebook-whatsapp) | 49 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [53 comments](https://news.ycombinator.com/item?id=35721910)

Meta CEO Mark Zuckerberg has announced plans to integrate AI agents into billions of Meta apps in ways that will be useful and meaningful for regular people, creators, and businesses. Although it remains unclear how exactly Meta will incorporate generative AI into its applications, Zuckerberg teased the release of AI products in the coming months that will reportedly touch every single one of the company's products. The move comes as Meta attempts to keep up with competitors such as Snap and Google that have invested heavily in building AI infrastructure in recent years, and to address industry-wide interest in the potential applications of generative AI technology.
 
There is a discussion on how AI is impacting society, with some commenters noting concerns about AI collecting information and privacy issues. Others discuss the potential uses of AI in marketing and content creation. One commenter suggests Meta should focus on developing computer vision capabilities. While there are some who support the use of AI, others are skeptical and concerned about how AI technology will impact humanity. Additionally, there are some comments about the renaming of the company to Meta and speculation about the company's future.

### Bringing Memory Safety to sudo and su

#### [Submission URL](https://www.memorysafety.org/blog/sudo-and-su/) | 81 points | by [mritzmann](https://news.ycombinator.com/user?id=mritzmann) | [64 comments](https://news.ycombinator.com/item?id=35714347)

Prossimo, a project by Ferrous Systems and Tweede Golf, has announced their plan to re-implement the widely-used sudo and su utilities in Rust to increase memory safety and minimize risks to operating systems. As sudo and su were originally developed in the 1980s and written in C, they have experienced a number of vulnerabilities related to memory safety issues. This joint team from Ferrous Systems and Tweede Golf will work to implement the critical function of these utilities in Rust to secure the most critical software, particularly from memory safety vulnerabilities. The work is supported by Amazon Web Services and Prossimo welcomes contributions to improve memory safety.

Discussions in the comments focused on the effectiveness of Rust's memory safety features, the complexity and vulnerabilities of other programming languages, and the importance of memory safety in software security. Some commenters suggested that OpenBSD's Doas could be a smaller, simpler alternative to sudo, and others discussed the advantages of different programming languages for memory safety.

### A guide to prompting AI, for what it is worth

#### [Submission URL](https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what) | 179 points | by [jger15](https://news.ycombinator.com/user?id=jger15) | [50 comments](https://news.ycombinator.com/item?id=35712375)

Recently, there has been a lot of emphasis on the importance of prompting AI, with some influencers sharing secrets of how to use prompts effectively. However, Ethan Mollick argues that this emphasis on prompting is misplaced and the best way to use AI systems is through interaction rather than trying to craft the perfect prompt. That being said, Mollick provides some tips on how to approach prompting, such as giving context and constraints to the system, providing additional data, and thinking about programming in prose. Ultimately, the key to using AI effectively is practice.

The discussion covers a variety of perspectives, including tips for approaching prompting, the limitations of AI in understanding human intent, and the importance of providing context and constraints to the system. Some commenters suggest that the emphasis on prompting is misplaced, while others argue that finding the right wording and constraints is crucial for successful outcomes. Overall, the discussion highlights the complex and ongoing nature of working with AI systems.

