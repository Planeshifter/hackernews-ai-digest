## AI Submissions for Tue Nov 21 2023 {{ 'date': '2023-11-21T17:10:03.063Z' }}

### Margaret Mead, technocracy, and the origins of AI's ideological divide

#### [Submission URL](https://resobscura.substack.com/p/margaret-mead-technocracy-and-the) | 129 points | by [benbreen](https://news.ycombinator.com/user?id=benbreen) | [67 comments](https://news.ycombinator.com/item?id=38364179)

The recent fracturing of OpenAI has brought into public view the ideological divide surrounding AI. This article explores the historical origins of this ideological divide and its connection to anthropologist Margaret Mead. Mead was a leading proponent of techno-optimism in the early 20th century, believing that technology would propel humanity towards a transcendent new state. However, after World War II, Mead became a prominent theorist of existential risk, recognizing the potential dangers posed by technology. This complex figure serves as a reminder that a middle ground is needed between dystopian fears and naive techno-optimism in the realm of AI.

The discussion in the comments revolves around various aspects of cybernetics, AI, and the historical context of these fields. Some users share their knowledge of the development of cybernetics, including references to the Macy Conferences and the Ratio Club. Others discuss the relationship between cognitive science and AI, as well as the significance of Norbert Wiener's work in cybernetics. There is also mention of the inclusion of AI in computer science curricula and the importance of understanding the broader principles of computing. Furthermore, there are discussions about the ideological implications of cybernetics and the impact of cybernetics during the Cold War era. The conversation also touches upon the relationship between cybernetics and the governments of the USSR and Romania. Some users express concerns about the potential dangers of AI and the need for safety measures. Lastly, there is mention of the connection between effective altruism and Christian charity, as well as the role of ethics in AI development.

### Orca 2: Teaching Small Language Models How to Reason

#### [Submission URL](https://arxiv.org/abs/2311.11045) | 291 points | by [fgfm](https://news.ycombinator.com/user?id=fgfm) | [76 comments](https://news.ycombinator.com/item?id=38361735)

Researchers at Orca have developed a new method, called Orca 2, for teaching small language models (LMs) how to reason. In previous research, training small LMs relied heavily on imitation learning to replicate the output of larger models. However, the Orca 2 team argues that this approach limits the potential of smaller models. Instead, they aim to teach small LMs different solution strategies for different tasks, potentially different from those used by larger models. They also focus on helping the model learn the most effective solution strategy for each task. The researchers evaluated Orca 2 on 15 diverse benchmarks, consisting of approximately 100 tasks and over 36,000 unique prompts. The results showed that Orca 2 significantly outperformed models of similar size and achieved performance levels similar to, or better than, models 5-10 times larger, particularly on complex tasks that require advanced reasoning abilities. Orca 2 has been open-sourced to encourage further research on the development and evaluation of smaller LMs.

There is discussion about the performance and potential of the Orca 2 model compared to other language models. Some users express skepticism about the quantized versions of the models, while others mention their impressive performance. There is also discussion about the usefulness of smaller models like Orca 2 in various tasks and how they compare to larger models. Some users also discuss the potential limitations and challenges of reasoning in language models. Overall, there is a mix of opinions and perspectives on the topic.

### My north star for the future of AI

#### [Submission URL](https://www.theatlantic.com/technology/archive/2023/11/ai-ethics-academia/675913/) | 81 points | by [oska](https://news.ycombinator.com/user?id=oska) | [49 comments](https://news.ycombinator.com/item?id=38362242)

In a personal essay, a computer science professor reflects on the growing obsession with artificial intelligence (AI) in the 2010s. He discusses the neglect of foundational texts in favor of more topical sources of information, as well as the distractions posed by tech giants recruiting AI talent. The professor shares his surprise when a close colleague decides to turn down a faculty offer from Princeton to join a private research lab called OpenAI. He also recalls a toast made by OpenAI's founding members, suggesting that the future of AI would be shaped by those with corporate resources. The professor ponders the uncertain path that AI will take and references the term "Fourth Industrial Revolution," which gained acceptance during that time.

The comments on this submission cover a range of topics related to AI ethics, the responsibility of engineers, the role of corporations, the decline of liberal rights, and personal reflections on the field of AI. Some users discuss the need for engineers to consider ethics in their work and the importance of laws and regulations in guiding ethical practices. Others question whether the primary responsibility for ethical decision-making rests with engineers or stakeholders. There are also discussions about the potential dangers and benefits of AI, with some expressing concerns about the power that corporations hold in shaping the future of AI. The conversation also touches on the decline of liberal rights and the role of critical theory in shaping public discourse. Several users share personal experiences and reflections on AI and its impact on society. Overall, the discussion seems to center around the ethical implications and responsibilities associated with AI development.

### Show HN: Neum AI â€“ Open-source large-scale RAG framework

#### [Submission URL](https://github.com/NeumTry/NeumAI) | 146 points | by [picohen](https://news.ycombinator.com/user?id=picohen) | [27 comments](https://news.ycombinator.com/item?id=38368570)

Neum AI is a best-in-class framework for managing vector embeddings at a large scale. It provides a comprehensive solution for Retrieval Augmented Generation (RAG), allowing developers to extract data from various sources, process it into vector embeddings, and ingest it into vector databases for similarity search. The framework offers features like high throughput distributed architecture, real-time synchronization of data sources, customizable data pre-processing, and cohesive data management for hybrid retrieval with metadata. Neum AI can be used in the cloud or locally, and there are plans to release a self-hosted version in the future. The roadmap includes upcoming features like additional data connectors, embedding services, vector stores, retrieval feedback, filter support, and extensibility options.

The discussion on Hacker News about the Neum AI framework for managing vector embeddings at a large scale included various comments and questions from the community.

One user mentioned that the framework seems to be a simplification of existing tools and frameworks, and suggested that it may be beneficial for businesses and individuals who want to accelerate development without relying on highly specialized knowledge. Another user shared their experience building a Retrieval Augmented Generation (RAG) application and found it surprisingly efficient.

There were comments discussing the use of semantic chunking tools and libraries like GPT-4 and Stanford Stanza. Some users expressed concerns about the limitations and potential issues with these tools. Another user highlighted the importance of sanitizing input data and improving performance.

The relevance calculations and handling of vector databases were discussed, with suggested improvements and the recommendation of using Weaviate for relevance calculations. There was also a mention of another library, LlamaIndex, which offers enhancements for retrieval and semantic search.

One user asked about improving retrieval compared to using vector databases for semantic search. Another user responded, mentioning the convenience of abstracting complex data sources and sinks and adding more functionality to the framework.

Other comments included suggestions for starting projects using similar frameworks like Haystack or connecting with MemGPT. There was also a mention of using databases like MySQL, PostgreSQL, and Redis as data sources for Neum AI.

Overall, the discussion highlighted the interest in the Neum AI framework and its potential applications, as well as the exploration of different tools and approaches for managing vector embeddings and enabling semantic search.

### Make Pixels Dance: High-Dynamic Video Generation

#### [Submission URL](https://makepixelsdance.github.io/) | 94 points | by [trueduke](https://news.ycombinator.com/user?id=trueduke) | [16 comments](https://news.ycombinator.com/item?id=38362271)

Today, we have an exciting new development in video generation: high-dynamic videos that make P I X E L S dance! Researchers from ByteDance Research have created an AI system capable of generating dynamic videos, even with out-of-domain inputs. The team has presented a demo showcasing the capabilities of their AI, and it's truly impressive.

In basic mode, the AI generates motion-rich videos based on text and image instructions. For example, it can create a video of a bronze sculpture couple rotating while kissing and embracing, or an angry Godzilla roaring and causing explosions in the background. It can even make a cute cat pirate surf on the sea while dancing on a board. The possibilities seem endless with this AI's ability to generate captivating videos.

But it doesn't stop there. The research team also introduced a magic mode, which takes things to the next level. With more complex instructions, the AI can generate intricate out-of-domain scenes and actions. Imagine a ball turning into a dragon made of fire or grass and flowers growing from someone's hair while bees fly around. It can even transform half of a face into a cyborg face or create a ghost walking down a Halloween street with bats flying overhead. This mode truly allows for the creation of mesmerizing and surreal videos.

Additionally, the researchers showcased a gallery of videos that were generated based on instructions provided by users. One video features a beautiful woman driving a red convertible sports car, while another depicts a fiery humanoid monster with burning flames. And of course, there's a video of a man and a woman gracefully performing a social dance.

This AI-generated video technology opens up a whole new world of possibilities for creators and artists. With the ability to bring imagination to life through videos, the potential for creating stunning visual experiences is truly limitless. We're excited to see where this technology will take us in the future.

The discussion about the submission includes several comments from users highlighting different aspects of the topic.

- User "brynrsmssn" comments on the blocking of a TikTok URL by Cisco Umbrella security researchers, but their comment is blocked in some categories due to security threats. This prompts responses from other users mentioning that the URL has been blocked by various security measures.
- User "whelp_24" expresses concerns about the security risks associated with the technology mentioned in the submission.
- User "mdrzn" discusses ByteDance Research's efforts in generating future content for TikTok using AI technology, and this leads to a conversation about the concept of content generation platforms and the challenges of convincing people that machine-generated content can be as good as that created by humans.
- User "drtyhppfr" makes a humorous comment questioning the need for a citation.
- User "mg794613" shares a link to a screenshot from World of Warcraft, suggesting that the source of the AI-generated videos may be from similar sources like video games.
- User "cbfx" speculates about the work of Pixar and how their text-to-image models might relate to the topic.
- User "jdss" comments on the potential of the AI-generated videos to bring cost-effective content production to industries like animation.
- User "twlghtzn" adds a positive comment, describing the videos generated by AI as a lovely story.

### 'AI' Is Supercharging Our Broken Healthcare System's Worst Tendencies

#### [Submission URL](https://www.techdirt.com/2023/11/21/ai-is-supercharging-our-broken-healthcare-systems-worst-tendencies/) | 203 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [142 comments](https://news.ycombinator.com/item?id=38363687)

In a recent article on TechDirt, author Karl Bode discusses the negative impact of AI implementation in journalism and the healthcare industry. Bode argues that instead of using AI for innovative purposes, organizations are using it to cut costs and automate systems that are already flawed. In the case of journalism, the rushed deployment of AI has led to plagiarism, lower quality content, and chaos. In the healthcare industry, companies like UnitedHealthcare are using AI to determine whether elderly patients should be cut off from Medicare benefits. However, investigations have found that the AI consistently makes major errors and denies coverage prematurely. The AI algorithm used by UnitedHealthcare was reportedly reversed by human review 90% of the time. Despite this, employees are mandated to strictly adhere to the AI's decisions, leading to frustrated consumers and underpaid employees. Bode argues that without proper regulation or penalties, organizations will continue to use AI to automate problematic systems.

The discussion on this submission centers around the role of AI in various industries, particularly journalism and healthcare. Some commenters argue that AI implementation can lead to cost-cutting measures and the automation of flawed systems, resulting in lower quality content and incorrect decisions in healthcare. Others highlight the potential benefits of AI, such as improving physician documentation and reducing administrative burden. However, there are concerns about the lack of clarity in regulation and the accountability of companies using AI. Some commenters suggest that AI should not replace skilled healthcare professionals but rather enhance their capabilities. The discussion also touches on the complexities of the healthcare system, the need for clearer certification processes, and the potential role of AI in public health systems. Overall, there are mixed opinions about the impact of AI on society and the need for proper regulation and ethical considerations.

### New Amazon AI initiative includes scholarships, free AI courses

#### [Submission URL](https://www.aboutamazon.com/news/aws/aws-free-ai-skills-training-courses) | 73 points | by [jnord](https://news.ycombinator.com/user?id=jnord) | [14 comments](https://news.ycombinator.com/item?id=38359269)

Amazon is launching a new initiative called "AI Ready," with the goal of providing free AI skills training to 2 million people globally by 2025. The company will be offering eight new and free AI and generative AI courses, as well as a partnership with Code.org to help students learn about generative AI. A recent study by AWS and research firm Access Partnership found that hiring AI-skilled talent is a priority for 73% of employers, but three out of four say they are unable to meet their AI talent needs. With AI becoming more integral to business operations, Amazon hopes to open up opportunities for those with a desire to learn about AI and benefit from its potential. The new initiatives include courses for business and nontechnical audiences, as well as courses for developers and technical audiences. Additionally, through the AWS Generative AI Scholarship, Amazon will provide Udacity scholarships to more than 50,000 high school and university students from underserved communities.

The discussion surrounding Amazon's new AI Ready initiative on Hacker News covers several different topics. 
One user points out the high demand for AI-skilled talent, with 73% of employers prioritizing the hiring of individuals with AI skills. However, three out of four employers say they are unable to meet their AI talent needs. Another user shares their frustration in finding an AI company to invest in, despite their desire to learn bout AI and participate in its growth within the industry.
In response to this frustration, someone mentions that managers should support and promote internal innovation to show investors that they are investing in cutting-edge technologies like AI. They also note that traditional investments in tech do not necessarily reflect the expressed priorities outside of the tech industry.
There is a brief mention of courses or training for managers in AI, with one user suggesting that managers should have a basic understanding of AI concepts even if they don't have technical skills.
The conversation then moves on to discussing different AI tools and frameworks. One user compares Microsoft's AI offerings to Amazon's, mentioning that Microsoft's offerings are based on OpenAI and utilize Azure as well as various Python-based machine learning frameworks.
Another user mentions that training AI engineers only benefits the service and compt content marketing, sales, and finance sectors. This comment suggests that AI engineers are not directly involved in these sectors.

Other tangential comments in the discussion include a mention of including lessons on board management, a comparison to a fictional character from the TV show "Silicon Valley," a reference to Google's equivalent of Amazon's AI Ready initiative, and the intersection of AI and cybersecurity.

### Show HN: I built local copilot alternative using Codellama

#### [Submission URL](https://marketplace.visualstudio.com/items?itemName=ex3ndr.llama-coder) | 35 points | by [ex3ndr](https://news.ycombinator.com/user?id=ex3ndr) | [6 comments](https://news.ycombinator.com/item?id=38368767)

Llama Coder is a new extension for Visual Studio Code that aims to provide a better and self-hosted alternative to Github Copilot. It uses Ollama and codellama to offer autocomplete functionality that runs on your hardware, providing fast performance and eliminating the need for telemetry or tracking.

To get the best experience with Llama Coder, it is recommended to use it with hardware such as Mac M1/M2/M3 or an RTX 4090. The extension works with any programming language and offers features comparable to Copilot. However, it does require a minimum of 16GB RAM, with more RAM being better, as even the smallest model takes 5GB of RAM.

There are two ways to install Llama Coder: locally or remotely. For local installation, you need to install Ollama on your machine and then launch the extension in VSCode. Everything should work as expected. For remote installation, you need to install Ollama on a dedicated machine and configure the endpoint in the extension settings. It is recommended to use a machine with a good GPU for optimal performance.

Llama Coder currently supports only Codellama as the model for autocomplete. The model can be quantized in different ways, but tests have shown that q4 is the optimal way to run the network. When selecting a model, it is recommended to choose the one with the biggest size and the highest possible quantization for your machine. The default model, codellama:7b-code-q4_K_M, should work everywhere, while codellama:34b-code-q4_K_M is the best possible option.

Llama Coder is available for free and is licensed under MIT. So if you're looking for a self-hosted alternative to Github Copilot with excellent performance and no tracking, give Llama Coder a try!

The discussion surrounding the submission of Llama Coder on Hacker News includes several comments:

1. "Broge" expresses interest in the differences between Llama Coder and Github Copilot and provides a link to the Github repository for more information.

2. "hld" agrees with the idea of a self-hosted solution that prioritizes privacy and data integrity. They suggest that Github Copilot must have such a solution.

3. "ex3ndr" finds the idea of using consumer GPUs and databases for self-hosted solutions interesting.

4. "mch" appreciates the work done and thanks the developers for creating a non-telemetry self-hosted alternative. They mention that they didn't expect having to manually start Llama in the terminal, and suggest creating a short video to demonstrate how Llama works for coding, especially for those unfamiliar with Github Copilot.

5. "ex3ndr" responds to "mch," acknowledging the need for better documentation from a coding standpoint.

6. "Havoc" sees potential in Llama Coder and plans to give it a try the following day.

Overall, the comments express curiosity and interest in Llama Coder as a self-hosted alternative to Github Copilot, with some mentioning the need for better documentation and tutorials.

Based on the limited information available, it seems that the discussion is centered around resignations, Elon Musk's actions on Twitter, and the involvement of the CEO of Twitch in some capacity. However, without more context, it is difficult to fully understand the details of the discussion.

