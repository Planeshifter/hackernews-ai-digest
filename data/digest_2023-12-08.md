## AI Submissions for Fri Dec 08 2023 {{ 'date': '2023-12-08T17:10:30.750Z' }}

### Cyborg cockroach could be the future of earthquake search and rescue

#### [Submission URL](https://www.nature.com/articles/d41586-023-03801-0) | 28 points | by [sohkamyung](https://news.ycombinator.com/user?id=sohkamyung) | [22 comments](https://news.ycombinator.com/item?id=38568062)

Researchers at Nanyang Technological University in Singapore are developing cyborg insects, specifically Madagascar hissing cockroaches, to aid in search and rescue missions after natural disasters like earthquakes. These cyborg cockroaches can be remotely controlled through implanted electrodes in their nervous systems and are equipped with sensors and transmitters to locate survivors and communicate with rescue workers. The project is part of the emerging field of biohybrid robotics, where engineers combine biological materials with synthetic materials to create functional robots. While there are still challenges to overcome, harnessing the natural capabilities of living organisms shows promise for advancing robotics.

The discussion on this submission covers a range of opinions and perspectives. Some comments express skepticism about the ethics and practicality of using electronic implants in insects, suggesting that it may not be ethical to control animals for human purposes. Others discuss the potential benefits of using cyborg insects in extreme environments for search and rescue missions. The efficiency and capabilities of cockroaches compared to small robots are also debated, with some suggesting that cockroaches are more adaptable and resilient. Additionally, there are discussions about the feasibility of controlling animals in general, with references to recent studies on implanting electronic devices in fish for navigation. Some comments express disgust or aversion to the idea, while others find it interesting from a scientific perspective. Overall, the discussion encompasses a variety of viewpoints on the topic.

### QuIP#: 2-bit Quantization for LLMs

#### [Submission URL](https://cornell-relaxml.github.io/quip-sharp/) | 191 points | by [jasondavies](https://news.ycombinator.com/user?id=jasondavies) | [45 comments](https://news.ycombinator.com/item?id=38576351)

Researchers have developed a compression method called QuIP#, which combines lattice codebooks with incoherence processing to create state-of-the-art 2 bit quantized language models (LLMs). LLMs are known for their impressive performance but are also very large, requiring significant memory resources. QuIP# addresses this issue by reducing the size of LLMs without sacrificing performance. By quantizing LLMs from 16 bit to 2 bit precision, the size of the models can be reduced by 8x, making them more manageable on GPUs. QuIP# achieves near-native performance at 2 bits, outperforming other baselines. The researchers provide a full codebase and infrastructure for users to quantize and deploy their own models using QuIP#. Overall, QuIP# presents a promising solution to the challenges posed by the size of LLMs.

The discussion on this submission covers various topics related to the paper. 

- Some users discuss the improvements in paragraph quality and the challenge of understanding network precision and quantization.
- Others mention the importance of quantization, especially for models like Mistral MoE, and how it works for smaller models.
- There is a discussion on pixel statistics and binary space compression in RGBA space.
- Some users ask questions about quantization, including its relationship to weight matrix flattening and its implementation on CPUs and GPUs.
- LM Studio is mentioned, but it is noted that running it on a MacBook requires a GPU server.
- There is a discussion on quantized LLMs, including the code and implementation details.
- Users discuss the testing and deployment of quantized models.
- Some users suggest looking into different quantization formats, such as EXL2 and OmniQuant.
- There is a request to test multi-level cell LLM quantization.
- A user provides details about the concept and application of higher-order functions, such as tetration.
- There is a clarification on the relevance of QuIP# in the discussion.
- Users discuss the challenges and feasibility of 1-bit quantization for functional programming and its potential usefulness in certain tasks.
- A user mentions a paper from 2017 that successfully utilized 1-bit quantization.

### Gaussian Head Avatar: Ultra High-Fidelity Head Avatar via Dynamic Gaussians

#### [Submission URL](https://yuelangx.github.io/gaussianheadavatar/) | 171 points | by [phil9l](https://news.ycombinator.com/user?id=phil9l) | [41 comments](https://news.ycombinator.com/item?id=38567074)

Researchers from Tsinghua University and NNKosmos Technology have developed a new method called "Gaussian Head Avatar" for creating high-fidelity 3D head avatars. The method combines controllable 3D Gaussians with a fully learned deformation field to capture complex expressions, resulting in fine-grained dynamic details and expression accuracy. To ensure stability and convergence during training, the researchers devised a geometry-guided initialization strategy based on implicit SDF and Deep Marching Tetrahedra. The experiments showed that their approach outperformed other state-of-the-art methods, achieving ultra high-fidelity rendering quality even under exaggerated expressions. The Gaussian Head Avatar rendered images at a resolution of 2K and demonstrated impressive cross-identity reenactment results with details like beards and teeth. The research paper provides further details on the methodology, and a demo video is available for reference.

The discussion surrounding the submission "Gaussian Head Avatar: High-Fidelity 3D Head Avatar from a Single Image" on Hacker News covers a range of topics. Some users discuss the potential applications of this technology, such as in gaming and virtual meetings, while others mention its resemblance to concepts found in science fiction, such as identity cloning. There is also mention of other related research papers and discussions on the technical aspects of Gaussian splitting. Additionally, there are comments discussing the potential impact of high-quality avatars on virtual reality and the challenges of distinguishing real photos from fictional ones. Other topics touched upon include security concerns and the trustworthiness of online meetings.

### 5Ghoul: Unleashing Chaos on 5G Edge Devices

#### [Submission URL](https://asset-group.github.io/disclosures/5ghoul/) | 134 points | by [rho138](https://news.ycombinator.com/user?id=rho138) | [24 comments](https://news.ycombinator.com/item?id=38567149)

The Singapore University of Technology and Design is making waves in the world of technology and design. The students, researchers, and faculties there are constantly pushing boundaries and making groundbreaking contributions to various fields. From developing innovative technologies to designing cutting-edge systems, they are leaving no stone unturned.

Their expertise extends across a range of domains, including people, research, publications, code, disclosures, testbeds, service, information systems, and technology. Each division brings its unique perspective, contributing to the university's reputation as a hub of innovation.

In terms of research, the Singapore University of Technology and Design is at the forefront. Their research projects cover a wide range of topics, from artificial intelligence and robotics to sustainable development and urban planning. With a multidisciplinary approach, their research aims to address real-world problems and deliver practical solutions.

The university's publications showcase the innovative ideas and breakthroughs achieved by their researchers. These publications serve as a valuable resource for scholars, industry professionals, and enthusiasts alike. Whether it's a journal article or a conference paper, the publications highlight the expertise and knowledge generated at the Singapore University of Technology and Design.

Code is at the heart of technological advancements, and the university recognizes its significance. By sharing their code, the researchers at the Singapore University of Technology and Design enable others to build upon their work, fostering collaboration and accelerating progress. Open-source projects and code snippets are just a few examples of their commitment to advancing technology.

Disclosures play a crucial role in ensuring transparency and trust. The university understands this and actively shares information about their inventions, patents, and intellectual property. By doing so, they encourage collaboration, licensing, and potentially even commercialization of their innovations.

Testbeds provide a real-world environment for researchers and students to validate their ideas and prototypes. The Singapore University of Technology and Design offers state-of-the-art testbeds, enabling hands-on experimentation and validation. These testbeds facilitate the development of robust and reliable solutions, ready to tackle real-world challenges.

Service is ingrained in the university's DNA. They actively engage with industry partners, government agencies, and the community to offer their expertise and resources. From consultancy services to collaborative projects, the Singapore University of Technology and Design aims to make a positive impact and drive meaningful change.

Information systems play a vital role in today's interconnected world. The university's expertise in this field allows them to develop efficient and secure systems. By leveraging cutting-edge technologies and innovative approaches, they contribute to the advancement of information systems, ensuring a seamless and secure digital experience.

The Singapore University of Technology and Design's commitment to technology and design is evident in all their endeavors. Their interdisciplinary approach, collaborative mindset, and focus on practical solutions make them a force to be reckoned with. As they continue to push boundaries and explore new frontiers, their impact on the world of technology and design will only continue to grow.

The discussion on this submission revolves around various aspects of technology and design, including software vulnerabilities, proprietary data, and communication protocols. Here are some key points from the discussion:

- One commenter points out that critical vulnerabilities in modern mobile devices often go unnoticed for a long time until they are patched.
- The disclosure of sensitive data and crash bugs in certain services is discussed, with some expressing concerns about the safety of customer data.
- A debate ensues regarding vulnerability branding and the need for CVE numbers to address specific vulnerabilities.
- The disclosure of sensitive data, particularly how it affects the confidentiality of LTE devices and exposes the International Mobile Subscriber Identity (IMSI), is mentioned.
- The presence of proprietary data and its impact on firmware and bootloaders is questioned, with concerns raised about the potential for malware.
- The impact of communication protocols on network security and privacy is discussed, with references to past vulnerabilities in protocols such as SMTP and Signaling System 7 (SS7).
- The limitations of current network protocols and the potential hindrance to innovation are also mentioned.
- Lastly, the discussion touches on the challenges of hardware and software integration, particularly in the context of computer systems in cars.

Overall, the discussion delves into the complexities and vulnerabilities in technology and design, highlighting the need for continuous improvement and innovation.

### Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts (2017)

#### [Submission URL](https://arxiv.org/abs/1701.06538) | 57 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [9 comments](https://news.ycombinator.com/item?id=38572284)

Researchers at Google have developed a new type of neural network layer called the Sparsely-Gated Mixture-of-Experts (MoE) layer, which allows for the creation of outrageously large neural networks. The MoE layer consists of thousands of feed-forward sub-networks and a trainable gating network that selects which experts to use for each example. This approach allows for greater model capacity without a proportional increase in computation. The researchers applied the MoE layer to language modeling and machine translation tasks, achieving significant improvements in results compared to state-of-the-art models at a lower computational cost. The model architectures they developed included a MoE layer with up to 137 billion parameters.

The discussion around the submission centers on the topic of outrageously large neural networks and the use of the Sparsely-Gated Mixture-of-Experts (MoE) layer. Some commenters point out that previous state-of-the-art models had significantly fewer parameters, ranging from 2 million to 151 million, while the MoE layer enables models with up to 137 billion parameters. They also mention the potential importance of scaling up model capacity appropriately for effective results. 

One commenter raises concerns about the tendency of some companies and practitioners to focus on model size and hyperparameters rather than the actual quality of the model and the importance of properly contextualizing research in the larger machine learning community. They highlight the strong evidence supporting the efficacy of other models and techniques like CNNs and Transformers.

Another commenter highlights the difficulties and the high costs associated with training and exploring generative models. They mention the challenges of reviewing, rejecting, and finding convincing results with models many times larger than previously explored, as well as the need for proper exploration of domain differences and scaling.

In addition to the discussion about the size and potential limitations of outrageously large models, there are references to previous discussions on similar topics dating back to 2016 and 2017. Some commenters provide their perspectives on the feasibility and cost considerations of implementing such large models, with one commenter noting that a 137 billion parameter model would cost around $120K to train. Other commenters mention their experiences running smaller models, with one suggesting that a 30 billion parameter model can run on a decent laptop, while another notes the potential cost savings of quantization techniques.

Overall, the discussion revolves around the implications, feasibility, and potential drawbacks of outrageously large neural networks and the Sparsely-Gated Mixture-of-Experts (MoE) layer.

### The industries AI is disrupting are not lucrative

#### [Submission URL](https://www.theintrinsicperspective.com/p/excuse-me-but-the-industries-ai-is) | 68 points | by [snewman](https://news.ycombinator.com/user?id=snewman) | [86 comments](https://news.ycombinator.com/item?id=38575199)

In a recent article from The Intrinsic Perspective, the author takes a critical look at the current state of AI and its potential impact on industries. The article highlights Google's recently unveiled AI model, Gemini, which was showcased in a video demonstrating its abilities to interact with a questioner in real-time. However, the author argues that this video was staged, with pre-recorded frames sent to Gemini for a response. This leads to the larger point that the AI industry relies heavily on hype and large investments, but the industries they are disrupting are not necessarily lucrative. The article questions the audience for the GPT Store, a platform for AI apps, and suggests that the use cases mentioned, such as writing essays or digital art, may not generate significant profits. The author concludes by stating that while AI models like Gemini may be impressive in their capabilities, the industries they are disrupting may not offer substantial returns on investment.

The discussion on Hacker News revolves around various aspects of the article. Here are some key points raised by the commenters:

1. The first commenter agrees with the article that many people do not fully realize the impact of language models (LLMs) on businesses. They highlight how LLMs can handle classification and structuring tasks that would otherwise require thousands of human hours.
2. Another commenter elaborates on their experience using LLMs for helpdesk support and points out that while the approach may not always work perfectly, it can enhance productivity for support agents.
3. Some commenters express agreement with the article's critique of the hype around AI and its potential impact on industries. They argue that AI models like ChatGPT may not completely replace current systems and that the current interface of ChatGPT is marketed as a replacement for Google, which is hard to achieve.
4. The discussion also touches upon the potential disruption caused by LLMs in various industries. Examples mentioned include government contractors and junior analysts in the market research industry.
5. There is a debate on the accuracy and reliability of LLMs in tasks such as classification and combating spam. Some commenters highlight the limitations and false outputs of LLMs, while others discuss approaches and solutions to improve their performance.
6. One commenter emphasizes the psychological mechanism of stochastic parroting, where LLMs mimic and respond randomly like a parrot. They argue that LLMs cannot fully replace human judgement and experience.
7. The discussion also includes concerns about the AI industry being in a bubble and the potential negative effects if it bursts. Commenters express skepticism about the potential long-term impact of AI and its underlying technology.
8. Lastly, there are arguments about the role of software-based technologies in creating and bursting bubbles. Some commenters question the feasibility of preventing bubbles and whether technological advancements can deliver substantial promises.

### "vi – How do I exit Vim?" on stackoverflow viewed +3M times

#### [Submission URL](https://stackoverflow.com/questions/11828270/how-do-i-exit-vim) | 13 points | by [virskyfan](https://news.ycombinator.com/user?id=virskyfan) | [13 comments](https://news.ycombinator.com/item?id=38576082)

The top submission on Hacker News is a request for users to take a short survey to help improve Stack Overflow. The survey aims to gather feedback on various aspects of the platform. In other news, Stack Overflow has introduced a new feature called Collectives™, which allows users to find centralized and trusted content related to the technologies they use most. It also enables collaboration within specific technology communities.  Additionally, Stack Overflow has launched Teams, a platform where users can ask and answer questions related to their work in a structured and easily searchable manner. 

Users can also get early access to new features through the Labs section of Stack Overflow. 

In terms of specific questions on the platform, one submission asks how to exit Vim, a notoriously "sticky" text editor. The question receives numerous responses, with suggestions including pressing the Escape key and typing ":q", using the command ":x" to save and quit, or using the command ":wq" to write and quit. The thread also provides other useful commands and tips for using Vim effectively. 

Overall, these top stories highlight Stack Overflow's efforts to improve user experience and provide valuable resources for developers and technology enthusiasts.

The discussion around the top submission involves users expressing their frustration with the question classification system on Stack Overflow. One user mentioned that they tried to search for an answer to a CS-related question but instead received search results unrelated to their query. They suggested that Stack Overflow should improve the search functionality. Another user responded, encouraging the original poster to click on the link provided in the comment to discuss their confusion and provide relevant information. 

In another discussion thread, a user asked a question about how to exit Vim, a famous text editor. One user replied with a simple command to remove Vim, while another user jokingly commented that they have been using Vim for 10 years and still don't know how to quit.  A separate user commented that they often get distracted while customizing their Vimrc file and asked for tips on how to quickly quit Vim. Another user responded, mentioning studies that show Vim is harder to quit than other text editors. 

In another comment, a user mentioned that they appreciate the defaults of Vim and find it frustrating when they accidentally exit the program. There was also a comment mentioning a blog article from 2017 that reached 1 million views on Stack Overflow. Lastly, a user shared their frustration with accidentally quitting the virtual machine and having to restart it. Another user suggested using a command that kills all processes associated with the virtual machine. A further comment mentioned that switching to Busybox, a minimal Unix-like operating system, can sometimes solve common issues with running virtual machines.

### Google launched a new AI, and has already admitted at least one demo wasn't real

#### [Submission URL](https://www.theverge.com/2023/12/7/23992737/google-gemini-misrepresentation-ai-accusation) | 75 points | by [ronron4693](https://news.ycombinator.com/user?id=ronron4693) | [30 comments](https://news.ycombinator.com/item?id=38564359)

Google recently launched Gemini, its latest suite of AI models, but it has already faced criticism for a demonstration video that appears to be edited and not fully representative of the AI's capabilities. In the video, Gemini is shown responding quickly and accurately to prompts, but a disclaimer in the video description reveals that latency was reduced and outputs were shortened. According to a Bloomberg op-ed, Google admitted that the video used still image frames and text prompts rather than real-time spoken prompts. This is not the first time Google has faced scrutiny over video demos, as its Duplex demo was also questioned for lack of ambient noise and authenticity. The op-ed suggests that Google is "showboating" to distract from the fact that Gemini still lags behind OpenAI's GPT. Google, however, maintains that the video is real and serves to inspire developers. The op-ed concludes that Google should focus on letting journalists and developers experience the AI's capabilities directly rather than relying on edited videos.

The discussion on this submission includes various opinions and perspectives. Some commenters criticize Google for the edited demonstration video of Gemini, arguing that it misrepresents the AI's capabilities. They compare it to previous instances of Google facing scrutiny over video demos. Others express skepticism about the reliability and intelligence of AI models, stating that they cannot accurately predict real-world scenarios. There is also debate about the potential benefits and drawbacks of self-driving cars and personalized advertising. Some commenters suggest that personalized ads are a problem, while others believe they are a solution. There is a discussion about the Verge's coverage of Google and the relevance of personalized data. Additionally, there are comments questioning the authenticity of the video and the expectations set by Google's announcements. Overall, the discussion covers a range of topics related to Google's AI models and the ethical implications of AI technology.

