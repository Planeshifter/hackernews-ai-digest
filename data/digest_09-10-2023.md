## AI Submissions for Sun Sep 10 2023 {{ 'date': '2023-09-10T17:09:50.120Z' }}

### CityDreamer: Compositional Generative Model of Unbounded 3D Cities

#### [Submission URL](https://arxiv.org/abs/2309.00610) | 79 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [13 comments](https://news.ycombinator.com/item?id=37457426)

The paper titled "CityDreamer: Compositional Generative Model of Unbounded 3D Cities" introduces a novel approach to generating realistic 3D cities. While 3D natural scene generation has been extensively studied, generating 3D cities presents greater challenges due to the complex structural distortions and varied appearances of buildings. To address these challenges, the authors propose CityDreamer, a compositional generative model that separates the generation of buildings from other background objects like roads and green lands. The model leverages two datasets, OSM and GoogleEarth, to enhance the realism of the generated cities. The experiments demonstrate that CityDreamer outperforms state-of-the-art methods in generating lifelike 3D cities. This research opens up possibilities for generating virtual cities with high levels of detail and realism.

The discussion on this submission covers various topics related to generative city modeling. One user points out that the OSM dataset could lead to black spots in the generated cities, while another user suggests removing special identifiable landmarks like the Eiffel Tower from the background. One comment provides a link to the CityDreamer gallery and a YouTube video for further exploration. Another user compares CityDreamer to SceneDreamer, highlighting their different approaches to generating cities. One user appreciates the research but also mentions the importance of well-tended interactions in producing realistic and complex city compositions. Another user discusses the concept of generative city modeling and its applications for urban planning. There is a reference to CityEngine, a procedural city generation tool presented at SIGGRAPH 2001, and its use of L-systems and context-dependent rules to generate detailed cities. The comment also provides links for further reading. Shape grammars are mentioned as a related concept with a similar syntax. There is a mention of the game Townscaper and a link to a tweet thread discussing its development. Another user shares a video link to Night Call, which showcases the generation of Paris using an nth-fly technique. The conversation shifts to discussing the use of digital twins and how city planning departments often rely on outdated and incomplete data. One user finds it fascinating how City Skylines, a game, doesn't have an API to model its city generator. The discussion concludes with a few short comments.

### Training and aligning LLMs with RLHF and RLHF alternatives

#### [Submission URL](https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives) | 95 points | by [rasbt](https://news.ycombinator.com/user?id=rasbt) | [14 comments](https://news.ycombinator.com/item?id=37455859)

Today's article on Sebastian Raschka's blog explores the process of Reinforcement Learning with Human Feedback (RLHF) in the context of training Language Models (LLMs). RLHF is an important component of modern LLM training as it allows for the incorporation of human preferences into the optimization process, leading to improved model performance and safety.

The article provides a step-by-step breakdown of RLHF, starting with a discussion of the canonical LLM training pipeline. This pipeline consists of three main steps: pretraining, supervised finetuning, and alignment. In the pretraining phase, models learn from vast unlabeled text datasets using a next-word prediction task. This allows for the leveraging of large, unlabeled datasets without the need for manual labeling.

The next step is supervised finetuning, where models are trained on instruction-output pairs. This involves predicting the next tokens in the output given specific instructions. Supervised finetuning requires smaller datasets compared to pretraining, as it involves human or high-quality LLM-generated instructions and desired outputs.

Finally, the article delves into the RLHF-based alignment step, which aims to align the LLM with human preferences. RLHF involves fine-tuning the model using reinforcement learning, where human feedback is used to guide and improve the model's responses. The article also provides a comparison between ChatGPT's and Llama 2's implementations of RLHF.

For those interested in alternatives to RLHF, the article includes a section that highlights the most recent alternatives and intends to keep it regularly updated.

Overall, the article offers a comprehensive overview of RLHF and its role in LLM training, providing insights into its importance and practical implementations.

The discussion on the submission revolves around various aspects of RLHF and its implications for language models. Here are some key points raised by the commenters:

- Discussions on the alignment process of LLMs highlight the challenges related to the quality and quantity of training data. The commenter "og_kalu" points out that producing good supervised fine-tuning (SFT) datasets can be quite challenging, while "phllpcrtr" emphasizes the high degree of reliability and reproducibility needed in LLMs, which may not be achieved easily.

- "wstrnr" suggests the addition of additional layers in LLMs to determine the relevance and logical soundness of presented conclusions, supporting the conclusions presented in the article.

- The issue of hallucination in language models is addressed by multiple commenters. "bgglbtl" states that the high degree of reliability and reproducibility in LLMs is crucial, and "Salgat" discusses the limitations of simple linear regression models in dealing with hallucinations and the need for more complex algorithms.

- "ftxbr" argues that large language models lack creativity and are limited in their cognitive capabilities, while "Salgat" counters that hallucination is a part of creativity and that wrong predictions are an inherent flaw of creative language models.

- "ShamelessC" criticizes the article for subtly misrepresenting OpenAI's intention regarding RLHF's role in hallucination reduction, stating that it was partially flawed in its design and purpose. The commenter also mentions Yann LeCun's opinion on training lesser models and retraining researchers.

Overall, the discussion explores the challenges and implications of RLHF in language models, including issues related to training data quality, hallucination, reliability, reproducibility, and creativity.

### What You Say to Google Assistant and Alexa (Not Siri) Gets Used for Ad Targeting

#### [Submission URL](https://www.consumerreports.org/electronics/digital-assistants/voice-assistants-and-ad-targeting-a1098726954/) | 64 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [13 comments](https://news.ycombinator.com/item?id=37460403)

Have you ever wondered if your interactions with voice assistants like Google Assistant and Alexa are being used for ad targeting? Well, a new study by Northeastern University in Boston has found evidence that Google and Amazon do indeed use your voice interactions to draw conclusions about you. Based on what you say to these devices, Google can infer details like your marital status and homeowner status, while Amazon takes note of products you may be interested in. These companies use this data to supplement the information they already gather from your phones and laptops, and in turn, marketers use this valuable information to target ads to the people they believe are most likely to buy their products. So the requests you make to Alexa or Google Assistant can actually influence the ads you see online. The study also revealed that Google Assistant's responses to you can be influenced by your past interactions. On the other hand, Apple's Siri does not appear to connect any tags directly to users or use voice interactions to build a marketing profile. This study highlights the need for better transparency in the data privacy practices of voice assistants. While you may be used to being tracked online, it's important to consider how your interactions with voice assistants may also be contributing to targeted advertising.

The discussion on this submission revolves around the implications of the study's findings and the differences between voice assistants. Some users are surprised by the extent to which Google and Amazon use voice interactions for targeted advertising, while others expect this level of personalization. Commenters point out that Google profits from targeted ads based on user searches, while Amazon builds marketing profiles from Alexa purchases. There is also a mention of Apple's Siri, which does not seem to use voice interactions for ad targeting, leading to a discussion on Siri's privacy practices. One commenter shares an anecdote about their family's experience with targeted ads on their iPhones, raising questions about IP-based targeting and privacy. Another commenter mentions that Siri uses location services. One user dismisses the idea of any conspiracy theories surrounding the study findings and emphasizes the predictability and relevance of targeted ads. However, it is noted that people may not fully understand the extent to which their interactions are being used. A final comment raises the question of whether Siri has a private API or if Apple has access to Siri's data.

### A.I. tools fueled a 34% spike in Microsoftâ€™s water consumption

#### [Submission URL](https://fortune.com/2023/09/09/ai-chatgpt-usage-fuels-spike-in-microsoft-water-consumption/) | 26 points | by [alexzeitler](https://news.ycombinator.com/user?id=alexzeitler) | [8 comments](https://news.ycombinator.com/item?id=37460532)

Microsoft, OpenAI, and Google are facing increased scrutiny over the environmental impact of their artificial intelligence (AI) projects. Specifically, these companies' AI tools, such as Microsoft's ChatGPT, require significant amounts of water to cool their powerful supercomputers. In Microsoft's latest environmental report, it revealed that its global water consumption rose by 34% from 2021 to 2022, largely due to its AI research. Similarly, Google reported a 20% growth in water use during the same period, which can also be attributed to its AI work. Researchers estimate that ChatGPT uses around 500 milliliters of water each time it is prompted with a series of questions. The companies' water usage includes both direct and indirect consumption, such as the water required to cool power plants that supply electricity to the data centers. Microsoft and OpenAI have stated that they are investing in research to measure the energy and carbon footprint of AI and are working on making large systems more efficient. They are also committed to meeting sustainability goals, including being carbon negative, water positive, and zero waste by 2030.

The discussion revolves around the environmental impact of the water consumption by Microsoft, OpenAI, and Google for their AI projects. Here are some key points:

1. Veserv comments on the massive amount of water used, stating that 17 billion gallons of water were consumed, which is equivalent to 7 million cubic meters or 5,200 Olympic swimming pools. The cost of this water consumption amounts to $50 per cubic meter or $35 million in water gas charges.

2. PrivateButts questions why the water cannot be discharged after being used for cooling. They suggest that perhaps the worst pumped holding pond could release the water back into the supply.

3. 1letterunixname argues that unless the data centers are partially designed to reuse municipal potable water or adopt innovative methods for cooling, such as using vaporative cooling or thermal gradients, the water consumption is wasteful. They give the example of data centers using chilled water from a cogeneration plant to save non-potable freshwater. They also highlight the importance of preventing Legionnaires' disease by using non-potable water with disinfectants.

4. Phil21 adds that evaporative cooling is a standard method in the industry and has been dependent on local geography for the past 15 years. They are surprised that it is still a widely-used cooling method.

5. Rch shares a link to an archived article discussing the issue.

6. __loam comments that it is important for people to realize the wastefulness of certain technologies and the energy requirements of data centers.

7. Bone_frequency suggests that it is a key issue and emphasizes the importance of tackling it.

8. PeterStuer compares the energy footprints of traveling and data centers.

Overall, the discussion highlights concerns about the water consumption of AI projects and encourages the adoption of more sustainable and efficient practices in data centers to reduce environmental impact.

### Moral Crumple Zones: Cautionary Tales in Human-Robot Interaction (2019)

#### [Submission URL](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2757236) | 23 points | by [viburnum](https://news.ycombinator.com/user?id=viburnum) | [19 comments](https://news.ycombinator.com/item?id=37452801)

Title: "Moral Crumple Zones: Cautionary Tales in Human-Robot Interaction"

Author: Madeleine Clare Elish

Publication date: March 1, 2019

In a thought-provoking paper, Madeleine Clare Elish explores the concept of "moral crumple zones" in human-robot interaction. Drawing on examples of high-profile accidents involving complex automated systems, the author argues that the responsibility for an action may be unfairly attributed to a human operator who has limited control over the behavior of an autonomous or automated system. 

Much like a crumple zone in a car absorbs the force of impact in a crash, the author describes the human operator in a complex and automated system as a "component" that bears the brunt of moral and legal responsibilities when the system malfunctions. This concept challenges the design and regulation of human-robot systems, highlighting the potential for consumer and worker harm in new complex technologies.

By examining cases such as accidents involving driverless cars and other autonomous technologies, the paper raises important questions about responsibility, ethics, and the social perceptions of technology. Understanding and addressing these moral crumple zones is crucial as the use of artificial intelligence and automation continues to expand in society.

Overall, Elishâ€™s paper provides a valuable perspective on the complex relationship between humans and technology, emphasizing the need for responsible design and regulation in the development of autonomous systems.

The discussion on this submission revolves around the concept of assigning responsibility in cases of accidents involving autonomous or automated systems. One user points out that legal systems have already adapted to handle situations where crimes are committed by proxy through human agents, but questions whether it makes sense to attribute responsibility to AI systems. Another user raises concerns about the consequences of neglecting human responsibility and shifting liability to non-human entities. They argue that failure to hold companies accountable for the actions of AI systems could lead to negative outcomes. 

The discussion also touches upon the role of truck drivers and whether they can be blamed for accidents caused by AI systems. Some argue that truck drivers are being unfairly blamed for accidents caused by system malfunctions. Others point out that human drivers may react differently in dangerous situations and that AI malfunctions may not be fully preventable.

There is also a discussion about the power dynamics and politics involved in assigning responsibility for accidents caused by AI systems. One user suggests that the legal system allows courts to determine appropriate punishments based on circumstances, while another argues that the legal system is flawed and that personal background and limited experience are factors in decision-making. 

The conversation delves into the broader issues of employer demands and the consequences of violating laws. Some argue that employees are forced to comply with unsafe conditions and that companies should be held responsible. Others mention the power imbalance between employers and employees and the importance of protections for employees. 

There is also a brief discussion on the role of courts and the ability of defendants to control their actions, as well as a comment about the inability to assign blame to non-human entities.

Overall, the discussion highlights the complexities of assigning responsibility and the need to address ethical and legal considerations in human-robot interaction.

### Improving NeRF quality by progressive camera placement

#### [Submission URL](https://arxiv.org/abs/2309.00014) | 33 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [12 comments](https://news.ycombinator.com/item?id=37460465)

A recent paper titled "Improving NeRF Quality by Progressive Camera Placement for Unrestricted Navigation in Complex Environments" explores how to enhance the quality of novel view synthesis using Neural Radiance Fields (NeRFs) in complex environments. NeRFs excel at object-centric reconstructions, but their performance in environments such as rooms and houses is often underwhelming. The researchers argue that high-quality data is crucial for optimizing a NeRF effectively, and propose an algorithm that suggests new camera placements to improve the visual quality of the reconstruction. Their solution outperforms existing methods and can be used with any NeRF model. This research has the potential to advance the field of computer vision and pattern recognition.

In the comments, user "brdknwls" suggests that capturing 3D video instead of stills and using optimal camera placement can capture more information. User "fudged71" wonders if Gaussian Splattering techniques and AR headsets could also be effective. "Legend2440" mentions that NeRFs work with Gaussian splatting and improving 3D representation. "PaulHoule" finds the research exciting and suggests that the field could benefit from incorporating light field cameras for creating 3D models. "blvscff" mentions a separate research paper on Gaussian splattering. "lucb1e" explains the role of Neural Radiance Fields (NeRFs) in rendering 3D reconstructions and user "PaulHoule" agrees. "CharlesW" brings up a similar technique called Multi-View Stereo (MVS), and "blvscff" comments on the differentiable process of NeRFs.

### Show HN: Monthly budgeting spreadsheet and ML expense categorisation

#### [Submission URL](https://www.expensesorted.com/) | 11 points | by [ffstrauf](https://news.ycombinator.com/user?id=ffstrauf) | [7 comments](https://news.ycombinator.com/item?id=37452986)

Introducing an AI-powered tool that will revolutionize your monthly expense tracking! Say goodbye to the tedious task of manually categorizing your expenses. This tool seamlessly integrates with Google Sheets to provide you with an efficient workflow.

With advanced AI algorithms, your expenses are automatically categorized, saving you time and effort. Your data is protected with a secure Google Sheets integration, ensuring privacy and data protection.

The streamlined interface offers a seamless user experience, making it easy for you to navigate and manage your expenses. The tool's accurate transaction identification reduces the need for manual oversight.

Customization is key, and you can easily modify or add categories that suit your personal or business needs. This flexibility ensures that the tool caters to your specific requirements.

Don't just take our word for it â€“ hear what other users are saying! Jason N. found that this tool transformed his monthly budgeting routine, making it efficient and incredibly accurate. Vicky S., a small business owner, is saving hours each month thanks to the AI-driven classification.

Curious to know more? Check out the FAQ section to get all your questions answered. Rest assured, the connection to your Google Sheet is prioritized for security, using OAuth 2.0 and never storing your data.

Experience a demo of this game-changing tool and witness its capabilities first-hand. From bank transactions to expense tracking, this tool is designed to simplify your life. Take control of your finances with Google Sheet Expense Tracking.

The discussion on this submission revolves around the topic of expense tracking and categorization using AI-powered tools. One user, tkkn, expresses interest in the integration of multiple bank accounts and cards and asks if there is a feature similar to You Need a Budget (YNAB) for historical transaction imports. Another user, ffstrf, suggests checking out Tiller Money, which offers the ability to import transactions from bank accounts using the Plaid service.

In response, tkkn thanks ffstrf for the suggestion. The conversation ends with no further comments.

In a separate comment thread, user kfk shares their positive experience with using machine learning in their role as a controller in a finance department. They mention that ML-powered spreadsheets have been useful for controlling expenses, reconciling bank transactions, managing cost categories, and generating reports.

In response, ffstrf expresses gratitude for the information and adds that spreadsheets are helpful in handling structured data.

Attempting to delve deeper into the topic, kfk mentions that they primarily use Excel spreadsheets, which support Typescript. However, they have not explored building solutions to handle bank transactions and accounting postings.

ffstrf finds this interesting and speculates that it might be possible to leverage hacking services or replicate existing solutions that support machine learning.

The conversation ends without further comments.

