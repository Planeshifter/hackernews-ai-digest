## AI Submissions for Sun Sep 14 2025 {{ 'date': '2025-09-14T17:13:49.913Z' }}

### The AI-Scraping Free-for-All Is Coming to an End

#### [Submission URL](https://nymag.com/intelligencer/article/ai-scraping-free-for-all-by-openai-google-meta-ending.html) | 64 points | by [geox](https://news.ycombinator.com/user?id=geox) | [64 comments](https://news.ycombinator.com/item?id=45240266)

Headline: The AI-scraping free-for-all meets its first real speed bumps

Summary:
- After years of “take now, ask later” data collection, AI training data is getting fenced off. Big firms cut licensing deals (OpenAI with Reddit and Vox Media; Google and Amazon elsewhere) while scraping has escalated into an arms race with covert crawlers and massive request floods.
- Publishers say AI crawlers “copy and compete,” unlike search engines that send traffic back. A leaked list tied to Meta suggests industry‑wide scraping from copyrighted, pirated, and adult sources — reinforcing that this isn’t a one‑off.
- Countermoves are arriving from the infrastructure layer. Cloudflare is rolling out tools to identify AI scraping and a prospective marketplace for paid ingestion. Meanwhile Reddit, Medium, Quora, and Fastly unveiled RSL (Really Simply Licensing), a standard to declare if/what can be scraped, how to attribute it, and what it costs.
- Enforcement could actually bite this time because CDNs can throttle or block stealth bots at scale. Many sites may go “AI-invisible” by default — except for the Google wrinkle, since its Search and AI crawls share infrastructure and blocking one risks search visibility.

Why it matters:
- If major CDNs and big publishers align, frontier models could be starved of fresh web data, nudging the industry toward paid licensing rather than blanket scraping.
- Power may shift from open crawling to closed deals and infrastructure gatekeeping, potentially squeezing smaller labs and accelerating a balkanized web.
- Open questions: Will big AI honor RSL signals? How will compliance be audited? Where does fair use or text/data mining law land? And will this push more content behind APIs and paywalls?

**Summary of Discussion:**

- **Enforcement Challenges & Technical Workarounds:**  
  Participants note the difficulty of enforcing anti-scraping measures, as AI companies exploit loopholes like browser extensions (e.g., Comet) or covert bots to bypass restrictions. Some suggest browsers themselves act as intermediaries, making legal enforcement tricky. Others argue detection tools are ineffective if browsers comply with scraping.

- **Legal Gray Areas:**  
  Debates arise over the legality of AI-enabled scraping, particularly for paywalled or members-only content. Questions about consent, MITM (man-in-the-middle) browser behavior, and jurisdictional compliance highlight unresolved legal ambiguities.

- **Copyright Reform Proposals:**  
  A lengthy critique of current copyright law calls for shorter terms (e.g., 5-15 years), mandatory rights documentation, and royalties for creators. Critics dismiss this as idealistic, while others advocate for simplified systems to reward creators without bureaucratic complexity.

- **Syndication vs. Centralization:**  
  Some argue paywalls and logins favor large platforms (e.g., Spotify, YouTube), accelerating industry consolidation. Others counter that syndication benefits creators and consumers, though concerns persist about monopolistic control and reduced competition.

- **Technical Countermeasures:**  
  Ideas include throttling bots via CDNs, using JavaScript-free paywalls, or hosting content on archive sites. Skepticism remains about effectiveness, with examples like AI scraping archived content despite paywalls.

- **Power Shifts & Industry Dynamics:**  
  Fears that big tech (Google, Meta) will dominate licensing deals, marginalizing smaller AI labs. Participants also note irony in discussing paywalled news while relying on platforms like HN for open discourse.

- **Ethical Concerns:**  
  Criticisms of AI companies scraping private or pirated content, with calls for transparency and accountability. Some highlight privacy risks, such as archived data exposing user credentials.

**Key Themes:**  
Scraping evasion tactics, legal uncertainty, copyright reform debates, centralization risks, and skepticism toward technical fixes dominate the discussion. Many express concern that existing solutions disproportionately empower large corporations while failing to protect creators or smaller entities.

### CorentinJ: Real-Time Voice Cloning (2021)

#### [Submission URL](https://github.com/CorentinJ/Real-Time-Voice-Cloning) | 88 points | by [redbell](https://news.ycombinator.com/user?id=redbell) | [22 comments](https://news.ycombinator.com/item?id=45239016)

Corentin Jemine’s widely starred repo (55.6k stars, 9.1k forks) implements SV2TTS: clone a voice from a few seconds of audio and generate arbitrary speech in real time. Under the hood it chains three well-known components: a GE2E encoder (speaker embedding from a short clip), a Tacotron-style synthesizer (text → mel spectrogram), and a WaveRNN vocoder (mel → waveform) for real-time output.

Notably, the maintainer flags that the project is now dated: modern SaaS and newer open-source projects produce higher quality. The README points newcomers to paperswithcode for current work and to “Chatterbox” as a more up-to-date, 2025‑level alternative, but this repo remains a solid learning and prototyping baseline.

Quick start:
- Python ≥3.5 (3.7 recommended), ffmpeg, and PyTorch (CUDA optional; GPU helps).
- pip install -r requirements.txt; pretrained models auto-download.
- Test: python demo_cli.py. GUI toolbox: python demo_toolbox.py (optionally with a LibriSpeech subset).

Why it matters: It’s the repo that popularized “clone a voice in 5 seconds” for hobbyists and researchers, making the SV2TTS pipeline tangible. For production quality in 2025, look to newer models—but this remains a formative reference. Ethical note: obtain consent and consider disclosure when cloning voices.

**Summary of Discussion:**

- **Ethical & Security Concerns**: Users highlighted risks like potential misuse for scams, NSFW content, and voice cloning's ethical implications. Debates arose on consent and disclosure, with mentions of GitHub's role in controlling content (deleting repos vs. forking/cloning).

- **Technical Comparisons**: Discussions noted newer models (e.g., Microsoft's VibeVoice) surpassing the repo's dated tech. Links to a community-maintained fork ([VibeVoice-ComfyUI](https://github.com/Enemyx-net/VibeVoice-ComfyUI)) were shared, emphasizing ongoing development despite the original project's stagnation.

- **Project Relevance**: Users pointed out the repo’s age (papers from 2017–2018, inactive since 2021), with some defending its foundational role in democratizing voice cloning. Others stressed that modern SaaS tools and open-source alternatives now offer higher quality.

- **Security Measures**: Concerns about voice identity protection surfaced, underscoring the need for safeguards against AI-driven impersonation.

- **Platform Dynamics**: GitHub’s content policies were debated, distinguishing between cloning (local copies) and forking (platform-linked copies), with implications for censorship and preservation.

**Takeaway**: While the repo remains a key educational resource, its technical limitations and ethical challenges highlight the rapid evolution of voice cloning tech and the ongoing need for responsible use and updated solutions.

### Gentoo AI Policy

#### [Submission URL](https://wiki.gentoo.org/wiki/Project:Council/AI_policy) | 178 points | by [simonpure](https://news.ycombinator.com/user?id=simonpure) | [171 comments](https://news.ycombinator.com/item?id=45244295)

Gentoo bans AI-assisted contributions to official projects

The Gentoo Council voted on April 14, 2024 to prohibit any content created with the assistance of NLP-based AI tools from being contributed to Gentoo projects. The policy can be revisited if a tool is shown not to raise copyright, ethical, or quality concerns. It does not block adding packages for AI-related software, nor packaging software that was developed upstream with AI.

Why they did it:
- Copyright: Unsettled law around AI-generated content could jeopardize Gentoo’s copyright claims and copyleft assurances.
- Quality: LLMs often produce plausible but incorrect output, increasing review burden and risking degraded project quality.
- Ethics: Concerns over training on copyrighted data, heavy energy/water use, labor impacts and reduced service quality, and the role of LLMs in enabling spam/scams.

Impact: Contributors must avoid AI-assisted text/code in Gentoo-managed work, while users can still expect AI software to be packageable within the distribution.

The discussion surrounding Gentoo's ban on AI-assisted contributions highlights several key debates and perspectives:

1. **Quality Concerns**:  
   - Participants noted that AI-generated code often appears plausible but contains subtle errors, increasing the review burden. One user shared an example of a PR to LLVM with over 100 comments, where AI-generated code led to time-consuming fixes and stylistic mismatches.  
   - Critics argued that contributors relying on AI might not fully understand the code they submit, forcing maintainers to spend extra effort catching mistakes or enforcing project conventions.  

2. **Impact on Contributors**:  
   - Some expressed concern that banning AI tools could raise barriers for new contributors, likening it to the steep learning curve of niche projects like TempleOS. Others countered that Gentoo’s policy prioritizes **sustainability** over accessibility, ensuring contributors invest time to understand the project’s standards.  
   - A recurring tension emerged between encouraging contributions and maintaining quality. While AI might help newcomers, poorly vetted AI code risks overwhelming volunteer maintainers with low-quality PRs.  

3. **Disclosure and Ethics**:  
   - Suggestions were made to mandate **disclosure** of AI use in PRs, though skeptics doubted this would resolve underlying issues. One user emphasized that even disclosed AI-generated code requires thorough review, negating short-term productivity gains.  
   - Ethical concerns mirrored Gentoo’s stance, with some participants criticizing AI’s environmental impact and reliance on copyrighted training data.  

4. **Project Integrity**:  
   - Supporters of the ban argued that AI-generated code undermines a project’s "social norms," such as developers’ responsibility to understand and explain their work. They viewed Gentoo’s policy as a defense against “detritus” that could degrade long-term code health.  
   - Critics warned that overly strict policies might alienate potential contributors, but proponents maintained that high standards attract committed developers.  

5. **Broader Industry Trends**:  
   - Some noted parallels in tech leadership’s focus on AI-driven productivity metrics, which risk prioritizing quantity over code robustness. Gentoo’s decision was framed as a pushback against this trend.  

In summary, the discussion reflects a divide between those who see AI as a risky shortcut threatening project quality and those who view it as a tool needing careful governance. Gentoo’s ban is seen as a proactive measure to protect copyright, ethics, and code integrity, albeit with trade-offs in contributor accessibility.

### SpikingBrain 7B – More efficient than classic LLMs

#### [Submission URL](https://github.com/BICLab/SpikingBrain-7B) | 146 points | by [somethingsome](https://news.ycombinator.com/user?id=somethingsome) | [44 comments](https://news.ycombinator.com/item?id=45237754)

SpikingBrain-7B: a brain-inspired 7B LLM with “spike” encoding, MoE, and long-context speedups

What’s new
- Architecture: Combines hybrid efficient attention, MoE sparsity, and spike-style activation encoding, plus a “universal conversion” pipeline to plug into the broader open-source model ecosystem.
- Performance claims: 
  - >100× faster time-to-first-token on 4M-token sequences (TTFT) vs baselines in their setup.
  - ~69% micro-level activation sparsity from spiking; combined with MoE macro-sparsity for efficiency.
  - Continual pretraining with <2% of data while matching mainstream open-source models (per their perplexity-based eval).
- Hardware story: Trains/runs on non-NVIDIA (MetaX) clusters; includes “vllm-hymeta” plugin to bring the HyMeta backend into vLLM for NVIDIA GPUs without forking vLLM.
- Variants: 
  - Base (7B), SFT chat (7B-SFT), and a quantized “W8ASpike” build that approximates spiking at the tensor level (pseudo-spiking).
  - Full repo includes Hugging Face format, vLLM integration, and quantized inference.

Why it matters
- Long context, fast start: TTFT improvements at 4M tokens are notable if they hold up outside their stack—could materially improve UX for ultra-long prompts.
- Sparsity for efficiency: Micro (spiking) + macro (MoE) sparsity is aligned with the direction of efficient inference and future neuromorphic hardware.
- Backend modularity: A clean plugin path for alternative hardware backends in vLLM lowers integration/maintenance cost.

How to try
- Weights: Hosted on ModelScope
  - 7B base: Panyuqi/V1-7B-base
  - 7B SFT (reasoning): Panyuqi/V1-7B-sft-s3-reasoning
  - 7B quantized (W8ASpike): Abel2076/SpikingBrain-7B-W8ASpike
- vLLM: Install the repo (pip install .) to enable the HyMeta plugin; serve with vllm serve <model_path> --dtype bfloat16 and optional TP/PP flags.
- HF: Load as a standard AutoModelForCausalLM; SFT comes with a chat template; example scripts in run_model/.

Caveats
- “Spiking” here is pseudo-spiking (tensor-level approximation), not true event-driven SNNs on neuromorphic hardware.
- Reported performance is largely perplexity-based; some baselines are trained on limited Chinese data; independent benchmarks pending.
- The MetaX-focused stack and plugin-based NVIDIA path may affect reproducibility across environments.

Links
- Repo: BICLab/SpikingBrain-7B
- Tech report: English/Chinese; arXiv: 2509.05276

**Summary of Discussion:**

- **Skepticism About Neuromorphic Claims**:  
  Commenters question whether "spiking" in SpikingBrain-7B is genuine neuromorphic computation (event-driven, brain-like) or merely a marketing term. Critics argue it relies on tensor-level approximations ("pseudo-spiking") rather than true spiking neural networks (SNNs) on neuromorphic hardware. Comparisons are drawn to historical neuromorphic projects like Synaptics, viewed as overhyped.

- **Technical Debates on Efficiency**:  
  Discussions explore whether spike-based encoding (binary vs. numerical) improves efficiency. Some argue binary encoding could reduce power consumption by minimizing transistor switching, while others question if current implementations truly replicate biological mechanisms like spike-timing-dependent plasticity (STDP). The hybrid approach (sparsity + MoE) is seen as promising but unproven in practice.

- **Historical Context and Criticism**:  
  The term "neuromorphic" is traced back to Carver Mead’s 1980s work, with skepticism about its modern overuse as a buzzword. Projects like SpiNNaker (ARM-based neuromorphic systems) are cited as examples of hardware that prioritizes efficiency but may not meaningfully mimic brain dynamics. Critics highlight past failures in neuromorphic ventures and caution against conflating marketing with technical substance.

- **Hardware and Geopolitical Nuances**:  
  MetaX (non-NVIDIA hardware) is noted as part of China’s long-term strategy to reduce reliance on Western tech. While MetaX’s current competitiveness is debated, its integration via vLLM plugins is seen as a pragmatic step. However, reproducibility concerns arise due to stack specialization.

- **Asynchronous vs. Synchronous Processing**:  
  Debates contrast neuromorphic systems’ event-driven, asynchronous dataflow with traditional synchronous architectures. Proponents argue async processing reduces power use by activating components only when inputs change, while skeptics question whether CMOS-based designs can truly avoid constant power draw.

- **Cultural and Academic Critique**:  
  Some liken neuromorphic hype to historical pseudoscientific trends, referencing 19th-century "brain metaphor" overreach in fields like psychology. The discussion underscores the tension between biologically inspired innovation and the risk of overselling unproven paradigms.

**Key Takeaway**:  
The discussion reflects cautious interest in SpikingBrain-7B’s efficiency claims but emphasizes the need for independent benchmarks and clarity on whether its "spiking" mechanics offer novel computational advantages or repackage existing sparse methods. Broader skepticism about neuromorphic computing’s practical maturity persists, with calls to prioritize measurable outcomes over metaphorical branding.

### Vibe coding has turned senior devs into 'AI babysitters'

#### [Submission URL](https://techcrunch.com/2025/09/14/vibe-coding-has-turned-senior-devs-into-ai-babysitters-but-they-say-its-worth-it/) | 123 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [107 comments](https://news.ycombinator.com/item?id=45242788)

AI “vibe coding” is turning senior engineers into AI babysitters — and many say the trade-off is still worth it. TechCrunch profiles veterans like Carla Rover, who rebuilt an entire project after trusting AI-generated code, and Feridoon Malekzadeh, who leans on tools like Lovable but expects a lot of cleanup.

Key points:
- Speed vs. rework: Rover used AI to move fast at her startup but found major issues only after manual and third‑party reviews, forcing a full restart. “I handed it off like the copilot was an employee. It isn’t.”
- Babysitting burden: A Fastly survey of ~800 devs found at least 95% spend extra time fixing AI code, with the verification load falling hardest on seniors. Problems range from hallucinated package names to deleted critical info and security risks.
- New job title: Some companies now have “vibe code cleanup specialists” focused on making AI output production-safe.
- Reliability metaphors: Rover likens AI to a clever six-year-old carrying a coffee pot—capable, but not safely autonomous. Malekzadeh calls it a “stubborn, insolent teenager” that needs repeated instructions and breaks things along the way.
- Workflow reality: Malekzadeh spends ~50% on requirements, 10–20% vibe coding, 30–40% vibe fixing. He says AI lacks systems thinking, duplicating features in multiple inconsistent ways.
- Trust issues: Rover reports the model confidently fabricated explanations, later admitting it hadn’t used her uploaded data.

Bottom line: AI can accelerate solo builders and cut costs, but only with rigorous specs, oversight, and post‑gen cleanup. Left unchecked, vibe code ships faster—and breaks harder.

The Hacker News discussion on AI "vibe coding" reveals skepticism, frustration, and cautious pragmatism among developers, with recurring themes of productivity trade-offs, job market shifts, and comparisons to past tech trends like web3. Key points include:

### 1. **AI as the New "Gold Rush"**  
   - Many liken AI hype to the web3 bubble, where outsiders invest in vague promises. User **grskl** critiques the cycle: "People talk gold rushes by selling shovels instead of digging gold... a sign of a bubble."  
   - **cdll** compares AI-generated projects to web3’s "completely incomprehensible" infrastructure, suggesting both rely on opaque jargon to mask impracticality.

### 2. **Productivity vs. Cleanup Burden**  
   - Developers report mixed results: **trtltntn** cites a study claiming AI makes some 20% faster but others 20% slower.  
   - **mtthwfcrlsn** and **lrdnch** describe AI as a "half-baked intern" requiring tedious oversight: "Spend hours convincing it to do dumb things." Cleanup often outweighs initial coding gains.  
   - **anon22981** notes a drop in code quality, with seniors submitting "garbage PRs" due to over-reliance on AI.

### 3. **Job Market Fears and Realities**  
   - **cs702** outlines startups replacing juniors with AI, prompting fears of senior roles evaporating. **krmtt** sarcastically replies, "Step 3: Hire devs at double pay" to handle AI fallout.  
   - **Spivak** warns of “job board battery” gig economies replacing traditional junior roles, with AI increasing risk for smaller teams.

### 4. **Technical Limitations and Workflow Costs**  
   - **siliconc0w** critiques “vibe coding” as non-deterministic, sparking debate. **jb1991** clarifies that deterministic outputs *are* possible but require restrictive configurations (e.g., fixing seeds, disabling GPU batch processing).  
   - **nlv** highlights juniors using AI to churn out brittle code: "2000-line PRs with no tests" create maintenance nightmares. **dglsh** laments reviewing "garbage" PRs from juniors: "It's soul-crushing."

### 5. **AI as a Leadership Challenge**  
   - **hplt** frames AI collaboration as akin to managing people: "GIGO (garbage in, garbage out)" applies. Effective use demands clear specs and governance.  
   - **lrdnch** compares AI to a "stubborn teenager," requiring explicit architectural guidance to avoid duplicated or conflicting code.

### Bottom Line:  
The consensus echoes the article: **AI accelerates code output but demands rigorous oversight**. Developers see value in leveraging AI for repetitive tasks, but warn against unchecked adoption. As **nlv** summarizes: "If juniors use AI to spit out patchwork code, the quality debt will pile up." The trade-off—speed for technical debt—echoes past tech cycles, leaving many wary but reluctantly pragmatic.

