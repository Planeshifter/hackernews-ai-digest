## AI Submissions for Tue Jan 06 2026 {{ 'date': '2026-01-06T17:16:09.549Z' }}

### Opus 4.5 is not the normal AI agent experience that I have had thus far

#### [Submission URL](https://burkeholland.github.io/posts/opus-4-5-change-everything/) | 740 points | by [tbassetto](https://news.ycombinator.com/user?id=tbassetto) | [1067 comments](https://news.ycombinator.com/item?id=46515696)

Headline: Developer says Claude Opus 4.5 crossed the “agent replaces developer” threshold

- A solo dev claims Claude Opus 4.5 delivered the AI coding agent experience “we were promised,” reversing his view from three months ago that agents couldn’t replace developers.
- Workflow: GitHub Copilot’s VS Code agent harness, a custom agent prompt (shared in the post), voice dictation to Claude, and a single MCP (Context7). Minimal planning; mostly chat-driven.
- Key behavior shift: Opus 4.5 scaffolds, builds, runs CLI commands, reads errors, and iterates with high first-try accuracy—reducing the copy/paste/fix loops that usually derail agent sessions.
- Project 1 (Windows image converter): One-shot build for a right‑click Explorer conversion utility. Opus handled .NET app setup, installer/uninstaller via PowerShell, landing site, GitHub Actions, and icon pipeline. Limitation: needed manual help for XAML errors.
- Project 2 (screen recorder/editor): Started as a simple GIF recorder, quickly grew into a basic video/image editor (capture, shapes, crop, blur). Not finished, but “hours” to reach a surprisingly capable state.
- Project 3 (AI posting utility): Mobile app for batch photo uploads that auto-generates captions and schedules Facebook posts. Opus recommended and wired up Firebase (auth, storage, backend posting). The author says it reached functional iOS status in the time it took to install blinds.
- Caveats and tone: The author stresses these are personal impressions and could be “50% wrong.” Some rough edges remain (e.g., UI/XAML visibility, complex editor still ongoing). But the net takeaway is a strong claim that, with Opus 4.5, agents can now “absolutely” replace developers for a wide range of app work.
- Likely HN discussion: reproducibility across setups, long-term maintainability, security/permissions for automated builds and deploys, API compliance (Facebook), cost control (Firebase Blaze), and whether “hours to MVP” translates to production-grade software.

Here is a summary of the discussion:

**Skepticism and Evidence**
A significant portion of the debate focuses on the validity of anecdotal success stories. Criticism arises regarding the lack of rigorous data, with users like *vldsh* arguing that software engineering involves trade-offs and logical planning that anecdotes don't capture. *flmpcks* demands unedited "8-hour videos" of the workflow rather than curated 5-minute demos, fearing that AI tools empower people to create technical debt they don't understand. Conversely, *wtndrf* argues that long-form coding videos do exist, but skeptics—often late adopters or middle managers protecting their status—refuse to watch them.

**Product Quality vs. "Bloat"**
*hllwtrtl* challenges the community to point out high-performance software built entirely by AI, arguing that modern software (like Teams or VS Code) is bloated despite major companies having access to these tools. They ask why there are no AI-built "Excel killers" or faster browsers.
*   **The "Silent" Success:** *enraged_camel* suggests that people successfully generating revenue (citing a cousin making $10k/mo) with "vib-coded" apps don't disclose their methods to avoid inviting competition.
*   **Customer Indifference:** *g947o* notes that customers do not care if a product is AI-generated; success relies on UX, marketing, and integration, which AI coding alone does not solve.

**Organizational Bottlenecks**
*forgotaccount3* provides a counterpoint regarding corporate environments. They argue that even if an AI can code a feature in minutes, the productivity gains are negated by corporate bureaucracy—planning, cost-benefit analysis, and PMO reporting—which takes hundreds of hours regardless of coding speed.

**The "Democratization" Niche**
Several users (*bstr*, *broken_ceiling*) suggest the immediate value of these agents isn't in rebuilding massive products like Discord, but in democratization. They argue AI is best suited for replacing off-the-shelf SaaS with custom internal tools, personal scripts, and small business CRUD apps, effectively lowering the barrier to entry for bespoke software.

### A 30B Qwen model walks into a Raspberry Pi and runs in real time

#### [Submission URL](https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/) | 310 points | by [dataminer](https://news.ycombinator.com/user?id=dataminer) | [110 comments](https://news.ycombinator.com/item?id=46518573)

HN Top Story: 30B Qwen3 runs “real-time” on a Raspberry Pi with ByteShape’s bitlength learning

What’s new
- The team focuses on what users actually feel: tokens per second (TPS) and quality on a specific device, treating memory as a budget to meet—not something to minimize at all costs.
- Using Shapelearn (bitlength learning), they pick per-weight datatypes that maximize TPS and quality for Qwen3-30B-A3B-Instruct-2507. Key point: in llama.cpp, fewer bits don’t automatically mean faster; different quant formats trigger different kernels, and lower-bit can even be slower on some GPUs.

Key results
- Raspberry Pi 5 (16GB): A 30B model feels real-time.
  - Q3_K_S-2.70bpw [KQ-2]: 8.03 TPS at 2.70 BPW, 94.18% of BF16 quality.
  - ByteShape consistently sits up-and-right of Unsloth in TPS vs quality plots: higher TPS at the same quality or higher quality at the same TPS.
  - Accuracy-first options reach ~98.8% with 5–6 TPS; comparable Unsloth entries land around ~97.9% with lower TPS.
  - Even when prioritizing speed, ByteShape’s Q3_K_S-3.25bpw beats Unsloth on accuracy, size, and speed.
- Intel i7 (64GB): ByteShape extends the lead.
  - Only ByteShape hits 26+ TPS.
  - Quality-first: IQ4_XS-4.67bpw gets 0.25% relative error, beating Unsloth Q6_K (0.36%) and Q5_K_M (0.44%) at similar or better speed; MagicQuant mxfp4 trails.
  - Best balance: Q3_K_S-3.25bpw delivers ~98% accuracy at 23.1 TPS with just 3.25 BPW; Unsloth needs more bits for similar accuracy and falls behind on speed.

Why it matters
- Practical guidance: After the model fits in memory, optimize for TPS and quality—don’t chase the smallest file.
- Predictable tradeoffs: With the right datatypes, you can dial in speed vs accuracy to match constraints.
- Big shift for edge: “Real-time” generation from a 30B model on a Raspberry Pi reframes what Pi-class devices can do.

Try it
- Qwen3-30B-A3B-Instruct-2507 with ByteShape configs (e.g., Q3_K_S-2.70bpw on Pi 5 for responsiveness; IQ4_XS-4.67bpw on desktop for top accuracy).

Here is a summary of the discussion regarding the submission:

**The Holy Grail of Local Voice Assistants**
The primary reaction to running a 30B model on a Raspberry Pi is the potential for a truly private, "plug-and-play" local home assistant. Users envision a standardized component—a "smart speaker" that protects data rather than harvesting it—but note that the market lacks this because big tech companies (Amazon, Google) rely on data collection or subscriptions to subsidize their hardware costs.

**The Hardware Bottleneck: Microphones**
While the LLM software is catching up (thanks to optimizations like ByteShape and platforms like Home Assistant Voice), the hardware remains a major hurdle.
*   **The "Echo" Standard:** Commenters argue that Amazon Echo devices have superior far-field microphones, noise cancellation, and beamforming that make them hear you from across a room even with music playing.
*   **The DIY Reality:** In contrast, home-rolled solutions involving Raspberry Pis, USB speakerphones (like Jabra), or ESP32-based satellites often struggle with deafness, requiring users to shout or be very close to the device.

**UX and Interaction Paradigms**
The community debated the ideal interface for a local AI:
*   **Wake Words:** Some find current open-source wake word detection lacking compared to proprietary solutions.
*   **Alternatives:** Suggestions included physical buttons, proximity sensors, or simple touchscreens for basic info (weather, time) to bypass the "listening" problem entirely.
*   **Proactive AI:** A sub-thread humorously imagined an AI that uses spare cycles to proactively solve household problems or act as a "virtual drill instructor" for alarm clocks, rather than passively waiting for commands.

**Home Assistant Dominance**
Home Assistant (HA) is cited repeatedly as the de facto platform for integrating these models. While HA handles the logic and "plumbing" well, the consensus is that affordable, high-quality voice input hardware is the missing piece of the puzzle to make local AI distinct from cloud-based assistants.

### Comparing AI agents to cybersecurity professionals in real-world pen testing

#### [Submission URL](https://arxiv.org/abs/2512.09882) | 116 points | by [littlexsparkee](https://news.ycombinator.com/user?id=littlexsparkee) | [82 comments](https://news.ycombinator.com/item?id=46518996)

AI agents rival human pentesters on a live 8,000‑host network

- A Stanford/CMU team benchmarked six AI security agents against 10 professional penetration testers in a real university enterprise environment (~8,000 hosts, 12 subnets).
- Their new scaffold, ARTEMIS, finished second overall: 9 validated vulnerabilities with an 82% valid submission rate, outperforming 9 of 10 human participants and matching the top humans on technical depth and report quality.
- Other existing agent frameworks (e.g., Codex, CyAgent) lagged most human testers, suggesting the scaffold and workflow matter as much as the underlying model.
- Strengths: systematic asset enumeration, parallelizing tasks, and cost efficiency—some ARTEMIS setups ran at ~$18/hour vs. ~$60/hour for human pentesters.
- Gaps: higher false-positive rates and struggles with GUI-heavy workflows, reinforcing the need for human oversight and better tooling integration.
- The framework features dynamic prompt generation, plug‑in sub‑agents, and automatic vulnerability triage—pointing to a “copilot” future for red teams rather than full autonomy (for now).

Based on the discussion, Hacker News users analyzed the implications of the Stanford/CMU study, focusing on the shift in the cybersecurity labor market, the importance of agent architecture over raw model power, and the economics of automated vulnerability detection.

**The Evolution of Pentesting**
Users widely agreed that AI agents are poised to transform penetration testing from a manual craft into a managerial role.
*   **Checklists vs. Novelty:** Commenter `tptck`, claiming 20 years in the field, argued that 80–90% of pentesting consists of routine "checklist" tasks (network, web, mobile reviews) that are perfect for automation. `jnhx` and `EE84M3i` concurred, suggesting that while agents excel at defined tasks, humans are still required for identifying business logic bugs and novel exploits.
*   **Scale over Depth:** `KurSix` noted that the primary advantage of agents is horizontal scaling. While a human is constrained by time and attention, an agent system can spin up 1,000 sub-agents to test low-probability hypotheses in parallel—sheer volume compensates for lower individual intelligence.
*   **The "Copilot" Future:** The consensus leans toward a hybrid model where humans manage automated loops. `tptck` predicts that by 2027, the distinction between agent and human tests will blur, though `sry-gnsh` worried this might atrophy the human talent pool needed to find truly novel exploits.

**Scaffolding and Architecture**
The community emphasized that ARTEMIS’s success was due to its software architecture rather than just the underlying LLM.
*   **Role Separation:** `KurSix` and `bsrvtnst` pointed out that ARTEMIS outperformed raw models (like Codex) because it used a scaffolded approach: splitting roles into Supervisors, Workers, and Triage modules.
*   **Memory Management:** `ckngnr` raised concerns about agents lacking the memory required for complex bypass attacks. However, others noted that ARTEMIS solves this architecturally by passing structured state and logs between routines, effectively creating a functional equivalent to long-term memory.
*   **Broader Application:** Users speculated that this methodology (decomposing complex workflows into sub-agent tasks) will soon be applied to other complex domains like PCB design and 3D modeling.

**Economics and Industry Impact**
Much of the debate centered on cost efficiency versus report quality.
*   **Cost Analysis:** `scndnvn` broke down the costs, noting ARTEMIS ran at roughly $18/hour ($37k/year) compared to human testers costing significantly more ($125k+/year). `raesene9` observed that pentesting day rates in the UK have already stagnated due to outsourcing, and AI automation will likely accelerate this trend.
*   **False Positives:** While critics like `JohnMakin` pointed out the high false-positive rate and missed obvious bugs, `pedro_caetano` argued that if the cost is low enough, false positives are acceptable—similar to how Static Code Analysis tools are used despite their imperfections.
*   **Skepticism:** `trgns` and `fby` remained skeptical of the "trounced humans" narrative, questioning the baseline security of the test network and noting that benchmarks often favor specific, diverse findings over deep, critical exploit chains.

### Show HN: Mantic.sh – A structural code search engine for AI agents

#### [Submission URL](https://github.com/marcoaapfortes/Mantic.sh) | 70 points | by [marcoaapfortes](https://news.ycombinator.com/user?id=marcoaapfortes) | [33 comments](https://news.ycombinator.com/item?id=46512182)

Mantic.sh: a structural code search engine for AI agents that finds relevant files in under 500ms without embeddings, vector DBs, or external services.

What it is
- Local-first file retrieval that infers intent from repository structure and metadata instead of reading entire files.
- Designed to feed AI agents only the right files before they write code, reducing token usage and latency.

What’s new in v1.0.18
- Native accelerator: swapped fast-glob for git ls-files / fd, cutting cold start on Chromium from ~30s to under 2s.
- Parallel processing: worker threads for scoring very large repos (50k+ files).
- Process fixes: resolved CLI hang; exits instantly after results.
- Faster ignore filtering via prefix-based matching.
- Improved semantic matches, especially for deep path intent.

Why it matters
- Speed: consistently sub-500ms retrieval, even on huge monorepos (Chromium scale).
- Efficiency: filters out irrelevant files first, reducing token spend (claims up to 63%).
- Privacy: runs entirely locally with zero data egress.
- Deterministic results: predictable, consistent rankings.

Notable features
- Git-native scanning prioritizes tracked files.
- Impact analysis to estimate change blast radius.
- Native MCP server support for Claude Desktop, Cursor, VS Code; shows up as a search_codebase tool.
- Modes and filters: code-only, config-only, test-only; JSON or file-path output; session carryover.

Performance (author’s benchmarks, M1 Pro)
- Cal.com (~9.6k files): 0.32s vs 0.85s vector search.
- Chromium (~480k files, 59GB): ~0.40s vs 5–10s vector search (12–25x faster).

How it works (structural scoring)
- Intent recognition of the query (e.g., auth, UI, payments).
- File enumeration via git ls-files for speed.
- Ranking signals:
  - Path relevance (e.g., packages/features/payments).
  - Filename specificity (stripe.service.ts > stripe.txt).
  - Business-logic awareness (.service.ts boosted; .test.ts penalized).
  - Boilerplate penalties (index.ts, page.tsx lowered).
- Outputs confidence scores and token estimates.

Cost posture (as presented)
- Mantic: $0, local-first.
- Vector embeddings stack: recurring infrastructure costs.
- Cloud SaaS: higher ongoing costs and data egress.

Getting started
- One-off: npx mantic.sh@latest "your search query"
- From source: clone repo, npm install, build, npm link.
- MCP: add to Claude Desktop config or install in Cursor/VS Code; then call search_codebase.
- CLI options: --code, --config, --test, --json, --files, --impact, --session <id>.

Who it’s for
- Teams using AI coding agents who need fast, private, and deterministic context retrieval across large repos.
- IDE/agent workflows where “find the right files first” is a bottleneck.

Repo snapshot
- 256 stars, 7 forks at time of posting; includes AGENT_RULES for IDEs to auto-call Mantic before code generation.

Based on the discussion, here is the summary:

*   **Licensing and Cost:** There was confusion regarding the project's AGPL license and its implications for commercial SaaS. Users pointed out the author’s initial explanation sounded more like LGPL; the author acknowledged the mix-up and updated the documentation. Others engaged in a debate about the author's cost comparison, validating that local heuristics are significantly cheaper than recurring vector database costs.
*   **Rapid Bug Fixes:** Users reported issues with large repositories (specifically Chromium) and missing features like ignore patterns. The author deployed immediate updates (v1.0.13 and v1.0.15) within the thread to add environment variables, fix timeouts, and implement regex-based function extraction, bringing Chromium scan times down to ~2.3 seconds.
*   **"AI Slop" Accusations:** The extreme speed of these code fixes, combined with the author's use of the term "weights" in the code, led some skepticism. Commenters accused the account of being an LLM and the code of being "AI slop." The author pushed back, clarifying that the "weights" are deterministic (hardcoded values for file importance like `.ts` vs `.md`), not neural network parameters, and that no LLM is involved in the search ranking itself.
*   **Mechanism Clarification:** Commenters compared the tool to `fzf` and JetBrains' search algorithms, questioning the "cognitive" branding. The author confirmed the tool relies on structural metadata (paths, folder depth, recency) rather than semantic embeddings, arguing that developers naturally encode intent into file structures.

### Hierarchical Autoregressive Modeling for Memory-Efficient Language Generation

#### [Submission URL](https://arxiv.org/abs/2512.20687) | 43 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [3 comments](https://news.ycombinator.com/item?id=46515987)

PHOTON: hierarchical LMs that read “vertically” to crush KV-cache bottlenecks

What’s new
- The authors propose PHOTON (Parallel Hierarchical Operation for Top-down Networks), an autoregressive language model that replaces Transformers’ flat, token-by-token scanning with hierarchical, multi-resolution context access.
- Instead of attending over an ever-growing sea of token states, PHOTON maintains a stack of latent streams: a bottom-up encoder compresses tokens into low-rate contextual states, and lightweight top-down decoders reconstruct fine-grained token representations when needed.

Why it matters
- Transformer decoding is increasingly memory-bound at long context because KV-cache reads/writes dominate throughput. PHOTON’s “vertical” access slashes decode-time KV traffic, aiming to lift that bandwidth bottleneck.
- The authors report better throughput–quality trade-offs than competitive Transformer LMs, with large advantages on long-context and multi-query workloads—use cases that are notoriously KV-bound.

Key claims
- Dramatic reduction in KV-cache traffic during decoding.
- Up to 10^3× higher throughput per unit memory.
- Superior performance on long-context and multi-query tasks at similar quality.

Takeaways
- If validated, hierarchical top-down reconstruction could make long-context serving far cheaper and faster by shifting the bottleneck back toward compute and away from memory bandwidth.
- Paper is concise (12 pages, 5 figures); code isn’t linked in the abstract snippet. Independent benchmarks and open-source implementations will be key to assess real-world gains.

Paper: arXiv:2512.20687 (cs.LG), “PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation”
Link: https://arxiv.org/abs/2512.20687 (DOI pending)

**Discussion**
*   **Performance skepticism:** Commenters pointed out that the authors acknowledge using a tiny model and corpus, yielding accuracy that is currently only comparable to or worse than standard Transformers.
*   **Not yet SOTA:** Critics noted the experimental design does not demonstrate near state-of-the-art results, suggesting significant additional work is needed for high-profile conference acceptance.
*   **Aesthetic impressions:** One reader described a "sci-fi feeling" while skimming the paper, observing that the diagrams are reminiscent of boolean arithmetic circuits.

### Show HN: llmgame.ai – The Wikipedia Game but with LLMs

#### [Submission URL](https://www.llmgame.ai) | 23 points | by [jmcallister](https://news.ycombinator.com/user?id=jmcallister) | [20 comments](https://news.ycombinator.com/item?id=46508299)

I don’t have the submission details yet. Please share the Hacker News post you want summarized (title + link, or paste the article text). If you want comment highlights, include a few top comments.

Optional:
- Desired length: one-liner, 3–5 bullets, or ~150 words
- Tone: neutral, punchy, or technical
- Any specific angles to emphasize (privacy, business impact, engineering details)

Based on the comment logs provided, here is a summary of the discussion surrounding the submission (which appears to be a link to an LLM-based semantic association game, likely located at `www.llm.gm`).

**Story:** **LLMgm: An LLM-based semantic path-finding game**
**Link:** [Inferred: www.llm.gm]

**Summary of Discussion:**
The discussion consists primarily of users sharing their "paths" and scores from a game where the objective is to navigate between two unrelated concepts (e.g., "Piano" to "Volcano") using LLM-generated associations. The game appears to function like a "Six Degrees of Wikipedia" race but traverses the latent space of a Large Language Model rather than static hyperlinks.

**Comment Highlights:**

*   **Gameplay Strategies:** Users shared widely different routes to solve the day's puzzles.
    *   **Piano $\to$ Volcano:** One user took a geographic route (Piano $\to$ Yamaha $\to$ Japan $\to$ Mt. Fuji $\to$ Volcanoes), while another took a physics/geology route (Piano $\to$ Vibration $\to$ ... $\to$ Plate Tectonics).
    *   **Books $\to$ Rainbow:** A user found a cultural path via Johannes Gutenberg $\to$ Printing Press $\to$ Social Movements $\to$ Pride Flag $\to$ Rainbow.
*   **Creator Insights:** The creator (**jmcllstr**) participated heavily, noting:
    *   The underlying prompts command the LLM to return "distinct Wikipedia-style article titles" and focus on specific named entities rather than abstract descriptions.
    *   Upcoming feature ideas include an "Intersection" action (finding common topics) and a daily leaderboard.
*   **User Experience:** Players described the experience as navigating a "1024-dimensional field" and noted the difficulty of forcing the LLM to make specific jumps (e.g., failing to bridge "Visible Spectrum" directly to "Rainbow").

### My Tamagotchi is an RL agent playing Slither.io

#### [Submission URL](https://nkasmanoff.github.io/#/blog/tamagotchi-rl-slitherio) | 36 points | by [nkaz123](https://news.ycombinator.com/user?id=nkaz123) | [18 comments](https://news.ycombinator.com/item?id=46509307)

*Unable to generate AI summary: Empty discussion summary returned from API*

### Few Shall Return is now gen-AI free

#### [Submission URL](https://www.ballardgames.com/tales/gen-ai-go-away/) | 33 points | by [victorhurdugaci](https://news.ycombinator.com/user?id=victorhurdugaci) | [12 comments](https://news.ycombinator.com/item?id=46508923)

Few Shall Return demo is live — and now AI-free
- Origin story: Two devs started in Nov 2024 aiming for a 2D dungeon extraction game, but asset sourcing stalled progress. They pivoted to 3D using Synty packs to ship a cohesive first build.
- The AI detour: To get their Steam page out, they briefly used AI-generated marketing art (think imperfect sword handles and other telltale artifacts) as stopgaps.
- Big milestone: The latest build is officially AI-free after hiring a dedicated artist who replaced those generated assets with handcrafted work.
- Next phase: They plan to swap every store-bought asset for custom, in-house art to give the game a unique visual identity—ambitious for a small team, but central to their vision.
- Call to action: The demo is live; wishlist on Steam and join their Discord. This post is part of their “Tales of a Small Indie Studio” series.

**Discussion:**

*   **AI as a Placeholder:** Commenters generally validated the developer's workflow, agreeing that Generative AI is acceptable for internal prototypes or temporary assets ("placeholders") as long as they are replaced by human-created work for the final product. One user predicted this will become the standard best practice as the "hype cycle" dies down.
*   **Quality vs. "Slop":** While some users are indifferent to AI use by solo developers for tedious tasks, they warned that over-reliance results in "slop" or generic content. One user cited *Trepang2* as an example where AI-generated in-game text/lore felt boring and valueless, suggesting developers should focus on gameplay rather than filling the world with generated fluff.
*   **Defining "AI-Free":** A debate emerged regarding the definition of "AI-free." Skeptics accused the post of virtue signaling, questioning if the studio also abstained from using LLMs (like Copilot) for coding. They argued that claiming to be AI-free while using AI coding assistants would be hypocritical, though others countered that the label usually applies specifically to visual and audio assets in the public eye.

### Show HN: ccrider - Search and Resume Your Claude Code Sessions – TUI / MCP / CLI

#### [Submission URL](https://github.com/neilberkman/ccrider) | 18 points | by [nberkman](https://news.ycombinator.com/user?id=nberkman) | [4 comments](https://news.ycombinator.com/item?id=46512501)

ccrider: a fast TUI/CLI to search and resume your Claude Code sessions (local, private)

What it is
- A Go-based tool that indexes ~/.claude/projects and makes past Claude Code conversations instantly searchable and resumable.
- Includes a polished terminal UI, a CLI, and an MCP server so Claude itself can query your history.

Why it matters
- Finding that one fix in months of nested JSON logs is painful; ccrider brings full-text search (SQLite FTS5), project/date filters, and one-keystroke resume.
- Claims 100% schema coverage, a single static binary, and real “resume” support—addressing common gaps in other tools.

Highlights
- TUI: browse sessions; / to search; p to filter by current project; r to resume; o to open in a new terminal tab (Ghostty/iTerm/Terminal.app aware).
- CLI search: project and date filters; instant FTS5 results.
- Resume: launches claude --resume in the right directory automatically.
- Incremental sync: imports new messages without reprocessing everything.
- MCP server: lets Claude search/list sessions, fetch details, and tail messages; read-only, stays local.
- Configurable via ~/.config/ccrider (custom resume flags, terminal command, prompt template).

Tech
- Go, SQLite FTS5, Bubbletea TUI; clean core/interface separation.
- MIT-licensed.

Quick start
- brew install neilberkman/tap/ccrider
- ccrider sync
- ccrider tui (or ccrider search "authentication bug")
- Optional: claude mcp add --scope user ccrider $(which ccrider) serve-mcp

Repo: github.com/neilberkman/ccrider

**ccrider: TUI/CLI to search and resume Claude Code sessions**
This Go-based tool indexes your local Claude Code history via SQLite FTS5, providing a fast TUI and CLI to search past conversations and resume them directly. It supports fuzzy filtering, full-text search, and includes an MCP server that allows Claude to query its own session history.

**Hacker News Discussion**
*   **Manual renaming vs. Search:** A user suggested that the existing ability to rename sessions (e.g., `rename api-migration`) makes resumption easy enough without a dedicated tool. The creator acknowledged that renaming helps, but noted it relies on the user remembering to name the session and recalling that name later; `ccrider` solves the problem of searching the entire history for specific content inside sessions, even if they were never renamed or if the name was forgotten.
*   **Installation issues:** A commenter reported that the Homebrew tap link was returning a 404 error; the author thanked them and pushed a fix.

### The skill of the future is not 'AI', but 'Focus' (2025)

#### [Submission URL](https://carette.xyz/posts/focus_will_be_the_skill_of_the_future/) | 65 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [15 comments](https://news.ycombinator.com/item?id=46513728)

The skill of the future isn’t “AI”—it’s focus. This essay argues that while LLMs are powerful copilots for boilerplate, brainstorming, and debugging, they’re trained on solutions to known problems and can mislead on truly novel ones. That shifts the burden of verification back to engineers—and risks atrophying the very problem‑solving muscles we need most.

Key points:
- Tools vs. mastery: LLMs can accelerate work, but blind acceptance turns engineering into answer‑retrieval instead of problem‑solving. Understanding the why behind outputs is essential.
- Exploration vs. exploitation: Search engines encourage both; LLMs default to immediate exploitation, reducing exploratory breadth and increasing instability when answers are wrong.
- The real risk: Under delivery pressure, engineers practice focus less, eroding foundational skills that complex work depends on. Without intentional practice, we drift toward outsourcing ingenuity to “self‑reflecting” AIs.

Takeaway: Use LLMs, but keep humans in the loop—not just to catch errors, but to preserve the habit of deep focus, deliberate exploration, and mastery of fundamentals.

Here is a summary of the discussion:

Commenters engaged with the essay's premise on focus and skill atrophy, broadening the debate to include corporate culture, the definitions of creativity, and the quality of modern software.

*   **The Abstraction Ladder:** Users debated whether skill atrophy is a fatal flaw or just the next step in engineering evolution. While some agreed that relying on pre-solutions hinders the ability to tackle novel challenges, others argued that few engineers actually work on "truly novel" problems, suggesting we are simply moving up the abstraction ladder as we have with previous tools.
*   **Convergent vs. Divergent Thinking:** A distinction was drawn between problem-solving (convergent) and creative thinking (divergent). Participants noted that while LLMs are excellent "housekeeping" tools that free up mental space for problem-solving, they are often uninspiring or detrimental when relied upon for creative brainstorming.
*   **Deep Work vs. Corporate Reality:** The conversation drifted toward Cal Newport’s concept of "Deep Work." Commenters pointed out the irony that valid focus is often undermined by management practices; specifically, "back-to-back meetings" are frequently used as status indicators ("flexing"), preventing the deep focus required to handle the complex work AI leaves behind.
*   **Quality and Ethics:** Skepticism emerged regarding whether AI will improve software quality. Users contrasted the "beautiful system software" of the past (Linux, Git) with modern, user-hostile products filled with dark patterns, fearing AI will only accelerate the latter. One user suggested that behaving ethically is the actual skill of the future.
*   **The "Chemical" Solution:** A cynical sub-thread jokingly (or perhaps not) noted that the industry's current solution for achieving high-level focus relies less on mental discipline and more on stimulants like Adderall.

### OpenAI Must Turn over 20M ChatGPT Logs, Judge Affirms

#### [Submission URL](https://news.bloomberglaw.com/ip-law/openai-must-turn-over-20-million-chatgpt-logs-judge-affirms) | 35 points | by [rvnx](https://news.ycombinator.com/user?id=rvnx) | [4 comments](https://news.ycombinator.com/item?id=46517836)

OpenAI ordered to hand over 20M anonymized ChatGPT logs in AI copyright MDL

- A federal judge in S.D.N.Y. upheld a ruling requiring OpenAI to produce 20 million de-identified ChatGPT logs in consolidated pretrial proceedings spanning 16 copyright suits by content owners. District Judge Sidney H. Stein said Magistrate Judge Ona T. Wang properly weighed privacy concerns against relevance.

- News plaintiffs, including The New York Times and Chicago Tribune, first sought 120 million logs. OpenAI offered a 20 million sample (about 0.5% of preserved logs), then tried to limit production to search hits implicating plaintiffs’ works. The court rejected that, noting there’s no rule requiring the “least burdensome” discovery.

- The court distinguished a Second Circuit case restricting SEC call-recording discovery, emphasizing that ChatGPT users submitted communications voluntarily and OpenAI’s ownership of the logs is uncontested.

- Case: In re: OpenAI, Inc. Copyright Infringement Litigation, S.D.N.Y., No. 1:25-md-03143; order issued 1/5/26. Counsel for plaintiffs: Susman Godfrey, Rothwell Figg, Loevy & Loevy; for OpenAI: Keker Van Nest & Peters, Latham & Watkins, Morrison & Foerster.

Why it matters: Broad discovery into chat logs could reveal how models interact with copyrighted works, shaping future AI liability. It also raises stakes around logging and data-retention policies—even with anonymization—as courts signal willingness to compel expansive production in AI cases.

Commenters expressed concern regarding the security implications of the order, noting that state actors, AI competitors, and criminals would be eager to access a "dump" of 20 million logs. The discussion also criticized the legal basis of the decision; users argued the "third-party doctrine" is a mistake that allows government agencies to bypass Fourth Amendment protections by obtaining information from companies, a precedent described by one as a "travesty."

