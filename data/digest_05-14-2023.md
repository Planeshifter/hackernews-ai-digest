## AI Submissions for Sun May 14 2023 {{ 'date': '2023-05-14T17:10:07.377Z' }}

### Attempto Controlled English

#### [Submission URL](https://en.wikipedia.org/wiki/Attempto_Controlled_English) | 93 points | by [sublinear](https://news.ycombinator.com/user?id=sublinear) | [65 comments](https://news.ycombinator.com/item?id=35936396)

Attempto Controlled English (ACE) is a controlled natural language developed at the University of Zurich, which uses a subset of standard English with a restricted syntax and semantics. ACE serves as a knowledge representation, specification, and query language intended for professionals who want to use formal methods but may not be familiar with them. It has been used in various fields, such as software specifications, theorem proving, querying, medical documentation and planning. ACE texts are coherent sequences of anaphorically linked sentences, and can be translated into other formal languages for reasoning and validation. ACE version 6.7 was announced in 2013, and the vocabulary includes predefined function words, phrases, and content words, with a grammar expressed through construction and interpretation rules.

The discussion includes comparisons to other simplified or controlled versions of English and some considerations about how the English language has evolved and its inherent inconsistencies. Some argue that ACE could be a solution to these inconsistencies, while others are critical of the idea of artificially simplifying language. There is also mention of related projects and resources, such as Simple English Wikipedia and Thing Explainer. However, some participants expressed doubts about the effectiveness of these simplified approaches.

### Open-Llama: Complete training pipeline for building large language models

#### [Submission URL](https://github.com/s-JoL/Open-Llama) | 136 points | by [bayes-song](https://news.ycombinator.com/user?id=bayes-song) | [11 comments](https://news.ycombinator.com/item?id=35934458)

Open-Llama is an open-source project that offers a complete training pipeline for building large language models, ranging from dataset preparation to tokenization, pre-training, prompt tuning, lora, and the reinforcement learning technique RLHF. The model has recently been updated to version 2.1, which includes support for larger model training using DeepSpeed stage3 + offload + activation checkpoint, with the ability to train a 65B model with A100-80G. The model's training speed has been optimized, with the latest version reaching a speed of 3587 tokens/s, faster than the 3370 tokens/s reported in the original Llama paper, reaching the current state-of-the-art level.

Discussions include namespace collisions in the LLM space and the potential advantages of returning a model versus an API in machine learning. Additionally, there is a conversation on the cost of hardware and delivery services needed to run ML models, the accessibility of fast hardware and processors, and the potential for greater privacy in web browsers.

### Attention with Linear Biases (ALiBi)

#### [Submission URL](https://arxiv.org/abs/2108.12409) | 57 points | by [pmoriarty](https://news.ycombinator.com/user?id=pmoriarty) | [12 comments](https://news.ycombinator.com/item?id=35934700)

A team of researchers has introduced a new method called Attention with Linear Biases (ALiBi) to enable input length extrapolation in transformer models. While previous methods allowed for extrapolation by changing the position representation method, they were found to lack efficiency required for practical use. ALiBi biases query-key attention scores with a penalty that is proportional to their distance, and does not add positional embeddings to word embeddings. The researchers showed that ALiBi trains a 1.3 billion parameter model on input sequences of length 1024 that can extrapolate to input sequences of length 2048, achieving the same perplexity as a sinusoidal position embedding model trained on inputs of length 2048 but in less time and using less memory. ALiBi's inductive bias towards recency also led it to outperform multiple strong position methods on the WikiText-103 benchmark.

The discussion around the submission focuses on the proposed ALiBi method and how it compares to previous methods, such as positional embeddings, for handling input length extrapolation in transformer models. Some users express their understanding of the ALiBi method and its advantages over previous approaches, while others point out similarities and differences between ALiBi and other methods like sinusoidal position embeddings and relative positional encoding. There is also some discussion around the technical details of the paper, such as the use of linear biases in attention scores and the specific benchmarks used for evaluation. One user requests clarification on the use of the "sffx" (suffix) in the context of natural language sentences and positional encoding.

### 47% of all internet traffic came from bots in 2022?

#### [Submission URL](https://www.securitymagazine.com/articles/99339-47-of-all-internet-traffic-came-from-bots-in-2022) | 226 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [141 comments](https://news.ycombinator.com/item?id=35938433)

A report by Imperva has revealed that 47.4% of all internet traffic in 2022 came from bots, representing a 5.1% increase from the previous year. The study, Imperva’s 10th annual Bad Bot Report, outlined how bad bot traffic accounted for 30.2% of all automated traffic across the internet, marking a 2.5% increase over 2021. Additionally, 15% of all login attempts in the past 12 months were labelled account takeover, with gaming and telecoms industries experiencing the highest proportion of bad bot traffic on their websites and applications.

The discussion on this Hacker News thread revolves around various topics related to web scraping, search engines, and the sharing and preservation of knowledge online. Some users mention their experiences with bots and the challenges of blocking them, while others discuss the implications of web archiving and the importance of preserving knowledge for future generations. There are also debates about the value of forums and communities, and the role of individuals and businesses in contributing to the greater good.

### Show HN: Smol Developer – Human-Centric and Coherent Whole Program Synthesis

#### [Submission URL](https://github.com/smol-ai/developer) | 19 points | by [swyx](https://news.ycombinator.com/user?id=swyx) | [6 comments](https://news.ycombinator.com/item?id=35942352)

Smol AI has unveiled a prototype 'junior developer', which helps scaffold an entire codebase once a product spec has been given. The AI, which has been dubbed 'smol dev', is designed to make AI that is helpful, harmless, and honest. Smol dev complements a simple, safe, and small codebase of less than 200 lines of Python and Prompts and can help developers with tasks such as adding to a prompt, manually running the code and identifying errors, and making specific code change suggestions. The AI is only used as long as it is adding value, and then the developer can take over the codebase without fuss or hurt feelings.

A few people in the comments discuss the technical aspects of the AI, including some potential limitations regarding dependency libraries and speed. Additionally, another user shares their experience of using a teaching AI for Chrome extensions, sharing tips on how to approach learning program synthesis. Finally, one commenter expresses their gratitude towards the creators of smol dev.

### What does a leaked Google memo reveal about the future of AI?

#### [Submission URL](https://www.economist.com/leaders/2023/05/11/what-does-a-leaked-google-memo-reveal-about-the-future-of-ai) | 90 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [48 comments](https://news.ycombinator.com/item?id=35936489)

A leaked memo from within Google titled "We have no moat" reveals surprising developments in the field of artificial intelligence (AI). Contrary to past assumptions that AI would be dominated by a few deep-pocketed firms, researchers in the open-source community are now achieving comparable results to the biggest proprietary models using free online resources. By using a technique called low-rank adaption (LoRa), existing models can now be fine-tuned for specific tasks far more quickly and cheaply than training from scratch. This means that anyone can fine-tune their own AI quickly and affordably, opening up the technology and making monopolistic control by a handful of companies far less likely. However, easier access to AI also raises concerns about bad actors using the technology for nefarious purposes, making regulation more challenging.

Commenters point out that while this democratizes AI technology, it could also empower bad actors. The discussion also touches on the importance of Google, with some emphasizing the number of employees and the impact of the company's developments on the industry. Others argue that we should not inflate the hype around AI, and that the impact of AI should be measured in specific tasks. There is also discussion on the difficulty of open-source participation in AI for business, as well as the specific strengths and limitations of different models produced by Google, OpenAI, and other entities in the field.

