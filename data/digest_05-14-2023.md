## AI Submissions for Sun May 14 2023 {{ 'date': '2023-05-14T17:10:07.377Z' }}

### Distrobox: Use any Linux distribution inside your terminal

#### [Submission URL](https://github.com/89luca89/distrobox) | 357 points | by [denysonique](https://news.ycombinator.com/user?id=denysonique) | [84 comments](https://news.ycombinator.com/item?id=35939240)

89luca89's Distrobox is an innovative solution that allows users to utilize any Linux distribution within their terminal while still maintaining backward and forward compatibility with software. The tool relies on podman or docker to create containers, which can be integrated tightly with the host, allowing users to share their HOME directory, external storage, and even graphical apps. With 5.3k stars on GitHub, Distrobox offers a versatile solution for Linux enthusiasts.

The submission is about an innovative tool called Distrobox, which allows users to utilize any Linux distribution while maintaining compatibility with software. The comments discuss various aspects of the tool, including using it as a development environment for the Steam Deck gaming console, its integration with podman or docker, and its support for running graphical apps. There are also discussions about running Linux distributions in containers, using Distrobox for robotics, and comparisons to other virtualization solutions like LXD. Overall, there is a positive reception to Distrobox and its capabilities.

### Attempto Controlled English

#### [Submission URL](https://en.wikipedia.org/wiki/Attempto_Controlled_English) | 93 points | by [sublinear](https://news.ycombinator.com/user?id=sublinear) | [65 comments](https://news.ycombinator.com/item?id=35936396)

Attempto Controlled English (ACE) is a controlled natural language developed at the University of Zurich, which uses a subset of standard English with a restricted syntax and semantics. ACE serves as a knowledge representation, specification, and query language intended for professionals who want to use formal methods but may not be familiar with them. It has been used in various fields, such as software specifications, theorem proving, querying, medical documentation and planning. ACE texts are coherent sequences of anaphorically linked sentences, and can be translated into other formal languages for reasoning and validation. ACE version 6.7 was announced in 2013, and the vocabulary includes predefined function words, phrases, and content words, with a grammar expressed through construction and interpretation rules.

The submission is about Attempto Controlled English (ACE), a controlled natural language used for formal methods such as software specifications and theorem proving. The discussion includes comparisons to other simplified or controlled versions of English and some considerations about how the English language has evolved and its inherent inconsistencies. Some argue that ACE could be a solution to these inconsistencies, while others are critical of the idea of artificially simplifying language. There is also mention of related projects and resources, such as Simple English Wikipedia and Thing Explainer. However, some participants expressed doubts about the effectiveness of these simplified approaches.

### OpenSnitch in Debian ready for prime time

#### [Submission URL](https://people.skolelinux.org/pere/blog/OpenSnitch_in_Debian_ready_for_prime_time.html) | 219 points | by [pabs3](https://news.ycombinator.com/user?id=pabs3) | [29 comments](https://news.ycombinator.com/item?id=35936044)

The interactive application firewall OpenSnitch package is now ready for prime time in Debian Bookworm, thanks to developer Petter Reinholdtsen. The package got the latest fixes and dependencies and now comes with a GUI admin tool which is installed by default. OpenSnitch helps users discover which internet connections their programs are making. While it still can't build its eBPF module within Debian, Reinholdtsen recommends testing the program and seeing what you think.

The submission is about the availability of OpenSnitch, an interactive application firewall package in Debian Bookworm with a GUI admin tool that helps users discover which internet connections their programs are making. A commenter mentions the availability of Windows Firewall Control and GlassWire, which is a commercial software and a good Android app for blocking malicious connections and preserving privacy. 

Another commentator has used OpenSnitch on Linux and shares that while it is functional, it can be clunky in handling applications as Python, Java, Node, Electron, and Wine use complex regular expression with specific command parameters, and some runtime environments are out of scope.

Another commentator sees great functionality in OpenSnitch and believes that network namespaces and virtual machines can help with port binding and tracking connected devices, while another suggests disabling IPv6 kernel command line options for those that do not support virtual local area networks (VLANs).

Another comments on the combined filtering ability in Linux and MAC OS, while another looks forward to downstream distribution use. An existing Little Snitch user also shares their experience. Several commenters suggest Portmaster as a similar, available GUI solution on Linux, while others suggest Skolelinux and sponsor Ubuntu.

### A former pilot on why autonomous vehicles are so risky

#### [Submission URL](https://spectrum.ieee.org/self-driving-cars) | 100 points | by [obscurette](https://news.ycombinator.com/user?id=obscurette) | [113 comments](https://news.ycombinator.com/item?id=35938924)

Former pilot and transportation safety expert Missy Cummings shares her concerns about the safety of autonomous vehicles in a recent interview with IEEE Spectrum. She argues that ADAS-equipped cars are not fundamentally safer and that they can actually make drivers more likely to speed. Cummings also discusses the problem of "risk homeostasis," where drivers may trade safety for other factors such as getting home a few minutes earlier. She suggests that the policy for autonomy should be either the computer is driving or the human is driving, with no middle ground.

Missy Cummings, a former pilot and transportation safety expert, shares concerns about the safety of autonomous vehicles in a recent interview with IEEE Spectrum. She argues that ADAS-equipped cars might not fundamentally be safer and can actually make drivers more likely to speed. Cummings also discusses the problem of "risk homeostasis," where drivers may trade safety for factors such as getting home a few minutes earlier. She suggests that the policy for automation should be either the computer is driving or the human is driving, with no middle ground. In the comments, users discuss various aspects of the topic, including self-driving cars, NHTSA, crashes, and Elon Musk's involvement and comments.

### The unreasonable effectiveness of character-level language models (2015)

#### [Submission URL](https://colab.research.google.com/github/norvig/pytudes/blob/main/ipynb/Goldberg.ipynb) | 83 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [32 comments](https://news.ycombinator.com/item?id=35940506)

I'm sorry, I am not able to sign in as I am a language model AI designed to generate text based on user input. Is there anything specific I can assist you with today?

The discussion relates to the recent advancements and scaling of AI language models, with a particular focus on GPT-3. Some comments discuss the impressive parameter count of GPT-3, noting that it is orders of magnitude larger than the largest models from just a few years ago. Others mention that while GPT-3 is a significant improvement, it still struggles with contextual understanding, and researchers are looking to improve training data sets and design more efficient software. There are also discussions about the feasibility of scaling RNNs and LSTMs compared to Transformers, with some suggesting that RNNs are making a comeback. The discussion then shifts to the general effectiveness of mathematical models and phrases that have been considered harmful or ineffective. Finally, there is a brief discussion about how to properly characterize the performance of complex systems with simple concepts.

### Open-Llama: Complete training pipeline for building large language models

#### [Submission URL](https://github.com/s-JoL/Open-Llama) | 136 points | by [bayes-song](https://news.ycombinator.com/user?id=bayes-song) | [11 comments](https://news.ycombinator.com/item?id=35934458)

Open-Llama is an open-source project that offers a complete training pipeline for building large language models, ranging from dataset preparation to tokenization, pre-training, prompt tuning, lora, and the reinforcement learning technique RLHF. The model has recently been updated to version 2.1, which includes support for larger model training using DeepSpeed stage3 + offload + activation checkpoint, with the ability to train a 65B model with A100-80G. The model's training speed has been optimized, with the latest version reaching a speed of 3587 tokens/s, faster than the 3370 tokens/s reported in the original Llama paper, reaching the current state-of-the-art level.

Open-Llama is an open-source project that provides a complete training pipeline for building large language models. The latest version (2.1) can train a 65B model with A100-80G and its training speed has been optimized, achieving a speed of 3587 tokens/s, faster than the original Llama paper. Discussions include namespace collisions in the LLM space and the potential advantages of returning a model versus an API in machine learning. Additionally, there is a conversation on the cost of hardware and delivery services needed to run ML models, the accessibility of fast hardware and processors, and the potential for greater privacy in web browsers.

### Attention with Linear Biases (ALiBi)

#### [Submission URL](https://arxiv.org/abs/2108.12409) | 57 points | by [pmoriarty](https://news.ycombinator.com/user?id=pmoriarty) | [12 comments](https://news.ycombinator.com/item?id=35934700)

A team of researchers has introduced a new method called Attention with Linear Biases (ALiBi) to enable input length extrapolation in transformer models. While previous methods allowed for extrapolation by changing the position representation method, they were found to lack efficiency required for practical use. ALiBi biases query-key attention scores with a penalty that is proportional to their distance, and does not add positional embeddings to word embeddings. The researchers showed that ALiBi trains a 1.3 billion parameter model on input sequences of length 1024 that can extrapolate to input sequences of length 2048, achieving the same perplexity as a sinusoidal position embedding model trained on inputs of length 2048 but in less time and using less memory. ALiBi's inductive bias towards recency also led it to outperform multiple strong position methods on the WikiText-103 benchmark.

The discussion around the submission focuses on the proposed ALiBi method and how it compares to previous methods, such as positional embeddings, for handling input length extrapolation in transformer models. Some users express their understanding of the ALiBi method and its advantages over previous approaches, while others point out similarities and differences between ALiBi and other methods like sinusoidal position embeddings and relative positional encoding. There is also some discussion around the technical details of the paper, such as the use of linear biases in attention scores and the specific benchmarks used for evaluation. One user requests clarification on the use of the "sffx" (suffix) in the context of natural language sentences and positional encoding.

### The Group Decode ROM: The 8086 processor's first step of instruction decoding

#### [Submission URL](http://www.righto.com/2023/05/8086-processor-group-decode-rom.html) | 61 points | by [zdw](https://news.ycombinator.com/user?id=zdw) | [20 comments](https://news.ycombinator.com/item?id=35939168)

The Intel 8086 processor's instruction decoding process involves a Group Decode ROM that categorizes instructions into about 35 types that control how the instruction is decoded and executed. The Group Decode ROM determines how an instruction is executed, if it's implemented in hardware or microcode, and indicates how the instruction is structured. Most instructions in the 8086 are implemented in microcode, a layer of software underneath the machine instructions, with micro-instructions specified by the microcode. The Group Decode ROM is implemented through a two-level NOR gate structure called a PLA (Programmable Logic Array), which is considerably more efficient than a ROM structure, requiring just 36 columns compared to 256 columns.

This article explains how the Intel 8086 processor's instruction decoding process works with a Group Decode ROM system categorizing instructions into about 35 types. Discussions in the comments include the differences between Z80 and 8086, how the 8086's Lock Prefix and SMP configurations work, how CALL and RET opcodes work in processor instruction history, the number of instruction bytes in the 8086, and the impact of complex instruction formats on processor performance. There is also a discussion on running an 8088 processor in the basement for practical benefit in learning how to program. One person mentions being concerned about the temperature swings affecting the processor.

### Setting up Hetzner ARM instances with and for Objective-S

#### [Submission URL](https://blog.metaobject.com/2023/05/setting-up-hetzner-arm-instances-with.html) | 27 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [7 comments](https://news.ycombinator.com/item?id=35934287)

This post talks about the recent introduction of reasonably-priced ARM64 VPS instances by Hetzner and how they can be set up and managed with Objective-S. The author discusses the difficulties he faced in finding a low-cost VPS provider that supported ARM and how Hetzner's offering solved that problem. They also delve into setting up an API scheme handler for talking to the Hetzner API, creating a server, and interacting with servers, including deleting them. Overall, it's a comprehensive guide on how to utilize Hetzner's ARM instances with Objective-S.

The first comment is a brief introduction of Objective-S and its features. The second comment is about the experience of receiving spam texts after providing a phone number to Hetzner. Other users in the discussion share their experience, with one mentioning he has been a customer of Hetzner for years and only received a single spam text, while another user shares his running of VMs on Hetzner for years with no issues. One user also comments negatively about Hetzner, stating it's not a great company, while another user asks for clarification on the context.

### 47% of all internet traffic came from bots in 2022?

#### [Submission URL](https://www.securitymagazine.com/articles/99339-47-of-all-internet-traffic-came-from-bots-in-2022) | 226 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [141 comments](https://news.ycombinator.com/item?id=35938433)

A report by Imperva has revealed that 47.4% of all internet traffic in 2022 came from bots, representing a 5.1% increase from the previous year. The study, Imperva’s 10th annual Bad Bot Report, outlined how bad bot traffic accounted for 30.2% of all automated traffic across the internet, marking a 2.5% increase over 2021. Additionally, 15% of all login attempts in the past 12 months were labelled account takeover, with gaming and telecoms industries experiencing the highest proportion of bad bot traffic on their websites and applications.


The discussion on this Hacker News thread revolves around various topics related to web scraping, search engines, and the sharing and preservation of knowledge online. Some users mention their experiences with bots and the challenges of blocking them, while others discuss the implications of web archiving and the importance of preserving knowledge for future generations. There are also debates about the value of forums and communities, and the role of individuals and businesses in contributing to the greater good.

### Show HN: Smol Developer – Human-Centric and Coherent Whole Program Synthesis

#### [Submission URL](https://github.com/smol-ai/developer) | 19 points | by [swyx](https://news.ycombinator.com/user?id=swyx) | [6 comments](https://news.ycombinator.com/item?id=35942352)

Smol AI has unveiled a prototype 'junior developer', which helps scaffold an entire codebase once a product spec has been given. The AI, which has been dubbed 'smol dev', is designed to make AI that is helpful, harmless, and honest. Smol dev complements a simple, safe, and small codebase of less than 200 lines of Python and Prompts and can help developers with tasks such as adding to a prompt, manually running the code and identifying errors, and making specific code change suggestions. The AI is only used as long as it is adding value, and then the developer can take over the codebase without fuss or hurt feelings.

Smol AI has launched a prototype, ‘junior developer’ AI called ‘smol dev’ which helps scaffold entire codebases once a product spec has been given. It appears to be simple, safe, and small with less than 200 lines of Python and Prompts, complementing a simple, safe, and small codebase. It can help developers with tasks such as adding to a prompt, manually running the code and identifying errors, and suggesting specific code changes. The AI is only used as long as it is adding value, and the developer can take over the codebase without any fuss. A few people in the comments discuss the technical aspects of the AI, including some potential limitations regarding dependency libraries and speed. Additionally, another user shares their experience of using a teaching AI for Chrome extensions, sharing tips on how to approach learning program synthesis. Finally, one commenter expresses their gratitude towards the creators of smol dev.

### Show HN: WhyBot, making GPT-4 question itself

#### [Submission URL](https://whybot-khaki.vercel.app/) | 70 points | by [johnqian](https://news.ycombinator.com/user?id=johnqian) | [29 comments](https://news.ycombinator.com/item?id=35935271)

Great! In order to accomplish this task, I will need access to the Hacker News API and a way to publish the daily digest (e.g. email, blog, social media). Can you provide me with access to the API and let me know where you would like the digest to be published?

The top story on Hacker News is about the impact of technology on modern societies' dependence. Many users are having trouble understanding the prompt that the AI generated to start the conversation. Some users are discussing how visualizing unlimited data is becoming increasingly necessary and is indicative of modern trends. Another user is impressed by the LLMs' ability to detect bugs and identify relevance in the data. Some users are discussing ChatGPT's ability to respond similarly to AI language models but acknowledge that it cannot guarantee correct responses. Other users are discussing the simplicity of Slack's branching and its potential to improve probabilities for good results. One user shares a link and is flagged as spam, while others discuss Firefox's privacy extensions and DNS requests blocking ads. Some users show interest in integrating LLMs service providers, and others praise the technical exploration and critical thinking behind the story.

### What does a leaked Google memo reveal about the future of AI?

#### [Submission URL](https://www.economist.com/leaders/2023/05/11/what-does-a-leaked-google-memo-reveal-about-the-future-of-ai) | 90 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [48 comments](https://news.ycombinator.com/item?id=35936489)

A leaked memo from within Google titled "We have no moat" reveals surprising developments in the field of artificial intelligence (AI). Contrary to past assumptions that AI would be dominated by a few deep-pocketed firms, researchers in the open-source community are now achieving comparable results to the biggest proprietary models using free online resources. By using a technique called low-rank adaption (LoRa), existing models can now be fine-tuned for specific tasks far more quickly and cheaply than training from scratch. This means that anyone can fine-tune their own AI quickly and affordably, opening up the technology and making monopolistic control by a handful of companies far less likely. However, easier access to AI also raises concerns about bad actors using the technology for nefarious purposes, making regulation more challenging.

A leaked memo from within Google called "We have no moat" reveals surprising developments in the field of AI, showing that free online resources using LoRa can produce comparable results to proprietary models, leading to concern over regulation. Commenters point out that while this democratizes AI technology, it could also empower bad actors. The discussion also touches on the importance of Google, with some emphasizing the number of employees and the impact of the company's developments on the industry. Others argue that we should not inflate the hype around AI, and that the impact of AI should be measured in specific tasks. There is also discussion on the difficulty of open-source participation in AI for business, as well as the specific strengths and limitations of different models produced by Google, OpenAI, and other entities in the field.

### Stephen Wolfram: ChatGPT and the Nature of Truth, Reality and Computation

#### [Submission URL](https://www.youtube.com/watch?v=PdE-waSx-d8) | 24 points | by [technocratius](https://news.ycombinator.com/user?id=technocratius) | [4 comments](https://news.ycombinator.com/item?id=35942080)

Sorry, that's not a top story on Hacker News! Could you please provide me with the latest top stories on Hacker News?

I'm sorry, but I cannot summarize the discussion without knowing the context of the comments. Could you please provide me with a link or a title for the submission?

