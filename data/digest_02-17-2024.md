## AI Submissions for Sat Feb 17 2024 {{ 'date': '2024-02-17T17:10:38.171Z' }}

### OS-Copilot: Towards Generalist Computer Agents with Self-Improvement

#### [Submission URL](https://os-copilot.github.io/) | 167 points | by [lokimedes](https://news.ycombinator.com/user?id=lokimedes) | [39 comments](https://news.ycombinator.com/item?id=39413215)

Today's top story on Hacker News is about a groundbreaking research paper titled "OS-Copilot: Towards Generalist Computer Agents with Self-Improvement." The paper introduces a framework called OS-Copilot which aims to build generalist computer agents that can interact with various elements in an operating system, including web interfaces, code terminals, files, multimedia, and third-party applications.

The framework is used to create FRIDAY, a self-improving embodied agent that automates general computer tasks. FRIDAY outperforms previous methods on a benchmark for general AI assistants, showcasing strong generalization to unseen applications. The paper presents evidence that FRIDAY learns to control and self-improve on tasks like Excel and Powerpoint with minimal supervision.

The OS-Copilot framework consists of three main components: the planner, configurator, and actor. The planner reasons over user requests and decomposes complex tasks, the configurator configures subtasks for the actor, and the actor executes actions and learns from feedback.

FRIDAY's design principle focuses on self-refinement and self-directed learning, allowing it to acquire proficiency in controlling unfamiliar applications. The system uses dense retrieval to recall relevant information, generates new tools as needed, and iterates through executing, evaluating, and refining tasks until completion.

Overall, this research opens up new possibilities for building versatile computer agents with self-improvement capabilities, paving the way for more capable and general-purpose digital assistants.

The discussion on Hacker News regarding the groundbreaking research paper on "OS-Copilot: Towards Generalist Computer Agents with Self-Improvement" covers a range of topics and opinions.

1. **Robotic Process Automation (RPA) Impact**: There is a discussion about the impact of RPA products in the market, with mentions of using PowerShell and REST interfaces in ServiceNow ticketing systems. Some users express concerns about the limitations of RPA in controlling ServiceNow UI.

2. **Addition of AI to RPA**: The conversation expands to discuss the integration of AI with RPA, with some users considering RPA as one layer versus AI as another. There is a debate about whether AI and RPA can coexist or if AI could potentially replace RPA in the future.

3. **Embodiment in General AI**: A user critiques the use of the term "Embodiment" in the paper, linking it to cognitive science and embodied mind theories. There are discussions about the cognitive aspects of embodiment and its relevance to AI research.

4. **Speculation on Technological Progress**: Users speculate on the future of AI development, with mentions of AI surpassing human capabilities and advancements in technology like sensors. There are also references to OpenAI's development and the potential emergence of AGI.

5. **Comparisons and Predictions**: Comparisons are drawn between GPT-4 and OS-Copilot, with users discussing the capabilities and potential limitations of different AI models. Some express interest in seeing how OS-Copilot compares to GPT-4.

6. **Practical Application Issues**: Users raise practical concerns about using tools like ChatGPT Copilot for scripting tasks, citing challenges in interacting with APIs that may not exist or in handling logging efficiently.

Overall, the discussion touches upon various aspects of AI technology, its applications in RPA, theoretical considerations, and future implications for AI development.

### Code for the Byte Pair Encoding algorithm, commonly used in LLM tokenization

#### [Submission URL](https://github.com/karpathy/minbpe) | 66 points | by [magoghm](https://news.ycombinator.com/user?id=magoghm) | [21 comments](https://news.ycombinator.com/item?id=39407407)

The repository "minbpe" by karpathy provides minimal and clean code for the Byte Pair Encoding (BPE) algorithm, commonly used in Large Language Models (LLMs) tokenization. The BPE algorithm operates at the byte level on UTF-8 encoded strings and has been popularized by papers like GPT-2 and GPT-4 for training tokenizers. 

The repository includes two tokenizers: BasicTokenizer and RegexTokenizer, with RegexTokenizer extending the text splitting by categories before tokenization approach. There's also a GPT4Tokenizer that replicates tokenization in GPT-4. The provided `train.py` script demonstrates training the tokenizers on input text and saving the vocabulary for visualization. 

Usage examples are given in the code files, showcasing how to train, encode, and decode text using the implemented tokenizers. There are future plans to optimize the Python version for handling large files, potentially create a C or Rust version, and explore adding support for GPT-2 with a renamed tokenizer. Additionally, there is a plan to create a LlamaTokenizer inspired by SentencePiece and handle special tokens.

This repository is licensed under the MIT license and has garnered attention with 1.9k stars and 78 forks on GitHub.

- **krpthy** highlighted that there is a feedback loop in the development process of the project "minbpe," expressing anticipation for its improved version. They also mentioned encountering a few issues with the code, specifically in the merging function, expressing their interest in forthcoming updates.

- **nnd** shared Karpathy's insightful post on tokenization and referred to an Excel tutorial on Byte Pair Encoding (BPE).

- **thsz** noticed an incorrect count parsing issue in the code and compared their BPE implementation process to the complexities of the actual algorithm.

- **gzer0** proposed a solution for correcting counts in the code and explained the logic behind it. They clarified the skipping of certain elements in a sequence for effective scenarios.

- **jrpnt** commended the project's implementation related to Large Language Models (LLM) and suggested that the resulting vocabulary may differ slightly for strict correctness.

- **samarthr1** discussed the encoding reductions in languages based on phonetic syllables and reductions in space and character encoding, pointing out the public disclosure of the project's license.

- **lfthrsr** provided insights into the specialization of Byte Pair Encoding (BPE) as a compression scheme and related it to direct modeling of language grammars.

- **tmn** humorously mentioned that Karpathy's efforts might aim to make people happy in a world full of technical content.

- **dkjdyq** jokingly stated that the world benefits from Karpathy's unemployment, suggesting that OpenAI researchers closely follow his steps.

- **jszymbrsk** recalled an algorithm that introduces subword regularization to enhance word-like content.

- **countWSS** questioned the introduction of hidden biases towards word-like content in deep learning models, potentially impacting the quality of tokenization. Responding, **thtgysgy** pointed out that similarities exist in the behavior of language models like GPT-1 due to intentional design features.

- **15457345234** found parallels between Japanese and Korean language systems, noting similarities in the expression of syllables and complex characters.

Overall, the discussion involved technical feedback, insights into language encoding, comparisons with existing algorithms, and reflections on the implications of language modeling practices.

### So long, and thanks for all the bytes

#### [Submission URL](https://chethaase.medium.com/so-long-and-thanks-for-all-the-bytes-02a4ef972f65) | 337 points | by [ckue](https://news.ycombinator.com/user?id=ckue) | [134 comments](https://news.ycombinator.com/item?id=39409535)

Chet Haase bids farewell to Google and the tech world after a successful 14-year journey, choosing to pursue comedy screenwriting in grad school. Despite the financial sacrifice, his passion for comedy drives this bold career shift. Reflecting on his time in Android, Chet reminisces about the platform's growth and the joy of contributing to its evolution. As he embarks on this new chapter, he leaves with gratitude and excitement for what the future holds, ready to embrace the unpredictability of life beyond tech.

The discussion revolves around Chet Haase's departure from Google after 14 years and his venture into comedy screenwriting. Users reminisce about their time working on Android, highlighting its technical achievements and growth. Some discuss the challenges and intricacies of building operating systems, drawing parallels with other tech endeavors. The conversation also touches on software development methodologies, the importance of focused teams, and reflections on the tech industry as a whole. Chet's storytelling skills and notable presentations are acknowledged, with references to related talks and projects. Additionally, there is a broader discussion on career paths, personal fulfillment, and the evolving landscape of the tech industry, with varying perspectives on the impact of technology on individuals' lives.

### Automated Unit Test Improvement Using Large Language Models at Meta

#### [Submission URL](https://arxiv.org/abs/2402.09171) | 287 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [180 comments](https://news.ycombinator.com/item?id=39405996)

The paper titled "Automated Unit Test Improvement using Large Language Models at Meta" introduces Meta's TestGen-LLM tool, showcasing how it leverages LLMs to enhance existing human-written tests. This innovative approach ensures that the generated test classes surpass specific filters, enhancing the original test suite without falling into LLM hallucination pitfalls. The successful deployment of TestGen-LLM at Meta test-a-thons for Instagram and Facebook platforms highlights significant improvements in test case building, reliability, and coverage. With an 11.5% enhancement rate and 73% recommendation acceptance for production deployment by Meta software engineers, this marks a pioneering industrial-scale implementation of LLM-generated code for code enhancement.

The discussion on the Hacker News submission centers around various aspects of software testing and quality assurance. 
- One user talks about the challenges faced when trying to improve test coverage in legacy codebases and the importance of having experienced programmers handle test-related tasks effectively.
- Another user discusses the efforts being made in trying to make computers intelligent and the limitations in achieving true artificial intelligence.
- The conversation delves into the topic of business apathy towards focusing on complex metrics rather than solving real-world problems.
- The debate about the significance of magic numbers in code arises, with some users emphasizing the importance of clear and meaningful naming conventions for constants.
- Users share different perspectives on the use of magic numbers in code and the potential confusion they can cause, especially in mathematical contexts.
- The concept of mutation testing, its benefits in detecting faults, and the challenges of implementing it in large Java projects are also discussed.
- There is mention of the struggles faced when dealing with automated quality tools like Sonar and the tension between developers and management regarding code quality priorities and adherence to best practices.
- Additionally, the conversation touches upon the strategies and tools available for mutation testing in software development and ways to improve test efficiency and speed. 
Overall, the discussion showcases a diverse range of opinions and insights into the complexities of modern software development practices.

### I worry our Copilot is leaving some passengers behind

#### [Submission URL](https://joshcollinsworth.com/blog/copilot) | 232 points | by [headalgorithm](https://news.ycombinator.com/user?id=headalgorithm) | [130 comments](https://news.ycombinator.com/item?id=39411912)

In a recent blog post, the author expresses concerns about AI coding tools like GitHub Copilot and their impact on code quality and accessibility, especially in web development. While acknowledging the time-saving benefits of Copilot, the author worries that the tool might inadvertently worsen accessibility on the web by generating code that is not properly optimized for all users.

The post highlights instances where Copilot's suggestions were far from ideal, including the comical recommendation of starting components with excessive nested divs. Despite the humor in these situations, the author raises a more serious issue regarding the potential negative effects of relying too heavily on AI-generated code.

By sharing a personal experience of creating a simple footnote component in Svelte, the author demonstrates how Copilot's suggestions may not always align with best practices or accessibility standards. This example serves as a cautionary tale about the importance of critically evaluating AI-generated code and considering its broader implications for inclusive web development.

The discussion on the Hacker News submission revolves around the concerns raised by the author regarding AI coding tools like GitHub Copilot and their potential impact on code quality and accessibility in web development. 

Several users engage in a nuanced conversation about the efficiency of code writing versus time required, with references to the "ninety-ninety" rule and discussions about the challenges and benefits of using AI-generated code. Furthermore, there are reflections on the implications of relying heavily on AI assistants during coding interviews and the need for developers to critically evaluate the code suggestions provided by such tools. 

The conversation also touches on issues related to software development practices, the importance of understanding underlying concepts rather than blindly copying code, and the potential risks of overreliance on AI tools in coding tasks. Users share experiences and insights on the balance between efficiency and understanding in coding, emphasizing the significance of mindful coding practices and critical thinking in inclusive web development.

### Replicate vs. Fly GPU cold-start latency

#### [Submission URL](https://venki.dev/notes/replicate-vs-fly) | 86 points | by [venkii](https://news.ycombinator.com/user?id=venkii) | [31 comments](https://news.ycombinator.com/item?id=39411748)

Today's top story on Hacker News discusses the comparison of cold-start latency between two serverless GPU providers: Replicate and Fly. The author shares their experience using Replicate for setting up embedding models and Fly for hosting, highlighting the importance of minimizing query-time latency for a semantic search engine they are building.

In their testing, the author found that Replicate had significant cold-start latency issues, with machine startup taking about 60 seconds and model inference around 10 seconds, which may not be ideal for a search box scenario. On the other hand, Fly outperformed Replicate in both warm and cold inference times, with a minimum cold boot time of 2 seconds, making it a better option for deploying models in production.

Despite the latency challenges, the author still values Replicate for its open-source and social aspects, which support transforming efforts into public goods. They plan to continue using Replicate for testing various embedding models and building a universal embeddings API. However, when it comes to deploying models in production, the author recommends considering Fly over Replicate for better performance in terms of latency.

1. **bfrsh** from Replicate acknowledges the issue of cold start latency and mentions various optimizations they are implementing to fine-tune the models and reduce latency. They recognize the comparison with Fly and mention that they have optimized weights loading on GPU memory to maintain performance.

2. **rssbkr** raises concerns about Replicate's warm boot numbers compared to Fly, pointing out discrepancies in latency testing results. They suggest that Replicate should address the latency issues and consider pricing strategies like Fly.

3. **tptck** recommends creating a start-stop mechanism for Fly Machines and mentions the importance of optimizing resources. They suggest a JIT approach for on-demand creation of machines instead of holding them idle.

4. **trscncbt** discusses their work in the space of serverless GPU computing and the challenges they face in optimizing ML workloads across various environments. They mention using SquashFS for distributing system-related data efficiently.

5. **hrrsnjcksn** shares their experience in building a predictive model series and highlights the costs and challenges associated with training and inference. They appreciate the ease of use and customization offered by serverless GPUs.

6. **Aeolun** praises the speed of Fly's GPU servers for inference tasks, mentioning quick server boot times and efficient deployment processes.

7. **mrdffs** emphasizes the importance of minimizing cold start times in machine learning deployments and points out the impact of infrastructure on model performance.

8. **msccky** discusses their experience with Replicate, noting long boot times for custom models and considering switching to another platform for better performance. They mention using Beam for model switching and pricing policies for custom models.

9. **jnnycdr** shares a review of Replicate, highlighting concerns about slow startup times and questioning the dependencies causing the delays.

10. **tmnv** mentions downloading large models from HuggingFace on Fly and suggests using multi-stage Dockerfiles to reduce cold boot times.

11. **Szpadel** discusses the differences between single and multi-stage builds in Docker and suggests optimizing the Docker multi-stage build process for faster deployments.

12. **hntsk** expresses satisfaction with fast cold starts of their models using Fly's system.

13. **rkbrn** from Modal discusses the challenges in cold starting containers quickly for GPU-based inference tasks and points out the importance of low-latency and high-throughput workloads in their distributed file system.

14. **iAkashPaul** shares a script for optimizing Docker commands to cache weights and reduce loading times, streamlining the deployment process.

This summary encapsulates the various perspectives and experiences shared by Hacker News users regarding serverless GPU providers Replicate and Fly, focusing on latency optimization and model deployment strategies.

### Visualize Latent Spaces

#### [Submission URL](https://github.com/enjalot/latent-scope) | 105 points | by [skadamat](https://news.ycombinator.com/user?id=skadamat) | [23 comments](https://news.ycombinator.com/item?id=39408934)

I'm sorry, but it seems like the content you posted is not related to a typical Hacker News submission. Could you please provide a different submission or topic for me to create a summary from?

The discussion is quite technical and involves topics such as deep learning, machine learning, mathematics, and artificial neural networks. Some users are discussing the use of advanced mathematical concepts in machine learning models. One user mentions the benefits of symmetry structures in weight space optimization, while another highlights the importance of understanding the dynamics of high-dimensional spaces in training neural networks. The conversation also touches on techniques for visualizing and analyzing data embeddings, comparing different libraries and tools for machine learning tasks. Additionally, there are mentions of projects related to hyperdimensional spaces, semantic search, and text embeddings.

### Show HN: AI Generated (Not-Real) User Avatar Images for Development Needs

#### [Submission URL](https://avatars.tzador.com/) | 77 points | by [timz](https://news.ycombinator.com/user?id=timz) | [43 comments](https://news.ycombinator.com/item?id=39408158)

A new service has emerged on Hacker News, offering a convenient solution for developers in need of consistent and realistic user avatars. By leveraging cutting-edge technologies like DALL-E and ChatGPT-4, this service generates user profiles complete with faces and names that sound real. The service provides a range of options for filtering and customizing avatars, such as by gender, ethnicity, age range, and size. Developers can access a list of available profiles in JSON format and easily retrieve random or fixed avatars using specific IDs. This tool seems like a game-changer for projects requiring diverse and lifelike user representations. Check it out and discuss on Hacker News!

1. User "rmnhn" discussed the issues related to email address providers such as Gmail and Outlook being used for confidential emails in testing environments, with further comments highlighting the importance of catching outbound emails in development and handling redundancy efficiently.

2. User "pmlttc" shared thoughts on generated avatars and the need for diversity to avoid visual blindness in the digital world. Another user commented on the non-existent profile images and the lack of choices provided.

3. User "tylrrbnsn" praised the realistic nature of the generated avatars, with a discussion on the benefits of AI-generated faces contributing to a more immersive virtual world.

4. User "Brajeshwar" mentioned a service where people contribute real photos of avatars and how it differed from AI-generated faces, sparking a conversation about similar services and the history of avatar contributions online.

5. User "snet0" detailed the syntax mismatch for parameters needed for a project, with suggestions for generating data images and thanks for the helpful comments. Additional discussions included generating data images and managing parameters for a more precise search.

6. Users discussed the importance of accepting multiple parameters for generative avatars, such as age ranges and ethnicities, and suggestions for implementing such features.

7. Discussions arose on the challenges of achieving consistency in facial features for avatars and the importance of human-like characteristics, symmetry, and neck length in creating realistic avatars.

8. Users compared avatar development to emojis, with suggestions for improving the project by incorporating SVG elements for better customization options and licensing considerations.

9. Feedback on the default avatar styles was shared, with suggestions for extending the range of styles to include Disney-like characters and tweaking color schemes for a more inviting interface.

10. A user expressed the desire for more diverse representations in avatars, highlighting the importance of accurately depicting physical attributes like facial symmetry and avoiding generic appearances.

Overall, the discussions on Hacker News touched upon various aspects of the new avatar service, ranging from the technical challenges of generating diverse and realistic avatars to the visual aesthetics and usability of the platform. Users expressed their opinions on the benefits of AI-generated avatars and provided feedback on features and improvements for the service.

### New Google Chrome feature blocks attacks against home networks

#### [Submission URL](https://www.bleepingcomputer.com/news/google/new-google-chrome-feature-blocks-attacks-against-home-networks/) | 55 points | by [Wasserpuncher](https://news.ycombinator.com/user?id=Wasserpuncher) | [25 comments](https://news.ycombinator.com/item?id=39411976)

Google is stepping up its security game with a new Chrome feature aimed at protecting home networks. This innovative tool blocks malicious websites from hijacking devices or services on internal networks, like printers and routers, by leveraging the browser as a gateway. By conducting preflight checks and seeking permission from the target device, Chrome aims to prevent attacks originating from the web. Developers will receive warnings in the DevTools console during the testing phase, allowing adjustments before full enforcement kicks in. This enhancement seeks to safeguard against unauthorized access to local devices and routers, addressing concerns around web interface vulnerabilities. The implications are far-reaching, as Google pushes the boundaries of browser security to combat internet-based threats effectively.

The discussion on Hacker News regarding Google's new Chrome feature aimed at protecting home networks revolves around various viewpoints and considerations. Some users express concerns about the potential conflict of interest due to Google being a major tech company with advertising interests, suggesting that the blocking of ads might interfere with Google's revenue model. Others argue that blocking ads does not necessarily harm the web ecosystem and that Chrome's actions can be seen as intrusive and against Google's interests. There are also discussions about the impact on web standards, privacy, and the potential interference with Google's business model if Chrome blocks ads. Furthermore, the conversation delves into the technical aspects of the feature, such as the ability to block outsider intrusions on local area networks and the implications for IoT devices. Overall, the discussion covers a range of perspectives on the implications and technical aspects of Google's new security feature in Chrome.

### Experimenting with GPTs custom actions, an example written in Rust

#### [Submission URL](https://danielegarbagnati.com/articles/neuro-rs) | 30 points | by [danigrb](https://news.ycombinator.com/user?id=danigrb) | [3 comments](https://news.ycombinator.com/item?id=39411380)

The big news today is about ChatGPT Custom Actions, a feature that allows GPT to perform specific tasks within a conversation, like generating images or querying databases. Custom actions take this a step further, enabling GPT to perform specialized tasks defined by developers, such as checking the weather or ordering a pizza.

The potential of custom actions is huge, as they could lead to a new way of interacting with apps where users can simply ask their app to do things instead of clicking through menus. This feature is currently available in the GPT store to subscribers, sparking thoughts about the evolution of software development towards defining essential rules and API specifications for specialized UI like GPT to create personalized experiences.

To showcase this concept, a practical example using Rust shows how an app built around ChatGPT interacts with OpenAPI Specs, a Custom Backend REST API, and an OIDC Provider for authentication. The implementation details, including using Axum as the web framework in Rust and creating CRUD REST API endpoints for todos, demonstrate how custom actions can be integrated into an app effectively.

Overall, the rise of ChatGPT Custom Actions signals a shift towards more conversational and intuitive interactions with technology, potentially reshaping the future of software development.

The comments on the submission mainly discuss the experimentation and potential of using ChatGPT Custom Actions. One user highlighted the potential to try incorporating player functionality in RPGs using this approach, and another expressed appreciation for the implementation of a proof of concept involving embedding vectors and databases into applications using the GPT platform. Additionally, there was mention of exploring custom actions as an alternative to traditional software interactions in a blog post shared on GitHub, emphasizing practical implementations in Rust with OIDC authentication. Overall, the discussion reflects a positive outlook on the possibilities and applications of ChatGPT Custom Actions in software development contexts.

### O(zero)

#### [Submission URL](https://koliber.com/articles/o-zero) | 18 points | by [koliber](https://news.ycombinator.com/user?id=koliber) | [5 comments](https://news.ycombinator.com/item?id=39409121)

Today on Hacker News, a post by Krystian Cybulski delves into the fascinating world of algorithmic complexity. The author takes us on a journey from the familiar realms of O(n^2) and O(n) to the more optimized O(log(n)) and the coveted O(1). But just when you think you've reached the pinnacle of efficiency, along comes the concept of O(zero). Yes, zero time! 

O(zero) challenges the notion that constant time is the best we can achieve in algorithmic efficiency. It's about questioning whether a task even needs to be done in the first place. The fastest code, after all, is the one that doesn't need to run at all. By eliminating unnecessary steps or processes, engineers can achieve remarkable gains in efficiency.

The key takeaway? Sometimes doing nothing at all is the most efficient solution. It's a powerful concept that can elevate your problem-solving skills to new heights. So next time you're optimizing code, remember to ask yourself: is there a way to accomplish this task without doing anything? The answer might just surprise you.

In the discussion on the submission about algorithmic complexity, users had varied reactions. 

- "cmrx64" mentioned the Richard Clarkson Open Source Institute identifying algorithms that may question the time spent on computing an answer, mentioning the possibility of an O(0) algorithm where no answer sharing is needed. They noted that documenting examples offline could be problematic and questioned what classic algorithms inherently provide a better answer.

- "drts" expressed that it seemed like an empty read.

- "czzyd" made a comment about a Baikal, and then there was a nested reply by "mnhtp".

- "az09mugen" simply commented "Nice pen." 

Overall, the discussions touched on the complexity and nuances of algorithmic efficiency, with some users raising interesting points and reflections related to the topic.

### Sierra Says Conversational AI Will Kill Apps and Websites

#### [Submission URL](https://www.wired.com/story/plaintext-sierra-conversational-ai-will-kill-apps-and-websites/) | 12 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [15 comments](https://news.ycombinator.com/item?id=39413575)

Two Silicon Valley leaders, Bret Taylor and Clay Bavor, have set out to revolutionize customer experiences with their AI startup, Sierra. The company aims to enhance interactions between big corporations and their customers using AI-powered agents. Sierra's approach, focusing on AI advancements for mainstream companies, challenges the traditional pursuit of superintelligence in the tech industry.

By implementing innovative AI models and safeguards against misinformation, Sierra's agents are designed to understand and represent a company as effectively as a human employee. This human-like touch includes providing empathy at scale, a concept that WeightWatchers embraced when Sierra promised genuine and relatable AI interactions. Despite skepticism about robots displaying empathy, WeightWatchers found value in the emotional support their AI agents could offer to customers in need.

The potential impact of Sierra's work extends beyond just improving customer interactions; it could redefine how companies engage with their audience in the digital realm. Through their advanced AI technology, Sierra is striving to shift automated customer interactions from frustrating experiences to positive ones, ultimately transforming how businesses exist in the digital landscape.

- **Zetobal** commented on the submission, but the content seems to be encoded in a way that is not understandable.
- **lxgr** mentioned the challenges of conversational UI in terms of solving concrete problems while also highlighting the difficulty in generating various responses. They hinted at the possibility of more sophisticated AI that can read minds to have more natural conversations.
- **yzzk** sarcastically suggested that companies making chatbots believe that chatbots can replace actual human employees.
- **vvzkstrl** brought up the recall of chatbots killing websites and apps in 2016, referencing Pepperidge Farm's meme.
- **llamaLord** discussed the limitations of chat-based interfaces due to their high focus on providing precise answers, which can lead to narrow and boring interactions. They highlighted the inefficiency of text-based communication in discovering information compared to other methods.
- **sfk** expressed that people prefer human-like conversational UIs.
- **pxmpxm** explained the limitations in transferring vehicle information through conversations and suggested separating conversational knowledge content from structured content.
- **wslh** questioned if conversational AI is the future of interface communication and mentioned that search engines like Google dominate the market due to their efficiency in providing quick results in a single interface.
- **dvngnt_** pointed out the potential problem where chatbots might kill digital assistants.
- **nprtm** shared insights on the training data required for systems like chatbots and mentioned the differences in training systems for web content versus search engines.
- **throwaway6733** discussed Clay's background at Google and their involvement in creating chat interfaces and visual searches. They highlighted the rapid growth of the enterprise chat service market.
- **DrNosferatu** commented on the thought-provoking nature of the conversation.
- **bkfj** shared an archive link.
- **j45** suggested making conversational approaches more approachable and expressed the need for transparency in information presentation on screens.
- **RecycledEle** threw in a disclaimer about resisting links starting with "https" and warned about potential security risks online.

### New chip opens door to AI computing at light speed

#### [Submission URL](https://phys.org/news/2024-02-chip-door-ai.html) | 36 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [10 comments](https://news.ycombinator.com/item?id=39407525)

The University of Pennsylvania has made a groundbreaking advancement in AI technology with the development of a new chip that operates at the speed of light, using light waves instead of electricity for complex mathematical computations. This innovation has the potential to revolutionize computer processing speed and energy efficiency. The chip, known as a silicon-photonic (SiPh) chip, combines Nanoscale manipulation techniques with silicon technology to perform calculations at unprecedented speeds. This technology could be a game-changer for AI applications, offering faster speeds, lower energy consumption, and enhanced privacy features. The implications of this new chip are vast, with applications ranging from neural networks to graphics processing units. Read more about this exciting development in AI computing at light speed in the full article provided by the University of Pennsylvania.

Discussion Summary:

- **crtsf** shared a link to a paper published in Nature Photonics and arXiv discussing the University of Pennsylvania's breakthrough in photonics chips. The paper describes the chip's ability to solve matrix-vector and matrix-matrix products efficiently, demonstrating the potential for larger-scale wave-based analog computing platforms.

- **mrnq** commented that this technology may not work well for machine learning tasks involving matrices with billions of parameters, as light-based calculations may have limitations when dealing with large matrices.

- **xsctt** pointed out that NVIDIA's tensor cores can handle large matrix calculations efficiently, even with matrix sizes as large as 32000x32000.

- **fnrdpglt** highlighted the potential for large-scale parallel processing using 2x2 to 10x10 matrix sizes demonstrated in the proof-of-concept.

- **mchlb** mentioned reading about light chips being a futuristic concept akin to the mythical battery technologies of the 1990s, but expressed skepticism about tangible products resulting from this technology.

- **DrNosferatu** shared a link related to neuromorphic engineering and integration as a point of novelty.

- **tmkld** raised concerns about the vulnerability of virtually unhackable technology in terms of memory management and potential security risks.

- **JieJie** shared a link related to buffer overflow vulnerabilities.

- **crnbrrytrky** made a short enthusiastic comment about the topic.

Overall, the discussion touched upon the potential limitations and applications of the University of Pennsylvania's light-based chip technology for AI computing, raised concerns about security vulnerabilities, and discussed related concepts in neuromorphic engineering and memory management.

### AI hiring tools may be filtering out the best job applicants

#### [Submission URL](https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination) | 63 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [75 comments](https://news.ycombinator.com/item?id=39412283)

AI hiring tools have been a hot topic on Hacker News today. Companies are increasingly turning to artificial intelligence-driven platforms to screen job applicants, with tools like body-language analysis, vocal assessments, and CV scanners being used to filter candidates. However, concerns are rising that these AI tools may be excluding highly qualified candidates, leading to potentially harmful repercussions. 

These tools are supposed to help eliminate biases in the hiring process but some experts argue that they could actually be exacerbating the problem. One example highlighted in the article is a make-up artist who lost her job after an AI tool scored her body language poorly. Similarly, biases in the algorithms can lead to qualified candidates being unfairly rejected based on factors like hobbies or educational background.

There are fears that marginalized groups could be disproportionately affected by these tools, as well as concerns about the lack of transparency in how candidates are evaluated. Additionally, there are worries that companies may not have the incentive to address biases in these systems, especially as they have replaced human HR staff with AI to save time and money.

Efforts are being made to address these issues, with initiatives like the Conditional Demographic Disparity test being developed to help companies identify biases in their AI algorithms. Ultimately, the goal is to have AI tools that are fair, unbiased, and capable of making merit-based decisions to benefit both the candidates and the companies.

The discussion on the topic of AI hiring tools includes various perspectives and concerns. 

1. One user pointed out that non-verbal interviews, body language analysis, and vocal assessments are highly discriminatory towards individuals who may not fit the standard criteria set by these tools.

2. Another user highlighted the importance of considering demographic variance in these tools and the potential biases they may carry.

3. There was a discussion about personal projects listed on resumes and the significance of effectively showcasing skills during the interview process.

4. The debate extended to the idea that self-promotion and interpersonal skills are essential for a successful hiring process, and some users emphasized the importance of these skills in the engineering field.

5. The discussion touched upon concerns about AI tools potentially leading to discrimination, especially in the case of large companies handling a high volume of applications.

6. The conversation veered towards how the use of AI tools could inadvertently create biases and harm the recruitment process, potentially affecting the diversity of candidates being considered.

7. The role of HR professionals and their knowledge in addressing discrimination was also scrutinized, with some users emphasizing the need for proper training in handling discriminatory issues.

8. Additionally, the conversation delved into the potential age discrimination that could occur in the hiring process due to AI tools that tweak applications to make candidates appear younger.

9. There was a discussion about the implications of these tools on disabled candidates and how they may face challenges due to the standardized criteria these tools use for evaluation.

Overall, the discussion highlights various concerns regarding the use of AI hiring tools and their potential impact on the recruitment process and candidate diversity.

