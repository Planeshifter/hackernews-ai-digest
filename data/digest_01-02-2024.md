## AI Submissions for Tue Jan 02 2024 {{ 'date': '2024-01-02T17:09:27.205Z' }}

### Images altered to trick machine vision can influence humans too

#### [Submission URL](https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/) | 75 points | by [xnx](https://news.ycombinator.com/user?id=xnx) | [75 comments](https://news.ycombinator.com/item?id=38846764)

A new study published in Nature Communications reveals that digital images altered to deceive computer vision systems can also influence human perception. The researchers conducted a series of experiments and found that human judgments were systematically influenced by adversarial perturbations. Adversarial images are those that have been subtly altered to mislead AI models into misclassifying their contents. The study highlights the need for further research to understand the impact of adversarial images on both humans and AI systems. While human vision is not as susceptible to these perturbations as machine vision, the study suggests that they can still bias human perception towards the decisions made by machines. These findings have implications for AI safety and security research, and could potentially contribute to the development of more robust computer vision models.

The discussion on this submission covers various aspects of the study and its implications. Some users discuss the specific details of the experiments, such as the types of images used and the participants involved. Others highlight the potential implications of adversarial images for AI systems and question the reliability of machine vision. There is also a conversation about the methodology of the study, including the sample size and the validity of the findings. Some users express disappointment with the research methodology, suggesting that it is wasteful and does not provide significant insights. Overall, the discussion touches on different angles of the study and raises questions about its significance and validity.

### Distributed Inference and Fine-Tuning of Large Language Models over the Internet

#### [Submission URL](https://browse.arxiv.org/html/2312.08361v1) | 100 points | by [cyanf](https://news.ycombinator.com/user?id=cyanf) | [20 comments](https://news.ycombinator.com/item?id=38843069)

Researchers from HSE University, Yandex, Neiro.ai, the University of Washington, and Hugging Face have developed a cost-efficient method for running large language models (LLMs) by pooling together idle compute resources over the Internet. LLMs with over 50 billion parameters have become increasingly useful in natural language processing (NLP) tasks, but they require high-end hardware that is inaccessible to most researchers. The team investigated methods for distributed inference and fine-tuning of LLMs, comparing local and distributed strategies. They found that a large enough model can run efficiently on geodistributed devices in a consumer-grade network. The team developed fault-tolerant inference algorithms and load-balancing protocols to address the challenges of unreliable devices and unequal hardware, enabling efficient pooling of resources for LLMs. They showcased their algorithms in Petals, a decentralized system that runs LLMs over the Internet up to 10 times faster than offloading for interactive generation. The performance of the system was evaluated in simulated conditions and a real-world setup spanning two continents. This work provides a more cost-effective way of running large language models and opens up access to these models for researchers with limited resources.

The discussion on this submission covers a range of topics related to the development and implementation of decentralized technologies, concerns about the implications of large language models, and debates around the use of Proof of Work in cryptocurrencies.
One user points out that decentralized and distributed technologies are important for the future of AI and suggests practical measures to ensure security. Another user comments that this development makes it harder to shut down AI, while another argues that it makes fighting closed corporations supported by AI more difficult.
A user shares a link to the project they are working on, which is related to the topic of distributed networks and GPUs. Another user expresses surprise at how quickly this technology has progressed and recommends various protocol projects to explore.
The conversation then shifts towards a discussion about distributed network GPUs, with remarks about the availability and affordability of GPUs in the market. Some users argue for the use of cryptocurrencies as a means of payment for GPU usage, while others question the necessity of cryotocurrencies in this context.
There is also a mention of the potential waste of resources in GPU hosting and the need for participants in distributed networks to make choices based on energy efficiency.
The conversation takes a tangent to discuss the environmental impact of Bitcoin and the unnecessary resource consumption compared to other cryptocurrencies.

Lastly, a user mentions the Gridcoin BOINC project as a relevant example of decentralized computing.

Overall, the discussion touches upon various related topics, including decentralized technologies, the implications of large language models, and debates about different approaches to cryptocurrency.

### Microsoft Copilot iOS App

#### [Submission URL](https://apps.apple.com/at/app/microsoft-copilot/id6472538445) | 69 points | by [franze](https://news.ycombinator.com/user?id=franze) | [45 comments](https://news.ycombinator.com/item?id=38841302)

Introducing Copilot: The AI-powered chat assistant designed to enhance your productivity. Powered by the latest OpenAI models, GPT-4 and DALL·E 3, Copilot provides fast, complex, and accurate responses, as well as the ability to create stunning visualizations from simple text descriptions. Whether you're drafting emails, writing stories or scripts, summarizing complex texts, translating content, creating personalized travel plans, or updating resumes, Copilot is the versatile AI assistant that can help you get things done faster. But that's not all - Copilot also features Image Creator, which can transform your design process by quickly generating high-quality visualizations based on text prompts. Whether you're exploring new styles and ideas, curating social media content, developing brand motifs, designing logos, creating custom backgrounds, building portfolios, illustrating books, or visualizing film and video storyboards, Copilot combines the power of GPT-4 with the imagination of DALL·E 3 to elevate your design workflow and inspire your creativity. Experience the future of AI interaction - download Copilot for free today!

The discussion on this submission covers a few different topics:

1. Comparing GPT-4 and Microsoft's AI products: One commenter asks for a detailed analysis comparing GPT-4 with Microsoft's AI products, but no responses with specific comparisons are provided.
2. Issues with Apple's Private Relay and Microsoft sign-in: A discussion starts about concerns with Apple's Private Relay service not working properly in certain regions and Microsoft sign-in problems.
3. Various comments on different apps: Some users mention different apps they have installed, including weather apps, Bing AI apps, and Twitch chat on iOS.
4. Testing the complexity of the AI: One user mentions testing the complexity of the AI and compares it to ChatGPT.
5. Issues with text input and background processes: Some users mention issues with text input not capitalizing sentences correctly and background processes related to Microsoft Edge and Bing.
6. OpenAI's pricing: A user speculates that OpenAI may drop their pricing for GPT-4.
7. ChatGPT's limitations: Users discuss limitations of ChatGPT, such as daily limits and the AI's ability to approximate Hitler's rhetoric.
8. Facebook and Microsoft products: Users express dissatisfaction with Facebook Messenger and Microsoft products, including complaints about cancellation of services and the building of personal profiles.
9. Paying for AI apps: A discussion emerges about people not wanting to pay for AI apps and the value they expect from free software.
10. Privacy concerns: Some commenters express concerns about the privacy implications of AI systems collecting data and Microsoft's practices compared to Apple's.
11. Starting with Copilot: One commenter expresses excitement about trying Copilot.

This summary provides an overview of the main topics discussed, but please note that the comments have been condensed and may not reflect the full context of each discussion.

### Improving Text Embeddings with Large Language Models

#### [Submission URL](https://arxiv.org/abs/2401.00368) | 41 points | by [cmcollier](https://news.ycombinator.com/user?id=cmcollier) | [6 comments](https://news.ycombinator.com/item?id=38845508)

Researchers Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei have introduced a new method for improving text embeddings using large language models (LLMs). Unlike existing approaches that rely on multi-stage pre-training and fine-tuning with labeled data, their method uses synthetic data generated by proprietary LLMs followed by fine-tuning on open-source decoder-only LLMs. The experiments show that their method achieves strong performance on competitive text embedding benchmarks without using any labeled data. Additionally, when fine-tuned with a combination of synthetic and labeled data, their model sets new state-of-the-art results on the BEIR and MTEB benchmarks. The paper is available for download in PDF format.

The discussion on this submission revolves around the use of synthetic data and large language models (LLMs) for improving text embeddings. One user finds the idea of using synthetic data helpful for generating useful embeddings, especially when fine-tuning with the E5 model. Another user expresses surprise that LLMs can be used for text embeddings. They are then informed that LLMs are commonly used for embedding models, and larger LLMs tend to yield better results.

Another user discusses the comparison between different sizes of LLMs, mentioning that while a larger LLM may be more effective, it also has slower training times. Lastly, a user expresses confusion about LLMs and text embeddings, to which another user explains that LLMs can effectively generate embeddings for semantically similar content while minimizing distances between dissimilar content.

