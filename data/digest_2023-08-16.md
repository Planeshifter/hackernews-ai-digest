## AI Submissions for Wed Aug 16 2023 {{ 'date': '2023-08-16T17:09:45.495Z' }}

### Ts_zip: Text Compression Using Large Language Models

#### [Submission URL](https://bellard.org/ts_server/ts_zip.html) | 240 points | by [Deeg9rie9usi](https://news.ycombinator.com/user?id=Deeg9rie9usi) | [129 comments](https://news.ycombinator.com/item?id=37152978)

The ts_zip utility in the ts_server software has introduced a new way to compress text files using Large Language Models. Unlike other compression tools, ts_zip achieves significantly higher compression ratios. However, there are a few caveats to keep in mind. Firstly, the language model needs to be available during decompression. Additionally, a GPU is necessary to achieve reasonable speeds, and it's crucial to use the same GPU model and program versions for compression and decompression. 

The compression ratio for each model is measured in bits per byte. CMIX v19 is particularly impressive in terms of compression. The table provided shows the compression ratios for various files, including alice29.txt, book1, enwik8, and linux-1.2.13.tar.

When compressing the book1 file on an RTX A6000 GPU, the compression speed and required GPU memory are measured. Interestingly, the decompression speed and memory requirements are similar. Different models, such as rwkv_169M, rwkv_430M, pythia_deduped_70M, rwkv_7B_q4, and falcon_7B_q4, are compared in terms of compression speed and GPU memory usage.

In conclusion, the smaller RWKV models seem to strike a good balance for text compression. They utilize less memory due to their RNN structure and offer relatively high compression speeds. Fabrice Bellard, the developer behind ts_zip, is the mastermind behind this innovative text compression utility.

The discussion surrounding the ts_zip utility focuses on various aspects of text compression using Large Language Models (LLMs). Some comments discuss the potential limitations and challenges of using LLMs for compression. One user points out that the models require the availability of the language model during decompression, and another highlights the need for a compatible GPU model and program versions for compression and decompression. 

Others explore related topics such as externalizing dictionaries, the use of autoencoders and variational autoencoders for compression, and the concept of lossy text compression. The discussion also mentions Fabrice Bellard, the developer behind ts_zip, and his other notable works such as QEMU, BPG Portable Graphics, and FFmpeg.

Some users express concerns about lossy text compression and the potential loss of semantic meaning and information. Others find the concept fascinating and discuss its possible applications and implications. There are also mentions of JBIG2 and its vulnerabilities, as well as discussions about checksums and error correction.

### Show HN: LlamaGPT â€“ Self-hosted, offline, private AI chatbot, powered by Llama 2

#### [Submission URL](https://github.com/getumbrel/llama-gpt) | 205 points | by [mayankchhabra](https://news.ycombinator.com/user?id=mayankchhabra) | [71 comments](https://news.ycombinator.com/item?id=37148210)

Introducing LlamaGPT: A Self-Hosted, Offline ChatGPT-Like Chatbot

LlamaGPT is a new self-hosted, offline chatbot powered by Llama 2. It offers a private and secure experience with no data leaving your device. Whether you want to run it on your Umbrel home server or any other x86 or arm64 system, LlamaGPT is easily installable. Simply clone the repository and run the appropriate Docker command based on your hardware's RAM. Once installed, you can access LlamaGPT at http://localhost:3000. The roadmap for LlamaGPT includes adding CUDA and Metal support, separating the model from the Docker image, and updating the front-end. If you're a developer interested in contributing, check out the friendly issues or open a new one to discuss ideas. LlamaGPT is made possible by developers and teams such as Mckay Wrigley, Georgi Gerganov, Andrei, NousResearch, Tom Jobbins, and Meta. Check out the demo and installation instructions on the Umbrel website.

The discussion around the submission revolves around various aspects of LlamaGPT and related topics. Here are some key points mentioned in the comments:

- One user describes a simple approach to describing the retrieval-augmented generation (RAG) process discussed in the article, involving embedding private data chunks and using a model to retrieve similar chunks in a vector database based on cosine similarity.
- The need for significant computing power is highlighted, especially for tasks like retrieving relevant information from large technical books or generating embeddings for search.
- The limitations of the cosine similarity approach in handling context windows are discussed, and alternative techniques like RoPE scaling are mentioned.
- The process of training word vectors and embedding text in vector databases is explained.
- Fine-tuning Llama models is suggested as a possible approach for custom training and inference.
- The potential use of GPUs is discussed, and the challenges related to GPU support in LlamaGPT are mentioned. The availability of CUDA and Metal support is suggested as a way to address this.
- The potential trademark infringement in using the name "GPT" is raised, with some comparing it to other cases of trademark disputes with generic terms.
- The differences in trademark laws and practices in different countries are mentioned, along with examples of trademarks that have become generic terms in specific regions.
- The suggestion to trademark LlamaGPT or ChatGPT is made.

Overall, the discussion covers a range of technical and legal aspects related to LlamaGPT and its potential implications.

### OpenAI acquires Global Illumination

#### [Submission URL](https://openai.com/blog/openai-acquires-global-illumination) | 115 points | by [davidbarker](https://news.ycombinator.com/user?id=davidbarker) | [53 comments](https://news.ycombinator.com/item?id=37150098)

OpenAI has made an exciting move by acquiring the team at Global Illumination. Founded by Thomas Dimson, Taylor Gordon, and Joey Flynn, Global Illumination has been utilizing AI to develop creative tools, infrastructure, and digital experiences. With the acquisition, the entire Global Illumination team will be joining OpenAI to work on their core products, including ChatGPT. This team brings impressive experience, having worked on early products at Instagram and Facebook, as well as contributing to YouTube, Google, Pixar, Riot Games, and other notable companies. OpenAI is thrilled about the impact this talented group will make within the organization.

The discussion about OpenAI's acquisition of the Global Illumination team centers around various aspects and implications of the move:

1. The Global Illumination team's previous projects and experience are highlighted, including their work at Instagram, Facebook, YouTube, and other notable companies.
2. There is speculation about the potential impact of the acquisition on OpenAI's gaming business, particularly in deploying AI agents in 3D worlds and rendering scenes using AI.
3. Some users discuss the possibility of using OpenAI's technology to generate dialogue and interactions with NPCs in games like Skyrim.
4. Concerns are raised about the direction of OpenAI's product roadmap, with some suggesting a focus on monetizing the technology and highlighting the influence of investors in decision-making.
5. Others discuss the potential applications of OpenAI's technology in creating 3D spatial environments and generating content for virtual worlds.
6. The topic of training machine learning models using Minecraft and text commands is mentioned, with some expressing interest in using AI to generate custom game engines and graphics.
7. A few comments touch on the potential competitive implications of OpenAI's acquisition, particularly in regard to Microsoft's involvement in the Minecraft ecosystem.
8. The discussion briefly deviates into the topic of AI safety and the need for caution in pushing the limits of AI capabilities.
9. Some users mention other AI-related projects, such as Roblox AI and OpenAI's work on voxel-based AI navigation in 3D environments.
10. Lastly, there is a general mention of the growing demand for real-world-based datasets in machine learning.

### With some tech savvy, you can disconnect your robot vacuum from the cloud

#### [Submission URL](https://www.engadget.com/robot-vacuum-security-privacy-irobot-cloud-133008625.html) | 27 points | by [thunderbong](https://news.ycombinator.com/user?id=thunderbong) | [11 comments](https://news.ycombinator.com/item?id=37149524)

Robot vacuums have become advanced Internet of Things devices with features like internet capabilities, video recording, and voice control. However, the security measures for these devices haven't caught up. There have been cases where robot vacuums have captured private moments and sent the data to third parties. Dennis Giese, a PhD student at Northeastern University, spoke about how owners can hack their robot vacuums to disconnect from the cloud and gain more control over their devices. While this requires technical expertise, there are steps owners can take to improve on-device data security, such as wiping all data before selling or disposing of the device.

The discussion surrounding the submission is primarily focused on the features and experiences of different robot vacuum models, as well as concerns about privacy and security.

- Some users discuss the convenience of scheduling and zoning features, allowing the robot vacuum to clean specific areas at specific times.
- Others mention their preference for certain brands and models, such as the Roomba or Neato D80, based on their personal experiences.
- One user mentions their intention to get a robot vacuum but is concerned about privacy, considering placing a heavy box to limit the vacuum's movements.
- The topic of hacking robot vacuums is raised, with one user pointing out that while disconnecting from the cloud and gaining more control may be possible through technical means, it is not a long-term solution if the device's design does not prioritize privacy and security.
- A separate conversation discusses the surprising discovery of someone talking about scheduling their vacuum on a public Wi-Fi network, raising concerns about privacy and security risks.
- A user mentions using the Valetudo Dreame software to gain more control over their robot vacuum but notes that unfortunate OTA (over-the-air) updates may limit this functionality.
- Finally, a humorous comment about "vacuum-jacking" is made.

Overall, the discussion spans topics such as the functionality and performance of various robot vacuum models, privacy concerns, and hacking possibilities.

### Amazon Pharmacy automates discounts to help insulin patients get pledged prices

#### [Submission URL](https://www.reuters.com/business/retail-consumer/amazon-pharmacy-automates-discounts-help-insulin-patients-get-pledged-prices-2023-08-15/) | 79 points | by [benkan](https://news.ycombinator.com/user?id=benkan) | [82 comments](https://news.ycombinator.com/item?id=37145558)

Amazon Pharmacy has announced that it will automatically apply manufacturer-sponsored coupons to over 15 insulin and diabetes medicines to help patients access discounts. Patients using Amazon Pharmacy will no longer have to manually search for and enter coupons from major insulin makers Novo Nordisk, Eli Lilly, and Sanofi. This move comes after these companies pledged to slash insulin prices by at least 70% by 2024. However, a report released by Senator Elizabeth Warren last month revealed that some patients were struggling to access discounted generic insulin at the promised lower price. With this new program, Amazon aims to make it easier for patients to get their insulin at the lowest possible prices. The discounts will also apply to diabetes-related medical devices and other cardiometabolic medicines. Since launching its healthcare business in late 2020, Amazon has been competing with established pharmacies like CVS and Walgreens by offering convenience and choices to customers.

The discussion on this submission revolves around several aspects of Amazon Pharmacy's new program to automatically apply manufacturer-sponsored coupons to insulin and diabetes medicines. 

One user mentions that Amazon's program is essentially charging a spread reimbursement, which means they are taking a cut from the manufacturer's discount. Another user disagrees, stating that Amazon is simply applying the manufacturer's discount to the patient's price.

The discussion then shifts to the high cost of medication and the difficulty patients face in accessing coupons. Some users express frustration with the healthcare system's complexity, while others note that the responsibility falls on doctors to prescribe more affordable alternatives or help patients navigate the discounts.

There is also a discussion on the influence of pharmaceutical companies and the practice of kickbacks. Some users highlight the cost-saving practices in other countries, such as Canada, where doctors actively help patients find cheaper generic alternatives.

Overall, the discussion highlights the challenges and complexities of the healthcare system and the need for more affordable medication options.

