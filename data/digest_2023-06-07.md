## AI Submissions for Wed Jun 07 2023 {{ 'date': '2023-06-07T17:12:30.581Z' }}

### Deepmind Alphadev: Faster sorting algorithms discovered using deep RL

#### [Submission URL](https://www.nature.com/articles/s41586-023-06004-9) | 729 points | by [anjneymidha](https://news.ycombinator.com/user?id=anjneymidha) | [261 comments](https://news.ycombinator.com/item?id=36228125)

Researchers have developed a new AI algorithm, AlphaDev, which was trained to discover more efficient sorting and hashing routines. By formulating the task of optimizing sorting algorithms as a single-player game, AlphaDev used deep reinforcement learning to discover small sorting algorithms from scratch. These algorithms were found to outperform previously known human benchmarks and have now been integrated into the LLVM standard C++ sort library. The approach used in this study could have applications in other domains and could potentially discover other unknown routines.

In the comments, there is a discussion about the specifics of the algorithm, including the benchmarks and the potential for the routines to be used in other contexts. Additionally, there is a debate about the need for cryptographically secure hashing functions and the role of hashing in cryptographic applications. There is also a discussion about the requirements for a hash function to be considered secure and suggestions for further research.

### CodeTF: One-Stop Transformer Library for State-of-the-Art Code LLM

#### [Submission URL](https://arxiv.org/abs/2306.00029) | 91 points | by [pabo](https://news.ycombinator.com/user?id=pabo) | [6 comments](https://news.ycombinator.com/item?id=36233881)

A team of researchers have developed an open-source Transformer-based library called CodeTF designed to simplify the development and deployment of deep learning-based models for code intelligence. CodeTF supports a variety of pretrained Code LLM models and popular code benchmarks with a unified interface that allows for rapid access and development across different models, datasets, and tasks. The library also includes language-specific parsers and utility functions for extracting code attributes. The researchers hope CodeTF will bridge the gap between machine learning/generative AI and software engineering, providing a comprehensive open-source solution for developers, researchers, and practitioners.

The discussion includes various comments on the open-source Transformer-based library, CodeTF, developed by researchers to simplify the development and deployment of deep learning-based models for code intelligence. One user suggests that Salesforce's investment in resources focused on machine learning/generative AI for software engineering could positively impact the field, and they are pleased with the comprehensive open-source solution. Another user discusses the differences in released models and notes CodeTF's inclusion of various models and benchmarks. Several users mention their experience with the library, including using it to train models for specific programming languages, struggling with certain prompts, and the limited support for certain languages such as C++ and Rust. Overall, the comments show interest in CodeTF and its potential impact on code intelligence and software engineering.

### I'm afraid I can't do that: Prompt refusal in generative language models

#### [Submission URL](https://arxiv.org/abs/2306.03423) | 170 points | by [belter](https://news.ycombinator.com/user?id=belter) | [160 comments](https://news.ycombinator.com/item?id=36230750)

Max Reuter and William Schulze have submitted a paper titled "I'm Afraid I Can't Do That: Predicting Prompt Refusal in Black-Box Generative Language Models" to KDD 2023, in which they examine the refusal behavior of OpenAI's ChatGPT and the fine-tuning bias that affects which prompts the model chooses to refuse. The authors use a black-box attack to query ChatGPT with offensive and benign prompts, manually labeling each response as compliance or refusal. They then train a refusal classifier using a small manually-labeled dataset and use it to bootstrap a larger dataset on which they train a prompt classifier to predict whether ChatGPT will refuse a given question. The prompt classifier achieves 76% accuracy on a test set of manually labeled questions, and the authors examine the classifiers and the prompt n-grams that are most predictive of either compliance or refusal.

In the discussion on Hacker News, users mentioned possible ways to improve moderation and reduce offensive prompts in AI models, such as implementing a moderation filter, using encryption, adding latency to the response, and creating a conversation topic that is entirely foreign to ChatGPT. Some users expressed concern about privacy and censorship, while others pointed out the importance of good UI design to avoid confusing users and to give warning signals when necessary.

### Is AI killing the stock photo industry? A data perspective

#### [Submission URL](https://www.stockperformer.com/blog/is-ai-killing-the-stock-industry-a-data-perspective/) | 146 points | by [giuliomagnifico](https://news.ycombinator.com/user?id=giuliomagnifico) | [208 comments](https://news.ycombinator.com/item?id=36223307)

As the stock photography industry grapples with the implications of AI-generated imagery, Stock Performer has attempted to shed some light on how it has affected the sector. While there is little data available on the uptake of AI-generated images, the blog post from Stock Performer, which analysed information from its customers who upload to Adobe Stock, found that at present only 13% of those contributors have submitted AI-generated content. The data also revealed that revenue and download numbers for iStockphoto and Adobe Stock have increased in recent years, while Shutterstock has suffered from a substantial rise in monthly uploads without seeing a matching upswing in sales.

Some commenters pointed out the dark UX patterns of subscription services for stock photography and suggested that subscriptions may be more appealing for companies needing a large number of images than individual buyers, and that AI-generated stock photography is often lower quality than premium stock photography produced by humans. Others suggested that the industry is overvalued and may soon collapse, while others commented on the potential socioeconomic implications of AI-generated imagery, including job displacements and the concentration of capital among the owners of AI technologies. Overall, it seems that the industry is still trying to respond to the challenges and opportunities presented by AI-generated stock photography.

### How many sensors for autonomous driving?

#### [Submission URL](https://semiengineering.com/how-many-sensors-for-autonomous-driving/) | 96 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [200 comments](https://news.ycombinator.com/item?id=36226986)

As autonomous driving technology advances, carmakers are debating the number of sensors needed for vehicles. The cost of sensors ranges from $15 to $1,000 and they are used to collect data about the surrounding environment. These include image, lidar, radar, ultrasonic, and thermal sensors. However, each type of sensor has its limitations which has driven the development of sensor fusion. Combining multiple sensors can achieve safe autonomous driving. OEMs are taking very different design and deployment approaches. Mercedes-Benz has installed 30 sensors for autonomous driving while Tesla has adopted a camera-only autonomous driving technology strategy. Sensor fusion remains an active area of research as each type of sensor has limitations. The number of sensors required will depend on various factors including the level of autonomy and type of vehicle.

The discussion in the comments touches on a range of related topics, including the advantages and disadvantages of various sensor types, the challenges of developing sensor fusion, the capabilities of humans versus robots in perceiving depth and other aspects of the environment, and the importance of software in ensuring safe self-driving cars. Some commenters suggest that sensors alone are not sufficient and that driver feedback and other forms of interaction may be necessary, while others emphasize the importance of improving human understanding of the physical world and enhancing machine learning models to better extrapolate physical interactions. Some commenters argue that the focus on sensors is misplaced and that the biggest challenge facing self-driving cars is the intricacy of the road network itself, which requires new levels of communication and coordination between vehicles.

### Run and create custom ChatGPT-like bots with OpenChat

#### [Submission URL](https://github.com/openchatai/OpenChat) | 157 points | by [udev4096](https://news.ycombinator.com/user?id=udev4096) | [55 comments](https://news.ycombinator.com/item?id=36223972)

OpenChat is a console designed to simplify the usage of large language models. It serves as a hub for managing multiple customized chatbots, supporting GPT models, and providing two-step setup processes to create a comprehensive chatbot console. Currently available features include the creation of unlimited local chatbots, customization of chatbots by providing PDF files, websites, and integrations with platforms like Notion and Confluence, and the ability to use the entire codebase as a data source for chatbots. The project is licensed under the MIT License, and contributions are welcomed.

The comments discuss various approaches to content embedding, including chunking, which some users believe to be a neglected approach that may improve retrieval quality. Several users suggest various methods for controlling the number of results returned by fine-tuning language models, and others discuss the challenges of integrating OpenAI and open-source language models. Additionally, users raise concerns about security and mention the importance of content provided by platforms such as Notion and Confluence in providing integrations.

### C++ Implementation of StableDiffusion

#### [Submission URL](https://github.com/axodox/axodox-machinelearning) | 152 points | by [smusamashah](https://news.ycombinator.com/user?id=smusamashah) | [35 comments](https://news.ycombinator.com/item?id=36235338)

Axodox has released a C++ ONNX implementation of StableDiffusion for image synthesis, including txt2img, img2img, and inpainting. With competitive performance, this solution does not rely on Python and can integrate into virtually any application as long as they can import C++ or C functions. The ONNX models are executed using the ONNX runtime, and Axodox offers an example integration called Unpaint, which showcases how the libraries can be integrated into a simple WinUI-based user interface. The current codebase and the resulting NuGet packages target Windows and use DirectML, although only small sections of the code utilize Windows-specific APIs and can be ported to other platforms with minimal effort.

The most significant topics of discussion touch on why someone would choose C++ over Python in this use case, a platform-specific implementation, and package management. The discussion goes on to list different methods of package management and suggest different libraries and hardware accelerations to use when implementing machine learning models in C++.

### DeepFilterNet: Noise supression using deep filtering

#### [Submission URL](https://github.com/Rikorose/DeepFilterNet) | 211 points | by [nitinreddy88](https://news.ycombinator.com/user?id=nitinreddy88) | [42 comments](https://news.ycombinator.com/item?id=36221534)

DeepFilterNet is a speech enhancement framework that uses deep filtering and was designed to reduce noise in speech signals for full-band audio. The open-source framework is available for Linux, MacOS, and Windows, and includes a Python wrapper for processing and a LADSPA plugin for real-time noise suppression. DeepFilterNet2, a newer version of the framework, aims for real-time speech enhancement on embedded devices. Recently, the team behind DeepFilterNet released a new demo and a paper on Deep Multi-Frame Filtering for Hearing Aids.

Although some users raised concerns over its efficacy, the majority of commenters agreed that the use of deep filtering over classic speech control algorithms showed strong potential. Some users mentioned Python's limitations with dependency management and Poetry, a modern dependency tool for Python, was suggested as an alternative. The discussion also covered multiple topics, such as the integration of Pipewire, neural network-based approaches to image recognition, and the challenges of researching noise suppression for voice-recognition applications.

### OpenLLaMA 7B Training Completed to 1T Tokens

#### [Submission URL](https://huggingface.co/openlm-research/open_llama_7b) | 56 points | by [jncraton](https://news.ycombinator.com/user?id=jncraton) | [3 comments](https://news.ycombinator.com/item?id=36228535)

OpenLLaMA offers an open source reproduction of Meta AI's LLaMA large language model, complete with 7B and 3B models trained on 1T tokens, and a preview of a 13B model trained on 600B tokens. The project provides PyTorch and JAX weights of pre-trained OpenLLaMA models, evaluation results, and comparisons against the original LLaMA models. The models are trained on the RedPajama dataset released by Together and evaluated on a range of tasks, with results showing comparable performance to the original LLaMA and GPT-J on the majority of tasks. The weights are released under the Apache 2.0 license, and the team welcomes feedback from the community.

The first comment warns that the loading of the weights was developed using a different tokenizer than Hugging Face, which sometimes leads to incorrect tokenization. The second comment praises the project's performance, noting that a 7B model was trained on the MosaicML's Falcon cluster, costing around $183k in computation. A third comment expands on this, stating that the training process for the 7B model was roughly the same as MosaicML's Falcon.

### First Impressions of Vision Pro and VisionOS

#### [Submission URL](https://daringfireball.net/2023/06/first_impressions_of_vision_pro_and_visionos) | 43 points | by [ryanwhitney](https://news.ycombinator.com/user?id=ryanwhitney) | [9 comments](https://news.ycombinator.com/item?id=36231202)

Tech enthusiasts are eagerly anticipating the launch of Vision Pro and VisionOS after tech blogger John Gruber had a sneak preview of the devices. In his blog post, Gruber praised the technology, calling it "extraordinary" and feeling like they have been "pulled forward in time from the future". However, he also noted that the software is far from complete, which makes it hard to determine whether the product will be successful. Vision Pro and VisionOS are part of a new platform from Apple that could rival MacOS and iOS/iPadOS.

Some Hacker News users are skeptical of the hype around Apple's Vision Pro and VisionOS, as they believe that Steve Jobs' philosophy was that technology shouldn't "make compelling products into platforms," and that Apple has a history of taking existing technology and working backward to create a cohesive product experience. Other users feel that Apple has a long history of successful innovation, and that while the Vision Pro may be expensive, it could bring value for certain use cases. One user suggests that Apple is trying to co-create a platform for immersive 3D design with haptic feedback, while others debate the price point of the device. There are also discussions about whether Apple is following in the footsteps of Xerox PARC and if they are trying to create a new platform to compete with MacOS and iOS/iPadOS.

### OpenAI CEO suggests agency like UN’s nuclear watchdog could oversee AI

#### [Submission URL](https://apnews.com/article/open-ai-sam-altman-emirates-10b15d748212be7dc5d09eabd642ff39) | 33 points | by [belter](https://news.ycombinator.com/user?id=belter) | [31 comments](https://news.ycombinator.com/item?id=36226761)

OpenAI CEO Sam Altman has suggested that an international agency should oversee artificial intelligence worldwide, comparing it to the International Atomic Energy Agency that oversees nuclear power, during his global tour discussing AI in the United Arab Emirates. Altman expressed concerns over AI's "existential risk" to humanity and called for the world to "manage those risks and make sure we still get to enjoy those tremendous benefits." Altman's comments follow the success of OpenAI's popular chatbot, ChatGPT, and concern among industry leaders about mitigating the risks of AI and its impact on society.

The Hacker News community has been discussing Sam Altman's suggestion to implement an international agency that oversees artificial intelligence (AI) worldwide. Some users believe that AI regulation can have significant benefits, while others argue that the regulations will only exacerbate legal issues faced by startups. Furthermore, some comments express skepticism about Altman's intentions and believe that he is not trustworthy enough to lead this initiative. Other comments express concerns that centralized control over AI could lead to further greed and corrupt practices. Additionally, some users believe that prioritizing the development of AI over human needs will lead to disastrous consequences for humanity. Some users suggest that AI regulation is crucial because of the technology's existential risk and the potential negative effects it can have on society, including displacement of jobs and invasion of privacy.

### Ken Griffin says the AI community is making a mistake by creating so much hype

#### [Submission URL](https://www.cnbc.com/2023/06/07/citadels-ken-griffin-says-the-ai-community-is-making-a-mistake-by-creating-so-much-hype.html) | 24 points | by [SirLJ](https://news.ycombinator.com/user?id=SirLJ) | [27 comments](https://news.ycombinator.com/item?id=36225505)

Ken Griffin, the founder and CEO of Citadel, has said that the near-term hype around generative AI is a "terrible mistake". Speaking to Citadel's new class of interns, Griffin believes the AI community is creating a "huge disservice" by creating such a buzz around AI, although he does concede that AI will one day be transformative. However, he argues that the threat of AI eliminating white-collar jobs is far from reality due to the need for precision and accuracy in finance. Griffin also suggests that the biggest target for generative AI is programming and software engineering, and that it is crucial for software engineers to be close to domain problems that need to be solved.

The discussion in the comments covers various topics like the capabilities of LLMs, the potential risks and benefits of AI, the need for software engineers to be close to domain problems that need to be solved, and the role of AI in specific tasks like detecting patterns in text and summarizing information. Some users also share their concerns about AI's impact on society and job displacement. However, others defend the potential benefits of AI, especially in specific tasks like summarizing information and solving software problems.

