## AI Submissions for Thu Jan 25 2024 {{ 'date': '2024-01-25T17:09:49.426Z' }}

### New embedding models and API updates

#### [Submission URL](https://openai.com/blog/new-embedding-models-and-api-updates) | 212 points | by [Josely](https://news.ycombinator.com/user?id=Josely) | [76 comments](https://news.ycombinator.com/item?id=39132901)

OpenAI has announced several updates and new releases for their models and APIs. They are launching new embedding models, introducing GPT-4 Turbo and moderation models, providing API usage management tools, and lowering the pricing for GPT-3.5 Turbo.

The new embedding models include a smaller and more efficient text-embedding-3-small model and a larger and more powerful text-embedding-3-large model. These models help machine learning models and algorithms understand the relationships between content and perform tasks like clustering or retrieval.

The text-embedding-3-small model has shown improved performance over its predecessor, with an increased average score on benchmark tests. Additionally, it has been priced 5 times lower than the previous generation model.

The text-embedding-3-large model is OpenAI's best performing model and creates embeddings with up to 3072 dimensions. It has shown substantial improvements in benchmark scores compared to its predecessor.

OpenAI is also introducing native support for shortening embeddings, allowing developers to trade-off performance and cost. This feature enables flexible usage and allows developers to use larger embeddings while specifying a smaller vector size, thus reducing costs.

Next week, OpenAI will release a new GPT-3.5 Turbo model with reduced prices. The input prices for the new model will be reduced by 50%, and the output prices will be reduced by 25%. This model will also include improvements in accuracy and bug fixes.

OpenAI has also released an updated GPT-4 Turbo preview model, which is more thorough in completing tasks like code generation. They plan to launch GPT-4 Turbo with vision in general availability in the coming months.

Overall, these updates and releases from OpenAI aim to provide developers with improved models, more cost-effective solutions, and better management tools for API usage.

The discussion surrounding OpenAI's updates and releases on Hacker News covers various topics related to the models and their performance.

One user remarks on the dimensions of the embeddings, stating that typical dimensionality reduction techniques require specialized training techniques. Another user suggests using SuperBit random projection as an effective technique for reducing dimensionality.

There is also a discussion about the comparison between GPT-4 Turbo and previous models. Some users express skepticism that GPT-4 Turbo will outperform GPT-3 in text generation tasks. Another user mentions that GPT-4 Turbo performs worse than the November 2021 model in coding benchmarks.

The topic of API performance and limitations is also discussed. Some users raise concerns about the incompleteness of responses from the ChatGPT API, while others discuss the usefulness of ChatGPT for debugging and finding hard-to-google answers.

The moderation API is mentioned, with one user expressing surprise at OpenAI offering API checks for strings containing potentially harmful content.

Other topics include the compression of embeddings, the availability of the GPT-4 Turbo preview model, and the changes in default data usage for OpenAI API.

Overall, the discussion covers a wide range of topics related to OpenAI's updates, including model performance, API limitations, and potential applications.

### How AI is changing gymnastics judging

#### [Submission URL](https://www.technologyreview.com/2024/01/16/1086498/ai-gymnastics-judging-jss-world-championships-antwerp-paris-olympics/) | 109 points | by [mjwhansen](https://news.ycombinator.com/user?id=mjwhansen) | [144 comments](https://news.ycombinator.com/item?id=39127532)

In a recent gymnastics competition, an athlete's routine was judged not by humans, but by artificial intelligence (AI). The Judging Support System (JSS), developed by Fujitsu, analyzed high-definition footage of each gymnast's routine to assess their performance with unprecedented accuracy. While AI judging is meant to provide a fair and transparent assessment, some worry that it will detract from the subjective nature of the sport. Nevertheless, the use of AI in gymnastics marks a significant moment for the sport and showcases the advancements in technology that can aid in judging complex movements.

The discussion on the submission centers around the use of AI in judging gymnastics routines. Some commenters express concern about the AI judging system, comparing it to motion-controlled games like Wii Sports and suggesting that it could lead to a less subjective experience. Others argue that AI judging could make competition fairer and more objective. The discussion also touches on the challenges of creating an AI model that can accurately assess complex movements and the potential impact on the sport. Some commenters draw parallels to other sports, such as baseball and boxing, where AI or technology has influenced judging. There is also discussion about the role of human judgment versus AI judgment and the potential for biases and flaws in both systems. Overall, the comments reflect a mix of skepticism, curiosity, and cautious optimism about the use of AI in gymnastics judging.

### Hugging Face and Google partner for AI collaboration

#### [Submission URL](https://huggingface.co/blog/gcp-partnership) | 144 points | by [powera](https://news.ycombinator.com/user?id=powera) | [55 comments](https://news.ycombinator.com/item?id=39130849)

Hugging Face, an open AI platform, has announced a strategic partnership with Google Cloud to enable companies to build their own AI using open models and open source technologies. The collaboration aims to democratize good machine learning by making the latest AI research more accessible to the community. Google Cloud's contributions to open AI research and open source tools, such as Tensorflow and JAX, will help accelerate the availability of AI innovations through Hugging Face's open-source libraries. Additionally, the partnership will provide new experiences for Google Cloud customers to easily train and deploy Hugging Face models within Google Kubernetes Engine (GKE) and Vertex AI, leveraging the unique hardware capabilities available on Google Cloud. These new experiences will be made available to Hugging Face Hub users and will include features such as easily deploying models for production on Google Cloud, accelerating applications with TPUs on Hugging Face Spaces, and managing the usage and billing of Enterprise Hub subscriptions through Google Cloud accounts. The collaboration will start rolling out in the coming quarter.

The discussion on this submission revolves around several key points. 

One aspect that is discussed is the strategic partnership between Hugging Face and Google Cloud. Some users express their excitement about the collaboration, believing it will lead to improved access to AI models and services. Others speculate that Google's investment in Hugging Face is a strategic move to compete with other cloud platforms like Azure and AWS.

Another point of discussion is the democratization of AI and open-source technologies. Some users argue that open-source models and platforms like Hugging Face are crucial for making advancements in AI research more accessible to the community. However, there are also concerns raised about the potential commercialization and control of open-source projects by big companies like Google.

The controversy surrounding the GPT-3 model and the need to trust AI systems is also mentioned in the discussion. Users express their skepticism about the reliability and accountability of AI models and voice concerns about potential ethical issues.

There are also comments about the practical implications of the partnership, such as the integration of Hugging Face models into Google Cloud services like GKE and Vertex AI. Additionally, users discuss the benefits and drawbacks of Hugging Face's open-source libraries, such as the ease of deployment but potential integration challenges.

Some users highlight the importance of community collaboration in driving advancements in AI and open-source projects. Others discuss the financial aspects of partnerships like these, speculating on the returns and market integration for both Hugging Face and Google.

Overall, the discussion covers a range of topics, including the democratization of AI, the role of big companies in open-source projects, questions of trust and accountability in AI systems, and the practical implications of the partnership between Hugging Face and Google Cloud.

### COSP and USP: New methods to advance reasoning in LLMs

#### [Submission URL](https://pub.towardsai.net/inside-cosp-and-usp-google-research-new-methods-to-advance-reasoning-in-llms-07338b323dfd) | 25 points | by [TheIronYuppie](https://news.ycombinator.com/user?id=TheIronYuppie) | [4 comments](https://news.ycombinator.com/item?id=39133628)

Google Research has introduced two new techniques, COSP and USP, that enhance reasoning capabilities in language models. These techniques leverage the model's zero-shot outputs as demonstrations for prompting itself, bridging the gap between zero-shot and few-shot prompting. COSP focuses on question-answering tasks, while USP extends the approach to other natural language processing tasks such as classification and generation. Both techniques rely on measuring the model's confidence and self-consistency to select reliable pseudo-demonstrations. These methods represent significant advancements in AI prompting and have shown promising results in various benchmarks.

The discussion on this submission revolves around the techniques introduced by Google Research for enhancing reasoning capabilities in language models. One user mentions the papers and provides links to them, highlighting the potential of these advancements. Another user humorously remarks about the close relationship between Google and their "frnd brthr." The discussion then briefly veers off-topic as users mention other sources related to the topic.

### Social Media, AI, and the Battle for Your Brain

#### [Submission URL](https://proto.life/2023/12/social-media-artificial-intelligence-and-the-battle-for-your-brain/) | 73 points | by [marban](https://news.ycombinator.com/user?id=marban) | [57 comments](https://news.ycombinator.com/item?id=39132026)

In an interview with Proto.life, law professor Nita Farahany and technologist Aza Raskin discussed their work and the challenges posed by social media and artificial intelligence (AI). Farahany highlighted the rapid pace of technological advancement in AI and neurotechnology and the need for ethical and legal guidance to align technology with societal benefit. Raskin compared social media as "first contact with AI" and discussed the misalignment between AI and what is best for humanity. He emphasized that the second contact with AI, which involves generative AI, could magnify existing problems and called for a better understanding of incentives and externalities in technology development.


There was a range of discussion on this submission. One commenter mentioned that they have found effective ways to remove quick access to social media, such as removing bookmarks and suggestions from their browser, which helps them limit their usage. Another commenter remarked on the difficulty of combating AI and its influence on children. A discussion ensued about the relationship between freedom of thought and expression in regard to recommendation systems and generative AI. One commenter mentioned the concept of "legending AI" and how it relates to misinformation and manipulation. There was also a discussion about the limitations of AI and its impact on common sense and critical thinking. Another commenter discussed the problem of selective coverage and biased reporting by traditional news networks, while another commenter pointed out that fake news is not only propagated by mainstream media, but also by individuals on social media. Overall, the discussions touched on the challenges posed by technology, the need for responsible usage, and the impact of AI and social media on society.

### Self-rewarding-lm-PyTorch: Self-Rewarding Language Model from MetaAI

#### [Submission URL](https://github.com/lucidrains/self-rewarding-lm-pytorch) | 141 points | by [swyx](https://news.ycombinator.com/user?id=swyx) | [30 comments](https://news.ycombinator.com/item?id=39125646)

There is a new implementation of the training framework proposed in the Self-Rewarding Language Model. This implementation is in Python and uses PyTorch. The Self-Rewarding Language Model is a deep learning model that aims to go beyond human data by incorporating a self-reward mechanism during training. It has received a lot of attention in the field of artificial intelligence. The implementation is available on GitHub and is released under the MIT license. It has already garnered 903 stars and 34 forks, indicating its popularity among developers. If you're interested in deep learning, transformers, or artificial intelligence, this project might be worth checking out.

The discussion surrounding the submission includes various comments about the self-rewarding language model and its implementation:

- One user questions the effectiveness of the self-rewarding mechanism and suggests it might not reflect reality, mentioning the potential risks of choosing quick but inaccurate responses.

- Another user responds, citing examples from different fields, such as geometry and games, where self-improving models have shown performance improvements over time.

- There is a discussion about the implementation of the Llama2 model and its performance compared to existing systems like AlpacaEval. A user highlights the release of the Snorkel-Mistral-PairRM-DPO model and provides links to related resources.

- Some comments discuss the naming of the models used, with one user finding it confusing but others clarifying their purpose and the techniques employed.

- A user expresses gratitude for the clarification provided and mentions being a casual investor in Hugging Face, indicating their limited familiarity with technical details.

- A user mentions a paper titled "Macroexpanded Self-Rewarding Language Models," offering a link for further information.

- There is a discussion about the complexity and framework of training models, with one user offering an alternative perspective and suggesting that the process is more straightforward.

- Conversation diverges to unrelated topics such as the significance of EpicMafia and Svelte Society, with users reminiscing about experiences and the impact of these communities.

- A user mentions training competition held by the HF, which results in an undisclosed private cluster.

- A comment notes that Google has not released substantial updates in the meantime.

- There is a discussion about the limitations of AlpacaEval and the potential vulnerabilities of leaderboard hacking in language models.

- A user expresses appreciation for the work and plans to try it out, with another user asking about the use of variable symbols.

 Overall, the discussion covers a range of topics related to the self-rewarding language model, its implementation, performance, and potential limitations. It also veers into unrelated conversations about various communities and personal anecdotes.

### Did an AI write that hour-long "George Carlin" special? I'm not convinced

#### [Submission URL](https://arstechnica.com/ai/2024/01/did-an-ai-write-that-hour-long-george-carlin-special-im-not-convinced/) | 14 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [7 comments](https://news.ycombinator.com/item?id=39129541)

A recent video titled "George Carlin: I'm Glad I'm Dead" created quite a stir, with many people believing that an AI had generated new material from the legendary comedian who passed away in 2008. However, further investigation suggests that the video was actually a human-written and performed comedy routine using voice- and image-generation tools to create an "AI face." This case raises interesting questions about the public's understanding of AI capabilities and its acceptance of AI models as almost magical, potentially human-replacing technology. The situation with Dudesy's Carlin imitation may turn out to be a case of a human imitating an AI imitating a human, blurring the lines between AI-generated content and human creativity.

The discussion revolves around the recent video featuring what seemed to be an AI-generated imitation of George Carlin. Some users point out that it doesn't sound like Carlin and that it was probably a poorly written comedy sketch. Others mention that they are reminded of another podcast called "Dudesy," which may have used a similar gimmick with an AI-generated script. One user is surprised by the reference and mentions how they were forced to watch a thousand hours of content by X guy, finding similarities but still finding the AI text generation plausible. Another user adds a tangential note, mentioning the signs accompanying AI-generated messages and speculating that the images in the video were likely created by DALL-E, an AI capable of generating images from text. A user praises the performance, mentioning that the jokes were expectedly well-voiced. Finally, another user compliments the video, agreeing that it was good and well scripted.

