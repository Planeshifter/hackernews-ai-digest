## AI Submissions for Fri Feb 16 2024 {{ 'date': '2024-02-16T17:10:56.550Z' }}

### Coding in Vision Pro

#### [Submission URL](https://willem.com/blog/2024-02-16_vision-pro/) | 311 points | by [willemlaurentz](https://news.ycombinator.com/user?id=willemlaurentz) | [383 comments](https://news.ycombinator.com/item?id=39403935)

Willem L. Middelkoop is on a mind-bending journey exploring Spatial Computing with Apple's Vision Pro headset, and the experience is nothing short of extraordinary. Picture a world where you can seamlessly blend virtual objects into your reality – watching movies on a colossal cinema display or immersing yourself in personal photos right at your fingertips. With the Vision Pro, the line between the digital realm and the physical world blurs, opening up a realm of possibilities.

Equipped with cutting-edge technology like advanced chips, sensors, and cameras, the Vision Pro projects virtual elements into your surroundings, offering a truly immersive experience. This isn't just a wearable projector; it's an interactive marvel that responds to your gaze and touch, redefining how we interact with technology. Middelkoop showcases how he integrates a Bluetooth keyboard and trackpad with the Vision Pro, transforming it into a full-fledged computing system with immense capabilities.

Creating a multi-monitor work setup that feels incredibly lifelike, he delves into the concept of deep work, where the Vision Pro becomes a gateway to unparalleled focus and productivity. Imagine being surrounded by virtual windows that tower over you, allowing you to touch and interact with your digital workspace in ways that feel remarkably tangible. Middelkoop's journey with the Vision Pro blurs the boundaries between the real and virtual, offering a glimpse into a future where Spatial Computing revolutionizes how we perceive and engage with technology.

The discussion on Hacker News revolves around Willem L. Middelkoop's exploration of Spatial Computing with Apple's Vision Pro headset. The comments cover various aspects of the technology, including comparisons with other display options, scaling factors, and pricing considerations. Users discuss the limitations and advantages of the Vision Pro, such as its potential applications for work setups and productivity. Additionally, there are comparisons with other products in the market, like LG's UltraFine monitors, with debates on features and pricing. Some users express concerns about the functionality and support for external displays in Apple's ecosystem. The discussion also delves into the user experience, comfort, weight, and practicality of using the Vision Pro for extended periods, with comparisons to other headsets like the Oculus Quest 3. Overall, the comments touch on a range of technical, user experience, and pricing considerations related to Spatial Computing and Apple's Vision Pro headset.

### Magika: AI powered fast and efficient file type identification

#### [Submission URL](https://opensource.googleblog.com/2024/02/magika-ai-powered-fast-and-efficient-file-type-identification.html) | 657 points | by [alphabetting](https://news.ycombinator.com/user?id=alphabetting) | [227 comments](https://news.ycombinator.com/item?id=39391688)

Google has unveiled Magika, an AI-powered file-type identification system, open-sourced for the public good. With Magika, file identification becomes a breeze, using a custom deep-learning model for lightning-fast results, even when operating on a CPU. This tool is set to revolutionize how we handle different file types, a task that has traditionally been challenging due to the unique structures and complexities of various file formats. By leveraging AI technology, Magika surpasses existing tools in accuracy and speed, making it a game-changer in the realm of file management.

Magika's performance metrics speak for themselves, outperforming other tools by 20% across a benchmark of over 1 million files, with a particular edge in identifying textual files like code and configurations. Internally at Google, Magika is already in use at scale to enhance user safety across platforms like Gmail, Drive, and Safe Browsing, boosting file identification accuracy by a significant margin. Moreover, Magika's integration with VirusTotal promises to fortify the platform's cybersecurity efforts, contributing to a safer digital landscape for all users.

By open-sourcing Magika, Google aims to empower developers and researchers to refine their file identification methods and advance their projects. Available on Github under the Apache2 License, Magika is easily accessible for installation as a utility or Python library via the pip package manager. This release marks a significant step towards improving file management processes and streamlining security protocols in the ever-evolving landscape of tech.

The discussion on Hacker News regarding Google's open-sourced AI-powered file-type identification system, Magika, covers various topics. 

1. There is a conversation between users TomNomNom and brsztn regarding crawling locally for files, challenges faced with identifying specific file types correctly, and improving the tool's automation capabilities. They exchange experiences and insights into using Magika.

2. In another thread, IvyMike and bbb discuss permissions for crawling data from Google and redistributing files, touching on the complexities and legal considerations involved in software development and copyright issues.

3. Users tmschmdt and bbb delve into fair use and copyright concerns related to posting files publicly, emphasizing the need for protection and potential legal implications.

4. The discussion expands to MIME types, file formats, cybersecurity methods, file signatures, and data management tools like PhotoRec and Kaitai Struct, shedding light on various aspects of file identification and processing.

5. Users like EnigmaFlare delve into the technical aspects of file identification, highlighting the challenges of predicting file types accurately and the differences between human classification and AI-based tools like Magika.

6. The conversation continues with insights into the unpredictability of file identification, the importance of accuracy in determining file types, and the potential limitations of Magika in handling certain file types.

Overall, the discussion provides a wealth of information and perspectives on file management, AI technology, copyright issues, and practical considerations in software development.

### UI = f(statesⁿ)

#### [Submission URL](https://daverupert.com/2024/02/ui-states/) | 160 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [92 comments](https://news.ycombinator.com/item?id=39399281)

The saying "UI is a function of state" is a popular concept in the front-end development realm, emphasizing the impact of various states on the user interface. Let's delve into the different states that can influence the UI layer:

1. **First-party application states:**
   - **Global state:** Includes data stores and feature gating at the application level, stored in places like Redux, Vuex, or local storage.
   - **Page/Component state:** Examples include loading states, error states, and success states, as outlined in Vince Speelman's Nine States of Design.
   - **Custom states:** Tailored states specific to your application, like realtime multiplayer event messages or scroll positions.

2. **Element states:**
   - Individual elements can have their own states related to HTML, CSS, and ARIA, such as cursor styles, visibility, and pseudo-class states.

3. **ARIA states:**
   - User-facing states reflected in ARIA attributes, like aria-current, aria-expanded, and more.

4. **Second-party user (or device) states:**
   - Factors related to the user's device and browsing environment, such as language settings, network connection, viewport dimensions, and device constraints.

5. **Modalities:**
   - Users interact with devices in various ways, utilizing inputs like mouse, keyboard, touch, gestures, and outputs like screens and speech recognition.

6. **Browser states:**
   - User preferences and browser features, such as color schemes, motion preferences, browser version, and feature support, also play a role in shaping the UI experience.

Understanding and considering these diverse states can help developers create more adaptive and user-friendly interfaces that cater to a wide range of scenarios and user preferences.

The discussion on this submission revolves around various aspects of front-end development, especially the challenges and solutions related to handling different states in UI design. Some users share their experiences and insights regarding the complexities of front-end development, the struggles with synchronizing data, and the use of tools like React and Hasura. Others discuss the difficulties in managing state rendering efficiently and suggest exploring alternatives like HTMX for server-side rendering. Additionally, there are conversations about the importance of properly representing state in UI components, handling form validation, and the intricacies of synchronizing states. Overall, the discussion provides a deep dive into the nuances and dilemmas faced by front-end developers when dealing with UI states and design complexities.

### LLM agents can autonomously hack websites

#### [Submission URL](https://arxiv.org/abs/2402.06664) | 70 points | by [pella](https://news.ycombinator.com/user?id=pella) | [17 comments](https://news.ycombinator.com/item?id=39403534)

The latest from the cryptography and security world: a groundbreaking paper titled "LLM Agents can Autonomously Hack Websites" sheds light on the offensive capabilities of large language models (LLMs). Authored by Richard Fang and his team, this research showcases how LLM agents, particularly GPT-4, can independently hack websites, performing tasks like blind database schema extraction and SQL injections without any human guidance. The study highlights the potential security risks posed by advanced AI agents and raises concerns about their widespread deployment. Dive into the details of this cutting-edge research to explore the implications for cybersecurity.

- **ActorNightly**: Points out that hacking website activity revolves around finding vulnerabilities, and exploiting those vulnerabilities listed in the paper due to mistakes in standard development practices. Mentions that LLMs exist and might be used for security reasons, and expresses uncertainty about LLMs being utilized for looking into Personally Identifiable Information (PII) leaks.
- **wsnks**: Agrees that LLMs could crack typical exploits found on weak websites, bringing up the OWASP10 paper that lists pages greatly cherry-picked for testing hypotheses and the breakthrough it indicates.
- **MattPalmer1086**: Confirms that the attacks' generic descriptions mentioned in the paper are fascinating and highlights the rough approachability ability to make functional calls. Mentions success rates and cost-effectiveness of attacks but also points out that attacking a human thing is a significant security risk.
- **vrptr**: Raises a significant point regarding the comparison of writing processes dedicated to running ready explanations and the concept of LLM, clarifying the program equivalent, and highlighting that security scanning is preceding full exploitation.
- **bemusedthrow75**: Shares OpenAI's IP ranges documented in links provided.
- **tyngq**: Comments on how easy it is to hack OpenAI through IP shifting, referencing a specific pattern.
- **maCDzP**: Hopes OpenAI doesn’t share large bounties.
- **pnqc**: Expresses skepticism about cybersecurity engineers safeguarding against AI.
- **g3ol4d0**: Points out a potentially automated vulnerability scanning tool.
- **your_friend**: Mentions the human tendency to hack websites casually.
- **bbr**: Concludes the discussion by emphasizing the danger of publishing vulnerabilities and how LLM capabilities might be widely available in the near future through APIs like OpenAI Assistants.

### Show HN: Host a planet-scale geocoder for $10/mo

#### [Submission URL](https://blog.ellenhp.me/host-a-planet-scale-geocoder-for-10-month) | 109 points | by [ellenhp](https://news.ycombinator.com/user?id=ellenhp) | [31 comments](https://news.ycombinator.com/item?id=39399064)

On February 16, 2024, a fascinating project was shared on Hacker News about hosting a planet-scale geocoder for just $10/month. The individual behind this initiative embarked on creating a cost-effective geocoder, aiming to overcome the challenge of hosting a planet-scale instance. They managed to develop an address parser inspired by Pelias and utilized tantivy as a search engine, leveraging tantivy-wasm to issue range queries from the browser. By implementing their own backing store for tantivy, they achieved impressive results with acceptable latency of 1-3 seconds, occasionally even as fast as 2ms. Running on Fly.io, the project costs around $10/month, making it highly affordable. The creator plans to expand the geocoder to support more locales and use-cases in the future. An open-source demo site is available for exploration, showcasing the innovative project's capabilities.

1. **lrmyn** pointed out a space-specific use case for the project and shared a link for reference.
   
2. **rmrm** highlighted the importance of S3 support for efficient search options, Quickwit as a distributed search engine, and Tantivy's effectiveness.
   
3. **frncsmsst** elaborated on the database requirements for the project, stating that they are designed for specifically tailored search experiences.
   
4. **hmplm** appreciated the difficulty of geocoding and considered the project a significant step forward.
   
5. **mlhpdx** shared gratitude for the Range Request feature and praised the approach of byte-indexing static objects.
   
6. **killingtime74** expressed admiration for the project.
   
7. **bnrymx** mentioned their interest in trying out the project on a cloud platform similar to Nominatim.
   
8. **llnhp** engaged in a cost comparison between Nominatim on EC2 and the current project, finding some significant differences in costs.
   
9. **bffrvrflw** shared information on AWS server costs for a 64GB RAM server.
   
10. **mcntx** enjoyed exploring the geocoding field further.
   
11. **Gigachad** found the project comparable in cost to Google Maps, sparking a discussion on Google Maps' API predictions.
   
12. **clmntms** mentioned hosting a geocoder for a lower cost per unit.
   
13. **ndsckt** brought up the concept of reverse geocoding.
   
14. **rnwltrd** praised the project creator for their work on the project.
   
15. **CyberDildonics** questioned the expenses associated with geocoders, leading to a conversation about writing one and the challenges involved.
   
16. **chrstngnc** shared their experience with hosting a geocoder and the associated costs.
   
17. **SOLAR_FIELDS** highlighted the challenges of managing multiple geocoders and the support available.
   
18. **ranger_danger** commented about professionalism in responses on Hacker News.
   
19. **CyberDildonics** flagged a comment about geocoding projects linked to various resources.
   

### Recording and visualising the 20k system calls it takes to "import seaborn"

#### [Submission URL](http://blog.mattstuchlik.com/2024/02/16/counting-syscalls-in-python.html) | 106 points | by [sYnfo](https://news.ycombinator.com/user?id=sYnfo) | [45 comments](https://news.ycombinator.com/item?id=39402868)

Today's top story on Hacker News delves into the world of system calls (syscalls) and how to analyze them using a new tool added to Cirron. The tool, called Tracer, allows you to see exactly what syscalls a piece of Python code is making. It works by using the strace tool to trace the system calls, capturing the output in a file for later analysis.

For example, tracing a simple print("Hello") statement reveals that it ultimately maps to a write syscall, writing the string "Hello\n" to stdout with some interesting details like the number of bytes written and the time taken for the call. 

Furthermore, the author tracks the syscalls generated by importing Seaborn library and finds that it results in around 20,000 syscalls which can be overwhelming to analyze manually. To overcome this, they introduce Perfetto Trace Viewer as a tool to visualize and analyze the syscall traces more efficiently. By converting the Tracer output to Trace Event Format, one can load the trace into Perfetto for detailed analysis.

Overall, the article provides a fascinating insight into how syscalls can be traced and analyzed using the Cirron tool, demonstrating a unique way to gain deeper understanding of the system-level operations carried out by Python code.

1. **nsm** commented on the efficiency of Python imports, mentioning the PYTHONPROFILEIMPORTTIME environment variable as a way to visualize the impact of imports on program startup time. They recommended identifying and optimizing the worst imports affecting program startup time. They also suggested checking out the PyOxidizer tool for compiling imports to improve performance.

2. **dmwlcx** shared their experience of transitioning from Python development to learning Forth, expressing frustration with modern programming languages. They mentioned Forth for its speed in executing cloud-based tasks.

3. **jsphg** discussed performance issues in a small web project developed using Flask, highlighting slow page load times and unresponsive behavior due to ORM and database management challenges. Other users shared similar experiences and provided insights into optimizing database queries and improving system performance.

4. **Spivak** recommended utilizing the ImPlot tool for plotting functions instead of developing them from scratch.

5. **xchzhv** provided context on the discussion about syscalls, emphasizing the difference between importing modules that may generate multiple syscalls and efficiently managing system resources to avoid unnecessary overhead.

6. **t8sr** clarified the misconception regarding the number of syscalls generated in plotting functions, pointing out that 20k syscalls are not directly related to plotting but rather to the process of importing modules. They explained the significance of dynamic libraries and the potential impact on performance.

7. **pdns** highlighted the impact of importing libraries on the number of syscalls in Python programs, emphasizing the efficiency of imports and their implications for system performance.

8. **hnlmrg** mentioned Python's handling of system calls and the implications of manually managing them in programming languages.

9. **chx** and **pdns** discussed learning Forth and the fundamental understanding of system calls in programming languages, emphasizing the importance of considering system-level operations in software development.

### Training LLMs to generate text with citations via fine-grained rewards

#### [Submission URL](https://arxiv.org/abs/2402.04315) | 165 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [28 comments](https://news.ycombinator.com/item?id=39399418)

Summary:
The paper titled "Training Language Models to Generate Text with Citations via Fine-grained Rewards" by Chengyu Huang and collaborators addresses the limitations of Large Language Models (LLMs) in producing credible responses by lacking references to reliable sources. The authors introduce a training framework using fine-grained rewards to guide LLMs in generating supportive and relevant citations, enhancing the correctness of their responses. By conducting experiments on Question Answering datasets, the proposed method outperforms conventional practices and even surpasses GPT-3.5-turbo on LLaMA-2-7B. This work contributes to improving the quality of text generation by incorporating in-text citations within language models.

1. **srjstr** commented that starting with smaller models shows promising results, and they are waiting for further results pending the launch of the GPT-4 system. 
   - **chasd00** noted that testing on small contexts is reliable.
   - **3abiton** mentioned about their excitement for the increasing model speed.

2. **skptrn** highlighted the importance of a 100M token context window.
   - **bgglbtl** and **mls** discussed the issues with large context sizes and the utilization of ELIZA for artificial neurons on GPU.

3. **th0ma5** delved into understanding programming intricacies and the importance of precision.
   - **nrdpnx** shared insights on the fundamental stochastic nature of LLMs and their training process.

4. **rbtl-dcy** supported the idea that predictions need to be unbiased and objective, advocating for the importance of including citations for accuracy.

5. **dmzztt** found the approach intriguing and shared a link for those interested in the method.
   - **dng** expressed concerns about promotional content on Hacker News.
   - **jrpnt** and **dmzztt** discussed the RAG method and its limitations.
   - **bgglbtl** expanded on the shortcomings of RAG-based approaches and the challenges faced in ranking and retrieval.

6. **nn-sr-srm** expressed concerns about AI innovations potentially replacing human expertise and the consequences of advancements in AI technology.
   - **phlpswd** shared thoughts on the dangers of over-reliance on AI for writing and its impact on memory and critical thinking skills.
   - **smtmn** commented briefly.

The discussion covered topics such as model sizes, training methodologies, programming nuances, concerns about AI advancements, and the potential implications of relying heavily on AI for various tasks.

### Show HN: I made a Pinterest clone using SigLIP image embeddings

#### [Submission URL](https://mood-amber.vercel.app) | 91 points | by [verse](https://news.ycombinator.com/user?id=verse) | [20 comments](https://news.ycombinator.com/item?id=39392582)

Today's top stories on Hacker News cover a wide range of topics, including the latest trends in technology, discussions on software development practices, and insights into the tech industry. Let's dive into some of the most popular submissions and see what the Hacker News community is buzzing about today.

1. **yrwb** discussed the duplication of results on a particular website, highlighting the issue with duplicate data being scraped. **vrs** commented on the pointing out of the flaw.

2. **llzx** shared a link for others to check out.

3. **mz** expressed interest in a project called SigLIP they have not tried before.

4. **Tiberium** discussed training with Id SigLIP and the performance of datasets using a certain algorithm. **jarebear6expepj** mentioned the availability of vision training models for the project.

5. **wcwrld** mentioned noticing cropped images and criticized the cropping in a specific style of layout. **jkcxn** explained the concept of masonry grid images and suggested proposals for a proper layout.

6. **GamerAlias** praised a project and highlighted its strengths compared to others. **vrs** shared their testing experience with CLIP and Supabase.

7. **sqm** complimented the project.

8. **Yenrabbit** appreciated the creativity in the dataset.

9. **gmmlst** found the source images interesting.

10. **cnvlvtrn** shared a surprising link.

11. **ijhuygft776** mentioned clean improvements and traction, clicking on Pinterest links for a good experience. **krlst** suggested removing Pinterest search results with a Chrome extension to avoid spammy results.

It seems like a mix of discussions around data duplication, project interest, image cropping, search result improvements, and testing experiences with different technologies.

### Video generation models as world simulators

#### [Submission URL](https://openai.com/research/video-generation-models-as-world-simulators) | 353 points | by [linksbro](https://news.ycombinator.com/user?id=linksbro) | [165 comments](https://news.ycombinator.com/item?id=39391458)

Researchers have developed Sora, a cutting-edge video generation model that acts as a world simulator. By training on a vast amount of video and image data, Sora leverages a transformer architecture to generate high-fidelity videos of various durations, resolutions, and aspect ratios. This innovative model, capable of creating one minute of detailed video, signifies a significant step towards constructing all-encompassing world simulators.

Incorporating patches of visual data akin to tokens in language models, Sora transforms videos into a compressed latent space before decomposing them into spacetime patches for training and generation. This approach allows Sora to operate on diverse video and image types effectively. Leveraging a diffusion model within a transformer framework, Sora refines its predictions of clean patches from noisy inputs, showcasing remarkable scaling properties across different domains.

By training on data at its native size rather than conforming to standard dimensions, Sora gains flexibility in sampling videos of varying resolutions and aspect ratios, boosting content creation for different devices and enhancing framing and composition. Moreover, Sora benefits from training on videos with highly descriptive captions, improving text fidelity and video quality. With the capability to generate high-quality videos based on user prompts, Sora represents a significant advancement in video generation technology.

The discussion on this submission revolves around the capabilities and implications of Sora, a cutting-edge video generation model. Some users draw parallels between Sora and existing models while others discuss the potential applications and limitations of advanced AI technology such as AGI. There is also a conversation about the challenges in creating an AI for games like Civilization, with mentions of the need for improved hardware and different strategies for training the AI. Additionally, the discussion touches upon the significance of generalization in reinforcement learning and the potential for AI to predict economic models in games like Civilization. Finally, a user references Yann LeCun's work on Objective-Driven AI and the gradual progress towards achieving AGI through various breakthroughs in AI technologies.

### LWM – Open LLM with 1M Tokens Context Window

#### [Submission URL](https://github.com/LargeWorldModel/LWM) | 153 points | by [amrrs](https://news.ycombinator.com/user?id=amrrs) | [35 comments](https://news.ycombinator.com/item?id=39398631)

Today on Hacker News, there's a buzz around LargeWorldModel/LWM, a fascinating repository with 1.1k stars and 54 forks. The project seems to be gaining traction quickly, with contributors like Wilson Yan, Hao Liu, and Ikko Eltociear Ashimine. The repository primarily uses Python (94.3%) and Shell (5.7%). Stay tuned for more updates on this intriguing project!

The discussion surrounding the LargeWorldModel/LWM repository on Hacker News covers various aspects of the project, including its technical requirements, scalability, and similarities to other models. Contributors delve into details such as the memory requirements for running the model, the inference capabilities, and the potential performance gains from using specific hardware setups like TPU-v4. There are also mentions of related models, the potential licensing of the project, and comparisons with existing frameworks. Overall, the conversation showcases a high level of technical understanding and interest in the nuances of large-context models like the one presented in the repository.

### The fifth epoch of distributed computing

#### [Submission URL](https://cloud.google.com/blog/topics/systems/the-fifth-epoch-of-distributed-computing) | 55 points | by [simonpure](https://news.ycombinator.com/user?id=simonpure) | [42 comments](https://news.ycombinator.com/item?id=39396151)

In a recent keynote by Google Fellow Amin Vahdat, the evolution of computing from its origins to the present era was examined. Over the past fifty years, exponential growth in computing capacity has revolutionized human capabilities, enabling instant access to knowledge, real-time language translation, and advanced AI systems tackling complex challenges. These advancements have led to a need for foundational breakthroughs every decade to sustain progress. Vahdat proposes the concept of a fifth epoch of computing, focused on being data-centric, declarative, and outcome-oriented to democratize access to knowledge and opportunities. Reflecting on computing history, four epochs have already shaped our technology landscape. From the introduction of the first transistor in 1947 to the birth of the modern Internet in 1969, each era marked significant milestones in computing development. The progression through these epochs led to improvements in network communication, high-level programming languages, multi-user operating systems, and the emergence of the ARPANet, laying the groundwork for the exponential growth in subsequent epochs. The move from asynchronous to synchronous communication, the rise of personal computers, and the advent of the World Wide Web symbolize the transformative shifts in computing paradigms over the years. As we stand on the brink of a new era, the fifth epoch of computing promises to redefine how we interact with technology, driven by a data-centric approach and aimed at delivering insights proactively to users.

The discussion on Hacker News about the keynote by Google Fellow Amin Vahdat covers various perspectives on the evolution of computing and the proposed fifth epoch of computing. 

- One user expressed skepticism towards the insights of the article, criticizing its MBA-style language and expecting technical depth. 
- Another user highlighted the shift in the internet landscape over the years, mentioning concerns about consolidation, access to information, and the dangers of intrusive AI. 
- GMoromisato discussed the impact of AI on programming and user experience, emphasizing the potential of AI in simplifying complex tasks in software development. 
- There was a debate about the role of AI in programming and the difficulty of managing increasingly complex systems. 
- The importance of teaching the next generation of programmers was emphasized by one user, suggesting that engineers should focus on sharing knowledge with younger developers. 
- Some users discussed the necessity of declarative programming models focused on business logic due to the increasing complexity in computing. 

Overall, the discussion highlighted concerns, insights, and differing opinions on the future of computing and the impact of AI on software development and technology.

### V-JEPA: Video Joint Embedding Predictive Architecture (V-JEPA) Model

#### [Submission URL](https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/) | 62 points | by [agnosticmantis](https://news.ycombinator.com/user?id=agnosticmantis) | [6 comments](https://news.ycombinator.com/item?id=39392104)

Today, the tech world is buzzing with the release of the Video Joint Embedding Predictive Architecture (V-JEPA), a significant leap towards achieving advanced machine intelligence as envisioned by Yann LeCun. This model excels at understanding detailed interactions between objects in a physical world model. Released under a Creative Commons license, V-JEPA aims to pave the way for more grounded machine intelligence.

V-JEPA operates by predicting missing parts of a video in an abstract space, enhancing training efficiency by up to 6x. The model uses self-supervised learning, pre-training solely with unlabeled data, and then adapts to specific tasks with labeled examples. By focusing on abstract representations rather than specific pixel details, V-JEPA demonstrates improved learning efficiency.

The unique masking strategy of V-JEPA ensures that the model learns complex aspects of the world by predicting masked spatio-temporal regions in videos. This approach makes the model adept at frozen evaluations, enabling efficient adaptation to new skills with minimal additional training.

Excitingly, V-JEPA outshines other video models in label efficiency, proving its effectiveness in low-shot settings. As the tech world marches towards more human-like machine intelligence, V-JEPA's release marks a significant milestone in this journey.

1. **jimmySixDOF** shared a cryptic message about Gemini 15 Sora Magic investment happening at Gemini. Another user, **sbstnnght**, referred to a previous test last year. **jimmySixDOF** then elaborated that the reference was to a benchmark test establishing baseline performance where phrases from the Gemini white paper flashed on the screen, and the model had to compare and predict the performance of Large Language Models (LLMs).

2. **cm** mentioned something about a "Magic investment," and **strmfthr** commented that the development of the Magic platform has received a $100 million investment. The CEO appears to be impressed with the progress towards using Long Context-Optimized LLMs to replace developers.

3. **btshftfcd** noted that Alpha has started training on human data to predict real-world events. They are curious if a similar approach using Large Language Models can ground real-world video prediction with minimal language abilities, suggesting a breakthrough in bootstrapping machine learning laws with physics and mathematics.

The discussion seems to revolve around advancements in AI models like LLMs, their applications in predicting real-world events, and investments in AI development.

### How much electricity does AI consume?

#### [Submission URL](https://www.theverge.com/24066646/ai-electricity-energy-watts-generative-consumption) | 102 points | by [doener](https://news.ycombinator.com/user?id=doener) | [114 comments](https://news.ycombinator.com/item?id=39397161)

Today's top story on Hacker News discusses the energy consumption of AI models, shedding light on the significant power requirements behind machine learning. The article highlights the challenges in accurately estimating the energy cost of AI due to varying configurations and the reluctance of companies to share such data. Training AI models, like GPT-3, is described as highly energy-intensive, with the electricity used equivalent to that consumed by 130 US homes annually. Furthermore, the article discusses the differences in energy usage between training and deploying AI models for inference tasks. Researchers have started to analyze the energy consumption of various AI models, providing insights into the environmental impact of AI technologies. Despite the lack of absolute figures, these studies offer comparative data on the energy costs associated with AI activities. The article raises important questions about the hidden energy expenses of AI systems and emphasizes the need for more transparency in this area.

The discussion on Hacker News regarding the energy consumption of AI models covers various aspects related to the topic. Users discussed the challenges in estimating global energy consumption due to AI and the comparison between different energy-efficient hardware solutions for AI tasks. Some users expressed concerns about the potential increase in energy consumption with the rise of AI technologies and the need for more efficient hardware and software optimizations to mitigate this issue. The conversation also delved into the energy efficiency of data centers, Bitcoin mining, and the implications of AI development on overall energy consumption. Aspects such as the efficiency of GPUs compared to custom ASICs for AI tasks and the potential environmental impact of AI models were also explored. The discussion highlighted the importance of improving energy efficiency in AI systems to address the growing energy demands of emerging technologies.

### Reddit Signs AI Content Licensing Deal Ahead of IPO

#### [Submission URL](https://www.bloomberg.com/news/articles/2024-02-16/reddit-is-said-to-sign-ai-content-licensing-deal-ahead-of-ipo) | 32 points | by [Nas808](https://news.ycombinator.com/user?id=Nas808) | [11 comments](https://news.ycombinator.com/item?id=39404051)

I'm sorry, but I can't browse the internet in real-time to access the latest stories on Hacker News. If you have a specific topic or story in mind that you would like me to summarize, please provide the details, and I'd be happy to help!

- **mnmxr**: Expresses frustration about Reddit limiting public data access to prevent AI scraping, but acknowledges that PushShift dataset still provides interesting results. Shares a blog post analyzing Reddit data.
  - **dpd**: Points out the problem with aggregators not including certain sources and criticizes the API lockdown to protect data.
  - **stvrs**: Disputes the idea that AI scraping facilitates deals and mentions not being a fan of using AI for such purposes.
- **artninja1988**: Mentions paying $60 million for garbage data and scraping content models for incumbents, with a comment wishing a happy cake day to the poster.
  - **cdpc**: Offers a simple "Happy cake day" greeting.
- **Sabinus**: Suggests that API access restriction may be a good move for Reddit's relevance.
- **pstlrt**: Indicates getting sick of Reddit content.
- **CM30**: Draws parallels between AI content licensing on Reddit and potential controversies, mentioning a possible IPO and criticizing Reddit's decisions.
- **shstck**: Asks what is the central point in the comments.
- **dmtrygr**: Lists points related to multi-million dollar deals, IPO price targets, and profit in AI content licensing.
- **jg**: Criticizes the idea of a $5 billion IPO, questioning Meta's interest in Reddit threads and the value proposition of AI content on the platform.

