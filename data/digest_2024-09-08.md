## AI Submissions for Sun Sep 08 2024 {{ 'date': '2024-09-08T17:11:12.553Z' }}

### Serving AI from the Basement – 192GB of VRAM Setup

#### [Submission URL](https://ahmadosman.com/blog/serving-ai-from-basement/) | 291 points | by [XMasterrrr](https://news.ycombinator.com/user?id=XMasterrrr) | [240 comments](https://news.ycombinator.com/item?id=41481852)

In an ambitious endeavor, one dedicated tech enthusiast has embarked on a project to build a high-performance AI server in their basement, featuring a staggering 192GB of VRAM powered by eight RTX 3090 GPUs. Motivated by limitations in his previous setup, which only had 48GB of VRAM, the creator sought to construct a system capable of handling the demanding Meta Llama-3.1 405B model.

The post outlines the nuts and bolts of this impressive machine, from the selection of an Asrock Rack ROMED8-2T motherboard and AMD Epyc Milan 7713 CPU boasting 64 cores, to the intricacies of using PCIe lanes effectively. Key design considerations include leveraging NVLinks for superior data transfer rates, careful attention to power supply needs, and navigating the complexities of PCIe connections to ensure stability and performance.

Future posts promise to dive deeper into the challenges faced during assembly, as well as practical insights on benchmarking inference engines and fine-tuning LLMs. The builder reflects on the rapid evolution of technology, pondering how today's whopping 192GB of VRAM will be viewed two decades from now—definitely a sign of the fast-paced advancements in AI infrastructure!

Stay tuned for more insights from this project as this ambitious DIYer navigates the exciting world of large language models and shares his journey with the community!

The discussion on Hacker News revolves around a user's ambitious project to set up a high-performance AI server, showcasing their journey and technical challenges faced. Key topics of conversation include hardware specifics, power supply considerations, and safety during installation.

1. **User Experiences and Tips:** Users share personal experiences with their own setups and suggest best practices for power management when running multiple GPUs, such as using power conditioning and ensuring safety precautions.

2. **Technical Discussions:** There were detailed exchanges about the technical aspects of machinery setup, including the use of circuit breakers, the need for adequate power supply upgrades, and considerations for operating heavy-duty CPUs and GPUs.

3. **Safety and Legality Concerns:** The group also delves into the safety implications of residential power setups, discussing the potential risks and the importance of adhering to legal regulations when carrying out such installations. Users stress the necessity of professional electrical work to avoid hazards.

4. **General Advice and Future Plans:** Participants express their plans for blogging and sharing further insights into their experiences building AI systems, emphasizing the community's role in collaborative learning and support.

5. **Community Reactions:** Discussions reflect a mix of enthusiasm and skepticism regarding DIY high-performance computing setups at home, highlighting the complexity and risks involved.

Overall, the interchange illustrates a blend of technical know-how, practical advice, and a community-driven spirit in navigating the intricacies of building a powerful AI server.

### GPT-fabricated scientific papers on Google Scholar

#### [Submission URL](https://misinforeview.hks.harvard.edu/article/gpt-fabricated-scientific-papers-on-google-scholar-key-features-spread-and-implications-for-preempting-evidence-manipulation/) | 209 points | by [celadevra_](https://news.ycombinator.com/user?id=celadevra_) | [94 comments](https://news.ycombinator.com/item?id=41477516)

In a revealing study, researchers have highlighted a concerning trend in the academic landscape: the rise of questionable scientific papers generated by generative AI tools like ChatGPT. These papers, which often mimic legitimate scientific writing, are increasingly found across platforms like Google Scholar, where they sit alongside peer-reviewed research, undermining public trust in scientific integrity. 

The researchers analyzed a sample of these AI-generated papers, noting that approximately two-thirds exhibited signs of being produced through undisclosed AI use. Alarmingly, most of these papers focused on sensitive and highly contested areas such as health, the environment, and technology. The presence of such content in the academic discourse raises red flags about disinformation and the capacity for manipulation within the research community.

The implications of this trend are significant; the sheer volume of fabricated studies risks drowning out genuine research and complicates the scholarly communication infrastructure. As AI continues to empower easy generation of scientific-sounding content, the integrity of the scientific record hangs in the balance, presenting societal risks that echo far beyond academia.

As discussions about the role of AI in research gain momentum, the study argues for a critical examination of academic tools like Google Scholar, which, despite its convenience and widespread use, lacks robust standards of transparency and quality control. This calls for an urgent reassessment of how research outputs are curated and evaluated in a rapidly evolving digital landscape.

The discussion surrounding the study on AI-generated scientific papers on Hacker News indicated widespread concern about the impact of generative AI tools, like ChatGPT, on academic integrity. Participants pointed out that a significant number of papers are being produced through these technologies and often lack the depth and rigor expected from real research. 

Several commenters emphasized the problematic nature of using AI in the peer-review process. Critics noted that some reviews generated by these AI systems exhibit a lack of critical engagement, leading to poorer quality in assessments. Others highlighted the growing pressure on conference organizers and reviewers, which complicates their responsibilities. There is a shared anxiety about the implications of AI’s increasing role in generating content, which risks creating a dilution of scholarly rigor and potentially spreading misinformation.

Discussions arose around the structure and incentives within academic publishing that might be encouraging the submission of poorly constructed AI-generated work. Some participants raised concerns about the academic community's response to this trend, suggesting that reliance on AI for summarizing and reviewing could undermine traditional methods of scholarly evaluation. 

Overall, there seems to be a consensus on the need for more transparent quality control measures in academic platforms like Google Scholar to mitigate these risks as the capability of generative AI evolves. The conversation highlighted a critical need for ongoing dialogue about maintaining integrity in scientific communication amidst the rise of AI technologies.

### Why do so many home robots still suck?

#### [Submission URL](https://techcrunch.com/2024/09/01/why-do-so-many-home-robots-still-suck/) | 13 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [17 comments](https://news.ycombinator.com/item?id=41481696)

This September marks the 62nd anniversary of "The Jetsons," spotlighting the iconic Rosie the Robot and the ongoing quest for practical home automation. Despite the domestic robot industry evolving significantly since the Roomba's launch 22 years ago, home robots still largely underdeliver on the futuristic promises we envisioned.

Brian Heater explores the complexities behind this reality in his recent article, asserting that while consumer demand is strong, the technology often falls short due to high costs and operational limitations. Although iRobot has successfully sold over 50 million Roombas, other robotic innovations—like lawnmowers and pool cleaners—have yet to capture widespread consumer interest.

Despite ambitious proposals, like Elon Musk's vision of a multifunctional humanoid robot, the challenge remains: creating reliable machines that can tackle multiple tasks effectively without breaking the bank. Experts agree that future robots will likely need to focus on simplified, single-function roles as they lay the groundwork for more sophisticated designs.

The article reflects on the foundation laid by early devices like the Roomba, showing how they challenged expectations and pushed forward the field of robotics, even if their successors still struggle to achieve the multipurpose capabilities imagined in classic sci-fi. As the industry continues to grapple with these challenges, the dream of a fully functional home robot remains tantalizingly just out of reach.

In the discussion following the article on the unfulfilled promise of home robots, several users expressed mixed experiences with current robotic technologies. A user noted that while their Roomba performed well with mapping, it struggled with small objects and deep cleaning, leading to a preference for traditional vacuuming methods. Others shared their positive experiences with Roborock vacuums, which outperformed Roombas in certain tasks.

The complexity of robot mechanics and the challenges of creating machines that can handle household tasks effectively were highlighted. Discussions also included concerns over battery life and repair costs, which can make robotic purchases less appealing. Some participants brought up innovative concepts, such as combining AI advancements with robotics for more sophisticated home assistants, while others suggested more straightforward robots with specific functions, like fetching items or performing laundry tasks.

Overall, participants reflected on the high expectations set by early robotic designs, acknowledging both the potential for future advancements and the limitations imposed by current technology. There was a consensus that while consumer interest exists, the technology still has a long way to go to meet the sci-fi standards set by classics like "The Jetsons."

