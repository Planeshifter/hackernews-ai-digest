## AI Submissions for Fri Jun 16 2023 {{ 'date': '2023-06-16T17:10:17.354Z' }}

### Meta's plan to offer free commercial AI models puts pressure on Google, OpenAI

#### [Submission URL](https://www.artisana.ai/articles/metas-plan-to-offer-free-commercial-ai-models-puts-pressure-on-google-and) | 211 points | by [Andugal](https://news.ycombinator.com/user?id=Andugal) | [72 comments](https://news.ycombinator.com/item?id=36360452)

Meta, the California-based company formerly known as Facebook, is set to disrupt the AI industry by releasing an open-source language model (LLM) for commercial use. This move challenges other AI giants like Google and OpenAI with their closed-source models. If this shift towards an open-source alternative gains traction, it could revolutionize the AI landscape, making it more affordable and more accessible to companies. Furthermore, Meta would benefit from input from countless AI engineers worldwide, contributing improvements to its core models. Meta released a highly capable open-source LLM, LLaMA, in February 2023, which has already served as a foundation for numerous new open-source AI models developed on top of its core technology.

Some commenters argue that Meta’s strategy will commoditize complements and cut into the profits of AI giants, while others praise the democratization of AI and the advantages of open-source technology. One commenter even drew a comparison between Meta's approach and IBM's approach to personal computing in the 1980s-90s.

### Deep Learning’s Diminishing Returns (2021)

#### [Submission URL](https://spectrum.ieee.org/deep-learning-computational-cost) | 71 points | by [jrepinc](https://news.ycombinator.com/user?id=jrepinc) | [30 comments](https://news.ycombinator.com/item?id=36361906)

Deep learning has become increasingly ubiquitous in applications such as language translation, protein folding prediction, and medical scan analysis, among others. However, the cost of deep learning's improvement is becoming unsustainable. Researchers are nearing the frontier of what their tools can achieve and must find a new way forward to reshape machine learning. Deep learning's rise has been due to powerful computers and the ability to construct networks with more connections and neurons. Early AI systems were rule-based, while today's neural networks incorporate learning with adjustable parameters that are part of flexible computer models that become universal function approximators if large enough.

Commenters bring up various points, including the need for new methods to reduce energy consumption and the potential for small models to be more efficient than larger ones. Some also discuss the need to address the environmental impact of deep learning research. Overall, the conversation highlights the challenges and potential solutions for creating sustainable and efficient deep learning models.

### The Distributed Tensor Algebra Compiler (2022)

#### [Submission URL](https://arxiv.org/abs/2203.08069) | 35 points | by [yeesian](https://news.ycombinator.com/user?id=yeesian) | [6 comments](https://news.ycombinator.com/item?id=36349110)

The DISTAL compiler for dense tensor algebra has been introduced, targeting modern distributed and heterogeneous systems. The new system enables users to independently describe how tensors and computation map onto target machines through separate format and scheduling languages. The compiler generates code that is competitive with optimized codes for matrix multiplication on 256 nodes of the Lassen supercomputer. It outperforms existing systems by between 1.8x to 3.7x, with a 45.7x outlier, on higher order tensor operations. The combination of choices for data and computation distribution creates a large design space that includes many algorithms from both the past and the present.

The discussion in the comments of this Hacker News submission revolves around the recently introduced DISTAL compiler, which targets distributed and heterogeneous systems for tensor algebra. One user is interested in discussing the scheduling of algebraic expressions and computation checkpointing on these distributed platforms, as well as the difficulties involved in designing homogeneous compute clusters. Others in the thread recommend looking into tensor compilers like MLIR/LLVM, the Plyhedral sparse_tensor tc, and Dask for related work. There is also discussion of the intersection of algebraic structures with machine learning and the importance of scheduling computations on volunteer machines. One user provides links to papers on TACO, which is a project aimed at distributed sparse tensor computations that may be worth looking into.

### Building “A Young Lady's Illustrated Primer” (2011)

#### [Submission URL](https://proto-knowledge.blogspot.com/2011/11/building-young-ladys-illustrated-primer.html) | 18 points | by [ctoth](https://news.ycombinator.com/user?id=ctoth) | [11 comments](https://news.ycombinator.com/item?id=36349395)

A Young Lady's Illustrated Primer from Neal Stephenson's book "The Diamond Age" is a futuristic educational technology that provides personalized, interactive learning experiences. It mimics a cognitive apprenticeship where the book models a skill through fairy tale characters and the learner imitates it. Currently, educational technology has early examples of adaptive tutoring systems, but not an artificial intelligence that can mentor learners in real-life complex problems. However, the One-Laptop-Per-Child teaching software, inspired by the primer, includes an evolving, personalized narrative called "Nell" that helps children learn without the traditional teaching methods.

The discussion includes skepticism about the effectiveness of such technologies and suggests the importance of maintaining real-life interactions in the learning process. Additionally, participants discuss other AI-powered educational resources like the Global Learning XPRIZE and Khan Academy. Some commenters express their interest in the technology, while others find it slightly tangential to the topic.

### CUDA Accelerated Raytracer

#### [Submission URL](https://github.com/maxilevi/raytracer) | 65 points | by [maxilevi](https://news.ycombinator.com/user?id=maxilevi) | [18 comments](https://news.ycombinator.com/item?id=36349893)

Maxilevi's raytracer is a C++ program that can rasterize defined scenes and output .tga files. It supports custom models and runs calculations either on the CPU using C++11 threads or on the GPU through CUDA. The program implements several eye candy features like ambient occlusion, diffuse and metal shading as well as perpective camera and UV mapping. It also optimizes collision detection with a Bounding Volume Hierarchy (BVH) and simulates diffuse lighting. The project is still in progress, but benchmarks and more lights are expected to be added soon.

The submission is about Maxilevi's raytracer, a C++ program with several eye candy features like ambient occlusion, diffuse and metal shading, and perspective camera and UV mapping. The program optimizes collision detection with a Bounding Volume Hierarchy (BVH) and simulates diffuse lighting. The discussion around the submission includes several comments on related projects, such as a path tracer that can run on a GPU using CUDA, a web browser-compatible material model lighting, and Blender's CUDA-cclrtd rytrcng. Some users also express interest in learning more about raytracing and electrical engineering, while others congratulate the developer on their project.

### Do Foundation Model Providers Comply with the EU AI Act?

#### [Submission URL](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html) | 65 points | by [latentdeepspace](https://news.ycombinator.com/user?id=latentdeepspace) | [66 comments](https://news.ycombinator.com/item?id=36352137)

In a recent blog post, Stanford researchers evaluate major foundation model providers such as OpenAI and Google for their compliance with the proposed EU law on AI. The researchers found that these providers largely do not comply with the draft requirements, particularly with regards to adequate disclosure of information regarding data, compute and deployment of their models, as well as key characteristics of the models themselves. The EU AI Act is the world’s first comprehensive regulation governing AI and will impose requirements for AI not only in the EU but also set a precedent for AI regulation around the globe. The researchers recommend prioritizing transparency to hold foundation model providers accountable.

However, in this discussion, some users argue that the EU's proposed requirements are misguided and that foundation models are not the high-risk AI systems that the EU is targeting. Others debate the practicality of the proposed requirements for tracking energy consumption of AI systems and express concern about the potential negative impact on innovation.

### The workers already replaced by artificial intelligence

#### [Submission URL](https://www.bbc.com/news/business-65906521) | 34 points | by [pg_1234](https://news.ycombinator.com/user?id=pg_1234) | [14 comments](https://news.ycombinator.com/item?id=36353351)

Artificial Intelligence (AI) is becoming more prevalent in the workforce, raising concerns about job displacement for human workers. Copywriter Dean Meadowcroft was replaced by an AI system that could process content in 10 minutes instead of 60-90, but he has since changed jobs and now works alongside AI to provide employee assistance. Similarly, voiceover artist Alejandro Graue had work taken over by an AI-generated voiceover system, but it was ultimately unsuccessful due to poor quality. Despite these setbacks, AI will likely continue to be integrated into the workforce and could displace jobs across administrative and legal professions.

The comments on the post discuss various applications of AI in fields such as customer service and creative content creation. The discussion also touches on the potential disruption AI could cause in various industries and raises concerns about copyright and intellectual property laws in relation to AI-generated content. Overall, the comments reflect a mix of skepticism and intrigue towards the integration of AI into the workforce.

