## AI Submissions for Thu Sep 28 2023 {{ 'date': '2023-09-28T17:10:27.204Z' }}

### Show HN: Generative Fill with AI and 3D

#### [Submission URL](https://github.com/fill3d/fill) | 319 points | by [olokobayusuf](https://news.ycombinator.com/user?id=olokobayusuf) | [87 comments](https://news.ycombinator.com/item?id=37695530)

Introducing Fill 3D: Generative fill in 3D. This project is a stripped-down version of fill3d.ai and is powered by Function. Fill 3D allows you to create beautiful, intricate designs in three dimensions. Simply clone the repository, rename `.env.example` to `.env.local`, and paste your Fill 3D API key in the `.env.local` file. Then run `npm run dev` in the terminal to start the development server. You're now ready to unleash your creativity and fill the world with stunning 3D designs! PRs are welcome, so feel free to contribute to this exciting project. Check out the GitHub repository for more details.

The discussion regarding the submission "Introducing Fill 3D: Generative fill in 3D" covers various topics. 

- Users discuss the potential use cases for Fill 3D in real estate, with some suggesting that it could prevent real estate marketplaces from showing fake pictures. Others mention the challenge of accurately representing properties without misrepresentation. 
- Some users mention the need for examples of different room types and interiors, while another user suggests creating a gallery page to showcase the capabilities of Fill 3D. 
- The discussion also touches on the use of Fill 3D in decorating apartments and creating 3D models of furniture. Some users share their experiences with similar tools and technologies. 
- There is a debate about the feasibility and usefulness of augmented reality (AR) in real estate. Some argue that AR is not immersive enough, while others mention the limitations of current AR technology. 
- Users also discuss the potential business model for Fill 3D, with one user mentioning the idea of integrating it with a Multiple Listing Service (MLS). Another user suggests the possibility of creating a subscription model for real estate agents. 
- The technical aspects of Fill 3D are also discussed, including the generation of 3D models and the use of AI for searching and rendering. Some users provide suggestions for improvements and offer insights into related technologies. 
- The issue of licenses and copyright infringement is brought up, with some users expressing concerns about misuse of the software. 
- Other topics mentioned include creating 3D renderings, the advantages of using Gaussian splits, creating screen casts, virtual staging, and replacing objects in an image.

### AI language models can exceed PNG and FLAC in lossless compression, says study

#### [Submission URL](https://arstechnica.com/information-technology/2023/09/ai-language-models-can-exceed-png-and-flac-in-lossless-compression-says-study/) | 74 points | by [belter](https://news.ycombinator.com/user?id=belter) | [40 comments](https://news.ycombinator.com/item?id=37691535)

Researchers from DeepMind have discovered that their large language model, Chinchilla 70B, can perform lossless compression on images and audio data, outperforming algorithms specifically designed for these tasks. In a research paper titled "Language Modeling Is Compression," the team details how Chinchilla compressed image patches from the ImageNet database to 43.4% of their original size, surpassing the PNG algorithm's compression rate of 58.5%. For audio data, Chinchilla achieved a compression rate of 16.4% compared to FLAC compression at 30.3%. This finding suggests that language models like Chinchilla can be used not only for text prediction and writing but also for effectively compressing various types of data. The relationship between compression and intelligence is a topic of ongoing debate and research.

The discussion around the submission on Hacker News covers various points related to the findings of the DeepMind research paper titled "Language Modeling Is Compression."

- Users discuss the surprising results of Chinchilla 70B, a large language model, outperforming specialized compression algorithms for image and audio data compression.
- Some commenters mention that language models like Chinchilla can generalize and compress different types of data beyond text, which suggests practical applications for large-scale compression.
- There is a discussion about the benefits of distributed compression and the use of distributed hash tables for file sharing.
- One user suggests that the Chinchilla model may be beneficial for compressing small subsets of larger dictionaries.
- The relationship between language modeling and compression is explored, with comments noting the role of probability modeling and entropy coding in compression algorithms.
- There is further discussion on the efficiency of different compression methods, including the usage of lookup tables and specific algorithms like LZW for PNG compression.
- Some users speculate on the potential benefits and limitations of using large language models for compression, especially in relation to network connections and device limitations.
- The topic of information compression in AI language models and the need for mathematical proofs and algorithms specifically tailored to these models is brought up.
- Commenters discuss the historical relevance of mathematicians and computer scientists in finding exact mathematical relationships for specific compression algorithms.
- The potential approach of starting with simple compression algorithms and language models and iteratively improving and exploring mathematical bounds is mentioned.
- The importance of incremental research and the role of mathematicians in finding exact mathematical relationships is noted.

Overall, the discussion touches upon the surprising findings of the research paper and explores various aspects related to the use of language models for compression and the mathematical foundations behind them.

### RZK: Experimental proof assistant for synthetic ∞-categories

#### [Submission URL](https://github.com/rzk-lang/rzk) | 58 points | by [adamnemecek](https://news.ycombinator.com/user?id=adamnemecek) | [43 comments](https://news.ycombinator.com/item?id=37692166)

Introducing rzk: An Experimental Proof Assistant for Synthetic ∞-Categories

rzk is an experimental proof assistant based on a type theory for synthetic ∞-categories. Built as a way to bring Riehl and Shulman's 2017 paper to life, rzk aims to implement a proof assistant capable of checking various formalizations. It currently offers an online playground for testing, with larger formalizations available in related projects. The implementation uses a version of second-order abstract syntax and aims to support dependent type inference in the future. An important component of rzk is a tope layer solver, which functions as a theorem prover for a part of the type theory. Additionally, rzk plans to incorporate a project called simple-topes, which supports user-defined cubes, topes, and tope layer axioms. This expansion will allow for formalizations of cubical, globular, and other geometric versions of HoTT. For smaller formalizations, users can utilize the online playground, while larger and multi-file formalizations can be installed locally using the latest stable or development version of rzk. There is also a VS Code extension available on the Marketplace for syntax highlighting and other features.

The submission is about rzk, an experimental proof assistant for synthetic ∞-categories. The discussion on Hacker News includes various comments discussing the topic. Some users discuss the implementation and features of rzk, while others discuss category theory and its relevance to computer science and mathematics. There is also a mention of the influence of category theory on programming languages like Haskell and the connection between category theory and the development of modern programming languages and libraries.

