## AI Submissions for Sun May 28 2023 {{ 'date': '2023-05-28T17:11:43.785Z' }}

### Easy Effects: Audio effects for PipeWire applications

#### [Submission URL](https://github.com/wwmm/easyeffects) | 148 points | by [marcodiego](https://news.ycombinator.com/user?id=marcodiego) | [34 comments](https://news.ycombinator.com/item?id=36108927)

Easy Effects is a collection of audio effects for PipeWire applications that includes limiter, compressor, convolver, equalizer, and auto volume plugins. Previously known as PulseEffects, the application was renamed to Easy Effects after it started using GTK4 and native PipeWire filters. Users have full control over the order of effects with the up/down arrows next to the effect labels on the left side. Easy Effects requires a number of dependencies including plugins from Linux Studio and Calf Studio, libebur128, Zamaudio, zita-convolver, soundtouch, and RNNoise. Easy Effects can be installed via Flatpak or via package managers on Linux distributions. Donations are welcome to help with further development of the project.

While users have praised its effectiveness, some have criticized the UI design as not suitable for touchscreens and lacking respect for the display's space. Nonetheless, it has been recommended for projects like Noise Reduction, filtering, and software graphic equalizers. Other users discussed a variety of related topics, such as alternative effects libraries with GitHub links, headphone parameters, multi-device redirection, among others.

### The halting problem is decidable on a set of asymptotic probability one (2006)

#### [Submission URL](https://projecteuclid.org/journals/notre-dame-journal-of-formal-logic/volume-47/issue-4/The-Halting-Problem-Is-Decidable-on-a-Set-of-Asymptotic/10.1305/ndjfl/1168352664.full) | 145 points | by [Schiphol](https://news.ycombinator.com/user?id=Schiphol) | [116 comments](https://news.ycombinator.com/item?id=36105717)

A new study by researchers at the University of Notre Dame, has found that the halting problem for Turing machines is decidable on a set of asymptotic probability one. The result is dependent on the particular computational models used and has significant implications for the future of computing and computational theory. Some commenters discussed their experiences solving the Brainfuck problem and creating non-halting programs. Others discussed the implications of the study, including the possibility of future developments in computing and computational theory. Some commenters discussed the lambda calculus and its role in describing mathematical functions and programs. There was also discussion of the definition of state space and its relationship to program checking and software verification.

### Retrowin32: Async, DLL loading, tracing execution, and Zig

#### [Submission URL](https://neugierig.org/software/blog/2023/05/retrowin32-async-dll-tracing-zig.html) | 78 points | by [goranmoomin](https://news.ycombinator.com/user?id=goranmoomin) | [12 comments](https://news.ycombinator.com/item?id=36104608)

The author of retrowin32, a Win32 emulator, has been working on loading external DLLs to play music in a demo. However, the DLL loading function uses a DllMain that needs to be invoked when the DLL is loaded for initialization purposes, which required some effort to figure out. To handle this, the author used Rust's async support to define EnumDisplayModes, which awaits a call to a callback and can potentially generalize well to cases where emulated code wants to synchronously perform an operation that ends up asynchronously in the web platform. To isolate a bug in the emulator that causes the demo to fail a self-check, the author wrote a Windows debugger program in Zig to introspect a debuggee's behavior. The author also explains the interesting parts of how a debugger works, which involves overwriting an address with an int3 instruction to stop execution at a certain point.

The discussion on this submission covers several topics related to Windows development and debugging. One user discusses their experience with disassembling native Windows machine code and finding undocumented parts of the architecture, while another suggests that many software programs don't use Windows system calls directly. A few users share their thoughts on DLL usage in Windows and some of the problems they've encountered, including the potential for proxy DLLs to interfere with the workings of an application. One user suggests that a proxy DLL located alongside the .exe file may work better than one located in the system directory. Overall, users seem to find the submission informative and share their own experiences and insights on the topic.

### Mirages: On Anthropomorphism in Dialogue Systems

#### [Submission URL](https://arxiv.org/abs/2305.09800) | 38 points | by [frabcus](https://news.ycombinator.com/user?id=frabcus) | [18 comments](https://news.ycombinator.com/item?id=36102082)

A new paper titled "Mirages: On Anthropomorphism in Dialogue Systems" warns about the potential harm of encouraging people to relate to automated dialogue systems as if they were human. The authors argue that conscious and unconscious design choices can guide users to personify these systems to varying degrees, which can lead to transparency and trust issues, as well as high-risk scenarios due to over-reliance on their outputs. They recommend that future dialogue system developers take particular care in their design, development, release, and description, and attend to the many linguistic cues that can elicit personification by users.

Some individuals argue that the linguistic expressions used in dialogue systems do not necessarily imply anthropomorphism. Others believe that it is essential to develop dialogue systems that integrate natural language models to prevent anthropomorphization. There is a debate about whether confabulation and hallucination justify anthropomorphism, with some arguing that dialogue systems do not convey non-factuality or correctness in answers to the expected response. The discussion also touches on the benefits and harms of using linguistic factors that contribute to anthropomorphism and gender and cultural stereotypes.

### Large language models do not recognize identifier swaps in Python

#### [Submission URL](https://arxiv.org/abs/2305.15507) | 73 points | by [lnyan](https://news.ycombinator.com/user?id=lnyan) | [98 comments](https://news.ycombinator.com/item?id=36101429)

A new paper titled "The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python" explores the limits of large language models (LLMs) in understanding programming. The authors demonstrate that despite their impressive performance, LLMs lack a deep understanding of programming semantics, particularly invariances and equivariances like the renaming of identifiers. This shortcoming makes them unsuitable for tasks that statistically deviate from their training data, and even increases prediction errors with larger model sizes - an instance of the phenomenon known as Inverse Scaling.

The discussion in the comments covers a variety of topics, including the usefulness of LLMs for certain tasks, the limitations of training data, the reliability of LLMs, and the differences between human understanding and that of LLMs. Some commenters express disappointment in the level of credulity given to LLMs and suggest that the limitations of artificial intelligence should be more widely acknowledged.

