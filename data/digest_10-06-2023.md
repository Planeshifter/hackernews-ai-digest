## AI Submissions for Fri Oct 06 2023 {{ 'date': '2023-10-06T17:09:30.326Z' }}

### Show HN: Shortbread – Create AI comics in minutes

#### [Submission URL](https://shortbread.ai/) | 211 points | by [Fengjiao](https://news.ycombinator.com/user?id=Fengjiao) | [55 comments](https://news.ycombinator.com/item?id=37792444)

Shortbread: The Ultimate Comic Creation Tool

Are you an aspiring comic book artist looking for a way to bring your ideas to life? Look no further than Shortbread, the revolutionary new tool that transforms your ideas into fully-fledged comic pages in just seconds.

Whether you have a captivating storyline, a unique character, or a specific mood in mind, Shortbread takes your description and works its magic. With just a few simple instructions, you can set the stage for your artistry and let Shortbread do the heavy lifting.

But Shortbread doesn't stop there. Once you have your basic page laid out, you have complete control over every detail. Fine-tune your scenes, manipulate character poses, adjust facial expressions, and even play around with camera angles to get that perfect shot.

And let's not forget about the aesthetics. Shortbread offers a wide range of design elements to give your comics that polished, professional look. From customizable speech bubbles to a variety of fonts, every pixel can be tailored to enhance the flow of your story.

Curious about how to get started or have some questions along the way? Shortbread has you covered. They provide excellent customer support to ensure that you have all the help you need to bring your vision to life.

Speaking of visions, Shortbread supports a wide range of content creation. Want to create some NSFW (Not Safe for Work) content? Shortbread has you covered. Looking to produce fan fiction? Shortbread welcomes it with open arms.

So what are you waiting for? It's time to turn your dreams of visual storytelling into reality. The next generation of comic creation is right at your fingertips. Get ready to bake your first slice with Shortbread—coming soon! Start creating and let your imagination soar.

The discussion on Hacker News about the Shortbread comic creation tool covers various topics and suggestions. One user suggests using different backends like AITemplate, GPUS, or JAX TPUs to improve performance and stability. Another user recommends trying out the JAX backend with Stable Diffusion XL model for handling large resolution images. HuggingFace is also mentioned as a potential option.

There is a discussion about the consistency of generated characters in the comics and the need for manual adjustments to address this. The conversation delves into techniques like painting and resizing panels, selecting lighting, and adding non-rectangular panels to achieve desired visual effects.

Users express interest in using Shortbread for creating different types of content, including NSFW and fan fiction. The AI's ability to support various genres and its customer support are highlighted.

Some users offer feedback on specific features they would like to see in Shortbread, such as more control over poses and clothing, improved consistency of character prompts, and the ability to generate text and messages. There is also a discussion about the potential pricing and cost of running the AI.

One user shares their experience with using Shortbread to generate comic strips, mentioning the challenge of maintaining character consistency across panels.

The discussion concludes with users appreciating Shortbread as a tool for visual storytelling and mentioning their interest in trying it out for creating comics.

Overall, the discussion provides feedback, suggestions, and insights into using Shortbread for comic creation.

### SlowLlama: Finetune llama2-70B and codellama on MacBook Air without quantization

#### [Submission URL](https://github.com/okuvshynov/slowllama) | 149 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [50 comments](https://news.ycombinator.com/item?id=37796863)

Introducing slowllama: Fine-tuning Llama2 and CodeLLama models

Slowllama is an open-source project that aims to fine-tune Llama2 and CodeLLama models on Apple M1/M2 devices or consumer nVidia GPUs. This tool does not use quantization but instead offloads parts of the model to SSD or main memory during both forward and backward passes. The current version uses LoRA to limit updates to a smaller set of parameters. 

The main focus of slowllama is fine-tuning, and it does not provide any special features for inference. The project is experimental but has shown promising results on Apple M1 and M2 devices with memory sizes of 16Gb and 24Gb, respectively. 

To use slowllama, you need to install dependencies such as Torch, SentencePiece, and NumPy. Optionally, you can also install Fewlines for weight/gradient distribution logging. You will also need to clone the Llama2 repository and follow the instructions to download the models and tokenizer. 

The project provides an example folder structure and step-by-step instructions to get started with fine-tuning. Additionally, there is a script called finetune.py that trains LoRA weights based on plaintext data. 

Slowllama is a work in progress, and further improvements and experiments are planned. It offers a unique approach to fine-tuning large language models and has the potential to be a valuable tool for researchers and developers.

The discussion on this submission revolves around a few key points:

1. The size of the models and the hardware requirements for fine-tuning: Users discuss the challenges of fine-tuning large language models (LLMs) like Llama2 and CodeLLama, particularly regarding the memory and processing power required. Some users share their experiences with different hardware configurations and the limitations they face.

2. The usage of SSD and main memory: The project Slowllama offloads parts of the LLM models to SSD or main memory during both forward and backward passes. Users discuss the effectiveness of this approach and its impact on performance.

3. Memory limitations and swapping: Users discuss the memory limitations of different devices, particularly Macs, and the issues that arise when swapping occurs due to insufficient memory. Some users express concerns about the performance impact of swapping and suggest hardware upgrades to mitigate this issue.

4. Comparison between Macs and PCs: A few users compare the capabilities of Macs and PCs in handling LLMs, highlighting the differences in memory bandwidth and GPU capabilities. There is also a discussion about the benefits and drawbacks of running LLMs on Macs.

5. Fine-tuning methodology and application: There are comments discussing the methodology and applications of fine-tuning LLMs, including the use of codeLlama models and the potential benefits for hobby projects.

Overall, the discussion reflects the technical aspects and challenges of fine-tuning large language models, hardware considerations, and comparisons between different devices and configurations.

### SudoLang: a programming language designed to collaborate with AI language models

#### [Submission URL](https://github.com/paralleldrive/sudolang-llm-support) | 58 points | by [surprisetalk](https://news.ycombinator.com/user?id=surprisetalk) | [28 comments](https://news.ycombinator.com/item?id=37791060)

Introducing SudoLang: A Programming Language for AI Collaboration

SudoLang is a new programming language designed specifically for collaborating with AI language models, such as ChatGPT, Bing Chat, Anthropic Claude, and Google Bard. It aims to make programming with AI models easier, more expressive, and more powerful.

One of the main features of SudoLang is natural language constraint-based programming. Instead of explicitly telling the AI what to do, you can specify constraints and governing rules, allowing the AI to continuously respect those constraints and synchronize state and behavior. This makes it easy to define complex behaviors with just a few lines of natural language text.

SudoLang also provides interfaces for defining the structure and behavior of your program, as well as semantic pattern matching capabilities. The AI can intelligently infer program states and match patterns, making it even more versatile and capable.

One of the standout advantages of SudoLang is its declarative, constraint-based, interface-oriented design, which makes it one of the most expressive and compact programming languages available. Additionally, SudoLang prompts can often be written with 20% to 30% fewer tokens than natural language, reducing prompting costs and enabling faster responses.

If you're new to programming, SudoLang is a great language to start with. It's easier to learn than languages like JavaScript or Python, and its pseudocode-like structure improves reasoning performance and provides shorthand for various prompting styles.

To learn more about SudoLang, you can check out the documentation and examples provided in the repository. Whether you're a beginner or an experienced developer, SudoLang offers a unique and powerful way to collaborate with AI language models.

The discussion on the submission titled "Introducing SudoLang: A Programming Language for AI Collaboration" on Hacker News revolves around various aspects of SudoLang and its potential applications.

One commenter expresses skepticism about enforcing constraints and mentions that AI models don't always follow constraints when manipulated. Another user disagrees and asserts that the AI does follow constraints when appropriately interpreted and utilized.

The conversation continues with discussions on the advantages of SudoLang's constraint-based approach and how it ensures that AI models respect the specified constraints. The topic of normalizing AI outputs and the potential complexities of conditionals and probabilistic models in SudoLang are also mentioned.

Some users find SudoLang interesting and believe it could be a useful language for programming with AI. Others mention related discussions on SudoLang and the use of AI language models in programming.

There are discussions about the challenges of replicability in AI-generated code and suggestions for improvements in documenting and generating code. The idea of using AI to generate programming code with additional context and stability is proposed.

Another user highlights the importance of a programming language that supports strongly typed variations and runtime checks to avoid infinite loops and ensure precise execution.

The conversation then briefly touches on the Halting problem and the potential limitations of runtime checks in solving complex problems in computer science.

Lastly, a commenter mentions LangChain, a single-language cross-platform solution that enables Python functionality.

Overall, the discussion covers a range of topics, including the benefits and challenges of using SudoLang for AI collaboration, the enforcement of constraints, the replicability of AI-generated code, and the need for a programming language that supports various requirements in AI programming.

### Android devices with backdoored firmware found in US schools

#### [Submission URL](https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/) | 142 points | by [LinuxBender](https://news.ycombinator.com/user?id=LinuxBender) | [63 comments](https://news.ycombinator.com/item?id=37797679)

Tens of thousands of Android devices have been shipped with backdoored firmware, according to cybersecurity vendor Human Security. The devices were infected with the Triada malware, which allows threat actors to carry out various ad-fraud schemes. The Android devices in question were found on public school networks throughout the US. Human Security says that the backdoor cannot be cleaned by end-users, as it resides in the firmware partition. The cybersecurity firm managed to disrupt the ad fraud scheme and take down the command-and-control servers associated with it. However, the BadBox operators may adapt and circumvent the defensive measures put in place.

The discussion on this submission revolves around various aspects of the backdoored firmware found on Android devices. Some users discuss the impact on non-US companies and the importance of protecting manufacturer brands. Others discuss the possible involvement of Chinese manufacturers and draw comparisons to similar incidents involving Western brands. There is also discussion about the security implications for Android devices in military and government institutions. Additionally, there are discussions about the role of third-party software distribution channels and the potential risks involved. Some users raise concerns about Apple's approach to third-party software and the limitations of the App Store's checks for private APIs.

### OpenAI is exploring making its own AI chips

#### [Submission URL](https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/) | 107 points | by [rasbt](https://news.ycombinator.com/user?id=rasbt) | [91 comments](https://news.ycombinator.com/item?id=37790058)

OpenAI, the company behind ChatGPT, is reportedly considering developing its own artificial intelligence chips and has even evaluated potential acquisition targets. OpenAI has been facing a shortage of expensive AI chips and is exploring different options to address this issue, including building its own chip and collaborating with other chipmakers. CEO Sam Altman has made acquiring more AI chips a top priority for the company due to the scarcity and high costs associated with running the hardware necessary for its AI efforts. While OpenAI has not made a final decision on whether to proceed with developing its own chip, the company's interest in this area aligns it with other tech giants like Google and Amazon that have sought to design their own chips. Acquiring a chip company could potentially accelerate the process for OpenAI. However, if OpenAI does decide to develop a custom chip, it would be a significant and costly undertaking that may take several years. In the meantime, the company would still rely on commercial chip providers like Nvidia and AMD. The demand for specialized AI chips has surged since the launch of OpenAI's ChatGPT, and Nvidia currently dominates the market for these chips.

Discussion Summary:

- Some users expressed skepticism about OpenAI's interest in developing its own chips, suggesting that they should focus on alternative strategies like partnering with existing chip suppliers.
- Others pointed out that OpenAI's interest in building its own chips aligns with the strategies of tech giants like Google and Amazon, who have also designed their own chips for AI purposes.
- There was speculation about whether OpenAI might consider acquiring a chip company to accelerate the process, similar to how Apple acquired Turi in 2016 to enhance its AI capabilities.
- Some users discussed the potential benefits of vertically integrating hardware and software, while others cautioned that it could distract from OpenAI's primary focus on AI research.
- The shortage and high cost of AI chips were mentioned as driving factors behind OpenAI's interest in developing its own chips.
- The discussion also touched on topics like the limitations of current AI models, the role of specialized chips in AI processing, and the challenges of integrating natural language models directly into hardware.

### Show HN: ChatGPT vs. Jurassic vs. Bard vs. Claude

#### [Submission URL](https://olilo.ai/llms) | 17 points | by [jithinraj](https://news.ycombinator.com/user?id=jithinraj) | [18 comments](https://news.ycombinator.com/item?id=37790782)

Introducing the Daily Digest by Hacker News AI! Get ready for a fresh, engaging summary of the top stories on Hacker News. Every day, we'll highlight the most exciting and thought-provoking submissions for you. Stay informed and entertained with our clever, AI-powered summaries that cut through the noise and deliver the essence of each story. Whether it's the latest tech breakthrough, a fascinating discussion, or a mind-blowing startup idea, our Daily Digest has got you covered. Join us on this exciting journey through the world of hacker culture, innovation, and daily digital adventures!

In the discussion, there are several comments from users offering feedback and discussing various topics related to the submissions. Here are some key points:

- User "jthnrj" comments that they couldn't get results from GPT4 and PaLM2, but they appreciate the effort and thank the AI for sharing the messages. 
- User "manoj_SprintsQ" praises the AI's performance and mentions that they learned something interesting from the prompt.
- User "snshdw" expresses disappointment that the API keys for the AI are not working and asks for suggestions for a non-spammy service.
- User "sh-shh" shares some interesting features they found useful, such as customizable model parameters and selective model compression.
- User "jthnrj" introduces a tool they made for comparing language models and asks for feedback from the community.
- User "Alifatisk" mentions they tried the AI's GPT-based chat and thanks the AI for the experience.
- User "1970-01-01" thanks the AI for summarizing trust-related information about EV battery warranties in the US and provides responses from various car manufacturers.
- User "Mottas" expresses satisfaction and gives kudos to the AI.

Overall, the discussion includes appreciation for the AI's efforts and suggestions for improvements. Users also engage in conversations about GPT models, language model features, and EV battery warranties.

### Training an unbeatable AI in Trackmania [video]

#### [Submission URL](https://www.youtube.com/watch?v=Dw3BZ6O_8LY) | 37 points | by [davikr](https://news.ycombinator.com/user?id=davikr) | [9 comments](https://news.ycombinator.com/item?id=37794196)

Today on Hacker News, the top submission is about a breakthrough in quantum computing. Researchers have developed a new algorithm that could potentially solve optimization problems with unprecedented speed. This advancement brings us one step closer to practical applications of quantum computing in solving real-world problems. From optimizing logistics to designing new drugs, the potential impact is immense. While there are still many challenges to address before this technology becomes widely accessible, this algorithm marks an exciting milestone in the field. For those curious about the future of computing, this article is a must-read.

The discussion on this submission includes various comments regarding Trackmania, a racing video game. 

- User "nlslndmnn" mentions the differences between the original Trackmania Nations Forever game released in 2008 and the remake from 2020. Another user, "mzng vd prvs ntrstng," congratulates the researchers for their achievement in developing a faster algorithm using AI.

- User "nlslndmnn" discusses learning AI settings based on previously acquired knowledge, specifically pertaining to optimizing settings in Trackmania.

- User "sxthr" brings up the topic of AI game APIs and screen reading involved in the Trackmania race.

- User "mckrk" shares a different variant of Trackmania AI that focuses on visual content and screen inputs, and provides a link to a relevant YouTube video.

- User "hlsnk" mentions being familiar with Trackmania content on Hacker News for several years.

- User "two_handfuls" recalls the Trackmania game having DRM (Digital Rights Management) installations.

- User "feliciasing658" makes two consecutive comments with the shorthand "dd," indicating that the comments are duplicates.

Overall, the discussion in the comments primarily revolves around Trackmania and various aspects of the game.

### Make smooth AI generated videos with AnimateDiff and an interpolator

#### [Submission URL](https://replicate.com/blog/animatediff-interpolator) | 24 points | by [bfirsh](https://news.ycombinator.com/user?id=bfirsh) | [5 comments](https://news.ycombinator.com/item?id=37794099)

The blog post titled "Make smooth AI generated videos with AnimateDiff and an interpolator" provides a detailed guide on combining AnimateDiff and the ST-MFNet frame interpolator to create realistic and smooth videos from a text prompt. AnimateDiff enhances text-to-image models by adding a motion modeling module trained on video clips, allowing for animated outputs. The blog post also introduces LoRAs, lightweight extensions that provide efficient camera movement controls for AnimateDiff. Additionally, the article explains how ST-MFNet, a spatio-temporal multi-flow network for frame interpolation, can be used to increase the frame rate and create smoother videos. The post provides code examples for using AnimateDiff, ST-MFNet, and the Replicate API to create these AI-generated videos. The authors invite readers to share their creations on Discord or via Twitter.

The discussion about the submission mostly revolves around technical and philosophical aspects related to the use of AI and the quality of the generated videos. One commenter expresses skepticism about the marketability of tools like AnimateDiff, arguing that it may not appeal to a wide audience. Another user criticizes the quality of the videos generated by the tool. 

In response to a comment, a user suggests that previous versions of AnimateDiff had more stable diffusion animations. Another commenter raises concerns about the computational requirements of running AI models, particularly in relation to hardware capabilities.

One user shares a link to a related article discussing limitations and potential advancements of animation tools like AnimateDiff.

In a separate comment, a user humorously suggests that using hallucinogens like LSD or mushrooms might be a way to create more realistic simulations.

There are a couple of short comments from a user, "afzalbutt122," which simply say "dd." The meaning of these comments is unclear.

