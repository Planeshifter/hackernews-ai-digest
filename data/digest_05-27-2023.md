## AI Submissions for Sat May 27 2023 {{ 'date': '2023-05-27T17:10:54.654Z' }}

### Superintelligence: An idea that eats smart people (2016)

#### [Submission URL](https://idlewords.com/talks/superintelligence.htm) | 158 points | by [082349872349872](https://news.ycombinator.com/user?id=082349872349872) | [246 comments](https://news.ycombinator.com/item?id=36098332)

In 2016, Nick Bostrom published the book Superintelligence, which warns of the potential danger of a runaway reaction where a machine intelligence could reach and exceed human levels of intelligence in a very short span of time, ultimately causing catastrophic social and economic problems. Bostrom suggests that if we can prove thinking minds exist and that the mind arises out of ordinary physics, then it is possible to create an artificial intelligence that could operate at electronic hardware time scales and be significantly smarter than humans. With the space of all possible minds being large and with the potential for computers to get faster and smaller, Bostrom's argument has gained the serious attention of many thought leaders, including Stephen Hawking and Elon Musk. However, there's no a priori reason to think that we're near the limit of intelligence, and there is still much room for debate about the risks posed by superintelligence.

The comments include discussions on the possibility and consequences of superintelligence and the limits of artificial intelligence. Some users disagree with the potential risks of superintelligence, while others assert the importance of precautions due to the rapid explosion of sophistication of intelligence. There are also discussions regarding security, the development of AI, and comparisons with other technological advancements. Some users show concern over the safety of AI and suggest the need for global cooperation to safeguard against AI's negative outcomes.

### Integrating Zig and SwiftUI

#### [Submission URL](https://mitchellh.com/writing/zig-and-swiftui) | 155 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [49 comments](https://news.ycombinator.com/item?id=36097321)

In this post, Mitchell Hashimoto shares his approach to building a truly native GUI for a cross-platform application, by writing all of the business logic in a cross-platform language and then writing platform-specific GUI code. He uses Zig as the example shared-logic language and SwiftUI in XCode as the GUI logic. With Zig, Hashimoto makes it easy to export a C API and create a static library, which is then integrated with XCode. He also discusses how to package up all the dependencies and create a universal (multi-arch) library, which works on both the x86_64 and aarch64 architectures.

Commenters discussed the challenges of working with shared code and cross-platform maintenance, the benefits of declarative UI frameworks, and the compatibility of Rust, Zig, and C++ as cross-platform options. Some also shared their experience working on projects where the GUI code can constitute up to 70% of the project's code.

### Landmark Attention: Random-Access Infinite Context Length for Transformers

#### [Submission URL](https://arxiv.org/abs/2305.16300) | 18 points | by [johntb86](https://news.ycombinator.com/user?id=johntb86) | [4 comments](https://news.ycombinator.com/item?id=36098879)

A new paper titled "Landmark Attention: Random-Access Infinite Context Length for Transformers" has proposed a novel approach to handling the issue of limited context length for the attention mechanism of transformers in natural language processing. The approach uses a landmark token to represent each block of the input, allowing access to the complete context while retaining random-access flexibility. The authors demonstrate that their method can obtain comparable performance with Transformer-XL while significantly reducing the number of retrieved tokens in each step, and can extend the context length capacity up to 32k tokens, allowing for inference at the context lengths of GPT-4.

The discussion on the submission starts with a user linking to the paper and mentioning that the proposed landmark attention approach will be published later. Another user finds the idea of an infinite context length of up to 32k tokens intriguing. A third user discusses the potential limitations, mentioning that an infinite context length could lead to longer computation times and memory requirements. Another user suggests that landmarking and compression can be used to mitigate these limitations. Overall, the discussion is focused on the potential benefits and limitations of the proposed approach.

### Hard stuff when building products with LLMs

#### [Submission URL](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm) | 218 points | by [mavelikara](https://news.ycombinator.com/user?id=mavelikara) | [96 comments](https://news.ycombinator.com/item?id=36096811)

Honeycomb has launched Query Assistant, a natural language querying interface powered by Generative AI that helps users ask for the right data to answer their questions. However, Phillip Carter, in a post on Thought Leadership, says building a product with Large Language Models (LLMs) is hard. He discusses some of the challenges faced by Honeycomb in building Query Assistant, including the "context window" problem, determining which fields to use from a large schema and chaining issues that slow it down. Despite the challenges, Carter suggests that LLMs are too important to ignore and believes that recent advancements indicate that things are heading in the right direction.

In the comments, there is a discussion about the benefits and limitations of chatbot interfaces and LLMs in general, with some expressing skepticism and others highlighting potential benefits. There is also a debate about the priorities of investing in LLMs versus solving more significant global issues.

### Democratizing AI with open-source language models

#### [Submission URL](https://lwn.net/Articles/931853/) | 27 points | by [marcodiego](https://news.ycombinator.com/user?id=marcodiego) | [3 comments](https://news.ycombinator.com/item?id=36095571)

AI is rapidly advancing, but access to advanced language models is limited to those who can afford to pay for them, leaving out many developers and researchers who could benefit from access. OpenAI has offered their chatbot, ChatGPT, to the public, but it's not fully open-source and users require a connection to their cloud service. However, several open-source alternatives have emerged, including BLOOM, a freely available large language model that was developed by a global collaboration involving over a thousand scientists. These open-source language models may not match the performance of ChatGPT yet, but they are making strides towards democratizing AI for everyone.

The discussion on this submission seems to be focused on personal experiences and experiments related to language models. One user shared their experience running a machine with 24GB RAM that took 15 minutes to complete a task related to common transportation in Amsterdam. Another user shared their experience with running a 6GB Nvidia card machine with impressive performance. Additionally, another user mentioned that they have tried open-source language models for testing the performance of their PC and GPU for commercial tasks.

### Hot Pixel' Attack Steals Data from Apple, Intel, Nvidia, and AMD Chips

#### [Submission URL](https://www.tomshardware.com/news/hot-pixel-attack-steals-data-from-apple-and-nvidia-chips-using-frequency-power-and-temperature-info) | 78 points | by [uguuo_o](https://news.ycombinator.com/user?id=uguuo_o) | [15 comments](https://news.ycombinator.com/item?id=36094760)

A team of security researchers funded in part by the US Air Force and DARPA has demonstrated a side-channel physical attack on CPUs manufactured by Apple, Qualcomm and Intel. The researchers were able to steal data by monitoring chip temperature, power and frequency during normal operation, using information exposed by the Dynamic Voltage and Frequency Scaling mechanism. While proof-of-concept rates are low, the researchers have shown that future optimisation of the process could increase exfiltration rates and enable accelerated exploitation by other entities. The paper reports that all vendors notified have acknowledged the issues, but as yet no mitigations have been announced.

The discussion on the submission revolves around the practicality and effectiveness of the attack and how fingerprinting comes into play. Some argue that fingerprinting requires accessing system temperature metrics, which may not be accessible to attackers, while others highlight the subtleties of the thinking process of the security industry and suggest that statistical methods could help discriminate between devices more efficiently. Some participants note that the attack requires access to the system's internal power temperature frequency sensors and metrics, suggesting that the attack should be hard to execute without administrator access. Other discussions involve the grammar and clarity of the paper, technical details of the testing, security vulnerabilities in browser fingerprinting, and the accuracy of pixel extraction in Table 19.

### Show HN: No more copy-pasting – a ChatGPT plugin to read code from your computer

#### [Submission URL](https://github.com/kesor/chatgpt-code-plugin) | 44 points | by [kesor](https://news.ycombinator.com/user?id=kesor) | [21 comments](https://news.ycombinator.com/item?id=36099507)

Kesor has developed "Code ChatGPT Plugin," a TypeScript code analyzer that allows ChatGPT to interact with your code. It can identify all TypeScript files in a project, locate all functions within a file, and even retrieve content from a specific function. It's perfect for developers looking to understand a TypeScript code base and for automated tools that need to analyze or manipulate the code. The plugin includes several features, including fetching files, functions, and content from a specific function. Kesor encourages community contributions to the open source project. The discussion includes suggestions for integrating ChatGPT with projects, comparing ChatGPT and Copilot, and tips for working with ChatGPT plugins.

