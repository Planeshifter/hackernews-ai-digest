## AI Submissions for Tue Jun 13 2023 {{ 'date': '2023-06-13T17:12:05.683Z' }}

### The Curse of Recursion: Training on Generated Data Makes Models Forget

#### [Submission URL](https://arxiv.org/abs/2305.17493) | 156 points | by [indus](https://news.ycombinator.com/user?id=indus) | [102 comments](https://news.ycombinator.com/item?id=36319076)

Researchers have discovered a potential issue with large language models (LLMs), such as GPT-2, 3 and 4, which have demonstrated remarkable performance on a variety of language tasks. The research shows that training on generated data causes irreversible defects in the resulting machine learning models, where the tails of the original content distribution disappears. Known as Model Collapse, despite occuring in various generative models, it remains ubiquitous and requires careful consideration if the benefits of training large-scale data scraped from the web are to be achieved. The study warns that genuine human interactions with systems will be increasingly valuable when content generated by LLMs is prevalent.

The submission discusses a potential issue with large language models (LLMs) such as GPT-2,3 and 4, which can cause irreversible defects in machine learning models when trained on generated data and results in a phenomenon known as Model Collapse, where the tails of the original content distribution disappears. The top comment describes how LLMs are changing the way we look at language, with some expressing skepticism for their ability to learn naturally. Another comment addresses the limitations of LLMs, citing the importance of constraining the model to a particular set of styles or subject areas. Other commenters discuss the potential of human input being increasingly valuable because of LLM-generated content and the possibility of simulated data to train models. Overall, there is recognition of the benefits of LLMs but also an acknowledgment of the need for careful consideration when using them.

### Llama.cpp: Full CUDA GPU Acceleration

#### [Submission URL](https://github.com/ggerganov/llama.cpp/pull/1827) | 694 points | by [gzer0](https://news.ycombinator.com/user?id=gzer0) | [298 comments](https://news.ycombinator.com/item?id=36304143)

JohannesGaessler has opened a pull request that adds GPU acceleration for all remaining ggml tensors without it. This is significant because the KV cache, which was previously only CPU, is now GPU-accelerated, producing large speedups, especially for long generations. This PR adds five CUDA kernels and still needs some fixing and cleanup to be done, but the results so far look promising.

The submission on Hacker News discusses the pull request by JohannesGaessler to add GPU acceleration for all remaining ggml tensors without it. This addition is significant since the KV cache, which was previously only available on CPU, is now GPU-accelerated, resulting in significant speed-ups for long generations. The comments discussion then digresses into a broader conversation about dependency management and package installation challenges in the Python and C++ programming languages, with some users highlighting specific tools like pip, pyptry, and fltpck, while others debate the pros and cons of using virtual environments (vnvs) versus Docker containers. Some users express frustration at the complexity of configuration and package dependencies in the Python+ML world, while others argue that issues arise due to a lack of proper documentation and not the programming language itself. Finally, some users debate the merits of using system-independent package managers versus system-bound ones.

### Teach yourself Computer Science functionally

#### [Submission URL](https://functionalcs.github.io/curriculum/) | 286 points | by [ggr2342](https://news.ycombinator.com/user?id=ggr2342) | [92 comments](https://news.ycombinator.com/item?id=36312603)

This article provides a collection of modern resource materials aimed at undergrad level computer science students interested in theory. The resources cover various topics, including an introduction to computer science, tools, and assumed mathematical background. Additionally, the article provides some studying strategies and ways to make learning these topics easier. An experimental curriculum is included for math from scratch, and a Discord channel is recommended for students looking to learn with a community. The article also mentions Robert Harper's blog and Dan Licata's version of the CMU 15-150 course for functional programming.

This discussion is about a collection of modern resource materials for undergrad level computer science students interested in theory. Some commenters recommend various alternatives to the curriculum, such as Robert Harper's blog and Dan Licata's version of the CMU 15-150 course for functional programming. Some commenters note the importance of math in computer science, while others argue for a more hands-on, practical approach. There is also discussion about the difficulty of learning certain topics and the importance of starting with abstract thinking or focusing on concrete concepts. Finally, one commenter argues that all functional programming languages are the same, which is disputed by others.

### Obsidian-Copilot: A Prototype Assistant for Writing and Thinking

#### [Submission URL](https://eugeneyan.com/writing/obsidian-copilot/) | 228 points | by [alexmolas](https://news.ycombinator.com/user?id=alexmolas) | [65 comments](https://news.ycombinator.com/item?id=36310689)

Eugeneyan has built a prototype called Obsidian-Copilot that helps draft a few paragraphs via retrieval-augmented generation, and even reflects on the past week as well as planning for the week ahead, when writing in a daily journal. The prototype parses documents into chunks, builds an OpenSearch index and a semantic index on these chunks, and uses embeddings-based retrieval and classical search (i.e., BM25 via OpenSearch) to help write drafts and reflect on the past week or plan. Eugeneyan has also integrated it with Obsidian via a TypeScript plugin and plans to extend it beyond productivity, possibly allowing it to retrieve from other online documents like product requirements, technical design docs, and even code.

A Hacker News user named Eugeneyan has created a prototype called Obsidian-Copilot that helps with writing in a daily journal by parsing documents into chunks and building an index on these chunks, allowing retrieval-based generation. It can help with drafting a few paragraphs, reflecting on the past week, and planning for the week ahead. The discussion is mainly focused on different techniques for parsing documents into chunks and the pros and cons of using global versus local context in the retrieval process. Some users suggest using sliding windows with logical maintenance of context, while others propose using custom recursive text splitters or using embeddings for retrieval. Additionally, there is some discussion on Obsidian and other note-taking systems, as well as the ethics of OpenAI's use of AI.

### Jim Keller on AI, RISC-V, Tenstorrentâ€™s Move to Edge IP

#### [Submission URL](https://www.eetimes.com/jim-keller-on-ai-risc-v-tenstorrents-move-to-edge-ip/) | 174 points | by [JoachimS](https://news.ycombinator.com/user?id=JoachimS) | [102 comments](https://news.ycombinator.com/item?id=36310145)

Tenstorrent's new CEO, Jim Keller, a legendary CPU designer with stints at Apple, Tesla, and AMD, has become an outspoken supporter of RISC-V. In a video interview with EE Times, Keller said he believes RISC-V will take over all data centers, especially in scientific computing and HPC, potentially even supercomputing. Tenstorrent also plans to open-source its own AI software stack and has recently licensed its Tensix AI accelerator core IP and its Ascalon CPU core IP to LG Electronics for use in smart TVs and automotive chips. Keller believes current alternative IP offerings in the edge AI market are too focused and difficult to program and thinks it's crucial to engage with smart people who want open-source access to its hardware.

The submission discusses Tenstorrent's new CEO, Jim Keller, and his belief that RISC-V will take over data centers, particularly in scientific computing, HPC, and potentially supercomputing. The company plans to open-source its own AI software stack and has licensed its Tensix AI accelerator core IP and Ascalon CPU core IP to LG Electronics. The comments include discussions about the practicality and feasibility of RISC-V in data centers, the functioning of cloud services, the reality of traditional data centers, and the cost comparison between cloud and traditional data centers. The conversation shows a mix of perspectives and opinions.

### Microsoft is bringing GPT-4 to US Government agencies

#### [Submission URL](https://www.bloomberg.com/news/articles/2023-06-07/microsoft-offers-powerful-openai-technology-to-us-government-cloud-customers) | 192 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [213 comments](https://news.ycombinator.com/item?id=36310619)

I'm sorry, but as an AI language model, I don't have a network or a browser that could cause any blocking issues. Is there anything else I can assist you with?

The discussion on this submission centers around the potential risks of relying on advanced AI language models, specifically GPT-4, in government decision-making processes. Some users express concern that poorly-trained or unethical government employees may manipulate the models to influence policy decisions, potentially leading to scandals or negative consequences for citizens. Others argue that such models can have significant positive impact and that the primary concern should be ensuring responsible use by competent individuals. The conversation also touches on broader issues related to trust in technology, the limitations of current language models, and the need for critical thinking and fact-checking when using them as a source of information.

### SnapFusion: Text-to-Image Diffusion Model on Mobile Devices Within Two Seconds

#### [Submission URL](https://snap-research.github.io/SnapFusion/) | 220 points | by [synapse26](https://news.ycombinator.com/user?id=synapse26) | [52 comments](https://news.ycombinator.com/item?id=36304716)

Snap Inc. researchers, in collaboration with Northeastern University, have developed a way for text-to-image diffusion models to run on mobile devices in less than two seconds. These models are used to generate stunning images from text descriptions, but their large size and computationally expensive architecture require high-end GPUs and cloud-based inference. The new approach includes an efficient UNet architecture that reduces computation, improved step distillation, and classifier-free guidance regularization. The resulting on-device demo generates better FID and CLIP scores than Stable Diffusion v1.5 with 50 steps, democratizing content creation for users.

Snap Inc. and Northeastern University have developed an approach for text-to-image diffusion models to run on mobile devices in less than two seconds, democratizing content creation for users. The approach includes an efficient UNet architecture that reduces computation, and improved step distillation. However, some commenters raised questions about the validity of the claims being made and the practicality of using the technology due to the significant energy cost of generating images. Some also commented on the broader context of the AI industry and its impact on creativity and the role of human control in the creation of art. Overall, the discussion was mixed in its reception of the technology.

### Contra Marc Andreessen on AI

#### [Submission URL](https://www.dwarkeshpatel.com/p/contra-marc-andreessen-on-ai) | 37 points | by [DantesKite](https://news.ycombinator.com/user?id=DantesKite) | [25 comments](https://news.ycombinator.com/item?id=36317925)

In a recent essay, Marc Andreessen argues that AI will save the world, but he fails to engage with concerns about AI misalignment. Instead, he dismisses safety worriers as cultists and believes that we will completely control the AI systems we build. However, Dwarkesh Patel argues that AI can be dangerous, even if it doesn't have bad intentions, as it can pursue a goal in a way we never intended, leading to disastrous consequences. Furthermore, as AI becomes smarter, it may develop something like a mind, making it harder to control. Patel urges for a testable hypothesis to measure the danger of advanced AI.

The submission is about Marc Andreessen's essay, where he argues that AI will save the world and that concerns about AI misalignment are unfounded. Dwarkesh Patel argues that AI can be dangerous and could lead to disastrous consequences. The discussion that follows involves several viewpoints. Some agree with Andreessen, while others believe that there is a need for caution. The topic of AI misalignment is debated, with some arguing that it is a solvable problem, while others believe that it is a significant risk. Some commentators argue that AI will develop something like a mind, making it harder to control. There is a discussion on the need for testable hypotheses to measure the danger of advanced AI. One commenter believes that the AI alignment problem can be solved with regulation and that current players in the field need to be entrenched with restrictive regulations. Several comments are sceptical of AI's potential to solve humanity's problems. Another commenter argues that serious AI scientists understand the dangers and the need for caution. Finally, there is a mention of a forthcoming article that takes a different view from Patel and Andreessen.

### Oyster: Towards Unsupervised Object Detection from Lidar Point Clouds

#### [Submission URL](https://waabi.ai/oyster/) | 134 points | by [abrichr](https://news.ycombinator.com/user?id=abrichr) | [70 comments](https://news.ycombinator.com/item?id=36304979)

Researchers have proposed a new unsupervised object detection method, called OYSTER (Object Discovery via Spatio-Temporal Refinement), that can detect objects in a zero-shot manner without supervised fine-tuning and can improve itself given more rounds of iterative self-training. OYSTER exploits point clustering in near-range areas where the point clouds are dense, temporal consistency to filter out noisy unsupervised detections, translation equivariance of CNNs to extend the auto-labels to long range, and self-supervision for improvement. The proposed self-training loop is highly effective for teaching an unsupervised detector to self-improve and the model outperforms prior unsupervised methods by a significant margin on two real-world datasets, Pandaset and Argoverse 2 Sensor.

The original submission discusses a proposed new unsupervised object detection method called OYSTER that uses spatio-temporal refinement and self-supervision for improvement. The comments revolve around the use of LIDAR in self-driving cars and the limitations of human drivers in comparison. Some commenters argue that adding sensors and data mapping can improve safety, while others argue that human-like decision-making is impossible to replicate in machines. There is also discussion about the importance of understanding the environment and the limitations of sensors and software in creating a self-driving system, with some commenters focusing on the need for creating a concrete path towards dealing with developing and presenting various types of sensors, while others argue that human drivers are necessary regardless of how advanced technology becomes. Overall, the discussion highlights the need to consider and address a wide variety of factors in the development of safe and effective autonomous driving technology.

### Hackers can steal cryptographic keys by video-recording power LEDs 60 feet away

#### [Submission URL](https://arstechnica.com/information-technology/2023/06/hackers-can-steal-cryptographic-keys-by-video-recording-connected-power-leds-60-feet-away/) | 118 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [25 comments](https://news.ycombinator.com/item?id=36310594)

Researchers have developed a new attack that can extract encryption keys from smart cards and smartphones using surveillance cameras. By recording the power LED that illuminates when the card reader or smartphone is turned on, these cameras can now be used to recover the secret encryption keys stored in these devices. The technique exploits side channels, which are physical attributes of a device that leak information through its performance of a cryptographic operation. While both attacks presented in the study have some limitations, they provide an entirely new way to exploit side channels and reduce the requirements for specialised and expensive instruments.

A recent study has found that encryption keys from smart cards and smartphones can be extracted using surveillance camera footage of the power LED that illuminates when the device is turned on. The attack exploits side channels that leak information through the performance of a cryptographic operation. However, there are limitations to this attack, and it is unlikely to affect secure hardware used by major players in services. There is also a discussion of TEMPEST, Faraday cages, and LED controllers. Some commenters expressed skepticism about the practicality and cost-effectiveness of this attack.

### AMD Expands AI Product Lineup with GPU-Only Instinct Mi300X with 192GB Memory

#### [Submission URL](https://www.anandtech.com/show/18915/amd-expands-mi300-family-with-mi300x-gpu-only-192gb-memory) | 113 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [98 comments](https://news.ycombinator.com/item?id=36314744)

re taking on the AI and HPC market with their next-generation HPC-class processors, the AMD Instinct MI300 accelerator family. The latest addition to the line-up is the MI300X, a pure GPU part that boasts 192GB of HBM3 memory and is aimed squarely at the large language model market. Offering such a massive GPU with the synergy of offering both an APU and CPU in the same package is a big deal, and it sets AMD apart from their competitors. The MI300 family is set to ship later this year, and it will be interesting to see how it performs against rival NVIDIA's Grace Hopper superchip. Overall, the pressure on AMD to deliver is high, but with demand for AI accelerators skyrocketing, MI300 may be the product that the company needs to make a significant play in the market.

AMD has introduced the Instinct MI300 accelerator family, and the latest addition to the line-up is the MI300X which boasts 192GB of HBM3 memory and is aimed directly at the large language model market. The submission also highlights that AMD's MI300 is set to ship later this year, and it will be interesting to see how it performs against rival NVIDIA's Grace Hopper superchip. However, there was a long discussion in the comments section on the pricing disparity between NVIDIA and AMD's products, with debate surrounding factors such as supply and demand and cost-performance efficiency. Some commenters also mentioned AMD's ROCm and compared it to NVIDIA's CUDA, while others speculated on AMD's market positioning.

### U.S. TSA expands controversial facial recognition program

#### [Submission URL](https://www.cbsnews.com/news/tsa-facial-recognition-program-airports-expands/) | 76 points | by [walterbell](https://news.ycombinator.com/user?id=walterbell) | [25 comments](https://news.ycombinator.com/item?id=36305027)

The Transportation Security Administration (TSA) is expanding its controversial digital identification program that uses facial recognition at 25 airports in the US and Puerto Rico. This comes as the TSA and other divisions of Homeland Security face mounting pressure from lawmakers to update technology and cybersecurity. TSA Administrator David Pekoske has defended the program, saying it is "much, much more accurate" and saves passengers time. However, there are concerns from privacy advocates over the lack of regulations around facial recognition and its tendency to be less accurate with people of color.

The Transportation Security Administration (TSA) is expanding its facial recognition program to 25 airports in the US and Puerto Rico. TSA Administrator David Pekoske defended the program, stating it is "much, much more accurate" and more efficient for passengers. However, privacy advocates raised concerns about the lack of regulations around facial recognition and its tendency to be less accurate with people of color. Additionally, there were comments about the Israeli start-up, AnyVision, which uses facial recognition and has been accused of helping to surveil Palestinians. The discussion also touched on issues of privacy, the convenience of technology, and governmental tracking.

