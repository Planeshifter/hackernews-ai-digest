## AI Submissions for Mon Dec 04 2023 {{ 'date': '2023-12-04T17:10:07.519Z' }}

### Starring the Computer

#### [Submission URL](http://starringthecomputer.com/) | 37 points | by [Lutzb](https://news.ycombinator.com/user?id=Lutzb) | [14 comments](https://news.ycombinator.com/item?id=38515351)

Starring the Computer is a website that catalogs and rates the appearance of computers in film and television. They rate each appearance based on its importance to the plot, realism, and visibility. In their latest update, they highlight a few notable appearances. 

In the series "Under the Banner of Heaven," they feature a Commodore 64, a Commodore PET, and an HP 85 computer. 

In an episode of "Secret Invasion," they spot a BBC Micro, as well as a Sharp MZ-80K and an IBM PS/2 Model 56SX. 

There are also a variety of laptop appearances, including an IBM 5140 in "Deceptions" and an Apple Powerbook 180 in "Beverly Hills, 90210." 

They also mention the appearance of Tandy computers, such as the TRS-80 Model I in "The New Adventures of Heidi" and the TRS-80 Model III in "White Noise." 

In terms of British eight-bit computers, they highlight the BBC Micro in "Gabrielle and the Doodleman" and the Amstrad CPC 6128 in "It's Nice Up North." 

There are several Apple computers featured, including an Aluminum iMac in "The 7th Dimension" and a Powerbook G4 in "Made in Romania." 

They also note the presence of Panasonic Toughbook computers in various films and TV shows, including "Security" and "The Wire." 

In the second season of "Halt and Catch Fire," they mention appearances from an Atari ST, Commodore 64s, and IBM PC XTs. 

There are also several Commodore computers featured, such as a PET in "The Sandman" and a VIC-20 in "Taggart." 

Lastly, they bring attention to the appearance of an ICT 1900 in the "Doomwatch" episode "The Iron Doctor" and an ICT 1301 in "The Logicians." They also note the presence of the IBM AN/FSQ-7 and the GE 635, as well as a Commodore PET 2001 in "Wrong Is Right."

The discussion on this submission covers a range of topics related to computers in film and television. 

- There is a comment pointing out the amusing fact that in some futuristic movies, the computer props have silent panels, modems, lights, and even tubes, which are not realistic.
- Another comment mentions a related Tumblr blog that features computer screens in TV shows and films.
- The original poster (OP) of the submission explains that Starring the Computer is a website dedicated to cataloging and rating computer appearances in films and TV shows based on their importance to the plot, realism, and visibility, except for fictional computers like HAL9000 from 2001: A Space Odyssey.
- A user asks if the website includes custom operating systems or just mock UIs, and another user replies that it is nice to see the different UIs created for movies and TV shows.
- The conversation deviates slightly as users discuss the presence of Amigas, Ataris, and NeXT computers in movies.
- One user mentions that they are the leader of those discussions and would play the game referenced in the submission.
- Another user responds that there are ways to play that game, but they don't think it matters much.
- The discussion then shifts to the topic of war games and the validity of their portrayal in movies like War Games.
- Finally, there is a comment mentioning the 6502 processor as something that can be frightening.

### Towards accurate differential diagnosis with large language models

#### [Submission URL](https://arxiv.org/abs/2312.00164) | 96 points | by [gwintrob](https://news.ycombinator.com/user?id=gwintrob) | [75 comments](https://news.ycombinator.com/item?id=38524595)

Researchers at arXiv have published a paper titled "Towards Accurate Differential Diagnosis with Large Language Models" by Daniel McDuff and his team. The paper introduces an optimized Large Language Model (LLM) for diagnostic reasoning and evaluates its effectiveness in generating a differential diagnosis (DDx) for medical cases. The LLM outperformed unassisted clinicians in terms of accuracy and produced higher-quality DDx compared to clinicians assisted by search engines and standard medical resources. The study suggests that LLMs have the potential to improve clinicians' diagnostic reasoning and accuracy in challenging cases, thus empowering physicians and increasing patients' access to specialist-level expertise. Further real-world evaluations are needed to confirm these findings.

The discussion on this submission revolves around various experiences and perspectives related to the use of AI in medical diagnosis, as well as criticisms towards the medical system.

One commenter expresses frustration with doctors not considering certain tests and relying on their own judgments instead. They share personal anecdotes of doctors dismissing their concerns and not investigating further. Another commenter argues that doctors have limited time and resources and implies that AI could potentially help improve their decision-making process.

Another discussion revolves around the challenges in creating medical guidelines and the importance of clinical experience. One commenter emphasizes the need for doctors to have practical experience and argues that AI should not replace them entirely. They also point out the difficulty of creating guidelines that fit every scenario.

There is also a debate about the role of doctors and the healthcare system. One commenter expresses dissatisfaction with the current system, stating that doctors prioritize monetary gain over patient care. They hope that AI can help improve the situation. Another commenter argues that insurance and the cost of medical tools are major problems and that the current system needs to change.

Overall, the discussion highlights a range of opinions on the role of AI in medical diagnosis, the challenges faced by doctors, and criticisms of the medical system.

### Joint initiative for trustworthy AI

#### [Submission URL](https://actu.epfl.ch/news/joint-initiative-for-trustworthy-ai/) | 63 points | by [huhtenberg](https://news.ycombinator.com/user?id=huhtenberg) | [20 comments](https://news.ycombinator.com/item?id=38523736)

ETH Zurich and EPFL have announced the launch of the "Swiss AI Initiative", a joint effort to position Switzerland as a global leader in transparent and reliable artificial intelligence (AI). The initiative will leverage the power of the new Alps supercomputer, equipped with 10,000 graphics processing units (GPUs), to provide Swiss scientists with access to cutting-edge computing power for AI applications. The aim of the project is to develop and train large language models (LLMs) that are transparent and open source, ensuring comprehensible and ethical results. The initiative will also foster collaboration among science, industry, and politics to drive the development and use of AI in Switzerland, with a focus on industry-specific applications in sectors such as robotics, medicine, climate sciences, and diagnostics.

In the discussion section of this submission about the Swiss AI Initiative, there are several different conversations taking place. 

One commenter points out that the government computing project with 10,000 GPUs is impressive hardware but may not provide a competitive advantage against offerings from Google and AWS, who are providing double computing power in a single data center. Another commenter responds that it's still a significant development and mentions that it's being led by EPFL and ETH Zurich.

Another conversation revolves around the trustworthiness of AI and the need for legal and ethical considerations. One commenter mentions the importance of reliability and validity in evaluating AI models and brings up the intersection of math, philosophy, and law. This leads to a discussion about the complexity of AI and how some people oversimplify it or misunderstand it from a technical perspective.

There is also a conversation about the philosophical implications of AI, with one commenter mentioning metaphysics, ethics, and the intersection with formal logic and German-Austrian mathematics. Another commenter argues that AI is ultimately grounded in mathematics and that things like trust and ethics can be applied to AI using mathematical models.

One commenter brings up the topic of safety in AI and how it should be handled in the real world. They discuss legal and monetary incentives for ensuring safety and mention that AI systems can make mistakes and should be held accountable.

Another commenter points out that discussions about large language models (LLMs) often generate a lot of words but lack substance, emphasizing the importance of non-linguistic aspects of AI.

In a separate conversation, one commenter argues that humans are the creators of AI, and discussions about the topic should adhere to certain philosophical demands. They mention that professionals design the systems based on legal, ethical, and scientific criteria.

There is also some discussion about the implications of AI in various industries. One commenter suggests that AI models and responses need to consider legal implications, while another mentions the importance of security and execution in business processes.

Lastly, there are comments flagged that discuss unrelated topics such as nationalistic filmmaking, banking secrecy in Switzerland, and democratic traditions in the country.

### AI and Trust

#### [Submission URL](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html) | 196 points | by [CTOSian](https://news.ycombinator.com/user?id=CTOSian) | [87 comments](https://news.ycombinator.com/item?id=38516965)

The author of this blog post explores the concept of trust in society and how it relates to artificial intelligence (AI). They argue that there are two types of trust: interpersonal trust (based on personal connections and intentions) and social trust (reliability and predictability). They believe that AI confuses these two types of trust, leading people to see AI as friends rather than just services. They also highlight concerns that corporations controlling AI may take advantage of this confusion. The author argues that it is the role of the government to create trust in society, including regulating the organizations that control and use AI. They conclude by emphasizing the importance of social trust in scaling society and the need to consider biases embedded in trust systems.

The discussion on this submission covers a range of topics related to trust in AI and the regulation of AI systems.

One user points out that AI controlled by corporations can lead to profit-maximizing behavior, potentially compromising trust. They highlight concerns about surveillance and manipulation business models, emphasizing the need for greater regulation. Another user agrees and suggests that smaller, open-source models can provide alternatives to large corporate-controlled AI systems.

The discussion also touches on the challenges of implementing private, locally installed models. Some users argue that it can be complicated to set up, requiring support from web browsers and operating systems. Others suggest that most people install apps without much difficulty.

One user highlights the importance of implementing technical and protocol approaches to ensure trustworthy AI. They argue for the use of local models and note the need for clear instructions and constraints in training data to avoid unintended biases.

The topic of regulating AI is also brought up. Some users argue that attempts at regulation should not focus solely on AI but should also address surveillance and manipulation, as these are existing issues in society. Another user brings up Promise Theory, which explores the notions of promises, obligations, and trust in systems.

The discussion veers into the realm of corporate control and the potential harm that can result from AI proxying human agents. The analogy of the music industry and contracts is used to illustrate the problems that can arise from proxying human decision-making to AI systems.

One user draws parallels between the arguments made in this discussion and the software movement's focus on trustworthiness and responsibility. They argue that trustworthiness should apply to non-AI software as well, highlighting the need for accountability and transparency in corporate-controlled software systems.

Overall, the discussion emphasizes the importance of trust, transparency, and responsible use of AI systems, and the need for regulatory measures to ensure these principles are upheld.

### IBM releases first-ever 1k-qubit quantum chip

#### [Submission URL](https://www.nature.com/articles/d41586-023-03854-1) | 38 points | by [birriel](https://news.ycombinator.com/user?id=birriel) | [4 comments](https://news.ycombinator.com/item?id=38520757)

IBM has announced the development of the first quantum computer with over 1,000 qubits – the quantum equivalent of digital bits in a classical computer. However, instead of continuing to increase the number of qubits in its machines, IBM will now focus on improving error resistance. Quantum states are notoriously prone to errors, and IBM plans to address this issue by using error-correction techniques that would require fewer physical qubits. The company aims to build chips designed to hold a few error-corrected qubits in about 400 physical qubits and network them together. This approach could reduce the number of physical qubits needed for useful computations by a factor of 10 or more. IBM's road map for its quantum research envisions achieving useful computations within the next decade.

The discussion on this submission primarily revolves around the topic of logical qubits and error-correction techniques in quantum computing. One user, vlovich123, points out that the reported numbers of qubits in quantum computers may refer to logical qubits rather than physical qubits. They mention that research generally indicates that error-correction techniques require around 1000 physical qubits for each logical qubit, and express excitement about an alternative error-correction scheme called quantum low-density parity-check (qLDPC) that could reduce this ratio by a factor of 10.

Another user, d-bcn, argues that 10 logical qubits defined on just one physical qubit is a reasonable definition of a logical qubit and highlights Google's work on quantum error correction. They discuss experiments that demonstrate fault-tolerant quantum error correction using 13 physical qubits and note that other groups have also achieved small-scale logical qubits with improved performance.

In response to vlovich123's earlier comment, d-bcn mentions that they have likely managed to create a logical qubit, pointing to experimental evidence from Egan and Google. They provide links to two experiments that showed small improvements in logical performance, although the improvements were relatively small in scale.

In conclusion, the discussion involves a technical debate about the definition and implementation of logical qubits, as well as the advancements and challenges in error-correction techniques for quantum computing.

### Show HN: HelpMoji – Build Co-pilots for your favorite Games

#### [Submission URL](https://helpmoji.com/) | 8 points | by [hienyimba](https://news.ycombinator.com/user?id=hienyimba) | [3 comments](https://news.ycombinator.com/item?id=38517221)

Introducing Helpmoji, the ultimate companion for gamers! With Helpmoji, you can access a wide range of friendly NPC helpers designed to assist and guide you through your favorite games. Whether you need personalized guidance, real-time assistance, or helpful walkthroughs, Helpmoji has got you covered. Plus, it's completely free!

So, how does Helpmoji work? It's simple! Just follow these three steps to create your very own game helper:

1. Choose your game: Input the name of the game you're playing, and Helpmoji will scour the web to find the best knowledge base and wiki sources for your co-pilot.

2. Select training data: Browse through the cool resources Helpmoji has found, and feel free to add your own if you have any.

3. Train your co-pilot: Helpmoji will ingest the chosen resources and train your co-pilot in the background. In just three minutes, your co-pilot will be ready to assist you to victory!

And that's not all! As a member of Helpmoji's community, you'll gain access to over 1000 pre-made helpers created by other members. From Genshin Impact to Among Us, Fortnite to Grand Theft Auto V, you'll find helpers for a wide range of popular games. It's like having a personal gaming assistant at your fingertips!

But what sets Helpmoji apart is its versatility. This tool is multilingual, meaning you can train your co-pilot in one language and chat in 30 different languages. Connect with gamers from around the world and level up your gameplay together!

Ready to boost your gaming experience? Create a game helper for your favorite game and gain free access to helpers crafted by the Helpmoji community. Get started now and let Helpmoji be your co-pilot to victory!

The discussion surrounding the submission revolves around the terminology used in the description of the product. One user comments that the term "NPC" (non-playable character) is commonly used in gaming and finds it humorous that it is being used to describe the game helpers in Helpmoji. Another user suggests that the inclusion of terms like "personalized walkthrough helper" would make it easier for people to understand the purpose of the product.

### Show HN: AIConsole, an Open-Source Desktop AI Editor to Customize Your Workflow

#### [Submission URL](https://aiconsole.ai) | 52 points | by [mcielecki](https://news.ycombinator.com/user?id=mcielecki) | [24 comments](https://news.ycombinator.com/item?id=38517060)

Introducing AIConsole, an open-source desktop AI editor designed to enhance your workflow. With its powerful features, this tool allows you to run code locally and perform all the tasks that you can on your machine. But that's just the beginning.

One of the standout features of AIConsole is its ability to learn from your input. Simply describe how to perform a task in plain text once, and AIConsole will remember it forever. This means that the more you use it, the better it gets at understanding and automating your tasks.

You can also leverage your own notes to teach AIConsole. By using your existing knowledge, you can train the AI to complete and automate even more complex tasks. It's like having a personal assistant that learns from your own expertise.

AIConsole also excels in expert prompt engineering. For every step in your tasks, you can expect a precise, efficient, and automatic multi-agent RAG system. The level of prompt engineering provided by AIConsole is on par with expert standards, ensuring that you have the most effective tools at your disposal.

One of the greatest perks of AIConsole is its commitment to being fully open-sourced. You can rest assured that no data is being sent to anyone other than the LLM APIs, and you can verify this for yourself. Additionally, AIConsole encourages you to build and share your domain-specific AI tools with the community. Whether it's on platforms like GitHub or Discord, you have the opportunity to contribute to the growth of this powerful tool.

If you're eager to give AIConsole a try, you can download it right away. But if you require a customized, hosted, or enterprise version, the AIConsole team is ready to develop it according to your needs.

Embrace the future of productivity with AIConsole and revolutionize your workflow.

The discussion surrounding the submission "Introducing AIConsole, an open-source desktop AI editor designed to enhance your workflow" on Hacker News revolves around various aspects of the tool.

One user, android521, encountered an issue with downloading the MacIntel MaxM2 Edit and mentioned that they received an "Invalid Open AI API key" error while trying to access the playground chat. Another user, mchlkljsz, suggested that the problem might be due to the requirement of the GPT-4 API for proper functioning.

The conversation then shifted towards the capabilities of AIConsole, with mchlkljsz noting that it could be useful for quickly generating specific tailored prompt tasks. Another user, smcld, mentioned that AIConsole has the potential for integration with Ollama, an RNA model server.

Odene expressed curiosity about using AIConsole to create prompts for Google Analytics 4 and generate dashboards. Other users, mritchie712 and mclck, discussed the limitations of various APIs such as Stripe, Shopify, and Hubspot in handling the collection of data and recommended AI-powered data assistants as a potential solution.

Krlrkssn chimed in to express interest in sharing tools created using AIConsole, to which mclck responded with the word "Effects."

Some users, including ylwht and glbrtk, praised the capabilities of AIConsole and its cross-platform nature. The conversation briefly referenced CodeLama and the release schedule, with psychctv mentioning "Lama 70b" and mchlkljsz noting the potential long-term benefits of LLMs (Large Language Models) in a local environment.

Xchn congratulated the AIConsole team on the launch and expressed amazement at its cross-platform functionality. Other users, such as lbns and lvnd, expressed their positive impressions and potential use cases for AIConsole. The discussion concluded with users KodakKojak and dwc10 simply stating that it looks impressive.

### OpenAI COO thinks AI for business is overhyped

#### [Submission URL](https://www.theverge.com/2023/12/4/23988019/openai-enterprise-hype-chatgpt-lightcap) | 23 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [9 comments](https://news.ycombinator.com/item?id=38522314)

OpenAI's chief operating officer, Brad Lightcap, has cautioned against the overhyping of AI for business transformation. In an interview with CNBC, Lightcap acknowledged that companies often expect AI to deliver significant changes instantly, but he emphasized that AI is still in its infancy and there is no one-size-fits-all solution. While AI has the potential to improve businesses, Lightcap explained that it is currently in the experimental phase and has yet to become an integral part of critical tools and applications. OpenAI has recently launched an enterprise version of its ChatGPT platform, which offers better data protection and more customization options. However, some early adopters of AI have faced challenges, including Morgan Stanley, whose chatbot built with OpenAI was reportedly underutilized by users. The article also highlights instances where AI-generated content has received backlash for being insensitive or inaccurate.

The discussion on this submission touches on a few different points:

- One user suggests that human loop verification is necessary to ensure the accuracy of AI-generated content. They argue that AI should not be relied upon to generate insights without human oversight.
- Another user shares their experience of using AI in their former company, where AI was used to search and classify documents. They emphasize the usefulness of AI in synthesizing information and identifying conflicting data.
- The discussion also touches upon the potential impact of AI on jobs. One user argues that AI-led automation may lead to job losses, while another user counters that innovation and technological advancements tend to create new job opportunities.
- One user points out the limitations of chatbot applications and suggests that the industry has not yet fully transformed or seen significant advancements in underlying technology.
- Another user highlights the importance of responsible management and executive involvement in understanding the capabilities and limitations of AI. They argue that proper research and testing are necessary to set appropriate expectations for AI projects and align them with business goals.

Overall, the discussion reflects varying perspectives on the current state and future potential of AI, as well as the challenges and considerations that come with its adoption in business settings.

