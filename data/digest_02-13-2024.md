## AI Submissions for Tue Feb 13 2024 {{ 'date': '2024-02-13T17:10:16.648Z' }}

### Memory and new controls for ChatGPT

#### [Submission URL](https://openai.com/blog/memory-and-new-controls-for-chatgpt) | 434 points | by [Josely](https://news.ycombinator.com/user?id=Josely) | [248 comments](https://news.ycombinator.com/item?id=39360724)

OpenAI is testing a new feature for ChatGPT that allows the AI to remember information from previous conversations, making future interactions more helpful. Users have control over ChatGPT's memory and can explicitly tell it to remember or forget certain things. They can also view and delete specific memories or clear all memories. This feature is being rolled out to a small group of free and Plus users for testing, with plans for a broader rollout in the future. In addition, OpenAI is also working on implementing memory for GPTs in general, allowing them to remember user preferences and tailor their responses accordingly.

The discussion on the submission revolves around the topic of lazy coding in ChatGPT and potential improvements that can be made. Some users argue that lazy coding leads to decreased coding quality, while others point out that lazy coding can be effective and efficient in certain situations. One user mentions the difficulty of filtering out irrelevant code in Rust parsing, while another user suggests using GitHub Copilot for generating code. There is also a discussion about GPT-4 Turbo's behavior and the need for refactoring tasks. Some users express concerns about OpenAI's censorship and the potential misuse of knowledge generated by AI models. Overall, the discussion highlights different perspectives on the efficiency and practicality of lazy coding and raises questions about responsible AI use and censorship.

### Nvidia's Chat with RTX is an AI chatbot that runs locally on your PC

#### [Submission URL](https://www.theverge.com/2024/2/13/24071645/nvidia-ai-chatbot-chat-with-rtx-tech-demo-hands-on) | 249 points | by [nickthegreek](https://news.ycombinator.com/user?id=nickthegreek) | [137 comments](https://news.ycombinator.com/item?id=39357900)

Nvidia has released an early version of Chat with RTX, an AI chatbot that runs locally on your PC. The app allows users to feed it YouTube videos and documents to create summaries and obtain relevant answers based on their own data. While the app is still in its early stages, it shows promise for data research purposes, particularly for journalists and individuals who work with large amounts of documents. Chat with RTX requires an NVIDIA RTX 30- or 40-series GPU with at least 8GB of VRAM. Users can search through video transcripts, summarize videos, and analyze local documents with the chatbot. While there are some bugs and limitations to be resolved, this AI chatbot demonstrates the potential of locally-run AI models on personal computers.

The discussion on the Hacker News submission revolves around the implementation and potential limitations of the Chat with RTX AI chatbot released by Nvidia. Here are the main points discussed:

1. Implementation: The chatbot is based on the TensorRT-LLM framework and requires an NVIDIA RTX 30- or 40-series GPU with at least 8GB of VRAM. Users can feed YouTube videos and documents to obtain summaries and relevant answers based on their own data. Some users have shared GitHub repositories and installation instructions for the chatbot.

2. Performance: Users have shared their experiences with the chatbot's performance. One user mentions that using it in conjunction with other AI models like Triton Inference Server has led to significant performance improvements. However, there are discussions about the limitations and complexities of running the chatbot, such as the requirement for large GPU memory.

3. Comparisons with Dr. Sbaitso: Some users bring up the resemblance of the chatbot to Dr. Sbaitso, a text-to-speech program from the 90s. They share anecdotes and nostalgic experiences related to the old program.

4. Local Language Models (LLMs): The discussion extends to the broader topic of locally-run language models. Users discuss the potential benefits and drawbacks of using LLMs, mentioning the need for technical knowledge and possible harmful effects of AI.

5. Simplified Solutions: Some users express confusion about the implementation details and suggest that simpler solutions should be made available. Others point out that various companies, such as OpenAI, Microsoft, and Google, are working on similar projects, and the complexity is due to the technical nature of the topic.

Overall, the discussion highlights both the potential of locally-run AI models for data research purposes and the complexities associated with their implementation and usage.

### Smart terminals: Personal computing’s true origin? (2023)

#### [Submission URL](https://thehistoryofhowweplay.wordpress.com/2023/10/23/smart-terminals-personal-computings-true-origin/) | 65 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [14 comments](https://news.ycombinator.com/item?id=39359307)

Today on Hacker News, we have an interesting article from the historyofhowweplay blog about the evolution of computer monitors. The author delves into the significance of terminals as they played a crucial role in the development of computer technology. Initially starting as text-based teletypes, terminals became popular in the 1950s and made programming much easier. The adoption of the ASCII computer text standard and the widespread use of timesharing with the Dartmouth model led to the demand for CRT-based terminals and the birth of the computer monitor industry. The article also mentions the development of graphical terminals for applications like Computer Aided Design (CAD) and the various experiments conducted to explore the possibilities of raster and vector graphics displays. Eventually, designers began to conceive of terminals with their own "brain" to bypass the need for constant computer interaction and unstable connectivity. The article points out the importance of the miniaturization of computer components in driving the development of standalone terminal systems. Overall, it's an intriguing read that delves into the forgotten history of computer monitors and their impact on personal computing.

The discussion on the article about the evolution of computer monitors goes in several directions. 

One user, ChuckMcM, points out the shift from centralized computing to distributed computing and how terminals played a role in each stage. They mention the transition from mainframe-based terminals to minicomputers with multiple servers, and then to personal computers that combined terminals and computing power. They also mention thin servers, Citrix-style clients, and web browsers as alternative ways to implement terminal-like functionality.

Another user, rbnffy, talks about alternative paths in computing, mentioning DEC's Gigi and other terminal models like Tek ReGIS. They also discuss how personal computers and modems worked similarly to terminals in the past.

The discussion then shifts to the similarities between smart phones and modern terminals. rbnffy notes that smart phones are essentially running local software that acts as a terminal to modern web browsers.

kjs3 weighs in by discussing specific terminal models like ATT 3b2 and BLIT, highlighting their features and capabilities. They also mention the existence of a similar but different terminal called BitGraph, as well as the Tektronix 4100 and 4200 series, which were impressive machines for graphics work.

Animats brings up the history of shared-logic word processors and dumb terminals in the context of IBM PCs and monitors.

SomeoneFromCA mentions that the Apple 1 was a representative transitional product from the era of dumb terminals to intelligent computers.

rbnffy adds that the sophistication of terminals did not help small computers running dedicated terminal firmware, as they were eventually overtaken by cheaper desktop computers running terminal software.

Finally, a user named aaron695 makes a one-word comment: "dd," which is unclear in its context.

### Mozilla downsizes as it refocuses on Firefox and AI

#### [Submission URL](https://techcrunch.com/2024/02/13/mozilla-downsizes-as-it-refocuses-on-firefox-and-ai-read-the-memo/) | 176 points | by [awkwardpotato](https://news.ycombinator.com/user?id=awkwardpotato) | [165 comments](https://news.ycombinator.com/item?id=39362481)

Mozilla, the organization behind the Firefox browser, is undergoing major changes to its product strategy. It plans to scale back investment in various products, including its VPN, Relay, and Online Footprint Scrubber, and shut down Hubs, its 3D virtual world launched in 2018. Approximately 60 employees will be affected by the layoffs. Mozilla aims to refocus on Firefox and bring "trustworthy AI into Firefox." The company will bring together teams working on Pocket, Content, and AI/ML to achieve this goal. These changes suggest a shift towards prioritizing Firefox and addressing criticism of diversifying its product portfolio.

The discussion on this submission revolves around various aspects of Mozilla's product strategy changes. Here are some key points:

- Some users are expressing skepticism about the impact of Mozilla's refocus on Firefox and its plans to bring trustworthy AI into the browser.
- There is a discussion on the market share of Firefox, particularly in relation to Chrome and Safari. It is pointed out that while Firefox's market share is relatively low in desktop Linux, it has a stronger presence in Germany.
- Users debate the significance of Mozilla's decision to scale back investment in products such as VPN and Relay, with some suggesting that these projects were not generating enough profit.
- The potential implications of Mozilla's reliance on Google for revenue, particularly from search deals, are discussed, with some expressing concern about the impact on the company's independence.
- There is also a mention of the financial challenges faced by Mozilla and the need for the organization to prioritize revenue-generating projects.
- Some users express support for Mozilla's VPN and mention alternatives such as Mullvad.
- The discussion touches on the importance of open-source alternatives and the potential for Mozilla to collaborate with projects like LibreWolf.

### Court Dismisses Authors' Copyright Infringement Claims Against OpenAI

#### [Submission URL](https://torrentfreak.com/court-dismisses-authors-copyright-infringement-claims-against-openai-240213/) | 35 points | by [isaacfrond](https://news.ycombinator.com/user?id=isaacfrond) | [9 comments](https://news.ycombinator.com/item?id=39357210)

In a recent court case, OpenAI successfully had the copyright infringement claims filed against them by two authors dismissed. The authors, Paul Tremblay and Mona Awad, accused OpenAI of using their books without permission or compensation to train its AI models. OpenAI argued that using books to train AI does not constitute copyright infringement, and the court largely agreed. The court also dismissed claims that OpenAI violated the Digital Millennium Copyright Act (DMCA) by altering copyright management information. However, the authors still have the opportunity to file an amended complaint, and the direct copyright infringement claim against OpenAI will proceed. Many other AI copyright lawsuits are ongoing.

The discussion on Hacker News revolves around various aspects of the court case between OpenAI and authors Paul Tremblay and Mona Awad. Some key points discussed include:

- One user mentions that OpenAI's defense likely focused on the argument that using books to train AI models does not constitute copyright infringement. Another user adds that OpenAI's successful defense could set a precedent for similar cases in the future.

- There is a comment expressing confusion about the judge's decision, stating that the court case is still in its early stages and the legal battle is just beginning.

- A user highlights that the article's title is misleading, as it suggests the claims were dismissed entirely, while in reality, only specific claims were dismissed. They mention that it would be interesting to see specific examples of alleged copyright infringement.

- Another user brings up an interesting point, stating that ChatGPT accurately reproduces the impression of paragraphs from articles, making it appear as though people can read NYT content without actually engaging with it fully. They argue that this misrepresentation could harm the reputation of the NYT and potentially lead to legal issues.

- One user comments that this is just the beginning and the court case will likely have significant implications for copyright law. They mention that it is a good start to see the dominance of the major tech companies being challenged.

- A user suggests that the discontinuation of using NYT training data is a positive development, as it emphasizes the importance of respecting copyrights and benefits the rights holders.

- In response, another user points out the irony that OpenAI, which is associated with extremely wealthy individuals, is being taken to court by other wealthy individuals, highlighting the power dynamics at play.

- A discussion emerges about the nature of legal claims being broadly made and then eventually dropped or dismissed in many cases involving wealthy individuals.

Overall, the discussion showcases different perspectives on the court case, with additional insights raised about copyright infringement, the impact on media organizations, and the involvement of wealthy individuals.

### GPT inputs outgrow world chip and electricity capacity

#### [Submission URL](https://www.astralcodexten.com/p/sam-altman-wants-7-trillion) | 19 points | by [quirkot](https://news.ycombinator.com/user?id=quirkot) | [13 comments](https://news.ycombinator.com/item?id=39358693)

In a recent post on Astral Codex Ten, the author discusses Sam Altman's desire for $7 trillion and why it's a significant reminder of the challenges that AI will face in scaling up. The post breaks down the cost of training AI into three main components: compute, electricity, and training data. With each new generation of AI models, the cost increases significantly. For example, GPT-4 is estimated to have cost $100 million, and GPT-5 is rumored to have cost $2.5 billion. The author speculates that GPT-6 could cost $75 billion and GPT-7 a whopping $2 trillion. 

The challenge lies in the resources required to train these models. In terms of compute, GPT-4 took about six months using 1/2000th of all the computers in the world. Scaling this up, GPT-7 would require 15 times as many computers as currently exist. As for electricity, GPT-7 would need the output of fifteen Three Gorges Dams, the largest power plant in the world. Training data presents another challenge, as the amount of text available is limited. While synthetic data can be used to generate more training data, it's not yet clear how effective this approach will be for written text.

Overall, Altman's $7 trillion aspiration serves as a reminder of the immense resources required to scale AI models and the challenges that lie ahead. It highlights the need for advancements in compute power, energy production, and training data generation techniques.

The discussion on this post revolves around several points. 

- One commenter criticizes the article, pointing out that its title and substance misrepresent the actual growth rate of AI models. They clarify that the growth is not exponential but rather increases by factors of 100x, 25x, and 25x respectively for each generation.

- Another commenter expresses their wish for AMD to quickly implement transparent methodologies for GPU computing, specifically mentioning the LLVM compiler infrastructure.

- One commenter argues that previous predictions about the hard drive storage capacity being quickly exceeded were proven wrong when it comes to DNA sequencing. They suggest that people are not fully considering the scaling limitations of language models being discussed.

- A commenter highlights an interesting point from the article, specifically that GPT-4 consumed 50 gigawatt-hours of energy during training, and with a scaling factor of 30x, they estimate that GPT-5 would require 1,500 gigawatt-hours, GPT-6 would require 45,000 gigawatt-hours, and GPT-7 would require 13 million gigawatt-hours.

- A comment thread discusses the assumption that OpenAI's training is exclusively powered by Microsoft's low carbon energy. One commenter argues that there are limitations to renewable energy production and maintenance and questions Microsoft's commitment to a 100% renewable energy world.

- Another commenter in the thread suggests that Microsoft is hiring nuclear scientists, possibly to power their AI initiatives, and they criticize Microsoft for promoting green energy while relying on dirty energy elsewhere.

- The discussion then moves towards the dynamics of power purchase agreements (PPAs), renewable energy credits (RECs), and the translation of lowering electricity production CO2 footprints. The comment highlights competitive wind and solar power production in certain locations and carbon cap-and-trade systems to prevent increased power demand relying on fossil energy.

- Another commenter supports the claim made in the previous comment and shares links to independent research that corroborates it.

- Lastly, a commenter mentions that slower training generations of large language models (LLMs) can select from a wider range of low carbon energy sources without compromising their training efficiency, regardless of the energy source mix in the market for electricity generation.

- Another commenter suggests that companies like Microsoft are likely making renewable energy commitments regardless of cost. They share links to articles discussing Microsoft's renewable energy pledges.

### Nvidia Chat with RTX

#### [Submission URL](https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/) | 71 points | by [diymaker](https://news.ycombinator.com/user?id=diymaker) | [3 comments](https://news.ycombinator.com/item?id=39359599)

The NVIDIA Chat with RTX app is now available for download. This demo app allows you to personalize a GPT large language model (LLM) by connecting it to your own content, such as documents, notes, videos, or other data. Using retrieval-augmented generation (RAG), TensorRT-LLM, and RTX acceleration, you can ask a custom chatbot specific questions and receive contextually relevant answers. The app runs locally on your Windows RTX PC or workstation, ensuring fast and secure results. The system requirements include a Windows 11 platform, an NVIDIA GeForce RTX 30 or 40 Series GPU (or NVIDIA RTX Ampere or Ada Generation GPU) with at least 8GB of VRAM, 16GB or greater RAM, and driver version 535.11 or later. Notably, Chat with RTX supports various file formats, including text, pdf, doc/docx, and xml. You can also provide the URL of a YouTube playlist, and the app will load the transcriptions of the videos in the playlist for easy querying. Developers can refer to the TensorRT-LLM RAG developer reference project on GitHub to build and deploy their own RAG-based applications for RTX, accelerated by TensorRT-LLM. NVIDIA's Chat with RTX harnesses the power of AI to enhance creativity, productivity, and gaming on GeForce RTX and NVIDIA RTX GPUs. If you're interested in exploring NVIDIA's generative AI developer tools and enterprise solutions, you can learn more on their website.

The discussion on Hacker News regarding the submission of the NVIDIA Chat with RTX app consists of two comments.

The first comment by "nckthgrk" contains a link to an external website along with the comment "dp". The content of the link is not provided in the summary.

The second comment by "ChrisArchitect" informs that there is more discussion on the topic available in the linked duplicate post.

No further details or insights from the discussion are provided in the given information.

### Dude, where's my self-driving car?

#### [Submission URL](https://www.theverge.com/24065447/self-driving-car-autonomous-tesla-gm-baidu) | 18 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [32 comments](https://news.ycombinator.com/item?id=39357882)

In 2015, Google's self-driving car project leader Chris Urmson predicted that self-driving cars would be so widespread by 2020 that his then-11-year-old son would never need a driver's license. Fast forward to 2024, and autonomous vehicles are still far from being a common sight on the roads. Over the years, there have been numerous missed deadlines and overly optimistic predictions about the availability of self-driving cars. Companies like Baidu, Lyft, GM, and Ford all promised to have autonomous vehicles on the market by certain dates, but those deadlines have come and gone without fruition. Even Tesla CEO Elon Musk, known for his bold claims, has made inaccurate predictions about the readiness of autonomous vehicles. Despite some autonomous cars currently operating in select cities, they are confined to geofenced service areas and face technological limitations, opposition from labor unions, and restrictions on certain roads and weather conditions. The hype surrounding autonomous vehicles has allowed companies to secure funding for their experiments, while regulators have taken a relatively lenient stance on self-driving car testing. However, the industry's failure to deliver on its promises raises questions about the underlying reasons for the delay. One of the primary motivations behind the optimistic predictions was financial gain, as companies were able to secure funding based on the promise of an imminent autonomous future. This flow of money also influenced regulators to adopt a more permissive approach to self-driving car testing. Companies operating in the autonomous vehicle space have raised billions of dollars through traditional fundraising channels and partnerships with big tech and car companies. While some progress has been made, the widespread availability of self-driving cars still remains a distant reality.  

The discussion on this submission revolves around various aspects of self-driving cars. One user shares their experience with adaptive cruise control in a 2022 Kia Telluride, mentioning its limitations and the need for constant attention while driving. Another user expresses their skepticism about relying on self-driving technology, citing personal experiences of confusion and dangerous situations with Tesla's Full Self-Driving (FSD) feature. The discussion then moves to a debate about the safety and reliability of autonomous driving systems compared to human drivers. Some users argue that self-driving technology is not yet capable of completely replacing human drivers, while others defend Tesla's capabilities and criticize non-Tesla manufacturers. There is also a discussion about the societal impact of self-driving cars, with one user mentioning the convenience of having a personal chauffeur for long trips and another user highlighting the hassle of public transportation for weekend ski trips. The conversation concludes with a user expressing their disinterest in purchasing a Level 4+ autonomous vehicle due to the limited budgets and high costs associated with self-driving options.

