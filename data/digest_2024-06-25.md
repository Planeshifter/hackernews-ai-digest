## AI Submissions for Tue Jun 25 2024 {{ 'date': '2024-06-25T17:11:41.785Z' }}

### Waymo One is now open to everyone in San Francisco

#### [Submission URL](https://waymo.com/blog/2024/06/waymo-one-is-now-open-to-everyone-in-san-francisco/) | 450 points | by [ra7](https://news.ycombinator.com/user?id=ra7) | [559 comments](https://news.ycombinator.com/item?id=40789411)

Waymo has officially opened its doors to all residents and visitors in San Francisco, offering autonomous ride-hailing services 24/7. The service, Waymo One, has been steadily growing, providing tens of thousands of weekly trips to various destinations in the city, including local businesses, medical appointments, and even weddings. With a focus on sustainability, Waymo's all-electric fleet has significantly reduced carbon emissions and improved the overall sense of personal safety for riders.

This expansion marks a significant milestone in Waymo's journey to revolutionize transportation, with a strong emphasis on safety and responsible scaling. By leveraging their extensive experience in autonomous driving technology, Waymo aims to enhance road safety and provide a reliable, eco-friendly transportation option for San Franciscans. Through collaborations with organizations like Mothers Against Drunk Driving, Waymo is dedicated to preventing road tragedies and making a positive impact on the community.

With a growing number of riders and a commitment to gradual expansion, Waymo is set to transform the way people travel in San Francisco, offering a unique and inclusive mobility experience for all.

The discussion on Hacker News about Waymo's autonomous ride-hailing service in San Francisco included various viewpoints and concerns. Some users highlighted the cleanliness and comfort of the vehicles compared to traditional taxis and Uber, emphasizing the benefits of the service. Others raised issues regarding unsupervised driving, potential safety risks, and the need for internal cameras to monitor the passengers and the environment. There were also comments about the challenges of maintaining cleanliness in self-driving cars and the incentives for drivers to keep the vehicles clean. Additionally, there was a discussion about the responsibility for cleaning the vehicles and the differences in cleanliness standards between Uber and Waymo. Overall, the conversation touched on aspects related to safety, cleanliness, technological advancements, and operational challenges in autonomous transportation services.

### Twonkie: A USB-PD sniffer/injector/sink based on Google's Twinkie open hardware

#### [Submission URL](https://github.com/dojoe/Twonkie) | 161 points | by [transpute](https://news.ycombinator.com/user?id=transpute) | [23 comments](https://news.ycombinator.com/item?id=40783485)

Today on Hacker News, a project called "Twonkie" caught the attention of the tech community. It is a USB-PD sniffer/injector/sink that is a re-design of Google's Twinkie, made to be more accessible for hobbyists to manufacture. While Twinkie was a great but challenging solution due to its complex design, Twonkie simplifies the process by using a four-layer PCB that can be easily manufactured by services like OSHPark. It also uses leaded parts for easier soldering and supports both TQFP and QFN microcontroller footprints.

The project addresses the challenges faced by hobbyists by providing detailed instructions on how to build your own Twonkie, including sourcing the parts and assembling the device. The creator also shares tips on possible part replacements and beginner-friendly advice for those new to soldering.

Overall, Twonkie offers a more accessible alternative to Google's Twinkie for those interested in USB-PD sniffing and related projects.

The discussion on the submission about the project "Twonkie" on Hacker News covers various aspects related to USB-PD sniffing devices. Here are some key points summarized from the comments:

- A commenter highlighted that commercial PD analyzers are available for around $200 and provided links for reference.
- Other users discussed alternatives to building a Twonkie, such as a $60 charger load tester or a Power-Z KM003C device.
- There were discussions on the functionality and performance of different devices, as well as references to related hardware tools for USB-PD monitoring.
- Some users shared their experiences with USB-C brackets, power supplies, and 3D-printed enclosures for related projects.
- A commenter shared insights about AliExpress search terms for similar devices and experiences with testing different products.
- Links to original resources like the Twinkie project archive and other related tools were also shared in the comments.

Overall, the discussion provided a mix of technical insights, experiences with similar devices, and recommendations for tools and resources related to USB-PD sniffing and monitoring projects.

### Language models on the command line

#### [Submission URL](https://simonwillison.net/2024/Jun/17/cli-language-models/) | 137 points | by [rednafi](https://news.ycombinator.com/user?id=rednafi) | [42 comments](https://news.ycombinator.com/item?id=40782755)

Simon Willison shared his insights on accessing Large Language Models (LLMs) from the command-line in a recent talk at the Mastering LLMs online conference. His LLM Python command-line utility allows users to explore and utilize LLMs for various tasks conveniently. By installing the tool, configuring it with OpenAI models or plugins for other providers, users can run prompts like "five great names for a pet pelican" and stream the output to their terminal or redirect it to a file. Simon also highlighted the usage of plugins like llm-claude-3, which provides access to models such as Claude 3 Opus and Claude 3 Haiku. Additionally, he demonstrated logging prompts and responses to a SQLite database for further analysis using tools like Datasette. Simon further discussed the integration of images and the use of plugins like llm-cmd and llm-gpt4all, offering diverse options for interacting with local models. Furthermore, he touched upon running models efficiently with options like llm chat, llm-ollama for hosting models, and llamafile for bundling models and software in a single executable file. Simon emphasized the potential to create scripts for automating tasks, showcasing a Bash script he developed to summarize Hacker News discussions using LLMs like Claude 3 Haiku or Google Gemini 1.5. This informative presentation opens up exciting possibilities for leveraging LLMs directly from the command line.

The discussion around Simon Willison's talk on accessing Large Language Models (LLMs) from the command-line has attracted a variety of responses and projects. 

- **CLI Tools for Using LLMs**: Users have shared various CLI tools they've developed or come across for working with LLMs in the terminal, such as the Open Interpreter project and tools like llm-claude-3 and llm-gpt4all.

- **Wrapping LLMs for Specific Purposes**: Some users have shared their experiences of wrapping LLMs for specific tasks, such as generating tutorials based on recent commits or experimenting with LLMs for coding tasks.

- **Exploring LLM Capabilities**: Discussions revolve around the potential of leveraging LLMs for different tasks, such as investigating Prometheus, Jira, and PagerDuty, and the challenges of fine-tuning LLMs for specific applications.

- **Automating Tasks with LLMs**: Users have highlighted the potential for automating tasks using LLMs, such as creating a Bash script to summarize Hacker News discussions or utilizing LLMs for efficient command-line interactions.

- **Enhancing User Interaction with LLMs**: Projects like Descartes aim to provide a spatial, UX-focused command-line tool for non-hackers to efficiently interact with LLMs, emphasizing the transformative potential of LLMs in changing computer interaction paradigms.

- **RAG (Retrieval Augmented Generation) Applications**: Implementations like RAG for search results and answer generation in the terminal showcase the practical applications of LLMs for retrieving and summarizing information effectively.

Overall, the conversation reflects a diverse range of interests and projects centered around exploring, utilizing, and enhancing the capabilities of LLMs via the command-line interface.

### Sohu: The First Transformer ASIC

#### [Submission URL](https://www.etched.com/) | 36 points | by [HCazlab](https://news.ycombinator.com/user?id=HCazlab) | [14 comments](https://news.ycombinator.com/item?id=40790775)

Exciting news on Hacker News today! Etched has secured a whopping $120 million in funding to develop Sohu, the world's first transformer ASIC. By embedding the transformer architecture directly into silicon chips, Sohu promises to revolutionize AI model processing by making it 10 times faster and more cost-effective than using GPUs. This breakthrough technology opens the door to creating products that were previously impossible with traditional GPUs, such as real-time voice agents and multicast speculative decoding to generate content on the fly. Sohu boasts fully open-source software, support for trillion-parameter models, and a massive 144 GB HBM3E per chip. The future of AI processing just got a whole lot more thrilling!

The discussion on Hacker News about Etched's $120 million funding for developing Sohu, the transformer ASIC, touched on various aspects of the technology and its potential implications:

1. User "mysterEFrank" made a cryptic statement regarding the architecture and speed of the transformer ASIC, which prompted responses discussing memory bandwidth limitations and the efficiency of computing on such chips.
2. User "galaxyLogic" pointed out the differences between ASICs and FPGAs, highlighting the fast memory requirements of ASICs and mentioning the acquisition of Xilinx by AMD.
3. User "ted_dunning" explained the concept of ASICs and their application-specific nature, emphasizing their potential for faster memory access and large matrix arithmetic operations.
4. User "Zaheer" mentioned the significance of custom ASICs in comparison to Nvidia's designs, with discussions revolving around transformer model structures and programmability considerations.
5. User "ChrisArchitect" shared the official post link related to the announcement.
6. Lastly, comments by "jkllyrtp" and "ted_dunning" discussed the implications of designing and deploying ASICs in the context of dominating the AI market, with a mention of OpenAI's API interface.

