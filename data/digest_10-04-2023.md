## AI Submissions for Wed Oct 04 2023 {{ 'date': '2023-10-04T17:10:47.024Z' }}

### Vespa.ai is spinning out of Yahoo as a separate company

#### [Submission URL](https://blog.vespa.ai/vespa-is-becoming-its-own-company/) | 330 points | by [bratao](https://news.ycombinator.com/user?id=bratao) | [128 comments](https://news.ycombinator.com/item?id=37769962)

Vespa.ai, the open big data serving engine that was originally developed by Yahoo, is now being spun off as a separate company. Since it was open-sourced in 2017, Vespa has grown to become a popular platform for applying AI to big data sets in real-time. It has been particularly favored by enterprises working with large language models and vector databases. To address scalability needs, a centralized cloud service was created to host Vespa applications, resulting in significant time and resource savings. While Vespa is separating from Yahoo, the search engine will still own a stake in the company and continue to use Vespa for personalized content and search. The creation of a separate company will allow Vespa to expand its offerings to the rest of the world and accelerate the development of new features.

The discussion on the Hacker News submission revolves around various aspects of Vespa.ai, its spin-off from Yahoo, and its potential. Here are the key points raised in the comments:

- Some users highlight the financial aspects of Yahoo's decision, speculating that Yahoo's stake in Vespa may be a strategic move for future growth.
- Others compare Vespa's spin-off strategy to that of Cisco's, emphasizing the advantages of separating a research and development company to attract investors and focus on experimental products.
- There is a discussion about Yahoo's past decisions and their impact on their current relevance, with some users criticizing Yahoo's previous focus on irrelevant projects.
- One user mentions Vespa's technology being built for search serving, while Yahoo's recent moves seemed to distract from their core goals.
- Several users express their excitement and congratulate the Vespa team for its impressive platform that combines traditional search with semantic search and embeddings.
- The benefits of Vespa's hybrid search capabilities and its functionality for multi-phase ranking and machine learning models are highlighted.
- It is mentioned that Vespa's platform is competitive in the market, especially for vector databases, versatile text search, and complex search systems.
- Some users discuss their experiences working with Vespa and other search platforms, such as Solr, ElasticSearch, and Weaviate.

Overall, the discussion highlights the significance of Vespa's technology, its potential for growth, and the positive reception from users who have worked with it.

### Security weaknesses of Copilot generated code in GitHub

#### [Submission URL](https://arxiv.org/abs/2310.02059) | 122 points | by [belter](https://news.ycombinator.com/user?id=belter) | [81 comments](https://news.ycombinator.com/item?id=37770233)

A recent study has analyzed the security weaknesses of code snippets generated by GitHub Copilot, a popular code generation tool that uses AI models. The researchers conducted an empirical study on publicly available projects hosted on GitHub to investigate the security issues in automatically generated code in real-world scenarios. Out of 435 code snippets generated by Copilot, they found that 35.8% contained Common Weakness Enumeration (CWE) instances. The security weaknesses were diverse and related to 42 different CWEs, with OS Command Injection, Use of Insufficiently Random Values, and Improper Check or Handling of Exceptional Conditions being the most frequently occurring issues. The study highlights the importance of careful consideration and security checks when adding code generated by AI code generation tools like Copilot.

The discussion on this submission revolves around the weaknesses and capabilities of GitHub Copilot, as well as the concept of intelligence and how it should be measured. One commenter suggests that Copilot's popularity doesn't necessarily mean it generates correct code, as common weaknesses can still be present. Another commenter argues that AI models like Copilot are not true artificial intelligence but rather artificial mediocrity. There is also a discussion on the definition of intelligence, with some arguing that AI cannot be compared to human intelligence and others suggesting that AI can perform intelligent tasks regardless of its type. The conversation branches out to topics such as IQ, the limitations of AI, the ambiguity of the term "intelligence," and the potential impact of AI on democratic governments. Other commenters mention the importance of evaluating Copilot's functionality and suggest that improvements could be made based on user feedback.

### AI beats human sleuth at finding problematic images in research papers

#### [Submission URL](https://www.nature.com/articles/d41586-023-02920-y) | 142 points | by [webmaven](https://news.ycombinator.com/user?id=webmaven) | [87 comments](https://news.ycombinator.com/item?id=37772206)

Artificial intelligence (AI) tools are now being used to detect image manipulation in scientific papers, helping to catch alterations that go beyond accidental or aesthetic changes. In a recent study, a biologist manually examined several hundred papers for duplicated images and then compared the results to those generated by an AI tool. The AI tool not only identified almost all of the papers flagged by the biologist, but also found additional suspect papers that were missed. This suggests that AI can significantly enhance the detection of manipulated images in scientific research. Various publishers and academic institutions are already using AI tools to screen papers for image integrity. One such tool, Imagetwin, compares images in a paper to a database of over 25 million images from other publications. While AI tools are helpful, they do have limitations, such as missing duplications in low-contrast images. Overall, the adoption of AI for image checking is expected to improve the detection and prevention of image manipulation in research papers.

The discussion on this submission revolves around various aspects of using AI tools to detect image manipulation in scientific papers. Some commenters express concerns about privacy and potential misuse of AI tools, drawing parallels with the use of AI for detecting illegal content. Others highlight the limitations of AI tools, such as their inability to detect manipulations in low-contrast images. There is also a debate about the reliability of peer review, with some arguing that it is flawed and prone to bias. The discussion touches on the need for better measures to detect and prevent image manipulation in research papers, including the use of AI tools.

### Extracting Hacker News book recommendations with the ChatGPT API

#### [Submission URL](https://blog.reyem.dev/post/extracting_hn_book_recommendations_with_chatgpt_api/) | 403 points | by [kristianp](https://news.ycombinator.com/user?id=kristianp) | [199 comments](https://news.ycombinator.com/item?id=37761273)

The Hacker News (HN) book recommendation threads are full of intriguing titles and authors. Using the GPT API, one user extracted the top 50 book recommendations from these threads. At the top of the list is "Structure and Interpretation of Computer Programs" by Abelson and Sussman, with 376 mentions. Other popular books include "Gödel, Escher, Bach" by Douglas Hofstadter, "How to Win Friends and Influence People" by Dale Carnegie, and "The C Programming Language" by Brian Kernighan and Dennis Ritchie. The list also features classics like "1984" by George Orwell and "The Lord of the Rings" by J.R.R. Tolkien. The user found that GPT's responses varied, but overall, it provided valuable information on book titles, authors, and even links to purchase the books.

The discussion on this submission revolves around various topics related to book recommendations, the accuracy of AI-generated content, and the limitations of artificial intelligence compared to human intelligence.

One user comments on the ability of people to make money through Amazon affiliate programs but criticizes the OP for sharing a link that disguises the affiliate tag. Another user suggests that they have been reading books recommended on Hacker News and have found it to be a great way to learn and expand their mind. They also provide links to different resources for finding book recommendations on Hacker News.

A user thanks the OP for sharing the book recommendations but mentions that they had previously saved a similar list two years ago. Another user points out that it's surprising that the book "Code" by Charles Petzold didn't make it to the top 50, speculating that HN might have skewed preferences when it comes to book recommendations.

A discussion on trustworthiness and validity of online content ensues. Some users express skepticism toward trusting AI-generated content and emphasize the importance of verifying information through reliable sources. Others argue that humans can also be unreliable and that critical thinking should be applied to any source of information, whether it's created by AI or humans.

The conversation then diverges to debating the intelligence of AI compared to humans. Some users believe that AI like ChatGPT can be as intelligent or more intelligent than humans, while others argue that human expertise and nuanced understanding cannot be replicated by AI.

There are also discussions about the content of specific books such as "Gödel, Escher, Bach" and "Code," where users share their opinions and recommendations.

Overall, the discussion covers a range of perspectives on book recommendations, the trustworthiness of AI-generated content, and the capabilities of AI compared to human intelligence.

### Expressive text-to-image generation with rich text

#### [Submission URL](https://rich-text-to-image.github.io/) | 85 points | by [plurby](https://news.ycombinator.com/user?id=plurby) | [33 comments](https://news.ycombinator.com/item?id=37770260)

Researchers from the University of Maryland, Adobe Research, and Carnegie Mellon University have developed a framework that enables expressive text-to-image generation by incorporating versatile format information from rich text. The framework allows for precise control over local styles, generation of accurate colors, and supplementary descriptions for detailed prompts. By utilizing attributes such as font size, color, style, and footnotes, the framework can generate images based on text prompts that specify various visual elements and artistic styles. The researchers demonstrated the framework's capabilities by generating images of pizzas, night skies, churches, pandas, pixel art ducks, girls in cafes, and more, each with detailed descriptions and style control. The framework outperforms existing methods in terms of local style control, color generation, and supplementary descriptions. The research paper on this framework, titled "Expressive Text-to-Image Generation with Rich Text," was presented at the IEEE International Conference on Computer Vision (ICCV) in 2023.

The discussion about the submission on Hacker News includes several comments that provide insights and opinions on the framework for expressive text-to-image generation with rich text. Here are some key points from the discussion:

- One user mentioned that plain-text prompts can result in baseline image generation, while rich-text prompts can expand the range of possibilities. They shared a link to a research paper that showcases the results of full-text prompts and their limitations in changing colors and styles.

- Another user pointed out that specifying styles when describing an image can be simple and effective. They shared examples of how words like "Ukiyo- Van Gogh" can generate detailed descriptions with desired styles.

- A user raised confusion about the capabilities of the models when presented with extremely similar prompts resulting in different images. They suggested that it might be harder to interactively change the text and generate entirely new images.

- There was a discussion about the interpretation of fonts and their styles. One user mentioned that fonts can have cultural and stylistic meanings and wondered if the framework can interpret different fonts accurately. The researcher clarified that the framework does not interpret font styles in the paper.

- Some users highlighted the importance of stable diffusion in generating images and the challenges of controlling local changes in the existing diffusion-based approaches. They mentioned that stability is one of the biggest problems in current methods.

- Another user appreciated the use of rich text prompts and the control it provides over generating images with specific colors and styles. They mentioned that tools like Regional Prompter can help in specifying regional specifications for image prompts.

- One user expressed their interest in pixel art generation and mentioned that they will give it a try.

- A few users discussed the potential applications of the framework in natural language processing and the benefits of using detailed descriptions in generating images.

- Overall, the discussion was positive, with users praising the capabilities and advancements of the framework, while also providing constructive criticism and asking questions about specific aspects of the research.

### Qualcomm’s Hexagon DSP, and Now, NPU

#### [Submission URL](https://chipsandcheese.com/2023/10/04/qualcomms-hexagon-dsp-and-now-npu/) | 53 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [23 comments](https://news.ycombinator.com/item?id=37772427)

Qualcomm is adding matrix multiplication capabilities to its Hexagon DSP (Digital Signal Processor) to address the recent rise in machine learning applications. Hexagon is an in-order, four-wide very long instruction word (VLIW) processor that offloads signal processing tasks from the CPU, resulting in lower power usage. It uses a co-processor model for its vector and tensor units, providing massive per-clock throughput. Hexagon supports virtual memory and caching and can run compiled C code. It has a branch predictor for efficient execution and fetches a 128-bit VLIW bundle from the instruction cache. The scalar unit of Hexagon is powerful and can handle lightweight DSP tasks on its own, with specialized instructions for various operations. Hexagon also has hardware looping and circular buffer handling to improve instruction density and register utilization.

The discussion on the submission about Qualcomm adding matrix multiplication capabilities to its Hexagon DSP involves a range of topics. 

- Several comments express surprise that Qualcomm's Hexagon DSP is a closed system and lacks documentation. One user compares this to their experience with Nvidia, where they found better public documentation and transparency. Another user suggests that Qualcomm's licensing model may be a reason for the lack of openness.

- There is a discussion about the restrictions on accessing Hexagon DSP features. One user points out that the High-level OS running on Hexagon requires signed Qualcomm firmware, limiting its use to certified OEMs. Another user mentions that unsigned PDs (Process Development) are allowed but with limited access to the underlying DSP drivers.

- A user shares their experience with trying to make Halide work on Hexagon, a programming language for efficiently implementing image processing algorithms. They mention that using Halide could greatly benefit developers.

- The restriction of Hexagon DSP access on non-platform Android apps is mentioned, indicating that certain things may not work on those devices.

- A user expresses their frustration with the approach of relying on specialized co-processors like Hexagon for performance improvements, stating that it leads to fragmented user experiences and unnecessary complexity.

- The difficulty of programming Hexagon DSP is discussed, with one user mentioning that the Hexagon SDK does not provide direct access to the tensor hardware, and another user agrees that the documentation and support for certain hardware conversions and optimizations are lacking.

- The Hexagon DSP's VLIW architecture is mentioned, and a user points out that while VLIW can make programming harder, it also has benefits in terms of instruction dependencies and program generation.

- The use of high-level programming models such as FastRPC and Halide is mentioned positively.

- The confusion caused by Qualcomm's naming schemes is discussed, with users expressing frustration about the lack of clarity and documentation, particularly with regards to Hexagon Matrix Extensions (HMX).

Overall, the discussion highlights the challenges and complexities involved in programming Hexagon DSP, the limitations imposed on accessing its features, and the need for better documentation and transparency from Qualcomm.

### Ring attention with blockwise transformers for near-infinite context

#### [Submission URL](https://arxiv.org/abs/2310.01889) | 40 points | by [muggermuch](https://news.ycombinator.com/user?id=muggermuch) | [16 comments](https://news.ycombinator.com/item?id=37769893)

The paper titled "Ring Attention with Blockwise Transformers for Near-Infinite Context" by Hao Liu, Matei Zaharia, and Pieter Abbeel presents a new approach called Ring Attention for handling long sequences in AI models. Transformers, which have become popular in AI architectures, have limitations when it comes to handling long sequences due to memory constraints. Ring Attention overcomes these limitations by distributing long sequences across multiple devices and overlapping the communication of key-value blocks with the computation of blockwise attention. This enables processing of longer input sequences while maintaining memory efficiency, effectively eliminating the memory constraints imposed by individual devices. The paper demonstrates the effectiveness of Ring Attention through extensive experiments on language modeling tasks. The approach allows for larger sequence input sizes and improves performance.

The discussion on this submission covers a range of topics. Here are some key points:

- Some users express skepticism about the effectiveness of transformers and suggest that researchers may be looking for alternatives. They discuss the limitations of transformers when it comes to handling long sequences.
- One user shares a paper titled "Linear Transformers are Secretly Fast Weight Programmers" and another user shares a paper titled "Language Models Implicitly Perform Gradient Descent on Meta-Optimizers" for further reading.
- There is a discussion about the proliferation of transformer-related research and the need for more diversity in research topics.
- Some users comment on the abstract of the paper and provide their thoughts on the proposed Cyclical Attention Mechanism. They discuss how it enhances transformer architectures and enables the handling of long-range dependencies, leading to improved performance in various tasks.
- One user expresses disappointment with the phrase "Near-Infinite" in the paper title, while others suggest alternative terms like "Unbounded" or "Virtually Infinite."
- Finally, there is a comment expressing excitement with multiple repetitions of "WOWOWOWOWOWOWOWOOWOWOWOWOWOWOWOW."

Overall, the discussion touches on the limitations of transformers, alternative approaches, related research papers, and thoughts on the proposed Cyclical Attention Mechanism.

### Meta starts rolling out generative AI tools for all advertisers

#### [Submission URL](https://www.reuters.com/technology/meta-starts-rolling-out-generative-ai-tools-all-advertisers-2023-10-04/) | 57 points | by [mfiguiere](https://news.ycombinator.com/user?id=mfiguiere) | [34 comments](https://news.ycombinator.com/item?id=37768018)

Social media giant Meta Platforms (formerly Facebook) has announced the rollout of generative AI tools that can create content for advertisers, such as image backgrounds and variations of written text. These tools were initially tested with a select group of advertisers in a "testing playground" and will be available in Meta's Ads Manager, with the rollout expected to be completed next year. This marks Meta's first integration of generative AI technology into its products, allowing for the generation of new content using vast stores of past data. Meta's portfolio of AI products includes its language model "Llama 2" and an AI chatbot called Meta AI.

The discussion surrounding Meta Platforms' announcement about the rollout of generative AI tools for advertisers on Hacker News covers a range of topics. Here are the main points discussed:

- Some users express concerns about the potential for misuse of this technology, warning that it could lead to misleading advertising and phishing scams. They criticize Meta for not prioritizing user trust and safety in its pursuit of new AI capabilities.
- Others highlight the difficulty of controlling technology and its potential negative effects on society. They argue that the development of advanced AI is ultimately leading to the downfall of civilization.
- Some users reference recent incidents where YouTube released targeted Western-sounding voiceovers for Chinese companies, suggesting that this technology can be used to create deceptive content.
- There are mentions of Apple News and the effectiveness of fully generated display ads in that platform.
- One user criticizes Mark Zuckerberg for promoting a cryptocurrency trading platform called Libre and argues that Facebook itself is not trustworthy.
- The topic of AI-generated profiles and its implications is briefly touched upon, with one user comparing it to "The Truman Show" and suggesting that AI could create a pleasant online environment.
- Users discuss the impact of AI on advertising campaigns and the advantages it provides for established companies versus smaller players in the business.
- Some users mention Google's programmatically driven advertising tools and discuss the challenges and benefits of using AI in advertising.
- The thread ends with a user expressing frustration with Facebook Ads and their experience with customer support.

Overall, the discussion highlights some concerns about user trust and safety, the potential for misuse of AI technology, and the complexities and impact of AI in advertising.

### Training language models with pause tokens

#### [Submission URL](https://arxiv.org/abs/2310.02226) | 152 points | by [og_kalu](https://news.ycombinator.com/user?id=og_kalu) | [69 comments](https://news.ycombinator.com/item?id=37764382)

The paper titled "Think before you speak: Training Language Models With Pause Tokens" explores the idea of letting language models manipulate a larger number of hidden vectors before generating the next token in a sequence. The authors introduce a "pause" token that allows the model to process extra computations before committing to an answer. They evaluate this approach on various tasks and find that pre-training and fine-tuning with delays at inference time leads to significant gains in performance. For example, they observe an 18% increase in EM score on the QA task of SQuAD and an 8% increase on CommonSenseQA. The findings of this study open up new research questions and possibilities for delayed next-token prediction as a new paradigm in language modeling.

The discussion on Hacker News revolves around various aspects of the paper titled "Think before you speak: Training Language Models With Pause Tokens." Some commenters express curiosity about the potential benefits of externalizing higher-level information for language models to improve their performance. Others find the concept fascinating but note that it may require further research.

There is a discussion about the effectiveness of using pause tokens in language models. Some commenters suggest that allowing models to spend more time considering an answer can lead to better results, while others question the need for additional computation and its impact on inference speed.

One commenter mentions that ChatGPT users have suggested that filler tokens can lead to longer responses and higher quality answers, although the overall functioning of these tokens is described as bizarre.

There is also a debate about the relationship between language models and human thinking. Some commenters argue that language models can improve their output by mimicking human thinking processes, while others believe that human thinking and internal monologue are fundamentally different from the models' operations.

The discussion also touches on the replication crisis in psychology and references the book "Thinking, Fast and Slow" by Daniel Kahneman. Some commenters express skepticism about the credibility of certain psychological studies, while others view Kahneman's work as holding up under scrutiny.

In response to a comment about the possibility of internal monologue in language models, one commenter suggests that models already have the capability but may not express it in the same way as humans do.

Overall, the discussion delves into the potential implications and limitations of the paper's findings, as well as broader considerations regarding human thinking and the capabilities of language models.

### On re-reading “Brave New World”

#### [Submission URL](https://gossmanster.substack.com/p/brave-new-world) | 6 points | by [johngossman](https://news.ycombinator.com/user?id=johngossman) | [3 comments](https://news.ycombinator.com/item?id=37772415)

In this blog post from Spherical Cows and Repugnant Conclusions, the author reflects on their recent re-reading of Aldous Huxley's "Brave New World." They discuss the different themes and critiques presented in the book, including the satire of capitalism and consumerism, as well as the cautionary tale about socialism. The author also quotes passages from the book that touch on philosophy and the idea of utopia. They end the post with a powerful quote from one of the World leaders in the book, highlighting the absence of nobility or heroism in a stable society.

The discussion in the comments revolves around various interpretations and critiques of Aldous Huxley's "Brave New World." One user points out that they couldn't understand or appreciate the book due to its absurd tendencies and the Cold War context in which it was written. Another user agrees, stating that they found the book to be a negative portrayal of human consumption, with extreme consumption being harmful to society. Another user adds that they personally found the extreme consumption depicted in the book to be expanding their perspective.

### Self-Assembling Artificial Neural Networks Through Neural Developmental Programs

#### [Submission URL](https://arxiv.org/abs/2307.08197) | 65 points | by [hardmaru](https://news.ycombinator.com/user?id=hardmaru) | [16 comments](https://news.ycombinator.com/item?id=37759668)

Researchers Elias Najarro, Shyam Sudhakaran, and Sebastian Risi have published a paper titled "Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs." The paper explores the idea of creating neural networks that grow through a developmental process similar to embryonic development in biological organisms. The researchers propose a Neural Developmental Program (NDP) that guides the growth process through local communication. The paper investigates the role of neural growth on various machine learning benchmarks and optimization methods. The authors also highlight future research directions and opportunities enabled by this self-organizing approach to neural network development.

The discussion on this submission includes various perspectives and opinions on the topic. 

One commenter, Nevermark, points out that the brain wasn't built like artificial neural networks. They believe that DNA programming in biological organisms changes slowly through evolution and is not specifically designed to work on survival problems. They also mention that not every aspect of the brain's architecture is custom-designed for specific problems and data.

Another commenter, vcty, suggests that brains need neural networks for evaluation, including terms like brain development, sexual dimorphism, and genetics. They argue that it's not as simple as changing sensory inputs over time and that brain development involves scruples and crosses.

Great_psy finds the idea promising but suggests that it requires extra competition to achieve self-assembly. They compare it to the competition that occurs in human-designed neural networks.

Mdlss expresses surprise that designing neural network architectures is a problem, as neural networks fight by humans tend to work well. They also mention the concept of self-optimizing architectures not being standard or documented.

Signa11 responds to Mdlss, agreeing that designing neural architectures is a problem, but they suggest that self-optimizing architectures can be achieved through evolutionary algorithms such as Neuroevolution of augmenting topologies (NEAT).

Nsphr adds to the conversation by discussing the role of evolution and environment in the development of organisms, suggesting that organisms not only try to respond logically to the environment but may also recreate and regenerate the environment.

Drgnwrtr believes that designing neural network architectures is a difficult problem. They mention the limitations of current state-of-the-art neural network architectures and the need for high-quality training data to train neural networks effectively.

Great_psy suggests that maybe humans are building neural network architectures, and a neural network design would be a byproduct of human design. They propose that neural networks eventually just begin to compete with human-designed architectures, and then human design becomes the optima for complexity optimization.

In another comment, Dsgn discusses the current state of designing neural network architectures. They mention that the current crop of large language models (LLMs) started with a predefined neural network architecture, but things like the number of layers, class cost function, and specific architecture choices can be explored. They argue that this kind of knowledge leveraged by human engineers could be applied to building more optimized neural network architectures.

The final comment by Djldmn provides an abstract of the paper, mentioning that while biological nervous systems are fundamentally different from current artificial neural networks, their growth process shares similarities with embryonic development in biological organisms. The paper proposes a Neural Developmental Program (NDP) that guides the growth process through local communication. The authors investigate the role of neural growth on various machine learning benchmarks and optimization methods and highlight future research directions enabled by this self-organizing approach to neural network development.

### AI is replacing customer service jobs across the globe

#### [Submission URL](https://www.washingtonpost.com/technology/2023/10/03/ai-customer-service-jobs/) | 39 points | by [bookofjoe](https://news.ycombinator.com/user?id=bookofjoe) | [23 comments](https://news.ycombinator.com/item?id=37764050)

Indian e-commerce platform Dukaan has replaced its customer service team with an AI-powered chatbot, highlighting the shift towards automation in call centers. The company, led by CEO Suumit Shah, implemented OpenAI's ChatGPT to enhance its in-house chatbot Lina. The bot was trained using Dukaan's help center content and began fielding customer messages in December 2022. The company found that customers were largely satisfied with the AI-powered customer service. By June, Dukaan had fired 27 customer service agents and replaced them with the bot. Economists and workforce development experts warn that the automation of call centers could have a significant impact on economies, particularly in countries like India and the Philippines, which heavily rely on call center work. The emergence of artificial intelligence threatens millions of jobs in these countries, but some experts argue that AI can augment human workers rather than replace them completely.

The discussion surrounding the submission revolves around the impact of replacing customer service teams with AI-powered chatbots in call centers. Some users express concerns about the mental health of call center workers and argue that the job can be mentally taxing. They also mention the potential loss of job opportunities for low-skilled workers due to automation. Others believe that AI can support traditional customer service and enhance efficiency. There is a mention of a company that allegedly mistreated its customer service employees, and some users express skepticism about the capabilities and limitations of AI chatbots. One user provides an example of an AI chatbot answering questions in a problematic manner. The discussion also touches on topics such as the privacy of AI chatbots and the need for human involvement in customer service interactions.

### Generative AI Is the Newest Tool in the Dictator's Handbook

#### [Submission URL](https://gizmodo.com/freedom-house-2023-freedom-on-the-net-report-ai-1850887842) | 32 points | by [rntn](https://news.ycombinator.com/user?id=rntn) | [3 comments](https://news.ycombinator.com/item?id=37764238)

A recent report from Freedom House reveals that political leaders in at least 16 countries have been using deepfakes and other AI tools to manipulate public opinion and suppress dissent. Examples include former Pakistan Prime Minister Imran Khan sharing a video clip on Twitter showing manipulated images of his supporters, and former President Donald Trump and Florida Governor Ron DeSantis using deepfaked videos and audio to smear each other. The report also highlights how governments are mandating social media companies to use AI to remove disfavored political, social, and religious speech, ultimately enabling political repression. Additionally, state actors are employing private "AI-for-hire" companies to create AI-generated propaganda, including deepfake newscasters. The report warns that as AI tools become more convincing and affordable, the use of deepfakes may become more prevalent.

The discussion revolves around the topic of regulating the use of AI tools and its potential for negative consequences. One commenter brings up historical examples of art and technology being regulated, such as Leni Riefenstahl's mountain pictures and the printing press. They argue that strict regulation of AI is necessary to prevent harmful outcomes, including revenge pornography, child sexual abuse material (CSAM), instructional videos promoting dangerous behavior, propaganda, and the spread of hate. Another commenter adds that the disruptive nature of AI may have negative impacts on society, similar to how the hacking news practice is considered unpleasant. One response suggests that people commonly condemn technology as a common denominator.

