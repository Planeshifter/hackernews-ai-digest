## AI Submissions for Sun May 05 2024 {{ 'date': '2024-05-05T17:10:26.067Z' }}

### Infini-Gram: Scaling unbounded n-gram language models to a trillion tokens

#### [Submission URL](https://arxiv.org/abs/2401.17377) | 128 points | by [nsagent](https://news.ycombinator.com/user?id=nsagent) | [50 comments](https://news.ycombinator.com/item?id=40266791)

The paper titled "Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens" by Jiacheng Liu and team explores the relevance of $n$-gram language models vis-a-vis neural large language models. By training at the same scale as neural LLMs (5 trillion tokens) and introducing $\infty$-gram LM with backoff, the authors showcase the potential of $n$-gram LMs in text analysis and enhancing neural LLMs. The novel infini-gram engine, powered by suffix arrays, enables efficient computation of $\infty$-grams with millisecond-level latency for next-token prediction. Their findings suggest that $\infty$-gram LM can aid in reducing neural LLM perplexity and reveal insights into deficiencies in neural LLM pretraining and Transformer positional embeddings. This research pushes the boundaries of language modeling and offers valuable insights for both text analysis and model improvement.

The discussion on Hacker News surrounding the submission about the paper "Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens" by Jiacheng Liu and team delved into various aspects of language models, artificial intelligence, and the implications of the research findings:

1. Discussion on the relevance and refinement of current mental models of large language models (LLMs), the incorporation of attention mechanisms in models, the limitations in neural LLMs, and the potential benefits of n-gram language models in improving neural LLMs.
2. Conversation on human stochastic processes and learning, the comparison between toddlers' learning processes and the challenges faced by artificial neural networks in understanding concepts, and the utility of n-grams in basic arithmetic and language learning.
3. Exploration of creating small group personalities for internal dialogue generation, the concept of stream consciousness in internal decisions, and the role of neural LLMs in extrapolating experiences and synthesizing coherent thoughts.
4. Debate on the extrapolation of experiences in artificial intelligence, the limitations of statistical models in comparison to human intelligence, and the fundamental differences between AI capabilities and human cognition.
5. Analysis of sophisticated data structures like compressing suffix trees and the utilization of massive corpora for training language models.
6. Mention of the Infini-gram engine by Hugging Face and the expectations in large-scale language model training.
7. Critique on the perplexity results and the presentation of training data in machine learning models.

Overall, the discussion touched upon a wide range of topics, from the technical aspects of language models to the philosophical considerations of human intelligence and the challenges faced by artificial neural networks in emulating human cognitive abilities.

### Machine Unlearning in 2024

#### [Submission URL](https://ai.stanford.edu/~kzliu/blog/unlearning) | 304 points | by [ignoramous](https://news.ycombinator.com/user?id=ignoramous) | [84 comments](https://news.ycombinator.com/item?id=40264352)

In May 2024, Ken Liu delves into the compelling world of machine unlearning, a concept gaining traction as machine learning models expand in size and complexity. Unlearning involves removing undesired elements like private data, copyrighted material, and harmful content from trained models without starting from scratch. The article explores the history and motivations behind unlearning, spurred by regulations like the GDPR's right-to-be-forgotten. As models evolve to encompass a wide range of data and tasks, the need for unlearning has grown beyond privacy concerns to encompass issues of access revocation and model correction. The post provides insights into the challenges, techniques, and potential solutions in the realm of machine unlearning, offering a thought-provoking look at the future of AI ethics and model governance.

The discussion on the submission about machine unlearning on Hacker News raised several interesting points. Users discussed practicality in implementing unlearning methods, highlighting the need for real-world applications and legal acceptance. They also delved into the technical aspects of unlearning, such as the challenges in legal compliance and the accuracy of deleted data. Additionally, there were debates on the effectiveness of certain technologies like Markov chains and Deep Learning, with some questioning their utility in this context. The conversation also touched upon ethical considerations regarding the deletion of copyrighted content and the potential implications of using machine learning models for commercial purposes without proper authorization. Finally, there were discussions about the challenges of enforcing laws related to machine unlearning, such as handling copyright infringement and ensuring accountability.

### The long long tail of AI applications

#### [Submission URL](https://blog.waleson.com/2024/05/the-long-long-tail-of-ai-applications.html) | 14 points | by [jtwaleson](https://news.ycombinator.com/user?id=jtwaleson) | [3 comments](https://news.ycombinator.com/item?id=40268011)

The author explores the long tail of AI applications where foundational AI like GPT-4 and applied AI companies play a crucial role. They highlight the challenges faced in utilizing large language models (LLMs) effectively. Firstly, it's essential to ask the right questions to LLMs to receive accurate responses, a task that requires significant input from human intelligence. Secondly, LLMs have limited context by default, necessitating manual programming of agents to provide relevant information. Thirdly, LLMs are not AGI and require structured commands for tasks, making agent programming essential. Fourthly, LLMs struggle with specialized problems as they lack access to non-public or non-English information. Lastly, integrating AI into products demands substantial effort, from framing questions to providing context, which indicates a significant workload for applied AI companies in the foreseeable future.

The discussion revolves around the importance of structuring and designing workflows to accomplish tasks effectively in real-world applications. One user emphasizes the significance of understanding human intelligence and the differences between AI, AGI, and human productivity in this context. Another user highlights the vital role of structuring information and building good applications to ensure successful task completion, mentioning the complexities of real-world use cases and the challenges faced in integrating models into applications effectively.

### SEQUOIA: Exact Llama2-70B on an RTX4090 with half-second per-token latency

#### [Submission URL](https://infini-ai-lab.github.io/Sequoia-Page/) | 127 points | by [zinccat](https://news.ycombinator.com/user?id=zinccat) | [60 comments](https://news.ycombinator.com/item?id=40261965)

The Sequoia project introduces a cutting-edge speculative decoding framework that revolutionizes the speed and efficiency of serving large language models on consumer GPUs without compromising accuracy. By leveraging a large speculation budget, Sequoia achieves remarkable results, such as serving a Llama2-70B model on an RTX-4090 with an impressive latency of only 0.57 seconds per token. This is a significant improvement compared to existing serving systems, making it 8 times faster than a highly optimized offloading serving system.

Sequoia's scalability and robustness make it stand out in the field of speculative decoding. Its ability to adjust the size and depth of speculation trees based on hardware platforms ensures optimal performance across different configurations. The framework's innovative approach, including dynamic programming algorithms and sampling without replacement techniques, sets it apart in terms of efficiency and adaptability.

Moreover, Sequoia's potential impact extends beyond current hardware capabilities, as it is expected to perform exceptionally well on future hardware generations with increased compute and bandwidth ratios. This forward-looking approach makes Sequoia a promising solution for hosting powerful language models like the 70B variant on various low-cost consumer GPUs, opening up new possibilities for AI-generated content applications.

In conclusion, Sequoia's groundbreaking advancements in speculative decoding set a new standard for speed, scalability, and hardware-awareness in serving large language models. The project's emphasis on adaptability and future-proofing makes it a key player in the evolving landscape of AI technologies.

The discussion on the submission revolves around the OpenAI's GPT-4 model and its implications. Some users express skepticism regarding the progress and efficiency of GPT-4, citing concerns about its capability to compete with newer models like GPT-5. Others discuss the speculation surrounding OpenAI's secretive projects and the potential impact on the industry. There are debates on the performance and efficiency of GPT-4 compared to models like Claude 3 and Gemini. Additionally, the conversation touches upon the financial investments in OpenAI, the challenges of releasing advanced AI models, and the strategic decisions made by companies in the AI space. Discussions also include technical aspects such as model training, scalability, hardware utilization, and the future development of AI technologies.
