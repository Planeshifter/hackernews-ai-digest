## AI Submissions for Sun Jun 18 2023 {{ 'date': '2023-06-18T17:12:12.467Z' }}

### OpenLLaMA 13B Released

#### [Submission URL](https://huggingface.co/openlm-research/open_llama_13b) | 221 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [102 comments](https://news.ycombinator.com/item?id=36381136)

OpenAI has open-sourced its large language model, OpenLLaMA, which is a reproduction of Meta AI's LLaMA. OpenLLaMA is trained on 1T tokens and comes in 3B, 7B, and 13B models, with PyTorch and JAX weights. The models were trained using the RedPajama dataset and EasyLM, a JAX-based training pipeline. OpenLLaMA also offers evaluation results that indicate its performance is comparable to that of GPT-J and LLaMA on various tasks. It can be directly loaded from Hugging Face Hub, but it is recommended that users avoid using the fast tokenizer and instead use the LlamaTokenizer class or pass the `use_fast=False` option for the AutoTokenizer class. In the discussion, people shared their experience using the models, suggested improvements such as larger context sizes, discussed licensing issues, and shared links to resources for language model training.

### ChatGPT, Google Bard Generates Generic Windows 11, Windows 10 Pro Keys

#### [Submission URL](https://www.tomshardware.com/news/chatgpt-generates-windows-11-pro-keys) | 112 points | by [el_hacker](https://news.ycombinator.com/user?id=el_hacker) | [41 comments](https://news.ycombinator.com/item?id=36385032)

Open-source technology has made it possible to get valid keys for different operating systems without having to buy one outright. Popular AI platform, ChatGPT, has been generating working keys for both Windows 10 and 11 Pro. These are similar to the Keys Management Service (KMS) keys published on Microsoft's website, although using enterprise keys to activate and access some of the premium features of the operating system carries risks. Siddiqi, aka @immasiddtweets on Twitter, successfully created generic keys for several Windows editions by tricking ChatGPT into generating keys that should only be used by enterprise clients, such as multi-national companies, without attribution. There are debates about the legality and morality of using this technology to obtain keys. Some comments include discussions about the technical aspects of key activation and licenses while others are skeptical or critical of the usefulness and relevance of the article.

### Infinite Photorealistic Worlds Using Procedural Generation

#### [Submission URL](https://arxiv.org/abs/2306.09310) | 294 points | by [cpeterso](https://news.ycombinator.com/user?id=cpeterso) | [75 comments](https://news.ycombinator.com/item?id=36376071)

A team of researchers has introduced Infinigen, a procedural generator of photorealistic 3D scenes of the natural world. The generator uses randomized mathematical rules to generate every asset, from shape to texture, allowing for infinite variation and composition without using any external sources. Infinigen covers objects and scenes in the natural world, such as plants, animals, terrains, and natural phenomena like fire, cloud, rain, and snow. It can be used to generate diverse training data for various computer vision tasks, including object detection, semantic segmentation, optical flow, and 3D reconstruction, making Infinigen a useful resource for computer vision research and beyond. The paper has been accepted to CVPR 2023 and is available for download along with code and pre-generated data.

A team of researchers has developed Infinigen, a procedural generator of photorealistic 3D scenes of the natural world that uses mathematical rules to generate every asset, allowing for infinite variation and composition without using external sources. The generator covers objects and scenes in the natural world, such as plants, animals, terrains, and natural phenomena, making it a useful resource for computer vision research and beyond. In the comments, users discuss the relevance of previous work in this field, the hardware requirements for using the generator, and the potential applications of the technology. Additionally, there are comparisons made to other procedurally generated games, such as No Man's Sky and Elite Dangerous.

### Tzap: Supercharged GitHub Copilot â€“ Includes your whole code repository

#### [Submission URL](https://github.com/tzapio/tzap) | 23 points | by [bevenky](https://news.ycombinator.com/user?id=bevenky) | [3 comments](https://news.ycombinator.com/item?id=36377918)

Tzap, an easy-to-use CLI tool, has been launched to streamline GPT-based code generation tasks. It simply indexes the project with embeddings and extracts relevant contextual information like interfaces, types, and database models, resulting in Tzap's combination with the prompt creating a suitable prompt for the GPT model. Tzap can create highly specific and complex code through GPT generation, but as it's still in the beta phase, existing files could be overwritten, so local changes should be committed first.

The discussion in the comments of the submission seems to be focused on the limitations and potential use cases of the Tzap tool. Users have raised concerns regarding the reliability of the generated code, with one user noting that beta tools can sometimes overwrite existing files, so caution is necessary. Another user suggested using local models in combination with Tzap for better results. There was also a comment about limitations on processing large amounts of code and GPU memory requirements. Overall, the discussion seems to highlight the potential of Tzap for streamlining code generation tasks while also highlighting the need for caution and consideration of specific use cases.

### LLMs can label data as well as human annotators, but 20 times faster

#### [Submission URL](https://www.refuel.ai/blog-posts/llm-labeling-technical-report) | 49 points | by [nihit-desai](https://news.ycombinator.com/user?id=nihit-desai) | [27 comments](https://news.ycombinator.com/item?id=36384015)

Refuel, an AI company, has introduced a benchmark for evaluating performance of Language Model Models (LLMs) for labeling text datasets. The benchmark aims to compare the performance of LLMs and human annotators on three axes: quality, turnaround time and cost. The company found that LLMs can label text datasets with comparable quality to skilled human annotators, but 20 times faster and seven times cheaper. The benchmark also found that GPT-4 is the best choice for achieving the highest quality labels, while GPT-3.5-turbo, PaLM-2 and open source models like FLAN-T5-XXL are compelling for achieving the best tradeoff between label quality and cost.

The comments on the Hacker News submission express some skepticism of the benchmark and discuss concerns around LLMs replacing human annotators, PII (personally identifiable information) privacy issues, and the existence of true ground truth in human annotation. Some users share their own experiences with text labeling and suggest alternatives to LLMs, while others argue for the benefits of LLMs in speeding up and reducing the cost of text labeling tasks.

### Google Go language goes with opt-in telemetry

#### [Submission URL](https://www.theregister.com/2023/05/17/googles_go_data_collection/) | 37 points | by [el_hacker](https://news.ycombinator.com/user?id=el_hacker) | [12 comments](https://news.ycombinator.com/item?id=36380292)

The stewards of Google's open-source Go language (Golang) have announced that they will implement software telemetry on an opt-in basis rather than turning data collection on by default and requiring developers to opt-out. This decision was made due to objections from Go developers who were concerned about data collection without permission. Many users also pointed out that Google, an advertising platform, had consistently opposed opt-in data collection. The telemetry will consist of recording various events like cache hits, feature usage, latency, and more to a local file. According to Russ Cox, the Golang tech lead at Google, even with "tens of thousands of users opted in, we should be able to get helpful data".

The discussion on the submission revolves around the topic of telemetry and whether it should be opt-in by default or not. Some believe that opt-in is the right approach, and Google, being an advertising platform, was hypocritical for not adopting this approach earlier. Others argue that telemetry is reasonable and essential for improving user experience and finding and fixing bugs. However, some users question the effectiveness of telemetry in environments with forwarded or repurposed networks and whether it can cause performance delays and false configuration overhead. There is also a debate over what level of telemetry should be considered reasonable and sufficient. Some respondents suggest an explanatory approach to telemetry, and others point out that the concern is overstated, citing examples of other applications and services that use telemetry.

