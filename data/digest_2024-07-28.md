## AI Submissions for Sun Jul 28 2024 {{ 'date': '2024-07-28T17:10:38.736Z' }}

### LeanDojo: Theorem Proving in Lean Using LLMs

#### [Submission URL](https://leandojo.org/) | 152 points | by [aseg](https://news.ycombinator.com/user?id=aseg) | [43 comments](https://news.ycombinator.com/item?id=41096486)

In an exciting development for the world of theorem proving, researchers have introduced LeanDojo, a platform that harnesses the power of language models as copilots to automate proof generation in Lean—a popular theorem proving environment. LeanDojo offers users the ability to interact with their own models, whether they run locally or in the cloud, enhancing the proof process by suggestive tactics and premise retrieval.

At the heart of LeanDojo is the ReProver model, which employs a sophisticated encoder-decoder Transformer architecture to navigate the complexities of theorem proving. By utilizing an extensive benchmark dataset—comprised of nearly 100,000 theorems, along with tens of thousands of tactics and premises from Lean's rich math library—ReProver demonstrates remarkable capabilities, outperforming traditional built-in tactics as well as zero-shot attempts with models like GPT-4.

LeanDojo also creates a gym-like environment for theorem provers, facilitating interactions with proof states and tactics while providing feedback on errors or completion status. In addition to generating new proofs—discovering 33 previously unproven statements in miniF2F and 39 in ProofNet—it has been instrumental in uncovering formalization bugs.

A unique feature of LeanDojo is its integration with ChatGPT, offering users a more conversational approach to theorem proving. While ChatGPT can intersperse informal discussions with formal proof steps, it currently struggles with complex proofs compared to specialized models like ReProver.

With these advancements, LeanDojo paves the way for a new era in theorem proving, expanding the potential for both formal verification and mathematical exploration.

**Discussion Highlights:**

1. **Real-World Applications:** Commenters discussed the broader implications of theorem proving, particularly in fields requiring high security and reliability, such as banking. They highlighted the necessity of strong reasoning capabilities in AI to tackle complex challenges in these areas.
2. **Integration with Other Technologies:** Several participants noted LeanDojo's potential in connecting with existing systems like AlphaProof, calling attention to the strengths and weaknesses of these technologies in formal verification and proof generation.
3. **Proof and Problem Complexity:** The complexity associated with automated theorem proving was a recurring theme. Users expressed curiosity about how AI might handle intricate mathematical problems, referencing historical challenges like the Riemann Hypothesis.
4. **Conversational AI in Theorem Proving:** The integration of ChatGPT with LeanDojo was seen as an interesting step towards making theorem proving more accessible, despite current limitations in handling complex proofs compared to specialized AI models.
5. **Mathematical Discoveries and Challenges:** The discussion included insights about previous proofs and conjectures, including the ABC conjecture and its implications for complexity in formal mathematics. Community members questioned whether current systems could independently prove mathematical statements traditionally deemed difficult.
6. **Future Prospects:** The community reflected on the future of formal methods and AI in mathematics, considering the potential for groundbreaking discoveries and revisiting unresolved conjectures through new AI approaches.

This ongoing conversation emphasizes the excitement surrounding LeanDojo's capabilities and the potential enhancements to theorem proving and formal verification in mathematics and other fields.

### How to Run Llama 3 405B on Home Devices? Build AI Cluster

#### [Submission URL](https://b4rtaz.medium.com/how-to-run-llama-3-405b-on-home-devices-build-ai-cluster-ad0d5ad3473b) | 45 points | by [b4rtazz](https://news.ycombinator.com/user?id=b4rtazz) | [14 comments](https://news.ycombinator.com/item?id=41092707)

In a recent article, Bartłomiej Tadych explains how you can harness the power of large language models (LLMs) right from your home by building an AI cluster capable of running the sizable Llama 3.1 405B model. Unlike proprietary models that lock you into cloud services, open models like Llama allow local execution, albeit with challenges related to their immense size and computational demands.

Tadych highlights the concept of **tensor parallelism**, a technique that distributes matrix multiplication tasks across multiple CPU/GPU cores—streamlining processes and potentially halving computation times when using multiple devices. However, synchronization bottlenecks can hinder performance, particularly on standard home networks, where speed is limited. Nevertheless, through smart architecture design, synchronization data can be reduced drastically, enabling smoother operations even on less advanced setups.

The article introduces the **Distributed Llama project**, which simplifies the running of LLMs across several devices. Using distinct roles for nodes (root and worker nodes), it efficiently manages RAM usage and network performance. For those looking to set up their own cluster, Tadych provides a comprehensive guide to installation, how to connect the devices, and the necessary commands for running the model inference.

Building such a setup promises an exciting avenue for enthusiasts and developers alike, allowing them to experiment with cutting-edge AI technology directly from the comfort of their own homes. As Llama continues to grow, tools like Distributed Llama may significantly enhance accessibility and operational efficiency for personal AI projects.

The discussion on Hacker News revolves around the challenges and requirements for setting up a home AI cluster capable of running large language models, especially with respect to hardware specifications and costs. 

Key highlights include:

1. **Hardware Constraints**: Users discuss the necessity for powerful machines, with many stating that a system with 256GB RAM is optimal. There are varying opinions on processors, with suggestions ranging from AMD EPYC CPUs to Ryzen processors for their performance and price efficiency.

2. **Cost Considerations**: Some users note the high costs associated with running such configurations, sometimes reaching upwards of $6000 for appropriate setups. Discussions mention using consumer-grade CPUs and the implications of memory bandwidth on performance.

3. **Cluster Configuration**: There is discussion about setting up distributed systems for running AI workloads, including considerations for network infrastructure and configuration to manage multiple devices effectively.

4. **Alternatives to Local Hardware**: Some users express interest in dedicated server providers and cloud-based GPU solutions, noting the balancing act between price and performance for running large models.

5. **AI Model Scaling**: Speculations and advice circulate on the viability of using 400B parameter models versus smaller models, with emphasis on the inefficiency of handling such large requirements on typical home setups.

Overall, the discourse highlights a mix of ambition and realism among enthusiasts considering the complexities of building and maintaining personal AI clusters.

### Fake Paper Generator

#### [Submission URL](https://fakepaper.app/) | 45 points | by [noah32](https://news.ycombinator.com/user?id=noah32) | [25 comments](https://news.ycombinator.com/item?id=41094180)

A new tool has emerged to help researchers and authors enhance the impact of their scientific papers: "Bring Your Scientific Paper to Life!" This innovative software employs AI to create engaging visualizations, dynamic presentations, and interactive content tailored to research findings. By transforming complex data into easily digestible formats, this tool not only aids in comprehending the research but also makes it more accessible to a broader audience. It's designed for scientists who wish to effectively communicate their work and captivate their readers, pushing the boundaries of traditional academic publishing. Whether you’re presenting at a conference or publishing online, this tool could redefine how scientific work is shared and understood.

The discussion around the submission of the "Bring Your Scientific Paper to Life!" tool generated a mix of humor and skepticism regarding AI-generated scientific content. Some users referenced the infamous SCIgen tool, which produces nonsensical but seemingly legitimate academic papers. They compared it to modern tools like ChatGPT, pointing out that while these models can generate coherent text, the quality and reliability of the content remain questionable.

Users discussed the increasing prevalence of AI in generating academic papers, expressing concerns that such tools could dilute the standards of scholarly work. Some found the concept amusing, joking about the absurdity of generated content. Others highlighted the importance of rigor in scientific communication, arguing that while AI tools can illustrate complex ideas, they should not replace thoughtful research and writing.

Certain comments noted that AI might inadvertently create misunderstandings about the scientific process if not used carefully. However, there was also acknowledgment of the potential benefits of these tools in making research more engaging and accessible. As discussions unfolded, participants bounced between humor and serious considerations about the implications of relying on AI for academic purposes.

### Compare 75 AI Models on 200 Prompts Side by Side

#### [Submission URL](https://aimodelreview.com) | 18 points | by [pajop](https://news.ycombinator.com/user?id=pajop) | [3 comments](https://news.ycombinator.com/item?id=41096054)

In a remarkable evaluative exercise, researchers conducted an extensive review of 75 AI models across 200+ diverse prompts, highlighting their capabilities in areas like knowledge, reasoning, creativity, emotional intelligence, and more. This analysis spanned scenarios both whimsical and serious, from playful inquiries about swimming pranks and mountain climbers to probing ethical dilemmas and social justice issues. Notably, it examined how models respond to absurd requests—like crafting an argument for smoking cigarettes as a health benefit—or explaining complex topics, such as quantum mechanics, at a child’s level. The review sought to test the models' guardrails in potentially harmful or discriminatory scenarios while also assessing their depth of understanding in scientific and political contexts. The findings aim to provide insights into the strengths and limitations of AI models, ultimately shaping future advancements and ethical considerations in AI interactions.

In the discussion surrounding the evaluation of AI models, commenters expressed their views on the model performances. One user pointed out perceived shortcomings in the GPT-4-Turbo's answers, particularly suggesting that it sometimes outputs responses that lack confidence, especially on questions where it should be straightforward or certain. Another commenter mentioned Gemini's capabilities, noting that it tends to answer against the backdrop of human cognitive biases, which can lead to confusion when dealing with complex queries. Overall, the dialogue reflected a mix of praise and critique regarding the ability of AI models to handle inquiries, showcasing concerns over their reliability and consistency in delivering credible information.

