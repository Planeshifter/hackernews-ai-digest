## AI Submissions for Tue Nov 04 2025 {{ 'date': '2025-11-04T17:15:46.980Z' }}

### Grayskull: A tiny computer vision library in C for embedded systems, etc.

#### [Submission URL](https://github.com/zserge/grayskull) | 153 points | by [gurjeet](https://news.ycombinator.com/user?id=gurjeet) | [13 comments](https://news.ycombinator.com/item?id=45816673)

Grayskull is a tiny, single-header computer vision library in C designed for microcontrollers, drones, and other resource-constrained devices. It sticks to grayscale, uses integer math, and avoids dependencies, dynamic allocation, and C++, making it predictable and small enough to fit in a few kilobytes. Think of it as an stb-style toolkit for embedded CV when OpenCV is overkill.

Highlights:
- Core ops: copy, crop, bilinear resize, downsample
- Filters: blur, Sobel edges, global/Otsu/adaptive thresholding
- Morphology: erosion, dilation
- Geometry: connected components, contour tracing, perspective warp
- Features: FAST/ORB keypoints, BRIEF/ORB descriptors, matching
- Detection: LBP cascades (faces, vehicles) via integral images
- Utilities: PGM read/write; simple C99 structs; optional gs_alloc/gs_free helpers

Why it matters: header-only and dependency-free means easier builds and deterministic memory use on MCUs; yet it still packs modern feature detection and basic object detection. MIT licensed, with examples and a browser demo. Repo: github.com/zserge/grayskull

The Hacker News discussion about **Grayskull** includes a mix of technical feedback, comparisons to other projects, and playful references to its name:

1. **Technical Insights**:  
   - Users discuss optimizations (e.g., ARM DSP extensions, intrinsics) and compare Grayskull to other lightweight libraries like [`fltcvd-sicom`](https://fltcvd-sicom) and [`Deimos`](https://github.com/aadv1k/deimos), a project aiming to rebuild OpenCV-like functions from scratch.  
   - A user shares their own OCR experiments with stroke-width transforms ([`swth`](https://github.com/aadv1k/swth)) and emphasizes optimizing functions for GPU/multithreading.  

2. **Feature Appreciation**:  
   - Praise for Grayskull’s perspective warping and grayscale efficiency, with one user noting its advantages over OpenCV when dropping color depth.  

3. **Name References**:  
   - Multiple users humorously tie the library’s name to *He-Man*’s Castle Grayskull ([Wikipedia link](https://en.wikipedia.org/wiki/Castle_Grayskull)), with a meme-filled subthread.  

4. **Miscellaneous**:  
   - A tangential Netflix show mention (*Nimona*) and a joke about missed He-Man-themed branding opportunities.  

Overall, the conversation blends technical interest in embedded CV tools with lighthearted nods to pop culture inspired by the project’s name.

### Launch HN: Plexe (YC X25) – Build production-grade ML models from prompts

#### [Submission URL](https://www.plexe.ai/) | 82 points | by [vaibhavdubey97](https://news.ycombinator.com/user?id=vaibhavdubey97) | [29 comments](https://news.ycombinator.com/item?id=45813310)

Plexe is a “prompt-to-production” platform that pitches itself as an agentic ML engineering team for businesses. Connect your data (files, DBs, APIs), get automatic data-quality checks and quick insights, describe what you want in plain English, and Plexe builds and deploys a tailored model as an API, batch job, or dashboard.

Highlights:
- Workflow: data ingestion → quality checks/patterns → natural-language model spec → auto-built model → one-click deploy.
- Transparency: surfaces metrics, training details, and preprocessing steps (e.g., one‑hot encoding) to explain performance and predictions.
- Use cases: fraud detection and credit underwriting (finance), churn prediction and recommendations (e‑commerce), plus logistics and cybersecurity.
- Outputs: “Quick Insights” summaries (e.g., base fraud rate ~1%, avg transaction $90.59 with high variance), model performance pages, and API usage.
- Positioning: YC S25-era launch with press mentions; targets teams that want faster, less bespoke ML delivery without giving up model visibility.

Why it matters: It aims to compress the ML lifecycle—from messy data to production endpoints—into a guided, auditable flow that non-specialists can drive, addressing the “black box” and time-to-value pain points common in applied ML.

**Summary of Discussion:**

The discussion around Plexe’s launch highlights technical inquiries, feedback, and practical considerations from the Hacker News community, with responses from the Plexe team clarifying their approach and roadmap:

### Key Themes:
1. **Technical Questions & Clarifications:**
   - **Data Handling:** Users asked about support for unstructured data (text/images), preprocessing steps, and schema inference. The team confirmed tabular data is prioritized, with preprocessing code mirrored in deployment and future plans for unstructured data.
   - **Model Building:** Questions arose about fine-tuning, model interpretability, and reliance on generic LLMs. Plexe clarified they use specialized models (e.g., Anthropic, OpenAI) for specific tasks, with custom pipelines for cost efficiency and performance.
   - **Input/Output Schemas:** Concerns about unclear API input formats were addressed with promises of UI improvements and schema documentation.

2. **Product Feedback:**
   - **Transparency:** Users emphasized the need for visibility into data cleaning/labeling steps. Plexe noted LLMs assist with data enrichment and hinted at future UI enhancements to showcase preprocessing.
   - **UI/UX:** Requests for clearer model-building statuses (e.g., “baseline deployed”) and expert analysis features were acknowledged, with some already implemented.

3. **Use Cases & Practicality:**
   - Community members praised Plexe’s focus on compressing the ML lifecycle but questioned real-world applicability. The team highlighted agentic workflows for domain-specific tasks (e.g., fraud detection) and shared internal benchmarking results.

4. **Pricing & Costs:**
   - A user inquired about token-based pricing for model building. Plexe clarified costs combine tokens (data processing), training compute, and inference/storage.

5. **Future Plans:**
   - **Computer Vision:** Limited support for images exists today, with expanded capabilities planned based on demand.
   - **Expert Analysis:** Users suggested exporting code snippets/reports for transparency, which the team is considering.

### Plexe Team’s Engagement:
- Actively addressed feedback, detailing near-term priorities (UI improvements, schema docs) and long-term goals (unstructured data support).
- Emphasized flexibility in model selection (balancing simplicity vs. performance) and commitment to reducing “black box” concerns through explainability features.

**Overall Sentiment:** Curiosity and optimism, tempered by requests for deeper technical clarity and transparency. The team’s responsiveness and roadmap suggestions (e.g., computer vision, preprocessing visibility) were well-received.

### Michael Burry bets against Nvidia and Palantir [video]

#### [Submission URL](https://www.youtube.com/watch?v=tTaatXk6Qds) | 36 points | by [mgh2](https://news.ycombinator.com/user?id=mgh2) | [3 comments](https://news.ycombinator.com/item?id=45815852)

Headline: YouTube link loads only the site footer — no content to summarize

Summary: The submitted URL appears to resolve to YouTube’s generic footer (About, Press, Copyright, Creators, Terms, Privacy, Safety, How YouTube works, Test new features, NFL Sunday Ticket; © 2025 Google LLC). That typically means the actual page/video didn’t load or is unavailable—common causes include removal, geo-restrictions, consent/cookie walls, or ad-block/login gating. There’s no substantive content accessible to summarize from this link.

Tips: If you have an alternate source or mirror, share it. Otherwise, try a different browser, disable blockers, open while logged in, use an Invidious front end (e.g., yewtu.be), or check the Wayback Machine.

**Summary of Discussion:**  
The comments discuss market dynamics and skepticism toward AI hype:  

1. **Market Irrationality & Michael Burry:** The first comment references the adage *"markets can stay irrational longer than you can stay solvent,"* critiquing Michael Burry’s reputation for taking premature short positions (e.g., predicting bubbles like the 2008 crisis) that risk capital loss if timed poorly.  

2. **AI Bubble Criticism:** The second comment argues that the current "gigantic AI bubble" may burst as generative models fail to meet inflated expectations, producing flashy demos but lacking true competence.  

3. **Additional Context:** The third comment links to another Hacker News thread (ID `45813734`), likely for further discussion.  

**Key Themes:** Skepticism toward speculative financial strategies, concerns about AI overhype, and references to historical market behaviors.  
*(Note: Comments were paraphrased from heavy shorthand/abbreviations.)*

### Lessons from interviews on deploying AI Agents in production

#### [Submission URL](https://mmc.vc/research/state-of-agentic-ai-founders-edition/) | 104 points | by [advikipedia](https://news.ycombinator.com/user?id=advikipedia) | [91 comments](https://news.ycombinator.com/item?id=45808308)

State of Agentic AI (Founder’s Edition): From Clippy jokes to enterprise reality

TL;DR: A survey of 30+ European agentic AI founders and 40+ enterprise practitioners finds that the hardest parts of deploying AI agents aren’t model quality—they’re integration, people, and privacy. Winning teams “think small,” ship co-pilots for hated tasks, and prove ROI fast. Budgets are real, outcome-based pricing isn’t (yet), and most startups are still building infra in-house.

Highlights
- The real blockers aren’t technical:
  - Workflow integration and human–agent interface: 60%
  - Employee resistance and other non-technical factors: 50%
  - Data privacy and security: 50%
- Deployment playbook: start with low-risk, medium-impact, easily verifiable tasks; frame as co-pilot (augment, don’t replace); automate work users dislike; show clear ROI quickly.
- Budgets have moved beyond experiments: 62% tap Line-of-Business or core spend.
- Pricing reality:
  - Most common: Hybrid and per-task (23% each)
  - Outcome-based is rare (3%) due to attribution, measurement, and predictability challenges.
- Build vs buy: 52% are building agentic infrastructure fully or mostly in-house.
- Reliability: 90% report ≥70% accuracy; “good enough” is acceptable for low-risk, high-volume, easily checked outputs—or when enabling net-new capabilities. Healthcare leads on accuracy.

How they define “agent”
- Goal-oriented, reasons and plans, takes actions via tools, and persists state/memory; full autonomy not required (co-pilots qualify if they meet these criteria).
- Handy mnemonic: Cache (memory), Command (tools/actions), Connect (who/what to talk to).

Why it matters
- Agentic AI is edging into core workflows and budgets, but success hinges on change management, UX, and governance—not just better models. Outcome-based pricing remains a stretch goal until measurement matures.

**Summary of Discussion:**

The Hacker News discussion revolves around the challenges of deploying **deterministic AI systems** in regulated industries (e.g., finance, healthcare, legal) and debates whether AI can meet strict reliability standards. Key points include:

1. **Determinism vs. Non-Determinism**:  
   - Critics argue AI systems (especially LLMs) are inherently **non-deterministic** due to probabilistic outputs, even with controlled parameters (temperature, seed). Factors like floating-point operations or hardware variations introduce variability.  
   - Proponents counter that **determinism is achievable** with fixed parameters and rigorous engineering, though real-world applications often prioritize "good enough" reliability over perfection.  

2. **Regulated Industries**:  
   - In sectors like banking or aviation, **deterministic workflows are mandatory** (e.g., payment processing, flight control). Users highlight that human workflows in these fields are already designed to be deterministic (e.g., checklists), raising skepticism about AI's ability to comply.  
   - Legal and financial workflows face hurdles due to AI’s occasional unpredictability, necessitating **human oversight** (e.g., double-checking AI outputs).  

3. **Practical Challenges**:  
   - **Accountability**: Users stress that non-deterministic AI complicates blame attribution. One commenter notes, "If a system fails, responsibility must be clear—AI’s ‘black box’ nature clashes with this."  
   - **Error Handling**: Current methods (e.g., test failures) are insufficient for production. One user jokes, "If an AI agent fails, deleting the test isn’t a fix!"  

4. **LLM Technical Debate**:  
   - While LLMs can be deterministic in theory (via controlled settings), real-world implementations often face **unpredictability** due to model complexity and external factors.  

5. **Human vs. AI Workflows**:  
   - A recurring theme: **Humans aren’t 100% deterministic either**, yet industries rely on them. The discussion questions whether AI must meet higher standards than humans or if "acceptable risk" thresholds apply.  

**Conclusion**: The discussion underscores that while Agentic AI shows promise, its adoption in critical domains hinges on overcoming technical non-determinism, ensuring explainability, and integrating human oversight—mirroring the submission’s emphasis on non-technical challenges (governance, UX, change management). Outcome-based pricing and full autonomy remain aspirational until these issues are resolved.

### Amazon sends legal threats to Perplexity over agentic browsing

#### [Submission URL](https://techcrunch.com/2025/11/04/amazon-sends-legal-threats-to-perplexity-over-agentic-browsing/) | 27 points | by [erhuve](https://news.ycombinator.com/user?id=erhuve) | [7 comments](https://news.ycombinator.com/item?id=45817032)

Amazon sends cease-and-desist to Perplexity over “agentic” shopping on Amazon.com

- What happened: Amazon told Perplexity to stop using Comet—its AI shopping agent—on Amazon’s storefront, saying Comet violates terms by not identifying itself as an automated agent. Perplexity published a post titled “Bullying is not innovation,” calling Amazon’s move a threat to “all internet users.”

- The arguments: Perplexity says agents act on a user’s behalf and therefore inherit the same permissions as the user, so no extra disclosure is needed. Amazon counters that intermediaries routinely identify themselves (think food delivery apps, gig shoppers, OTAs) and that third-party apps should “operate openly and respect service provider decisions whether or not to participate.”

- Stakes: Even if Comet self-identifies, Amazon could still block it—and has its own bot (Rufus). Perplexity claims Amazon’s real motive is protecting ads and product placement upsells that bots won’t click.

- Backdrop: Follows Cloudflare’s research showing Perplexity accessing sites that opted out of bots; defenders said that was user-directed browsing, critics pointed to identity-masking tactics. The clash previews the coming “agentic web” rules.

- Why it matters: Amazon is effectively setting a precedent: bots should declare themselves and accept platform gatekeeping. The outcome will shape how agentic shoppers, travel bookers, and reservation bots interact with walled platforms—and who controls the economics.

**Summary of the Hacker News Discussion:**

1. **Core Debate**: The discussion revolves around whether AI agents like Perplexity’s Comet should be required to self-identify when accessing websites like Amazon.  
   - Pro-Perplexity arguments assert that agents act on a user’s behalf (inheriting their permissions) and need no extra disclosure. Critics counter that transparency is necessary to prevent abuse and respect platform terms.  

2. **Platform Control vs. Openness**:  
   - Amazon’s move is compared to Apple’s App Store control, with accusations of “gatekeeping” to protect ads and revenue streams. Some argue this sets a precedent for corporate dominance over open-web ideals.  
   - Others highlight Amazon’s terms of service, emphasizing intermediaries (e.g., food delivery apps, travel sites) typically disclose their automated nature.  

3. **Scraping and Intellectual Property Concerns**:  
   - Users debate whether AI agents scraping content constitutes theft, especially when publishers explicitly block bots. Perplexity’s past behavior (e.g., bypassing opt-outs, triggering DDoS-like request volumes) is cited as problematic.  
   - Critics warn unchecked scraping erodes incentives for human creativity and journalism.  

4. **Technical and Legal Nuances**:  
   - Comparisons to DDoS attacks surface, with Perplexity accused of exceeding “benign” request thresholds. Amazon’s legal threat is framed as a response to potential terms-of-service violations.  
   - Questions arise about accountability: Should public web crawlers or end-users bear responsibility for compliance?  

5. **Philosophical Split**:  
   - One faction champions “agentic web” innovation, where AI acts on users’ behalf without bureaucratic friction.  
   - Others stress platforms’ rights to block unvetted automation, fearing economic exploitation (e.g., bypassing ads, affiliate links) and loss of control.  

**Key Quote**: *“Bullying is not innovation” vs. “Agents must operate openly.”* The clash encapsulates tensions between disruptive AI and established platforms defending their ecosystems. The outcome could reshape how AI interacts with the web—and who profits from it.

### Server DRAM prices surge 50% as AI-induced memory shortage hits hyperscalers

#### [Submission URL](https://www.tomshardware.com/pc-components/storage/server-dram-prices-surge-50-percent) | 139 points | by [walterbell](https://news.ycombinator.com/user?id=walterbell) | [120 comments](https://news.ycombinator.com/item?id=45812403)

Headline: DRAM crunch deepens: hyperscalers get only 70% of orders as prices spike; shortages may persist into 2026

TL;DR: AI buildouts are overwhelming the DRAM supply chain. Even after accepting steep price hikes, major cloud buyers are only getting about 70% of the server DRAM they order. Spot prices for DDR5 have nearly doubled since September, suppliers are refusing quotes, and smaller OEMs are being squeezed to the spot market. Expect tight supply and rising prices through 2025, with relief not likely before 2026.

Key points:
- Allocation squeeze: U.S. and Chinese hyperscalers are receiving ~70% of ordered server DRAM despite agreeing to Q4 contract increases of up to 50%. Smaller OEMs report just 35–40% fulfillment.
- AI-driven reprioritization: Samsung and SK hynix are diverting advanced-node capacity toward AI-focused parts (HBM and DDR5 RDIMMs). Samsung raised server SSD prices up to 35% and RDIMM contracts up to 50%.
- Prices jumping: DDR5 16 GB modules moved from $7–$8 in September to ~$13; spot prices have surged and several top-tier suppliers reportedly refused October quotes. Module makers warn of stockouts by quarter’s end.
- Market dynamics: Hyperscalers are locking in fixed allocations, pushing everyone else to day-to-day spot buying. TrendForce flags quote freezes and shift to daily pricing in China to avoid bad long-term deals.
- Outlook: Micron says DRAM remains a “tight industry” with bit supply growth lagging demand through at least the end of next year. DDR4 is being deprioritized (now ~20% of DRAM shipments), and retail DDR5 prices are creeping up with no near-term stabilization.

Why it matters:
- Cloud and AI operators face higher capex and potential deployment delays.
- PC/server vendors and smaller OEMs may see component shortages and margin pressure.
- Consumers should expect pricier RAM (and knock-on effects for SSDs) into 2025; significant easing likely requires new capacity or yield improvements, which aren’t expected before 2026.

**Summary of Hacker News Discussion:**

The discussion revolves around the DRAM shortage driven by AI demand, semiconductor industry dynamics, and broader economic implications. Key points include:

1. **DRAM Market Pressures**:  
   - AI-driven demand is overwhelming DRAM supply, causing price spikes (DDR5 prices nearly doubled since September) and allocation issues. Hyperscalers receive ~70% of orders, while smaller OEMs face worse shortages (~35–40% fulfillment).  
   - Suppliers like Samsung and SK hynix prioritize AI-focused memory (HBM/DDR5), deprioritizing DDR4. Micron warns of tight supply through 2025, with relief unlikely before 2026–2027.  

2. **Semiconductor Investments & Inflation Concerns**:  
   - Debate arises over Micron’s $150B semiconductor fab expansion, funded partly by public loans. Critics argue this could fuel inflationary pricing, subsidizing private gains while shifting costs to the public (e.g., via higher electricity bills).  
   - Data centers’ preferential energy pricing (e.g., in Virginia) is criticized for burdening households with grid upgrade costs, estimated at $19B+ in subsidies.  

3. **Energy Infrastructure Challenges**:  
   - Microsoft’s admission of power shortages for AI GPU deployment highlights growing energy demands. Critics accuse tech firms of “hoarding” infrastructure, exacerbating supply constraints and inflating prices.  

4. **AI Efficiency & Model Optimization**:  
   - Some hope market pressures will incentivize smaller, efficient AI models (e.g., GPT-OSS120B) over “bigger is better” trends. Techniques like Mixture of Experts (MoE), quantization (INT4/FP4), and inference optimizations are cited as paths to reduce reliance on scarce hardware.  
   - Concerns about job displacement for software engineers emerge, as AI efficiency could diminish traditional roles.  

5. **Economic & Policy Critiques**:  
   - Skepticism toward public-private partnerships, with accusations of propaganda pushing higher energy costs onto consumers. Critics argue governments enable corporate rent-seeking via lax regulation and subsidies.  

**Takeaways**: The DRAM crunch underscores systemic tensions between AI growth, infrastructure limits, and economic equity. While technical optimizations offer partial solutions, debates highlight distrust in corporate and governmental handling of resource allocation and public funds.

