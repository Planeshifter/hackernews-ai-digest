## AI Submissions for Mon Oct 23 2023 {{ 'date': '2023-10-23T17:10:02.663Z' }}

### How to Build Your Own AI-Generated Images with ControlNet and Stable Diffusion

#### [Submission URL](https://www.datature.io/blog/how-to-build-your-own-ai-generated-image-with-controlnet-and-stable-diffusion) | 172 points | by [gkeechin](https://news.ycombinator.com/user?id=gkeechin) | [58 comments](https://news.ycombinator.com/item?id=37993202)

Generative AI, a type of artificial intelligence that can generate new content without explicit programming, has gained recognition for its ability to create original images, music, text, and even video. By using machine learning algorithms to analyze and learn from large datasets, generative AI models can produce content that closely resembles the training data but is not identical.

The usefulness of generative AI lies in its potential to automate processes, improve content quality and diversity, and offer new insights and predictions. It can be applied in various ways, such as creating original content for advertising, marketing, and entertainment, generating new data samples to enhance machine learning, simulating environments for testing technologies like autonomous vehicles, personalizing content based on user preferences, and providing predictive analysis based on extensive datasets.

When it comes to generating images, generative AI models excel at producing diverse variations with a clear foreground object and a contextualized background. These models can seamlessly replace objects or backgrounds, change graphic styles, or create similar variations, enabling users to create impressive art, high-quality product advertisements, and even augment computer vision datasets.

Several methods are employed in generative AI. One popular technique is Generative Adversarial Networks (GANs), which use a pair of neural networks—an image generator and an image discriminator—to produce new content. The generator creates samples while the discriminator evaluates their similarity to the training data. Through adversarial training, the generator aims to deceive the discriminator, resulting in the creation of new samples that closely resemble the original data.

Another method is Stable Diffusion, which gradually generates an image from a noise signal by passing it through a series of increasingly complex convolutional neural networks. This process refines the image until the final output—an image resembling the training data—is achieved. Stable Diffusion addresses the challenges faced by other generative AI techniques, such as GANs, offering stability and the ability to produce high-quality, diverse, and realistic images.

In an interesting application example, generative AI can be used to augment backgrounds for single objects, benefiting object identification and product placement. By combining object transform and color augmentations, background in-painting, and object in-painting, users can generate pristine images with varying environments and smooth transitions between the foreground and background.

Generative AI offers immense potential for content creation, data augmentation, simulation, personalization, and predictive analysis. As the field continues to advance, we can expect even more impressive applications of generative AI in numerous industries.

The discussion on this submission revolves around the topic of generative AI, specifically Stable Diffusion and ControlNet models. Some users discuss the benefits and limitations of using these models for content generation. One user mentions their experience using DALL-E and generating thousands of images with it. Another user shares examples of images generated using SDXL (Stable Diffusion).

There is also a discussion about the learning curve and time required to achieve good results with generative AI models. Some users suggest tweaking prompts and experimenting with different approaches to improve the quality of generated content. The topic of customization and control over the generated content is also mentioned, with users discussing the advantages and limitations of different models.

Some users recommend specific tools and resources for working with generative AI models, such as ComfyUI for ControlNet and SDXL for Stable Diffusion. There is also a mention of other AI models like ChatGPT and RealVis XL.

Overall, the discussion provides insights into the capabilities and challenges of generative AI and its potential applications in various fields.

### How does macOS manage virtual cores on Apple Silicon?

#### [Submission URL](https://eclecticlight.co/2023/10/23/how-does-macos-manage-virtual-cores-on-apple-silicon/) | 227 points | by [todsacerdoti](https://news.ycombinator.com/user?id=todsacerdoti) | [149 comments](https://news.ycombinator.com/item?id=37991295)

Apple's new Sonoma chip, which is used in their M-series processors, includes two types of CPU cores: Efficiency (E) cores and Performance (P) cores. The E cores are energy-efficient but slower, while the P cores provide higher performance. The allocation of threads to these cores is determined by the Quality of Service (QoS) of the apps running on macOS. However, with the introduction of Game Mode in Sonoma, CPU scheduling can be adjusted to reserve E cores specifically for gaming.

This article explores how Sonoma handles CPU core allocation when running macOS virtual machines (VMs) with a set number of virtual cores. The M-series chips have different configurations of E and P cores depending on the model, with Pro and Max models having more cores than base models. The allocation of threads to cores depends on their QoS and the clustering of the cores.

In the case of VMs, all virtual CPU cores are equivalent to P cores, and there is no option to allocate threads to E cores on the host machine. This is demonstrated in tests performed on a Mac Studio M1 Max running Sonoma 14.0, where VMs with different numbers of virtual cores were used. The tests showed that the core allocation in the VMs mirrored the core clustering on the host machine's P cores.

Overall, the article provides insights into how Sonoma handles CPU core allocation for different workloads, highlighting the importance of QoS, clustering, and core types in determining thread scheduling and performance.

### COBOL on Wheelchair: Micro web-framework for COBOL

#### [Submission URL](https://github.com/azac/cobol-on-wheelchair/blob/master/tutorial/index.md) | 105 points | by [matsz](https://news.ycombinator.com/user?id=matsz) | [40 comments](https://news.ycombinator.com/item?id=37990646)

This project aims to bring the power of the Cobol programming language to the modern era. Cobol, known for being a reliable and robust language, is still widely used in critical systems across industries such as banking and government. However, its outdated tools and lack of modern development practices have made it less appealing for new developers. "Cobol on Wheelchair" seeks to change that by providing a modern IDE, compiler, and runtime environment for Cobol. With this project, developers can now write, compile, and run Cobol code on contemporary platforms. This initiative shows that even old languages can adapt and thrive in a rapidly evolving tech landscape. Kudos to azac for bringing Cobol back to life!

The discussion on Hacker News about the "Cobol on Wheelchair" project includes various comments discussing different aspects of Cobol and its relevance in modern systems. 

One user mentions working for a consulting bank and highlights the interest in Cobol due to its reliable and well-established use in critical systems. They also mention alternatives that have tried to compete with Cobol, but they haven't been successful. Another user adds that companies like Micro Focus provide tools and libraries to enable Cobol development on modern platforms. They mention using Cobol on Raspberry Pi with Perl 5 as a scripting language.

Another user engages in a conversation about the differences between ASCII and EBCDIC encodings and points out that Cobol has its own conventions for UI and file handling. They also mention the need for batch processing and real-time message processing in Cobol programs.

Other comments touch on the support for batch job scheduling and the flexibility of Linux in inter-process communication for batch processing.

Some users express their interest in GNU Cobol and the challenges of writing Cobol programs that run on different platforms. They mention the need for examples and more documentation.

There is also a discussion about different Cobol-related systems like JCL, Tivoli, IDMS, IMS, Adabas, DB2, CICS, RACF, and others. One user mentions that Cobol is often used in CICS transaction processing systems in online banking.

The conversation then shifts to the IBM mainframe environment, discussing aspects like physical file definitions, JCL, accessing datasets, and using REXX as a scripting language.

Further comments touch on ISPF, Unix environments, MVS OpenEdition, and modern computing history. Some users express their enjoyment of working with Cobol and mainframe systems, while others mention they have no interest in learning Cobol due to their current job requirements or personal preferences. The discussion ends with a comment about the functionality of Cobol compared to modern systems and the use of non-relational databases and I/O abstractions.

Overall, the discussion highlights the diverse opinions and experiences surrounding Cobol, its relevance in modern systems, and its role in critical infrastructure.

### Show HN: Autolicious – AI-powered bookmark cataloging Chrome extension

#### [Submission URL](https://chrome.google.com/webstore/detail/autolicious/jbmpomloomhbfflncpmcmfajbppfddjk) | 62 points | by [coolvision](https://news.ycombinator.com/user?id=coolvision) | [29 comments](https://news.ycombinator.com/item?id=37987877)

A group of scientists has developed a cutting-edge solar panel that is not only highly efficient, but also can be printed like a newspaper. This means that solar panels can now be produced on a much larger scale and at a significantly lower cost. This innovation has the potential to revolutionize the way we generate and use renewable energy, paving the way for a more sustainable future.

The discussion on this submission revolves around various topics:

1. The first comment suggests using a logical direction killer feature for a bookmark categorization system to improve knowledge-based reference points for conversations.
2. A response to the first comment mentions a non-source extension and proposes the use of RAG (Retrieval-Augmented Generation) models to enhance the browsing experience.
3. Another comment raises the question of why browsers don't incorporate small LLMs (Large Language Models) like Mistral to improve search functionality.
4. There is a mention of Zenfetch, a website that seems to be related to the topic.
5. A user comments that the discussion is messy and fast-paced.
6. Another user mentions that the topic is currently popular due to the increasing involvement of software vendors in open-source development.
7. There is a discussion about the efficiency and cost of using LLMs in browsers, as well as the possibility of running them on CPUs or using WebGPU.
8. A comment raises the point that GPT-4 may be blocking simpler tasks like video page loading and suggests using smaller models instead.
9. A user shares their experience with a method to clean up and restore bookmarks in Chrome after they became corrupted.
10. Another user suggests using dedicated bookmark managers instead of relying on browser-based solutions.
11. There is a discussion about using chat models to handle bookmarks and automate de-duplication tasks.
12. A comment unrelated to the topic expresses interest in trying out the Edge browser as an alternative to Chrome.
13. Someone wonders if open-source projects like OpenAI have non-technical daily activities.
14. A user asks for help in finding a custom local extension to manage bookmarks and submits a link to their thoughts on integrating it with ChatGPT.
15. There is a mention of a similar extension called Pinbot for sending data to an external server, along with a link to it.
16. The conversation ends with a thank-you message and a comment about making bookmarks and links work better, which leads to a discussion on creating an MVP over the weekend.

Overall, the discussion covers various ideas and suggestions related to bookmark management and the use of language models in browsers.

### New data poisoning tool lets artists fight back against generative AI

#### [Submission URL](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/) | 77 points | by [lawlessone](https://news.ycombinator.com/user?id=lawlessone) | [74 comments](https://news.ycombinator.com/item?id=37990750)

A research team from the University of Chicago has developed a tool called Nightshade that allows artists to add invisible changes to their artwork, which can disrupt the training of AI models if the images are scraped from the internet. The tool is intended to combat AI companies that use artists' work without permission, creating a powerful deterrent against copyright infringement and intellectual property violation. The team also created Glaze, a tool that allows artists to "mask" their personal style to prevent it from being scraped by AI companies. Nightshade exploits a security vulnerability in generative AI models and can cause the models to malfunction when they encounter the poisoned images. While there is a risk of malicious use, it would require thousands of poisoned images to inflict real damage on larger, more powerful AI models. The researchers have also made Nightshade open source, allowing others to use and modify the tool.

The discussion on this submission is varied and covers several different points. Some users express skepticism about the effectiveness of Nightshade and its ability to disrupt AI models. Others discuss the potential for malicious use of the tool and the need for safeguards against it. There is also a debate about the legality and ethics of AI companies using artists' work without permission and the role of copyright infringement in the art world. Some users mention the importance of protecting artists' rights and compensating them for their work, while others argue that AI-generated art is a natural progression in the field and should be accepted. Finally, there are discussions about the limitations of AI-generated art and the impact of technology on music discovery and consumption.

