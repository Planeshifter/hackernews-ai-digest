## AI Submissions for Mon Dec 18 2023 {{ 'date': '2023-12-18T17:09:50.734Z' }}

### LLMLingua: Compressing Prompts for Faster Inferencing

#### [Submission URL](https://github.com/microsoft/LLMLingua) | 136 points | by [TarqDirtyToMe](https://news.ycombinator.com/user?id=TarqDirtyToMe) | [38 comments](https://news.ycombinator.com/item?id=38689653)

Microsoft has developed a new tool called LLMLingua that compresses prompts for accelerated inference of large language models (LLMs). By eliminating unimportant tokens in the prompt, LLMLingua achieves up to 20x compression with minimal performance loss. This tool addresses the limitations of LLMs, such as prompt length limits and high pricing, by providing a simple and efficient method for compression. In addition, Microsoft has also introduced LongLLMLingua, which enhances LLMs' ability to perceive key information in long-context scenarios using prompt compression. This method not only improves performance but also saves cost, with potential savings of up to $28.5 per 1,000 samples. LLMLingua and LongLLMLingua offer practical solutions for users of LLMs, enabling longer contexts and more efficient processing.

The discussion around the submission revolves around various aspects of LLMLingua and its implications. Some users find the compression algorithm used in LLMLingua interesting and effective in reducing prompt sizes while maintaining semantic meaning. However, others point out potential limitations and risks such as subjective assessment of performance and concerns related to censorship.

There is a discussion about the benefits and drawbacks of prompt compression, with users expressing different views. Some highlight the importance of understanding contextual information and the potential harm of using compressed prompts. Others argue that it is necessary to optimize models for efficiency and cost-effectiveness.

The conversation expands to cover topics such as model expansion, text generation, compression in intelligence, common standards in context, and training LLMs. Some users wonder about the reverse application of large language models for compressing sentences. Others discuss the potential benefits of humans learning to read compressed language.

There is also a brief discussion about the use of shorthand and the benefits of humans learning to compress language. In addition, users discuss the challenges and potential improvements in working with LLMLingua, as well as the importance of context in efficient model tokenization.

Finally, there are flagged comments regarding the context of distributional alignment and the need for understanding and respectful communication.

### Show HN: Microagents: Agents capable of self-editing their prompts / Python code

#### [Submission URL](https://github.com/aymenfurter/microagents) | 214 points | by [gourmetcode](https://news.ycombinator.com/user?id=gourmetcode) | [75 comments](https://news.ycombinator.com/item?id=38679453)

Microagents: Modular Agents Capable of Self-Editing Their Prompts and Python Code

A GitHub repository called "microagents" has caught the attention of the Hacker News community. The repository contains a project that explores the concept of self-evolving agents capable of generating and improving themselves. These agents can automatically generate Python code prompts tailored to provide answers to user queries.

The process starts with a user query, which activates a basic "bootstrap" agent. The bootstrap agent plans and delegates tasks to specialized agents capable of running Python code for broader functions. An Agent Manager oversees these agents, selecting or creating them based on vector similarity. The agents have evolving system prompts that improve through learning.

The repository showcases two synthesized agent prompts: "CalculateAddition Agent" and "GetPopulationOfCountry Agent." The CalculateAddition Agent is an arithmetic solver that can calculate the sum of two numbers. The GetPopulationOfCountry Agent is a data extractor that retrieves the population of a given country using a provided Python code snippet.

The project faces certain challenges and potential improvements. Path optimization is needed to effectively discard non-functional agents. Performance and parallelization could be enhanced by implementing parallel processing for prompt evolutions. A refined strategy for prompt evolution, which quantifies the success ratio, would improve the system. Integrating persistent agent prompts with vector databases and sharing successful agents across runtime environments can improve efficiency. Implementing a hierarchical agent structure for managing requests could also lead to major improvements.

The project, written in Python, has garnered 365 stars and 7 forks on GitHub. It has sparked interest in the Hacker News community, with users discussing the potential applications and limitations of self-evolving agents.

The discussion on Hacker News revolves around the concept of self-evolving agents and their potential applications and limitations. Here are the main points raised:

- Some users discuss the similarity between the "Microagents" project and the movie Memento, where Leonard struggles to recall events due to a condition that causes him to lose his memories. They suggest that the prompt evolution in Microagents is similar to Leonard's experience of relying on prompts to recall information.

- Others point out that self-evolving agents can be useful but also present challenges, including the need for path optimization to discard non-functional agents and the potential for performance and parallelization enhancements.

- Users discuss the possibility of using a hierarchical agent structure for managing requests and the potential benefits of integrating persistent agent prompts with vector databases and sharing successful agents across runtime environments.

- There is interest in connecting or creating domain-specific languages (DSLs) inspired by Microagents and exploring its potential applications for Forth and Prolog.

- Some users mention related projects, such as OpenAI's prompt engine using Memento as a metaphor and the Soldier of the Mist project on Wikipedia.

- Others discuss the trade-offs and challenges of using multiple prompts for different tasks and the importance of context and history in generating effective responses.

- The performance and limitations of Microagents are discussed, including issues with generating correct responses and the potential limitations of passing messages and using machine learning models in the system.

- Some users describe their own experiments with similar projects, including a JavaScript-based Paint AI program and the challenges and feedback they encountered.

- There is appreciation for the implementation of prompt management in Microagents and its ability to generate prompts based on results.

- The discussion also touches on the broader topics of function systems, safety considerations, and the potential of genetic algorithms and thermodynamics as analogies for self-improving systems.

- Some users recommend reading materials on safety and optimality, and a few users engage in a debate about the limitations of language models and the possibilities for technological transformation.

Overall, the discussion showcases both enthusiasm for the possibilities of self-evolving agents and thoughtful consideration of the challenges and potential limitations of the approach.

### Small offline large language model â€“ TinyChatEngine from MIT

#### [Submission URL](https://graphthinking.blogspot.com/2023/12/small-offline-large-language-model.html) | 110 points | by [physicsgraph](https://news.ycombinator.com/user?id=physicsgraph) | [24 comments](https://news.ycombinator.com/item?id=38678773)

Introducing the Hacker News Daily Digest, your go-to source for a concise and engaging overview of the most trending stories on Hacker News. We've carefully hand-picked the top submissions and translated them into captivating summaries, so you can stay informed even when time is tight. From mind-blowing tech breakthroughs to thought-provoking discussions, we've got it all covered. So sit back, grab a cup of coffee, and let us bring you up to speed on all things Hacker News. Stay tuned for your daily dose of intellectual stimulation and inspiration!

The discussion about the submission "Introducing the Hacker News Daily Digest" on Hacker News covers a range of topics related to language models (LLMs), memory requirements, and performance. Here are the key takeaways:

1. Users discuss the feasibility of utilizing smaller LLMs for specific tasks. One user suggests that they have had success with smaller LLMs and provides examples of personal use cases.

2. There is a suggestion to consider running LLMs on devices with limited resources, such as a 4GB MacBook Air, but concerns are raised about the impact on performance due to memory limitations.

3. A discussion ensues about whether Mixtral MoE, a large language model, should load submodels sequentially instead of all at once to fit within memory constraints. The potential performance trade-offs of loading weights sequentially are debated.

4. The topic of Python as a tool for natural language inference (NLI) is briefly mentioned, with one user pointing out that Python's NLI engine relies on native code.

5. A user expresses confusion about the TinyChatEngine and its ability to handle smaller, locally modified language models, as there are concerns about the large model file sizes.

6. A link to a GitHub repository for TinyChatEngine is shared, with additional information provided about the hardware requirements and performance expectations.

7. The usage of preprocessed models and their specific size and latency characteristics are mentioned. These models can be optimized and downloaded from HF (Hugging Face) Dropbox.

8. A brief discussion takes place regarding the ability of LLMs to talk and how they handle complex templates.

9. Users share their personal experiences in using LLMs, discussing their performance on different devices and their ability to parse unstructured data.

10. There is a mention of someone trying the installation on macOS 10.14.6, with satisfactory performance on an i5-8600 CPU running at 3.1GHz with 6 cores and 32GB memory.

11. The comparison between AI language models and assembly language models is briefly discussed, with a link to additional resources.

Overall, the discussion delves into various technical aspects of language models, including memory requirements, performance considerations, and practical use cases.

### Wasm3 entering a minimal maintenance phase

#### [Submission URL](https://github.com/wasm3/wasm3) | 522 points | by [padolsey](https://news.ycombinator.com/user?id=padolsey) | [137 comments](https://news.ycombinator.com/item?id=38681672)

Wasm3: A Fast WebAssembly Interpreter and Universal WASM Runtime

Wasm3 is a powerful and efficient WebAssembly interpreter that offers a universal runtime for running WASM code. It is built with speed and versatility in mind, passing the WebAssembly spec testsuite and running many WASI apps.

The project provides a small getting started guide to help developers install and use Wasm3. It can be used as a library for various programming languages, including Python3, Rust, C/C++, GoLang, Zig, Perl, and more. Wasm3 also runs on a wide range of architectures and platforms, such as x86, ARM, RISC-V, Linux, Windows, iOS, Android, and even in browsers using WebAssembly itself.

While some might question why use a "slow interpreter" instead of a "fast JIT" for running WebAssembly, Wasm3 highlights the advantages of the interpreter approach. These include improved runtime executable size, reduced memory usage, and lower startup latency. Additionally, the interpreter approach offers better portability, security, and ease of integration into existing projects.

Wasm3's main motivation is to provide a lightweight and reliable engine for running WebAssembly on embedded devices. While it started as a research project, Wasm3 has practical use cases in edge computing, scripting, plugin systems, IoT rule execution, smart contracts, and more.

The project is actively maintained, although the developer has recently faced personal challenges due to the destruction of their home. They assure the community that they are committed to keeping the project alive and will actively review and merge incoming Pull Requests.

If you're interested in exploring the capabilities of WebAssembly and need a fast and universal runtime, Wasm3 is a solid choice. You can find demos, installation instructions, troubleshooting tips, and more on the project's GitHub repository.

The discussion surrounding the submission revolves around various topics, including personal challenges faced by the developer, the performance of Wasm3 compared to native interpreters, and a heated debate about the political situation in Ukraine and Russia.

Some commenters express their concern and offer support to the developer who has faced personal challenges due to the destruction of their home. The developer assures the community that they remain committed to maintaining the project and reviewing incoming pull requests.

There is a debate about the performance of Wasm3 as an interpreter compared to native interpreters. Some users argue that Wasm3's performance is slower than native interpreters, while others agree with the developer's emphasis on the advantages of the interpreter approach, such as improved runtime executable size and lower startup latency.

The discussion then takes a political turn, with commenters discussing the conflict between Ukraine and Russia. Some users raise concerns about the involvement of foreign countries and the spread of misinformation, while others share their personal experiences and views on the matter. The debate includes discussions about forced conscription, nationalism, and the interpretation of historical events.

In response to some comments linking Azov, a Ukrainian nationalist group, to neo-Nazism, other users refute these claims and argue that Russia is the one supporting neo-Nazi ideologies. There is a back-and-forth about the involvement of fascist ideologies in the conflict and the credibility of certain sources of information.

Overall, the discussion involves a mix of technical discussions about the project itself and the broader political context in which it exists.

### Behind the scenes scaling ChatGPT and the OpenAI APIs [video] - Eng Mgr @ OpenAI

#### [Submission URL](https://www.youtube.com/watch?v=PeKMEXUrlq4) | 106 points | by [slyall](https://news.ycombinator.com/user?id=slyall) | [7 comments](https://news.ycombinator.com/item?id=38681541)

Introducing the AI Digest, your daily dose of the most exciting stories from Hacker News! Today's top submission takes us on a thrilling ride through the world of technology. So buckle up and get ready for a wild adventure!

Our featured story is all about the fascinating advancements in artificial intelligence. Imagine a world where machines can understand and generate code on their own. Sounds like something out of a sci-fi film, right? Well, hold on to your hats, because OpenAI's latest creation, "GitHub Copilot," is here to make that a reality!

GitHub Copilot is an AI-powered code assistant that uses machine learning models to assist developers in writing code. It analyzes the code you're working on and suggests relevant lines or even entire functions. It's like having a coding partner who knows all the ins and outs, always ready to lend a helping hand.

But here's where it gets even more mind-blowing. GitHub Copilot doesn't just rely on pre-existing code snippets. It can actually generate new code from scratch based on the context and your intentions. It's as if the program is able to peer into the minds of developers and understand their coding style and goals. Talk about a game-changer!

While GitHub Copilot is still in its early stages, developers all around the world are already excited about the possibilities it brings. Some see it as a helpful tool that can save time and reduce the likelihood of making errors, while others express concerns about potential copyright violations or the risk of reliance on AI-generated code.

OpenAI is well aware of these concerns, and they emphasize the importance of developing responsible AI technology. They aim to ensure that Copilot is a useful tool for developers, while still respecting the legal and ethical boundaries of code generation.

So, whether you're an experienced developer or a coding newbie, GitHub Copilot promises to revolutionize the way we write code. It's an exciting glimpse into the future where AI becomes a true partner in our technological endeavors.

And that wraps up today's digest of the top story on Hacker News. Keep your eyes peeled for tomorrow's edition of the AI Digest, where we'll dive into another captivating tale from the world of technology. Stay curious, stay informed, and keep hacking!

The following discussion on Hacker News revolves around the submission titled "Introducing the AI Digest, your daily dose of the most exciting stories from Hacker News!" Here are some key points from the discussion:

- User "tkkn" shares a link to the AI Digest and comments that it is an interesting talk.
- User "nliang86" appreciates the breakdown of sections in the digest and suggests adding key messages to each section.
- User "3abiton" mentions that AI-generated recipes could be an interesting topic to cover in future digests.
- User "have_faith" mentions a video called "VideoGist" and its connection to the discussion.
- User "troelsSteegin" shares a link to "Show HN" and invites others to check it out.
- User "frakt0x90" refers to a specific post history but does not provide further context.
- User "SeanAnderson" responds to "frakt0x90," stating that post history does not necessarily imply anything and that the response could be a marketing strategy to make the product relevant to the topic.

Lastly, user "T3RMINATED" indicates that the summary is done.

### Tofu-maker Yamami sees shares surge after automating ancient craft

#### [Submission URL](https://www.japantimes.co.jp/business/2023/12/18/companies/japan-tofu-maker-share-up/) | 55 points | by [mikhael](https://news.ycombinator.com/user?id=mikhael) | [13 comments](https://news.ycombinator.com/item?id=38687443)

Tofu-maker Yamami is experiencing a surge in shares after successfully automating its ancient craft. While many tofu producers in Japan are struggling to stay afloat, Yamami is forecasting record profits thanks to its mass production capabilities. The company's newest factory, located at the foot of Mount Fuji, can churn out 15,000 units of tofu per hour, surpassing its competitors. Yamami attributes its success to the ability to access pristine groundwater with a stable temperature, which is essential for tofu production. In contrast to its domestic rivals, Yamami's shares have skyrocketed by 138% this year, outperforming both Japanese packaged-food peers and the broader market indexes.

The discussion on this submission covers a few different topics. 

One user, KolmogorovComp, shares a link to a YouTube video discussing the use of plastic containers in tofu production. Another user, thunderbird120, comments on the grammar and pronunciation in the video, noting that it is written by non-native speakers but can still be understood.

Terr_ replies to thunderbird120, saying that they are trying to improve their English script and that small changes can make a big difference. dtgrscm agrees, noting that they can tell when something is written wrong, even if they can't always explain what is wrong with it.

In response to a comment by Terr_, klpt provides examples of incorrect grammar and suggests the use of spelling checkers to avoid such errors. Terr_ mentions that sometimes there are misspellings and typos that are not caught by spell checkers.

rcrdbt adds a comment, stating that tofu has been produced for thousands of years and is both healthy and tasty.

Overall, the discussion touches on grammar, pronunciation, plastic container usage in tofu production, and the longevity and quality of tofu as a food product.

### Jarvis: A Voice Virtual Assistant in Python (OpenAI, ElevenLabs, Deepgram)

#### [Submission URL](https://github.com/AlexandreSajus/JARVIS) | 78 points | by [Alyx1337](https://news.ycombinator.com/user?id=Alyx1337) | [57 comments](https://news.ycombinator.com/item?id=38682095)

Introducing JARVIS: Your Own Personal Voice Assistant

AlexandreSajus has developed a new voice assistant called JARVIS, which allows users to interact with their computer using voice commands. JARVIS uses Deepgram for voice-to-text conversion, OpenAI's GPT-3 API for generating responses, and ElevenLabs for converting text to speech. The conversation between the user and JARVIS is then displayed in a web interface.

To use JARVIS, users simply speak into the microphone and JARVIS will convert their speech to text. The text is then sent to the GPT-3 API to generate a response, which is converted back to speech and played using Pygame. The conversation is also displayed in a web interface for easy reference.

To install JARVIS, users need to clone the repository and install the required dependencies. They also need to obtain API keys for Deepgram, OpenAI, and ElevenLabs. Once everything is set up, users can run the web interface and voice assistant scripts to start using JARVIS.

JARVIS is a powerful tool for hands-free computer interaction and can be customized to suit individual needs. With JARVIS, users can perform tasks, get information, and control their computer using voice commands. So, why not give JARVIS a try and experience the convenience of a personal voice assistant?

The discussion about the JARVIS voice assistant submission on Hacker News covers various topics related to speech-to-text and text-to-speech technology, as well as the potential applications and limitations of voice assistants.

Some users discuss the different speech-to-text providers, such as Deepgram, Speechmatics, and Assembly AI, highlighting their strengths and weaknesses in terms of accuracy and speed. The implementation of local speech models is also mentioned, with examples like Whisper SDK, VOSK, DeepSpeech, and Kaldi.

The conversation delves into real-time streaming and the challenges of handling streaming chunks for both speech-to-text and text-to-speech models. Users mention that current models have limited support for streaming and often suffer from drops in accuracy when dealing with smaller chunks of text or attention window constraints.

There are references to other related projects and technologies, including Microsoft's Local AI Voice Chat, Linguflex addons, and Vocal AI detection software. Some users suggest using ESP boxes and other hardware solutions for speech processing.

The discussion also touches on the Marvel Cinematic Universe's JARVIS and the potential applications of voice assistants in military and defense settings. The limitations of current models for handling complex mechanical tasks are mentioned, and the idea of combining different projects and frameworks is explored.

Users express their appreciation for the work done with OpenAI, ElevenLabs, and Deepgram, praising their performance and low latency. Some users suggest alternatives like Willow and RoboDad for text-to-speech synthesis.

One user mentions an issue with repurposing GPT-3 for voice assistant functionality and an unresolved question on Stack Overflow about recording audio. Another user suggests using local models nested within OpenAI models.

The discussion concludes with users sharing their own voice assistant projects, such as Kel and AI Terminal Assistant, as well as mentioning the trademark conflict with the name JARVIS from Marvel.

### Autonomous subs use AI to wayfind without GPS

#### [Submission URL](https://spectrum.ieee.org/reinforcement-learning-autonomous-submarines) | 49 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [44 comments](https://news.ycombinator.com/item?id=38678657)

Researchers at Flinders University in Australia have been testing deep reinforcement learning systems for autonomous underwater vehicles (UUVs) that can navigate without the use of GPS. UUVs face challenges in communication and navigation control due to the distorting effect of water. Since GPS signals cannot penetrate underwater and underwater cameras suffer from low visibility, researchers have turned to machine learning techniques to help UUVs navigate more accurately. The researchers used deep reinforcement learning to train the UUVs to navigate in difficult conditions and compensate for interference from ocean currents. The goal is to eventually use these autonomous subs to perform tasks such as scrubbing bio organisms off ship hulls to reduce the introduction of invasive species and lower shipping costs.

The discussion on this submission covers various topics related to underwater navigation and artificial intelligence (AI). Some commenters discuss the technical aspects of using AI for underwater navigation, such as the challenges of underwater communication and the potential for AI to replace traditional navigation methods. There is also a mention of the use of AI in nuclear submarines and the limitations of GPS-based navigation. Other discussions revolve around the use of AI in general, with comments about its marketability and its potential to replace expensive hardware. Some commenters also discuss the use of inertial navigation and the need for additional sensors in underwater vehicles. The discussion also touches on related topics such as underwater acoustic communication and the importance of accurate navigation for submarines.

