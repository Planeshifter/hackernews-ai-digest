## AI Submissions for Mon Dec 18 2023 {{ 'date': '2023-12-18T17:09:50.734Z' }}

### LLMLingua: Compressing Prompts for Faster Inferencing

#### [Submission URL](https://github.com/microsoft/LLMLingua) | 136 points | by [TarqDirtyToMe](https://news.ycombinator.com/user?id=TarqDirtyToMe) | [38 comments](https://news.ycombinator.com/item?id=38689653)

Microsoft has developed a new tool called LLMLingua that compresses prompts for accelerated inference of large language models (LLMs). By eliminating unimportant tokens in the prompt, LLMLingua achieves up to 20x compression with minimal performance loss. This tool addresses the limitations of LLMs, such as prompt length limits and high pricing, by providing a simple and efficient method for compression. In addition, Microsoft has also introduced LongLLMLingua, which enhances LLMs' ability to perceive key information in long-context scenarios using prompt compression. This method not only improves performance but also saves cost, with potential savings of up to $28.5 per 1,000 samples. LLMLingua and LongLLMLingua offer practical solutions for users of LLMs, enabling longer contexts and more efficient processing.

The discussion around the submission revolves around various aspects of LLMLingua and its implications. Some users find the compression algorithm used in LLMLingua interesting and effective in reducing prompt sizes while maintaining semantic meaning. However, others point out potential limitations and risks such as subjective assessment of performance and concerns related to censorship. There is a discussion about the benefits and drawbacks of prompt compression, with users expressing different views. Some highlight the importance of understanding contextual information and the potential harm of using compressed prompts. Others argue that it is necessary to optimize models for efficiency and cost-effectiveness. The conversation expands to cover topics such as model expansion, text generation, compression in intelligence, common standards in context, and training LLMs. Some users wonder about the reverse application of large language models for compressing sentences. Others discuss the potential benefits of humans learning to read compressed language. There is also a brief discussion about the use of shorthand and the benefits of humans learning to compress language. In addition, users discuss the challenges and potential improvements in working with LLMLingua, as well as the importance of context in efficient model tokenization.

Finally, there are flagged comments regarding the context of distributional alignment and the need for understanding and respectful communication.

### Show HN: Microagents: Agents capable of self-editing their prompts / Python code

#### [Submission URL](https://github.com/aymenfurter/microagents) | 214 points | by [gourmetcode](https://news.ycombinator.com/user?id=gourmetcode) | [75 comments](https://news.ycombinator.com/item?id=38679453)

A GitHub repository called "microagents" has caught the attention of the Hacker News community. The repository contains a project that explores the concept of self-evolving agents capable of generating and improving themselves. These agents can automatically generate Python code prompts tailored to provide answers to user queries.
The process starts with a user query, which activates a basic "bootstrap" agent. The bootstrap agent plans and delegates tasks to specialized agents capable of running Python code for broader functions. An Agent Manager oversees these agents, selecting or creating them based on vector similarity. The agents have evolving system prompts that improve through learning.
The repository showcases two synthesized agent prompts: "CalculateAddition Agent" and "GetPopulationOfCountry Agent." The CalculateAddition Agent is an arithmetic solver that can calculate the sum of two numbers. The GetPopulationOfCountry Agent is a data extractor that retrieves the population of a given country using a provided Python code snippet.
The project faces certain challenges and potential improvements. Path optimization is needed to effectively discard non-functional agents. Performance and parallelization could be enhanced by implementing parallel processing for prompt evolutions. A refined strategy for prompt evolution, which quantifies the success ratio, would improve the system. Integrating persistent agent prompts with vector databases and sharing successful agents across runtime environments can improve efficiency. Implementing a hierarchical agent structure for managing requests could also lead to major improvements.
The project, written in Python, has garnered 365 stars and 7 forks on GitHub. It has sparked interest in the Hacker News community, with users discussing the potential applications and limitations of self-evolving agents.

The discussion on Hacker News revolves around the concept of self-evolving agents and their potential applications and limitations. Here are the main points raised:

- Some users discuss the similarity between the "Microagents" project and the movie Memento, where Leonard struggles to recall events due to a condition that causes him to lose his memories. They suggest that the prompt evolution in Microagents is similar to Leonard's experience of relying on prompts to recall information.
- Others point out that self-evolving agents can be useful but also present challenges, including the need for path optimization to discard non-functional agents and the potential for performance and parallelization enhancements.
- Users discuss the possibility of using a hierarchical agent structure for managing requests and the potential benefits of integrating persistent agent prompts with vector databases and sharing successful agents across runtime environments.
- There is interest in connecting or creating domain-specific languages (DSLs) inspired by Microagents and exploring its potential applications for Forth and Prolog.
- Some users mention related projects, such as OpenAI's prompt engine using Memento as a metaphor and the Soldier of the Mist project on Wikipedia.
- Others discuss the trade-offs and challenges of using multiple prompts for different tasks and the importance of context and history in generating effective responses.
- The performance and limitations of Microagents are discussed, including issues with generating correct responses and the potential limitations of passing messages and using machine learning models in the system.
- Some users describe their own experiments with similar projects, including a JavaScript-based Paint AI program and the challenges and feedback they encountered.
- There is appreciation for the implementation of prompt management in Microagents and its ability to generate prompts based on results.
- The discussion also touches on the broader topics of function systems, safety considerations, and the potential of genetic algorithms and thermodynamics as analogies for self-improving systems.
- Some users recommend reading materials on safety and optimality, and a few users engage in a debate about the limitations of language models and the possibilities for technological transformation.

Overall, the discussion showcases both enthusiasm for the possibilities of self-evolving agents and thoughtful consideration of the challenges and potential limitations of the approach.

### Wasm3 entering a minimal maintenance phase

#### [Submission URL](https://github.com/wasm3/wasm3) | 522 points | by [padolsey](https://news.ycombinator.com/user?id=padolsey) | [137 comments](https://news.ycombinator.com/item?id=38681672)

Wasm3 is a powerful and efficient WebAssembly interpreter that offers a universal runtime for running WASM code. It is built with speed and versatility in mind, passing the WebAssembly spec testsuite and running many WASI apps. The project provides a small getting started guide to help developers install and use Wasm3. It can be used as a library for various programming languages, including Python3, Rust, C/C++, GoLang, Zig, Perl, and more. Wasm3 also runs on a wide range of architectures and platforms, such as x86, ARM, RISC-V, Linux, Windows, iOS, Android, and even in browsers using WebAssembly itself.

While some might question why use a "slow interpreter" instead of a "fast JIT" for running WebAssembly, Wasm3 highlights the advantages of the interpreter approach. These include improved runtime executable size, reduced memory usage, and lower startup latency. Additionally, the interpreter approach offers better portability, security, and ease of integration into existing projects. Wasm3's main motivation is to provide a lightweight and reliable engine for running WebAssembly on embedded devices. While it started as a research project, Wasm3 has practical use cases in edge computing, scripting, plugin systems, IoT rule execution, smart contracts, and more. The project is actively maintained, although the developer has recently faced personal challenges due to the destruction of their home. They assure the community that they are committed to keeping the project alive and will actively review and merge incoming Pull Requests. If you're interested in exploring the capabilities of WebAssembly and need a fast and universal runtime, Wasm3 is a solid choice. You can find demos, installation instructions, troubleshooting tips, and more on the project's GitHub repository.

The discussion surrounding the submission revolves around various topics, including personal challenges faced by the developer, the performance of Wasm3 compared to native interpreters, and a heated debate about the political situation in Ukraine and Russia. Some commenters express their concern and offer support to the developer who has faced personal challenges due to the destruction of their home. The developer assures the community that they remain committed to maintaining the project and reviewing incoming pull requests. There is a debate about the performance of Wasm3 as an interpreter compared to native interpreters. Some users argue that Wasm3's performance is slower than native interpreters, while others agree with the developer's emphasis on the advantages of the interpreter approach, such as improved runtime executable size and lower startup latency. The discussion then takes a political turn, with commenters discussing the conflict between Ukraine and Russia. Some users raise concerns about the involvement of foreign countries and the spread of misinformation, while others share their personal experiences and views on the matter. The debate includes discussions about forced conscription, nationalism, and the interpretation of historical events. In response to some comments linking Azov, a Ukrainian nationalist group, to neo-Nazism, other users refute these claims and argue that Russia is the one supporting neo-Nazi ideologies. There is a back-and-forth about the involvement of fascist ideologies in the conflict and the credibility of certain sources of information.

Overall, the discussion involves a mix of technical discussions about the project itself and the broader political context in which it exists.

### Tofu-maker Yamami sees shares surge after automating ancient craft

#### [Submission URL](https://www.japantimes.co.jp/business/2023/12/18/companies/japan-tofu-maker-share-up/) | 55 points | by [mikhael](https://news.ycombinator.com/user?id=mikhael) | [13 comments](https://news.ycombinator.com/item?id=38687443)

Tofu-maker Yamami is experiencing a surge in shares after successfully automating its ancient craft. While many tofu producers in Japan are struggling to stay afloat, Yamami is forecasting record profits thanks to its mass production capabilities. The company's newest factory, located at the foot of Mount Fuji, can churn out 15,000 units of tofu per hour, surpassing its competitors. Yamami attributes its success to the ability to access pristine groundwater with a stable temperature, which is essential for tofu production. In contrast to its domestic rivals, Yamami's shares have skyrocketed by 138% this year, outperforming both Japanese packaged-food peers and the broader market indexes.

The discussion on this submission covers a few different topics. One user, KolmogorovComp, shares a link to a YouTube video discussing the use of plastic containers in tofu production. Another user, thunderbird120, comments on the grammar and pronunciation in the video, noting that it is written by non-native speakers but can still be understood. Terr_ replies to thunderbird120, saying that they are trying to improve their English script and that small changes can make a big difference. dtgrscm agrees, noting that they can tell when something is written wrong, even if they can't always explain what is wrong with it. In response to a comment by Terr_, klpt provides examples of incorrect grammar and suggests the use of spelling checkers to avoid such errors. Terr_ mentions that sometimes there are misspellings and typos that are not caught by spell checkers. rcrdbt adds a comment, stating that tofu has been produced for thousands of years and is both healthy and tasty.

Overall, the discussion touches on grammar, pronunciation, plastic container usage in tofu production, and the longevity and quality of tofu as a food product.

### Autonomous subs use AI to wayfind without GPS

#### [Submission URL](https://spectrum.ieee.org/reinforcement-learning-autonomous-submarines) | 49 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [44 comments](https://news.ycombinator.com/item?id=38678657)

Researchers at Flinders University in Australia have been testing deep reinforcement learning systems for autonomous underwater vehicles (UUVs) that can navigate without the use of GPS. UUVs face challenges in communication and navigation control due to the distorting effect of water. Since GPS signals cannot penetrate underwater and underwater cameras suffer from low visibility, researchers have turned to machine learning techniques to help UUVs navigate more accurately. The researchers used deep reinforcement learning to train the UUVs to navigate in difficult conditions and compensate for interference from ocean currents. The goal is to eventually use these autonomous subs to perform tasks such as scrubbing bio organisms off ship hulls to reduce the introduction of invasive species and lower shipping costs.

The discussion on this submission covers various topics related to underwater navigation and artificial intelligence (AI). Some commenters discuss the technical aspects of using AI for underwater navigation, such as the challenges of underwater communication and the potential for AI to replace traditional navigation methods. There is also a mention of the use of AI in nuclear submarines and the limitations of GPS-based navigation. Other discussions revolve around the use of AI in general, with comments about its marketability and its potential to replace expensive hardware. Some commenters also discuss the use of inertial navigation and the need for additional sensors in underwater vehicles. The discussion also touches on related topics such as underwater acoustic communication and the importance of accurate navigation for submarines.

