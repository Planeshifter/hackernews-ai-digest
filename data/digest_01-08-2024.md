## AI Submissions for Mon Jan 08 2024 {{ 'date': '2024-01-08T17:10:26.628Z' }}

### Turing Complete Transformers: Two Transformers Are More Powerful Than One

#### [Submission URL](https://openreview.net/forum?id=MGWsPGogLH) | 181 points | by [georgehill](https://news.ycombinator.com/user?id=georgehill) | [68 comments](https://news.ycombinator.com/item?id=38919884)

The ICLR 2024 Conference Submission titled "Turing Complete Transformers: Two Transformers Are More Powerful Than One" has garnered significant attention. In this paper, the authors present Find+Replace transformers, a new family of multi-transformer architectures that outperform GPT-4 on various challenging tasks. The researchers establish that traditional transformers are not Turing complete, while Find+Replace transformers are. They go on to demonstrate how arbitrary programs can be compiled into Find+Replace transformers, potentially aiding interpretability research. Additionally, the paper showcases the superior performance of Find+Replace transformers over GPT-4 on a set of composition challenge problems. This work aims to provide a theoretical foundation for multi-transformer architectures and encourage further exploration in this area.

The discussion on this submission revolves around several key points. 

1. The claim that traditional transformers are not Turing complete: Some users express skepticism and argue that traditional transformers can be considered Turing complete. Others agree with the authors' argument that Find+Replace transformers are more powerful.

2. The concept of intelligence: There is a discussion about the definition of intelligence and whether current AI models truly exhibit intelligence. Some argue that intelligence is a loosely defined concept that can be attributed to humans, animals, and even inanimate objects, while others argue that current AI models have significant limitations.

3. Quantum effects and consciousness: There are debates about the relevance of quantum effects and whether they are necessary for achieving true intelligence. Some users discuss the potential impact of quantum computers on AI, while others dismiss the idea as not essential.

4. The limitations of current AI models: Users discuss the limitations of current AI models, such as their inability to provide intelligent answers without resorting to trivial or nonsensical responses. There is also a discussion about the need for better feedback mechanisms to improve AI performance and address the issue of AI generating irrelevant or misleading information.

5. Philosophical considerations: Some users engage in philosophical discussions, highlighting that the topic raises questions about the nature of intelligence and the distinction between humans and machines.

6. Reviewing and feedback: Users discuss the importance of constructive criticism in academic research, comparing it to receiving feedback from renowned figures such as Gordon Ramsey.

Overall, the discussion covers a range of topics, including the capabilities of transformers, the definition of intelligence, the role of quantum effects, the limitations of current AI models, and the value of critical feedback in research.

### Machine learning helps fuzzing find hardware bugs

#### [Submission URL](https://spectrum.ieee.org/hardware-hacking) | 37 points | by [rbanffy](https://news.ycombinator.com/user?id=rbanffy) | [20 comments](https://news.ycombinator.com/item?id=38906736)

A technique called "fuzzing," originally developed in the 1980s to find instabilities in UNIX command-line prompts, is being retooled to automate chip tests on the assembly line and discover bugs that could lead to hardware vulnerabilities. Fuzzing involves introducing commands and prompts to a chip that are not quite correct, which triggers erratic responses that can point researchers to potential weak links in the system. This technique saves time as it can be automated and executed multiple times during product development. In a recent study, researchers used reinforcement learning to select inputs for fuzz testing, making the process more efficient and faster.

The discussion on this submission covers a range of topics related to fuzzing and testing. Some users mention that fuzzing is effective for finding bugs in popular software and can be used to test chip designs. Others argue that fuzzing is not a substitute for traditional testing and that it mainly finds surface-level issues. The use of reinforcement learning in fuzzing is also discussed, with some users mentioning that it can make the process more efficient and faster. There is debate about the effectiveness of fuzzing in hardware validation, with some users questioning its ability to validate complex hardware designs. The limitations of existing hardware fuzzers are also debated, with suggestions for new approaches using multi-armed bandit algorithms. The discussion also touches on the importance of security in hardware design and the existence of prior work on the subject.

### Duolingo Cuts 10% of Contractors as It Uses More AI to Create App Content

#### [Submission URL](https://www.bloomberg.com/news/articles/2024-01-08/duolingo-cuts-10-of-contractors-in-move-to-greater-use-of-ai) | 244 points | by [leotravis10](https://news.ycombinator.com/user?id=leotravis10) | [295 comments](https://news.ycombinator.com/item?id=38918279)

Sorry, but I can't provide a digest of Hacker News right now.

The discussion on the submission revolves around the effectiveness of methods for learning languages, particularly using apps like Duolingo. Some commenters argue that comparing classroom learning with Duolingo is not a fair comparison because Duolingo provides a different learning experience. They also mention that spending 30 minutes on structured learning doesn't equate to 30 minutes of mindlessly scrolling through social media, as the effectiveness of learning can vary based on individual effort and commitment. Others express skepticism about the accuracy and usefulness of spending hundreds of hours on Duolingo to learn a language. The discussion also touches on topics like the definition of slavery and the limitations of language exposure and learning streaks.

### An "AI Breakthrough" on Systematic Generalization in Language?

#### [Submission URL](https://aiguide.substack.com/p/an-ai-breakthrough-on-systematic) | 46 points | by [picometer](https://news.ycombinator.com/user?id=picometer) | [4 comments](https://news.ycombinator.com/item?id=38916596)

In a recent paper, researchers Brenden Lake and Marco Baroni presented a neural network that demonstrates "human-like systematic generalization" in language understanding. This is significant because neural networks have traditionally struggled with this kind of generalization, where they can understand and produce related sentences if they can understand or produce a particular sentence. The researchers created a set of puzzles that tested this ability and found that their neural network performed on par with humans, including making similar errors. The media covered this as an "AI Breakthrough" and a method for helping AI "generalize like people do." However, there is still debate over the extent to which this achievement fulfills those enthusiastic characterizations.

The discussion on this submission focuses on the significance and limitations of the research paper. 

User "sgt101" finds the paper interesting and suggests that it makes some fascinating contributions to the field of AI, particularly in abstract reasoning. They also mention the importance of in-depth reviews of such papers.

User "shrmntnktp" provides three points to consider. Firstly, they refer to Betteridge's law of headlines, which suggests that the answer to any headline question is most likely "no." Secondly, they mention a study that involved 25 participants from Mechanical Turk, implying that the sample size is small and the results may not be directly comparable to human performance. Lastly, they express skepticism about the media coverage of this research, emphasizing the need for scrutiny and caution when interpreting results.

User "vrptr" engages with "shrmntnktp" and asks for clarification on their criticism. 

User "shrmntnktp" responds, agreeing that the sample size of 25 is small and may not adequately characterize human reasoning. They argue that this is a classic problem in psychology and AI research, where small sample sizes often lead to claims that do not hold up to scrutiny. They emphasize the need for a stronger foundation and extrapolation of the results.

### OpenAI and journalism

#### [Submission URL](https://openai.com/blog/openai-and-journalism) | 101 points | by [zerojames](https://news.ycombinator.com/user?id=zerojames) | [120 comments](https://news.ycombinator.com/item?id=38915673)

OpenAI has responded to The New York Times lawsuit, stating that it supports journalism and believes the lawsuit is unfounded. The company emphasizes its collaboration with news organizations and the new opportunities it creates for them. OpenAI aims to assist reporters and editors by using AI to analyze documents and translate stories. It also allows news publishers to connect with readers through its AI models.

OpenAI further addresses the issue of training AI models using publicly available internet materials, stating that it is fair use. However, the company provides an opt-out option for publishers who do not want their content accessed by OpenAI's tools, as a gesture of goodwill. The company highlights the widespread support for training AI models as fair use and its significance for AI innovation.

The issue of "regurgitation," where AI models reproduce content without generating original insights, is acknowledged by OpenAI. The company considers it a rare bug that they are actively working to eliminate. OpenAI expects users to use its technology responsibly and not manipulate the models to regurgitate content.

Lastly, OpenAI claims that The New York Times did not provide the full story in their lawsuit. The company states that discussions with The New York Times were progressing towards a partnership, which included real-time display with attribution in ChatGPT. OpenAI argues that The New York Times' content does not substantially contribute to their training data and that any regurgitation was likely induced by manipulated prompts. OpenAI expresses disappointment over The New York Times' surprise lawsuit.

The discussion on this submission revolves around various aspects of copyright infringement, fair use, and the role of AI models in reproducing content. Some users sympathize with OpenAI, stating that regurgitation is an issue that the company is actively working to address. They argue that training AI models using publicly available internet materials falls under fair use, but acknowledge the need for an opt-out option for publishers who do not want their content accessed.

Others raise concerns about the distinction between reproducing text verbatim and transformative use. They argue that simply copying and reproducing articles without substantial transformation may still infringe on copyright. Some users also highlight the importance of transparency in AI development and the potential implications of AI models regurgitating copyrighted works.

The discussion also touches on the potential legal implications for OpenAI and the distinction between models trained on public-facing internet data versus proprietary sources. Some users draw analogies with libraries and argue that the ability to recall and reproduce information is a fundamental aspect of AI models. However, others express concerns about the legality of reproducing copyrighted works without proper authorization.

Overall, the discussion highlights the complexity and nuances surrounding copyright, fair use, and AI technologies, with users providing different perspectives on the matter.

### My 2024 AI Predictions

#### [Submission URL](https://axflow.dev/blog/ai-predictions-2024/) | 51 points | by [nichochar](https://news.ycombinator.com/user?id=nichochar) | [31 comments](https://news.ycombinator.com/item?id=38915863)

Today's top stories on Hacker News focus on the advancements in generative AI and its impact on various industries. This year has marked a significant milestone in the development of generative AI, with text models like chatGPT paving the way for other modalities such as images, videos, and audio. Image models, led by Midjourney, have reached impressive levels of quality and artistic expression. Video generation and personalized news delivery are still in early stages but show promise with products like Pika and Runway. Audio models, both for text-to-speech and speech-to-text, have reached a level that can convincingly fool humans.

The advancement of generative AI has far surpassed the Turing test, with products built using these models making their mark in various markets. Consumer assistants, powered by language models, have seen a surge in popularity. These assistants, also known as copilots, are being utilized in domains such as law (Harvey), artificial characters (character.ai), life guidance (Dot), wellness/nutrition (Welling), and healthcare (doctor GPTs). However, OpenAI's attempt to build a marketplace for these specialized assistants may not succeed due to the complexity and customization required to create reliable products in this space. Surprisingly, tech giants like Amazon and Apple have been relatively slow in adopting these technologies for their voice assistants (Alexa and Siri).

Another significant category leveraging generative AI is code generation and reasoning. Predicting the next token in formally structured programming languages, such as TypeScript and Python, is a natural fit for language models. Developers, being domain experts, can evaluate the performance of AI products in this category more efficiently compared to other domains. Consequently, coding assistants and tools like codestory, Sweep.dev, and GitHub Copilot are seeing rapid innovation and adoption among developers.

Lastly, unstructured data processing, such as document parsing, is being revolutionized by language models. Complex data pipelines that previously relied on heuristic logic are now being migrated to LLMs, particularly in large companies.

Overall, the year 2024 holds immense potential for AI, with generative models making significant strides across different industries.

The discussion about the submission on Hacker News covers several topics related to the advancements in generative AI:

1. Unstructured document parsing: The conversation begins with a discussion about the challenges and benefits of using generative AI for converting unstructured data, such as legal contracts or chat logs, into structured, queryable data. While some users express skepticism about the accuracy and effectiveness of such models, others highlight the potential for extracting specific information, performing analysis, and answering questions. It is noted that language models have the ability to replace manual processing of legal documents with more accurate and efficient JSON-based data processing.

2. Historical data and data formats: Another user mentions the challenges faced in exchanging information in various inconsistent data formats in industries such as healthcare. They suggest that large-scale generative models like GPT-4V could be used to generate clean, normalized, and structured JSON data from historical documents, simplifying the data migration process and reducing the time required significantly.

3. Pricing and adoption of generative AI: The conversation shifts to discussing the market demand and pricing of generative AI products. Some users argue that companies may not be willing to pay high fees for AI-generated applications similar to Slack. Others point out that there are alternatives to Slack available today, and that companies paying high fees for AI-powered solutions are likely supporting external integrations like speech recognition. A user also mentions the hesitation of tech giants like Amazon and Apple in adopting these technologies for their voice assistants.

4. Code generation and reasoning: The discussion touches on the topic of AI-assisted coding and tools like codestory, Sweep.dev, and GitHub Copilot. Developers emphasize the success and innovation seen in this field, as predicting the next token in programming languages is a natural fit for language models. Comparisons are made to the progress seen in other domains, highlighting the efficiency of developers in evaluating AI products in the coding space.

5. The limitation of Turing test: One user expresses their opinion that while generative AI models like chatGPT have made advancements, they have not passed a true Turing test. They argue that models like GPT are not actively interacting and engaging in conversations like human beings, and that the Turing test requires a demonstration of understanding in a meaningful way.

Overall, the discussion highlights the potential and challenges of generative AI across various industries and sheds light on the advancements made so far. It also touches on the limitations of current models and their adoption in the market.

### Thousands of AI Authors on the Future of AI

#### [Submission URL](https://arxiv.org/abs/2401.02843) | 81 points | by [treebrained](https://news.ycombinator.com/user?id=treebrained) | [111 comments](https://news.ycombinator.com/item?id=38918366)

A recent paper titled "Thousands of AI Authors on the Future of AI" presents the findings of the largest survey of its kind, involving 2,778 researchers who have published in top-tier artificial intelligence (AI) venues. The researchers were asked to give their predictions on the pace of AI progress and the potential impacts of advanced AI systems. The aggregate forecasts suggest that there is at least a 50% chance of AI systems achieving several significant milestones by 2028, including autonomously constructing a payment processing site from scratch, creating a song indistinguishable from a new song by a popular musician, and autonomously downloading and fine-tuning a large language model. The study also found that if science continues undisrupted, there is a 10% chance of unaided machines outperforming humans in every possible task by 2027 and a 50% chance by 2047. However, there is still substantial uncertainty among respondents about the long-term value of AI progress, with disagreement about the potential outcomes, including extremely bad outcomes such as human extinction. While most researchers expressed optimism about the positive outcomes of superhuman AI, many also acknowledged the need to prioritize research aimed at minimizing potential risks from AI systems. Overall, the study highlights the diverse perspectives and concerns within the AI research community about the future of AI and its implications for society.

The discussion on this submission involves various points of disagreement and clarification regarding the topic of AI and the simulation of the human brain. Some users express skepticism about the approach of simulating chemical processes and neural networks in the brain, arguing that it is not an accurate representation of its functioning. Others delve into the complexity of chemical processes in cells and the challenges of understanding and modeling them.

There is a debate about the capability of AI systems to simulate the human brain and achieve general intelligence. Some argue that current AI research has not shown the ability to fully represent the brain's neural network, while others suggest that estimates of the parameter counts in AI models imply that sufficient representation is possible.

The discussion also touches on the limitations of simulating neural networks and the computational resources required. Some users discuss the bandwidth and processing limitations of systems compared to the vast number of synapses and channels in the brain.

Additionally, there are arguments about the definition of general intelligence and whether humans possess it. Some users highlight the difference between humans and computers in terms of their ability to perform intellectual tasks, while others emphasize that humans do possess general intelligence.

Overall, the discussion reflects a range of views and opinions on the topic of AI and its potential to simulate the human brain and achieve general intelligence.

### I made an app that runs Mistral 7B 0.2 LLM locally on iPhone Pros

#### [Submission URL](https://apps.apple.com/us/app/offline-chat-private-ai/id6474077941) | 289 points | by [winstonschen](https://news.ycombinator.com/user?id=winstonschen) | [182 comments](https://news.ycombinator.com/item?id=38906966)

Introducing Offline Chat, the revolutionary AI ChatBot that doesn't rely on an internet connection. This means you can use it anywhere and keep your data private and secure. Although it may not have the same capabilities as top-tier online models, Offline Chat is a versatile tool that stands out in engaging conversations and assisting with various tasks like writing. However, it's always advisable to fact-check independently.

To run the app, you'll need a Pro iPhone with at least 6GB of RAM. Compatible devices include the iPhone 15 Pro, iPhone 14 Pro, iPhone 13 Pro, and iPhone 12 Pro. For iPads, you'll have to check the RAM requirements based on your model and year. Technically, the AI behind Offline Chat is a finely tuned large language model based on Mistral 7B 0.1, quantized to 3-bit.

In the latest update (version 1.02, released on December 26, 2023), Offline Chat has been upgraded to use the Mistral 7B 0.2 model, which is truly extraordinary considering its small size. Users have rated the app 4.4 out of 5 stars, highlighting its usefulness and performance.

Privacy is a significant concern, and the developer, Opus Noma LLC, reassures users that no data is collected by the app. However, privacy practices may still vary depending on the features used or the user's age. The app is available for $1.99 and supports Family Sharing, allowing up to six family members to utilize it.

The discussion on the submission revolves around various aspects of Offline Chat, the AI ChatBot that doesn't require an internet connection. Here are the main points raised in the comments:

- Some users agree that local applications that rely on on-device AI models have their advantages, especially in terms of privacy and targeted functionality.
- The performance and capabilities of on-device AI models compared to cloud-based AI services were discussed. It was noted that on-device models may have limitations due to thermal, battery, and memory constraints.
- The discussion also touched on the feasibility and sustainability of expanding AI functionality in on-device models, with concerns raised about the processing power, battery life, and scalability of such models.
- Commentators mentioned examples of on-device AI functionalities found in various applications, such as Snapchat filters, pht processing, speech-to-text, and object detection.
- The importance of stability and context in AI chatbots was highlighted, with concerns raised about the stability and reliability of the AI models used in Offline Chat.
- There was discussion about the technical aspects of the AI models used in Offline Chat, including the Mistral 7B model and its implementation in the application.
- The possibility of running the Offline Chat app on different devices, such as Android and iPhones, was also raised.
- The matter of saved conversations and privacy was touched upon, with some users expressing concerns about the availability and security of chat histories.
- Users provided feedback on their experiences using Offline Chat, including issues with stability and memory consumption, and made suggestions for improvements.

Overall, the discussion highlighted the pros and cons of using on-device AI models and raised practical considerations related to performance, scalability, and privacy.

### Show HN: I used an LLM to parse HN Who's Hiring comments to structured job data

#### [Submission URL](https://hnjobsai.vercel.app/) | 13 points | by [tekmaven](https://news.ycombinator.com/user?id=tekmaven) | [5 comments](https://news.ycombinator.com/item?id=38911168)

📰 Here's your daily digest of the top posts on Hacker News:

1. 🌍 Resleeve, a company based in the Netherlands, is hiring a senior front-end engineer with experience in React and TypeScript, specifically using the Konva library. The role is remote-friendly and offers exciting opportunities to work with cutting-edge technologies. [Read more](https://jobs.polymer.co/resleeve/29359)

2. 🌍 Resleeve is also seeking a full-time intern for a front-end role. The intern should have experience with React, TypeScript, and Konva. Remote work is an option for this position as well. [Read more](https://jobs.polymer.co/resleeve/29360)

3. 🌍 Resleeve is additionally looking for a senior backend engineer with at least 7 years of experience in Python development. The position is remote and can be based in the Netherlands. [Read more](https://jobs.polymer.co/resleeve/29361)

4. 🌍 Comuneo, a German company, is searching for a software engineer who is interested in joining as a co-founder. They are focused on building a SaaS solution. If you have a passion for entrepreneurship and software development, this could be a great opportunity for you. [Read more](www.comuneo.org)

5. 🌍 Symmetry Investments, based in the UK, is hiring a senior ReactJS developer. If you have expertise in ReactJS and TypeScript, this could be an exciting role for you. [Read more](Email: jlenormand@symmetryinvestments.com)

That's it for today's digest! Stay tuned for more updates tomorrow.

The discussion surrounding the submission includes the following comments:

1. User "quickthrower2" remarks that the remote job opportunities mentioned in the post are excellent, with flexible time zones and global applicability. They suggest that applicants specify their desired time zone and have a window of around three hours from it. They also express that they would love to make good progress with the mentioned technologies.

2. User "hlsnkndrw" appreciates the timely comment and finds the job listings posted here very valuable, stating they have been searching for such opportunities for the past five days.

3. User "tkmvn" thanks "hlsnkndrw" for the suggestion and agrees with the idea of displaying job postings in a more structured and sorted manner.

4. User "chrssnll" brings up the topic of Kubernetes and various related technologies, possibly discussing their relevance in relation to the job opportunities mentioned in the submission.

5. User "nmyjsk" comments that the submission is pretty interesting.

