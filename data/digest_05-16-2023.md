## AI Submissions for Tue May 16 2023 {{ 'date': '2023-05-16T17:11:59.587Z' }}

### A guidance language for controlling LLMs

#### [Submission URL](https://github.com/microsoft/guidance) | 516 points | by [evanmays](https://news.ycombinator.com/user?id=evanmays) | [176 comments](https://news.ycombinator.com/item?id=35963936)

Microsoft has released a new guidance language designed to help control large language models. Called Guidance, the language allows developers to interleave generation, prompting and logical control into a single continuous flow that can mimic the way a language model processes text. With more powerful language models such as GPT-4 becoming available, Guidance can enable even richer structures to be created more easily and affordably. The language features a simple and intuitive syntax based on Handlebars templating, smart seed-based generation caching and easy integration with HuggingFace models.

The comments on the submission discussed various ways to control large language models, including prompt injection and exploiting prompt-injection and conditional inferences. Some commenters suggest that instructing models with correct instructions could significantly improve accuracy, while others question the usefulness of starting prompts, stating that it could lead to unnecessary or irrelevant output. Some commenters also mentioned attempts to create language syntaxes specific to certain businesses, such as insurance claims, and the challenges of building trust in testing frameworks.

### On the foolishness of “natural language programming” (1978)

#### [Submission URL](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD06xx/EWD667.html) | 111 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [57 comments](https://news.ycombinator.com/item?id=35968148)

In E.W. Dijkstra's essay "On the foolishness of 'natural language programming'," he challenges the idea that programming could be simplified if machines could be instructed in human languages. Drawing from the history of mathematics, he argues that the use of formal symbolism is a privilege, not a burden, and that communicating in natural language would actually complicate the work of both man and machine. Dijkstra also expresses concern about the decline of mastery of language in modern times, suggesting that the idea of natural language programming may be misguided.

The discussion on Hacker News revolves around the idea that human language programming can complicate the work of both man and machine. While some argue that natural language programming interfaces can help machines interpret and understand human language, others claim that formal language enhances precision and structure, making it easier to write and debug code. Some commenters suggest that programming ability is independent of language mastery while others highlight the importance of clarity and formalism in programming languages, calling for the use of formal symbols and expressions to transmit information to machines. The discussion also raises questions about the role of Artificial Intelligence in programming, asserting that computers do not necessarily need to understand natural language to be effective; instead, developers need to align their understanding with the machine's language to communicate effectively.

### The RedMonk Programming Language Rankings: January 2023

#### [Submission URL](https://redmonk.com/sogrady/2023/05/16/language-rankings-1-23/) | 55 points | by [clairegiordano](https://news.ycombinator.com/user?id=clairegiordano) | [26 comments](https://news.ycombinator.com/item?id=35967458)

RedMonk has released its language rankings for the first quarter of 2023, using GitHub and Stack Overflow data to measure language discussion and usage. The results show that, once again, JavaScript is the most popular language, followed by Python and Java. While the language industry is evolving rapidly, there is little evidence of rapid ascents and descents of programming languages in general. However, the emergence of large language models (LLMs) could have an impact in the future, perhaps by lowering the barriers of entry to new languages. As a result of the static language landscape, there are discussions about the possibility of shifting from bi-annual to annual language rankings.

In the comments, Nix, Nim, and JVM were discussed as well as programming for charting and a working language for Ada weapon systems for European banks. One commenter points out that Roff projects, GitHub projects, Julia, Haskell, and Perl are not being considered, while another says that Perl is rarely considered in popularity rankings. Ballerina, an open-source, cloud-native programming language that specializes in networking, is also discussed.

### Optimization Without Derivatives: Prima Fortran Version and Inclusion in SciPy

#### [Submission URL](https://fortran-lang.discourse.group/t/optimization-without-using-derivatives-the-prima-package-its-fortran-implementation-and-its-inclusion-in-scipy/5798) | 162 points | by [zaikunzhang](https://news.ycombinator.com/user?id=zaikunzhang) | [74 comments](https://news.ycombinator.com/item?id=35959991)

PRIMA, a package for solving general nonlinear optimization problems without using derivatives, has been developed by Zaikun Zhang. This package provides the reference implementation of Powell’s derivative-free optimization methods, including COBYLA, UOBYQA, NEWUOA, BOBYQA, and LINCOA. PRIMA is a project that aims to make Powell’s solvers understandable to everyone, not just experts. The modern Fortran version of PRIMA has already been completed, and interfaces for MATLAB and Python have been provided. The inclusion of PRIMA into SciPy is under discussion, which would replace the buggy and unmaintained Fortran 77 version of COBYLA underlying scipy.optimize.minimize. Native implementations of PRIMA in other languages will be available later.

The submission discusses PRIMA, a derivative-free optimization package that aims to be accessible to non-experts, and its potential inclusion in SciPy to replace the currently buggy and unmaintained Fortran 77 version of COBYLA. The discussion in the comments covers topics such as the use of modern Fortran, the availability of alternative optimization libraries like Mystic, and the challenges of optimizing performance using different languages and computing systems. The comments also touch on the importance of documentation and resources for learning modern Fortran.

### EU Artificial Intelligence Act

#### [Submission URL](https://artificialintelligenceact.eu/) | 140 points | by [Trouble_007](https://news.ycombinator.com/user?id=Trouble_007) | [118 comments](https://news.ycombinator.com/item?id=35966543)

The EU has proposed a new law on artificial intelligence, the AI Act, which assigns AI applications to three risk categories. Applications that create an unacceptable risk, like government-managed social scoring systems used in China, are banned, while high-risk applications, such as CV-scanning tools, are subject to legal requirements. Applications not explicitly banned or listed as high-risk are largely unregulated. The AI Act could become a global standard like the GDPR, affecting AI's positive or negative impact on daily life worldwide. Brazil's Congress recently passed a similar bill, though with some limitations. The AI Act is not without loopholes or inflexibility, so further improvements are necessary.

The discussion in the comments focuses on the difficulties of determining risk categories and the potential for discrimination in high-risk applications based on protected attributes such as skin color. Additionally, there are concerns about the effectiveness of the AI Act in regulating AI, and the need for further improvements. The discussion also touches on the GDPR and its limitations in creating a level playing field for tech companies, particularly for small startups.

### How Small Can Language Models Be and Still Speak Coherent English?

#### [Submission URL](https://arxiv.org/abs/2305.07759) | 37 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [10 comments](https://news.ycombinator.com/item?id=35958133)

Researchers Ronen Eldan and Yuanzhi Li have developed a new synthetic dataset called TinyStories to evaluate language models (LMs) with fewer parameters than those typically used in natural language processing. TinyStories consists of short stories with words typically understood by 3- or 4-year-olds, generated by GPT-3.5 and GPT-4, and the LMs trained on it have only one transformer block rather than many layers of global attention. Despite their small size, the LMs produce coherent and fluent text that demonstrates reasoning capabilities. A new evaluation paradigm grades content generated by these models using GPT-4 to provide a multidimensional score.

The discussion on the submission mainly revolved around the effectiveness of Tiny Language Models (LMs) with fewer parameters. Some users found the idea of using a synthetic dataset with simple language interesting, while others questioned the ability of these models to generate complex material. One user expressed frustration about the limitations of text-to-speech models that do not recognize different languages, while another commented on the importance of machine learning training. The conversation then drifted toward other machine learning applications. Finally, one user shared a link to a resource related to the topic.

### Colossus: The Forbin Project (1970) [video]

#### [Submission URL](https://archive.org/details/colossus-the-forbin-project-1970) | 129 points | by [Animats](https://news.ycombinator.com/user?id=Animats) | [78 comments](https://news.ycombinator.com/item?id=35957944)

The Internet Archive has made available for free the 1970 movie "Colossus: The Forbin Project," which explores the consequences of a sentient computer in the context of the Cold War. Viewers have praised the film's relevance to modern-day conversations about artificial intelligence, as well as its prescience.

The comments on Hacker News include discussions about the accuracy and relevance of the movie, as well as debates about the Turing Test and AI's potential to take over the world. Some commenters praise the movie for its portrayal of the risks associated with AI while others suggest that it presents an overly negative view. Other sci-fi classics, such as Demon Seed, The Andromeda Strain, and Soylent Green, are also mentioned.

### OpenAI CEO wants A.I. licensed for company benefit

#### [Submission URL](https://finance.yahoo.com/news/openai-ceo-sam-altman-tells-200241500.html) | 26 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [6 comments](https://news.ycombinator.com/item?id=35969352)

Today's top story is about OpenAI CEO Sam Altman testifying before a subcommittee of the Senate Judiciary Committee, which held hearings on the possible regulation of AI. Altman called for appropriate safety requirements and a licensing and registration regime for AI systems beyond a certain capability. However, Altman also urged a flexible governance framework to adapt to new technological developments while balancing incentivizing safety and ensuring people can access technology's benefits. Senator Marsha Blackburn was concerned about generative AI's copyright implications and impact on the Nashville-based country music scene. Overall, senators seemed aware of some of AI's resulting issues, including misinformation, election interference, fraud, bias, defamation, exploitative data gathering practices, data privacy violations, emerging evidence of wage depression in some fields, and environmental impacts.

The discussion on this submission includes a mix of agreement, disagreement, and humor. One user argues that OpenAI's policy on AI safety risks should play a large role in their product releases, to prevent harm to consumers or to the companies themselves. Another suggests making it mandatory to publish results from text-based generators to ensure transparency and avoid any associated problems. There is some humor mixed in as well, with one user joking about the "country AI" mention and others making jokes about the use of language in comments. Overall, there is a relatively light-hearted tone to the discussion.

### LMQL: A query language for programming (large) language models

#### [Submission URL](https://github.com/eth-sri/lmql) | 106 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [12 comments](https://news.ycombinator.com/item?id=35956484)

LMQL, a query language for large language models, combines natural language prompting with the expressiveness of Python and allows users to express advanced, multi-part queries. With only a few lines of code, LMQL can facilitate the interaction between users and large language models and optimize the queries for efficient execution within the language decoding loop. LMQL can be installed with a Python >= 3.10 environment and allows for GPU support for local models. The LMQL playground IDE includes a showcase of many exemplary LMQL programs, which can be executed using the lmql run command, or launched in a browser-based environment with lmql playground.

The discussion included descriptions of LMQL's benefits, limitations, and uses. It was noted that LMQL functions like SQL in that it provides primitives for basic search and constrained responses. It was also discussed that LMQL can be used to parse text and create models with a specific topic format. Users expressed interest in the application of LMQL in Nodejs and other languages, and the author indicated that they are actively investigating this. Finally, a user shared a demonstration of LMQL's control prompt.

### Asimov – The Original Prompt Engineer

#### [Submission URL](https://lojones.github.io/2023/04/30/asimov-prompt-engineer.html) | 24 points | by [sohkamyung](https://news.ycombinator.com/user?id=sohkamyung) | [4 comments](https://news.ycombinator.com/item?id=35956594)

Isaac Asimov's visionary Robot Series explored the interactions between humans and robots, laying the groundwork for today's prompt engineering. Prompt engineering involves crafting input prompts for AI systems to generate accurate and relevant outputs. Asimov's Robot universe, set in a future where humans and robots coexist, offered a unique exploration of the ethical and philosophical implications of AI systems. Asimov's Robot stories emphasized the importance of giving precise commands to robots, which can be seen as a precursor to modern prompt engineering. An example of prompt engineering from Asimov's works can be seen in "Mirror Image", where Detective Elijah Baley interrogates a robot to solve a crime.

The first comment includes a reference to a scene from the movie 2001: A Space Odyssey where a computer named HAL seems to be malfunctioning and repeating the phrase "I'm sorry, Dave, I'm afraid I can't do that". The second comment is discussing the concept of prompt engineering and how it relates to the design of user interfaces. It includes examples of how prompts are used in various software tools. The third comment refers to the programming concepts discussed in Isaac Asimov's Robot series and the movie Interstellar, particularly the character TARS who was designed with a 90% honesty function. A fourth comment discusses a recent development in natural language processing and the use of grammar validation in chatbots.


