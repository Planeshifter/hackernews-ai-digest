## AI Submissions for Tue May 16 2023 {{ 'date': '2023-05-16T17:11:59.587Z' }}

### Vintage AI predictions show our hopes and fears aren’t new, even if the tech is

#### [Submission URL](https://gizmodo.com/ai-chatbot-chatgpt-tech-1850433697) | 48 points | by [gumby](https://news.ycombinator.com/user?id=gumby) | [23 comments](https://news.ycombinator.com/item?id=35958374)

Rare documents and photos from the early days of AI have been showcased at the New York International Antiquarian Book Fair. The documents, penned between the late 1940s and 1960s, showed that concepts such as neural networks, probabilistic computing and machines impersonating humans were already being considered before the technology was there to see it through. While thriving open source networks currently experiment with AI, most of the papers exhibited were from a time of scientists researching for research's sake, and not in the halls of academia alone. Women, such as Jean Hall and Joyce Friedman, were frequently at the cutting edge of machine intelligence but are often left out of discussions of early AI research.

The submission discusses rare documents and photos from the early days of AI showcased at the New York International Antiquarian Book Fair. The discussion reveals that the Dartmouth summer workshop of 1956 is widely regarded as the ‚Äúkickstart to AI research.‚Äù Participants included significant problem solvers such as John McCarthy, Marvin Minsky, and Claude Shannon, among others, who made significant progress in creating machines that could solve problems reserved for humans. The comments touched upon the progress made in the years that followed and how AI has evolved from being limited by hardware capacity to becoming abstract concepts liberated from boundaries. There was also some discussion on how people dismiss doomsday claims with almost 100% accuracy and the issue of building trust, reputation, and credibility. Finally, the thread moves to discuss various topics ranging from robotic terminologies, Proto-Indo-European language to Karel pk's War Newts.

### A guidance language for controlling LLMs

#### [Submission URL](https://github.com/microsoft/guidance) | 516 points | by [evanmays](https://news.ycombinator.com/user?id=evanmays) | [176 comments](https://news.ycombinator.com/item?id=35963936)

Microsoft has released a new guidance language designed to help control large language models. Called Guidance, the language allows developers to interleave generation, prompting and logical control into a single continuous flow that can mimic the way a language model processes text. With more powerful language models such as GPT-4 becoming available, Guidance can enable even richer structures to be created more easily and affordably. The language features a simple and intuitive syntax based on Handlebars templating, smart seed-based generation caching and easy integration with HuggingFace models.

Microsoft has introduced a new guidance language called Guidance, which allows developers to control large language models such as GPT-4, by enabling even richer structures to be created more easily and affordably. The comments on the submission discussed various ways to control large language models, including prompt injection and exploiting prompt-injection and conditional inferences. Some commenters suggest that instructing models with correct instructions could significantly improve accuracy, while others question the usefulness of starting prompts, stating that it could lead to unnecessary or irrelevant output. Some commenters also mentioned attempts to create language syntaxes specific to certain businesses, such as insurance claims, and the challenges of building trust in testing frameworks.

### On the foolishness of “natural language programming” (1978)

#### [Submission URL](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD06xx/EWD667.html) | 111 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [57 comments](https://news.ycombinator.com/item?id=35968148)

In E.W. Dijkstra's essay "On the foolishness of 'natural language programming'," he challenges the idea that programming could be simplified if machines could be instructed in human languages. Drawing from the history of mathematics, he argues that the use of formal symbolism is a privilege, not a burden, and that communicating in natural language would actually complicate the work of both man and machine. Dijkstra also expresses concern about the decline of mastery of language in modern times, suggesting that the idea of natural language programming may be misguided.

The discussion on Hacker News revolves around the idea that human language programming can complicate the work of both man and machine. While some argue that natural language programming interfaces can help machines interpret and understand human language, others claim that formal language enhances precision and structure, making it easier to write and debug code. Some commenters suggest that programming ability is independent of language mastery while others highlight the importance of clarity and formalism in programming languages, calling for the use of formal symbols and expressions to transmit information to machines. The discussion also raises questions about the role of Artificial Intelligence in programming, asserting that computers do not necessarily need to understand natural language to be effective; instead, developers need to align their understanding with the machine's language to communicate effectively.

### The RedMonk Programming Language Rankings: January 2023

#### [Submission URL](https://redmonk.com/sogrady/2023/05/16/language-rankings-1-23/) | 55 points | by [clairegiordano](https://news.ycombinator.com/user?id=clairegiordano) | [26 comments](https://news.ycombinator.com/item?id=35967458)

RedMonk has released its language rankings for the first quarter of 2023, using GitHub and Stack Overflow data to measure language discussion and usage. The results show that, once again, JavaScript is the most popular language, followed by Python and Java. While the language industry is evolving rapidly, there is little evidence of rapid ascents and descents of programming languages in general. However, the emergence of large language models (LLMs) could have an impact in the future, perhaps by lowering the barriers of entry to new languages. As a result of the static language landscape, there are discussions about the possibility of shifting from bi-annual to annual language rankings.

RedMonk has released its language rankings for Q1 2023, which shows JavaScript retaining its top position, followed by Python and Java. Despite industry evolution, programming languages see little ascents and descents. Still, emergence of Large Language Models (LLMs) can potentially impact the future by lowering barriers of entry for new languages. Due to the static language landscape, the possibility of shifting from bi-annual to annual language rankings is being discussed. In the comments, Nix, Nim, and JVM were discussed as well as programming for charting and a working language for Ada weapon systems for European banks. One commenter points out that Roff projects, GitHub projects, Julia, Haskell, and Perl are not being considered, while another says that Perl is rarely considered in popularity rankings. Ballerina, an open-source, cloud-native programming language that specializes in networking, is also discussed.

### Sam Altman goes before US Congress to propose licenses for building AI

#### [Submission URL](https://www.reuters.com/technology/openai-chief-goes-before-us-congress-propose-licenses-building-ai-2023-05-16/) | 873 points | by [vforgione](https://news.ycombinator.com/user?id=vforgione) | [1180 comments](https://news.ycombinator.com/item?id=35960125)

The CEO of OpenAI, the startup behind ChatGPT, testified before a Senate panel on Tuesday about the potential misuse of artificial intelligence (AI) in elections. CEO Sam Altman stated that the use of AI to harm election integrity is a "significant area of concern" and called for regulation and guidelines to be established. Altman also suggested that licensing and testing requirements be implemented for the development of AI models. The White House has convened top technology CEOs, including Altman, to address AI, and US lawmakers are seeking ways to limit AI's misuse while promoting its benefits and national security.

OpenAI CEO Sam Altman testified before a Senate panel on Tuesday and addressed potential AI misuse in elections, calling for regulation and guidelines. The discussion that follows includes various viewpoints on AI regulation, with some suggesting that AI should not be controlled by a small number of powerful corporations or governments. Others argue that implementing regulations is crucial to prevent the misuse of AI and protect national security. Some also express concern about the potential disruption AI may cause to various industries and society as a whole. There is also discussion surrounding the efficiency of AI training and the impact of AI on profit and social issues.

### Optimization Without Derivatives: Prima Fortran Version and Inclusion in SciPy

#### [Submission URL](https://fortran-lang.discourse.group/t/optimization-without-using-derivatives-the-prima-package-its-fortran-implementation-and-its-inclusion-in-scipy/5798) | 162 points | by [zaikunzhang](https://news.ycombinator.com/user?id=zaikunzhang) | [74 comments](https://news.ycombinator.com/item?id=35959991)

PRIMA, a package for solving general nonlinear optimization problems without using derivatives, has been developed by Zaikun Zhang. This package provides the reference implementation of Powell’s derivative-free optimization methods, including COBYLA, UOBYQA, NEWUOA, BOBYQA, and LINCOA. PRIMA is a project that aims to make Powell’s solvers understandable to everyone, not just experts. The modern Fortran version of PRIMA has already been completed, and interfaces for MATLAB and Python have been provided. The inclusion of PRIMA into SciPy is under discussion, which would replace the buggy and unmaintained Fortran 77 version of COBYLA underlying scipy.optimize.minimize. Native implementations of PRIMA in other languages will be available later.

The submission discusses PRIMA, a derivative-free optimization package that aims to be accessible to non-experts, and its potential inclusion in SciPy to replace the currently buggy and unmaintained Fortran 77 version of COBYLA. The discussion in the comments covers topics such as the use of modern Fortran, the availability of alternative optimization libraries like Mystic, and the challenges of optimizing performance using different languages and computing systems. The comments also touch on the importance of documentation and resources for learning modern Fortran.

### Chosen-prefix collision for SHA-1 (2019)

#### [Submission URL](https://sha-mbles.github.io/) | 22 points | by [aburan28](https://news.ycombinator.com/user?id=aburan28) | [8 comments](https://news.ycombinator.com/item?id=35962667)

An international team of researchers has been able to create a "practical" SHA-1 collision, which is significant because this is the first time researchers have attacked the SHA-1 hashing algorithm using a “chosen-prefix collision” as opposed to mathematical calculations. This means the team was able to create two PDF files with different messages that were able to create the same SHA-1 hash, which could then lead to key misuse. Criminals could use these keys to use these algorithms to impersonate other people or misdirect traffic. The team carried out their research with a relatively small budget by renting mining graphics processing units for $40 a day from the Russian mining company CleverMining.

The submission discusses the recent announcement by an international team of researchers who have managed to create a practical SHA-1 collision using a "chosen-prefix collision" attack, which could lead to key misuse by criminals. The discussion in the comments revolves around the vulnerabilities of different hashing algorithms and their resistance to length extension attacks. Some users recommend using SHA-3 instead of SHA-2 due to its better resistance to length extension attacks. The submission also includes a link to the research paper and a discussion of its findings. Finally, one user talks about the potential implications of the SHA-1 collision discovery on encrypted blobs and transactions.

### EU Artificial Intelligence Act

#### [Submission URL](https://artificialintelligenceact.eu/) | 140 points | by [Trouble_007](https://news.ycombinator.com/user?id=Trouble_007) | [118 comments](https://news.ycombinator.com/item?id=35966543)

The EU has proposed a new law on artificial intelligence, the AI Act, which assigns AI applications to three risk categories. Applications that create an unacceptable risk, like government-managed social scoring systems used in China, are banned, while high-risk applications, such as CV-scanning tools, are subject to legal requirements. Applications not explicitly banned or listed as high-risk are largely unregulated. The AI Act could become a global standard like the GDPR, affecting AI's positive or negative impact on daily life worldwide. Brazil's Congress recently passed a similar bill, though with some limitations. The AI Act is not without loopholes or inflexibility, so further improvements are necessary.

The EU has proposed a new law on artificial intelligence, called the AI Act, which categorizes AI applications into unacceptable risk, high risk, and low risk categories. The act has been criticized for not being clear and for potentially hindering innovation. The discussion in the comments focuses on the difficulties of determining risk categories and the potential for discrimination in high-risk applications based on protected attributes such as skin color. Additionally, there are concerns about the effectiveness of the AI Act in regulating AI, and the need for further improvements. The discussion also touches on the GDPR and its limitations in creating a level playing field for tech companies, particularly for small startups.

### How Small Can Language Models Be and Still Speak Coherent English?

#### [Submission URL](https://arxiv.org/abs/2305.07759) | 37 points | by [tosh](https://news.ycombinator.com/user?id=tosh) | [10 comments](https://news.ycombinator.com/item?id=35958133)

Researchers Ronen Eldan and Yuanzhi Li have developed a new synthetic dataset called TinyStories to evaluate language models (LMs) with fewer parameters than those typically used in natural language processing. TinyStories consists of short stories with words typically understood by 3- or 4-year-olds, generated by GPT-3.5 and GPT-4, and the LMs trained on it have only one transformer block rather than many layers of global attention. Despite their small size, the LMs produce coherent and fluent text that demonstrates reasoning capabilities. A new evaluation paradigm grades content generated by these models using GPT-4 to provide a multidimensional score.

The discussion on the submission mainly revolved around the effectiveness of Tiny Language Models (LMs) with fewer parameters. Some users found the idea of using a synthetic dataset with simple language interesting, while others questioned the ability of these models to generate complex material. One user expressed frustration about the limitations of text-to-speech models that do not recognize different languages, while another commented on the importance of machine learning training. The conversation then drifted toward other machine learning applications. Finally, one user shared a link to a resource related to the topic.

### Colossus: The Forbin Project (1970) [video]

#### [Submission URL](https://archive.org/details/colossus-the-forbin-project-1970) | 129 points | by [Animats](https://news.ycombinator.com/user?id=Animats) | [78 comments](https://news.ycombinator.com/item?id=35957944)

The Internet Archive has made available for free the 1970 movie "Colossus: The Forbin Project," which explores the consequences of a sentient computer in the context of the Cold War. Viewers have praised the film's relevance to modern-day conversations about artificial intelligence, as well as its prescience.

The Internet Archive has made the 1970 movie "Colossus: The Forbin Project" available for free. The film explores the consequences of a sentient computer in the context of the Cold War, and viewers have praised its relevance to modern-day conversations about artificial intelligence. The comments on Hacker News include discussions about the accuracy and relevance of the movie, as well as debates about the Turing Test and AI's potential to take over the world. Some commenters praise the movie for its portrayal of the risks associated with AI while others suggest that it presents an overly negative view. Other sci-fi classics, such as Demon Seed, The Andromeda Strain, and Soylent Green, are also mentioned.

### OpenAI CEO wants A.I. licensed for company benefit

#### [Submission URL](https://finance.yahoo.com/news/openai-ceo-sam-altman-tells-200241500.html) | 26 points | by [RafelMri](https://news.ycombinator.com/user?id=RafelMri) | [6 comments](https://news.ycombinator.com/item?id=35969352)

Today's top story is about OpenAI CEO Sam Altman testifying before a subcommittee of the Senate Judiciary Committee, which held hearings on the possible regulation of AI. Altman called for appropriate safety requirements and a licensing and registration regime for AI systems beyond a certain capability. However, Altman also urged a flexible governance framework to adapt to new technological developments while balancing incentivizing safety and ensuring people can access technology's benefits. Senator Marsha Blackburn was concerned about generative AI's copyright implications and impact on the Nashville-based country music scene. Overall, senators seemed aware of some of AI's resulting issues, including misinformation, election interference, fraud, bias, defamation, exploitative data gathering practices, data privacy violations, emerging evidence of wage depression in some fields, and environmental impacts.

The discussion on this submission includes a mix of agreement, disagreement, and humor. One user argues that OpenAI's policy on AI safety risks should play a large role in their product releases, to prevent harm to consumers or to the companies themselves. Another suggests making it mandatory to publish results from text-based generators to ensure transparency and avoid any associated problems. There is some humor mixed in as well, with one user joking about the "country AI" mention and others making jokes about the use of language in comments. Overall, there is a relatively light-hearted tone to the discussion.

### LMQL: A query language for programming (large) language models

#### [Submission URL](https://github.com/eth-sri/lmql) | 106 points | by [behnamoh](https://news.ycombinator.com/user?id=behnamoh) | [12 comments](https://news.ycombinator.com/item?id=35956484)

LMQL, a query language for large language models, combines natural language prompting with the expressiveness of Python and allows users to express advanced, multi-part queries. With only a few lines of code, LMQL can facilitate the interaction between users and large language models and optimize the queries for efficient execution within the language decoding loop. LMQL can be installed with a Python >= 3.10 environment and allows for GPU support for local models. The LMQL playground IDE includes a showcase of many exemplary LMQL programs, which can be executed using the lmql run command, or launched in a browser-based environment with lmql playground.

LMQL, a query language for large language models, was submitted to Hacker News. The language combines natural language prompting with the expressiveness of Python, and allows for advanced, multi-part queries. It can facilitate the interaction between users and large language models and optimize queries for efficient execution within the language decoding loop. LMQL can be installed with a Python >= 3.10 environment, and includes GPU support for local models. The LMQL playground IDE showcases exemplary programs, which can be executed using the "lmql run" command or launched in a browser-based environment with "lmql playground". The discussion included descriptions of LMQL's benefits, limitations, and uses. It was noted that LMQL functions like SQL in that it provides primitives for basic search and constrained responses. It was also discussed that LMQL can be used to parse text and create models with a specific topic format. Users expressed interest in the application of LMQL in Nodejs and other languages, and the author indicated that they are actively investigating this. Finally, a user shared a demonstration of LMQL's control prompt.

### Asimov – The Original Prompt Engineer

#### [Submission URL](https://lojones.github.io/2023/04/30/asimov-prompt-engineer.html) | 24 points | by [sohkamyung](https://news.ycombinator.com/user?id=sohkamyung) | [4 comments](https://news.ycombinator.com/item?id=35956594)

Isaac Asimov's visionary Robot Series explored the interactions between humans and robots, laying the groundwork for today's prompt engineering. Prompt engineering involves crafting input prompts for AI systems to generate accurate and relevant outputs. Asimov's Robot universe, set in a future where humans and robots coexist, offered a unique exploration of the ethical and philosophical implications of AI systems. Asimov's Robot stories emphasized the importance of giving precise commands to robots, which can be seen as a precursor to modern prompt engineering. An example of prompt engineering from Asimov's works can be seen in "Mirror Image", where Detective Elijah Baley interrogates a robot to solve a crime.

The first comment includes a reference to a scene from the movie 2001: A Space Odyssey where a computer named HAL seems to be malfunctioning and repeating the phrase "I'm sorry, Dave, I'm afraid I can't do that". The second comment is discussing the concept of prompt engineering and how it relates to the design of user interfaces. It includes examples of how prompts are used in various software tools. The third comment refers to the programming concepts discussed in Isaac Asimov's Robot series and the movie Interstellar, particularly the character TARS who was designed with a 90% honesty function. A fourth comment discusses a recent development in natural language processing and the use of grammar validation in chatbots.

### Show HN: Python library to add voiceovers to Manim videos programmatically

#### [Submission URL](https://osolmaz.github.io/blog/code-driven-videos) | 20 points | by [hosolmaz](https://news.ycombinator.com/user?id=hosolmaz) | [6 comments](https://news.ycombinator.com/item?id=35961318)

A new plugin called Manim Voiceover has been developed for the Python math animation library, Manim, that allows voiceovers to be added directly in Python, automating the video editing process. The plugin lets developers create educational videos entirely in Python, with AI-generated voiceovers or actual recordings added seamlessly to video animations. Manim Voiceover greatly increases video production speed and, as everything can be done in Python, allows for a fully collaborative and open-source way of working. The API is comprehensive and makes voiceover integration easy with a variety of services.

The discussion on this Hacker News submission revolves around the newly developed Manim Voiceover, a plugin for the Python math animation library "Manim" that allows voiceovers to be added directly in Python, automating the video editing process. One user asks for advice on integrating AWS Polly speech generation for their API, while another suggests a method of aligning words with specific animations. The original poster clarifies that the project began roughly a year ago and provides a link to the project's documentation. One user mentions that the plugin looks great and wants to try it out, while another describes it as a promising concept for data-driven video editing.

