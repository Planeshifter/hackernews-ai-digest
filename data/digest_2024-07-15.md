## AI Submissions for Mon Jul 15 2024 {{ 'date': '2024-07-15T17:10:30.311Z' }}

### Run CUDA, unmodified, on AMD GPUs

#### [Submission URL](https://docs.scale-lang.com/) | 1070 points | by [Straw](https://news.ycombinator.com/user?id=Straw) | [315 comments](https://news.ycombinator.com/item?id=40970560)

Today on Hacker News, a new GPGPU programming toolkit called SCALE by Spectral Compute is making waves. SCALE allows CUDA applications to be natively compiled for AMD GPUs without requiring any modifications to the CUDA program or its build system. This innovative toolkit is designed to be fully compatible with NVIDIA CUDA, making it easy for users to leverage their existing codebase for AMD GPUs.

Some key features of SCALE include accepting CUDA programs as-is, no need for porting to another language, and impersonating an installation of the NVIDIA CUDA Toolkit to ensure existing build tools and scripts work seamlessly. The toolkit has been tested with various open-source CUDA projects like NVIDIA Thrust, Blender Cycles, and xgboost, showcasing its capabilities.

In terms of GPU support, SCALE currently covers AMD gfx1030 and gfx1100, with plans to expand support to other AMD GPU architectures in the future. The toolkit comprises components like an nvcc-compatible compiler, implementations of the CUDA runtime and driver APIs for AMD GPUs, and open-source wrapper libraries for handling CUDA-X APIs.

SCALE's goal is to eliminate the need for maintaining multiple codebases or sacrificing performance to support different GPU vendors. It offers opt-in language extensions to enhance the efficiency of GPU code, providing users with a seamless transition from nvcc to SCALE.

For those interested in learning more or trying out SCALE, there are resources available such as tutorials, examples, and ways to get in touch with the team through Discord or email at [email protected] This toolkit is continuously evolving, with plans to incorporate more features and support for additional GPU architectures in the future.

The discussion on Hacker News regarding the new GPGPU programming toolkit SCALE by Spectral Compute delves into various technical aspects and opinions. Some users discuss the challenges of supporting AMD GPUs in contrast to Nvidia due to legal agreements and technical difficulties, while others point out the benefits and complexities of using the toolkit. There is a debate on the efficiency of porting solutions like HIP versus creating new solutions like HIP. Additionally, the conversation touches on the high costs associated with working with CUDA, potential alternatives like AWS instances, and the advantages and disadvantages of investing in CUDA knowledge. Moreover, there are humorous references to the value of gold and light-hearted comments about studying for CUDA and Ancient Rome's use of gold to measure power. Ultimately, the discussion emphasizes the technical intricacies, challenges, and practical considerations surrounding GPGPU programming with SCALE and CUDA.

### Shapeshift: Semantically map JSON objects using key-level vector embeddings

#### [Submission URL](https://github.com/rectanglehq/Shapeshift) | 94 points | by [marvinkennis](https://news.ycombinator.com/user?id=marvinkennis) | [23 comments](https://news.ycombinator.com/item?id=40972130)

The top story on Hacker News today is about a fascinating project called Shapeshift by rectanglehq. Shapeshift is a TypeScript library that allows you to transform JSON objects using vector embeddings. It uses semantic similarity to map keys between objects, enabling intelligent and flexible object transformation, even for nested structures.

Some key features of Shapeshift include:
- Mapping objects with different structures based on the semantic similarity of keys.
- Support for nested objects.
- Multiple embedding providers like Cohere, OpenAI, and Voyage.
- Customizable embedding models and similarity thresholds.

To use Shapeshift, you can install it via npm and then provide an API key from your preferred embedding provider. The library provides a simple API for mapping source objects to target objects based on semantic matches between keys.

Shapeshift can handle nested objects by flattening them into a single-level structure, performing semantic matching, and then reconstructing the nested structure in the output.

If you're interested in contributing to the project, you can submit a pull request as contributions are welcome. Shapeshift is licensed under the MIT License.

Stay tuned for more exciting updates in the world of tech and innovation!

The discussion on the Hacker News post about Shapeshift by rectanglehq covers various aspects and opinions on the project. Here are some highlights:

1. Users discussed the technical aspects of the project, including implementing mappings, suggestions for design changes, and potential use cases such as transforming unstructured personal data instances into structured data for analysis.

2. There was a mention of concerns regarding data transformation and modeling complexities, particularly comparing embeddings and potential issues with missing keys.

3. One user shared a quick version of a similar project using Substrate for JSON schema generation and handling advanced scenarios.

4. Suggestions were made for further improvements, such as implementing caching and fuzzy key mappings for better handling of real-world data challenges.

5. Some users discussed the challenges and practical applications of using embeddings for key mapping and data transformation tasks.

6. Other users mentioned the potential for utilizing Shapeshift in question-answering prompts, job generation, and non-negligible data matching aspects using embeddings.

Overall, the discussion provided insights into the technical capabilities, challenges, and possibilities of using Shapeshift and similar projects for data transformation and manipulation tasks.

### Guide to Machine Learning with Geometric, Topological, and Algebraic Structures

#### [Submission URL](https://www.arxiv.org/abs/2407.09468) | 158 points | by [johmathe](https://news.ycombinator.com/user?id=johmathe) | [26 comments](https://news.ycombinator.com/item?id=40969192)

The paper "Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures" delves into the realm of modern machine learning beyond traditional Euclidean spaces. Authored by Sophia Sanborn and a team of eight experts, the paper explores the challenges and opportunities in extracting knowledge from non-Euclidean data with intricate geometric, topological, and algebraic structures. By providing a graphical taxonomy and proposing a unified framework, the authors aim to enhance our understanding of unconventional data types and pave the way for future developments in this evolving field.

1. **Pseudomanifold**: A user shared several works and references related to topology in machine learning, discussing connectivity and continuity concepts. Another user thanked them for the insights.
2. **dpfln**: A discussion ensued about the references in the papers and how they could be more approachable to beginners. A user criticized the mathematical content and lack of clear conclusions in the papers. Another user emphasized the importance of sharing references.
3. **tssd**: The common theme in the paper appears to be folding properties and identifying important properties in geometric, algebraic, and topological structures. The discussion touched on embedding different types of data into networks and the relevance to machine learning.
4. **mjhy**: The user expressed conviction in the potential of the paper's approaches in addressing resource-intensive challenges in machine learning and the mismatch between Euclidean spaces and higher-dimensional structures. This sparked a debate about the use of tools from algebra, topology, geometry, and physics in machine learning.
5. **fnnygrff**: A user humorously commented on the intersection of geometric, topological, and algebraic structures in data analysis. The discussion expanded to the significance of these topics in academia and industry, particularly in design and chemical engineering.  
6. **llm_trw**: A user shared success with hyperbolic embeddings in machine learning models, prompting further discussion on the practical advantages and experiences with such approaches.
7. **fjrk**: The user discussed the explicit definition of mathematical objects in machine learning and the potential insights gained from different perspectives.
8. **OutOfHere**: A user noted the limitations of GPU hardware in dealing with non-Euclidean matrix operations. 
9. **mistrial9**: Discussion revolved around the impact of solving previously intractable problems with mathematical data computation, leading to commercial success and substantial changes in problem-solving approaches.
10. **fnnygrff**: Further discussion ensued about the implications of solving previously intractable problems with new methods and the uncertainty of the practical impact in the real world.

Overall, the discussion covered a variety of viewpoints on the mathematical, practical, and industrial implications of the paper's exploration into non-Euclidean machine learning structures.

### Picking up the fight against deepfakes, voice cloning and generative AI

#### [Submission URL](https://www.garandor.com/) | 18 points | by [matyask](https://news.ycombinator.com/user?id=matyask) | [10 comments](https://news.ycombinator.com/item?id=40970532)

Garandor recently launched its Early Access phase, welcoming early adopters to explore its cutting-edge invisible watermarking technology aimed at disrupting deepfakes, voice cloning, and unauthorized training to secure digital identities and copyrights. Users can easily watermark images and audio files to protect their creations without compromising quality. The roadmap outlines upcoming features such as quality preservation, content protection, authorship verification, and robust protection mechanisms.

The platform offers tools for image watermarking with imperceptible identifiers and audio watermarking with inaudible markers. Video watermarking, adversarial watermarking to counter generative AI misuse, Garandor Drive for secure cloud storage, and API access for workflow integration are upcoming offerings. By leveraging Garandor's technology, artists, creators, businesses, and developers can safeguard their digital assets in the ever-evolving online landscape.

The discussion on Hacker News surrounding Garandor's launch of its Early Access phase revolves around the technical understanding of the watermarking technology, skepticism about the company's claims and the need for validation, concerns about the possible misuse of generative AI, and the importance of watermarking in securing digital identities and copyrights.

- User mrbng is trying to understand the resistance of watermarking methods, mentioning simple methods like scaling, compression, and convolutional filters.
- User trod123 finds the company's technology interesting but raises concerns about the lack of information to validate their claims and the potential for false positives leading to miscarriages of justice.
- User mtdt points out that watermarking aggressively re-encodes images, potentially affecting marketability and the resolution of images.
- User gmrc discusses the fundamental threat of misinformation, deepfakes, and the need to protect against major political parties and the scarcity of resources.

Overall, the discussion highlights a mix of technical curiosity, skepticism about the company's claims, concerns about the potential misuse of technology, and the importance of robust protection mechanisms in the digital landscape.

### Lagrange: LAser GRavitational-wave ANtenna at GEo-lunar Lagrange points (2011)

#### [Submission URL](https://arxiv.org/abs/1111.5264) | 54 points | by [Bluestein](https://news.ycombinator.com/user?id=Bluestein) | [17 comments](https://news.ycombinator.com/item?id=40965835)

The paper titled "LAGRANGE: LAser GRavitational-wave ANtenna at GEo-lunar Lagrange points" introduces a new space gravitational wave observatory design that aims to maintain the essence of important scientific work at a reduced cost and technical risk. The observatory consists of three spacecraft positioned at the Earth-Moon L3, L4, and L5 Lagrange points, enabling continuous communication with Earth through fixed antennas. The innovative design includes a Modular Gravitational Reference Sensor with a drag-free operation mode, Interferometric Measurement System, telescopes with advanced optical technology, and scalable modular subsystems. These advancements make the system interchangeable with other gravitational science missions, with plans to qualify critical technologies on small satellite flights starting in 2013.

1. **rglrfry** discusses the practicality of today's precious materials test mass with a cost of $17,736,577 versus $53,209,731, highlighting the importance of materials surface shape balance, density, and magnetic susceptibility. They mention that the estimated cost range for the LAGRANGE project is between $600M to $1B and note similarities with the LISA project. They also talk about the differences in properties between platinum and gold-platinum alloys.

2. **SideburnsOfDoom** mentions the high costs associated with space launches.
3. **ntcrft** shares a link discussing sensitivity frequencies.
4. **Loughla** references a test launch planned for 2013 and highlights the LISA project's abstract.
5. **_joel** and **dylan604** discuss project deadlines and delivery speed in the context of space innovation and advancements, with a focus on launch years like 2035 for astronomical projects.
6. **Bluestein** engages in a conversation with **_joel** about the challenges and potential of bringing AI into space projects for generation of goods and services.
7. **ChrisArchitect** and **jssrdl** mention the year 2011.
8. **__lbracket__** reveals that they are bit-encoding.
