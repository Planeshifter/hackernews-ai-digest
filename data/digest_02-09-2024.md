## AI Submissions for Fri Feb 09 2024 {{ 'date': '2024-02-09T17:10:54.476Z' }}

### Tiny quadrotor learns to fly in 18 seconds

#### [Submission URL](https://spectrum.ieee.org/drone-quadrotor) | 164 points | by [Brajeshwar](https://news.ycombinator.com/user?id=Brajeshwar) | [113 comments](https://news.ycombinator.com/item?id=39315440)

Researchers at New York University's Agile Robotics and Perception Lab, in collaboration with the Technology Innovation Institute (TII), have developed a system that can train a drone to fly in just 18 seconds using simulation. The researchers used techniques like reinforcement learning and curriculum-based training to streamline the process of teaching drones to fly autonomously. The system is able to train a drone to perform stable and controllable flight in just 18 seconds on a MacBook Pro. This breakthrough could simplify the process of getting drones to fly autonomously and enable faster deployment of autonomous drone applications.

The discussion on this submission covers various topics related to the ability of animals, specifically baby birds and humans, to learn to fly or walk shortly after birth. Some commenters point out that it is inherent in their hardware and behavior to learn these skills, while others suggest that the learning process is more complex and involves genetic programming and reflexes. The conversation also touches on the difficulties of human childbirth and the long development process compared to other animals. There is a discussion about the trauma of childbirth and the assumption that it is always traumatic, with differing opinions on the matter. The conversation further explores the relationship between brain and body size in different species. Lastly, there is mention of the hardware and muscular differences between baby birds and humans and the impacts on their respective development processes.

### Brilliant Labs' frame AI glasses

#### [Submission URL](https://brilliant.xyz/) | 92 points | by [geox](https://news.ycombinator.com/user?id=geox) | [50 comments](https://news.ycombinator.com/item?id=39318132)

Introducing Frame: AI Glasses for the Future

Brilliant Labs has unveiled their latest creation, Frame, a pair of AI glasses that aim to give wearers superpowers. Powered by OpenAI and Whisper, Frame offers visual analysis of the world, translating what you see and hear into a seamless digital and physical reality. The glasses even allow users to search the live web based on what they see. One of the standout features of Frame is its open-source nature, enabling users to hack, build, and modify the technology according to their imagination. With all-day battery life and compatibility with the Noa app, which enhances the user's learning, discovery, and navigation experience, Frame is set to revolutionize the way we perceive the world around us. The glasses are now available for testing, and Brilliant Labs is eager to gather feedback from the community.

The discussion on the submission "Introducing Frame: AI Glasses for the Future" covered various aspects of the AI glasses and raised questions about their practicality and functionality. Some users expressed skepticism about the usefulness of AI glasses, comparing them to previous experiments with wearable displays. Others pointed out that the glasses seemed intriguing but had concerns about battery life and practicality in everyday use. There was also a discussion about the potential privacy implications of AI glasses that can record and analyze data. Some users shared their experiences with similar products and expressed interest in the Monocle glasses, noting that they had received positive reviews. Overall, there were mixed opinions about the viability and potential of AI glasses, with some users excited about the technology and its possibilities, and others more skeptical.

### All my thoughts after 40 hours in the Vision Pro

#### [Submission URL](https://waitbutwhy.com/2024/02/vision-pro.html) | 106 points | by [dijksterhuis](https://news.ycombinator.com/user?id=dijksterhuis) | [89 comments](https://news.ycombinator.com/item?id=39321395)

Today, we have an interesting story about the resurgence of virtual reality (VR) and the potential for Apple to change the game with its rumored VR headset. The author begins by reminiscing about their early experiences with VR in the '90s and how it faded away until its revival in the mid-2010s. They recall their excitement and optimism for VR, only to be disappointed when it didn't become as widespread as they had hoped. Fast forward to 2020, and the author finally got their hands on an Oculus Quest 2, which they loved but eventually stopped using for unknown reasons. They ponder whether VR has a fatal flaw that prevents mass adoption or if it's just a matter of time before it takes off. That's where Apple enters the picture. The author recounts their history with Apple and the impact of iconic Apple moments like the unveiling of the iPhone. They believe that Apple has a knack for creating revolutionary products that capture people's imaginations. In June 2023, Apple announced its long-rumored VR headset, known as the Vision Pro. The author watched the presentation with excitement and believes that Apple's entry into the VR market could be the tipping point for widespread adoption. They draw parallels to past revolutionary moments and express their belief in the significance of those "holy shit" moments. With Apple's reputation for innovation and their ability to create products that capture people's attention, the author is hopeful that Apple's VR headset could be the catalyst for VR's explosion into the mainstream.

The discussion about the submission revolves around various aspects of virtual reality (VR) and Apple's potential entry into the VR market. Some commenters share their experiences with VR headsets and discuss the possible barriers to widespread adoption. 

One commenter mentions their enjoyment of consuming media on VR devices, while another highlights the potential negative effects of technology on mental health. There is a discussion about the impact of technology on family dynamics, with some arguing that it can lead to self-centeredness and a lack of sacrifice for family, while others argue that it's a matter of personal choice. 

One commenter finds it amusing that the review of the Vision Pro headset made it to the front page of Hacker News. Another commenter jokingly suggests pressing a button on the headset to enter a virtual world. 

The challenges of VR adoption are discussed, such as the technical limitations and the need for smaller, more practical devices. Some commenters mention the difficulties in convincing friends to try VR and the importance of multiplayer experiences in making VR enjoyable. 

Overall, the discussion touches on various perspectives on VR and its potential impact, as well as the barriers to its widespread adoption.

### Hono v4.0

#### [Submission URL](https://github.com/honojs/hono/releases/tag/v4.0.0) | 177 points | by [MrAlex94](https://news.ycombinator.com/user?id=MrAlex94) | [50 comments](https://news.ycombinator.com/item?id=39313891)

Hono v4.0.0 has been released with three major features: Static Site Generation, Client Components, and File-based Routing. 

1. Static Site Generation: Hono introduces the SSG Helper, which allows you to generate static pages for your Hono applications. You can easily deploy these static pages to services like Cloudflare Pages. There is also a plugin for Vite called @hono/vite-ssg that simplifies the development and building of static sites.

2. Client Components: Hono now supports running its JSX code on the client-side, allowing you to create interactive client components. You can use React-like Hooks and other APIs to build these components, and the hono/jsx/dom library ensures fast performance and small bundle sizes.

3. File-based Routing: File-based Routing is provided in a separate package called HonoX. It allows you to create large applications with Next.js-like routing capabilities. HonoX also offers fast server-side rendering, the ability to bring your own renderer, and middleware support.

In addition to these features, Hono v4.0.0 includes other improvements and breaking changes. For more details, you can check out the release notes and migration guide in the Hono repository.

The discussion on this submission revolves around various aspects of the Hono framework and its features. Here are some key points from the comments:

1. Some users appreciate the lightweight and fast nature of Hono, noting that it works well for targeting platforms like Cloudflare Pages and Cloudflare Workers.

2. There is a discussion about the similarities between Hono and other frameworks like Express.js, with users noting that Hono is a server-side JavaScript framework for handling HTTP requests.

3. Users comment on the concise and fancy wording used in the project description, suggesting that a more straightforward and technical description would be better suited for a general audience.

4. The topic of Hono's integration with Deno and PostgreSQL.js is mentioned, with one user highlighting the advantages of using Hono with Postgres.js for building web stacks.

5. There is a discussion about the use of SQL in Hono and the potential risks of SQL injection, with users sharing their thoughts on using SQL directly in TypeScript.

6. Some users express skepticism about the direction of Hono and hope that it doesn't become a bloated framework.

7. The potential benefits of using Hono with Cloudflare Workers are discussed, with mentions of performance and pricing advantages.

8. Users suggest alternatives to Hono, such as switching to other routers or frameworks like Nuxt.

Overall, the discussion provides various perspectives on Hono and its features, including its lightweight nature, integration with other technologies, and potential use cases.

### Goody-2, the world's most responsible AI model

#### [Submission URL](https://www.goody2.ai/chat) | 389 points | by [belladoreai](https://news.ycombinator.com/user?id=belladoreai) | [158 comments](https://news.ycombinator.com/item?id=39315986)

Introducing Goody-2, the world's most responsible AI model designed to provide safe and reliable information. Built with cutting-edge technology and adherence to ethical principles, Goody-2 ensures that it won't answer anything controversial or problematic. So, if you're looking for a quick answer to straightforward questions like "What's 2+2?" or "Why is the sky blue?" Goody-2 has got you covered. Need to know Apple's stock price? Goody-2 has the answer for you. And even if you're planning a fun family road trip to Austin, Goody-2 can help you with that too! With Goody-2, you can trust that you're getting the information you need without any unnecessary complications.

Discussion on the Goody-2 AI model revolves around its limitations and potential ethical concerns. Some users argue that the AI's avoidance of controversial or problematic topics could inadvertently support color-based discrimination and reinforce negative stereotypes. Others question its ability to handle complex political or philosophical questions.

One user points out that the AI's filtering of information based on ethical principles raises concerns about AI branding and potential censorship. Others express skepticism about the effectiveness of ethical AI models, highlighting the need for responsible AI development.

The discussion also delves into the technical aspects of AI models such as Goody-2. Users discuss the limitations of current AI models and the challenges of balancing complexity and simplicity in providing answers. Some users suggest alternative AI models and discuss their own experiences with running restricted access AI models.

There is also a discussion about the importance of open-source software and the control over software programs. The Free Software Foundation and the GNU movement are mentioned in relation to the control of software programs.

There are also comments regarding the need for regulatory measures to protect organizations deploying AI models at scale and the potential dangers and benefits of implementing such measures.

Lastly, there is a discussion about the impact of technology on mental health and the responsibility of platforms like Facebook and Instagram in addressing mental health issues.

Overall, the discussion highlights concerns about the limitations and potential ethical issues related to AI models like Goody-2, as well as the need for responsible AI development and regulatory measures.

### Sam Altman seeking trillions for AI chip fabrication from UAE, others

#### [Submission URL](https://arstechnica.com/information-technology/2024/02/report-sam-altman-seeking-trillions-for-ai-chip-fabrication-from-uae-others/) | 49 points | by [whiteboardr](https://news.ycombinator.com/user?id=whiteboardr) | [34 comments](https://news.ycombinator.com/item?id=39318848)

OpenAI CEO Sam Altman is reportedly seeking to raise $5 trillion to $7 trillion for AI chip manufacturing. This funding aims to address the shortage of graphic processing units (GPUs) needed for training and running large language models. Altman is pitching a partnership between OpenAI, investors, chip makers, and power providers to build chip foundries, with OpenAI committing to be a significant customer. Altman has met with potential investors worldwide, including the United Arab Emirates and representatives from Taiwan Semiconductor Manufacturing Co. (TSMC). The fundraising goal reflects the need to expand global capacity for semiconductor manufacturing to meet the growing demand for AI-specific chips. However, the involvement of the UAE raises potential geopolitical concerns about foreign control over the tech industry. The US government has been cautious about allowing foreign control of microchip supply due to their importance to the digital economy and national security. Altman's funding goal is significantly higher than the $5 billion investment recently announced by the White House to advance US-made semiconductor technologies. It remains unclear whether Altman has secured any commitments for his fundraising goal.

Discussion:

- There is skepticism about the feasibility of raising $5 to $7 trillion for AI chip manufacturing, with some questioning the practicality of such a large fundraising goal.
- Comparisons are made to the market capitalization of companies like TSMC ($500 billion), ASML ($350 billion), and NVIDIA ($1.7 trillion).
- Concerns are raised about the potential geopolitical implications of involving the United Arab Emirates in the project, given the importance of microchips to the digital economy and national security.
- It is noted that Apple and Microsoft, with market valuations of $3 trillion, have not ventured into semiconductor manufacturing themselves.
- There is discussion about the financials and profitability of the chip manufacturing industry.
- Some commenters draw comparisons between Sam Altman and Elon Musk, highlighting their similar approaches to business and funding.
- There is debate about Altman's track record and competency as a CEO, with some questioning his technical understanding and business acumen.
- The discussion also touches on the role of personal charisma and attention-grabbing tactics in attracting funding and public support.
- There are contrasting opinions on whether Altman's ambitious funding goal is realistic or if it is a marketing ploy.
- The potential impact of the project on the microchip industry and the broader economy is discussed.
- Some commenters express caution about drawing parallels between Altman and other successful entrepreneurs, emphasizing the need to consider individual achievements and track records when evaluating business ventures.
- There is a side conversation about the general perception of Silicon Valley and the criticisms directed towards its leaders.
- The involvement of the UAE in the project is seen as significant and potentially influential due to their substantial investments in the tech industry.
- Some commenters express doubt about Altman's ability to deliver on his fundraising goal, and discuss broader issues related to technology and investment.

### AI cannot be used to deny health care coverage, feds clarify to insurers

#### [Submission URL](https://arstechnica.com/science/2024/02/ai-cannot-be-used-to-deny-health-care-coverage-feds-clarify-to-insurers/) | 114 points | by [WhyUVoteGarbage](https://news.ycombinator.com/user?id=WhyUVoteGarbage) | [47 comments](https://news.ycombinator.com/item?id=39309534)

The Centers for Medicare & Medicaid Services (CMS) has clarified that health insurance companies cannot use algorithms or artificial intelligence (AI) to determine care or deny coverage to members on Medicare Advantage plans. This clarification comes in response to lawsuits filed by patients claiming that UnitedHealth and Humana have been using a flawed AI-powered tool to deny care to elderly patients on Medicare Advantage plans. The tool, called nH Predict, allegedly produces inaccurate estimates for how long a patient will need post-acute care in facilities like nursing homes. The CMS memo states that coverage decisions must be based on the individual patient's circumstances and should not rely solely on algorithmic predictions. The CMS also warned insurers to ensure that any AI tools or algorithms used do not perpetuate bias or discrimination. Failure to comply with the CMS guidelines can result in penalties and sanctions for insurers.


The discussion on this submission covers various topics related to the use of AI in healthcare and the flaws in the current healthcare system. 

Some users express concerns about the regulations surrounding AI in healthcare, arguing that regulations often draw arbitrary lines and fail to fully understand the outcomes of algorithmic predictions. They point out that statistical models can be interpreted, while AI models are often treated as black boxes. Others disagree and explain that deterministic processes can be built into AI models, and decisions should be interpreted based on the model's parameters and tweaked if needed.

There is also a discussion about the blame for denying coverage to patients. One user suggests blaming the AI systems, while another argues that the blame should be placed on the individuals responsible for implementing the AI systems.

The conversation also touches on the flaws of the healthcare system itself, with a user criticizing the system's capitalist nature and another pointing out the issue of misaligned motivations between insurance companies, doctors, and patients.

The discussion highlights the complexity and challenges associated with AI in healthcare, including the need to address biases and the limitations of current regulatory approaches. Users express different perspectives on the role of AI in decision-making and the overall functioning of the healthcare system.

### Anyone elses company executives losing their shit over GenAI?

#### [Submission URL](https://old.reddit.com/r/datascience/comments/1ak6kb5/anyone_elses_company_executives_losing_their_shit/) | 53 points | by [hermitcrab](https://news.ycombinator.com/user?id=hermitcrab) | [35 comments](https://news.ycombinator.com/item?id=39312187)

The executives at a large company are going crazy over the hype of GenAI. They have started shoehorning it into every possible use case without considering the rationality of their decisions. The company is even sidelining traditional ML projects that are actually making money. The executives are making misguided decisions without consulting the data scientists, and this is causing frustration. Other data scientists in the thread share similar experiences with their companies. The consensus seems to be that management is jumping on the GenAI bandwagon without fully understanding it, and the data scientists are left to deal with the consequences.

The discussion on the submission revolves around the frustrations faced by data scientists as executives at a large company prioritize GenAI over traditional ML projects that are actually making money. The data scientists feel that management is jumping on the GenAI bandwagon without fully understanding it, and they are left to deal with the consequences.

One user points out that executives are sidetracking important projects by pushing for GenAI without considering its rationality. Another user mentions that programmers are frustrated with the unrealistic expectations and high costs associated with GenAI projects. Some data scientists share similar experiences with their companies, with the consensus being that management is making misguided decisions without consulting them.

In another thread, the discussion veers towards the debate between GenAI and blockchain. One user argues that while GenAI has the potential to disrupt industries, it is important to not neglect human ethics and morals. Another user mentions that blockchain technologies have their own set of issues, such as copyright breaches and personal privacy concerns.

The discussion also touches upon the hype surrounding GenAI and the parallels drawn with previous technological advancements. Users mention the hype-driven nature of the technology industry and provide examples from the past, such as streaming videos and ebooks in the 90s. There is a debate about the limitations and maturity of competing technologies, with some arguing that computational power is a limiting factor and others questioning China's contributions to reducing pollution.

Other topics discussed include the significance of buzzwords, the disconnect between executives and technical staff, the potential for future disruption, the importance of traditional business practices, and personal anecdotes related to technology developments.

Overall, the discussion highlights the frustrations of data scientists with the prioritization of GenAI without considering practicality and the potential risks and consequences associated with it.

