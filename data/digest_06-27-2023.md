## AI Submissions for Tue Jun 27 2023 {{ 'date': '2023-06-27T17:10:49.205Z' }}

### H100 GPUs Set Standard for Gen AI in Debut MLPerf Benchmark

#### [Submission URL](https://blogs.nvidia.com/blog/2023/06/27/generative-ai-debut-mlperf/) | 140 points | by [Anon84](https://news.ycombinator.com/user?id=Anon84) | [70 comments](https://news.ycombinator.com/item?id=36499073)

NVIDIA's H100 Tensor Core GPUs have achieved excellent AI performance, particularly in large language models (LLMs) used in generative AI, according to user feedback and industry-standard benchmarks. The GPUs set new records on all eight MLPerf training benchmarks, with outstanding performance on a new MLPerf test for generative AI. For example, on a cluster of 3,584 H100 GPUs co-developed by startup Inflection AI and cloud service provider CoreWeave, the system completed a GPT-3-based training benchmark in under 11 minutes. These results highlight the H100 GPUs' top performance in a variety of AI workloads, such as recommenders, computer vision, medical imaging, and speech recognition. The GPUs also demonstrated scalability and achieved near-linear performance scaling on demanding LLM tests when scaled from hundreds to thousands of GPUs. NVIDIA was the only company to submit results on MLPerf's updated benchmark for recommendation systems. The comprehensive performance of NVIDIA AI across different workloads and its wide ecosystem of partners have made it a reliable choice for customers in both cloud and on-premises environments. As AI performance requirements continue to grow, energy efficiency becomes crucial, and NVIDIA's accelerated computing solutions help optimize performance while reducing rack space and energy consumption. NVIDIA AI Enterprise, the software layer of the NVIDIA AI platform, offers enterprise-grade support and is available for optimized AI workloads.

### Open source AI is critical – Hugging Face CEO before US Congress

#### [Submission URL](https://venturebeat.com/ai/hugging-face-ceo-tells-us-house-open-source-ai-is-extremely-aligned-with-american-interests/) | 315 points | by [thibo_skabgia](https://news.ycombinator.com/user?id=thibo_skabgia) | [70 comments](https://news.ycombinator.com/item?id=36499498)

Hugging Face CEO Clement Delangue testified before the U.S. House Science Committee, stating that open science and open-source AI are crucial for American innovation and align with American values. Delangue emphasized that the US's leading position in AI is thanks to open-source tools like PyTorch, Tensorflow, Keras, transformers, and diffusers. Delangue's testimony follows a letter from senators questioning Mark Zuckerberg about the potential misuse of Meta's open-source LLM LLaMA model. Hugging Face, a New York-based startup valued at $2 billion, has become a hub for open-source code and models and has been a significant voice in the open-source AI community. Delangue highlighted how open science and open source drive the development of AI startups and ensure accountability, mitigate biases, reduce misinformation, and reward stakeholders. Hugging Face promotes ethical openness through institutional policies, technical safeguards, and community incentives.

The discussion on this submission covers various topics related to open-source AI and its implications. Some users highlight the importance of open-source code and models for digital security, while others discuss the differences between open-source and closed-source software. There is also a conversation about the licensing of models and the challenges of sharing and replicating results. Some users express concerns about the computational costs of training AI models and the competitiveness within the industry. Others mention the potential dangers of AI regulation and the need for government involvement. The conversation also touches on the role of Hugging Face in the AI community and its efforts to promote open science. There are mentions of specific projects and technologies, such as Hugging Face's API and the GitHub repository for AI. Overall, the discussion reflects a mix of perspectives on open-source AI, its benefits, challenges, and potential future developments.

### Show HN: Superblocks AI – AI coding assistant for internal apps

#### [Submission URL](https://www.superblocks.com/blog/introducing-superblocks-ai) | 105 points | by [frankgrecojr](https://news.ycombinator.com/user?id=frankgrecojr) | [58 comments](https://news.ycombinator.com/item?id=36495680)

Superblocks AI is revolutionizing the way developers build internal tools. This new tool offers powerful code generation, explanation, performance optimization, and mock data generation capabilities. With Superblocks AI, developers can generate code snippets from a prompt, making it easier to handle unfamiliar languages or write boilerplate queries and business logic. The tool also provides concise explanations for code, simplifying code comprehension and improving development efficiency. Additionally, Superblocks AI allows users to edit code, generate third-party API calls, and generate personalized mock data for UI development. With its diverse features, Superblocks AI aims to help developers write better applications and streamline their development process.

In the comments, there is a discussion about the practicality and limitations of AI-generated code. Some people express concerns about relying too heavily on AI tools and the potential for them to generate incorrect or problematic code. Others discuss the benefits of using AI-generated code for tasks like prototyping or generating boilerplate code. One commenter shares their experience with using AI-generated code for specific tasks like React programming and finding it to be helpful. There is also a conversation about the historical tradition of early adopters experiencing the rough effects of new technologies, such as the impact of AI code generation on the experience level of developers. Additionally, there are discussions about the challenges and potential pitfalls of using AI tools and the importance of understanding the context in which they are used.

### LLM Powered Autonomous Agents

#### [Submission URL](https://lilianweng.github.io/posts/2023-06-23-agent/) | 275 points | by [DanielKehoe](https://news.ycombinator.com/user?id=DanielKehoe) | [165 comments](https://news.ycombinator.com/item?id=36488871)

Today's digest covers an overview of an agent system powered by a large language model (LLM) as its core controller. The system consists of several components that enhance the agent's capabilities. The first component is planning, where the agent breaks down complex tasks into smaller subgoals for efficient handling. The second component is memory, which includes both short-term and long-term memory for contextual learning and information retention. The third component is tool use, where the agent learns to utilize external APIs for additional information and resources. 

The digest also explores the first component in detail, which is planning. It discusses task decomposition techniques such as Chain of Thought (CoT) and Tree of Thoughts, which help the agent break down tasks into manageable steps. It also introduces an alternative approach, LLM+P, which uses an external classical planner for long-horizon planning. 

Self-reflection is another crucial aspect of the agent system, allowing the agent to improve its decision-making and learn from past actions. Two frameworks, ReAct and Reflexion, are mentioned as examples that integrate reasoning and self-reflection capabilities within LLM. Overall, building an autonomous agent system with LLM as its core offers immense potential for solving complex problems and improving task performance through effective planning and self-reflection.

The discussion on the submission includes various topics related to language models (LLMs) and their functionality. One user explains how LLMs generate outputs by selecting tokens based on probabilities. Another user mentions the concept of beam search as a popular method for generating results in language models. It is also noted that LLMs can be non-deterministic and that there are challenges in controlling the output. There is a discussion about the differences between LLMs and other models based on their types. It is mentioned that LLMs can be more progressive compared to other models, with examples of specific models like Google's Progressive Neural Network and Parti. The topic of task decomposition and planning is brought up, with explanations of how LLMs can break down tasks into smaller steps. Different approaches to planning, such as Chain of Thought and Tree of Thoughts, are discussed. The use of external classical planners for long-horizon planning is also mentioned.

There is a conversation about the limitations and challenges of LLMs, including issues with manipulating probabilities, interpretability, and training on large contexts. Some users share resources and research on understanding LLMs and their limitations. The conversation touches on the topic of memory in LLMs, with one user mentioning the implementation of memory in OpenAI's API. Another user relates the concept of memory in LLMs to Quick Resume technology in gaming consoles. Overall, the discussion includes various insights and perspectives on the capabilities and limitations of language models, particularly LLMs, and their application in autonomous agent systems.

