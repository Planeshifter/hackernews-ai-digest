## AI Submissions for Wed May 15 2024 {{ 'date': '2024-05-15T17:11:42.913Z' }}

### New exponent functions that make SiLU and SoftMax 2x faster, at full accuracy

#### [Submission URL](https://github.com/ggerganov/llama.cpp/pull/7154) | 359 points | by [weinzierl](https://news.ycombinator.com/user?id=weinzierl) | [69 comments](https://news.ycombinator.com/item?id=40371612)

In a recent update to the llama.cpp project on GitHub, contributor jart proposed a significant change to rewrite the silu and softmax functions for CPUs. This adjustment replaces the previous lookup table method with vectorized expf() functions, allowing for more accurate calculations. The update ensures support for aarch64 and sse2+ with a minimal rounding error of 2 ulp. Although avx2 and avx512 implementations were considered, they were found to offer little benefit compared to sse2+fma. The community responded positively to this change, with various reactions including thumbs up, hooray, heart, rocket, and eyes emojis. The performance details of the update were also highlighted in the discussion, showing improvements in processing speed and efficiency.

The discussion on the submission involved various topics ranging from programming techniques to hardware optimization. Contributors shared their thoughts on the proposed changes to the llama.cpp project, with some expressing admiration for the performance enhancements and others delving into technical details such as memory bandwidth considerations and SIMD instructions. Additionally, there were discussions on the practical implications of the changes in terms of inference speed and memory usage, as well as comparisons with other frameworks like ONNX, TensorFlow Lite, and Google ML. Some contributors highlighted challenges in making modifications to the llama.cpp project and the complexities of optimizing code for different hardware architectures. Overall, the discussion provided a diverse range of perspectives on the technical aspects and implications of the proposed changes.

### Show HN: Tarsier – Vision utilities for web interaction agents

#### [Submission URL](https://github.com/reworkd/tarsier) | 173 points | by [KhoomeiK](https://news.ycombinator.com/user?id=KhoomeiK) | [61 comments](https://news.ycombinator.com/item?id=40369319)

Today on Hacker News, one of the trending topics is a project called Tarsier by reworkd. Tarsier is a set of vision utilities designed for web interaction agents. These tools help in providing webpage perception for web agents like the minimalistic GPT-4 LangChain web agent. 
Tarsier addresses challenges such as feeding webpages to large language models (LLMs) and mapping LLM responses back to web elements. It visually tags interactable elements on a page with IDs in brackets, allowing for better interaction. Moreover, Tarsier offers an OCR algorithm to convert page screenshots into a structured string for LLMs to understand even without vision, improving performance on web interaction tasks.
The project includes detailed instructions on installation, usage, local development setup, testing, and future roadmap. Tarsier supports various OCR services like Google Cloud Vision, and upcoming support for Amazon Textract and Microsoft Azure Computer Vision. 
If you're into web automation, Python, OCR, selenium, or GPT-4, checking out Tarsier could provide valuable insights into enhancing web interaction capabilities.

1. **bckmn** made a connection between Tarsier and Language Intermediate Representation and shared a link to an article about the philosophical thoughts behind word meaning and linguistic structure.
2. **wyclf** shared pictures from a trip to the Tarsier Wildlife Sanctuary in Bohol, Philippines and received positive feedback.  
3. **brchr** announced the shipping of OpenAdapt's FastSAM, a UI tool for segmenting elements for LLMs, and a user asked about integrating Tarsier with GPT in the project's GitHub repository.
4. **dvdx** discussed the challenges in selecting elements robustly using regular browser automation tools and praised the design and features of Tarsier in addressing these challenges.
5. **ghxst** raised a question about handling multiple calls to action in web pages for LLM-based interaction systems.
6. **dbsh** discussed combining OCR accessibility with speech recognition to interpret desktop-based screen sharing and recommended a tool called Bananalyzer for benchmarking.
7. **SomaticPirate** expressed surprise at Azure's OCR outperforming AWS Textract for document recognition.
8. **rdbrbr** shared a project similar to Tarsier for tagging features in web pages using Typescript.
9. **brvr** raised questions about Tarsier's functionality in handling headless mode and capturing full-page screenshots for web pages.
10. **savy91** speculated about Tarsier as an alternative to Rabbit AI for assisting large language models in web interactions.
11. **pk19238** complimented Tarsier's creative solution and mentioned the Platonic Representation Hypothesis in relation to ASCII characters.
12. **shekhar101** discussed the challenge of converting tables to structured text and merging cells, seeking solutions involving multi-modal LLMs.
13. **shodai80** inquired about labeling web elements like text boxes, and **wtkns** explained Tarsier's mapping of element IDs for better automation.

This summarises the key discussions around the Tarsier project on Hacker News, ranging from philosophical connections and visual design to practical challenges and alternatives in the space of web interactions and AI assistance.

### Viking 7B: open LLM for the Nordic languages trained on AMD GPUs

#### [Submission URL](https://www.silo.ai//blog/viking-7b-the-first-open-llm-for-the-nordic-languages) | 108 points | by [reqo](https://news.ycombinator.com/user?id=reqo) | [51 comments](https://news.ycombinator.com/item?id=40368760)

- Viking 7B: The first open LLM for the Nordic languages
- Silo AI and appliedAI partner to boost AI adoption in European industrial firms
- Viking 7B/13B/33B: Navigating the multilingual Nordic seas

In today's tech news, Viking 7B introduces the first open LLM for the Nordic languages, enabling advanced language processing. Additionally, Silo AI and appliedAI join forces to support AI adoption in European industrial companies. Viking continues its linguistic journey with models 13B and 33B. Ready to enhance your AI capabilities for long-term success? Connect with experts, subscribe to newsletters, and explore Silo AI's offerings. Stay informed with Silo AI's resources, including blogs, webinars, and more.

The discussion on Hacker News revolves around the newly introduced Viking 7B model focusing on the Nordic languages. Users discuss the intricacies of the Finnish language within the context of Nordic languages, highlighting its unique characteristics and relationship to neighboring languages. Additionally, there are conversations about the development of multilingual models and their implications for understanding languages and cultures. The conversation delves into topics such as language structure, borrowed words, and language evolution. Furthermore, there are discussions on the technical aspects of training models, considerations for linguistic diversity, and the challenges of multilingual models in language processing. Users also touch on the environmental impact of high-performance computing and the relevance of maintaining cultural diversity. The conversation includes insights on GPU training experiences, the integration of different languages, and the potential for deeper insights and reasoning within language models.

### LLMs are not suitable for brainstorming

#### [Submission URL](https://piaoyang0.wordpress.com/2024/05/15/llms-are-not-suitable-for-brainstorming/) | 65 points | by [bcstyle](https://news.ycombinator.com/user?id=bcstyle) | [87 comments](https://news.ycombinator.com/item?id=40373709)

The author discusses the limitations of large language models (LLMs) like GPT-4 in performing effective brainstorming tasks, highlighting that while they exhibit some creativity, they tend to converge on existing patterns in data rather than generating truly innovative ideas. The author suggests that for cutting-edge problems, LLMs may not offer substantial insights beyond clichés. Proposing solutions such as curating specialized training datasets and implementing methods to reward creativity in LLM responses, the author reflects on the challenges and potential enhancements needed in LLM training processes. Overall, the article questions the current efficacy of LLMs in advanced brainstorming scenarios and presents avenues for potential improvements in their capabilities.

The discussion on the Hacker News submission regarding limitations of large language models (LLMs) like GPT-4 in brainstorming tasks involved various viewpoints and insights. 

1. Users debated the creativity of LLMs in brainstorming, with one user highlighting that LLMs tend to follow existing patterns in the data rather than generating truly innovative ideas. Another user emphasized the importance of prompt engineering to enhance creativity in LLM responses.

2. There was discussion on the training patterns of LLMs, with a user suggesting that LLMs need to be trained to diverge from existing patterns and reward creativity. This led to conversations about the impact of increasing temperature settings on the model's performance.

3. Some users criticized the methodology of a reviewed article regarding the validation of LLMs' creative thinking capabilities, pointing out flaws in the sample size and training data used.

4. Users discussed the role of randomness in LLMs and AI research, with some advocating for the incorporation of randomness to improve creativity and problem-solving abilities in models.

5. The conversation also touched upon the misconception of the novelty of ideas generated by LLMs compared to human creativity and highlighted the challenges in fostering creativity through AI training processes.

Overall, the discussion highlighted the complexities and areas for improvement in leveraging LLMs for advanced brainstorming tasks.

