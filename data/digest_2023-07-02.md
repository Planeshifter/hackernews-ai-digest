## AI Submissions for Sun Jul 02 2023 {{ 'date': '2023-07-02T17:09:42.147Z' }}

### AI and the Automation of Work

#### [Submission URL](https://www.ben-evans.com/benedictevans/2023/7/2/working-with-ai) | 196 points | by [CharlesW](https://news.ycombinator.com/user?id=CharlesW) | [214 comments](https://news.ycombinator.com/item?id=36565854)

In a recent blog post, Benedict Evans discusses the impact of generative AI, Large Language Models (LLMs), and ChatGPT on the automation of work. He acknowledges that while there is agreement in the tech industry about the transformative power of these technologies, there is much debate about the implications and future consequences.

Evans points out that automation has been happening for the past 200 years, and each wave of automation has eliminated certain jobs but also created new ones. However, when facing automation in our own generation, it's natural to worry that the new jobs won't materialize. While historical evidence suggests otherwise, it's hard to predict what new jobs will emerge. To address this concern, Evans refers to the "Lump of Labour" fallacy, which assumes that there is a fixed amount of work to be done and automation reduces job opportunities. He argues that when automation makes things cheaper, it leads to increased consumption and the creation of new jobs. The ripple effect through the economy generates prosperity and employment.

One criticism of this model is that automation has been progressively moving up the scale of human capabilities. From physical labor to white-collar jobs, if we automate white-collar work, what's left? To counter this, Evans introduces the concept of the Jevons Paradox, which explains that as technology becomes more efficient, it's used more extensively, leading to increased resource consumption. In the case of white-collar work, automation has historically created new opportunities rather than eliminating jobs.

Evans gives examples from history, such as the impact of typewriters and adding machines on clerical employment. Although these technologies reduced the number of clerks required for certain tasks, they also increased productivity and enabled new forms of work. Similarly, he argues that automation can lead to more analysis, improved inventory management, and the creation of businesses that can only exist because of automation.

In conclusion, while concerns about job displacement due to automation are valid, historical evidence suggests that new jobs will emerge. Automation has consistently led to increased productivity and economic growth. Although we can't predict the exact nature of future jobs, Evans remains optimistic that automation will continue to present new opportunities for prosperity.

The discussion on Hacker News revolves around the capabilities and potential dangers of AI taking over various jobs. Some users express concerns about security issues and the potential for AI machines to misinterpret human intentions, leading to fatal mistakes. Others argue that AI reporting machines can be useful in certain situations but should not replace human judgment entirely. The discussion also touches on the impact of automation on the military and law enforcement sectors, with some users pointing out the risks and limitations of relying too heavily on AI in those fields. There is a debate about whether AI will truly replace human jobs or if it will primarily enhance them by taking over tasks that are repetitive or require specific expertise. Overall, the discussion raises valid concerns about the implications of AI in the workforce while also acknowledging its potential benefits.

### Automated CPU Design with AI

#### [Submission URL](https://arxiv.org/abs/2306.12456) | 89 points | by [skilled](https://news.ycombinator.com/user?id=skilled) | [23 comments](https://news.ycombinator.com/item?id=36565671)

Researchers from the field of Artificial Intelligence (AI) have made a significant breakthrough in the realm of machine design. In a recent publication, titled "Pushing the Limits of Machine Design: Automated CPU Design with AI," a team of 18 authors led by Shuyao Cheng introduces a revolutionary approach to automatically designing a central processing unit (CPU) using AI techniques. CPUs are considered one of the most complex devices ever created by humans, making the successful application of AI in their design a remarkable achievement.

In their research, the team developed a method that allows machines to design a CPU solely based on external input-output observations, rather than relying on formal program code. The AI approach generates the circuit logic of the CPU design using a graph structure called Binary Speculation Diagram (BSD), ensuring both accuracy and efficiency. To demonstrate the capability of their method, the researchers explored an unprecedentedly large search space of 10 to the power of 10 to the power of 540 possibilities, which is considered the largest of all machine-designed objects to date.

After only five hours of computation, the team's approach successfully generated an industrial-scale RISC-V CPU, which was able to run the Linux operating system and perform comparably to the human-designed Intel 80486SX CPU. This breakthrough not only significantly reduces the design cycle in the semiconductor industry but also has the potential to reform it by enabling machines to learn the von Neumann architecture autonomously.

The research paper, totaling 28 pages, was submitted to the arXiv preprint server under the category of Artificial Intelligence (cs.AI) and Hardware Architecture (cs.AR). The authors provide extensive technical details and analysis of their methodology, making it a valuable resource for researchers in the field. This groundbreaking work represents a significant leap forward in machine design, opening up new possibilities for AI systems to tackle increasingly complex tasks in the future.

### It's 2023 and memory overwrite bugs are not just a thing theyre still number one

#### [Submission URL](https://www.theregister.com/2023/06/29/cwe_top_25_2023/) | 111 points | by [LinuxBender](https://news.ycombinator.com/user?id=LinuxBender) | [50 comments](https://news.ycombinator.com/item?id=36562727)

Memory overwrite bugs continue to be the most dangerous type of software bug, according to MITRE. These bugs, also known as out-of-bounds write bugs, are responsible for 70 vulnerabilities on the US government's list of known vulnerabilities that are under active attack. Out-of-bounds write bugs occur when software or hardware alters memory it shouldn't, causing unexpected changes or crashes. Exploit code can trigger these bugs to take control of the software. MITRE recommends using memory-safe languages like Rust to prevent these bugs. Cross-site scripting bugs and SQL injection flaws are the second and third most dangerous bugs, respectively. CISA has added eight more vulnerabilities to its Known Exploited Vulnerabilities Catalog, including flaws in D-Link and Samsung devices. The list of the Top 25 most dangerous software weaknesses for 2023 remains the same as last year. MITRE will publish reports to help organizations effectively use the Top 25 list.

### The open-source AI boom is built on Big Techâ€™s handouts. How long will it last?

#### [Submission URL](https://www.technologyreview.com/2023/05/12/1072950/open-source-ai-google-openai-eleuther-meta/) | 32 points | by [AnhTho_FR](https://news.ycombinator.com/user?id=AnhTho_FR) | [27 comments](https://news.ycombinator.com/item?id=36560473)

The rise of open-source large language models is threatening the dominance of Big Tech in the field of artificial intelligence (AI), according to a leaked memo by a senior engineer at Google. These freely available alternatives to Google's Bard or OpenAI's ChatGPT offer researchers and app developers the ability to study, modify, and build upon them. While this increased accessibility has driven innovation and democratized AI, it also poses risks. Many of these models rely on the work of big firms like Meta AI and OpenAI, which could choose to restrict access in the future. Closing down access would not only stifle the open-source community but also consolidate AI breakthroughs in the hands of the largest AI labs. However, some argue that opening up code for a limited period can drive innovation while still protecting the company's interests. The future of AI development and usage hangs in the balance as the industry grapples with the implications of open-source models.

The discussion on the Hacker News submission revolves around the rise of open-source large language models and its impact on the dominance of big tech companies in the AI field. Some commenters express skepticism about the benefits of open-source projects, stating that companies like Google, Meta, and Microsoft do not benefit from open sourcing their projects. However, others argue that open-source models offer alternatives and drive innovation. There is a debate about the control of AI technology, with some expressing concerns about big tech companies gaining a monopoly. However, others argue that big tech companies do not rely solely on open-source projects and have internal versions that are not shared with the world. The discussion also touches on the importance of open-source software in the AI industry, with examples such as PyTorch and TensorFlow being mentioned. Additionally, there is a discussion about the role of open source in the survival and growth of big tech companies. Some commenters bring up historical examples, highlighting the impact of open-source software in the past, such as the case of Sun and Linux. Overall, the discussion delves into the benefits and limitations of open-source models and their potential implications for the future of AI development.

