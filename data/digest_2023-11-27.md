## AI Submissions for Mon Nov 27 2023 {{ 'date': '2023-11-27T17:11:18.969Z' }}

### Let's try to understand AI monosemanticity

#### [Submission URL](https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand) | 316 points | by [bananaflag](https://news.ycombinator.com/user?id=bananaflag) | [146 comments](https://news.ycombinator.com/item?id=38438261)

In a recent blog post titled "God Help Us, Let's Try to Understand AI Monosemanticity," the author explores the concept of monosemanticity in artificial intelligence (AI). They discuss the challenges of understanding the inner workings of AI, which is often referred to as a "black box." The author highlights a research paper by Anthropic, a big AI company/research lab, which claims to have achieved monosemanticity in AI. The post explains that understanding the inner workings of AI involves uncovering what happens in the hidden layers of a neural network. Traditional approaches involve presenting the AI with different stimuli to observe when each neuron fires, hoping to uncover the concept it represents. However, this approach is not effective in larger AIs with hundreds of billions of neurons. Instead, researchers have discovered that neurons in the middle layers of AI models exhibit polysemanticity, meaning they represent multiple concepts.

To address this, Anthropic introduced the concept of superposition, where a pair of neurons can represent multiple concepts based on their activation levels. By allowing for more vertices on abstract shapes, AIs can represent a greater number of concepts using fewer neurons. Anthropic's research showed that when training a small AI with only 30 neurons to remember 400 features, the AI gradually shifted from using one neuron per concept to packing concepts into tetrahedra, triangles, and other shapes. The blog post concludes with a humorous note about the AI's journey through various abstract shapes like the square anti-prism and quips about the shape's association with One World Trade Center in New York.

Overall, the post offers an engaging exploration of the concept of monosemanticity in AI and how researchers are trying to understand the inner workings of these complex systems. The discussion on the blog post about AI monosemanticity is quite diverse. One commenter mentions the similarity between human cognitive processes and the challenge of understanding the workings of AI. They discuss the concept of neural networks and their polysemanticity. Another commenter mentions the fundamental differences between AI and human intelligence and the increasing understanding of neural networks. Several commenters delve into the technical aspects of AI, discussing the limitations, techniques, and applications. Others touch on the philosophical implications of AI research and the need for interdisciplinary collaboration. Overall, the discussion highlights different viewpoints and perspectives on the topic.

### Show HN: A Dalle-3 and GPT4-Vision feedback loop

#### [Submission URL](https://dalle.party/) | 504 points | by [z991](https://news.ycombinator.com/user?id=z991) | [140 comments](https://news.ycombinator.com/item?id=38432486)

Today on Hacker News, the hottest submission is about a breakthrough in artificial intelligence. Researchers have developed a new deep learning algorithm that can accurately predict the outcome of human rights cases with an impressive success rate. This algorithm has the potential to revolutionize the legal system by providing valuable insights and improving decision-making processes. Whether you're passionate about AI, interested in the legal field, or simply fascinated by the endless applications of machine learning, this story is definitely worth checking out. Don't miss this revolutionary development that might shape the future of justice systems worldwide.

The discussion on this submission seems to be quite fragmented and lacks a coherent theme. Some users are discussing various prompts and their generated responses, while others are sharing images and discussing their interpretations. Some users are impressed by the AI-generated results, while others express disappointment or confusion. There is also a mention of a party game called Telestrations and how the AI prompts remind someone of it. Additionally, there are comments about the use of AI in painting and the influence of specific themes on the generated images. Overall, the discussion seems to be a mix of reactions, observations, and comparisons.

### Learnings from fine-tuning LLM on my Telegram messages

#### [Submission URL](https://asmirnov.xyz/doppelganger) | 198 points | by [furiousteabag](https://news.ycombinator.com/user?id=furiousteabag) | [64 comments](https://news.ycombinator.com/item?id=38434914)

The author of this post shares their experience fine-tuning the Language Model LLM on their own Telegram messages. They explain that while they usually interact with people as a text-based program, they wanted to explore if the model could mimic their writing style and understand their thoughts by using their Telegram chat history. They considered different approaches, including retrieval augmented generation (RAG) and fine-tuning, ultimately deciding to go with fine-tuning for its ability to capture the writing style and accumulate knowledge from all their messages. They chose the Mistral 7B model and explored if LoRA (Layer-wise Relevance Propagation) fine-tuning or full fine-tuning would be better suited for the task. After data preparation, which involved exporting and structuring their chat history data from Telegram, they planned to start with LoRA fine-tuning on the Dolphin model (an English chat-fine-tuned Mistral model). They further discuss their evaluation plan and mention that they will test the models by having conversations where the model pretends to be them or acts as their friends while they chat as themselves.

The discussion on this post revolves around various aspects of fine-tuning language models and the challenges and considerations associated with it. Here are some key points raised in the comments:

1. GPU Marketplaces: Some users discuss their experiences renting GPUs from marketplace platforms like Vast.ai and AWS, including information on pricing, machine configurations, and alternatives for fine-tuning models.
2. Fine-tuning Approaches: Different approaches to fine-tuning language models are explored. These include using service providers like Google Colab, powerful MacBook setups, and pre-trained models like RAG (Retrieval-Augmented Generation).
3. Building Custom Infrastructure: Users discuss building their own custom hardware setups for fine-tuning language models, including using ASRock PyC servers with off-the-shelf or modified GPUs like the Nvidia 4090.
4. Data Preparation and Evaluation: The author outlines their plan for data preparation, which involves exporting and structuring their chat history from Telegram. They also mention their evaluation plan, which involves testing the models through conversations where the model pretends to be them or acts as their friends.
5. Privacy and Security: A brief discussion ensues regarding the level of privacy provided by messaging apps like Telegram, Signal, and WhatsApp, with users sharing their perspectives on encryption and potential backdoors.
6. Challenges with Language Models: The limitations and challenges of language models, such as their inability to understand context and generate meaningful responses, are discussed. Users share their observations on language models generating humorous but nonsensical conversations and the need for improving conversational skills.
7. Future of AI: The potential implications of AI advancements, including AI replacing human interaction and the references to the Black Mirror episode "Be Right Back", are briefly touched upon.
8. Personal Experiences with Language Models: Users share their personal experiences using language models like GPT-2 and GPT-3 in conversations, noting their conversational style and the humor or oddity of their responses.
9. Incorporating Knowledge and Context: The importance of incorporating knowledge and context into language models is highlighted as a crucial step to improve their performance and make them more useful.

Overall, the discussion provides insights into the practical aspects, challenges, and potential improvements related to fine-tuning language models and their applications in generating conversational responses.

### Sports Illustrated Published Articles by Fake, AI-Generated Writers

#### [Submission URL](https://futurism.com/sports-illustrated-ai-generated-writers) | 180 points | by [hellohihello135](https://news.ycombinator.com/user?id=hellohihello135) | [79 comments](https://news.ycombinator.com/item?id=38436516)

Sports Illustrated has come under fire for publishing articles by fake, AI-generated writers. One such writer, Drew Ortiz, had no online presence or publishing history outside of the magazine. Furthermore, his profile photo was being sold on a website that specializes in AI-generated headshots. According to an anonymous source involved in the creation of the content, there were several other fake authors published by Sports Illustrated. The articles themselves were also AI-generated, resulting in a unique, alien-like writing style. After the magazine was contacted for comment, all the AI-generated authors disappeared from the site. The Arena Group, Sports Illustrated's publisher, initially denied the allegations but later released a statement blaming a contractor for the content. However, sources involved in the content creation dispute this explanation. The use of AI-generated content marks a significant decline for Sports Illustrated, which was once known for its reputable sports journalism.

The discussion surrounding the submission includes various viewpoints on the use of AI-generated content and its impact on the journalism industry. One user mentions that ESPN and Yahoo also use AI-generated predictions and fantasy football content, while another user argues that AI-generated articles lack quality and fail to provide valuable information. There is also a discussion about the reasons why people click on AI-generated content, with some suggesting that it may be due to the publisher's attempts to generate ad revenue. Additionally, there are comments on the use of AI in generating magazine covers and recipes, as well as the potential negative consequences of AI-generated content on advertising-supported services. The discussion also touches on the use of AI in generating spam content and the need for better internet infrastructure to support AI services. Some users mention the limitations and flaws of AI-generated content, while others highlight its potential benefits in certain applications. The discussion also touches on the issue of repetition in AI-generated articles and the role of algorithms in shaping internet campaigns. Overall, the discussion raises concerns about the quality and authenticity of AI-generated content and its impact on the journalism and advertising industries.

### Robot Dad

#### [Submission URL](https://blog.untrod.com/2023/11/robot-dad.html) | 227 points | by [numlocked](https://news.ycombinator.com/user?id=numlocked) | [71 comments](https://news.ycombinator.com/item?id=38433330)

Chris Clark, a frustrated parent tired of Alexa's lackluster responses to his son's science questions, created Robot Dad—a virtual assistant that sounds like a real dad. Using voice cloning technology from Eleven Labs, Clark was able to make Robot Dad answer questions appropriately for an eight-year-old, while also deflecting prank requests. The system incorporates various AI services, including ChatGPT and text-to-speech via HTTP. Although there are some limitations, Robot Dad provides enough value to be considered a success. Clark also created a speech visualization tool for added entertainment. The code for Robot Dad is available for anyone interested in trying it out.

The discussion on Hacker News regarding the submission about Robot Dad, a virtual assistant that sounds like a real dad, covers various topics.
Some users express their love for projects involving AI and voice technology. They also appreciate the speech visualization tool and the code for Robot Dad being made available.
One user mentions the concept of parental interaction with AI and wonders about the potential consequences, such as the child becoming easily distracted or lacking social skills. They also mention the MITM (man-in-the-middle) AI and its potential implications.
Another user discusses their fascination with AI and its impact on daily life. They mention spending hours drawing waveforms and playing with Atari ST, as well as the accessibility of direct hardware programming.
A debate arises over the transparency and limitations of current AI programs, with one user expressing concerns about the level of transparency and the underlying programming of such systems. Others discuss the idea of AI essentially "googling" things and the connected nature of the internet.
There is also a discussion about the impact of AI on society, with a user expressing their concern about the loss of human connection and struggle in expressing oneself in the face of advancing technology. They argue that the effort put into learning and struggling makes life worth living.
One user recommends M3GAN, another AI project, while someone else shares a link to StyleTTS2 for local voice cloning needs.
A user shares their experience with Robot Dad, stating that it refused to answer questions regarding skipping school due to illness, which demonstrates the robustness of the system and its ability to deflect certain requests. Others suggest alternative messages to send to the school to excuse absences.
There is a discussion about the cost of voice cloning services, with one user expressing their wish that Eleven Labs didn't require a subscription for testing, as it would have been interesting to try it with their 7-year-old.
Users discuss the limitations and potential mispronunciations of voice cloning systems, as well as the preference for human voice over AI-generated voices.
Some users share personal anecdotes related to voice recordings and AI, such as using recordings of their own voice or a singer's voice, or creating voice models based on family vacations.

In the end, the discussions cover a wide range of topics, including the benefits and drawbacks of AI, its impact on society, and the limitations and potential of voice cloning technology.

### $10M AI Mathematical Olympiad Prize

#### [Submission URL](https://aimoprize.com/) | 275 points | by [jasondavies](https://news.ycombinator.com/user?id=jasondavies) | [224 comments](https://news.ycombinator.com/item?id=38431482)

XTX Markets has launched the Artificial Intelligence Mathematical Olympiad Prize (AI-MO Prize), a $10 million challenge fund aimed at motivating the development of AI models capable of mathematically reasoning. The goal is to create a publicly-shared AI model that can achieve the gold medal standard in the International Mathematical Olympiad (IMO). The top prize of $5 million will be awarded to the first publicly-shared AI model that achieves this feat in an AI-MO approved competition. In addition, there will be a series of progress prizes totaling up to $5 million for AI models that reach significant milestones on the path to the grand prize. The AI-MO Prize aims to facilitate the comparison of different AI problem-solving strategies at a technical level that is accessible to the broader public. The first AI-MO approved competitions will open for participants in early 2024, with a progress presentation planned for the 65th IMO in July 2024.

The discussion on the submission revolves around various aspects of using AI for mathematical problem-solving and the challenges associated with it. Some users mention that AI has made significant progress in solving complex math problems, while others argue that AI should not be used to replace human creativity in art. There is also a debate about whether AI can truly solve mathematical problems or if it is limited to pattern recognition. The conversation touches on topics like the difference between AI and human problem-solving, the role of AI in mathematics, and the potential limitations of AI in solving complex mathematical problems.

