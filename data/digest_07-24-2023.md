## AI Submissions for Mon Jul 24 2023 {{ 'date': '2023-07-24T17:10:35.408Z' }}

### Google’s nightmare “Web Integrity API” wants a DRM gatekeeper for the web

#### [Submission URL](https://arstechnica.com/gadgets/2023/07/googles-web-integrity-api-sounds-like-drm-for-the-web/) | 969 points | by [jakobdabo](https://news.ycombinator.com/user?id=jakobdabo) | [404 comments](https://news.ycombinator.com/item?id=36854114)

Google is proposing a new web standard called the "Web Environment Integrity API" which aims to verify the integrity of the client environment running in the web browser. The goal is to ensure that the browser hasn't been modified or tampered with, and that the person on the other side is not a robot. This proposal has raised some concerns, as it brings up issues of privacy and control over devices. The API takes inspiration from existing native attestation signals such as Apple's App Attest and Android's Play Integrity API. The proposal has sparked a lot of discussion and debate in the tech community.

The discussion on Hacker News revolves around various aspects of Google's proposal for the Web Environment Integrity API. Some users express skepticism towards Google's intentions, highlighting the company's dominance in multiple areas and questioning their need for more control. Others emphasize their concerns about privacy and the potential for abuse of such an API. The comparison is made to Apple's previous controversy with the U2 album auto-downloading, which resulted in a lack of trust from some users. There are also discussions about the implications for ad-blocking and browser restrictions, with some users expressing frustration with the limitations imposed by certain browsers. The conversation also touches on alternative browsers and their potential to circumvent such API restrictions. Overall, there is a mixture of opinions and concerns surrounding the proposal. Some users see it as a necessary security improvement, while others view it as potentially problematic and restrictive.

### Meta-Transformer: A unified framework for multimodal learning

#### [Submission URL](https://kxgong.github.io/meta_transformer/) | 101 points | by [ulrikhansen54](https://news.ycombinator.com/user?id=ulrikhansen54) | [33 comments](https://news.ycombinator.com/item?id=36851505)

A team of researchers from The Chinese University of Hong Kong and Shanghai AI Laboratory has developed a framework called Meta-Transformer that enables unified multimodal learning. This framework utilizes the same backbone to process various data modalities such as natural language, images, point clouds, audio, video, infrared, hyperspectral, X-ray, time-series, tabular, and graph data. By converting the raw input data from different modalities into a shared token space and using a modality-shared encoder with frozen parameters, Meta-Transformer can extract high-level semantic features and achieve favorable performance across modalities. This framework has been evaluated on benchmarks like ImageNet, GLUE, ModelNet-40, S3DIS, ShapeNetPart, and Speech Commands V2, showcasing its potential for developing unified multimodal intelligence with transformers. Meta-Transformer has applications in various fields such as 3D recognition, nighttime security, and weather prediction.

The discussion on this submission revolves around the capabilities and limitations of the Meta-Transformer framework and the general purpose of multimodal learning. Some users express skepticism about the effectiveness of using transformers for different modalities, arguing that specialized models may perform better in specific tasks. Others discuss the potential scalability challenges and the need for large amounts of data to train such models. The discussion also touches on the comparison between GPT-4 and Meta-Transformer and the trade-offs between model size and effectiveness. Additionally, there are debates about the potential dangers of AI and the need for responsible scientific progress. The existence and risks of AI are debated, with one user referencing a documentary on AI in the military as evidence of its capabilities. The discussion then delves into defining and evaluating risks associated with AI and the distinction between science fiction and science. The conversation also explores the historical progress of AI and the advancements made in fields like optical lithography and computer vision. Finally, there are concerns raised about existential threats posed by AI and the need to address research directions that can mitigate potential dangers.

### Text Embeddings Reveal (Almost) as Much as Text

#### [Submission URL](https://openreview.net/forum?id=wK7wUdiM5g0) | 65 points | by [jxmorris12](https://news.ycombinator.com/user?id=jxmorris12) | [9 comments](https://news.ycombinator.com/item?id=36851930)

Researchers have proposed a method called Vec2Text that can reconstruct 90% of 32-token embedded inputs exactly, revealing how much private information text embeddings can disclose about the original text. This method treats embedding inversion as a controlled generation problem, generating text that, when reembedded, is close to a fixed point in latent space. While a naive model conditioned on the embedding performs poorly, a multi-step method that iteratively corrects and re-embeds text can recover 92% of 32-token text inputs accurately. The researchers trained their model to decode text embeddings from two state-of-the-art embedding models and demonstrated that it can recover personal information, such as full names, from clinical notes.

The discussion on this submission covers a range of topics related to text embeddings and privacy. Some of the points raised include:

- There is a debate about whether text embeddings should be considered as encryption or compressed representations, with one commenter stating that they are compressed representations and another arguing that they are hashed and therefore not easily reversible.
- The importance of security in text embeddings and the interest in exploring methods to tweak embedding values to find token points corresponding to different latent spaces.
- A commenter highlights that the research demonstrates the ability to recover 90% of text exactly with semantic overlap in vector space. They mention that while the text might not be visually identical, the meaning is preserved with meaningful shifts of words.
- The concept of single reference differential privacy is brought up in the context of protecting privacy.
- The discussion references the experiment section (Section 5.3) of the paper, which focuses on attempting to recover private information from clinical notes using embeddings. The commenter finds it interesting and wonders if recovering names is possible by using custom distance metrics.
- One commenter asks if embedding protection can be achieved without encrypting individual words.
- It is mentioned that the linked paper demonstrates different results in terms of text retrieval and reconstruction performance.
- A commenter argues that it is difficult to achieve fundamental point computer representations of meaning in regional text using accessible embeddings.

Overall, the discussion examines various aspects related to the research topic, including the nature of text embeddings, privacy concerns, and the technical details of the proposed method.

### Apple Vision Pro developer kit

#### [Submission URL](https://developer.apple.com/visionos/developer-kit/) | 161 points | by [Pulcinella](https://news.ycombinator.com/user?id=Pulcinella) | [181 comments](https://news.ycombinator.com/item?id=36851535)

Apple is inviting developers to apply for the Vision Pro developer kit, which will help them build and test apps for the new App Store on Vision Pro. The kit includes a loaned Vision Pro device, assistance with setup and onboarding, guidance from Apple experts, and code-level support requests. Developers need to be Account Holders in the Apple Developer Program and submit an application that highlights their team's skills and existing apps. Priority will be given to apps that make use of visionOS features and capabilities.

The discussion revolves around Apple's new Vision Pro developer kit and its implications for gaming. Some users express interest in the potential for gaming on the Vision Pro device, while others question Apple's commitment to gaming and the use of VR controllers. The conversation touches on topics such as the competition between gaming consoles and PCs, Apple's approach to gaming, VR gaming, and the importance of game standards and controllers. Some users express skepticism about Apple's focus on gaming and suggest that the company should prioritize other aspects of its devices. Others argue that gaming is a significant market and criticize Apple for not fully understanding or facilitating it. Additionally, there are discussions on the limitations of VR controllers, the need for hand tracking, and the challenges of implementing gaming features.

