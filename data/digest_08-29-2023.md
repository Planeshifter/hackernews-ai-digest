## AI Submissions for Tue Aug 29 2023 {{ 'date': '2023-08-29T17:10:56.808Z' }}

### Meta AI releases CoTracker, a model for tracking any points (pixels) on a video

#### [Submission URL](https://co-tracker.github.io/) | 297 points | by [crakenzak](https://news.ycombinator.com/user?id=crakenzak) | [77 comments](https://news.ycombinator.com/item?id=37314073)

Researchers from Meta AI and the Visual Geometry Group at the University of Oxford have introduced a new video motion prediction method called CoTracker. Unlike existing methods that either track points independently or estimate motion jointly using optical flow, CoTracker simultaneously tracks multiple points throughout an entire video. It incorporates ideas from both optical flow and tracking literature and utilizes a transformer network to model the correlation between different points over time. The architecture can be applied to long videos by using a sliding-window approach. CoTracker outperforms state-of-the-art point tracking methods in terms of efficiency and accuracy. The researchers provided visualizations comparing CoTracker with other methods, demonstrating its ability to produce cleaner and more accurate trajectories, particularly in handling occlusions.

The discussion surrounding the submission on Hacker News covers a variety of topics related to the use of AI in business and the implications of the CoTracker video motion prediction method. Some users express their skepticism about the business relevance of AI research, while others discuss the potential benefits and challenges of using AI for content creation in virtual reality (VR) environments. The conversation also touches on issues regarding leadership and strategy in AI development, with some users questioning the integrity and intentions of Mark Zuckerberg. Other topics include Meta's revenue, the importance of attracting AI talent, the use of tracking algorithms in VR, and the justification of Facebook's open-source initiatives.

### Griffin â€“ A fully-regulated, API-driven bank, with Clojure

#### [Submission URL](https://www.juxt.pro/blog/clojure-in-griffin/) | 372 points | by [coder94](https://news.ycombinator.com/user?id=coder94) | [188 comments](https://news.ycombinator.com/item?id=37313183)

Griffin is a fully-regulated UK bank that aims to disrupt the market with its modern technology platform. The bank, often referred to as "the bank you can build on," offers a range of API-driven services that allow fintech businesses to integrate banking features quickly and securely. In a recent interview with Allen Rohner, co-founder and CTO of Griffin, he explained how they've built the bank from the ground up using Clojure as their language of choice. 

Rohner highlighted several reasons for choosing Clojure, including its immutability, power, and suitability for financial services and audit logs. He also shared the story of how he discovered Clojure, starting with his interest in Lisp and his encounter with Paul Graham's writings. Despite initial concerns about the "JVM tax" associated with Clojure, Rohner eventually realized the benefits of the JVM and its extensive library ecosystem. 

By using Clojure, Griffin aims to differentiate itself from traditional banks and appeal to high-end talent who prefer working with niche languages. Rohner emphasized the importance of using the most powerful language in a startup, and for him, that language is Clojure. 

In terms of architecture, Griffin runs on Kubernetes and AWS, with a focus on event sourcing. They also use FoundationDB as their database and are working on open sourcing an additional proprietary technology. 

Overall, Griffin's use of Clojure demonstrates their commitment to leveraging powerful technologies and their determination to disrupt the banking industry with their innovative platform.

The discussion on this submission revolves around several topics. 

One commenter appreciated the use of Clojure by Griffin and thanked them for sharing their experience. Another commenter raised concerns about the control behavior and underlying Java threading libraries, as well as the non-deterministic execution system. The original poster clarified that their system is fully synchronous and explained the threading approach they take.

Another commenter suggested using a modified version of the missionary structured concurrency DSL to handle process supervision and testing. This led to a discussion about the potential non-deterministic nature of the API interactions and the need for synchronization points.

There was also a discussion about the hindsight bias in the title and the importance of having a banking license. One commenter noted that it's important for a technology company to have a banking license to justify their expertise. Another commenter pointed out that in the US, banks have been slow in adopting technology innovations.

A commenter raised a serious question about the choice of language and whether it is necessary to write the entire service in Clojure. One commenter mentioned that it is common for tech stack-focused blog posts to attract attention and that people find the technology interesting. There was also a discussion about the acceptance of programming languages and how some languages take time to gain popularity.

There was a brief discussion about the book "Learning ClojureScript" written by the co-founder of Griffin. Another commenter mentioned that Griffin's API allows fintech businesses to integrate banking features quickly and securely.

The role of regulations in the banking industry was also discussed. One commenter mentioned that the UK has actively encouraged banks to adopt technology innovations, while another commenter noted that US bank regulations are more strict compared to the UK and EU.

Finally, there were comments about the prevalence of proprietary software in software banking and the challenges of getting a banking charter.

### MapReduce, TensorFlow, Vertex: Google's bet to avoid repeating history in AI

#### [Submission URL](https://www.supervised.news/p/mapreduce-tensorflow-bard-also-hello) | 135 points | by [coloneltcb](https://news.ycombinator.com/user?id=coloneltcb) | [85 comments](https://news.ycombinator.com/item?id=37312385)

Google is making a massive bet on its Google Cloud AI infrastructure Vertex AI to avoid repeating its past mistakes in the field of AI. In the early 2000s, Google created the groundbreaking technique MapReduce but allowed its competitors to take advantage of it. The same situation occurred with the release of TensorFlow in 2015. Now, Google is hoping to reclaim its position as the most powerful AI company with Vertex AI, which offers various models to serve different use cases. The company is also playing a complicated game against OpenAI and is working on a new language model development framework called PaxML. This move is seen as a way for Google to recapture what it has lost with TensorFlow. Learn more: [Supervised](https://www.supervised.news/p/cksg1rvsjzc010611wigduesm/mapreduce-tensorflow-vertex-googles)

The discussion on Hacker News revolves around various aspects of Google's past AI projects and their current efforts with Vertex AI. Here are some key points from the discussion:

- One commenter mentions that Google has historically missed important details in their projects, such as with AppEngine in 2008, which didn't address certain scalability and consistency issues.
- Another user shares their experience with AppEngine and how they eventually moved to AWS due to scalability issues.
- The significance of MapReduce is discussed, with one user pointing out that while Google's MapReduce and TensorFlow were groundbreaking technologies, their competitors, like Hadoop and PyTorch, were able to take advantage of them.
- The lack of communication and attention to detail from Google is raised as a recurring issue, with examples given of Google's poor support for certain functionalities like second-factor authentication.
- The compatibility of Google's products with enterprise contracts and customer requirements is questioned, suggesting that Google may need to address these concerns to attract larger organizations.
- The scalability of Google's SQL DBs and the alternative option of Google Spanner are discussed, with some users expressing their preference for alternative databases like MySQL and Postgres.
- The role of Kubernetes and Google Kubernetes Engine (GKE) in Google Cloud's competitiveness against AWS is touched upon, highlighting GKE's multi-cluster features and ease of use.
- The potential advantages of incorporating Kubernetes into Google Cloud's platform are also mentioned.
- The importance of integrating with Kubernetes and the overall integration of Google Cloud Platform (GCP) are emphasized as key factors for Google's competitiveness.
- The discussion concludes with a mention of the integration of Kubernetes into Google Cloud's services as a competitive advantage for the company.

Overall, the discussion reflects a mix of positive opinions about Google's potential with Vertex AI, as well as concerns about their past mistakes and the challenges they face in the AI space.

### Starlink's User Terminal Firmware

#### [Submission URL](https://blog.quarkslab.com/starlink.html) | 206 points | by [jandeboevrie](https://news.ycombinator.com/user?id=jandeboevrie) | [38 comments](https://news.ycombinator.com/item?id=37308405)

Today's top story on Hacker News is about an overview of Starlink's User Terminal runtime internals. The blog post provides insights into how the device works internally, focusing on the communications that occur within the device and with user applications. The author, who conducted this analysis during a 6-month internship at Quarkslab, also developed a set of tools that can aid further research on the same topic. The analysis involved reverse-engineering the firmware and various protocols used by Starlink. The blog post goes into detail about the firmware structure, the boot process, and the different partitions present in the user terminal. It also discusses the custom mechanisms used by SpaceX for data integrity. The tools developed during the internship will be described and published along with the blog post. Starlink is a satellite-based internet access service provided by SpaceX and currently has over 1.5 million subscribers worldwide.

The discussion on this submission covers a range of topics related to Starlink's User Terminal and general communication protocols.

One commenter points out that Starlink has refused to release the source code for their user terminal firmware, which goes against the principles of the GPL license. Another user, who is a major contributor to Buildroot, notes that they have sent multiple requests for the GPL compliance of the User Terminal firmware, but SpaceX has refused to provide the source code.

There is also a discussion about the implementation of GPS location for Starlink in different countries. One user mentions that Thuraya GPS receivers were refused to be connected to Starlink due to different country calling plans. Another user suggests that Starlink might be spoofing GPS location for their satellites, which could potentially be illegal.

The conversation then shifts to the potential security concerns of Starlink's constellation and the reliance on ground stations for communication. One user points out that if there are jamming devices that interfere with GPS signals, Starlink's satellites might also be affected. Another user mentions that Starlink relies on phased arrays and fast electronic beam steering to work with the moving footprint of the satellites.

A separate discussion revolves around the possibility of OpenWRT or similar firmware being used for Starlink. Several users express interest in analyzing the network hardware and mention existing customized versions of OpenWRT for various hardware.

Finally, there are comments acknowledging the blog post's contribution and sharing related resources, such as a YouTube video and a project called FACT Core for analyzing OpenWRT firmware.

Overall, the discussion provides additional insights, raises questions about the source code availability, discusses security concerns, and highlights potential open-source firmware possibilities for Starlink.

### Automatic Generation of Visualizations and Infographics with LLMs

#### [Submission URL](https://microsoft.github.io/lida/) | 172 points | by [monkeydust](https://news.ycombinator.com/user?id=monkeydust) | [50 comments](https://news.ycombinator.com/item?id=37305240)

LIDA is an automated tool for generating visualizations and infographics from data, and it is now open source on GitHub. This tool uses large language models (LLMs) and image generation models (IGMs) to understand the semantics of data, enumerate visualization goals, and generate visualization specifications. LIDA consists of four modules: a summarizer, a goal explorer, a visgenerator, and an infographer. It supports any programming language or visualization grammar and provides a Python API and a hybrid user interface for interactive chart, infographic, and data story generation. LIDA can summarize data, explore visualization goals, generate visualizations in any grammar, and create stylized infographics. It also offers operations on existing visualizations, such as explanation, self-evaluation, repair, and recommendation. However, LIDA may not work well with visualization grammars that are not well represented in the LLM's training dataset. The performance is also dependent on the choice of visualization libraries and the degrees of freedom granted to the model. LIDA currently requires code execution, so a sandbox environment is recommended to ensure safe execution. LIDA is built using large language models and image generation models. The research paper on LIDA has been accepted at the 2023 ACL Conference. You can try out LIDA locally on your own data now that it is open source on GitHub.

The discussion around the submission revolves around various aspects of LIDA, the automated tool for generating visualizations and infographics from data.

- Some users express their frustration with using Excel for data analysis and mention the usefulness of PivotTables.
- There is a discussion about the limitations of LIDA, including its dependence on the training dataset and choice of visualization libraries.
- One user shares a link to a blog post on data visualizations using Python and mentions the limitations of chartjunk.
- The conversation also touches on the potential commercial applications of LIDA and the ethical implications of using large language models (LLMs) in business models.
- Some users express their interest in LIDA and its potential applications, while others discuss the challenges of training LLMs and the difficulty of understanding the underlying algorithms.
- There is a brief discussion about the comparison between GPT and matplotlib in terms of generating charts.
- Users also discuss the relevance and limitations of LLM-based prompts for generating data descriptions and field names.
- The conversation raises concerns about the interpretability and accountability of LLMs in generating charts and the need to ensure data accuracy.

Overall, the discussion explores both the potential benefits and challenges of using LIDA and LLMs for data visualization. It highlights the need for further research and consideration of ethical and practical implications.

### Pentagon Wants to Buy 1,000s of Small, Cheap, Autonomous Drones in Next 2 Years

#### [Submission URL](https://www.airandspaceforces.com/pentagon-replicator-small-cheap-autonomous-drones/) | 43 points | by [mikece](https://news.ycombinator.com/user?id=mikece) | [23 comments](https://news.ycombinator.com/item?id=37312723)

The Pentagon has announced a new initiative called the "Replicator Initiative" that aims to build up mass with inexpensive autonomous systems within the next 18-24 months. Deputy Secretary of Defense Kathleen Hicks stated that the goal is to have "small, smart, cheap, and many" attritable, autonomous systems that can be changed, updated, or improved with shorter lead times. The driving force behind this initiative is the concern about the size of China's military. The Pentagon wants to counter China's mass with its own mass, but in a more agile and harder-to-hit manner. The specific details of the systems under the Replicator Initiative have not been disclosed in order to not tip off Beijing, but Hicks emphasized that the approach will be responsible and ethical. The initiative will likely use commercial technology to quickly scale up production. The Pentagon has previously sent drone capabilities to Ukraine as part of aid packages, indicating the importance and need for mass in modern armed conflicts. Experts welcome the high-level focus on autonomous technologies and the urgency expressed by the Pentagon in countering China.

The discussion on this submission revolved around various aspects of military strategy, the capabilities and effectiveness of drones, and the potential risks and implications of autonomous systems in warfare. Some users compared the Pentagon's initiative to the tactics used by Russia and suggested scattering swarms of drones as a destructive and dangerous approach. Others pointed out the importance of protecting civilian lives and raised concerns about the prioritization of military resources over civilian needs. One user mentioned the potential advantage of using AI death squads against enemy swarms, while another made a reference to a video game. Discussions also touched on the challenges of supply chain management and the disposable nature of drones. Some users expressed skepticism about the hype surrounding drones and questioned the relevance of this news in relation to previous developments in drone technology. Links to relevant articles and videos were also shared by users.

### New models, tooling for Vertex AI generative AI

#### [Submission URL](https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-next-2023-announcements) | 10 points | by [panarky](https://news.ycombinator.com/user?id=panarky) | [5 comments](https://news.ycombinator.com/item?id=37309261)

Google Cloud has announced new updates and additions to its Vertex AI platform, expanding its capabilities and tools for generative AI development. The updates include new models in Model Garden, upgrades to first-party foundation models, and new tools to help enterprises get more value out of their models. The new models in Model Garden include Llama 2 and Code Llama from Meta, as well as Falcon LLM from the Technology Innovation Institute. Upgrades to foundation models include higher quality outputs and expanded capabilities for enterprise data analysis. New tools include Vertex AI Extensions and data connectors for real-time data retrieval and integration. Overall, these updates aim to provide customers with more choices, flexibility, and customization options for their generative AI projects.

The discussion on this submission revolves around various aspects of the updates and additions to Google Cloud's Vertex AI platform.

One commenter, "lksh," mentions that they wonder about the competitive pricing of Google's offering compared to OpenAI's GPT-4 model. Another commenter, "JuanPosadas," responds by saying that OpenAI's Codey model works well and suggests that the commenter may have misspelled "Codey" as "Cody." This sparks a short exchange where "lksh" apologizes for the misspelling.

Another commenter, "jdrfmn," contributes to the discussion by mentioning that Sourcegraph, a tool for code search and navigation, utilizes OpenAI's default language model (LLM) called Claude 2 for its completions.

In a separate comment, "pnrky" introduces Anthropics Claude 232k context window and PaLM 2Adapter as additional models related to the updates.

Overall, the discussion touches upon the features, capabilities, and comparisons between Google Cloud's Vertex AI platform and other existing models and tools.

### AlloyDB AI: Generative AI applications with PostgreSQL

#### [Submission URL](https://cloud.google.com/blog/products/databases/helping-developers-build-gen-ai-apps-with-google-cloud-databases) | 85 points | by [jerryjerryjerry](https://news.ycombinator.com/user?id=jerryjerryjerry) | [29 comments](https://news.ycombinator.com/item?id=37312502)

Google Cloud has announced AlloyDB AI, a set of integrated capabilities built into AlloyDB for PostgreSQL. The goal is to help developers build performant and scalable generative AI applications using their operational data. AlloyDB AI provides built-in support for vector embeddings, allowing users to easily transform their data into vector embeddings with a simple SQL function. It also runs vector queries up to 10 times faster than standard PostgreSQL. Integrations with the open-source AI ecosystem and Google Cloud's Vertex AI platform provide an end-to-end solution for building generative AI applications. AlloyDB AI is currently in preview and will be launched later this year.

The discussion on this news submission revolves around various aspects of the Google Cloud announcement of AlloyDB AI. Some users discuss the application of vector databases and the use of vector similarity searches to match products and taxonomies. There are also mentions of using GPU for semantic search and the availability of a downloadable version for preview.

One user mentions that AlloyDB is similar to AWS's Aurora DB, and others discuss architectural comparisons between AlloyDB, Aurora, and Google Cloud SQL. The potential implications of AlloyDB AI and the concerns of embracing, extending, and extinguishing (EEE) strategies are also brought up.

There are discussions about the compatibility of AlloyDB with PostgreSQL and the potential impact of its EEE approach on the open-source community. Some users express reservations about Google's track record of dropping projects.

### Duet AI for Google Workspace Now Available

#### [Submission URL](https://workspace.google.com/blog/product-announcements/duet-ai-in-workspace-now-available) | 139 points | by [meetpateltech](https://news.ycombinator.com/user?id=meetpateltech) | [68 comments](https://news.ycombinator.com/item?id=37306530)

Google has announced the general availability of Duet AI for Google Workspace, a real-time collaboration tool powered by artificial intelligence (AI). The tool, which has already been used by thousands of companies and over a million testers, acts as a coach, inspiration source, and productivity booster. Duet AI can automate tasks like creating presentations based on relevant content, generating meeting summaries and action items, and capturing notes and video snippets. It also includes features such as studio-quality video and sound in Google Meet, automatic translated captions, and enhanced chat capabilities in Google Chat. Google emphasizes that user privacy and data security are prioritized, with users having control over their data and interactions with Duet AI being private.

The discussion on Hacker News revolves around various aspects of Google's announcement of Duet AI for Google Workspace. Some users express surprise at Google's decision to label it as "general availability" instead of a typical feature rollout. Others discuss the complexity of the Google Workspace subscription process and the potential pricing options for Duet AI. There are also comments about the functionality of Duet AI, comparing it to existing tools like Slack and Microsoft Teams. The conversation touches on the availability of Duet AI for existing Google Workspace customers and the competitive landscape with OpenAI's GPT products. Some users also share their experiences with similar AI-powered tools and express their skepticism or excitement about the new offering.

### FDA schedules meeting to establish regulatory rules for artificial womb trials

#### [Submission URL](https://www.fda.gov/advisory-committees/advisory-committee-calendar/pediatric-advisory-committee-meeting-announcement-09192023) | 56 points | by [apsec112](https://news.ycombinator.com/user?id=apsec112) | [92 comments](https://news.ycombinator.com/item?id=37308675)

The FDA has announced that the Pediatric Advisory Committee will be meeting on September 19-20, 2023 to discuss the development plans for artificial womb technology (AWT) devices. The committee will specifically focus on the safety and effectiveness of AWT as an alternative to standard-of-care management for extremely premature infants in the Neonatal Intensive Care Unit. The meeting will include discussions on regulatory and ethical considerations for first in human (FIH) studies. On September 20, the meeting will be closed to allow for the review of trade secret and confidential commercial information. Interested parties can participate in the meeting and submit comments until September 18, 2023 by following the instructions provided by the FDA.

The discussion around the submission revolves around various aspects of artificial womb technology and its implications. Some commenters raise concerns about the ethical and legal implications of using artificial wombs, particularly in relation to fetal viability and abortion laws. Others discuss the potential market demand for artificial wombs and the financial implications for parents. There are also discussions about the regulatory efforts and trials related to artificial womb technology. The conversation touches on topics such as surrogacy, the rights of unborn children, and the varying definitions of personhood and legal rights across different states.

### US Air Force wants $6B to build 2k AI-powered drones

#### [Submission URL](https://www.theregister.com/2023/08/29/us_airforce_drones/) | 29 points | by [LinuxBender](https://news.ycombinator.com/user?id=LinuxBender) | [22 comments](https://news.ycombinator.com/item?id=37309006)

The US Air Force is seeking approval for a $5.8 billion budget to build up to 2,000 AI-powered drones to serve alongside human pilots. The drones, called the XQ-58A Valkyrie, are designed to be significantly cheaper than crewed fighter jets, with a cost of around $3 million each. The Air Force envisions the drones performing a range of roles, including surveillance, resupply operations, and fighting alongside human pilots as part of a swarm. The drones will recommend actions to human operators, who will still make the final decision to drop bombs or fire missiles. The project is part of the Air Force's efforts to develop "Collaborative Combat Aircraft" to achieve air superiority. Congress must approve the five-year effort, with $3.03 billion required in FY 2028 alone.

The discussion around the submission focuses on various aspects of the US Air Force's plan to build AI-powered drones. Some users express concern about the use of AI in military operations, particularly the possibility of drones carrying weapons and the potential ethical implications. Others discuss the cost-effectiveness of the drones compared to crewed fighter jets and the potential for large-scale conflicts. There is also a mention of the parallel between the Air Force's drone project and Google's language models for robots. Additionally, the conversation touches on related topics such as robotic warfare, military surveillance, and the impact of AI on global politics. One user brings up the Skynet program from the Terminator franchise as a reference. The discussion ends with a comment about the budget for national defense and logistics spending.

