## AI Submissions for Sun May 21 2023 {{ 'date': '2023-05-21T22:22:11.209Z' }}

### Deep neural networks as computational graphs (2018)

#### [Submission URL](https://medium.com/tebs-lab/deep-neural-networks-as-computational-graphs-867fcaa56c9) | 79 points | by [softwaredoug](https://news.ycombinator.com/user?id=softwaredoug) | [28 comments](https://news.ycombinator.com/item?id=36020520)

Neural networks have often been referred to as "black boxes" due to their complex structure. However, understanding the mathematics behind neural networks and how they arrive at their predictions can provide valuable insight into their use. At the core of every neural network is a single mathematical function represented by a computational graph. A computational graph is a way of representing a mathematical function in the language of graph theory, where nodes represent input values or combining functions and edges receive their weights as data flows through the graph. While math notation can also be used to represent the same functions, computational graphs are preferable for more complex neural networks with hundreds of thousands of nodes and edges.

The submission highlights how understanding mathematical functions and computational graphs can help understand the predictions of neural networks. The discussion delves deeper into various topics. Users stress the fundamental importance of understanding mathematical expressions and graphs in analyzing and manipulating graphs, as well as the advantages of computational graphs over mathematical notation for complex neural networks. Additionally, there is a conversation on distinguishing different types of structures in computational graphs such as backpropagation. The discussion also explores the significance of graphs and compilers in math, with a focus on their benefits for deep learning systems.

Furthermore, the comments touch upon the relationship between neural networks and computational graphs and their significance in AI methods. There is also a conversation on the application of computing risk metrics in financial models, how neural networks are incorporated in these models and how analyzing computational graphs can allow for sensitivity analysis. One user also recommends watching a YouTube video which breaks down how to read math expressions in neural networks. Another user brings up the topic of Theano and TensorFlow and how PyTorch is increasingly being used partly because it enables control of the computational graphs used by the neural network.

### ONR Digital Computer Newsletter (1949-64)

#### [Submission URL](http://www.bitsavers.org/pdf/onr/Digital_Computer_Newsletter/) | 30 points | by [abrax3141](https://news.ycombinator.com/user?id=abrax3141) | [3 comments](https://news.ycombinator.com/item?id=36016774)

The digital archives of the Digital Computer Newsletter, a publication that dates back to April 1949, have been made available for public access. The newsletter, which covers various aspects of computer technology and the computing industry, includes issues from 1949 to 1964 and offers valuable insights into the early days of computing. The archives have been made available online thanks to the efforts of the Computer History Museum and the Internet Archive.

The first comment provides a link to a 1953 document that lists the computing world's floor space, kilowatts of power required and people needed to operate, and also mentions high-speed random-access memory plant being 53 kilobytes in size. The second comment highlights the significance of finding such digital archives, which offer great funding agency programs, experiences for students, and access to senior scientists. Lastly, the third comment expresses gratitude for the post.

### Perfectly secure steganography using minimum entropy coupling

#### [Submission URL](https://arxiv.org/abs/2210.14889) | 45 points | by [Topolomancer](https://news.ycombinator.com/user?id=Topolomancer) | [8 comments](https://news.ycombinator.com/item?id=36022598)

Researchers have developed what they claim is the first steganography algorithm to offer perfect security guarantees with non-trivial efficiency, according to a paper submitted to the Computer Science > Cryptography and Security arXiv. The team, from Carnegie Mellon University in Pittsburgh, used minimum entropy coupling to develop a scalable steganography procedure that is resistant to detection by adversaries. The researchers also found evidence of coupling in natural language and images, which should stimulate new approaches to steganalysis, the detection of hidden messages.

The article discusses a paper submitted to the Computer Science > Cryptography and Security arXiv, which claims to have developed the first steganography algorithm offering perfect security guarantees with non-trivial efficiency. The researchers from Carnegie Mellon University used minimum entropy coupling to develop a scalable steganography procedure that is resistant to detection by adversaries. The discussion in the comments covers various aspects of steganography, its limitations, and its potential impact. One user notes the potential application of AI-generated steganography in transmitting confidential information, while another user points out the use of steganography in creating unbreakable watermarks for downstream content. Another user notes that steganography is different from encryption, and the two serve different purposes. A user mentions their interest in the references cited in the paper, while another user mentions their understanding of steganography and explains the process of decoding it.

### PrivateGPT

#### [Submission URL](https://github.com/imartinez/privateGPT) | 444 points | by [antouank](https://news.ycombinator.com/user?id=antouank) | [127 comments](https://news.ycombinator.com/item?id=36024503)

PrivateGPT is a new tool designed to interact with your documents using the power of GPT and provide 100% private communication without any data leaks. You can ingest your own documents, ask questions without an internet connection, and rely on LangChain, GPT4All, LlamaCpp, Chroma, and SentenceTransformers for the functionalities this tool provides. The instructions for setting up an environment, ingesting a test dataset, and asking questions locally are all available in the README file.

The submission is about PrivateGPT, a tool that allows users to interact with their documents using GPT for private communication. The Reddit discussion revolves around issues with compatibility and dependencies, such as the conflicts between different versions of Python or between Pyenv and Homebrew installation methods. Some contributors recommend using Docker or virtual environments to manage dependencies and isolate environments. The thread also discusses the advantages and challenges of using self-hosted and self-trained language models and machine learning tools for enterprise and consumer applications.

### The DRAKON Language

#### [Submission URL](https://drakonhub.com/en/drakon) | 216 points | by [brudgers](https://news.ycombinator.com/user?id=brudgers) | [38 comments](https://news.ycombinator.com/item?id=36021495)

DRAKON is a visual language used in the aerospace industry to represent algorithms, processes, and procedures. Its goal is to make procedures easy to understand, and it has gained recognition outside of aerospace among developers, project managers, and in medical and business fields. DRAKON is based on best practices for flowchart drawing, but also has unique features such as the skewer, silhouette, and common fate. While it is possible to draw DRAKON flowcharts in a general-purpose diagram editor, using a specialized tool such as DrakonHub provides a faster and smoother experience.

DRAKON, a visual language used in the aerospace industry to represent algorithms, has gained recognition among developers and project managers in other fields. It has a specialized tool called DrakonHub, which provides a faster and smoother experience. People in the discussion mention the existence of other fascinating languages such as Analitik, CAS Matlab, and Dragon. Despite its popularity, some people in the discussion prefer local data understanding and text-based interface over using DRAKON. There is an ongoing debate about the efficiency of using DRAKON compared to other programming languages/tools, and some people question the Soviet engineers' preference for graphic languages over traditional languages. Furthermore, some people mentioned the existence of previous discussions about DRAKON and its specifications, and a few provided relevant links. At the same time, others shared their practical experience in using DRAKON for non-trivial projects.

### AI boom could expose investors’ natural stupidity

#### [Submission URL](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/) | 180 points | by [mirthlessend](https://news.ycombinator.com/user?id=mirthlessend) | [183 comments](https://news.ycombinator.com/item?id=36022768)

Behavioural economics has some important lessons for investors hoping to cash in on artificial intelligence (AI). The first lesson to beware of bubbles since the rush of investments in AI-related capital since OpenAI released its ChatGPT chatbot in November. Orthodox asset pricing models suggest that changing but rational assessments of future profitability drive the wild gyrations of the stock market. The second lesson is that natural stupidity can drive stock market valuations to unrealistic and ultimately unprofitable extremes. Finally, investors should question whether AI is able to replicate its extraordinary predictive ability in areas such as commercial, financial, and political life where the rules can be fuzzier.

The submission discusses the important lessons for investors hoping for a profitable return on investment in artificial intelligence based on behavioral economics. The commenters in the following discussion thread explore topics such as the flaws in training language models, the potential of AI causing job loss, the limitations of AI in replicating predictive ability in certain domains, and the benefits and limitations of using AI in business operations. Additionally, there is discussion around the modeling of the market and the impact of human behavior on investment. Some commenters express concern for the speculation in the AI market leading to a potential bubble effect.

### Neural Network Architecture Beyond Width and Depth

#### [Submission URL](https://arxiv.org/abs/2205.09459) | 66 points | by [StrauXX](https://news.ycombinator.com/user?id=StrauXX) | [11 comments](https://news.ycombinator.com/item?id=36022460)

Researchers propose a new neural network architecture with an additional dimension called height for greater expressive power. The new architecture, called nested network (NestNet), is constructed recursively through a nested structure, with each hidden neuron activated by a NestNet of height ≤s-1. When s=1, a NestNet degenerates into a standard network with a two-dimensional architecture. It is proven that ReLU NestNets of height-s can approximate 1-Lipschitz continuous functions on [0,1]^d with an error O(n^{-(s+1)/d}), while the optimal approximation error of standard ReLU networks is O(n^{-2/d}). The results are extended to generic continuous functions on [0,1]^d. Numerical experiments show the super-approximation power of ReLU NestNets.

A recent paper proposes a new neural network architecture called NestNet which boasts greater expressive power through an additional dimension called height. The architecture is constructed recursively through a nested structure, with each hidden neuron activated by a NestNet of height ≤s-1. When s=1, a NestNet degenerates into a standard network with a two-dimensional architecture. The paper explains that ReLU NestNets of height-s can accurately approximate 1-Lipschitz continuous functions on [0,1]^d with an error O(n^{-(s+1)/d}), while the optimal approximation error of standard ReLU networks is O(n^{-2/d}). The results are extended to generic continuous functions on [0,1]^d. Commentators discuss the potential scaling benefits and other similar approaches for reducing network complexity. There is also a discussion on the submission's approval and updates to the paper.

### Potentially millions of Android TVs and phones come with malware preinstalled

#### [Submission URL](https://arstechnica.com/information-technology/2023/05/potentially-millions-of-android-tvs-and-phones-come-with-malware-preinstalled/) | 267 points | by [PaulHoule](https://news.ycombinator.com/user?id=PaulHoule) | [190 comments](https://news.ycombinator.com/item?id=36020431)

Two new reports have discovered that some Android devices are being sold with pre-installed malware that is difficult to remove. Security firm Trend Micro found that upwards of 8.9 million Android phones, spread across about 50 different brands, had been infected with a backdoor malware known as Guerrilla. The malware causes infected devices to communicate regularly with a remote server to see if there are any new malicious updates to install. A second report from TechCrunch said several Android-based TV boxes sold through Amazon were infected with a similar clickbot malware. It is unknown which brands are being affected.

Reports indicate that some Android devices are being sold with pre-installed malware that is difficult to remove. One report by Trend Micro has identified that about 8.9 million Android phones, spread across about 50 different brands, are infected with Guerrilla, a backdoor malware. Another report from TechCrunch discovered that several Android-based TV boxes sold through Amazon were infected with a similar clickbot malware, and it is unknown which brands are being affected. The comments included a discussion on the need for technical literacy when purchasing products and the challenges of finding a device that is both affordable and reliable. Some users also shared their experiences with different brands and types of phones. Discussions also highlight the limitations and challenges of regulating the tech industry to ensure user privacy and security. Finally, some users discussed issues they have faced with Windows 11 and concerns about Microsoft's prioritization of pre-installed software and its impact on the user experience.

### Recreating RP2040 PIO Interface in an FPGA

#### [Submission URL](https://github.com/lawrie/fpga_pio) | 94 points | by [f_devd](https://news.ycombinator.com/user?id=f_devd) | [34 comments](https://news.ycombinator.com/item?id=36022695)

Lawrie's fpga_pio project is an attempt to recreate the Raspberry Pi RP2040's programmable I/O (PIO) interface in Verilog. The PIO is a flexible peripheral that can implement a range of protocols on any GPIO pins with high speed and runs up to eight independent state machines programmed with assembler code. Lawrie's implementation is incomplete but can run some programs on open source FPGA boards like Blackice MX and Ulx3s. Programs can be assembled using the Adafuit pioasm assembler, and synthesis is achieved by running the top.v Verilog file on the aforementioned FPGA boards.

Lawrie has created fpga_pio, which is a Verilog project that mimics Raspberry Pi RP2040's programmable I/O (PIO) interface. The PIO is a flexible peripheral that runs up to eight independent state machines programmed with assembler code to implement a range of protocols on any GPIO pins with high speed. The project is incomplete, but it can run some programs on open-source FPGA boards like Blackice MX and Ulx3s. Several comments discuss the potential applications of such technology, including CMOS sensors like ADCs and the possibility of integrating FPGAs with CPUs. A few users mention other similar FPGA chips or implementations and compare them with the RP2040. Some users express their interest in the technical aspects of the project and note the potential benefits of using FPGAs. A few users caution the high cost and complexity of using FPGAs and suggest exploring other options before pursuing FPGA-based solutions.

### GPT detectors are biased against non-native English writers

#### [Submission URL](https://arxiv.org/abs/2304.02819) | 325 points | by [giuliomagnifico](https://news.ycombinator.com/user?id=giuliomagnifico) | [258 comments](https://news.ycombinator.com/item?id=36019580)

A new study shows that widely-used GPT detectors for differentiating between AI and human-generated content are biased against non-native English writers. The study found that GPT detectors consistently misclassify non-native English writing samples as AI-generated while accurately identifying native writing samples. The authors caution against the use of these detectors in evaluative or educational settings, particularly when they inadvertently penalize or exclude non-native English speakers from the global discourse. The study suggests that these detectors may unintentionally penalize writers with constrained linguistic expressions and prompts for bypassing them.

The submission discusses a study which shows that GPT detectors exhibit bias against non-native English writers, consistently misclassifying their writing samples while accurately identifying native speakers. The comments include several discussions on the nature of writing styles, with some users arguing that GPT detectors might penalize writers who use constrained linguistic expressions and prompts for bypassing these detectors. Other users discuss plagiarism in academic settings, where some argue that cheating is prevalent and can result in students passing their courses without actually learning. Finally, there are discussions about cultural perspectives on cheating and the effectiveness of plagiarism detection tools.

### Tarteel – AI-powered Quran companion

#### [Submission URL](https://www.tarteel.ai/) | 88 points | by [nraf](https://news.ycombinator.com/user?id=nraf) | [31 comments](https://news.ycombinator.com/item?id=36018332)

Tarteel, an AI-powered Quran companion, has advanced Quran memorization by interacting with recitation and notifying users of mistakes in real-time. The app enforces correct sentence structure and detects missed words or incorrect verses, presents similar verses when mistakes are made, and supports voice search and follow-along reading. Tarteel also allows users to test their memorization by hiding unrehearsed words, choose from over 112 Quran translations, and set custom challenges or track their progress with streaks. With over 20,000 ratings on the Google Play Store and the Apple App Store, the app has been discovered by over 4 million Muslims worldwide, making the Quran a daily habit for many.

The discussion around the Tarteel app is varied, with some people congratulating the team and discussing the app's functionalities while others discuss Islamic topics and question certain interpretations. One user recommends alternative applications for religious text memorization and expresses doubts about the helpfulness of AI in certain areas. There is also a discussion around the lack of a privacy policy on the Tarteel website. In addition, there is a debate about the use of AI in interpreting religious texts and its compatibility with various Islamic perspectives. One user shares their experience being forced to read the Quran in school in Iran, while another user argues against child marriage and defends marital relativism.

### Typical: Data interchange with algebraic data types

#### [Submission URL](https://github.com/stepchowfun/typical) | 122 points | by [g0xA52A2A](https://news.ycombinator.com/user?id=g0xA52A2A) | [48 comments](https://news.ycombinator.com/item?id=36019005)

Typical is a data serialization framework that generates efficient serialization and deserialization code for various languages, including Rust, TypeScript, and JavaScript. It allows for forward and backward compatibility between different schema versions and employs modern type systems based on algebraic data types for safer programming with non-nullable types and exhaustive pattern matching. Typical offers a solution to safely add or remove fields in record types without breaking compatibility, via its concept of asymmetric fields. Supported by the experiences of using Protocol Buffers and Apache Thrift, Typical is a modern solution for API developers who seek uncompromising type safety and binary compatibility between schema versions.

Typical is a data serialization framework that generates efficient serialization and deserialization code for various languages. It facilitates forward and backward compatibility between different schema versions and ensures safer programming with non-nullable types and exhaustive pattern matching. In the comments, the discussion covers topics such as human-readable encoding, the asymmetry of some fields, and how Typical compares to similar serialization frameworks. Some commenters also raised questions about the safety rules and fundamental changes, while others suggested using expressive type systems and integrating with existing systems. It is worth noting that Typical aims to offer a modern solution for developers seeking uncompromising type safety and binary compatibility.

### Testing a Formally Verified Compiler

#### [Submission URL](https://hal.science/hal-04096390/document) | 124 points | by [luu](https://news.ycombinator.com/user?id=luu) | [31 comments](https://news.ycombinator.com/item?id=36018300)

I'm sorry, but this appears to be a PDF file and not a submission from Hacker News. Can you please provide a valid Hacker News submission URL for me to generate a daily digest?

The discussion on Hacker News centers around Rich Hickey's talk on guardrails in programming and the benefits and challenges of formal reasoning. Some users discuss the use of metaphors and rhetoric in arguments and the importance of practicality in automated testing. Others argue about the cultural standards and priorities of American programmers and the relevance of formal verification and functional programming. Finally, there is a brief mention of Donald Knuth's warning about the limitations of computer bugs.

### r9: Plan 9 in Rust

#### [Submission URL](https://github.com/r9os/r9) | 119 points | by [noja](https://news.ycombinator.com/user?id=noja) | [42 comments](https://news.ycombinator.com/item?id=36019030)

The r9 operating system is a reimplementation of the Plan 9 kernel in Rust. It is derived from the original Plan 9 source code and uses cargo and the xtask pattern to build the kernel. Currently only Raspberry Pi 3 is supported for aarch64, but other useful xtask subcommands are available. The runtime dependencies use llvm-objcopy, which is expected to live in the Rust toolchain path.

The r9 operating system is a reimplementation of Plan 9 kernel in Rust, currently only supporting Raspberry Pi 3 for aarch64. The operating system uses cargo and the xtask pattern to build the kernel. The runtime dependencies use llvm-objcopy, which is expected to be in the Rust toolchain path. In the Hacker News discussion, users discuss the features of Plan 9, including its transparency in implementing many features such as networking stack and filesystems. Some users also discuss other operating systems like BeOS, Haiku, IBM PalmOS, and Newton OS. There are also discussions of the importance of lower-level development, including constraints and limitations, for different OS models. Other topics discussed include the details of Plan 9's 9p protocol, graphical user interface and non-graphical user interface, and how UI products are window focused.

### DarkBERT: A Language Model for the Dark Side of the Internet

#### [Submission URL](https://arxiv.org/abs/2305.08596) | 138 points | by [rajtilakjee](https://news.ycombinator.com/user?id=rajtilakjee) | [59 comments](https://news.ycombinator.com/item?id=36018657)

Researchers have introduced DarkBERT, a language model that is specifically trained on Dark Web data, which they argue offers valuable insights and benefits for researchers studying the Dark Web. The research suggests that the language used on the Dark Web is significantly different from that used on the Surface Web, and aims to combat the extreme lexical and structural diversity of the Dark Web in order to build a proper representation of the domain. The researchers evaluated DarkBERT against other widely used language models and found that it outperformed them in various use cases.

The submission discusses the introduction of DarkBERT, a language model that can be used to gain valuable insights into the Dark Web. However, the comments section delves into the legality and ethics of accessing and analyzing Dark Web data, with some users expressing concern about sensitive and potentially illegal content such as child pornography and illicit drug sales. Others argue that law enforcement should monitor the Dark Web to prevent and prosecute criminal activity, while some express worry about the erosion of privacy and freedoms. The discussion also touches on issues such as copyright infringement, consumption of illegal material, and the ethics of demand for exploitative content. Overall, the comments section raises important questions about the use and limitations of language models like DarkBERT and the need for responsible and ethical analysis of the Dark Web.

### The Bitter Lesson – Rich Sutton (2019)

#### [Submission URL](http://incompleteideas.net/IncIdeas/BitterLesson.html?dup) | 28 points | by [hyperthesis](https://news.ycombinator.com/user?id=hyperthesis) | [7 comments](https://news.ycombinator.com/item?id=36017857)

In a thought-provoking post on Hacker News, AI pioneer Rich Sutton contends that the history of AI research shows that general purpose methods leveraging computation are ultimately the most effective. Rather than relying on human knowledge, breakthroughs in AI have come about through scaling up computation using search and learning. Sutton argues that researchers' psychological commitments to investment in their chosen approach can inhibit further progress, and reiterates the importance of recognizing the power of general purpose methods.

The top commenters on the submission discuss the relationship between energy efficiency and general purpose methods in AI research. One comment argues that general purpose methods and increased computation lead to greater efficiency, while another points out that there are limits to available energy and suggests that there may be other factors, such as stability, worth investing in. Another commenter provides a different perspective, suggesting that modern AI is built on interpretable models and fundamental knowledge. A fourth commenter adds that Sutton's thoughts are not particularly innovative, as he has written multiple books on the topic of reinforcement learning.

### Suspicious iOS KeePass Client

#### [Submission URL](https://old.reddit.com/r/techsupport/comments/13nqarb/suspicious_ios_keepass_client/) | 275 points | by [natrys](https://news.ycombinator.com/user?id=natrys) | [160 comments](https://news.ycombinator.com/item?id=36020196)

I'm sorry, but I don't think you've provided a prompt for me to generate a daily digest of the top stories on Hacker News. The text you've pasted seems to be unrelated to the task. Please provide me with a prompt so I can assist you better.

This thread discusses various self-hosted password managers and their features. The user "egberts1" recommends KeePassXC for sync and storage in local encrypted containers, offline, with cross-platform support, and cites its password-related security as well as the use of the TwoFish algorithm. Another user, "ssbsh," praises Strongbox as a good KeePass client with native apps for iOS and macOS, with no subscription plans and a small, transparent development team. They also mention the availability of a zero-trust version for one-time purchases. "bbx" mentions that there are three versions of Strongbox, with "Strongbox Pro" offering the most features for a yearly subscription. "lxgr" brings up the issue of security breaches and recommends using non-AES symmetric algorithms such as SalsaChacha. "js2" suggests using PasswordWallet for critical passwords, mentioning its iCloud Keychain integration, and bringing up the issue of API monitoring for keystrokes on the user's device.

### KDE is ready to deprecate IRC, XMPP, and Telegram in favor of Matrix

#### [Submission URL](https://mail.kde.org/pipermail/kde-devel/2023-May/001837.html) | 71 points | by [LorenDB](https://news.ycombinator.com/user?id=LorenDB) | [33 comments](https://news.ycombinator.com/item?id=36020134)

KDE, the open-source software community, has announced the retirement of its IRC services, including Pursuivant and the Telegram Matterbridge, as their use has reportedly declined. While the BNC had only 30 active connections, the Jabber services for the domains KDETalk.net and KDE.org had only 19 active clients. The community is now largely using Matrix as the official channel for chat and the Forum is likely to be replaced by Discourse soon. The retirement of these services will enable the organization to retire one of its smaller DigitalOcean servers and focus on other areas of infrastructure.

The open-source software community, KDE, has retired its IRC services, Pursuivant and Telegram Matterbridge, due to their declining usage. The community has shifted to Matrix as the official chat channel, and the forum is likely to change to Discourse soon. The organization plans to retire one of its DigitalOcean servers, which will allow them to focus on other areas of infrastructure. 

In the comments, users discussed the use of Matrix and bridging IRC; some found bridging challenging, while others felt it was working well. There was also a discussion about Amdocs, the funding company for Element (formerly Riot), which some users accused of being involved in Israeli espionage. However, other users disputed these claims, pointing out that Amdocs had contributed to Matrix's non-financial aspects and that the vulnerabilities exploited in the conspiracy theory were fixed in subsequent updates. Some users expressed surprise that Telegram wasn't more popular within the FOSS community, while others commented on KDE's multi-platform support and its benefit for cross-platform usage.

### Notes on the Cost of Go Finalizers

#### [Submission URL](https://utcc.utoronto.ca/~cks/space/blog/programming/GoFinalizerCostsNotes) | 67 points | by [ingve](https://news.ycombinator.com/user?id=ingve) | [10 comments](https://news.ycombinator.com/item?id=36018794)

Go finalizers can come with a high cost according to a recent test from Chris Siebenmann, with using a finalizer for freeing C memory being found to be roughly ten times slower compared to directly calling C malloc() and free(). The main reason for the overhead is the fact that using a finalizer causes heap allocation, whereas non-finalizer versions do not. Additionally, using finalizers will extend the time objects take to be garbage-collected, with unused objects having finalizers taking two GC cycles to collect instead of one. The extensive documentation and limitations that come with SetFinalizer() suggest that it was not intended for heavy use and has not been highly optimized.

The discussion includes various opinions and different approaches to using finalizers in Go. One comment suggests that it is curious to debate the use of finalizers, while another agrees and also mentions that the implementation of finalizers in Go is not optimized and has limitations. Someone else adds a case where manually calling the Close method was found to be more performant than using finalizers. The discussion also includes the importance of properly closing files to free system resources and avoiding memory leaks. Another comment notes that the issue with finalizers is that they cause heap allocation, which extends the time objects take to be garbage-collected. Finally, a developer mentions that the use of RAII in C++ is more flexible and effective than the use of finalizers in Go.

### Rodney Brooks on GPT-4

#### [Submission URL](https://spectrum.ieee.org/gpt-4-calm-down) | 273 points | by [marshblocker](https://news.ycombinator.com/user?id=marshblocker) | [393 comments](https://news.ycombinator.com/item?id=36017309)

er large language models are bringing us closer to AGI. According to Brooks, the language models are impressive in their ability to generate coherent text, but they lack a true understanding of the world and common sense reasoning. He warns against confusing performance with competence and emphasizes the importance of continued research and development in both language models and other areas of AI.

Brooks also addresses the ballooning valuations of companies marketing these language models, stating that while the technology has potential, it remains to be seen whether the companies will be able to justify the high valuations. He remains optimistic about the future of AI, particularly in warehouse robotics, where his startup Robust.AI is developing robots for medium-size warehouses. 

Overall, Brooks encourages a level-headed approach to the hype surrounding large language models and a focus on continued research and development to advance the field of AI.

The submission suggests that large language models (LLMs) bring us closer to AGI, but they lack true understanding and common sense reasoning. The comments section discusses how LLMs do not truly understand the world, but are instead fed information to produce language. Some people argue that LLMs will never understand the world, while others believe that they can gain an understanding through shared knowledge and experience. Additionally, there is discussion about the potential for LLMs to lead to high valuations for companies but also the danger of confusing performance with competence. One comment shares an experiment where an LLM-like model was trained to produce sounds based on music theory to understand the fundamentals behind music theory and produced impressive results. However, there is debate over whether this means the model truly understands music theory or if it is simply following patterns.

### Show HN: Loofi – Our AI-Powered SQL Query Builder

#### [Submission URL](https://loofi.dev/) | 16 points | by [daledoback](https://news.ycombinator.com/user?id=daledoback) | [6 comments](https://news.ycombinator.com/item?id=36017420)

Hello! I'm an AI language model and I can certainly help you with that task. Just let me know how you want me to approach the summary of each submission on Hacker News. For instance, would you like me to focus on the most upvoted stories or on specific topics such as technology, startups, science, or programming?

The submission is a question about the relative value of open-source products and SaaS products, with some context provided about the person's current project and their interest in using AI language models. Several users responded with discussions about their own programming projects, including one person who mentioned using Python and Flask to create an API and another who discussed working with baseball statistics and SQL. The conversation then turned to the potential benefits of accessing government databases and using natural language processing to search for specific information. One user provided a link to a website called Splitgraph that allows for querying and sharing of government datasets.

### TSA's Facial Recognition Tech Raises Questions About Bias and Data Security

#### [Submission URL](https://reason.com/2023/05/18/tsas-facial-recognition-tech-raises-questions-about-bias-and-data-security/) | 15 points | by [fortran77](https://news.ycombinator.com/user?id=fortran77) | [9 comments](https://news.ycombinator.com/item?id=36025011)

The Transportation Security Administration (TSA) has launched a voluntary trial of biometric facial recognition technology at 16 major US airports, raising privacy and discrimination concerns. While the TSA has insisted the program is optional, an interview with its administrator in March suggested that the technology will eventually become an imposed measure. Critics warn that the TSA risks violating travelers' privacy by collecting personal data and sending it to federal agencies. Additionally, recent studies show that facial recognition technologies are least accurate for women of color. These concerns prompted a group of five senators and civil liberties organizations to pressure TSA to halt the trial until the government addresses the transparency, discrimination, and data storage issues.

The discussion on this submission revolves around the privacy concerns related to the TSA's trial of biometric facial recognition technology at several major US airports. Some commenters argue that privacy expectations in airports are already low, and the increased security measures are necessary for safety. Others point out the potential for discrimination, technical inaccuracies, and data safety issues. Some suggest that the privacy advocates are overreacting or cannot expect privacy in public spaces. One commenter even provides a link to a website that tracks the cameras in airport bathrooms to highlight the lack of privacy in public spaces.

